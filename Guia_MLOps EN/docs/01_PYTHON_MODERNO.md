# 01. Modern Python for MLOps

## ğŸ¯ Module Objective

Transform your code from "works in a notebook" to "passes code review at a FAANG company".

In this portfolio you'll apply these patterns to `common_utils/` and the code of all three projects
(BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence), so that
your Python is consistent across the entire stack.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   BEFORE (Typical Data Scientist)       AFTER (MLOps Engineer)              â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â•‘
â•‘   â€¢ One giant file                       â€¢ Installable package               â•‘
â•‘   â€¢ No types                             â€¢ Type hints everywhere             â•‘
â•‘   â€¢ Hardcoded config                     â€¢ Pydantic validation               â•‘
â•‘   â€¢ "Works on my machine"                â€¢ Works on any machine              â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

<a id="00-prerrequisitos"></a>

## 0.0 Prerequisites

- Basic Python: functions, classes, modules.
- Terminal: run commands and navigate folders.
- Environment ready to run the portfolio (if you don't have it yet, use module **[04_ENTORNOS](04_ENTORNOS.md)**).
- Optional (but recommended): understand what it means to install a package in editable mode (`pip install -e .`).

---

<a id="01-protocolo-e-como-estudiar-este-modulo"></a>

## 0.1 ğŸ§  Protocol E: How to study this module

- **Before reading**: open **[Protocol E](study_tools/PROTOCOLO_E.md)** and define your *minimum output* for the session.
- **While implementing**: if you get stuck >15 min, log the blocker in **[Error Journal](study_tools/DIARIO_ERRORES.md)**.
- **When closing the week**: use **[Weekly Closure](study_tools/CIERRE_SEMANAL.md)** to decide what to improve (quality, reproducibility, etc.).

---

<a id="02-entregables-verificables-minimo-viable"></a>

## 0.2 âœ… Verifiable deliverables (minimum viable)

Upon finishing this module, you should be able to show (in at least 1 portfolio project):

- [ ] **Type hints** in public functions (data loading, features, train, predict)
- [ ] **`mypy` running** on `src/` without critical errors
- [ ] **Config with Pydantic** (loading YAML and validating ranges)
- [ ] **Real `src/` layout** (installable package)
- [ ] **Editable installation**: `pip install -e ".[dev]"` and `pytest` running from root

---

<a id="03-puente-teoria-codigo-portafolio"></a>

## 0.3 ğŸ§© Theory â†” code bridge (Portfolio)

For this to count as real progress, force this mapping:

- **Concept**: typing / Pydantic / packaging
- **File**: `src/<package>/config.py`, `src/<package>/training.py`, `pyproject.toml`
- **Test**: `mypy src/` + `pytest`
- **Evidence**: module checklist + 1 entry in Journal if there was a blocker
## ğŸ“‹ Contents

- **0.0** [Prerequisites](#00-prerrequisitos)
- **0.1** [Protocol E: How to study this module](#01-protocolo-e-como-estudiar-este-modulo)
- **0.2** [Verifiable deliverables (minimum viable)](#02-entregables-verificables-minimo-viable)
- **0.3** [Theory â†” code bridge (Portfolio)](#03-puente-teoria-codigo-portafolio)
- **0.4** [Review: Python Fundamentals for MLOps](#04-repaso-fundamentos-python) â­ NEW
1. [Type Hints: Your Contract with the Future](#11-type-hints-tu-contrato-con-el-futuro)
2. [Pydantic: Automatic Validation](#12-pydantic-validation-automatica)
3. [src/ Layout: Professional Structure](#13-src-layout-estructura-profesional)
4. [SOLID Principles for ML](#14-principios-solid-para-ml)
5. [OOP for ML: Protocols and ABC](#15-oop-para-ml) â­ NEW
6. [Pandera: DataFrame Validation](#16-pandera-validacion-dataframes) â­ NEW
7. [Practical Exercises](#17-ejercicios-practicos)

---

<a id="04-repaso-fundamentos-python"></a>

## 0.4 Review: Python Fundamentals for MLOps

> **If you come from basic Python**, this section prepares you for the jump to professional code.
> If you already master functions, classes and modules, you can skip to section 1.1.

### ğŸ¯ From Notebook to Professional Code: The Mindset

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  THE TYPICAL DATA SCIENTIST PROBLEM:                                          â•‘
â•‘                                                                               â•‘
â•‘  In a notebook:                                                               â•‘
â•‘  â€¢ You write code in messy cells                                             â•‘
â•‘  â€¢ Global variables everywhere                                               â•‘
â•‘  â€¢ "Works" = success                                                         â•‘
â•‘  â€¢ When something fails, you restart the kernel and run everything again     â•‘
â•‘                                                                               â•‘
â•‘  In production:                                                               â•‘
â•‘  â€¢ Code must be MODULAR (divided into reusable pieces)                       â•‘
â•‘  â€¢ Dependencies must be EXPLICIT (no magic variables)                        â•‘
â•‘  â€¢ "Works" = passes tests + is understandable + is maintainable              â•‘
â•‘  â€¢ When something fails, you need to DIAGNOSE without restarting             â•‘
â•‘                                                                               â•‘
â•‘  This guide takes you from the first mindset to the second.                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Functions: The Basic Unit of Reusable Code

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NIVEL BÃSICO: Funciones simples
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âŒ CÃ³digo de notebook (todo en celdas sueltas) - NO HAGAS ESTO
import pandas as pd                              # pandas: librerÃ­a para manipular tablas (DataFrames). "pd" es la convenciÃ³n universal.
df = pd.read_csv("data.csv")                     # read_csv() lee un archivo CSV y lo convierte en DataFrame (tabla en memoria).
df = df.dropna()                                 # dropna() elimina TODAS las filas con algÃºn valor faltante (NaN). Peligroso: puedes perder datos.
df["Age"] = df["Age"].fillna(df["Age"].mean())   # fillna() rellena NaN con un valor; mean() calcula el promedio. Problema: esto ya modificÃ³ df arriba.
# ... y asÃ­ 200 lÃ­neas mÃ¡s                       # En notebooks, el cÃ³digo crece sin estructura â†’ imposible de mantener/testear.

# âœ… CÃ³digo profesional (encapsulado en funciones)
def load_and_clean_data(path: str) -> pd.DataFrame:  # def: define una funciÃ³n. "path: str" indica que espera un string. "-> pd.DataFrame" indica quÃ© retorna.
    """Carga datos y aplica limpieza bÃ¡sica.         # Docstring: documentaciÃ³n de la funciÃ³n. SIEMPRE documenta funciones pÃºblicas.
    
    Args:                                            # Args: lista de parÃ¡metros que recibe la funciÃ³n.
        path: Ruta al archivo CSV.                   # Describe cada parÃ¡metro con tipo y propÃ³sito.
        
    Returns:                                         # Returns: describe quÃ© devuelve la funciÃ³n.
        DataFrame limpio listo para feature engineering.
        
    Example:                                         # Example: muestra cÃ³mo usar la funciÃ³n (doctests ejecutables con pytest).
        >>> df = load_and_clean_data("data/raw/churn.csv")
        >>> df.shape
        (10000, 14)
    """
    df = pd.read_csv(path)                           # Lee el CSV. La ruta viene como parÃ¡metro â†’ la funciÃ³n es REUTILIZABLE.
    df = df.dropna(subset=["target"])                # subset=["target"]: solo elimina filas donde "target" es NaN, no todas las filas.
    df["Age"] = df["Age"].fillna(df["Age"].median()) # median() es mÃ¡s robusto que mean() frente a outliers.
    return df                                        # return: devuelve el resultado. Sin return, la funciÃ³n devuelve None.

# Ahora puedo REUTILIZAR esta funciÃ³n en cualquier parte
df_train = load_and_clean_data("data/train.csv")     # Llamo la funciÃ³n con datos de entrenamiento â†’ obtienen misma limpieza.
df_test = load_and_clean_data("data/test.csv")       # Llamo con datos de test â†’ GARANTIZA consistencia entre train y test.
```

### Classes: Grouping Data and Behavior

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â¿POR QUÃ‰ CLASES? La AnalogÃ­a del Formulario
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Imagina que tienes que procesar solicitudes de crÃ©dito:
#
# SIN CLASES (diccionarios sueltos):
# solicitud1 = {"nombre": "Juan", "edad": 30, "salario": 50000}
# solicitud2 = {"nombre": "Ana", "edad": None, "salario": -1000}  # Â¿VÃ¡lido?
#
# Â¿CÃ³mo validas que la edad no sea None?
# Â¿CÃ³mo evitas salarios negativos?
# Â¿DÃ³nde pones la lÃ³gica de calcular el score crediticio?
#
# CON CLASES (estructura + validaciÃ³n + comportamiento):

from dataclasses import dataclass      # dataclass: decorador que genera automÃ¡ticamente __init__, __repr__, __eq__ para tu clase.
from typing import Optional            # Optional[X] significa "puede ser X o None". Equivale a Union[X, None].

@dataclass                             # @dataclass: convierte la clase en una "data class" â†’ menos cÃ³digo boilerplate.
class SolicitudCredito:                # class: define un nuevo tipo de objeto. PascalCase por convenciÃ³n (primera letra mayÃºscula).
    """Una solicitud de crÃ©dito con validaciÃ³n bÃ¡sica."""  # Docstring de la clase: explica su propÃ³sito.
    nombre: str                        # Atributo: nombre de tipo str (texto). dataclass lo convierte en parÃ¡metro del __init__.
    edad: int                          # Atributo: edad de tipo int (entero). SerÃ¡ obligatorio al crear la instancia.
    salario: float                     # Atributo: salario de tipo float (decimal). TambiÃ©n obligatorio.
    historial_crediticio: Optional[float] = None  # Atributo OPCIONAL: tiene valor por defecto None. Puede o no proporcionarse.
    
    def __post_init__(self):           # __post_init__: mÃ©todo especial que se ejecuta DESPUÃ‰S de que dataclass crea el objeto.
        """ValidaciÃ³n al crear la instancia."""  # AquÃ­ ponemos validaciones que deben ocurrir al instanciar.
        if self.edad < 18:             # self: referencia al objeto actual. self.edad accede al atributo edad de ESTA instancia.
            raise ValueError("Debe ser mayor de edad")  # raise: lanza una excepciÃ³n. ValueError: error por valor invÃ¡lido.
        if self.salario <= 0:          # ValidaciÃ³n de negocio: salario debe ser positivo.
            raise ValueError("Salario debe ser positivo")
    
    def calcular_score(self) -> float: # MÃ©todo: funciÃ³n que pertenece a la clase. self siempre es el primer parÃ¡metro.
        """Calcula score crediticio bÃ¡sico."""
        base = min(self.salario / 1000, 100)      # min(a, b): retorna el menor. Limita el score base a 100 mÃ¡ximo.
        edad_bonus = min(self.edad - 18, 30) * 0.5  # Bonus por edad, mÃ¡ximo 15 puntos (30 * 0.5).
        return base + edad_bonus       # return: devuelve el resultado del cÃ¡lculo.

# Ahora es IMPOSIBLE crear una solicitud invÃ¡lida
solicitud = SolicitudCredito(nombre="Juan", edad=30, salario=50000)  # Crea instancia: dataclass genera __init__ con estos parÃ¡metros.
print(f"Score: {solicitud.calcular_score()}")  # f-string: f"..." permite insertar {expresiones} dentro del string. Score: 56.0

# Esto FALLA inmediatamente con un error claro
# solicitud_mala = SolicitudCredito(nombre="Ana", edad=15, salario=-1000)
# ValueError: Debe ser mayor de edad  # El error es CLARO y ocurre EN LA CREACIÃ“N, no despuÃ©s cuando ya es tarde.
```

### Modules: Organizing Code in Files

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â¿POR QUÃ‰ MÃ“DULOS? La AnalogÃ­a de la Biblioteca
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Una biblioteca tiene SECCIONES (mÃ³dulos):
# - SecciÃ³n de novelas (data.py)
# - SecciÃ³n de ciencia (features.py)
# - SecciÃ³n de historia (training.py)
#
# Cada secciÃ³n tiene su PROPÃ“SITO y no mezclas libros de cocina con novelas.

# Estructura tÃ­pica de un proyecto ML:
#
# src/bankchurn/
# â”œâ”€â”€ __init__.py      # "Esta carpeta es un paquete Python"
# â”œâ”€â”€ config.py        # ConfiguraciÃ³n (Pydantic)
# â”œâ”€â”€ data.py          # Carga y limpieza de datos
# â”œâ”€â”€ features.py      # Feature engineering
# â”œâ”€â”€ training.py      # Entrenamiento del modelo
# â”œâ”€â”€ evaluation.py    # MÃ©tricas y evaluaciÃ³n
# â””â”€â”€ prediction.py    # Inferencia en producciÃ³n

# Importar desde mÃ³dulos:
from bankchurn.config import BankChurnConfig
from bankchurn.data import load_and_clean_data
from bankchurn.training import ChurnTrainer

# Esto es MUCHO mÃ¡s claro que tener todo en un archivo de 2000 lÃ­neas
```

### Decorators: Functions that Modify Functions

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DECORADORES: Muy usados en MLOps (logging, timing, caching, validaciÃ³n)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import time                            # time: mÃ³dulo estÃ¡ndar de Python para medir tiempo. time.time() da segundos desde 1970.
from functools import wraps            # wraps: preserva metadatos de la funciÃ³n original (nombre, docstring) al decorarla.

def medir_tiempo(func):                # Un decorador es una funciÃ³n que RECIBE otra funciÃ³n como parÃ¡metro.
    """Decorador que mide el tiempo de ejecuciÃ³n de una funciÃ³n."""
    @wraps(func)                       # @wraps(func): copia __name__, __doc__ de func a wrapper. Sin esto, se pierde el nombre original.
    def wrapper(*args, **kwargs):      # wrapper: funciÃ³n interna que "envuelve" a la original. *args/**kwargs capturan cualquier argumento.
        inicio = time.time()           # Guarda el tiempo ANTES de ejecutar la funciÃ³n.
        resultado = func(*args, **kwargs)  # Ejecuta la funciÃ³n original con sus argumentos. func es la funciÃ³n decorada.
        fin = time.time()              # Guarda el tiempo DESPUÃ‰S de ejecutar.
        print(f"â±ï¸ {func.__name__} tardÃ³ {fin - inicio:.2f}s")  # __name__: nombre de la funciÃ³n. :.2f formatea a 2 decimales.
        return resultado               # Retorna lo que retornÃ³ la funciÃ³n original (no "comerse" el resultado).
    return wrapper                     # El decorador retorna la funciÃ³n wrapper, que reemplaza a la original.

# Uso:
@medir_tiempo                          # @decorador es equivalente a: entrenar_modelo = medir_tiempo(entrenar_modelo)
def entrenar_modelo(X, y):             # Esta funciÃ³n ahora estÃ¡ "envuelta" por wrapper. Al llamarla, ejecuta wrapper.
    """Entrena un modelo (simulado)."""
    time.sleep(2)                      # sleep(2): pausa 2 segundos. Simula un proceso que tarda (como entrenar un modelo).
    return "modelo_entrenado"          # Retorna un string (en la realidad serÃ­a el modelo entrenado).

modelo = entrenar_modelo(None, None)   # Llamar entrenar_modelo() realmente llama a wrapper(), que mide tiempo y llama a la original.
# Output: â±ï¸ entrenar_modelo tardÃ³ 2.00s  # El decorador aÃ±adiÃ³ comportamiento (medir tiempo) SIN modificar la funciÃ³n original.

# En el portafolio verÃ¡s decoradores para:
# - Logging automÃ¡tico de funciones    # Registrar cada llamada a funciÃ³n con sus parÃ¡metros.
# - Caching de resultados costosos     # @lru_cache: guarda resultados para no recalcular.
# - ValidaciÃ³n de inputs/outputs       # Verificar tipos o rangos antes/despuÃ©s de ejecutar.
# - Retry de operaciones que pueden fallar  # Reintentar N veces si hay error (Ãºtil para APIs, BD).
```

### Context Managers: Resources that Clean Up Themselves

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTEXT MANAGERS: Cruciales para archivos, conexiones, MLflow runs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âŒ PROBLEMA: Si hay un error, el archivo queda abierto
f = open("data.csv", "r")              # open(): abre un archivo. "r" = modo lectura. Retorna un objeto file.
data = f.read()                        # read(): lee TODO el contenido del archivo a memoria (cuidado con archivos grandes).
# ... si algo falla aquÃ­, f nunca se cierra  # Si ocurre una excepciÃ³n, el cÃ³digo salta y f.close() nunca se ejecuta.
f.close()                              # close(): libera el recurso. Sin cerrar, puedes agotar file descriptors del sistema.

# âœ… SOLUCIÃ“N: with garantiza que el archivo se cierre
with open("data.csv", "r") as f:       # with: inicia un "context manager". "as f" asigna el archivo a la variable f.
    data = f.read()                    # El cÃ³digo dentro del with tiene acceso a f.
# f se cierra automÃ¡ticamente, incluso si hay error  # Al salir del with (normal o por excepciÃ³n), Python llama f.__exit__() que cierra el archivo.

# En MLflow (que usarÃ¡s en el mÃ³dulo 10):
import mlflow                          # mlflow: librerÃ­a para tracking de experimentos ML. VerÃ¡s mÃ¡s en mÃ³dulo 10.

with mlflow.start_run(run_name="experimento_1"):  # start_run(): inicia un "run" de MLflow. Es un context manager.
    mlflow.log_param("n_estimators", 100)         # log_param(): registra un hiperparÃ¡metro. Se guarda asociado al run.
    mlflow.log_metric("f1_score", 0.85)           # log_metric(): registra una mÃ©trica. Puedes ver esto en la UI de MLflow.
    # El run se cierra automÃ¡ticamente al salir del with  # MLflow guarda todo y marca el run como finalizado.
```

### Comprehensions: Concise and Pythonic Code

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPREHENSIONS: Transformaciones elegantes de datos
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# List comprehension (muy comÃºn en ML)
columnas = ["CreditScore", "Age", "Balance", "Exited"]  # Lista de strings con nombres de columnas.
columnas_numericas = [col for col in columnas if col != "Exited"]  # [expresiÃ³n for variable in iterable if condiciÃ³n]
# ['CreditScore', 'Age', 'Balance']  # Resultado: lista con todos los elementos EXCEPTO "Exited".
# Equivale a:                        # Es equivalente a un for loop, pero en UNA lÃ­nea:
# columnas_numericas = []            # result = []
# for col in columnas:               # for col in columnas:
#     if col != "Exited":            #     if col != "Exited":
#         columnas_numericas.append(col)  #         result.append(col)

# Dict comprehension (Ãºtil para mÃ©tricas)
metricas = {"accuracy": 0.85, "precision": 0.78, "recall": 0.72}  # Diccionario: {clave: valor}.
metricas_redondeadas = {k: round(v, 2) for k, v in metricas.items()}  # {clave: valor for clave, valor in dict.items()}
# items(): retorna pares (clave, valor). round(v, 2): redondea v a 2 decimales.

# Filtrar columnas por tipo (patrÃ³n comÃºn en feature engineering)
import pandas as pd                  # pandas ya se explicÃ³ arriba; aquÃ­ se re-importa por claridad del ejemplo.
df = pd.DataFrame({"A": [1, 2], "B": ["x", "y"], "C": [1.5, 2.5]})  # DataFrame: tabla con 3 columnas.
columnas_numericas = [col for col in df.columns if df[col].dtype in ["int64", "float64"]]
# df.columns: lista de nombres de columnas. df[col].dtype: tipo de datos de esa columna.
# "int64", "float64": tipos numÃ©ricos de pandas/numpy. Este patrÃ³n filtra SOLO columnas numÃ©ricas.

# Crear diccionario de features categÃ³ricas a codificar
cat_cols = ["Geography", "Gender"]   # Lista de columnas categÃ³ricas que queremos codificar.
encoding_map = {col: df[col].unique().tolist() for col in cat_cols}
# unique(): valores Ãºnicos de la columna. tolist(): convierte array a lista Python.
# Resultado: {"Geography": ["France", "Spain", ...], "Gender": ["Male", "Female"]}
```

### Exception Handling: Code that Doesn't Break

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXCEPCIONES: Anticipar y manejar errores profesionalmente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from pathlib import Path                # Path: clase para manejar rutas de archivos de forma segura y multiplataforma.
import logging                          # logging: mÃ³dulo estÃ¡ndar para registrar mensajes (mejor que print en producciÃ³n).

logger = logging.getLogger(__name__)    # getLogger(__name__): crea un logger con el nombre del mÃ³dulo actual.
                                        # __name__ es una variable especial que contiene el nombre del mÃ³dulo.

def cargar_modelo(path: Path):          # FunciÃ³n que recibe un Path (no string) â†’ mÃ¡s seguro y con autocompletado.
    """Carga un modelo serializado con manejo de errores.
    
    Args:
        path: Ruta al archivo .joblib del modelo.
        
    Returns:
        Modelo cargado.
        
    Raises:                              # Raises: documenta quÃ© excepciones puede lanzar esta funciÃ³n.
        FileNotFoundError: Si el archivo no existe.
        ValueError: Si el archivo no contiene un modelo vÃ¡lido.
    """
    if not path.exists():                # exists(): mÃ©todo de Path que verifica si el archivo/carpeta existe.
        raise FileNotFoundError(f"Modelo no encontrado: {path}")  # raise: lanza una excepciÃ³n. El programa se detiene aquÃ­.
    
    try:                                 # try: intenta ejecutar el cÃ³digo. Si falla, salta al except.
        import joblib                    # joblib: librerÃ­a para serializar objetos Python (modelos sklearn).
        modelo = joblib.load(path)       # load(): deserializa el archivo y retorna el objeto Python guardado.
    except Exception as e:               # except: captura la excepciÃ³n si algo fallÃ³ en el try. "as e" guarda el error.
        logger.error(f"Error cargando modelo: {e}")  # error(): registra un mensaje de nivel ERROR en el log.
        raise ValueError(f"Archivo invÃ¡lido: {path}") from e  # from e: encadena excepciones (muestra la causa original).
    
    # Validar que sea un modelo sklearn
    if not hasattr(modelo, "predict"):   # hasattr(): verifica si el objeto tiene un atributo/mÃ©todo. Todos los modelos sklearn tienen predict().
        raise ValueError(f"El archivo no contiene un modelo vÃ¡lido: {path}")
    
    logger.info(f"Modelo cargado exitosamente: {path}")  # info(): mensaje informativo (menos grave que error).
    return modelo                        # Si llegamos aquÃ­, todo saliÃ³ bien. Retornamos el modelo cargado.

# Uso con manejo de error
try:                                     # try/except: patrÃ³n para manejar errores sin que el programa crashee.
    modelo = cargar_modelo(Path("models/pipeline.joblib"))  # Path(): convierte string a objeto Path.
except FileNotFoundError:                # Captura SOLO FileNotFoundError. Otros errores no se capturan aquÃ­.
    print("âš ï¸ Modelo no encontrado. Ejecuta 'make train' primero.")  # Mensaje amigable al usuario.
except ValueError as e:                  # Captura ValueError. "as e" permite acceder al mensaje de error.
    print(f"âŒ Error de validaciÃ³n: {e}")  # f-string con el error especÃ­fico.
```

### ğŸ¯ Self-Assessment Exercise: Are You Ready?

Before continuing, verify that you can answer these questions:

```python
# 1. Â¿QuÃ© hace este cÃ³digo?
def process(items: list[str]) -> dict[str, int]:
    return {item: len(item) for item in items if item}

# 2. Â¿Por quÃ© esto es mejor que usar un diccionario?
@dataclass
class Config:
    batch_size: int = 32
    learning_rate: float = 0.001

# 3. Â¿QuÃ© problema evita el "with"?
with open("file.txt") as f:
    data = f.read()

# 4. Â¿QuÃ© imprime este cÃ³digo?
def decorator(func):
    def wrapper():
        print("antes")
        func()
        print("despuÃ©s")
    return wrapper

@decorator
def hello():
    print("hola")

hello()
```

<details>
<summary>ğŸ” Ver respuestas</summary>

1. **Crea un diccionario** donde las keys son strings no vacÃ­os y los values son sus longitudes.

2. **ValidaciÃ³n y documentaciÃ³n automÃ¡tica**: `@dataclass` genera `__init__`, `__repr__`, y permite type hints. Un diccionario no valida tipos ni tiene autocompletado en el IDE.

3. **Evita dejar archivos abiertos**: Si hay un error dentro del `with`, el archivo se cierra automÃ¡ticamente.

4. **Imprime**:
   ```
   antes
   hola
   despuÃ©s
   ```
   El decorador "envuelve" la funciÃ³n original.

</details>

---

<a id="11-type-hints-tu-contrato-con-el-futuro"></a>

## 1.1 Type Hints: Your Contract with the Future

### The Restaurant Analogy

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ½ï¸ IMAGINE A RESTAURANT:                                                 â•‘
â•‘                                                                           â•‘
â•‘  WITHOUT MENU (code without types):                                       â•‘
â•‘  - "Bring me something to eat"                                            â•‘
â•‘  - The chef improvises                                                    â•‘
â•‘  - The customer doesn't know what to expect                               â•‘
â•‘  - Result: surprises (bugs)                                               â•‘
â•‘                                                                           â•‘
â•‘  WITH MENU (code with types):                                             â•‘
â•‘  - "I want dish #5: Pasta Carbonara"                                      â•‘
â•‘  - The chef knows exactly what to prepare                                 â•‘
â•‘  - The customer knows what they'll receive                                â•‘
â•‘  - Result: consistency                                                    â•‘
â•‘                                                                           â•‘
â•‘  TYPE HINTS = Your code's menu                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Real Portfolio Code: Without Types vs With Types

```python
# âŒ ANTES: Â¿QuÃ© recibe? Â¿QuÃ© retorna? 
# (Esto es lo que encontrarÃ­as en un notebook)

def prepare_features(df, num_cols, cat_cols, target):  # Define una funciÃ³n sin type hints: no sabemos tipos esperados ni retornos.
    X = df.drop(columns=[target])  # Separa features (X) eliminando la columna objetivo del DataFrame.
    y = df[target]  # Extrae el target (y) como una Serie; asume que `target` existe y estÃ¡ bien escrito.
    
    preprocessor = ColumnTransformer([  # Crea un transformador por columnas: aplica pipelines distintos a columnas numÃ©ricas vs categÃ³ricas.
        ('num', StandardScaler(), num_cols),  # (nombre, transformer, columnas): escala numÃ©ricas a media=0, var=1 (ayuda a muchos modelos).
        ('cat', OneHotEncoder(), cat_cols)  # One-hot a categÃ³ricas; por defecto puede fallar si aparece una categorÃ­a nueva en inferencia.
    ])  # Termina la definiciÃ³n del ColumnTransformer (aÃºn no se ha entrenado/ajustado).
    
    X_transformed = preprocessor.fit_transform(X)  # Ajusta (fit) el preprocesador usando X y luego transforma X; devuelve una matriz (a menudo sparse).
    return X_transformed, y, preprocessor  # Retorna features transformadas, el target y el preprocesador ya ajustado (para usar igual en valid/test/inferencia).
```

```python
# âœ… DESPUÃ‰S: CÃ³digo real de BankChurn-Predictor/src/bankchurn/training.py

from __future__ import annotations  # Posponer evaluaciÃ³n de anotaciones: permite forward refs y reduce problemas de import/ciclos.

from pathlib import Path  # Paths tipados/seguros (mejor que strings) para rutas de archivos/directorios.
from typing import List, Tuple  # Tipos genÃ©ricos para anotar colecciones y retornos compuestos.

import numpy as np  # NumPy: arrays y tipos numÃ©ricos; Ãºtil para tipar dtypes concretos.
import pandas as pd  # Pandas: DataFrame/Series, estructuras tÃ­picas para datos tabulares.
from numpy.typing import NDArray  # Tipo estÃ¡tico para arrays NumPy: ayuda a mypy a entender shapes/dtypes (hasta cierto punto).
from sklearn.compose import ColumnTransformer  # Enrutador de transformaciones por grupo de columnas (numÃ©ricas/categÃ³ricas/etc.).
from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Transformadores estÃ¡ndar de scikit-learn.

def prepare_features(
    df: pd.DataFrame,  # Input tabular: se asume que contiene features + columna objetivo.
    num_cols: List[str],  # Lista de nombres de columnas numÃ©ricas: se usarÃ¡ para escalar.
    cat_cols: List[str],  # Lista de nombres de columnas categÃ³ricas: se usarÃ¡ para one-hot.
    target: str  # Nombre de la columna objetivo (label) que se va a separar en y.
) -> Tuple[NDArray[np.float64], pd.Series, ColumnTransformer]:
    """Prepara features para entrenamiento.
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    num_cols : List[str]
        Nombres de columnas numÃ©ricas.
    cat_cols : List[str]
        Nombres de columnas categÃ³ricas.
    target : str
        Nombre de la columna objetivo.
    
    Returns
    -------
    Tuple[NDArray, pd.Series, ColumnTransformer]
        Features transformadas, target, y preprocessor fitted.
    """
    X = df.drop(columns=[target])  # Construye X eliminando la columna objetivo: evita leakage obvio (target dentro de features).
    y = df[target]  # Construye y como Serie: etiqueta que el modelo intentarÃ¡ predecir.
    
    preprocessor = ColumnTransformer([  # Define el pipeline de preprocesamiento: se â€œfijaâ€ aquÃ­ para ser reproducible.
        ('num', StandardScaler(), num_cols),  # Escalado numÃ©rico: Ãºtil para modelos lineales/NN; inofensivo para muchos casos.
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # ignore evita crash en inferencia si llega una categorÃ­a nueva.
    ])  # Nota MLOps: guardar este objeto es clave para que producciÃ³n use la misma transformaciÃ³n que entrenamiento.
    
    X_transformed = preprocessor.fit_transform(X)  # Ajusta el preprocesador (learn stats/categorÃ­as) y transforma X al espacio numÃ©rico.
    return X_transformed, y, preprocessor  # Retorna tuple explÃ­cita y tipada: mypy/IDE verifican contratos y ayudan en refactors.
```

### Essential Types for ML

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS BÃSICOS - Los usarÃ¡s constantemente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import (                   # typing: mÃ³dulo estÃ¡ndar de Python para anotaciones de tipos.
    List,       # Lista de elementos: List[str] = ["a", "b"]  # Lista donde TODOS los elementos son strings.
    Dict,       # Diccionario: Dict[str, float] = {"acc": 0.95}  # Dict con claves str y valores float.
    Tuple,      # Tupla fija: Tuple[int, int] = (100, 10)  # Tupla de exactamente 2 enteros.
    Optional,   # Puede ser None: Optional[Path] = None  # Equivale a Union[Path, None].
    Union,      # MÃºltiples tipos: Union[str, List[str]]  # Puede ser string O lista de strings.
    Any,        # Cualquier tipo (evitar si posible)  # Desactiva type checking - Ãºsalo solo si es inevitable.
    Literal,    # Valores especÃ­ficos: Literal["train", "eval"]  # SOLO puede ser "train" o "eval", nada mÃ¡s.
)
from pathlib import Path               # Path: ya explicado en excepciones. Mejor que strings para rutas.

# Ejemplos del portafolio real:

# BankChurn: features son listas de strings
features: List[str] = ["CreditScore", "Age", "Balance"]  # ": List[str]" indica el tipo. mypy verifica que sea correcto.

# CarVision: mÃ©tricas son diccionario string->float
metrics: Dict[str, float] = {"rmse": 4794.27, "r2": 0.77}  # Claves son strings (nombres), valores son floats (nÃºmeros).

# TelecomAI: puede recibir path o None
model_path: Optional[Path] = None      # Optional[X] = puede ser X o None. Ãštil para parÃ¡metros opcionales.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS PARA ML - EspecÃ­ficos de Machine Learning
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import pandas as pd                    # pandas: la librerÃ­a estÃ¡ndar para datos tabulares. Ya la vimos antes.
import numpy as np                     # numpy: librerÃ­a para arrays numÃ©ricos de alto rendimiento. Base de sklearn/pandas.
from numpy.typing import NDArray       # NDArray: tipo para arrays numpy. NDArray[np.float64] = array de floats de 64 bits.
from sklearn.base import BaseEstimator # BaseEstimator: clase base de TODOS los modelos sklearn. Garantiza fit/predict.
from sklearn.pipeline import Pipeline  # Pipeline: encadena transformadores + modelo. Lo verÃ¡s en mÃ³dulo 07.

# DataFrame de pandas
def load_data(path: Path) -> pd.DataFrame:  # Retorna pd.DataFrame: indica que devuelve una tabla de pandas.
    return pd.read_csv(path)           # read_csv lee el archivo y retorna un DataFrame.

# Array NumPy tipado
def predict_proba(X: NDArray[np.float64]) -> NDArray[np.float64]:  # NDArray[np.float64]: array de floats 64-bit.
    return model.predict_proba(X)[:, 1]  # predict_proba retorna probabilidades. [:, 1] selecciona columna 1 (clase positiva).

# Modelo sklearn
def train_model(X: NDArray, y: NDArray) -> BaseEstimator:  # Retorna BaseEstimator: cualquier modelo sklearn.
    model = RandomForestClassifier()   # Crea instancia del modelo. RandomForest: ensemble de Ã¡rboles de decisiÃ³n.
    model.fit(X, y)                    # fit(): entrena el modelo con datos X (features) e y (target).
    return model                       # Retorna el modelo entrenado (listo para predict).

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS AVANZADOS - Para cÃ³digo mÃ¡s robusto
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import TypedDict, Literal  # TypedDict: dict con estructura fija. Literal: valores especÃ­ficos.

# TypedDict: diccionarios con estructura conocida
class MetricsDict(TypedDict):          # TypedDict: define un diccionario donde cada clave tiene tipo especÃ­fico.
    accuracy: float                    # La clave "accuracy" DEBE ser float. mypy lo verifica.
    precision: float                   # Todas las mÃ©tricas de clasificaciÃ³n son floats.
    recall: float                      # recall: proporciÃ³n de positivos reales detectados.
    f1: float                          # f1: media armÃ³nica de precision y recall.
    roc_auc: float                     # roc_auc: Ã¡rea bajo la curva ROC. 1.0 = perfecto.

# Literal: solo valores especÃ­ficos permitidos
ModelType = Literal["random_forest", "logistic", "gradient_boosting"]  # Crea un "tipo alias" que solo acepta estos 3 strings.

def build_model(model_type: ModelType, seed: int) -> BaseEstimator:  # model_type SOLO puede ser uno de los 3 valores.
    """
    mypy SABE que model_type solo puede ser estos 3 valores.
    Si escribes build_model("xgboost", 42), mypy darÃ¡ error.
    """
    if model_type == "random_forest":  # Compara string. Python permite esto aunque model_type sea Literal.
        return RandomForestClassifier(random_state=seed)  # random_state: semilla para reproducibilidad.
    elif model_type == "logistic":     # elif: "else if" - solo se evalÃºa si el if anterior fue False.
        return LogisticRegression(random_state=seed)      # LogisticRegression: modelo lineal para clasificaciÃ³n.
    else:  # gradient_boosting         # else: se ejecuta si ningÃºn if/elif fue True.
        return GradientBoostingClassifier(random_state=seed)  # GradientBoosting: ensemble de Ã¡rboles secuenciales.
```

### Configure mypy

Add this to your `pyproject.toml`:

```toml
# pyproject.toml - ConfiguraciÃ³n de mypy
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true      # â† Fuerza tipos en todas las funciones
ignore_missing_imports = true     # â† Para librerÃ­as sin stubs

# Ignorar librerÃ­as de ML que no tienen stubs completos
[[tool.mypy.overrides]]
module = [
    "sklearn.*",
    "pandas.*", 
    "numpy.*",
    "mlflow.*",
    "joblib.*",
]
ignore_missing_imports = true
```

Run:
```bash
mypy src/  # Verify types in all code
```

---

<a id="12-pydantic-validation-automatica"></a>

## 1.2 Pydantic: Automatic Validation

### The Security Guard Analogy

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ›¡ï¸ IMAGINE AN OFFICE BUILDING:                                           â•‘
â•‘                                                                           â•‘
â•‘  WITHOUT GUARD (code without Pydantic):                                   â•‘
â•‘  - Anyone enters with anything                                            â•‘
â•‘  - You discover problems AFTER THEY HAPPENED                              â•‘
â•‘  - "Why is test_size 1.5?" â†’ Error in production                         â•‘
â•‘                                                                           â•‘
â•‘  WITH GUARD (code with Pydantic):                                         â•‘
â•‘  - Verifies credentials AT THE ENTRANCE                                   â•‘
â•‘  - Problems detected BEFORE causing damage                                â•‘
â•‘  - "test_size must be between 0 and 1" â†’ Immediate and clear error       â•‘
â•‘                                                                           â•‘
â•‘  PYDANTIC = Your configuration's guard                                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Real Code: BankChurn Config (Staff Level)

This is the `src/bankchurn/config.py` file from the portfolio:

```python
"""Configuration management for BankChurn predictor.

Este mÃ³dulo demuestra Pydantic a nivel profesional:
- ValidaciÃ³n de rangos con Field
- Configuraciones anidadas
- Valores por defecto sensatos
- Carga desde YAML
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, List

import yaml
from pydantic import BaseModel, Field


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIONES ANIDADAS - Cada componente tiene su propia config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LogisticRegressionConfig(BaseModel):
    """HiperparÃ¡metros de Logistic Regression."""
    C: float = 0.1
    class_weight: str = "balanced"
    solver: str = "liblinear"
    max_iter: int = 1000


class RandomForestConfig(BaseModel):
    """HiperparÃ¡metros de Random Forest."""
    n_estimators: int = 100
    max_depth: int = 10
    min_samples_split: int = 10
    min_samples_leaf: int = 5
    class_weight: str = "balanced_subsample"
    n_jobs: int = -1


class EnsembleConfig(BaseModel):
    """ConfiguraciÃ³n del ensemble."""
    voting: str = Field("soft", pattern="^(hard|soft)$")  # â† Solo permite "hard" o "soft"
    weights: List[float] = [0.4, 0.6]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N PRINCIPAL - Agrupa todo con validaciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ModelConfig(BaseModel):
    """ConfiguraciÃ³n de entrenamiento del modelo."""
    type: str = "ensemble"
    test_size: float = Field(0.2, ge=0.0, le=1.0)   # â† VALIDACIÃ“N: entre 0 y 1
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)                   # â† VALIDACIÃ“N: mÃ­nimo 2
    resampling_strategy: str = "none"
    
    # Configuraciones de modelos especÃ­ficos (anidadas)
    ensemble: EnsembleConfig = EnsembleConfig()
    logistic_regression: LogisticRegressionConfig = LogisticRegressionConfig()
    random_forest: RandomForestConfig = RandomForestConfig()


class DataConfig(BaseModel):
    """ConfiguraciÃ³n de datos."""
    target_column: str = "Exited"
    categorical_features: List[str] = []
    numerical_features: List[str] = []
    drop_columns: List[str] = []


class MLflowConfig(BaseModel):
    """ConfiguraciÃ³n de MLflow tracking."""
    tracking_uri: str = "file:./mlruns"
    experiment_name: str = "bankchurn"
    enabled: bool = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N RAÃZ - El punto de entrada
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BankChurnConfig(BaseModel):
    """ConfiguraciÃ³n completa de BankChurn.
    
    Uso:
        config = BankChurnConfig.from_yaml("configs/config.yaml")
        print(config.model.test_size)  # 0.2
    """
    model: ModelConfig
    data: DataConfig
    mlflow: MLflowConfig

    @classmethod
    def from_yaml(cls, config_path: str | Path) -> BankChurnConfig:
        """Carga configuraciÃ³n desde archivo YAML.
        
        Parameters
        ----------
        config_path : str or Path
            Ruta al archivo YAML.
            
        Returns
        -------
        BankChurnConfig
            ConfiguraciÃ³n validada.
            
        Raises
        ------
        FileNotFoundError
            Si el archivo no existe.
        ValidationError
            Si la configuraciÃ³n es invÃ¡lida.
        """
        config_path = Path(config_path)
        
        if not config_path.exists():
            raise FileNotFoundError(f"Config file not found: {config_path}")
        
        with open(config_path, "r") as f:
            config_dict = yaml.safe_load(f) or {}
        
        # Valores por defecto para secciones faltantes
        if "model" not in config_dict:
            config_dict["model"] = ModelConfig().dict()
        if "data" not in config_dict:
            config_dict["data"] = DataConfig().dict()
        if "mlflow" not in config_dict:
            config_dict["mlflow"] = MLflowConfig().dict()
        
        return cls(**config_dict)  # â† Pydantic valida automÃ¡ticamente
```

### The Corresponding YAML

```yaml
# configs/config.yaml
model:
  type: ensemble
  test_size: 0.2         # Si pones 1.5, Pydantic darÃ¡ error
  random_state: 42
  cv_folds: 5            # Si pones 1, Pydantic darÃ¡ error
  resampling_strategy: none
  
  ensemble:
    voting: soft         # Si pones "maybe", Pydantic darÃ¡ error
    weights: [0.4, 0.6]
    
  random_forest:
    n_estimators: 200
    max_depth: 10

data:
  target_column: Exited
  categorical_features:
    - Geography
    - Gender
  numerical_features:
    - CreditScore
    - Age
    - Balance
  drop_columns:
    - RowNumber
    - CustomerId
    - Surname

mlflow:
  tracking_uri: "file:./mlruns"
  experiment_name: bankchurn
  enabled: true
```

### Validation Error Example

```python
# âŒ Esto FALLA inmediatamente con un error claro

config_dict = {
    "model": {
        "test_size": 1.5,  # â† Error: debe ser <= 1.0
        "cv_folds": 1,     # â† Error: debe ser >= 2
    },
    "data": {},
    "mlflow": {}
}

try:
    config = BankChurnConfig(**config_dict)
except ValidationError as e:
    print(e)
    # Output:
    # 2 validation errors for BankChurnConfig
    # model -> test_size
    #   ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
    # model -> cv_folds
    #   ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)
```

---

<a id="13-src-layout-estructura-profesional"></a>

## 1.3 src/ Layout: Professional Structure

### The House Analogy

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ  IMAGINE ORGANIZING A HOUSE:                                           â•‘
â•‘                                                                           â•‘
â•‘  MESSY HOUSE (code in root):                                              â•‘
â•‘  - Everything in the living room: clothes, food, tools                    â•‘
â•‘  - Impossible to find anything                                            â•‘
â•‘  - You invite someone: "sorry for the mess"                               â•‘
â•‘                                                                           â•‘
â•‘  ORGANIZED HOUSE (src/ layout):                                           â•‘
â•‘  - Kitchen for cooking, bathroom for bathroom, closet for clothes         â•‘
â•‘  - Everything in its place                                                â•‘
â•‘  - You invite someone: "welcome, have a seat"                             â•‘
â•‘                                                                           â•‘
â•‘  src/ layout = Professional code organization                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Portfolio Structure

```
BankChurn-Predictor/
â”œâ”€â”€ src/                          # â† TODO el cÃ³digo fuente aquÃ­
â”‚   â”œâ”€â”€ __init__.py               # Hace src/ un paquete
â”‚   â””â”€â”€ bankchurn/                # â† El paquete principal
â”‚       â”œâ”€â”€ __init__.py           # Exporta la API pÃºblica
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ training.py           # Pipeline de entrenamiento
â”‚       â”œâ”€â”€ evaluation.py         # MÃ©tricas y evaluaciÃ³n
â”‚       â”œâ”€â”€ prediction.py         # Inferencia
â”‚       â”œâ”€â”€ models.py             # Custom classifiers
â”‚       â””â”€â”€ cli.py                # Interfaz de lÃ­nea de comandos
â”‚
â”œâ”€â”€ app/                          # â† Aplicaciones (no es un paquete)
â”‚   â””â”€â”€ fastapi_app.py            # API REST
â”‚
â”œâ”€â”€ tests/                        # â† Tests (espejo de src/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidas
â”‚   â”œâ”€â”€ test_config.py            # Tests para config.py
â”‚   â”œâ”€â”€ test_training.py          # Tests para training.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ configs/                      # â† ConfiguraciÃ³n externa
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/                         # â† Datos (gitignored)
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ Churn_Modelling.csv
â”‚
â”œâ”€â”€ artifacts/                    # â† Artefactos generados (gitignored)
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ training_results.json
â”‚
â”œâ”€â”€ pyproject.toml                # â† Metadata del proyecto
â”œâ”€â”€ Makefile                      # â† Comandos comunes
â”œâ”€â”€ Dockerfile                    # â† ContainerizaciÃ³n
â””â”€â”€ README.md                     # â† DocumentaciÃ³n
```

### Why src/ and not code in root?

```python
# âŒ PROBLEMA: Sin src/, Python puede importar cÃ³digo no instalado
# Esto causa el famoso "funciona en mi mÃ¡quina pero no en CI"

# Estructura plana (problemÃ¡tica):
# myproject/
# â”œâ”€â”€ mymodule.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
import mymodule  # â† Â¿De dÃ³nde viene? Â¿Del directorio actual? Â¿De pip?

# âœ… SOLUCIÃ“N: Con src/, el cÃ³digo DEBE estar instalado para importar
# myproject/
# â”œâ”€â”€ src/
# â”‚   â””â”€â”€ mymodule/
# â”‚       â””â”€â”€ __init__.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
from mymodule import something  # â† Solo funciona si `pip install -e .`
```

### pyproject.toml: The Heart of the Project

```toml
# pyproject.toml - ConfiguraciÃ³n completa del proyecto
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "bankchurn"
version = "1.0.0"
description = "Bank Customer Churn Prediction System"
authors = [
    {name = "Daniel Duque", email = "duque@example.com"}
]
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    "pandas>=2.0.0",
    "scikit-learn>=1.3.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "mlflow>=2.9.0",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "mypy>=1.7.0",
    "ruff>=0.1.0",
]

[project.scripts]
bankchurn = "bankchurn.cli:main"  # â† Comando CLI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.setuptools.packages.find]
where = ["src"]  # â† Busca paquetes en src/

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=src/bankchurn --cov-report=term-missing"

[tool.coverage.run]
source = ["src"]
omit = ["tests/*"]

[tool.coverage.report]
fail_under = 79  # â† Coverage mÃ­nimo para pasar CI

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
disallow_untyped_defs = true
ignore_missing_imports = true
```

### Editable Mode Installation

```bash
# Install the package in editable mode (for development)
pip install -e .

# Now you can import from anywhere
python -c "from bankchurn.config import BankChurnConfig; print('âœ… Works!')"

# And tests also work
pytest tests/
```

---

<a id="14-principios-solid-para-ml"></a>

## 1.4 SOLID Principles for ML

### Single Responsibility: One Module, One Task

```python
# âŒ ANTES: Un archivo hace TODO
# training.py (500 lÃ­neas)
def train_model(data_path, config_path, output_path):
    # Carga datos (lÃ­neas 1-50)
    # Limpia datos (lÃ­neas 51-100)
    # Feature engineering (lÃ­neas 101-200)
    # Entrena modelo (lÃ­neas 201-300)
    # EvalÃºa modelo (lÃ­neas 301-400)
    # Guarda artefactos (lÃ­neas 401-450)
    # Loguea a MLflow (lÃ­neas 451-500)
    pass

# âœ… DESPUÃ‰S: Cada archivo tiene UNA responsabilidad
# src/bankchurn/
# â”œâ”€â”€ data.py         â†’ Solo carga y valida datos
# â”œâ”€â”€ features.py     â†’ Solo feature engineering
# â”œâ”€â”€ training.py     â†’ Solo entrenamiento
# â”œâ”€â”€ evaluation.py   â†’ Solo mÃ©tricas
# â””â”€â”€ prediction.py   â†’ Solo inferencia
```

### Real Portfolio Code

```python
# src/bankchurn/training.py - SOLO se encarga de entrenar
class ChurnTrainer:
    """Training pipeline - Single Responsibility."""
    
    def __init__(self, config: BankChurnConfig):
        self.config = config
    
    def load_data(self, path: Path) -> pd.DataFrame:
        """Delega a mÃ³dulo de datos."""
        pass
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """Prepara X e y."""
        pass
    
    def build_pipeline(self) -> Pipeline:
        """Construye el pipeline sklearn."""
        pass
    
    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:
        """Entrena el modelo."""
        pass
    
    def cross_validate(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """Valida con CV."""
        pass

# src/bankchurn/evaluation.py - SOLO se encarga de evaluar
def evaluate_model(
    model: Pipeline,
    X_test: pd.DataFrame,
    y_test: pd.Series
) -> Dict[str, float]:
    """Calcula mÃ©tricas - Single Responsibility."""
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    return {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, y_proba),
    }
```

---

<a id="15-oop-para-ml"></a>

## 1.5 OOP for ML: Protocols and Abstract Classes

> **CRITICAL**: Without understanding professional OOP, you WON'T be able to read the Portfolio code.

### The Problem: Non-Interchangeable Code

```python
# âŒ CÃ“DIGO JUNIOR: Cada trainer tiene API diferente
class TrainerA:
    def entrenar(self, X, y): ...  # espaÃ±ol
    def predecir(self, X): ...

class TrainerB:
    def fit_model(self, features, labels): ...  # nombres diferentes
    def get_predictions(self, features): ...

# Â¿CÃ³mo escribo cÃ³digo genÃ©rico que funcione con ambos?
# Imposible sin reescribir todo.
```

### The Solution: Protocol and ABC

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROTOCOL: Duck Typing verificable por mypy (para sklearn y librerÃ­as externas)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from typing import Protocol, runtime_checkable
from numpy.typing import ArrayLike

@runtime_checkable
class Predictor(Protocol):
    """Si tiene fit() y predict() con estas firmas, ES un Predictor."""
    
    def fit(self, X: ArrayLike, y: ArrayLike) -> "Predictor": ...
    def predict(self, X: ArrayLike) -> ArrayLike: ...

# sklearn cumple automÃ¡ticamente sin modificar nada:
from sklearn.ensemble import RandomForestClassifier
assert isinstance(RandomForestClassifier(), Predictor)  # True!


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ABC: Contrato que OBLIGA implementaciÃ³n (para TUS clases)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from abc import ABC, abstractmethod
import pandas as pd

class BaseTrainer(ABC):
    """Clase base para todos los trainers del portafolio.
    
    BankChurn, CarVision y TelecomAI DEBEN implementar estos mÃ©todos.
    Si no lo hacen, Python da error al instanciar.
    """
    
    @abstractmethod
    def fit(self, X: pd.DataFrame, y: pd.Series) -> "BaseTrainer":
        """Entrena el modelo."""
        pass
    
    @abstractmethod
    def predict(self, X: pd.DataFrame) -> pd.Series:
        """Genera predicciones."""
        pass
    
    @abstractmethod
    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> dict[str, float]:
        """EvalÃºa el modelo."""
        pass
    
    # MÃ©todo concreto que usa los abstractos
    def fit_and_evaluate(
        self, 
        X_train: pd.DataFrame, y_train: pd.Series,
        X_test: pd.DataFrame, y_test: pd.Series
    ) -> dict[str, float]:
        """Entrena y evalÃºa en un paso."""
        self.fit(X_train, y_train)
        return self.evaluate(X_test, y_test)


# ImplementaciÃ³n concreta:
class ChurnTrainer(BaseTrainer):
    """Trainer de BankChurn - DEBE implementar fit, predict, evaluate."""
    
    def fit(self, X: pd.DataFrame, y: pd.Series) -> "ChurnTrainer":
        self._pipeline = self._build_pipeline()
        self._pipeline.fit(X, y)
        return self
    
    def predict(self, X: pd.DataFrame) -> pd.Series:
        return pd.Series(self._pipeline.predict(X))
    
    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> dict[str, float]:
        y_pred = self.predict(X)
        return {"accuracy": accuracy_score(y, y_pred)}
```

### Bridge to Portfolio

Create `common_utils/base.py` with `BaseTrainer` so that all 3 projects share the same interface.

---

<a id="16-pandera-validacion-dataframes"></a>

## 1.6 Pandera: DataFrame Validation

> **CRITICAL**: Without Pandera, data errors appear in sklearn, not where they occurred.

### The Problem: DataFrames that Lie

```python
# âŒ CÃ“DIGO JUNIOR: Asume que el DataFrame es correcto
def train_model(df: pd.DataFrame) -> Pipeline:
    X = df.drop("Exited", axis=1)  # Â¿Y si "Exited" no existe?
    y = df["Exited"]               # Â¿Y si tiene valores como 2, -1, None?
    
    pipeline.fit(X, y)
    return pipeline

# Todo parece funcionar... hasta que llegan datos corruptos:
bad_data = pd.DataFrame({
    "Age": [-5, 25, 200],        # Edad negativa y 200 aÃ±os
    "Balance": [1000, -500, 0],  # Balance negativo
    "Exited": [0, 2, None],      # Valor 2 y None (no binario)
})
model = train_model(bad_data)  # NO DA ERROR, pero modelo es basura
```

### The Solution: Pandera Schema

```python
import pandera as pa
from pandera.typing import DataFrame, Series

class BankChurnSchema(pa.DataFrameModel):
    """Schema para datos de Bank Churn - producciÃ³n."""
    
    CreditScore: Series[int] = pa.Field(ge=300, le=850, description="FICO score")
    Age: Series[int] = pa.Field(ge=18, le=100, description="Edad del cliente")
    Balance: Series[float] = pa.Field(ge=0, description="Balance en cuenta")
    NumOfProducts: Series[int] = pa.Field(ge=1, le=4)
    Exited: Series[int] = pa.Field(isin=[0, 1], description="Target binario")
    
    class Config:
        strict = True   # Rechaza columnas extra
        coerce = True   # Convierte tipos automÃ¡ticamente


@pa.check_types  # Decorador que valida entrada automÃ¡ticamente
def train_model(df: DataFrame[BankChurnSchema]) -> Pipeline:
    """DataFrame GARANTIZADO vÃ¡lido por Pandera."""
    X = df.drop("Exited", axis=1)
    y = df["Exited"]
    # Ahora podemos confiar en que los datos son correctos
    ...


# Error CLARO si datos son invÃ¡lidos:
# SchemaError: Column 'Age' failed check: greater_than_or_equal_to(18)
```

### Portfolio Schemas

```python
# src/bankchurn/schemas.py

class RawDataSchema(pa.DataFrameModel):
    """Schema permisivo para datos crudos (permite nulos)."""
    CreditScore: Series[float] = pa.Field(nullable=True)
    Age: Series[float] = pa.Field(nullable=True, ge=0)
    class Config:
        strict = False  # Permite columnas extra (RowNumber, etc.)


class ProcessedDataSchema(pa.DataFrameModel):
    """Schema estricto para datos listos para entrenar."""
    CreditScore: Series[int] = pa.Field(ge=300, le=850)
    Age: Series[int] = pa.Field(ge=18, le=100)
    Exited: Series[int] = pa.Field(isin=[0, 1])
    class Config:
        strict = True  # No permite columnas extra


@pa.check_types
def preprocess(raw: DataFrame[RawDataSchema]) -> DataFrame[ProcessedDataSchema]:
    """Pipeline validado: entrada permisiva, salida estricta."""
    df = raw.dropna()
    df = df.drop(columns=["RowNumber", "CustomerId", "Surname"])
    return df
```

---

<a id="17-ejercicios-practicos"></a>

## 1.7 Practical Exercises

### Exercise 1: Add Type Hints

```python
# âŒ CÃ³digo sin tipos (tÃ­pico de notebook)
# Tu tarea: AÃ±ade type hints completos

def process_training_data(df, config):
    target = config["target"]
    features = config["features"]
    
    X = df[features]
    y = df[target]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.get("test_size", 0.2)
    )
    
    return X_train, X_test, y_train, y_test


def calculate_metrics(y_true, y_pred):
    return {
        "accuracy": accuracy_score(y_true, y_pred),
        "f1": f1_score(y_true, y_pred)
    }
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```python
from typing import Dict, List, Tuple, Any
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score


def process_training_data(
    df: pd.DataFrame,
    config: Dict[str, Any]
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """Procesa datos para entrenamiento.
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    config : Dict[str, Any]
        ConfiguraciÃ³n con keys: "target", "features", "test_size" (opcional).
    
    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]
        X_train, X_test, y_train, y_test
    """
    target: str = config["target"]
    features: List[str] = config["features"]
    
    X: pd.DataFrame = df[features]
    y: pd.Series = df[target]
    
    test_size: float = config.get("test_size", 0.2)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    return X_train, X_test, y_train, y_test


def calculate_metrics(
    y_true: pd.Series,
    y_pred: pd.Series
) -> Dict[str, float]:
    """Calcula mÃ©tricas de clasificaciÃ³n.
    
    Parameters
    ----------
    y_true : pd.Series
        Labels verdaderos.
    y_pred : pd.Series
        Predicciones del modelo.
    
    Returns
    -------
    Dict[str, float]
        Diccionario con accuracy y f1.
    """
    return {
        "accuracy": float(accuracy_score(y_true, y_pred)),
        "f1": float(f1_score(y_true, y_pred))
    }
```

</details>

---

### Exercise 2: Create Config with Pydantic

```python
# Tu tarea: Crea una configuraciÃ³n Pydantic para TelecomAI
# Requisitos:
# - project_name: str
# - random_seed: int (entre 0 y 1000)
# - test_size: float (entre 0.1 y 0.5)
# - model_type: solo puede ser "logreg", "random_forest", o "gradient_boosting"
# - features: lista de strings
# - target: str

# Escribe tu cÃ³digo aquÃ­:
from pydantic import BaseModel, Field
from typing import List, Literal

class TelecomConfig(BaseModel):
    # ... tu cÃ³digo
    pass
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```python
from pydantic import BaseModel, Field
from typing import List, Literal, Optional, Dict, Any
from pathlib import Path
import yaml


class TelecomConfig(BaseModel):
    """ConfiguraciÃ³n para TelecomAI Customer Intelligence."""
    
    project_name: str = Field(..., min_length=1)
    random_seed: int = Field(42, ge=0, le=1000)
    test_size: float = Field(0.2, ge=0.1, le=0.5)
    model_type: Literal["logreg", "random_forest", "gradient_boosting"] = "logreg"
    features: List[str] = Field(..., min_items=1)
    target: str
    
    # Opcionales
    threshold: float = Field(0.5, ge=0.0, le=1.0)
    mlflow_enabled: bool = True
    
    @classmethod
    def from_yaml(cls, path: str | Path) -> "TelecomConfig":
        with open(path) as f:
            data = yaml.safe_load(f)
        return cls(**data)
    
    class Config:
        extra = "forbid"  # No permite campos extra en el YAML


# Uso:
config = TelecomConfig(
    project_name="TelecomAI",
    features=["calls", "minutes", "messages", "mb_used"],
    target="is_ultra"
)

# Esto FALLA:
# config = TelecomConfig(
#     project_name="",  # Error: min_length=1
#     test_size=0.8,    # Error: le=0.5
#     model_type="xgboost",  # Error: not in Literal
#     features=[],      # Error: min_items=1
# )
```

</details>

---

### Exercise 3: Convert to src/ Layout

```
Your task: Reorganize this flat structure to src/ layout

BEFORE:
myproject/
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ data.csv
â””â”€â”€ test_train.py

AFTER:
myproject/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ???
â””â”€â”€ pyproject.toml
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```
myproject/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ myproject/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ training.py      # Antes: train.py
â”‚       â”œâ”€â”€ prediction.py    # Antes: predict.py
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Fixtures compartidas
â”‚   â””â”€â”€ test_training.py     # Antes: test_train.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ data.csv
â”œâ”€â”€ artifacts/               # Para modelos generados
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

 </details>

---

## ğŸ§¨ Common Errors and How to Debug Them

In this module, the same problems usually appear. The idea is not only to avoid them, but to **recognize them quickly** in your own projects.

If any of these errors took you **>15 minutes**, log it in the **[Error Journal](study_tools/DIARIO_ERRORES.md)** and apply the **cognitive rescue** flow from **[Protocol E](study_tools/PROTOCOLO_E.md)**.

### 1) Type hints + mypy: noisy errors in pandas/sklearn

**Typical symptoms**

- `Function is missing a type annotation for parameter 'df'`
- `Incompatible return value type (got "DataFrame", expected "Series")`
- Hundreds of warnings in external libraries (`pandas.*`, `sklearn.*`).
**Process to identify them**

- Always run:
  ```bash
  mypy src/  # or mypy src/bankchurn src/carvision src/telecomai
  ```
- First locate errors **in your code** (files inside `src/`), ignore library errors for now.
- If you see many errors in `site-packages` or external modules, check your `[tool.mypy]` section in `pyproject.toml` (see example in this module).

**How to solve them (general pattern)**

- Add types to **all public signatures** (functions/classes used outside their file).
- Use ML-specific types:
  - `pd.DataFrame`, `pd.Series`
  - `NDArray[np.float64]`
  - `BaseEstimator`, `Pipeline`
- Isolate very complex types using `TypedDict` or `Alias`:
  ```python
  class MetricsDict(TypedDict):
      accuracy: float
      f1: float
      roc_auc: float
  ```
- To **reduce mypy noise** with ML libraries:
  - Configure `ignore_missing_imports = true` and the overrides shown in this module.
  - Re-run `mypy` and verify that only errors in your code remain.

> ğŸ’¡ **Practical rule**: if mypy starts screaming in the middle of a refactor, reduce the problem to a small function, type that function well, and then propagate the types to the rest.

---

### 2) Pydantic: `ValidationError` due to poorly defined config

**Typical symptoms**

- When loading configuration:
  ```text
  pydantic.error_wrappers.ValidationError: 2 validation errors for ModelConfig
  model -> test_size
    ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
  model -> cv_folds
    ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)
  ```
- Your service/API doesn't start because reading `config.yaml` fails.

**Process to identify them**

- Locate **which Pydantic model** is failing (`ModelConfig`, `BankChurnConfig`, `TelecomConfig`, etc.).
- Check the `traceback`: it almost always indicates **the full field path** (`model -> test_size`, `data -> categorical_features`, etc.).
- Open the corresponding YAML (`configs/config.yaml`) and compare **actual value** vs **restriction in `Field(...)`**.

**How to solve them (general pattern)**

- Adjust the YAML to respect the ranges:
  - `test_size` between `0.0` and `1.0`.
  - `cv_folds` â‰¥ 2.
  - Valid literals (`voting: "hard" | "soft"`, `model_type: "logreg" | "random_forest" | ...`).
- If the error seems unjustified, check the model declaration:
  ```python
  test_size: float = Field(0.2, ge=0.0, le=1.0)
  ```
  Maybe you need to allow a different range in your context.
- In development, **fail fast**: don't catch `ValidationError` except to show a friendlier message; let the app crash rather than use a corrupt config.

> ğŸ”§ **Mental exercise**: purposely break your `configs/config.yaml` (put `test_size: 1.5`) and observe the error. Then fix it. Do it once and you'll never be scared of a `ValidationError` in production again.

---

### 3) src/ layout e imports: `ModuleNotFoundError` en CI pero no en tu mÃ¡quina

**SÃ­ntomas tÃ­picos**

- En local â€œtodo funcionaâ€, pero en GitHub Actions o en otra mÃ¡quina obtienes:
  ```text
  ModuleNotFoundError: No module named 'bankchurn'
  ```
- Tests only pass if you run `pytest` from the exact project root.

**Process to identify them**

- Check your project **structure** (it should look like the diagram in this module):
  - Code inside `src/<package>/`.
  - Tests under `tests/` using package imports, not weird relative paths.
- Verify your `pyproject.toml`:
  - `[project.name]` matches the package (`bankchurn`, `carvision`, `telecomai`).
  - `[tool.setuptools.packages.find] where = ["src"]`.
- Check if you installed in editable mode:
  ```bash
  pip install -e .
  python -c "import bankchurn; print(bankchurn.__file__)"
  ```

**How to solve them (general pattern)**

- Move root code to `src/` following this module's example.
- Change imports like:
  ```python
  # âŒ from .training import train_model  (desde scripts sueltos)
  # âœ… from bankchurn.training import train_model
  ```
- Make sure CI commands use editable installation:
  ```yaml
  - name: Install
    run: pip install -e ".[dev]"
  ```

> âš ï¸ **Red flag**: if your tests only work when you `cd src` or manually adjust `PYTHONPATH`, your layout is still not well resolved.

---

### 4) General debugging pattern for this module

1. **Reproduce the error** with a simple and deterministic command:
   - `mypy src/`
   - `python -m src.project.training`
   - `pytest -k test_name`.
2. **Read literally** the error message (field, value, restriction).
3. **Connect the error with the module concept**:
   - Type hints â†’ function signature or return type.
   - Pydantic â†’ `Field(...)` and YAML.
   - src/ layout â†’ folder structure + `pyproject.toml` + editable installation.
4. **Apply the solution pattern** you saw above.

If you automate this cycle in your three portfolio projects, your debugging time is drastically reduced and that's exactly what's expected of a Senior/Staff profile.

---

## âœ… Checkpoint: Did You Complete the Module?

Before continuing, verify:

- [ ] Your code has type hints in all functions
- [ ] You can run `mypy src/` without critical errors
- [ ] You have at least one Pydantic class for configuration
- [ ] Your project has src/ layout structure
- [ ] You can install your package with `pip install -e .`

---

## ğŸ”— ADR: Why These Decisions?

### ADR-001: Mandatory Type Hints

**Context**: ML code is often hard to maintain because functions accept "anything".

**Decision**: We require type hints in all public functions.

**Consequences**:
- âœ… IDE autocompletes correctly
- âœ… Errors detected before running
- âœ… Implicit documentation
- âŒ More code to write initially
- âŒ Learning curve for complex types

### ADR-002: Pydantic for Configuration

**Context**: Dictionary configurations are error-prone.

**Decision**: All configuration goes through Pydantic.

**Consequences**:
- âœ… Automatic validation
- âœ… Clear errors
- âœ… Config documentation
- âŒ Additional dependency
- âŒ More verbose than a simple dict

### ADR-003: src/ Layout

**Context**: Code in root causes import problems.

**Decision**: All code in `src/<package>/`.

**Consequences**:
- âœ… Consistent imports
- âœ… Works the same in development and CI
- âœ… Industry standard
- âŒ Requires `pip install -e .`
- âŒ Longer path for imports

---

## ğŸ“¦ How It Was Used in the Portfolio

This module applies **directly** to all 3 portfolio projects. Here are the actual files that implement each concept:

### Type Hints in the Portfolio

```python
# BankChurn-Predictor/src/bankchurn/config.py (lÃ­neas 89-109)
@classmethod
def from_yaml(cls, config_path: str | Path) -> BankChurnConfig:
    """Load configuration from YAML file.
    
    Parameters
    ----------
    config_path : str or Path
        Path to YAML configuration file.
    
    Returns
    -------
    config : BankChurnConfig
        Validated configuration object.
    """
```

### Pydantic in the Portfolio

Each project has its own Pydantic configuration:

| Project | File | Main classes |
|----------|---------|-------------------|
| BankChurn | `src/bankchurn/config.py` | `BankChurnConfig`, `ModelConfig`, `DataConfig` |
| CarVision | `src/carvision/config.py` | `CarVisionConfig`, `FiltersConfig` |
| TelecomAI | `src/telecomai/config.py` | `TelecomConfig` |

```python
# Ejemplo real: BankChurn-Predictor/src/bankchurn/config.py
class ModelConfig(BaseModel):
    """Model training configuration."""
    type: str = "ensemble"
    test_size: float = Field(0.2, ge=0.0, le=1.0)  # â† ValidaciÃ³n automÃ¡tica
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)  # â† MÃ­nimo 2 folds
```

### src/ Layout in the Portfolio

All 3 projects follow exactly the described structure:

```
BankChurn-Predictor/
â”œâ”€â”€ src/bankchurn/       â† Paquete instalable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py        â† Pydantic configs
â”‚   â”œâ”€â”€ pipeline.py      â† sklearn Pipeline
â”‚   â””â”€â”€ trainer.py       â† Clase de entrenamiento
â”œâ”€â”€ pyproject.toml       â† Metadata y dependencias
â””â”€â”€ setup.py             â† Fallback para pip install -e .
```

### ğŸ”§ Exercise: Verify in the Real Repo

```bash
# 1. Ve al proyecto BankChurn
cd BankChurn-Predictor

# 2. Instala en modo editable
pip install -e ".[dev]"

# 3. Verifica tipos con mypy
mypy src/bankchurn/config.py

# 4. Prueba que Pydantic valida correctamente
python -c "from bankchurn.config import BankChurnConfig; print(BankChurnConfig.from_yaml('configs/config.yaml'))"
```

---

## ğŸ’¼ Professional Tips

> **Recommendations to stand out in interviews and real projects**

### For Interviews

1. **Master Type Hints**: Interviewers value typed code. Practice explaining why `def process(data: pd.DataFrame) -> Dict[str, float]` is better than `def process(data)`.

2. **Know Pydantic vs Dataclasses**: Common question: "When would you use one or the other?" Answer: Pydantic for external data validation (APIs, configs), dataclasses for simple internal structures.

3. **Demonstrate understanding of `__init__.py`**: Explain how it controls a package's public API and why `from package import *` is dangerous.

### For Real Projects

| Situation | Tip |
|-----------|-----|
| Legacy code without types | Add types gradually, starting with public functions |
| Config validation | Use Pydantic with `model_validator` for cross-validations |
| Logs in production | Use `structlog` or `loguru` instead of `print()` |
| Errors in production | Implement custom exceptions with useful context |

### Anti-patterns to Avoid

- âŒ `from typing import *` â€” import only what you need
- âŒ `except Exception:` without logging â€” always log the error
- âŒ Functions over 50 lines â€” refactor into smaller functions
- âŒ Names like `data`, `info`, `result` â€” use descriptive names


---

## ğŸ“º Recommended External Resources

> See [RECURSOS_POR_MODULO.md](RECURSOS_POR_MODULO.md) for the complete list.

| ğŸ·ï¸ | Resource | Type |
|:--:|:--------|:-----|
| ğŸ”´ | [Type Hints - ArjanCodes](https://www.youtube.com/watch?v=dgBCEB2jVU0) | Video |
| ğŸ”´ | [Pydantic V2 Tutorial](https://www.youtube.com/watch?v=502XOB0u8OY) | Video |
| ğŸŸ¡ | [Python Type Checking - Real Python](https://realpython.com/python-type-checking/) | Tutorial |

**Official documentation:**
- [PEP 484 â€“ Type Hints](https://peps.python.org/pep-0484/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Python Packaging Guide](https://packaging.python.org/)

---

## ğŸ”— Glossary References

See [21_GLOSARIO.md](21_GLOSARIO.md) for definitions of:
- **Type Hints**: Type annotations in Python
- **Pydantic**: Data validation with type hints
- **src/ Layout**: Professional project structure

---

## âœ… Exercises

See [EJERCICIOS.md](EJERCICIOS.md) - Module 01:
- **1.1**: Add type hints to functions
- **1.2**: Create config with Pydantic
- **1.3**: Structure project with src/ layout

---

<div align="center">

[â† Back to Index](00_INDICE.md) | [Next: ML System Design â†’](02_DISENO_SISTEMAS.md)

</div>
