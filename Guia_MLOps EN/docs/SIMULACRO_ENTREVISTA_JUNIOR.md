# üéØ Simulacro de Entrevista Junior ML Engineer
## Portafolio MLOps ‚Äî 50 Preguntas Fundamentales

**Autor del Portafolio**: Daniel Duque (DuqueOM)  
**Versi√≥n**: 1.0  
**Fecha**: Diciembre 2025  
**Nivel**: Junior (0-2 a√±os de experiencia)

---

## üìã √çndice

1. [Python B√°sico](#1-python-b√°sico-preguntas-1-10)
2. [Machine Learning Fundamentos](#2-machine-learning-fundamentos-preguntas-11-20)
3. [Datos y Preprocesamiento](#3-datos-y-preprocesamiento-preguntas-21-30)
4. [Git y Herramientas](#4-git-y-herramientas-preguntas-31-40)
5. [Pr√°ctica con el Portafolio](#5-pr√°ctica-con-el-portafolio-preguntas-41-50)

---

## üéØ Antes de Empezar

### ¬øQu√© se espera de un Junior?

| Lo que S√ç se espera | Lo que NO se espera |
|---------------------|---------------------|
| Fundamentos s√≥lidos de Python | Dise√±o de arquitecturas complejas |
| Entender train/test split | Optimizaci√≥n de hiperpar√°metros avanzada |
| Saber qu√© es overfitting | Implementar MLOps completo |
| Usar Git b√°sico | CI/CD avanzado |
| Leer y modificar c√≥digo existente | Escribir c√≥digo de producci√≥n desde cero |
| Hacer preguntas inteligentes | Tener todas las respuestas |

### Consejos para la Entrevista

1. **S√© honesto**: "No lo s√©, pero lo investigar√≠a as√≠..." es mejor que inventar
2. **Muestra curiosidad**: Haz preguntas sobre el c√≥digo que ves
3. **Relaciona con el portafolio**: "En BankChurn aprend√≠ que..."
4. **Piensa en voz alta**: El proceso importa m√°s que la respuesta perfecta

---

# 1. Python B√°sico (Preguntas 1-10) {#1-python-b√°sico-preguntas-1-10}

## Pregunta 1: Tipos de Datos
**¬øCu√°l es la diferencia entre lista, tupla y diccionario?**

### Respuesta:
```python
# Lista: mutable, ordenada
features = ["age", "salary", "tenure"]  # Crea lista con 3 strings.
features.append("score")                 # append(): a√±ade elemento al final. Listas son mutables.

# Tupla: inmutable, ordenada
coordinates = (40.7, -74.0)              # Tupla de coordenadas. Par√©ntesis indican tupla.
# coordinates[0] = 41.0  # ERROR         # TypeError: las tuplas NO se pueden modificar.

# Diccionario: mutable, key-value
customer = {"id": 123, "name": "John", "churn": False}  # Dict: pares clave:valor.
customer["score"] = 0.85                 # A√±ade nueva clave. Dicts son mutables.
```

**Cu√°ndo usar cada uno**:
- **Lista**: Colecci√≥n que cambiar√° (features a seleccionar)
- **Tupla**: Datos que no deben cambiar (coordenadas, constantes)
- **Diccionario**: Acceso por clave (configuraci√≥n, datos de cliente)

---

## Pregunta 2: List Comprehension
**Reescribe este c√≥digo con list comprehension:**
```python
result = []                              # Lista vac√≠a para acumular resultados.
for x in range(10):                      # range(10): genera 0,1,2,...,9.
    if x % 2 == 0:                       # %: m√≥dulo. x%2==0 significa "x es par".
        result.append(x**2)              # **: exponente. A√±ade el cuadrado de x.
```

### Respuesta:
```python
result = [x**2 for x in range(10) if x % 2 == 0]  # List comprehension: [expresi√≥n for item in iterable if condici√≥n]
# [0, 4, 16, 36, 64]                              # Resultado: cuadrados de n√∫meros pares del 0 al 9.
```

**Ventajas**:
- M√°s conciso
- M√°s r√°pido (optimizado internamente)
- M√°s "pyth√≥nico"

---

## Pregunta 3: Funciones y Argumentos
**¬øQu√© hace `*args` y `**kwargs`?**

### Respuesta:
```python
def log_experiment(*args, **kwargs):    # *args: captura argumentos posicionales como tupla.
    # args: tupla de argumentos posicionales   # **kwargs: captura argumentos con nombre como dict.
    # kwargs: diccionario de argumentos con nombre
    print(f"Metrics: {args}")            # f-string: permite insertar variables con {}.
    print(f"Config: {kwargs}")           # Imprime el diccionario de kwargs.

log_experiment(0.85, 0.82, model="rf", n_estimators=100)  # 2 posicionales + 2 con nombre.
# Metrics: (0.85, 0.82)                  # args captura los valores sin nombre.
# Config: {'model': 'rf', 'n_estimators': 100}  # kwargs captura los pares key=value.
```

**En el portafolio** (`BankChurn/trainer.py`):
```python
def __init__(self, config: BankChurnConfig, **kwargs):
    self.config = config
    self.extra_params = kwargs  # Flexibilidad para params adicionales
```

---

## Pregunta 4: Manejo de Errores
**¬øPor qu√© usamos try/except?**

### Respuesta:
```python
def load_data(path: str) -> pd.DataFrame:  # Type hints: espera str, retorna DataFrame.
    try:                                    # try: intenta ejecutar c√≥digo que puede fallar.
        df = pd.read_csv(path)              # Operaci√≥n que puede lanzar excepciones.
        return df
    except FileNotFoundError:               # Captura error espec√≠fico: archivo no existe.
        print(f"Error: {path} no existe")
        raise                               # raise: re-lanza la excepci√≥n para que el caller la maneje.
    except pd.errors.EmptyDataError:        # Captura otro error espec√≠fico.
        print("Error: archivo vac√≠o")
        raise                               # Siempre re-lanzar si no puedes recuperarte.
```

**Buenas pr√°cticas**:
- Capturar excepciones espec√≠ficas, no gen√©ricas
- Hacer logging del error
- Re-lanzar si no puedes manejarlo

---

## Pregunta 5: Import y M√≥dulos
**¬øCu√°l es la diferencia entre estas formas de import?**

### Respuesta:
```python
# Importar m√≥dulo completo
import pandas as pd                      # Importa todo el m√≥dulo con alias "pd".
df = pd.read_csv("data.csv")             # Acceso via pd.funci√≥n().

# Importar funci√≥n espec√≠fica
from sklearn.model_selection import train_test_split  # Solo importa esta funci√≥n.
X_train, X_test = train_test_split(X)    # Uso directo sin prefijo.

# Importar todo (‚ö†Ô∏è evitar en producci√≥n)
from math import *                       # * importa TODO: contamina namespace, dif√≠cil saber origen.
```

**Best practice**: Importar lo que necesitas, usar alias est√°ndar (`pd`, `np`, `plt`).

---

## Pregunta 6: Type Hints
**¬øQu√© significan los type hints y por qu√© usarlos?**

### Respuesta:
```python
def predict_churn(
    credit_score: int,                    # : int indica que espera un entero.
    age: int,
    is_active: bool                       # : bool indica booleano (True/False).
) -> float:                               # -> float indica que RETORNA un decimal.
    """Retorna probabilidad de churn."""
    ...                                   # ... es placeholder (Ellipsis), indica "implementar".
```

**Beneficios**:
1. **Documentaci√≥n**: Claro qu√© espera y retorna
2. **IDE support**: Autocompletado, detecci√≥n de errores
3. **Tooling**: `mypy` puede verificar tipos

**En el portafolio**: Todos los archivos usan type hints (`config.py`, `training.py`).

---

## Pregunta 7: Clases B√°sicas
**¬øQu√© es `__init__` y `self`?**

### Respuesta:
```python
class BankChurnTrainer:                   # class: define un nuevo tipo de objeto.
    def __init__(self, config):           # __init__: constructor, se ejecuta al crear instancia.
        # Constructor: se ejecuta al crear instancia
        self.config = config              # self: referencia a ESTA instancia. Guarda config.
        self.model_ = None                # Atributo inicializado en None (convenci√≥n: _ para fitted).
    
    def train(self, X, y):                # M√©todo: funci√≥n que pertenece a la clase.
        # self permite acceder a atributos de la instancia
        if self.config.model_type == "rf":  # Accede a config guardada en __init__.
            self.model_ = RandomForestClassifier()
        self.model_.fit(X, y)             # Entrena y guarda modelo en self.

# Uso
trainer = BankChurnTrainer(config)        # Crea instancia: __init__ se ejecuta autom√°ticamente.
trainer.train(X, y)                       # Llama m√©todo train en esta instancia.
```

---

## Pregunta 8: Lectura de Archivos
**¬øC√≥mo lees un archivo CSV con pandas?**

### Respuesta:
```python
import pandas as pd

# B√°sico
df = pd.read_csv("data/raw/Churn.csv")    # Lee CSV y crea DataFrame.

# Con opciones
df = pd.read_csv(
    "data/raw/Churn.csv",
    sep=",",                              # Separador de columnas (coma por defecto).
    encoding="utf-8",                     # Codificaci√≥n del archivo.
    na_values=["", "NA", "null"],         # Valores que pandas tratar√° como NaN.
    dtype={"customer_id": str}            # Fuerza tipo de columna espec√≠fica.
)

# Verificar
print(df.shape)                           # (filas, columnas): (10000, 14).
print(df.info())                          # Muestra tipos de datos y valores nulos por columna.
print(df.head())                          # Primeras 5 filas del DataFrame.
```

---

## Pregunta 9: Entornos Virtuales
**¬øPor qu√© usamos entornos virtuales?**

### Respuesta:
```bash
# Crear entorno
python -m venv .venv          # -m venv: ejecuta m√≥dulo venv. .venv: nombre de la carpeta.

# Activar
source .venv/bin/activate     # Linux/Mac: source ejecuta el script de activaci√≥n.
.venv\Scripts\activate        # Windows: script diferente por el sistema.

# Instalar dependencias
pip install -r requirements.txt  # -r: lee archivo y instala todas las dependencias listadas.
```

**Razones**:
1. **Aislamiento**: Cada proyecto tiene sus propias versiones
2. **Reproducibilidad**: Mismo entorno en cualquier m√°quina
3. **Evita conflictos**: sklearn 1.3 en proyecto A, sklearn 1.2 en proyecto B

---

## Pregunta 10: Debugging B√°sico
**¬øC√≥mo depuras c√≥digo en Python?**

### Respuesta:
```python
# 1. Print statements (b√°sico pero √∫til)
print(f"X shape: {X.shape}, y shape: {y.shape}")  # f-string para inspeccionar variables.

# 2. Usar assert
assert X.shape[0] == y.shape[0], "Mismatch en filas"  # assert: falla si condici√≥n es False.

# 3. Breakpoints en IDE (recomendado)
# Poner breakpoint y usar F5 para debugear   # Pausa ejecuci√≥n y permite inspeccionar.

# 4. pdb (en terminal)
import pdb; pdb.set_trace()                   # pdb: debugger interactivo de Python.

# 5. Logging (producci√≥n)
import logging
logging.debug(f"Loaded {len(df)} rows")       # Mejor que print: niveles, archivos, formato.
```

---

# 2. Machine Learning Fundamentos (Preguntas 11-20) {#2-machine-learning-fundamentos-preguntas-11-20}

## Pregunta 11: Train/Test Split
**¬øPor qu√© separamos datos en train y test?**

### Respuesta:
```python
from sklearn.model_selection import train_test_split  # Funci√≥n para dividir datos.

X_train, X_test, y_train, y_test = train_test_split(  # Retorna 4 arrays.
    X, y, 
    test_size=0.2,      # 80/20 split: 20% para test.
    random_state=42,    # Semilla: mismos datos cada ejecuci√≥n.
    stratify=y          # Mantiene proporci√≥n de clases en ambos sets.
)
```

**Raz√≥n**: Evaluar c√≥mo el modelo generaliza a datos **nunca vistos**.
- **Train**: Aprende patrones
- **Test**: Simula producci√≥n, mide rendimiento real

**Error com√∫n**: Usar test para ajustar modelo ‚Üí overfitting al test.

---

## Pregunta 12: Overfitting vs Underfitting
**Explica overfitting y underfitting.**

### Respuesta:

| Concepto | S√≠ntomas | Causa | Soluci√≥n |
|----------|----------|-------|----------|
| **Overfitting** | Train acc: 99%, Test acc: 70% | Modelo muy complejo | Regularizaci√≥n, m√°s datos, simplificar |
| **Underfitting** | Train acc: 60%, Test acc: 58% | Modelo muy simple | M√°s features, modelo m√°s complejo |

```python
# Detectar en el portafolio
print(f"Train accuracy: {model.score(X_train, y_train):.2%}")  # .score(): accuracy del modelo.
print(f"Test accuracy: {model.score(X_test, y_test):.2%}")    # :.2%: formatea como porcentaje.

# Si diferencia > 10%, posible overfitting  # Train >> Test = modelo memoriza, no generaliza.
```

---

## Pregunta 13: Clasificaci√≥n vs Regresi√≥n
**¬øCu√°ndo usar clasificaci√≥n y cu√°ndo regresi√≥n?**

### Respuesta:

| Problema | Tipo | Target | M√©trica |
|----------|------|--------|---------|
| ¬øCliente har√° churn? | Clasificaci√≥n | S√≠/No (0/1) | Accuracy, F1, AUC |
| ¬øCu√°nto cuesta el auto? | Regresi√≥n | Precio ($) | RMSE, MAE, R¬≤ |
| ¬øQu√© plan elegir√°? | Clasificaci√≥n multiclase | A/B/C | Accuracy, F1 macro |

**En el portafolio**:
- **BankChurn**: Clasificaci√≥n binaria (churn: 0/1)
- **CarVision**: Regresi√≥n (precio continuo)
- **TelecomAI**: Clasificaci√≥n multiclase (tipo de plan)

---

## Pregunta 14: Cross-Validation
**¬øQu√© es cross-validation y por qu√© usarla?**

### Respuesta:
```python
from sklearn.model_selection import cross_val_score  # CV autom√°tico con scoring.

scores = cross_val_score(model, X, y, cv=5)          # cv=5: 5-fold cross-validation.
print(f"Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})")  # Media ¬± 2*std (95% confianza).
```

**Proceso K-Fold (K=5)**:
1. Divide datos en 5 partes iguales
2. Entrena en 4, valida en 1
3. Repite 5 veces (cada parte es validaci√≥n una vez)
4. Promedia resultados

**Ventajas**:
- Usa todos los datos para entrenar y validar
- Estimaci√≥n m√°s robusta del rendimiento
- Detecta variabilidad del modelo

---

## Pregunta 15: Feature Scaling
**¬øPor qu√© normalizamos features?**

### Respuesta:
```python
from sklearn.preprocessing import StandardScaler   # Estandariza: (x - media) / std.

scaler = StandardScaler()                          # Crea instancia del transformador.
X_scaled = scaler.fit_transform(X_train)           # fit: calcula media/std. transform: aplica.

# Antes: age=[18-92], salary=[20000-200000]        # Escalas muy diferentes.
# Despu√©s: ambas con media=0, std=1               # Escalas comparables.
```

**Razones**:
1. **Algoritmos sensibles a escala**: SVM, KNN, redes neuronales
2. **Gradiente descent**: Converge m√°s r√°pido
3. **Interpretaci√≥n**: Coeficientes comparables

**Algoritmos que NO necesitan scaling**: Random Forest, Decision Tree, XGBoost.

---

## Pregunta 16: One-Hot Encoding
**¬øC√≥mo manejas variables categ√≥ricas?**

### Respuesta:
```python
from sklearn.preprocessing import OneHotEncoder    # Convierte categor√≠as a columnas binarias.

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # ignore: no falla con categor√≠as nuevas.
X_encoded = encoder.fit_transform(df[['Geography', 'Gender']])  # fit: aprende categor√≠as. transform: aplica.

# Geography: France, Germany, Spain
# ‚Üí Geography_France, Geography_Germany, Geography_Spain  # 1 columna por categor√≠a, valores 0/1.
```

**Alternativas**:
- **Label Encoding**: Para ordinales (Bajo < Medio < Alto)
- **Target Encoding**: Codifica con la media del target (‚ö†Ô∏è riesgo de leakage)

---

## Pregunta 17: Missing Values
**¬øC√≥mo manejas valores faltantes?**

### Respuesta:
```python
from sklearn.impute import SimpleImputer            # Rellena valores faltantes (NaN).

# Num√©ricos: media o mediana
imputer_num = SimpleImputer(strategy='median')     # median: robusto a outliers.

# Categ√≥ricos: moda o valor constante
imputer_cat = SimpleImputer(strategy='constant', fill_value='Unknown')  # Rellena con 'Unknown'.
```

**Estrategias**:
| Caso | Estrategia |
|------|------------|
| Pocos missing (<5%) | Imputar con media/moda |
| Muchos missing | Considerar eliminar columna |
| Missing tiene significado | Crear feature `is_missing` |

---

## Pregunta 18: Random Forest
**Explica c√≥mo funciona Random Forest.**

### Respuesta:
```python
from sklearn.ensemble import RandomForestClassifier  # Ensemble de √°rboles de decisi√≥n.

rf = RandomForestClassifier(
    n_estimators=100,  # 100 √°rboles: m√°s √°rboles = m√°s robusto pero m√°s lento.
    max_depth=10,      # Profundidad m√°xima: limita complejidad, evita overfitting.
    random_state=42    # Semilla para reproducibilidad.
)
```

**Concepto simple**:
1. Crea N √°rboles de decisi√≥n
2. Cada √°rbol usa subset aleatorio de datos y features
3. Predicci√≥n final = voto mayoritario (clasificaci√≥n) o promedio (regresi√≥n)

**Ventajas**: Robusto, pocas configuraciones, maneja bien missing values.

---

## Pregunta 19: M√©tricas de Clasificaci√≥n
**¬øQu√© es accuracy, precision, recall y F1?**

### Respuesta:
```python
from sklearn.metrics import classification_report  # Reporte completo de m√©tricas.

print(classification_report(y_test, y_pred))       # Muestra precision, recall, f1 por clase.
```

| M√©trica | F√≥rmula | Cu√°ndo priorizar |
|---------|---------|------------------|
| **Accuracy** | Correctos / Total | Clases balanceadas |
| **Precision** | TP / (TP + FP) | Costo alto de falsos positivos |
| **Recall** | TP / (TP + FN) | Costo alto de falsos negativos |
| **F1** | 2 √ó (P √ó R) / (P + R) | Balance entre P y R |

**En BankChurn**: Priorizo **Recall** (no queremos perder clientes que har√°n churn).

---

## Pregunta 20: Curva ROC y AUC
**¬øQu√© es AUC-ROC?**

### Respuesta:
```python
from sklearn.metrics import roc_auc_score, roc_curve  # M√©tricas para clasificaci√≥n binaria.

# AUC: √Årea bajo la curva ROC
auc = roc_auc_score(y_test, y_pred_proba[:, 1])       # [:, 1]: probabilidad de clase positiva.
print(f"AUC: {auc:.3f}")                              # :.3f: 3 decimales.
```

**Interpretaci√≥n**:
- **AUC = 1.0**: Clasificador perfecto
- **AUC = 0.5**: Clasificador aleatorio
- **AUC > 0.8**: Generalmente bueno

**Ventaja**: Funciona bien con clases desbalanceadas.

---

# 3. Datos y Preprocesamiento (Preguntas 21-30) {#3-datos-y-preprocesamiento-preguntas-21-30}

## Pregunta 21: Exploraci√≥n de Datos
**¬øQu√© haces primero cuando recibes un dataset?**

### Respuesta:
```python
import pandas as pd

df = pd.read_csv("data.csv")                          # Carga el dataset.

# 1. Dimensiones
print(f"Shape: {df.shape}")                           # (filas, columnas): tama√±o del dataset.

# 2. Tipos de datos
print(df.dtypes)                                      # Tipo de cada columna (int, float, object).

# 3. Missing values
print(df.isnull().sum())                              # Cuenta NaN por columna.

# 4. Estad√≠sticas b√°sicas
print(df.describe())                                  # Media, std, min, max, cuartiles.

# 5. Primeras filas
print(df.head())                                      # Visualiza primeras 5 filas.

# 6. Target distribution
print(df['target'].value_counts(normalize=True))      # normalize=True: proporciones en vez de conteos.
```

---

## Pregunta 22: Detecci√≥n de Outliers
**¬øC√≥mo detectas outliers?**

### Respuesta:
```python
import numpy as np

# M√©todo IQR (Interquartile Range)
Q1 = df['Balance'].quantile(0.25)                     # Percentil 25.
Q3 = df['Balance'].quantile(0.75)                     # Percentil 75.
IQR = Q3 - Q1                                         # Rango intercuart√≠lico.

lower = Q1 - 1.5 * IQR                                # L√≠mite inferior.
upper = Q3 + 1.5 * IQR                                # L√≠mite superior.

outliers = df[(df['Balance'] < lower) | (df['Balance'] > upper)]  # Filtra outliers.
print(f"Outliers: {len(outliers)}")                   # Cuenta cu√°ntos hay.
```

**Qu√© hacer con outliers**:
1. Verificar si son errores de datos ‚Üí corregir
2. Si son leg√≠timos ‚Üí considerar winsorization o mantener
3. Para modelos sensibles ‚Üí eliminar o transformar

---

## Pregunta 23: Correlaci√≥n
**¬øC√≥mo identificas features correlacionadas?**

### Respuesta:
```python
import seaborn as sns
import matplotlib.pyplot as plt

# Matriz de correlaci√≥n
corr = df.corr()                                      # Calcula correlaci√≥n entre todas las columnas num√©ricas.

# Heatmap
plt.figure(figsize=(10, 8))                           # Tama√±o del gr√°fico.
sns.heatmap(corr, annot=True, cmap='coolwarm')        # annot: muestra valores. cmap: colores.
plt.show()

# Features altamente correlacionadas (>0.9)
high_corr = (corr.abs() > 0.9) & (corr != 1.0)        # abs(): valor absoluto. Excluye diagonal.
```

**¬øPor qu√© importa?** Features muy correlacionadas son redundantes ‚Üí considerar eliminar una.

---

## Pregunta 24: Desbalance de Clases
**¬øQu√© haces cuando tienes 95% clase A y 5% clase B?**

### Respuesta:
```python
# 1. Cambiar m√©trica (no usar accuracy)
from sklearn.metrics import f1_score, recall_score  # M√©tricas que consideran desbalance.

# 2. Class weights
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(class_weight='balanced')  # Penaliza m√°s errores en clase minoritaria.

# 3. Oversampling (SMOTE)
from imblearn.over_sampling import SMOTE             # Genera ejemplos sint√©ticos de clase minoritaria.
X_res, y_res = SMOTE().fit_resample(X, y)            # Balancea el dataset.

# 4. Undersampling
from imblearn.under_sampling import RandomUnderSampler  # Reduce clase mayoritaria.
```

**En BankChurn**: 80/20 balance ‚Üí usamos `class_weight='balanced'` y F1.

---

## Pregunta 25: Feature Selection
**¬øC√≥mo seleccionas features importantes?**

### Respuesta:
```python
from sklearn.ensemble import RandomForestClassifier

# 1. Feature importance de RF
rf = RandomForestClassifier().fit(X, y)              # Entrena RF.
importances = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_            # Importancia calculada por RF.
}).sort_values('importance', ascending=False)        # Ordena de mayor a menor.

# 2. Correlaci√≥n con target
correlations = df.corr()['target'].abs().sort_values(ascending=False)  # Correlaci√≥n absoluta.

# 3. SelectKBest
from sklearn.feature_selection import SelectKBest, f_classif  # Selecci√≥n estad√≠stica.
selector = SelectKBest(f_classif, k=10)              # k=10: selecciona las 10 mejores.
X_selected = selector.fit_transform(X, y)            # Retorna solo las k features.
```

---

## Pregunta 26: Data Leakage
**¬øQu√© es data leakage y c√≥mo evitarlo?**

### Respuesta:
Data leakage = cuando informaci√≥n del futuro o del target filtra al entrenamiento.

```python
# ‚ùå MAL: fit scaler en TODO antes de split
scaler.fit(X)                                        # Ve datos de test ‚Üí LEAKAGE.
X_train, X_test = train_test_split(X)

# ‚úÖ BIEN: fit solo en train
X_train, X_test = train_test_split(X)                # Primero split.
scaler.fit(X_train)                                  # fit SOLO en train.
X_train = scaler.transform(X_train)                  # transform train.
X_test = scaler.transform(X_test)                    # transform test (sin fit).
```

**En el portafolio**: Usamos Pipeline de sklearn que maneja esto autom√°ticamente.

---

## Pregunta 27: Pipelines de sklearn
**¬øPor qu√© usar Pipeline?**

### Respuesta:
```python
from sklearn.pipeline import Pipeline               # Encadena pasos de ML.
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

pipe = Pipeline([                                   # Lista de tuplas (nombre, transformador).
    ('scaler', StandardScaler()),                   # Paso 1: escalar.
    ('model', RandomForestClassifier())             # Paso 2: modelo.
])

# Un solo fit/predict
pipe.fit(X_train, y_train)                          # fit propaga por todos los pasos.
y_pred = pipe.predict(X_test)                       # predict: transforma y predice.
```

**Beneficios**:
1. **Evita leakage**: fit solo en train autom√°ticamente
2. **C√≥digo limpio**: Todo en un objeto
3. **F√°cil deploy**: `joblib.dump(pipe, 'model.joblib')`
4. **Reproducibilidad**: Mismo proceso siempre

---

## Pregunta 28: Guardado de Modelos
**¬øC√≥mo guardas y cargas un modelo entrenado?**

### Respuesta:
```python
import joblib                                       # Serializaci√≥n eficiente para objetos Python.

# Guardar
joblib.dump(model, 'artifacts/model.joblib')        # Serializa modelo a archivo.

# Cargar
model = joblib.load('artifacts/model.joblib')       # Deserializa de archivo.

# Usar
prediction = model.predict(new_data)                # Modelo listo para predecir.
```

**En producci√≥n** (FastAPI):
```python
@lru_cache()                                        # Cache: carga modelo UNA vez, reutiliza.
def load_model():
    return joblib.load("artifacts/pipeline.joblib") # Evita cargar en cada request.
```

---

## Pregunta 29: Validaci√≥n de Datos
**¬øC√≥mo validas que los datos de entrada son correctos?**

### Respuesta:
```python
from pydantic import BaseModel, Field, validator  # Pydantic: validaci√≥n de datos.

class CustomerInput(BaseModel):                   # Hereda de BaseModel para validaci√≥n autom√°tica.
    credit_score: int = Field(ge=300, le=850)     # ge: >=300, le: <=850. Validaci√≥n de rango.
    age: int = Field(ge=18, le=100)               # Edad entre 18 y 100.
    geography: str
    
    @validator('geography')                       # Validador custom para geography.
    def geography_valid(cls, v):                  # cls: clase, v: valor a validar.
        valid = ['France', 'Germany', 'Spain']
        if v not in valid:
            raise ValueError(f'Must be one of {valid}')  # Error descriptivo.
        return v                                  # Retorna valor validado.
```

**Beneficios**: Errores claros antes de llegar al modelo.

---

## Pregunta 30: Reproducibilidad
**¬øC√≥mo garantizas que tu experimento sea reproducible?**

### Respuesta:
```python
import random
import numpy as np

# 1. Fijar seeds
SEED = 42                                         # Constante para todas las semillas.
random.seed(SEED)                                 # Seed para m√≥dulo random de Python.
np.random.seed(SEED)                              # Seed para numpy.

# 2. En modelos
model = RandomForestClassifier(random_state=SEED) # random_state: semilla interna del modelo.

# 3. En split
train_test_split(X, y, random_state=SEED)         # Misma semilla = mismo split siempre.

# 4. Documentar versiones
# requirements.txt o pyproject.toml con versiones fijas  # sklearn==1.3.0, no sklearn.
```

---

# 4. Git y Herramientas (Preguntas 31-40) {#4-git-y-herramientas-preguntas-31-40}

## Pregunta 31: Git B√°sico
**¬øCu√°l es el flujo b√°sico de Git?**

### Respuesta:
```bash
# 1. Ver estado
git status                    # Muestra archivos modificados/nuevos/staged.

# 2. A√±adir cambios
git add .                     # A√±ade TODO al staging area.
git add archivo.py            # A√±ade archivo espec√≠fico.

# 3. Commit
git commit -m "feat: add preprocessing step"  # Guarda cambios con mensaje descriptivo.

# 4. Push
git push origin main          # Sube commits locales al remoto (origin/main).

# 5. Pull (obtener cambios)
git pull origin main          # Descarga y fusiona cambios del remoto.
```

---

## Pregunta 32: Branches
**¬øPor qu√© usar branches?**

### Respuesta:
```bash
# Crear branch
git checkout -b feature/add-validation  # -b: crea branch y cambia a ella.

# Trabajar...
git add .
git commit -m "feat: add pydantic validation"  # Conventional commit: tipo(scope): mensaje.

# Push branch
git push origin feature/add-validation  # Sube branch al remoto.

# Crear Pull Request en GitHub
# Despu√©s de aprobar, merge a main       # PR permite code review antes de merge.
```

**Razones**:
- Aislar cambios
- Revisar c√≥digo antes de merge
- Mantener main siempre funcional

---

## Pregunta 33: .gitignore
**¬øQu√© debe ir en .gitignore?**

### Respuesta:
```gitignore
# Datos (grandes, sensibles)
data/
*.csv
*.parquet

# Artefactos
artifacts/
*.joblib
*.pkl

# Entornos
.venv/
__pycache__/

# IDEs
.vscode/
.idea/

# Logs
*.log
mlruns/
```

**Regla**: No subir datos grandes, artefactos binarios, ni secretos.

---

## Pregunta 34: Requirements
**¬øC√≥mo manejas dependencias?**

### Respuesta:
```bash
# Crear requirements.txt
pip freeze > requirements.txt           # Exporta TODAS las dependencias instaladas.

# Mejor: usar pip-tools
pip-compile requirements.in > requirements.txt  # Genera lockfile desde requirements.in.

# Instalar
pip install -r requirements.txt         # Instala exactamente las versiones especificadas.

# Moderno: pyproject.toml
pip install -e ".[dev]"                 # -e: editable. [dev]: grupo de deps opcionales.
```

---

## Pregunta 35: Makefile
**¬øPara qu√© sirve un Makefile?**

### Respuesta:
```makefile
.PHONY: install test train              # Declara targets que no son archivos.

install:                                # Target: make install
	pip install -e ".[dev]"             # Comando a ejecutar (TAB obligatorio).

test:                                   # Target: make test
	pytest tests/ -v --cov=src          # Ejecuta tests con coverage.

train:                                  # Target: make train
	python main.py --config configs/config.yaml

lint:                                   # Target: make lint
	ruff check src/                     # Verifica calidad de c√≥digo.
```

**Uso**:
```bash
make install
make test
make train
```

**Beneficio**: Comandos est√°ndar, documentados, f√°ciles de recordar.

---

## Pregunta 36: pytest B√°sico
**¬øC√≥mo escribes un test b√°sico?**

### Respuesta:
```python
# tests/test_data.py
import pytest                            # Framework de testing.
import pandas as pd

def test_load_data():                    # Funci√≥n test: debe empezar con test_.
    df = pd.read_csv("data/raw/sample.csv")
    assert len(df) > 0                   # assert: falla si condici√≥n es False.
    assert "target" in df.columns        # Verifica que columna existe.

def test_no_nulls_in_target():           # Otro test independiente.
    df = pd.read_csv("data/raw/sample.csv")
    assert df["target"].isnull().sum() == 0  # No debe haber NaN en target.

# Ejecutar
# pytest tests/test_data.py -v           # -v: verbose, muestra detalles.
```

---

## Pregunta 37: Estructura de Proyecto
**¬øC√≥mo organizas un proyecto ML?**

### Respuesta:
```
mi-proyecto/
‚îú‚îÄ‚îÄ src/miproyecto/     # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py       # Configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ data.py         # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ features.py     # Feature engineering
‚îÇ   ‚îî‚îÄ‚îÄ training.py     # Entrenamiento
‚îú‚îÄ‚îÄ app/                # APIs
‚îú‚îÄ‚îÄ tests/              # Tests
‚îú‚îÄ‚îÄ configs/            # YAML configs
‚îú‚îÄ‚îÄ data/raw/           # Datos
‚îú‚îÄ‚îÄ artifacts/          # Modelos guardados
‚îú‚îÄ‚îÄ pyproject.toml      # Dependencias
‚îú‚îÄ‚îÄ Makefile           
‚îî‚îÄ‚îÄ README.md
```

---

## Pregunta 38: README
**¬øQu√© debe tener un buen README?**

### Respuesta:
```markdown
# Nombre del Proyecto

## Descripci√≥n
Qu√© hace el proyecto, problema que resuelve.

## Instalaci√≥n
```bash
pip install -e .
```

## Uso R√°pido
```python
from miproyecto import predict
result = predict(data)
```

## Estructura
√Årbol de directorios.

## Tests
```bash
make test
```

## Autor
Nombre, contacto.
```

---

## Pregunta 39: Docker B√°sico
**¬øQu√© es Docker y por qu√© usarlo?**

### Respuesta:
Docker empaqueta tu aplicaci√≥n con todas sus dependencias.

```dockerfile
FROM python:3.11-slim                    # Imagen base: Python 3.11 ligera.

WORKDIR /app                             # Directorio de trabajo dentro del contenedor.
COPY requirements.txt .                  # Copia solo requirements primero (cache de capas).
RUN pip install -r requirements.txt      # Instala dependencias.

COPY . .                                 # Copia el resto del c√≥digo.
CMD ["python", "main.py"]               # Comando por defecto al ejecutar contenedor.
```

```bash
# Construir
docker build -t mi-app .                 # -t: tag/nombre. .: contexto actual.

# Ejecutar
docker run mi-app                        # Ejecuta contenedor con la imagen.
```

**Beneficio**: "Funciona en mi m√°quina" ‚Üí Funciona en cualquier m√°quina.

---

## Pregunta 40: APIs B√°sicas
**¬øQu√© es una API REST?**

### Respuesta:
API = Interfaz para que otros programas usen tu c√≥digo.

```python
from fastapi import FastAPI               # Framework web moderno para APIs.

app = FastAPI()                           # Crea instancia de la aplicaci√≥n.

@app.get("/health")                       # Decorador: ruta GET /health.
def health():
    return {"status": "ok"}               # Retorna JSON autom√°ticamente.

@app.post("/predict")                     # Decorador: ruta POST /predict.
def predict(data: dict):                 # data: body del request como dict.
    # Usar modelo
    return {"prediction": result}         # Respuesta JSON.
```

```bash
# Ejecutar
uvicorn app:app --reload                 # uvicorn: servidor ASGI. --reload: hot reload.

# Probar
curl http://localhost:8000/health        # curl: hace request HTTP desde terminal.
```

---

# 5. Pr√°ctica con el Portafolio (Preguntas 41-50) {#5-pr√°ctica-con-el-portafolio-preguntas-41-50}

## Pregunta 41: Describir el Portafolio
**Cu√©ntame sobre el portafolio.**

### Respuesta:
"Es un portafolio de MLOps con 3 proyectos production-ready:

1. **BankChurn-Predictor**: Clasificaci√≥n binaria para predecir churn de clientes bancarios. Pipeline sklearn unificado, FastAPI, 79% coverage.

2. **CarVision-Market-Intelligence**: Regresi√≥n para predecir precios de autos usados. FeatureEngineer centralizado, Streamlit dashboard.

3. **TelecomAI**: Clasificaci√≥n multiclase para segmentaci√≥n de clientes de telecom.

Todos siguen las mismas pr√°cticas: estructura src/, Pydantic para configs, pytest, GitHub Actions CI."

---

## Pregunta 42: Ejecutar el Proyecto
**¬øC√≥mo ejecuto BankChurn?**

### Respuesta:
```bash
# 1. Clonar
git clone https://github.com/duqueom/ML-MLOps-Portfolio.git  # Descarga repositorio.
cd ML-MLOps-Portfolio/BankChurn-Predictor  # Entra al proyecto.

# 2. Crear entorno
python -m venv .venv                     # Crea entorno virtual.
source .venv/bin/activate                # Activa entorno (Linux/Mac).

# 3. Instalar
pip install -e ".[dev]"                  # Instala proyecto + deps de desarrollo.

# 4. Entrenar
python main.py --config configs/config.yaml  # Ejecuta entrenamiento con config.

# 5. API
uvicorn app.fastapi_app:app --reload     # Inicia servidor de desarrollo.

# 6. Tests
pytest tests/ -v                         # Ejecuta todos los tests.
```

---

## Pregunta 43: Entender el Pipeline
**¬øC√≥mo funciona el pipeline de BankChurn?**

### Respuesta:
```python
# 1. Cargar config
config = BankChurnConfig.from_yaml("configs/config.yaml")  # Pydantic valida config.

# 2. Cargar datos
df = pd.read_csv(config.data.raw_path)   # Ruta viene de config.

# 3. Crear trainer
trainer = Trainer(config)                 # Trainer encapsula l√≥gica de entrenamiento.

# 4. Entrenar (dentro crea Pipeline sklearn)
trainer.fit(X, y)                         # fit: entrena preprocesador + modelo.
# Pipeline = [preprocessor, model]        # Todo en un objeto.
# preprocessor = ColumnTransformer(numeric_pipe, categorical_pipe)

# 5. Evaluar
metrics = trainer.evaluate(X_test, y_test)  # Retorna dict de m√©tricas.

# 6. Guardar
trainer.save("artifacts/")                # Serializa pipeline completo.
```

---

## Pregunta 44: Modificar el C√≥digo
**¬øC√≥mo a√±adir√≠as una nueva feature?**

### Respuesta:
```python
# 1. En config.yaml, a√±adir columna
features:
  numerical:
    - CreditScore
    - Age
    - NewFeature  # Nueva                # Solo agregar aqu√≠ si ya existe en datos.

# 2. Si requiere transformaci√≥n, editar FeatureEngineer
class FeatureEngineer:                    # Transformer custom.
    def transform(self, X):
        X['NewFeature'] = X['Col1'] / X['Col2']  # Crea feature derivada.
        return X

# 3. Agregar test
def test_new_feature():                   # Test para la nueva feature.
    fe = FeatureEngineer()
    result = fe.transform(sample_df)
    assert 'NewFeature' in result.columns # Verifica que se cre√≥.

# 4. Ejecutar tests
pytest tests/test_features.py -v          # Verifica que todo sigue funcionando.
```

---

## Pregunta 45: Leer un Error
**Este c√≥digo falla. ¬øPor qu√©?**
```python
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)
```

### Respuesta:
**Problema**: `fit_transform` en test causa data leakage.

```python
# ‚úÖ Correcto
X_train = scaler.fit_transform(X_train)  # fit + transform: aprende de train.
X_test = scaler.transform(X_test)        # solo transform: usa params de train.
```

El scaler debe aprender (fit) solo de training data.

---

## Pregunta 46: Interpretar M√©tricas
**El modelo tiene accuracy 95% pero el negocio no est√° contento. ¬øPor qu√©?**

### Respuesta:
Posibles razones:

1. **Clases desbalanceadas**: Si 95% son clase 0, predecir siempre 0 da 95% accuracy pero es in√∫til.

2. **M√©trica incorrecta**: El negocio necesita recall (no perder churners) pero optimizaste accuracy.

3. **Falsos negativos costosos**: Cada cliente que hace churn y no detectamos cuesta $X.

**Soluci√≥n**: Usar F1, recall, o una m√©trica de negocio (costo).

---

## Pregunta 47: Configuraci√≥n YAML
**¬øPor qu√© usar archivos YAML para configuraci√≥n?**

### Respuesta:
```yaml
# configs/config.yaml
model:
  type: "random_forest"          # Tipo de modelo a usar.
  n_estimators: 100               # Hiperpar√°metros del modelo.
  max_depth: 10

data:
  raw_path: "data/raw/Churn.csv"  # Rutas configurables.
  test_size: 0.2                  # Proporci√≥n de test.

training:
  random_state: 42                # Semilla para reproducibilidad.
```

**Ventajas**:
1. **Separaci√≥n**: Cambiar par√°metros sin tocar c√≥digo
2. **Versionable**: Git puede trackear cambios
3. **Legible**: F√°cil de entender
4. **Reproducibilidad**: Guardar config de cada experimento

---

## Pregunta 48: CI/CD B√°sico
**¬øQu√© hace el workflow de GitHub Actions?**

### Respuesta:
```yaml
# .github/workflows/ci.yml
name: CI                          # Nombre del workflow.
on: [push, pull_request]          # Triggers: se activa en push o PR.

jobs:
  test:
    runs-on: ubuntu-latest        # Ejecuta en Ubuntu.
    steps:
      - uses: actions/checkout@v4  # Clona el repo.
      - uses: actions/setup-python@v5  # Instala Python.
      - run: pip install -e ".[dev]"  # Instala dependencias.
      - run: pytest tests/ -v     # Ejecuta tests.
```

**Flujo**:
1. Push c√≥digo ‚Üí GitHub Actions se activa
2. Crea m√°quina virtual limpia
3. Instala dependencias
4. Ejecuta tests
5. Reporta pass/fail

---

## Pregunta 49: Debugging en Producci√≥n
**El API retorna error 500. ¬øC√≥mo lo depuras?**

### Respuesta:
```python
# 1. Ver logs
uvicorn app:app --log-level debug # --log-level debug: muestra todos los logs.

# 2. A√±adir logging
import logging
logging.basicConfig(level=logging.DEBUG)  # Configura nivel de logging.

@app.post("/predict")
def predict(data: Input):
    logging.debug(f"Input: {data}")        # Log de entrada para debugging.
    try:
        result = model.predict(...)        # Operaci√≥n que puede fallar.
        logging.debug(f"Result: {result}") # Log de resultado.
        return result
    except Exception as e:
        logging.error(f"Error: {e}")       # Log de error con detalles.
        raise                              # Re-lanza para que FastAPI maneje.

# 3. Probar localmente
curl -X POST http://localhost:8000/predict \  # curl: cliente HTTP desde terminal.
  -H "Content-Type: application/json" \       # Header: indica formato JSON.
  -d '{"credit_score": 650, ...}'             # -d: data/body del request.
```

---

## Pregunta 50: Pr√≥ximos Pasos
**¬øQu√© aprender√≠as despu√©s de este portafolio?**

### Respuesta:
"Con las bases del portafolio, me gustar√≠a profundizar en:

1. **MLflow/Experiment Tracking**: Ya est√° configurado, pero quiero usarlo m√°s para comparar experimentos sistem√°ticamente.

2. **Docker avanzado**: Optimizar im√°genes, multi-stage builds.

3. **Testing m√°s robusto**: A√±adir tests de integraci√≥n, property-based testing.

4. **Kubernetes b√°sico**: Entender c√≥mo escalar los servicios.

5. **Monitoreo en producci√≥n**: Detectar drift, alertas.

El portafolio me dio la base; ahora quiero profundizar en cada √°rea."

---

# üìö Recursos para Preparaci√≥n

## M√≥dulos de la Gu√≠a Relacionados

| Pregunta | M√≥dulo |
|----------|--------|
| Python b√°sico | [01_PYTHON_MODERNO.md](01_PYTHON_MODERNO.md) |
| ML fundamentos | [07_SKLEARN_PIPELINES.md](07_SKLEARN_PIPELINES.md), [08_INGENIERIA_FEATURES.md](08_INGENIERIA_FEATURES.md) |
| Git | [05_GIT_PROFESIONAL.md](05_GIT_PROFESIONAL.md) |
| Testing | [11_TESTING_ML.md](11_TESTING_ML.md) |
| APIs | [14_FASTAPI.md](14_FASTAPI.md) |

## Checklist Pre-Entrevista

- [ ] Puedo ejecutar `make install && make test` en BankChurn
- [ ] Entiendo qu√© hace cada archivo en `src/bankchurn/`
- [ ] S√© explicar train/test split y por qu√© importa
- [ ] Puedo leer y modificar el `config.yaml`
- [ ] Entiendo el flujo Git b√°sico

---

<div align="center">

**¬°√âxito en tu entrevista! üöÄ**

*Recuerda: ser Junior significa estar aprendiendo. Muestra curiosidad y ganas de aprender.*

[‚Üê √çndice](00_INDICE.md) | [Simulacro Mid ‚Üí](SIMULACRO_ENTREVISTA_MID.md) | [Simulacro Senior ‚Üí](SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md)

</div>
