{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\ude80 Gu\u00eda MLOps \u2014 Portfolio Edition (24 Semanas)","text":"<p>De Cero a Senior/Staff MLOps en 6 Meses</p> <p>Mapa completo para construir el portafolio ML-MLOps-Portfolio desde cero.</p>"},{"location":"#tabla-de-contenidos","title":"\ud83d\udccb Tabla de Contenidos","text":"<ol> <li>\u00bfQu\u00e9 Lograr\u00e1s?</li> <li>Estructura del Programa (24 Semanas)</li> <li>Tabla de Mapeo: Concepto \u2192 Herramienta \u2192 Portafolio</li> <li>Roadmap Visual</li> <li>Contenido por Mes</li> <li>Ex\u00e1menes de Hito (6 Milestones)</li> <li>Gu\u00eda de Troubleshooting</li> <li>Quick Start</li> <li>Estructura de Carpetas</li> </ol>"},{"location":"#que-lograras","title":"\ud83c\udfaf \u00bfQu\u00e9 Lograr\u00e1s?","text":"<p>Al completar esta gu\u00eda de 24 semanas ser\u00e1s capaz de:</p> Habilidad Nivel Evidencia en el Portafolio C\u00f3digo Python profesional Senior Type hints, Pydantic, SOLID en los 3 proyectos Pipelines ML reproducibles Senior sklearn Pipeline unificado, sin data leakage Versionado de datos y modelos Senior DVC pipelines, MLflow Model Registry Testing &amp; CI/CD Senior 80%+ coverage, GitHub Actions, matrix testing APIs de producci\u00f3n Senior FastAPI con validaci\u00f3n, Docker multi-stage Observabilidad Staff Prometheus, logging estructurado, drift detection Infraestructura como C\u00f3digo Staff Terraform, Kubernetes manifests Pasar entrevistas t\u00e9cnicas Staff Simulacros completos, speech de 5-7 min"},{"location":"#estructura-del-programa-24-semanas","title":"\ud83d\udcc5 Estructura del Programa (24 Semanas)","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                        RUTA DE APRENDIZAJE (24 SEMANAS / 6 MESES)                    \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                                      \u2551\n\u2551  MES 1: FUNDAMENTOS (Semanas 1-4)                                                    \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                    \u2551\n\u2551  [S1] Python Moderno + Tipado                                                        \u2551\n\u2551  [S2] Dise\u00f1o de Sistemas + Arquitectura                                              \u2551\n\u2551  [S3] Estructura de Proyecto + Entornos                                              \u2551\n\u2551  [S4] Git Profesional + Pre-commit                                                   \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 1: Setup Completo                                               \u2551\n\u2551                                                                                      \u2551\n\u2551  MES 2: DATOS &amp; VERSIONADO (Semanas 5-8)                                             \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                            \u2551\n\u2551  [S5] DVC Fundamentos + Remote Storage                                               \u2551\n\u2551  [S6] Pipelines DVC + Reproducibilidad                                               \u2551\n\u2551  [S7] sklearn Pipelines B\u00e1sicos                                                      \u2551\n\u2551  [S8] ColumnTransformer + Custom Transformers                                        \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 2: Pipeline Reproducible                                        \u2551\n\u2551                                                                                      \u2551\n\u2551  MES 3: ML ENGINEERING (Semanas 9-12)                                                \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                \u2551\n\u2551  [S9]  Ingenier\u00eda de Features                                                        \u2551\n\u2551  [S10] Training Profesional + Cross-Validation                                       \u2551\n\u2551  [S11] MLflow Tracking + UI                                                          \u2551\n\u2551  [S12] MLflow Model Registry + Signatures                                            \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 3: Experimento Completo                                         \u2551\n\u2551                                                                                      \u2551\n\u2551  MES 4: TESTING &amp; CI/CD (Semanas 13-16)                                              \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                              \u2551\n\u2551  [S13] Testing Unitario para ML                                                      \u2551\n\u2551  [S14] Testing de Integraci\u00f3n + Fixtures                                             \u2551\n\u2551  [S15] GitHub Actions + Matrix Testing                                               \u2551\n\u2551  [S16] Coverage Gates + Security Scanning                                            \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 4: CI/CD Completo                                               \u2551\n\u2551                                                                                      \u2551\n\u2551  MES 5: DEPLOYMENT (Semanas 17-20)                                                   \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                                   \u2551\n\u2551  [S17] Docker Fundamentos + Multi-stage                                              \u2551\n\u2551  [S18] FastAPI para ML + Schemas Pydantic                                            \u2551\n\u2551  [S19] Streamlit Dashboards + Caching                                                \u2551\n\u2551  [S20] Observabilidad + Logging Estructurado                                         \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 5: API Desplegada                                               \u2551\n\u2551                                                                                      \u2551\n\u2551  MES 6: PRODUCCI\u00d3N &amp; MAESTR\u00cdA (Semanas 21-24)                                        \u2551\n\u2551  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550                                       \u2551\n\u2551  [S21] Estrategias de Despliegue + Cloud                                             \u2551\n\u2551  [S22] Infraestructura como C\u00f3digo (Terraform)                                       \u2551\n\u2551  [S23] Documentaci\u00f3n Profesional + Model Cards                                       \u2551\n\u2551  [S24] Proyecto Integrador + Preparaci\u00f3n Entrevistas                                 \u2551\n\u2551       \ud83d\udccb EXAMEN HITO 6: Portafolio Completo                                          \u2551\n\u2551                                                                                      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>Dedicaci\u00f3n sugerida: 8-10 horas/semana (total ~200 horas)</p>"},{"location":"#los-4-pilares-pedagogicos","title":"\ud83c\udfdb\ufe0f Los 4 Pilares Pedag\u00f3gicos","text":"<p>Cada semana de esta gu\u00eda est\u00e1 estructurada en 4 pilares que garantizan un aprendizaje profundo y aplicable:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         LOS 4 PILARES DE CADA SEMANA                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                     \u2502\n\u2502  1\ufe0f\u20e3 TEOR\u00cdA FUNDAMENTAL                2\ufe0f\u20e3 PR\u00c1CTICA GUIADA                          \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                        \u2502\n\u2502  \u2022 Explicaci\u00f3n conceptual              \u2022 C\u00f3digo paso a paso                         \u2502\n\u2502  \u2022 Analog\u00edas del mundo real            \u2022 Construcci\u00f3n incremental                   \u2502\n\u2502    (\"Docker es como un                 \u2022 Conexi\u00f3n directa con el                    \u2502\n\u2502     contenedor de carga...\")             portafolio real                            \u2502\n\u2502  \u2022 Tabla de decisiones t\u00e9cnicas        \u2022 Comandos exactos a ejecutar                \u2502\n\u2502                                                                                     \u2502\n\u2502  3\ufe0f\u20e3 LA TRAMPA (Debugging)             4\ufe0f\u20e3 EVALUACI\u00d3N                               \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500             \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                \u2502\n\u2502  \u2022 Errores comunes que                 \u2022 3 preguntas conceptuales                   \u2502\n\u2502    TODOS cometen                       \u2022 1 ejercicio de c\u00f3digo                      \u2502\n\u2502  \u2022 S\u00edntomas y diagn\u00f3stico              \u2022 R\u00fabrica de autoevaluaci\u00f3n                  \u2502\n\u2502  \u2022 Soluci\u00f3n paso a paso                \u2022 M\u00ednimo aprobatorio: 70%                    \u2502\n\u2502  \u2022 C\u00f3mo prevenirlo en futuro                                                        \u2502\n\u2502                                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#recursos-por-pilar","title":"\ud83d\udcda Recursos por Pilar","text":"Pilar Ubicaci\u00f3n Principal Contenido 1. Teor\u00eda Cada m\u00f3dulo (<code>docs/NN_*.md</code>) Conceptos, analog\u00edas, tablas de decisi\u00f3n 2. Pr\u00e1ctica README.md + m\u00f3dulos C\u00f3digo comentado, comandos, puentes al portafolio 3. La Trampa Secci\u00f3n \"\ud83e\udea4 La Trampa\" en cada m\u00f3dulo 50+ errores documentados integrados 4. Evaluaci\u00f3n Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" en cada m\u00f3dulo Quizzes integrados (3 preguntas + 1 ejercicio)"},{"location":"#flujo-de-aprendizaje-semanal","title":"\ud83c\udfaf Flujo de Aprendizaje Semanal","text":"<pre><code>Lunes-Martes     Mi\u00e9rcoles-Jueves     Viernes          Fin de Semana\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\ud83d\udcd6 TEOR\u00cdA        \ud83d\udcbb PR\u00c1CTICA          \ud83e\udea4 LA TRAMPA      \ud83d\udcdd EVALUACI\u00d3N\nLeer m\u00f3dulo      Replicar c\u00f3digo      Revisar errores  Completar quiz\nTomar notas      Aplicar al           Debugging        Verificar \u226570%\n                 portafolio           guiado\n</code></pre>"},{"location":"#tabla-de-mapeo-concepto-herramienta-portafolio","title":"\ud83d\uddfa\ufe0f Tabla de Mapeo: Concepto \u2192 Herramienta \u2192 Portafolio","text":"<p>Esta tabla conecta cada concepto te\u00f3rico con la herramienta pr\u00e1ctica y su ubicaci\u00f3n exacta en el portafolio:</p> Semana Concepto Te\u00f3rico Herramienta Ubicaci\u00f3n en Portafolio M\u00f3dulo Gu\u00eda S1 Tipado est\u00e1tico <code>mypy</code>, <code>Pydantic</code> <code>*/src/*/config.py</code> 01_PYTHON_MODERNO S2 Arquitectura ML ML Canvas, C4 Model <code>docs/architecture/</code> 02_DISENO_SISTEMAS S3 Estructura c\u00f3digo <code>src/</code> layout <code>BankChurn-Predictor/src/</code> 03_ESTRUCTURA_PROYECTO S4 Calidad c\u00f3digo <code>pre-commit</code>, <code>ruff</code> <code>.pre-commit-config.yaml</code> 05_GIT_PROFESIONAL S5 Versionado datos DVC <code>.dvc/</code>, <code>data/*.dvc</code> 06_VERSIONADO_DATOS S6 Pipelines datos DVC pipelines <code>dvc.yaml</code>, <code>dvc.lock</code> 06_VERSIONADO_DATOS S7 Preprocesamiento <code>sklearn.Pipeline</code> <code>*/src/*/pipeline.py</code> 07_SKLEARN_PIPELINES S8 Transformaciones <code>ColumnTransformer</code> <code>*/src/*/pipeline.py</code> 07_SKLEARN_PIPELINES S9 Feature Engineering Custom Transformers <code>*/src/*/features.py</code> 08_INGENIERIA_FEATURES S10 Entrenamiento <code>Trainer</code> class, CV <code>*/src/*/trainer.py</code> 09_TRAINING_PROFESIONAL S11 Experiment Tracking MLflow <code>mlruns/</code>, <code>mlflow.log_*</code> 10_EXPERIMENT_TRACKING S12 Model Registry MLflow Registry <code>models:/model_name/</code> 10_EXPERIMENT_TRACKING S13 Testing unitario pytest <code>tests/unit/</code> 11_TESTING_ML S14 Testing integraci\u00f3n <code>pytest-fixtures</code> <code>tests/integration/</code> 11_TESTING_ML S15 CI/CD GitHub Actions <code>.github/workflows/ci.yml</code> 12_CI_CD S16 Security <code>gitleaks</code>, <code>safety</code> <code>.github/workflows/security.yml</code> 12_CI_CD S17 Containerizaci\u00f3n Docker <code>Dockerfile</code>, <code>docker-compose.yml</code> 13_DOCKER S18 APIs ML FastAPI <code>app/fastapi_app.py</code> 14_FASTAPI S19 Dashboards Streamlit <code>app/streamlit_app.py</code> 15_STREAMLIT S20 Observabilidad <code>loguru</code>, Prometheus <code>*/src/*/logging.py</code> 16_OBSERVABILIDAD S21 Deploy strategies Blue-green, Canary <code>k8s/</code>, deployment configs 17_DESPLIEGUE S22 IaC Terraform <code>infra/terraform/</code> 18_INFRAESTRUCTURA S23 Documentaci\u00f3n Model Cards, MkDocs <code>docs/model_card.md</code> 19_DOCUMENTACION S24 Integraci\u00f3n Todo el stack Portafolio completo 20_PROYECTO_INTEGRADOR"},{"location":"#herramientas-del-stack-completo","title":"\ud83d\udd27 Herramientas del Stack Completo","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              STACK MLOps COMPLETO                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                     \u2502\n\u2502  DESARROLLO          \u2502  ML/DATA             \u2502  MLOps              \u2502  PRODUCCI\u00d3N     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500             \u2502  \u2500\u2500\u2500\u2500\u2500              \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500     \u2502\n\u2502  \u2022 Python 3.10+      \u2502  \u2022 pandas            \u2502  \u2022 DVC              \u2502  \u2022 Docker       \u2502\n\u2502  \u2022 Pydantic          \u2502  \u2022 numpy             \u2502  \u2022 MLflow           \u2502  \u2022 FastAPI      \u2502\n\u2502  \u2022 mypy              \u2502  \u2022 scikit-learn      \u2502  \u2022 pytest           \u2502  \u2022 Streamlit    \u2502\n\u2502  \u2022 ruff              \u2502  \u2022 joblib            \u2502  \u2022 GitHub Actions   \u2502  \u2022 Prometheus   \u2502\n\u2502  \u2022 pre-commit        \u2502                      \u2502  \u2022 gitleaks         \u2502  \u2022 Terraform    \u2502\n\u2502  \u2022 Poetry/pip        \u2502                      \u2502                     \u2502  \u2022 Kubernetes   \u2502\n\u2502                                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#contenido-por-mes","title":"\ud83d\udcda Contenido por Mes","text":""},{"location":"#mes-1-fundamentos-python-profesional-semanas-1-4","title":"\ud83d\uddd3\ufe0f MES 1: FUNDAMENTOS PYTHON PROFESIONAL (Semanas 1-4)","text":"<p>Objetivo: Dominar Python a nivel Staff Engineer \u2014 el c\u00f3digo del Portafolio NO se puede entender sin esto.</p>"},{"location":"#semana-1-type-hints-pydantic","title":"\ud83d\udcd6 Semana 1: Type Hints + Pydantic","text":"<p>\ud83c\udfaf Objetivo: C\u00f3digo con contratos expl\u00edcitos y configuraci\u00f3n validada.</p>"},{"location":"#teoria-fundamental","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Impacto en MLOps Tipado Est\u00e1tico Declarar tipos en tiempo de escritura mypy detecta errores ANTES de ejecutar Validaci\u00f3n en Frontera Verificar datos al ENTRAR al sistema Errores claros vs crashes cr\u00edpticos Fail Fast Fallar inmediatamente con error descriptivo Costo de bug: $1 (c\u00f3digo) vs $1000 (producci\u00f3n)"},{"location":"#practica-de-ingenieria","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EL PROBLEMA: C\u00f3digo Junior sin tipos\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef train(data, config):  # \u00bfQu\u00e9 tipos? \u00bfQu\u00e9 retorna?\n    pass  # Error aparece 3 capas despu\u00e9s\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LA SOLUCI\u00d3N: C\u00f3digo Staff con contratos\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nfrom typing import Tuple\nimport pandas as pd\nfrom pydantic import BaseModel, Field\n\nclass TrainConfig(BaseModel):\n    test_size: float = Field(default=0.2, ge=0.01, le=0.5)\n    n_estimators: int = Field(default=100, ge=10)\n\ndef train(\n    data: pd.DataFrame,\n    config: TrainConfig\n) -&gt; Tuple[Pipeline, dict[str, float]]:\n    \"\"\"Contrato claro: mypy verifica, Pydantic valida.\"\"\"\n    ...\n</code></pre>"},{"location":"#comandos-exactos","title":"\ud83d\udcbb Comandos Exactos","text":"<pre><code>pip install pydantic mypy ruff\nmypy src/bankchurn/training.py --strict  # 0 errores = listo\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/src/bankchurn/config.py</code></p> <p>\ud83d\udcdd Tarea: Tipar TODAS las funciones p\u00fablicas de <code>training.py</code></p>"},{"location":"#semana-2-oop-para-ml-protocolos-y-abc","title":"\ud83d\udcd6 Semana 2: OOP para ML \u2014 Protocolos y ABC","text":"<p>\ud83c\udfaf Objetivo: Escribir c\u00f3digo intercambiable y extensible con OOP profesional.</p>"},{"location":"#teoria-fundamental_1","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Uso en el Portafolio Protocol Duck typing verificable por mypy Compatibilidad con sklearn sin herencia ABC (Abstract Base Class) Contrato que OBLIGA implementaci\u00f3n BaseTrainer para los 3 proyectos Polimorfismo Mismo m\u00e9todo, diferentes implementaciones <code>trainer.fit()</code> funciona igual en BankChurn, CarVision, TelecomAI"},{"location":"#practica-de-ingenieria_1","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EL PROBLEMA: 3 trainers con APIs diferentes\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nclass TrainerA:\n    def entrenar(self, X, y): ...  # espa\u00f1ol\nclass TrainerB:\n    def fit_model(self, data): ...  # diferente firma\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LA SOLUCI\u00d3N: ABC define el contrato\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nfrom abc import ABC, abstractmethod\nimport pandas as pd\n\nclass BaseTrainer(ABC):\n    \"\"\"Todos los trainers del portafolio heredan de aqu\u00ed.\"\"\"\n\n    @abstractmethod\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"BaseTrainer\":\n        \"\"\"Entrenar modelo.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict(self, X: pd.DataFrame) -&gt; pd.Series:\n        \"\"\"Predecir.\"\"\"\n        pass\n\n# Protocol para sklearn (sin herencia):\nfrom typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass Predictor(Protocol):\n    def fit(self, X, y): ...\n    def predict(self, X): ...\n\n# sklearn cumple autom\u00e1ticamente:\nfrom sklearn.ensemble import RandomForestClassifier\nassert isinstance(RandomForestClassifier(), Predictor)  # True\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: Crear <code>common_utils/base.py</code> con <code>BaseTrainer</code></p> <p>\ud83d\udcdd Tarea: Hacer que <code>ChurnTrainer</code> herede de <code>BaseTrainer</code></p>"},{"location":"#semana-3-pandas-de-produccion-pandera","title":"\ud83d\udcd6 Semana 3: Pandas de Producci\u00f3n + Pandera","text":"<p>\ud83c\udfaf Objetivo: Validar DataFrames ANTES de que causen errores en el pipeline.</p>"},{"location":"#teoria-fundamental_2","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Por qu\u00e9 es cr\u00edtico Schema Contrato de estructura de datos Define qu\u00e9 columnas, tipos y rangos son v\u00e1lidos Pandera Validaci\u00f3n de DataFrames con decoradores Error claro: \"Age debe ser &gt;= 18\" vs crash en sklearn Data Contract Acuerdo entre productor y consumidor de datos El pipeline de features ESPERA cierta estructura"},{"location":"#practica-de-ingenieria_2","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EL PROBLEMA: C\u00f3digo Junior asume DataFrame correcto\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef train(df):\n    X = df.drop(\"Exited\", axis=1)  # \u00bfY si \"Exited\" no existe?\n    y = df[\"Exited\"]  # \u00bfY si tiene valores inv\u00e1lidos como 2 o -1?\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LA SOLUCI\u00d3N: Pandera valida en la frontera\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nimport pandera as pa\nfrom pandera.typing import DataFrame, Series\n\nclass BankChurnSchema(pa.DataFrameModel):\n    CreditScore: Series[int] = pa.Field(ge=300, le=850)\n    Age: Series[int] = pa.Field(ge=18, le=100)\n    Balance: Series[float] = pa.Field(ge=0)\n    Exited: Series[int] = pa.Field(isin=[0, 1])\n\n    class Config:\n        strict = True  # No permite columnas extra\n\n@pa.check_types\ndef train(df: DataFrame[BankChurnSchema]) -&gt; Pipeline:\n    \"\"\"DataFrame GARANTIZADO v\u00e1lido por Pandera.\"\"\"\n    X = df.drop(\"Exited\", axis=1)\n    y = df[\"Exited\"]\n    ...\n</code></pre>"},{"location":"#comandos-exactos_1","title":"\ud83d\udcbb Comandos Exactos","text":"<pre><code>pip install pandera\n# Crear src/bankchurn/schemas.py con los schemas\npytest tests/test_schemas.py -v\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/src/bankchurn/schemas.py</code></p> <p>\ud83d\udcdd Tarea: Crear <code>RawDataSchema</code> (permisivo) y <code>ProcessedDataSchema</code> (estricto)</p>"},{"location":"#semana-4-estructura-de-proyecto-git-profesional","title":"\ud83d\udcd6 Semana 4: Estructura de Proyecto + Git Profesional","text":"<p>\ud83c\udfaf Objetivo: Organizar c\u00f3digo como paquete instalable con calidad automatizada.</p>"},{"location":"#teoria-fundamental_3","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Beneficio src/ Layout C\u00f3digo en <code>src/package/</code> Fuerza <code>pip install -e .</code> \u2014 evita \"funciona en mi m\u00e1quina\" pyproject.toml Metadata est\u00e1ndar del proyecto Un archivo para deps, tools, builds Pre-commit Hooks que corren antes de commit Calidad GARANTIZADA en cada commit"},{"location":"#practica-de-ingenieria_3","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code>BankChurn-Predictor/\n\u251c\u2500\u2500 src/bankchurn/          # C\u00f3digo fuente\n\u2502   \u251c\u2500\u2500 __init__.py         # Exporta API p\u00fablica\n\u2502   \u251c\u2500\u2500 config.py           # Pydantic\n\u2502   \u251c\u2500\u2500 schemas.py          # Pandera  \n\u2502   \u251c\u2500\u2500 training.py         # Trainer\n\u2502   \u2514\u2500\u2500 cli.py              # CLI\n\u251c\u2500\u2500 tests/                  # Tests (espejo de src/)\n\u251c\u2500\u2500 configs/config.yaml     # Config externa\n\u251c\u2500\u2500 pyproject.toml          # Metadata\n\u251c\u2500\u2500 Makefile                # Comandos\n\u2514\u2500\u2500 .pre-commit-config.yaml # Hooks\n</code></pre>"},{"location":"#comandos-exactos_2","title":"\ud83d\udcbb Comandos Exactos","text":"<pre><code># Instalar en modo editable\npip install -e \".[dev]\"\n\n# Verificar import funciona\npython -c \"from bankchurn import ChurnTrainer; print('OK')\"\n\n# Configurar pre-commit\npip install pre-commit\npre-commit install\npre-commit run --all-files\n\n# Commit convencional\ngit commit -m \"feat(training): add type hints to ChurnTrainer\"\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/pyproject.toml</code></p> <p>\ud83d\udcdd Tarea: <code>pip install -e \".[dev]\"</code> + <code>pytest</code> + <code>mypy</code> pasan sin errores</p>"},{"location":"#mes-2-datos-pipelines-semanas-5-8","title":"\ud83d\uddd3\ufe0f MES 2: DATOS &amp; PIPELINES (Semanas 5-8)","text":"<p>Objetivo: Dominar versionado de datos, pipelines reproducibles y preprocesamiento profesional.</p>"},{"location":"#semana-5-dvc-versionado-de-datos","title":"\ud83d\udcd6 Semana 5: DVC \u2014 Versionado de Datos","text":"<p>\ud83c\udfaf Objetivo: Versionar datos como se versiona c\u00f3digo.</p>"},{"location":"#teoria-fundamental_4","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Por qu\u00e9 es cr\u00edtico Reproducibilidad Obtener EXACTAMENTE el mismo resultado \"Dame los datos de hace 3 meses\" Data Lineage Rastrear origen y transformaciones de datos Debugging y compliance Content-addressable Archivos identificados por hash, no por nombre Detecta cambios autom\u00e1ticamente"},{"location":"#practica-de-ingenieria_4","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EL PROBLEMA: Datos en carpetas con fechas\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# data/\n# \u251c\u2500\u2500 customers_v1.csv\n# \u251c\u2500\u2500 customers_v2_final.csv\n# \u251c\u2500\u2500 customers_v2_final_REAL.csv  # \u2190 \u00bfCu\u00e1l es el bueno?\n# \u251c\u2500\u2500 customers_backup_juan.csv\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LA SOLUCI\u00d3N: DVC trackea por contenido\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# data/\n# \u2514\u2500\u2500 customers.csv.dvc  # \u2190 Git trackea esto (puntero)\n# El archivo real est\u00e1 en remote storage, identificado por hash MD5\n</code></pre>"},{"location":"#comandos-exactos_3","title":"\ud83d\udcbb Comandos Exactos","text":"<pre><code># Inicializar DVC\ndvc init\ndvc add data/raw/bank_customers.csv\n\n# Ver el puntero creado\ncat data/raw/bank_customers.csv.dvc\n# outs:\n#   - md5: d41d8cd98f00b204e9800998ecf8427e\n#     path: bank_customers.csv\n\n# Commitear puntero (no datos)\ngit add data/raw/bank_customers.csv.dvc data/raw/.gitignore\ngit commit -m \"data: add raw customer data v1\"\n\n# Configurar remote y push\ndvc remote add -d storage s3://my-bucket/dvc\ndvc push\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/data/*.dvc</code>, <code>.dvc/config</code></p> <p>\ud83d\udcdd Tarea: <code>dvc pull</code> en una carpeta nueva debe traer exactamente los mismos datos</p>"},{"location":"#semana-6-pipelines-dvc-reproducibilidad","title":"\ud83d\udcd6 Semana 6: Pipelines DVC + Reproducibilidad","text":"<p>\ud83c\udfaf Objetivo: Crear pipelines de datos reproducibles con DAGs.</p>"},{"location":"#teoria-fundamental_5","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Por qu\u00e9 es cr\u00edtico DAG Directed Acyclic Graph \u2014 pasos ordenados sin ciclos Solo re-ejecuta lo que cambi\u00f3 Determinismo Mismo input \u2192 mismo output siempre Reproducibilidad cient\u00edfica Idempotencia Ejecutar N veces = ejecutar 1 vez Safe to retry"},{"location":"#practica-de-ingenieria_5","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># dvc.yaml \u2014 Define el pipeline completo\nstages:\n  prepare:\n    cmd: python src/bankchurn/prepare.py\n    deps:\n      - src/bankchurn/prepare.py\n      - data/raw/bank_customers.csv\n    outs:\n      - data/processed/train.csv\n      - data/processed/test.csv\n\n  train:\n    cmd: python src/bankchurn/train.py\n    deps:\n      - src/bankchurn/train.py\n      - data/processed/train.csv\n    outs:\n      - models/model.pkl\n    metrics:\n      - metrics.json:\n          cache: false\n</code></pre>"},{"location":"#comandos-exactos_4","title":"\ud83d\udcbb Comandos Exactos","text":"<pre><code>dvc repro           # Ejecuta pipeline completo\ndvc dag             # Visualiza el DAG\ndvc metrics show    # Muestra m\u00e9tricas\ndvc metrics diff    # Compara entre versiones\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/dvc.yaml</code>, <code>dvc.lock</code></p> <p>\ud83d\udcdd Tarea: <code>dvc repro</code> ejecuta sin errores y genera <code>metrics.json</code></p>"},{"location":"#semana-7-sklearn-pipelines-sin-data-leakage","title":"\ud83d\udcd6 Semana 7: sklearn Pipelines \u2014 Sin Data Leakage","text":"<p>\ud83c\udfaf Objetivo: Crear pipelines ML que previenen data leakage.</p>"},{"location":"#teoria-fundamental_6","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Por qu\u00e9 es cr\u00edtico Data Leakage Informaci\u00f3n del test contamina el train Modelo parece bueno pero falla en producci\u00f3n fit vs transform fit aprende estad\u00edsticas, transform las aplica fit SOLO en train, transform en train Y test Pipeline Cadena de transformaciones como un objeto Encapsula preprocessing + modelo"},{"location":"#practica-de-ingenieria_6","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EL PROBLEMA: Data Leakage (error de principiante)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # \u274c fit en TODO X (incluye test)\nX_train, X_test = train_test_split(X_scaled)  # Leakage!\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LA SOLUCI\u00d3N: Pipeline encapsula todo\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler()),\n    (\"classifier\", RandomForestClassifier())\n])\n\n# Split ANTES de cualquier fit\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# fit_transform SOLO en train\npipeline.fit(X_train, y_train)  # \u2705 Aprende de train\n\n# transform impl\u00edcito en predict (usa estad\u00edsticas de train)\npredictions = pipeline.predict(X_test)  # \u2705 Sin leakage\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>BankChurn-Predictor/src/bankchurn/pipeline.py</code></p> <p>\ud83d\udcdd Tarea: Crear <code>create_pipeline()</code> que retorna Pipeline completo</p>"},{"location":"#semana-8-columntransformer-custom-transformers","title":"\ud83d\udcd6 Semana 8: ColumnTransformer + Custom Transformers","text":"<p>\ud83c\udfaf Objetivo: Procesar diferentes tipos de columnas con transformadores custom.</p>"},{"location":"#teoria-fundamental_7","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Definici\u00f3n Por qu\u00e9 es cr\u00edtico ColumnTransformer Aplica transformaciones diferentes por grupo de columnas Num\u00e9ricas: escalar, Categ\u00f3ricas: one-hot BaseEstimator + TransformerMixin Clases base para transformadores sklearn-compatible Tu transformer funciona en Pipeline fit/transform API Contrato est\u00e1ndar de sklearn Interoperabilidad garantizada"},{"location":"#practica-de-ingenieria_7","title":"\ud83d\udd27 Pr\u00e1ctica de Ingenier\u00eda","text":"<pre><code>from sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\n\nclass OutlierClipper(BaseEstimator, TransformerMixin):\n    \"\"\"Custom transformer que recorta outliers usando IQR.\"\"\"\n\n    def __init__(self, factor: float = 1.5):\n        self.factor = factor\n\n    def fit(self, X, y=None):\n        Q1, Q3 = np.percentile(X, [25, 75], axis=0)\n        IQR = Q3 - Q1\n        self.lower_ = Q1 - self.factor * IQR\n        self.upper_ = Q3 + self.factor * IQR\n        return self  # \u2190 Siempre retorna self\n\n    def transform(self, X):\n        return np.clip(X, self.lower_, self.upper_)\n\n# Uso en ColumnTransformer:\npreprocessor = ColumnTransformer([\n    (\"num\", Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n        (\"outlier\", OutlierClipper()),\n        (\"scaler\", StandardScaler())\n    ]), numerical_columns),\n    (\"cat\", Pipeline([\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n    ]), categorical_columns)\n])\n</code></pre> <p>\ud83d\udce6 Puente al Portafolio: <code>CarVision-Market-Intelligence/src/carvision/features.py</code></p> <p>\ud83d\udcdd Tarea: Crear <code>OutlierClipper</code> y <code>FeatureEngineer</code> como transformers custom</p>"},{"location":"#mes-3-ml-engineering-semanas-9-12","title":"\ud83d\uddd3\ufe0f MES 3: ML ENGINEERING (Semanas 9-12)","text":"<p>Objetivo: Dominar entrenamiento profesional y tracking de experimentos.</p>"},{"location":"#semana-9-ingenieria-de-features","title":"\ud83d\udcd6 Semana 9: Ingenier\u00eda de Features","text":"<p>\ud83c\udfaf Objetivo: Crear features robustos sin data leakage.</p>"},{"location":"#teoria-fundamental_8","title":"\ud83d\udcd0 Teor\u00eda Fundamental","text":"Concepto Analog\u00eda Por qu\u00e9 importa Feature Engineering Preparar ingredientes antes de cocinar Features buenos = modelo bueno Target Encoding Reemplazar categor\u00eda por promedio del target Poderoso pero peligroso (leakage) FeatureEngineer class Chef que sabe todas las recetas Centraliza l\u00f3gica, evita duplicaci\u00f3n"},{"location":"#practica-empirica","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; src/bankchurn/features.py &lt;&lt; 'EOF'\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Crea features derivados para predicci\u00f3n de churn.\"\"\"\n\n    def fit(self, X: pd.DataFrame, y=None):\n        return self\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        X = X.copy()\n        # Feature: Ratio balance/salario\n        if \"Balance\" in X.columns and \"EstimatedSalary\" in X.columns:\n            X[\"BalanceToSalary\"] = X[\"Balance\"] / (X[\"EstimatedSalary\"] + 1)\n        # Feature: Es cliente nuevo\n        if \"Tenure\" in X.columns:\n            X[\"IsNewCustomer\"] = (X[\"Tenure\"] &lt; 2).astype(int)\n        return X\nEOF\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>CarVision-Market-Intelligence/src/carvision/features.py</code></p>"},{"location":"#semana-10-training-profesional-cross-validation","title":"\ud83d\udcd6 Semana 10: Training Profesional + Cross-Validation","text":"<p>\ud83c\udfaf Objetivo: Entrenar modelos con validaci\u00f3n robusta.</p>"},{"location":"#para-principiantes-analogias","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Cross-Validation Varios ex\u00e1menes de pr\u00e1ctica, no solo uno Estimaci\u00f3n m\u00e1s confiable Stratified K-Fold Cada examen tiene proporci\u00f3n similar Clases desbalanceadas bien representadas Trainer class Entrenador personal con programa estructurado C\u00f3digo organizado, m\u00e9tricas consistentes"},{"location":"#practica-empirica_1","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; src/bankchurn/trainer.py &lt;&lt; 'EOF'\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom dataclasses import dataclass\nimport numpy as np\n\n@dataclass\nclass TrainingResult:\n    cv_scores: list[float]\n    mean_score: float\n    std_score: float\n\nclass ChurnTrainer:\n    def __init__(self, pipeline, n_splits: int = 5):\n        self.pipeline = pipeline\n        self.cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    def train_with_cv(self, X, y, scoring: str = \"f1\") -&gt; TrainingResult:\n        scores = cross_val_score(self.pipeline, X, y, cv=self.cv, scoring=scoring)\n        self.pipeline.fit(X, y)\n        return TrainingResult(\n            cv_scores=scores.tolist(),\n            mean_score=float(np.mean(scores)),\n            std_score=float(np.std(scores))\n        )\nEOF\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>BankChurn-Predictor/src/bankchurn/trainer.py</code></p>"},{"location":"#semana-11-mlflow-tracking-ui","title":"\ud83d\udcd6 Semana 11: MLflow Tracking + UI","text":"<p>\ud83c\udfaf Objetivo: Registrar experimentos de forma sistem\u00e1tica.</p>"},{"location":"#para-principiantes-analogias_1","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa MLflow Cuaderno de laboratorio digital Nunca pierdes un experimento Run Experimento individual Cada entrenamiento queda registrado Artifact Archivos guardados (modelo, gr\u00e1ficas) Reproducir resultados exactos"},{"location":"#practica-empirica_2","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code># 1. Instalar MLflow\npip install mlflow\n\n# 2. Script de entrenamiento con tracking\ncat &gt; src/bankchurn/train_mlflow.py &lt;&lt; 'EOF'\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\n\nmlflow.set_experiment(\"bankchurn-classifier\")\n\nX, y = make_classification(n_samples=1000, n_features=20, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nwith mlflow.start_run(run_name=\"rf-baseline\"):\n    params = {\"n_estimators\": 100, \"max_depth\": 10}\n    mlflow.log_params(params)\n\n    model = RandomForestClassifier(**params, random_state=42)\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n    mlflow.log_metrics({\"accuracy\": accuracy_score(y_test, y_pred), \"f1\": f1_score(y_test, y_pred)})\n    mlflow.sklearn.log_model(model, \"model\")\nEOF\n\n# 3. Ejecutar e iniciar UI\npython src/bankchurn/train_mlflow.py\nmlflow ui --port 5000\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>mlruns/</code> en cada proyecto</p>"},{"location":"#semana-12-mlflow-model-registry-signatures","title":"\ud83d\udcd6 Semana 12: MLflow Model Registry + Signatures","text":"<p>\ud83c\udfaf Objetivo: Gestionar modelos en producci\u00f3n con versionado.</p>"},{"location":"#para-principiantes-analogias_2","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Model Registry Cat\u00e1logo de productos con versiones Sabes qu\u00e9 modelo est\u00e1 en producci\u00f3n Stages Estados: Staging \u2192 Production \u2192 Archived Control de qu\u00e9 modelo usan usuarios Signature Contrato de entrada/salida API sabe qu\u00e9 esperar del modelo"},{"location":"#practica-empirica_3","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; src/bankchurn/train_registry.py &lt;&lt; 'EOF'\nimport mlflow\nfrom mlflow.models import infer_signature\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\n\nmlflow.set_experiment(\"bankchurn-classifier\")\n\n# Datos con nombres\nfeature_names = [\"age\", \"balance\", \"tenure\", \"products\", \"salary\"]\nX = pd.DataFrame([[30, 1000, 2, 1, 50000]], columns=feature_names)\n\nwith mlflow.start_run():\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X, [0])\n\n    signature = infer_signature(X, model.predict(X))\n    mlflow.sklearn.log_model(\n        model, \"model\",\n        signature=signature,\n        registered_model_name=\"BankChurnClassifier\"\n    )\nEOF\n\npython src/bankchurn/train_registry.py\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>models:/BankChurn/Production</code></p>"},{"location":"#mes-4-testing-cicd-semanas-13-16","title":"\ud83d\uddd3\ufe0f MES 4: TESTING &amp; CI/CD (Semanas 13-16)","text":"<p>Objetivo: Implementar testing profesional y automatizaci\u00f3n.</p>"},{"location":"#semana-13-testing-unitario-para-ml","title":"\ud83d\udcd6 Semana 13: Testing Unitario para ML","text":"<p>\ud83c\udfaf Objetivo: Escribir tests que validen componentes ML.</p>"},{"location":"#para-principiantes-analogias_3","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Unit Test Probar cada pieza antes de ensamblar Detectas errores temprano pytest Robot que ejecuta todas las pruebas Automatizaci\u00f3n, reportes claros Fixture Ingredientes pre-preparados para tests Reutilizas setup, tests m\u00e1s limpios"},{"location":"#practica-empirica_4","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code># Crear estructura de tests\nmkdir -p tests/unit\n\ncat &gt; tests/conftest.py &lt;&lt; 'EOF'\nimport pytest\nimport pandas as pd\nimport numpy as np\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Datos de ejemplo para tests.\"\"\"\n    return pd.DataFrame({\n        \"Balance\": [1000, 2000, 0, 5000],\n        \"Tenure\": [1, 5, 3, 10],\n        \"Age\": [30, 45, 25, 60]\n    })\n\n@pytest.fixture\ndef sample_labels():\n    return np.array([0, 1, 0, 1])\nEOF\n\ncat &gt; tests/unit/test_pipeline.py &lt;&lt; 'EOF'\nfrom src.bankchurn.pipeline import create_pipeline\n\ndef test_pipeline_creation():\n    pipe = create_pipeline()\n    assert len(pipe.steps) == 3\n\ndef test_pipeline_fit_predict(sample_data, sample_labels):\n    pipe = create_pipeline()\n    pipe.fit(sample_data.values, sample_labels)\n    predictions = pipe.predict(sample_data.values)\n    assert len(predictions) == len(sample_labels)\nEOF\n\n# Ejecutar tests\npytest tests/ -v\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>tests/unit/</code></p>"},{"location":"#semana-14-testing-de-integracion-fixtures","title":"\ud83d\udcd6 Semana 14: Testing de Integraci\u00f3n + Fixtures","text":"<p>\ud83c\udfaf Objetivo: Probar componentes trabajando juntos.</p>"},{"location":"#para-principiantes-analogias_4","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Integration Test Probar el carro completo, no solo el motor Detectas problemas de conexi\u00f3n Mocking Usar dobles de prueba (actores) Tests r\u00e1pidos, sin dependencias externas conftest.py Recetario compartido de fixtures Un lugar para todos los fixtures"},{"location":"#practica-empirica_5","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; tests/integration/test_training_flow.py &lt;&lt; 'EOF'\nimport pytest\nfrom pathlib import Path\nimport tempfile\n\ndef test_full_training_flow(sample_data, sample_labels):\n    \"\"\"Test del flujo completo de entrenamiento.\"\"\"\n    from src.bankchurn.pipeline import create_pipeline\n    from src.bankchurn.trainer import ChurnTrainer\n\n    pipe = create_pipeline()\n    trainer = ChurnTrainer(pipe, n_splits=2)\n\n    result = trainer.train_with_cv(sample_data.values, sample_labels)\n\n    assert result.mean_score &gt;= 0.0\n    assert result.mean_score &lt;= 1.0\n    assert len(result.cv_scores) == 2\n\ndef test_model_persistence(sample_data, sample_labels):\n    \"\"\"Test de guardado y carga de modelo.\"\"\"\n    import joblib\n    from src.bankchurn.pipeline import create_pipeline\n\n    pipe = create_pipeline()\n    pipe.fit(sample_data.values, sample_labels)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        model_path = Path(tmpdir) / \"model.pkl\"\n        joblib.dump(pipe, model_path)\n\n        loaded = joblib.load(model_path)\n        assert loaded.predict(sample_data.values).shape == sample_labels.shape\nEOF\n\npytest tests/integration/ -v\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>tests/integration/</code></p>"},{"location":"#semana-15-github-actions-matrix-testing","title":"\ud83d\udcd6 Semana 15: GitHub Actions + Matrix Testing","text":"<p>\ud83c\udfaf Objetivo: Automatizar tests en cada push.</p>"},{"location":"#para-principiantes-analogias_5","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa GitHub Actions Robot que trabaja por ti 24/7 Tests autom\u00e1ticos en cada cambio Workflow Instrucciones para el robot Define qu\u00e9 hacer y cu\u00e1ndo Matrix Probar en m\u00faltiples versiones Compatibilidad garantizada"},{"location":"#practica-empirica_6","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>mkdir -p .github/workflows\n\ncat &gt; .github/workflows/ci.yml &lt;&lt; 'EOF'\nname: CI Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [\"3.10\", \"3.11\", \"3.12\"]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: |\n          pip install -e \".[dev]\"\n\n      - name: Run linting\n        run: |\n          ruff check src/ tests/\n\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ -v --cov=src --cov-report=xml --cov-fail-under=80\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\nEOF\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>.github/workflows/ci.yml</code></p>"},{"location":"#semana-16-coverage-gates-security-scanning","title":"\ud83d\udcd6 Semana 16: Coverage Gates + Security Scanning","text":"<p>\ud83c\udfaf Objetivo: Garantizar calidad y seguridad autom\u00e1ticamente.</p>"},{"location":"#para-principiantes-analogias_6","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Coverage Gate M\u00ednimo de cobertura para aprobar Garantiza tests suficientes gitleaks Detector de secretos filtrados Evita exponer passwords/API keys Dependabot Robot que actualiza dependencias Parches de seguridad autom\u00e1ticos"},{"location":"#practica-empirica_7","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code># A\u00f1adir security scanning al workflow\ncat &gt;&gt; .github/workflows/ci.yml &lt;&lt; 'EOF'\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run gitleaks\n        uses: gitleaks/gitleaks-action@v2\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Check dependencies\n        run: |\n          pip install safety\n          safety check\nEOF\n\n# Crear configuraci\u00f3n de gitleaks\ncat &gt; .gitleaks.toml &lt;&lt; 'EOF'\n[allowlist]\ndescription = \"Allowlist for secrets\"\npaths = [\n    '''tests/.*''',\n    '''docs/.*''',\n]\nEOF\n\n# Verificar coverage localmente\npytest --cov=src --cov-fail-under=80\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>.github/workflows/security.yml</code></p>"},{"location":"#mes-5-deployment-semanas-17-20","title":"\ud83d\uddd3\ufe0f MES 5: DEPLOYMENT (Semanas 17-20)","text":"<p>Objetivo: Desplegar modelos como APIs profesionales.</p>"},{"location":"#semana-17-docker-fundamentos-multi-stage","title":"\ud83d\udcd6 Semana 17: Docker Fundamentos + Multi-stage","text":"<p>\ud83c\udfaf Objetivo: Containerizar aplicaciones ML.</p>"},{"location":"#para-principiantes-analogias_7","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Docker Caja de mudanza que incluye todo Funciona igual en cualquier m\u00e1quina Image Foto/snapshot de tu aplicaci\u00f3n Versi\u00f3n inmutable para desplegar Multi-stage Cocinar y servir en platos diferentes Imagen final peque\u00f1a y segura"},{"location":"#practica-empirica_8","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; Dockerfile &lt;&lt; 'EOF'\n# Stage 1: Builder\nFROM python:3.11-slim as builder\nWORKDIR /app\nCOPY pyproject.toml .\nRUN pip install build &amp;&amp; python -m build --wheel\n\n# Stage 2: Runtime\nFROM python:3.11-slim as runtime\nWORKDIR /app\n\n# Crear usuario no-root\nRUN useradd --create-home appuser\nUSER appuser\n\n# Instalar dependencias\nCOPY --from=builder /app/dist/*.whl .\nRUN pip install --user *.whl\n\n# Copiar c\u00f3digo\nCOPY --chown=appuser:appuser app/ ./app/\nCOPY --chown=appuser:appuser models/ ./models/\n\nEXPOSE 8000\nCMD [\"python\", \"-m\", \"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\nEOF\n\n# Construir y ejecutar\ndocker build -t bankchurn:latest .\ndocker run -p 8000:8000 bankchurn:latest\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>Dockerfile</code></p>"},{"location":"#semana-18-fastapi-para-ml-schemas-pydantic","title":"\ud83d\udcd6 Semana 18: FastAPI para ML + Schemas Pydantic","text":"<p>\ud83c\udfaf Objetivo: Crear APIs de predicci\u00f3n robustas.</p>"},{"location":"#para-principiantes-analogias_8","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa FastAPI Recepcionista que valida y dirige peticiones R\u00e1pido, documentaci\u00f3n autom\u00e1tica Schema Formulario con campos requeridos Valida entrada/salida autom\u00e1ticamente /health Chequeo m\u00e9dico de la API Saber si el servicio est\u00e1 vivo"},{"location":"#practica-empirica_9","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; app/fastapi_app.py &lt;&lt; 'EOF'\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\nimport joblib\nfrom pathlib import Path\n\napp = FastAPI(title=\"BankChurn API\", version=\"1.0.0\")\n\n# Schemas\nclass PredictionRequest(BaseModel):\n    age: int = Field(..., ge=18, le=100)\n    balance: float = Field(..., ge=0)\n    tenure: int = Field(..., ge=0)\n    num_products: int = Field(..., ge=1, le=4)\n\nclass PredictionResponse(BaseModel):\n    prediction: int\n    probability: float\n    model_version: str\n\n# Cargar modelo\nMODEL_PATH = Path(\"models/model.pkl\")\nmodel = joblib.load(MODEL_PATH) if MODEL_PATH.exists() else None\n\n@app.get(\"/health\")\ndef health_check():\n    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n\n@app.post(\"/predict\", response_model=PredictionResponse)\ndef predict(request: PredictionRequest):\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Model not loaded\")\n\n    features = [[request.age, request.balance, request.tenure, request.num_products]]\n    prediction = int(model.predict(features)[0])\n    probability = float(model.predict_proba(features)[0][prediction])\n\n    return PredictionResponse(\n        prediction=prediction,\n        probability=probability,\n        model_version=\"1.0.0\"\n    )\nEOF\n\n# Ejecutar\npip install fastapi uvicorn\nuvicorn app.fastapi_app:app --reload --port 8000\n\n# Probar\ncurl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"age\": 35, \"balance\": 50000, \"tenure\": 5, \"num_products\": 2}'\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>app/fastapi_app.py</code></p>"},{"location":"#semana-19-streamlit-dashboards-caching","title":"\ud83d\udcd6 Semana 19: Streamlit Dashboards + Caching","text":"<p>\ud83c\udfaf Objetivo: Crear dashboards interactivos.</p>"},{"location":"#para-principiantes-analogias_9","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Streamlit PowerPoint interactivo con Python Demos r\u00e1pidos sin JavaScript st.cache Memoria para no repetir c\u00e1lculos App m\u00e1s r\u00e1pida Tabs Pesta\u00f1as de navegador Organiza contenido"},{"location":"#practica-empirica_10","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; app/streamlit_app.py &lt;&lt; 'EOF'\nimport streamlit as st\nimport requests\nimport pandas as pd\n\nst.set_page_config(page_title=\"BankChurn Predictor\", page_icon=\"\ud83c\udfe6\")\n\nst.title(\"\ud83c\udfe6 BankChurn Predictor\")\n\n# Tabs\ntab1, tab2 = st.tabs([\"Predicci\u00f3n\", \"Informaci\u00f3n\"])\n\nwith tab1:\n    st.header(\"Predecir Churn de Cliente\")\n\n    col1, col2 = st.columns(2)\n    with col1:\n        age = st.slider(\"Edad\", 18, 100, 35)\n        balance = st.number_input(\"Balance\", 0, 500000, 50000)\n    with col2:\n        tenure = st.slider(\"A\u00f1os como cliente\", 0, 20, 5)\n        num_products = st.selectbox(\"Productos\", [1, 2, 3, 4])\n\n    if st.button(\"Predecir\", type=\"primary\"):\n        try:\n            response = requests.post(\n                \"http://localhost:8000/predict\",\n                json={\"age\": age, \"balance\": balance, \"tenure\": tenure, \"num_products\": num_products}\n            )\n            result = response.json()\n\n            if result[\"prediction\"] == 1:\n                st.error(f\"\u26a0\ufe0f Alto riesgo de churn ({result['probability']:.1%})\")\n            else:\n                st.success(f\"\u2705 Cliente estable ({1-result['probability']:.1%})\")\n        except:\n            st.error(\"Error conectando con la API\")\n\nwith tab2:\n    st.header(\"Sobre el Modelo\")\n    st.markdown(\"\"\"\n    - **Algoritmo**: Random Forest\n    - **Accuracy**: 85%\n    - **Features**: Age, Balance, Tenure, Products\n    \"\"\")\nEOF\n\n# Ejecutar\npip install streamlit\nstreamlit run app/streamlit_app.py\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>app/streamlit_app.py</code></p>"},{"location":"#semana-20-observabilidad-logging-estructurado","title":"\ud83d\udcd6 Semana 20: Observabilidad + Logging Estructurado","text":"<p>\ud83c\udfaf Objetivo: Monitorear aplicaciones en producci\u00f3n.</p>"},{"location":"#para-principiantes-analogias_10","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Logging estructurado Bit\u00e1cora con formato fijo F\u00e1cil de buscar y analizar Prometheus Term\u00f3metro de la aplicaci\u00f3n M\u00e9tricas en tiempo real Drift detection Detector de cambios en datos Modelo sigue siendo v\u00e1lido"},{"location":"#practica-empirica_11","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>pip install loguru prometheus-client\n\ncat &gt; src/bankchurn/logging.py &lt;&lt; 'EOF'\nfrom loguru import logger\nimport sys\n\ndef setup_logging(json_format: bool = True):\n    \"\"\"Configura logging estructurado.\"\"\"\n    logger.remove()\n\n    if json_format:\n        logger.add(\n            sys.stdout,\n            format=\"{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}\",\n            serialize=True  # JSON format\n        )\n    else:\n        logger.add(sys.stdout, colorize=True)\n\n    return logger\nEOF\n\ncat &gt; app/metrics.py &lt;&lt; 'EOF'\nfrom prometheus_client import Counter, Histogram, generate_latest\nfrom fastapi import Response\n\n# M\u00e9tricas\nPREDICTIONS = Counter(\"predictions_total\", \"Total predictions\", [\"result\"])\nLATENCY = Histogram(\"prediction_latency_seconds\", \"Prediction latency\")\n\ndef get_metrics():\n    return Response(generate_latest(), media_type=\"text/plain\")\nEOF\n\n# A\u00f1adir a FastAPI\n# from app.metrics import PREDICTIONS, LATENCY, get_metrics\n# app.get(\"/metrics\")(get_metrics)\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>src/*/logging.py</code></p>"},{"location":"#mes-6-produccion-maestria-semanas-21-24","title":"\ud83d\uddd3\ufe0f MES 6: PRODUCCI\u00d3N &amp; MAESTR\u00cdA (Semanas 21-24)","text":"<p>Objetivo: Completar el portafolio y preparar entrevistas.</p>"},{"location":"#semana-21-estrategias-de-despliegue-cloud","title":"\ud83d\udcd6 Semana 21: Estrategias de Despliegue + Cloud","text":"<p>\ud83c\udfaf Objetivo: Entender opciones de deployment.</p>"},{"location":"#para-principiantes-analogias_11","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Blue-Green Cambiar de carril sin frenar Zero downtime en updates Canary Probar comida antes de servir Detectar problemas con pocos usuarios Serverless Taxi vs auto propio Pagas solo lo que usas"},{"location":"#practica-empirica_12","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code># docker-compose para desarrollo local\ncat &gt; docker-compose.yml &lt;&lt; 'EOF'\nversion: \"3.8\"\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - MODEL_PATH=/app/models/model.pkl\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  streamlit:\n    build:\n      context: .\n      dockerfile: Dockerfile.streamlit\n    ports:\n      - \"8501:8501\"\n    depends_on:\n      - api\nEOF\n\ndocker-compose up -d\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>docker-compose.yml</code>, <code>k8s/</code></p>"},{"location":"#semana-22-infraestructura-como-codigo-terraform","title":"\ud83d\udcd6 Semana 22: Infraestructura como C\u00f3digo (Terraform)","text":"<p>\ud83c\udfaf Objetivo: Definir infraestructura de forma reproducible.</p>"},{"location":"#para-principiantes-analogias_12","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Terraform Plano de construcci\u00f3n ejecutable Infraestructura versionada State Inventario de lo construido Sabe qu\u00e9 existe vs qu\u00e9 falta Plan Presupuesto antes de construir Ves cambios antes de aplicar"},{"location":"#practica-empirica_13","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>mkdir -p infra/terraform\n\ncat &gt; infra/terraform/main.tf &lt;&lt; 'EOF'\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\nvariable \"aws_region\" {\n  default = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  default = \"bankchurn\"\n}\n\n# ECR Repository\nresource \"aws_ecr_repository\" \"app\" {\n  name = \"${var.project_name}-api\"\n\n  image_scanning_configuration {\n    scan_on_push = true\n  }\n}\n\noutput \"ecr_repository_url\" {\n  value = aws_ecr_repository.app.repository_url\n}\nEOF\n\n# Comandos Terraform\n# terraform init\n# terraform plan\n# terraform apply\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>infra/terraform/</code></p>"},{"location":"#semana-23-documentacion-profesional-model-cards","title":"\ud83d\udcd6 Semana 23: Documentaci\u00f3n Profesional + Model Cards","text":"<p>\ud83c\udfaf Objetivo: Documentar modelos para producci\u00f3n.</p>"},{"location":"#para-principiantes-analogias_13","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa Model Card Ficha t\u00e9cnica de un electrodom\u00e9stico Usuarios saben limitaciones Dataset Card Etiqueta nutricional de datos Transparencia sobre fuente MkDocs Wiki profesional autom\u00e1tica Documentaci\u00f3n navegable"},{"location":"#practica-empirica_14","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code>cat &gt; docs/MODEL_CARD.md &lt;&lt; 'EOF'\n# Model Card: BankChurn Classifier\n\n## Model Details\n- **Developer**: Tu Nombre\n- **Model Date**: Diciembre 2024\n- **Model Version**: 1.0.0\n- **Model Type**: Random Forest Classifier\n\n## Intended Use\n- **Primary Use**: Predecir probabilidad de abandono de clientes bancarios\n- **Users**: Equipo de retenci\u00f3n de clientes\n- **Out-of-scope**: No usar para decisiones de cr\u00e9dito\n\n## Training Data\n- **Source**: Dataset sint\u00e9tico de clientes bancarios\n- **Size**: 10,000 registros\n- **Features**: Age, Balance, Tenure, NumOfProducts\n\n## Evaluation\n| Metric | Value |\n|--------|-------|\n| Accuracy | 0.85 |\n| F1-Score | 0.78 |\n| AUC-ROC | 0.82 |\n\n## Limitations\n- Entrenado solo con datos de un banco\n- No considera factores externos (econom\u00eda, competencia)\n\n## Ethical Considerations\n- Evitar discriminaci\u00f3n por edad\n- Decisiones finales deben ser revisadas por humanos\nEOF\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: <code>docs/model_card.md</code></p>"},{"location":"#semana-24-proyecto-integrador-preparacion-entrevistas","title":"\ud83d\udcd6 Semana 24: Proyecto Integrador + Preparaci\u00f3n Entrevistas","text":"<p>\ud83c\udfaf Objetivo: Validar portafolio completo y preparar presentaci\u00f3n.</p>"},{"location":"#para-principiantes-analogias_14","title":"\ud83d\udd30 Para Principiantes: Analog\u00edas","text":"Concepto Analog\u00eda Por qu\u00e9 importa R\u00fabrica Lista de requisitos para aprobar Sabes si est\u00e1s listo Speech Elevator pitch de tu trabajo Impresiona en 5 minutos Live Demo Mostrar el producto funcionando Credibilidad instant\u00e1nea"},{"location":"#practica-empirica_15","title":"\ud83d\udcbb Pr\u00e1ctica Emp\u00edrica","text":"<pre><code># Checklist final de validaci\u00f3n\ncat &gt; CHECKLIST_FINAL.md &lt;&lt; 'EOF'\n# Checklist de Portafolio Completo\n\n## BankChurn-Predictor\n- [ ] `make test` pasa con 80%+ coverage\n- [ ] `make serve` inicia API en localhost:8000\n- [ ] `curl localhost:8000/health` retorna OK\n- [ ] Dockerfile construye sin errores\n- [ ] CI/CD pasa en GitHub Actions\n\n## CarVision-Market-Intelligence  \n- [ ] Pipeline de features funciona\n- [ ] Dashboard Streamlit funciona\n- [ ] Tests pasan\n\n## TelecomAI-Customer-Intelligence\n- [ ] Multiclass classification funciona\n- [ ] MLflow tracking configurado\n- [ ] Documentaci\u00f3n completa\n\n## Documentaci\u00f3n\n- [ ] Model Cards para cada proyecto\n- [ ] README profesional en cada repo\n- [ ] ADRs documentando decisiones\n\n## Preparaci\u00f3n Entrevistas\n- [ ] Speech de 5-7 min practicado\n- [ ] Demo de 3 min funciona\n- [ ] Preguntas t\u00e9cnicas revisadas\nEOF\n</code></pre> <p>\ud83d\udce6 Ubicaci\u00f3n en Portafolio: Portafolio completo</p>"},{"location":"#examenes-de-hito-6-milestones","title":"\ud83d\udccb Ex\u00e1menes de Hito (6 Milestones)","text":"<p>Cada mes incluye un examen pr\u00e1ctico que valida tu progreso. Debes completar cada hito antes de avanzar al siguiente mes.</p>"},{"location":"#hito-1-setup-completo-fin-mes-1","title":"\ud83c\udfc6 HITO 1: Setup Completo (Fin Mes 1)","text":"<p>Objetivo: Demostrar que tienes un entorno de desarrollo profesional funcionando.</p>"},{"location":"#criterios-de-evaluacion","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar Entorno virtual funcionando 10 <code>python --version</code> muestra 3.10+ pyproject.toml v\u00e1lido 15 <code>pip install -e \".[dev]\"</code> funciona Pre-commit configurado 15 <code>pre-commit run --all-files</code> pasa Estructura src/ correcta 10 Existe <code>src/bankchurn/__init__.py</code> Makefile con comandos b\u00e1sicos 10 <code>make lint</code> funciona Git con commits convencionales 10 <code>git log --oneline</code> muestra formato correcto C\u00f3digo tipado con mypy 15 <code>mypy src/ --strict</code> sin errores README.md profesional 15 Incluye instalaci\u00f3n, uso, estructura <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Ejecutar todos los checks del Hito 1\nmake lint                          # Linting pasa\nmypy src/ --strict                 # Sin errores de tipos\npre-commit run --all-files         # Hooks pasan\npip install -e \".[dev]\"            # Instalaci\u00f3n funciona\n</code></pre>"},{"location":"#hito-2-pipeline-reproducible-fin-mes-2","title":"\ud83c\udfc6 HITO 2: Pipeline Reproducible (Fin Mes 2)","text":"<p>Objetivo: Demostrar pipelines de datos y ML reproducibles.</p>"},{"location":"#criterios-de-evaluacion_1","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar DVC inicializado 15 Existe <code>.dvc/config</code> Datos versionados 15 Existe <code>data/*.dvc</code> Pipeline DVC funcional 20 <code>dvc repro</code> ejecuta sin errores sklearn Pipeline creado 20 <code>create_pipeline()</code> retorna Pipeline Custom Transformer 15 Clase hereda de BaseEstimator Sin data leakage 15 fit solo en train, transform en test <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion_1","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Ejecutar todos los checks del Hito 2\ndvc status                         # Sin cambios pendientes\ndvc repro                          # Pipeline ejecuta completamente\npython -c \"from src.bankchurn.pipeline import create_pipeline; print(create_pipeline())\"\ndvc dag                            # Muestra DAG del pipeline\n</code></pre>"},{"location":"#hito-3-experimento-completo-fin-mes-3","title":"\ud83c\udfc6 HITO 3: Experimento Completo (Fin Mes 3)","text":"<p>Objetivo: Demostrar tracking de experimentos y model registry.</p>"},{"location":"#criterios-de-evaluacion_2","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar MLflow experiment creado 15 <code>mlflow experiments list</code> muestra experimento M\u00e9tricas logueadas 20 accuracy, f1, precision en MLflow UI Modelo registrado 20 Modelo en Model Registry Signature definida 15 Modelo tiene input/output signature Cross-validation implementada 15 Trainer usa StratifiedKFold FeatureEngineer funcional 15 Crea features sin leakage <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion_2","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Ejecutar todos los checks del Hito 3\nmlflow experiments list            # Experimento existe\nmlflow runs list --experiment-id 1 # Runs existen\npython src/bankchurn/train_mlflow.py  # Entrenamiento completo\nmlflow ui                          # UI muestra m\u00e9tricas\n</code></pre>"},{"location":"#hito-4-cicd-completo-fin-mes-4","title":"\ud83c\udfc6 HITO 4: CI/CD Completo (Fin Mes 4)","text":"<p>Objetivo: Demostrar testing y automatizaci\u00f3n profesional.</p>"},{"location":"#criterios-de-evaluacion_3","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar Tests unitarios 20 <code>pytest tests/unit/</code> pasa Tests integraci\u00f3n 15 <code>pytest tests/integration/</code> pasa Coverage \u2265 80% 20 <code>pytest --cov --cov-fail-under=80</code> GitHub Actions workflow 20 <code>.github/workflows/ci.yml</code> existe Matrix testing (3.10, 3.11, 3.12) 10 CI corre en m\u00faltiples versiones Security scanning 15 gitleaks configurado <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion_3","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Ejecutar todos los checks del Hito 4\npytest tests/ -v --cov=src --cov-report=term-missing --cov-fail-under=80\ncat .github/workflows/ci.yml       # Workflow existe\npre-commit run gitleaks --all-files  # Sin secretos expuestos\n</code></pre>"},{"location":"#hito-5-api-desplegada-fin-mes-5","title":"\ud83c\udfc6 HITO 5: API Desplegada (Fin Mes 5)","text":"<p>Objetivo: Demostrar deployment de modelo como servicio.</p>"},{"location":"#criterios-de-evaluacion_4","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar Dockerfile multi-stage 15 Imagen &lt; 500MB FastAPI /predict funcional 20 curl retorna predicci\u00f3n FastAPI /health funcional 10 curl retorna status Schemas Pydantic validados 15 Request inv\u00e1lido retorna 422 Streamlit dashboard 15 streamlit run funciona Logging estructurado 10 Logs en formato JSON M\u00e9tricas Prometheus 15 /metrics endpoint existe <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion_4","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Ejecutar todos los checks del Hito 5\ndocker build -t bankchurn:latest .\ndocker run -d -p 8000:8000 bankchurn:latest\nsleep 5\ncurl http://localhost:8000/health\ncurl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"age\": 35, \"balance\": 50000, \"tenure\": 5, \"num_products\": 2}'\ncurl http://localhost:8000/metrics\n</code></pre>"},{"location":"#hito-6-portafolio-completo-fin-mes-6","title":"\ud83c\udfc6 HITO 6: Portafolio Completo (Fin Mes 6)","text":"<p>Objetivo: Demostrar portafolio production-ready listo para entrevistas.</p>"},{"location":"#criterios-de-evaluacion_5","title":"Criterios de Evaluaci\u00f3n","text":"Criterio Puntos C\u00f3mo Validar 3 proyectos funcionando 20 make test pasa en los 3 Model Cards completos 15 docs/MODEL_CARD.md en cada proyecto CI/CD pasando en GitHub 15 Badge verde en README docker-compose funcional 10 <code>docker-compose up</code> levanta todo IaC documentado 10 infra/terraform/ con README Speech de 5-7 min preparado 15 Grabaci\u00f3n de pr\u00e1ctica Demo de 3 min funciona 15 Video o live demo <p>Puntuaci\u00f3n m\u00ednima: 70/100</p>"},{"location":"#comandos-de-validacion_5","title":"Comandos de Validaci\u00f3n","text":"<pre><code># Validaci\u00f3n final completa\nfor project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n  echo \"=== Testing $project ===\"\n  cd $project &amp;&amp; make test &amp;&amp; cd ..\ndone\n\n# Verificar documentaci\u00f3n\nls */docs/MODEL_CARD.md\n\n# Levantar stack completo\ndocker-compose up -d\ncurl http://localhost:8000/health\ncurl http://localhost:8501\n</code></pre>"},{"location":"#guia-de-troubleshooting","title":"\ud83d\udd27 Gu\u00eda de Troubleshooting","text":"<p>Errores comunes al configurar el entorno local por sistema operativo.</p>"},{"location":"#windows","title":"\ud83e\ude9f Windows","text":""},{"location":"#error-pip-install-falla-con-permisos","title":"Error: <code>pip install</code> falla con permisos","text":"<pre><code># S\u00edntoma\nERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied\n\n# Soluci\u00f3n 1: Usar --user\npip install --user -r requirements.txt\n\n# Soluci\u00f3n 2: Ejecutar PowerShell como Administrador\n# Click derecho &gt; \"Ejecutar como administrador\"\n\n# Soluci\u00f3n 3: Usar entorno virtual (recomendado)\npython -m venv .venv\n.venv\\Scripts\\activate\npip install -r requirements.txt\n</code></pre>"},{"location":"#error-python-no-reconocido","title":"Error: <code>python</code> no reconocido","text":"<pre><code># S\u00edntoma\n'python' is not recognized as an internal or external command\n\n# Soluci\u00f3n: A\u00f1adir Python al PATH\n# 1. Buscar \"Variables de entorno\" en Windows\n# 2. Editar PATH del usuario\n# 3. A\u00f1adir: C:\\Users\\TU_USUARIO\\AppData\\Local\\Programs\\Python\\Python311\\\n\n# O reinstalar Python marcando \"Add to PATH\"\n</code></pre>"},{"location":"#error-make-no-encontrado","title":"Error: <code>make</code> no encontrado","text":"<pre><code># S\u00edntoma\n'make' is not recognized\n\n# Soluci\u00f3n 1: Instalar chocolatey y make\nSet-ExecutionPolicy Bypass -Scope Process -Force\niex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))\nchoco install make\n\n# Soluci\u00f3n 2: Usar comandos directos sin make\npip install -e \".[dev]\"   # en vez de make install\npytest tests/ -v          # en vez de make test\n</code></pre>"},{"location":"#error-docker-desktop-no-inicia","title":"Error: Docker Desktop no inicia","text":"<pre><code># S\u00edntoma\nDocker Desktop - WSL 2 installation is incomplete\n\n# Soluci\u00f3n\n# 1. Abrir PowerShell como Admin\nwsl --install\n# 2. Reiniciar PC\n# 3. Abrir Docker Desktop\n</code></pre>"},{"location":"#linux-ubuntudebian","title":"\ud83d\udc27 Linux (Ubuntu/Debian)","text":""},{"location":"#error-python310-no-disponible","title":"Error: <code>python3.10</code> no disponible","text":"<pre><code># S\u00edntoma\nE: Unable to locate package python3.10\n\n# Soluci\u00f3n: A\u00f1adir deadsnakes PPA\nsudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt update\nsudo apt install python3.10 python3.10-venv python3.10-dev\n</code></pre>"},{"location":"#error-pip-no-encontrado","title":"Error: <code>pip</code> no encontrado","text":"<pre><code># S\u00edntoma\nCommand 'pip' not found\n\n# Soluci\u00f3n\nsudo apt install python3-pip\n# O usar pip3\npip3 install -r requirements.txt\n</code></pre>"},{"location":"#error-permisos-en-docker","title":"Error: Permisos en Docker","text":"<pre><code># S\u00edntoma\nGot permission denied while trying to connect to the Docker daemon socket\n\n# Soluci\u00f3n: A\u00f1adir usuario al grupo docker\nsudo usermod -aG docker $USER\nnewgrp docker\n# O cerrar sesi\u00f3n y volver a entrar\n</code></pre>"},{"location":"#error-libpq-dev-faltante-para-psycopg2","title":"Error: <code>libpq-dev</code> faltante (para psycopg2)","text":"<pre><code># S\u00edntoma\nError: pg_config executable not found\n\n# Soluci\u00f3n\nsudo apt install libpq-dev python3-dev\npip install psycopg2-binary  # versi\u00f3n sin compilar\n</code></pre>"},{"location":"#macos","title":"\ud83c\udf4e macOS","text":""},{"location":"#error-command-line-tools-faltantes","title":"Error: <code>Command Line Tools</code> faltantes","text":"<pre><code># S\u00edntoma\nxcrun: error: invalid active developer path\n\n# Soluci\u00f3n\nxcode-select --install\n</code></pre>"},{"location":"#error-conflicto-con-python-del-sistema","title":"Error: Conflicto con Python del sistema","text":"<pre><code># S\u00edntoma\nWARNING: pip is configured with locations that require TLS/SSL\n\n# Soluci\u00f3n: Usar pyenv\nbrew install pyenv\npyenv install 3.11.0\npyenv global 3.11.0\necho 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"#error-libomp-faltante-para-scikit-learn","title":"Error: <code>libomp</code> faltante (para scikit-learn)","text":"<pre><code># S\u00edntoma\nLibrary not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n\n# Soluci\u00f3n\nbrew install libomp\n</code></pre>"},{"location":"#error-docker-muy-lento-en-mac-m1m2","title":"Error: Docker muy lento en Mac M1/M2","text":"<pre><code># S\u00edntoma\nDocker builds extremadamente lentos\n\n# Soluci\u00f3n 1: Usar Rosetta\n# En Docker Desktop &gt; Settings &gt; General &gt; Use Rosetta\n\n# Soluci\u00f3n 2: Builds nativos ARM64\ndocker buildx build --platform linux/arm64 -t myapp .\n</code></pre>"},{"location":"#errores-comunes-de-dependencias","title":"\ud83d\udc0d Errores Comunes de Dependencias","text":""},{"location":"#error-conflicto-de-versiones-numpypandas","title":"Error: Conflicto de versiones numpy/pandas","text":"<pre><code># S\u00edntoma\nImportError: numpy.core.multiarray failed to import\n\n# Soluci\u00f3n: Reinstalar en orden\npip uninstall numpy pandas scikit-learn -y\npip install numpy==1.24.0\npip install pandas==2.0.0\npip install scikit-learn==1.3.0\n</code></pre>"},{"location":"#error-mlflow-no-conecta","title":"Error: MLflow no conecta","text":"<pre><code># S\u00edntoma\nConnectionRefusedError: [Errno 111] Connection refused\n\n# Soluci\u00f3n: Verificar que MLflow server est\u00e1 corriendo\nmlflow server --host 0.0.0.0 --port 5000 &amp;\n# O usar tracking local\nexport MLFLOW_TRACKING_URI=file:./mlruns\n</code></pre>"},{"location":"#error-dvc-remote-no-configurado","title":"Error: DVC remote no configurado","text":"<pre><code># S\u00edntoma\nERROR: failed to push data to remote - config file error\n\n# Soluci\u00f3n\ndvc remote add -d myremote /path/to/storage\ndvc remote modify myremote url s3://my-bucket/dvc\ndvc push\n</code></pre>"},{"location":"#error-pytest-no-encuentra-modulos","title":"Error: pytest no encuentra m\u00f3dulos","text":"<pre><code># S\u00edntoma\nModuleNotFoundError: No module named 'src'\n\n# Soluci\u00f3n: Instalar en modo editable\npip install -e \".[dev]\"\n\n# O a\u00f1adir al PYTHONPATH\nexport PYTHONPATH=\"${PYTHONPATH}:$(pwd)\"\n</code></pre>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":"<pre><code># 1. Clonar el portafolio\ngit clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git\ncd ML-MLOps-Portfolio\n\n# 2. Configurar entorno\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# .venv\\Scripts\\activate   # Windows\n\n# 3. Empezar con BankChurn (proyecto base)\ncd BankChurn-Predictor\npip install -e \".[dev]\"\n\n# 4. Verificar instalaci\u00f3n\nmake lint        # Verificar c\u00f3digo\nmake test        # Ejecutar tests\nmake train       # Entrenar modelo\nmake serve       # Iniciar API\n\n# 5. Probar API\ncurl http://localhost:8000/health\ncurl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"age\": 35, \"balance\": 50000, \"tenure\": 5, \"num_products\": 2}'\n</code></pre>"},{"location":"#estructura-de-carpetas","title":"\ud83d\udcc1 Estructura de Carpetas","text":"<pre><code>Guia_MLOps/\n\u251c\u2500\u2500 README.md                    # \ud83d\udc48 Este archivo (\u00edndice maestro)\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 00_INDICE.md            # \u00cdndice (ruta 24 semanas + ruta acelerada 8 semanas)\n\u2502   \u251c\u2500\u2500 01_PYTHON_MODERNO.md    # M\u00f3dulo: Python profesional\n\u2502   \u251c\u2500\u2500 02_DISENO_SISTEMAS.md   # M\u00f3dulo: Arquitectura ML\n\u2502   \u251c\u2500\u2500 03_ESTRUCTURA_PROYECTO.md\n\u2502   \u251c\u2500\u2500 04_ENTORNOS.md\n\u2502   \u251c\u2500\u2500 05_GIT_PROFESIONAL.md\n\u2502   \u251c\u2500\u2500 06_VERSIONADO_DATOS.md  # DVC\n\u2502   \u251c\u2500\u2500 07_SKLEARN_PIPELINES.md\n\u2502   \u251c\u2500\u2500 08_INGENIERIA_FEATURES.md\n\u2502   \u251c\u2500\u2500 09_TRAINING_PROFESIONAL.md\n\u2502   \u251c\u2500\u2500 10_EXPERIMENT_TRACKING.md  # MLflow\n\u2502   \u251c\u2500\u2500 11_TESTING_ML.md\n\u2502   \u251c\u2500\u2500 12_CI_CD.md             # GitHub Actions\n\u2502   \u251c\u2500\u2500 13_DOCKER.md\n\u2502   \u251c\u2500\u2500 14_FASTAPI.md\n\u2502   \u251c\u2500\u2500 15_STREAMLIT.md\n\u2502   \u251c\u2500\u2500 16_OBSERVABILIDAD.md\n\u2502   \u251c\u2500\u2500 17_DESPLIEGUE.md\n\u2502   \u251c\u2500\u2500 18_INFRAESTRUCTURA.md   # Terraform\n\u2502   \u251c\u2500\u2500 19_DOCUMENTACION.md     # Model Cards\n\u2502   \u251c\u2500\u2500 20_OBSERVABILIDAD_AVANZADA_DRIFT.md  # Drift detection\n\u2502   \u251c\u2500\u2500 21_CLOUD_FINOPS.md\n\u2502   \u251c\u2500\u2500 22_IAC_EMPRESARIAL.md  # Terraform avanzado\n\u2502   \u251c\u2500\u2500 23_PROYECTO_INTEGRADOR.md\n\u2502   \u251c\u2500\u2500 EJERCICIOS.md\n\u2502   \u251c\u2500\u2500 EJERCICIOS_SOLUCIONES.md\n\u2502   \u251c\u2500\u2500 SIMULACRO_ENTREVISTA_JUNIOR.md\n\u2502   \u251c\u2500\u2500 SIMULACRO_ENTREVISTA_MID.md\n\u2502   \u251c\u2500\u2500 SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md\n\u2502   \u251c\u2500\u2500 SIMULACRO_ENTREVISTA_SENIOR_PARTE2.md\n\u2502   \u2514\u2500\u2500 study_tools/            # Herramientas de estudio\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 Makefile\n\u2502   \u251c\u2500\u2500 ci.yml\n\u2502   \u251c\u2500\u2500 model_card_template.md\n\u2502   \u2514\u2500\u2500 dataset_card_template.md\n\u251c\u2500\u2500 notebooks/                  # Notebooks de pr\u00e1ctica\n\u2514\u2500\u2500 scripts/                    # Scripts auxiliares\n</code></pre>"},{"location":"#estructura-pedagogica-de-los-modulos","title":"\ufffd Estructura Pedag\u00f3gica de los M\u00f3dulos","text":"<p>Cada uno de los 23 m\u00f3dulos sigue una estructura pedag\u00f3gica consistente:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \ud83c\udfaf Objetivo del M\u00f3dulo                                         \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                           \u2502\n\u2502  Qu\u00e9 lograr\u00e1s al completar este m\u00f3dulo                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udccb Prerrequisitos + Protocolo E                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                   \u2502\n\u2502  Qu\u00e9 necesitas saber antes + c\u00f3mo estudiar                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83e\udde0 Mapa Mental de Conceptos                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                       \u2502\n\u2502  Diagrama visual de conceptos clave                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udcbb Ejercicio Puente                                            \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                               \u2502\n\u2502  Pr\u00e1ctica guiada antes de aplicar al portafolio                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio                                     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                        \u2502\n\u2502  Aplicaci\u00f3n real en BankChurn-Predictor                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u2705 Checkpoint de Conocimiento                                  \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                     \u2502\n\u2502  Preguntas + escenario de debugging                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>C\u00f3digo comentado: Todas las l\u00edneas de c\u00f3digo incluyen comentarios explicativos en espa\u00f1ol.</p>"},{"location":"#recursos-complementarios","title":"\ud83d\udcda Recursos Complementarios","text":""},{"location":"#planificacion-y-estructura","title":"\ud83d\udcd6 Planificaci\u00f3n y Estructura","text":"Recurso Descripci\u00f3n Link SYLLABUS.md Programa detallado macro-m\u00f3dulos docs/SYLLABUS.md MAPA_PORTAFOLIO_1TO1.md Mapa 1:1 (Portafolio \u2192 Gu\u00eda \u2192 Tareas/Evidencia) docs/MAPA_PORTAFOLIO_1TO1.md PLAN_ESTUDIOS.md Cronograma d\u00eda a d\u00eda (ruta acelerada 8 semanas) docs/PLAN_ESTUDIOS.md"},{"location":"#evaluacion-y-practica","title":"\ud83c\udfaf Evaluaci\u00f3n y Pr\u00e1ctica","text":"Recurso Descripci\u00f3n Link Quizzes Integrados 3 preguntas + 1 ejercicio por m\u00f3dulo (en cada m\u00f3dulo) Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" al final de cada m\u00f3dulo La Trampa Errores t\u00edpicos y c\u00f3mo evitarlos (en cada m\u00f3dulo) Secci\u00f3n \"\ud83e\udea4 La Trampa\" al final de cada m\u00f3dulo EJERCICIOS.md Problemas pr\u00e1cticos adicionales docs/EJERCICIOS.md"},{"location":"#preparacion-de-entrevistas","title":"\ud83c\udfa4 Preparaci\u00f3n de Entrevistas","text":"Recurso Descripci\u00f3n Link Defensa del Portafolio Preguntas de entrevista t\u00e9cnica sobre decisiones de arquitectura M\u00f3dulo 23 - Secci\u00f3n Defensa Speech Portafolio Gui\u00f3n 5-7 min para presentar tu trabajo docs/APENDICE_A_SPEECH_PORTAFOLIO.md Simulacro Junior 50 preguntas nivel entry docs/SIMULACRO_ENTREVISTA_JUNIOR.md Simulacro Mid 60 preguntas nivel mid docs/SIMULACRO_ENTREVISTA_MID.md Simulacro Senior 115 preguntas nivel senior docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md"},{"location":"#referencia","title":"\ud83d\udccb Referencia","text":"Recurso Descripci\u00f3n Link GLOSARIO.md 100+ t\u00e9rminos MLOps docs/apoyo/GLOSARIO.md Material de Apoyo Recursos externos, plantillas, checklists docs/apoyo/"},{"location":"#los-3-proyectos-del-portafolio","title":"\ud83c\udfaf Los 3 Proyectos del Portafolio","text":"Proyecto Problema Stack Principal Coverage BankChurn-Predictor Clasificaci\u00f3n binaria (churn) RandomForest, FastAPI, Docker 79%+ CarVision-Market-Intelligence Regresi\u00f3n (precios autos) FeatureEngineer, Streamlit 97% TelecomAI-Customer-Intelligence Clasificaci\u00f3n multiclase MLflow, LogisticRegression 97%   ## \ud83d\ude80 \u00a1Empieza Ahora!  **Semana 1** \u2192 [Python Moderno](docs/01_PYTHON_MODERNO.md)  ---  *Tiempo estimado: 24 semanas (6 meses) a ritmo moderado*  *\u00daltima actualizaci\u00f3n: Diciembre 2025*  **Autor**: Gu\u00eda MLOps Portfolio Edition"},{"location":"docs/","title":"\ud83d\udcda Gu\u00eda MLOps \u2014 Portfolio Edition","text":"<p>P\u00e1gina de entrada para MkDocs</p> <p>Este archivo es la p\u00e1gina de inicio para MkDocs. Para la documentaci\u00f3n completa, consulta el \u00edndice principal.</p>"},{"location":"docs/#documentacion-principal","title":"\ud83d\udcd6 Documentaci\u00f3n Principal","text":"<p>\u2192 Ir al \u00cdndice Principal (00_INDICE.md)</p>"},{"location":"docs/#estructura-de-la-guia","title":"\ud83d\udcc1 Estructura de la Gu\u00eda","text":""},{"location":"docs/#modulos-principales-01-23","title":"M\u00f3dulos Principales (01-23)","text":"Fase M\u00f3dulos Tema 1 01-06 Fundamentos de Ingenier\u00eda 2 07-10 ML Engineering 3 11-16 MLOps Core 4 17-18 Producci\u00f3n 5 19-23 Especializaci\u00f3n"},{"location":"docs/#material-complementario","title":"Material Complementario","text":"Recurso Descripci\u00f3n SYLLABUS.md Programa y macro-m\u00f3dulos MAPA_PORTAFOLIO_1TO1.md Mapa 1:1 Portafolio \u2192 Gu\u00eda PLAN_ESTUDIOS.md Cronograma d\u00eda a d\u00eda (ruta acelerada 8 semanas) templates/ Plantillas reutilizables"},{"location":"docs/#preparacion-de-entrevistas","title":"Preparaci\u00f3n de Entrevistas","text":"Recurso Descripci\u00f3n SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md 70 preguntas t\u00e9cnicas SIMULACRO_ENTREVISTA_SENIOR_PARTE2.md System design y liderazgo"},{"location":"docs/#quick-start-con-mkdocs","title":"\ud83d\ude80 Quick Start con MkDocs","text":"<pre><code>cd Guia_MLOps/docs\n# Recomendado (solo docs)\npip install -r requirements-docs.txt\n\n# Alternativa (stack completo ML/MLOps)\n# pip install -r requirements.txt\nmkdocs serve\n# Abrir http://localhost:8000\n</code></pre>"},{"location":"docs/#study-tools-protocolo-de-estudio","title":"\ud83e\udde0 Study Tools (Protocolo de Estudio)","text":"<p>\u2192 Abrir Study Tools</p>   **[\u2192 Empezar: \u00cdndice Principal](00_INDICE.md)**"},{"location":"docs/00_INDICE/","title":"\ud83d\udcda Gu\u00eda MLOps \u2014 Portfolio Edition","text":"<p>De Python B\u00e1sico a Senior/Staff en MLOps</p> <p>Ruta principal (recomendada): 24 semanas (6 meses).</p> <p>Ruta acelerada: 8 semanas.</p> <p>\ud83d\uddfa\ufe0f Mapa 1:1 Portafolio \u2192 Gu\u00eda: MAPA_PORTAFOLIO_1TO1.md</p>"},{"location":"docs/00_INDICE/#rutas-24-semanas-vs-8-semanas","title":"\u23f1\ufe0f Rutas (24 semanas vs 8 semanas)","text":"Ruta Dedicaci\u00f3n sugerida Para qui\u00e9n C\u00f3mo seguirla 24 semanas (principal) 8\u201310 h/sem Si quieres profundidad, margen para debugging real y pr\u00e1cticas de infra/ops Usa este \u00edndice (m\u00f3dulos 01\u201323) + el <code>README.md</code> del repo como roadmap 24 semanas. 8 semanas (acelerada) 15\u201320 h/sem Si ya tienes base fuerte o necesitas una versi\u00f3n r\u00e1pida para demo/entrevista Usa este \u00edndice + PLAN_ESTUDIOS.md como cronograma diario."},{"location":"docs/00_INDICE/#que-lograras","title":"\ud83c\udfaf \u00bfQu\u00e9 Lograr\u00e1s?","text":"<p>Al completar esta gu\u00eda ser\u00e1s capaz de:</p> Habilidad Nivel Evidencia en el Portafolio C\u00f3digo Python profesional Senior Type hints, Pydantic, SOLID en los 3 proyectos Pipelines ML reproducibles Senior sklearn Pipeline unificado, sin data leakage Testing &amp; CI/CD Senior 80%+ coverage, GitHub Actions, matrix testing APIs de producci\u00f3n Senior FastAPI con validaci\u00f3n, Docker multi-stage Observabilidad Staff Prometheus, logging estructurado, drift detection Pasar entrevistas t\u00e9cnicas Staff Simulacros completos, speech de 5-7 min"},{"location":"docs/00_INDICE/#como-usar-esta-guia","title":"\ud83e\udded C\u00f3mo Usar Esta Gu\u00eda","text":""},{"location":"docs/00_INDICE/#perfil-de-entrada","title":"Perfil de Entrada","text":"<ul> <li>Python b\u00e1sico (funciones, clases, m\u00f3dulos)</li> <li>Git elemental (clone, commit, push)</li> <li>Comodidad con la terminal</li> </ul>"},{"location":"docs/00_INDICE/#metodo-de-estudio","title":"M\u00e9todo de Estudio","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         CICLO DE APRENDIZAJE                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   1. LEER          2. REPLICAR         3. PRACTICAR      4. VALIDAR        \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2502\n\u2502   El m\u00f3dulo        En uno de los       Ejercicios        Examen de         \u2502\n\u2502   completo         3 proyectos         del m\u00f3dulo        hito              \u2502\n\u2502                                                                            \u2502\n\u2502   \ud83d\udca1 Cada m\u00f3dulo incluye TODO integrado:                                   \u2502\n\u2502      \u2022 \ud83d\udcfa Recursos externos (videos, cursos, docs)                         \u2502\n\u2502      \u2022 \u2696\ufe0f Decisiones t\u00e9cnicas (ADRs)                                       \u2502\n\u2502      \u2022 \ud83d\udd27 Ejercicios con soluciones                                        \u2502\n\u2502      \u2022 \ud83d\udd17 Glosario del m\u00f3dulo                                              \u2502\n\u2502      \u2022 \ud83d\udce6 Aplicaci\u00f3n en el portafolio                                      \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/00_INDICE/#checkpoints-de-fase","title":"\ud83c\udfc1 Checkpoints de Fase","text":"Fase M\u00f3dulo Final Incluye Fase 1 M\u00f3dulo 06 Examen Hito 1 + Simulacro Junior Fase 2 M\u00f3dulo 10 Examen Hito 2 Fase 3 M\u00f3dulo 16 Ex\u00e1menes 3-4 + Simulacro Mid Fase 4 M\u00f3dulo 18 Examen Hito 5 Fase 5 M\u00f3dulo 23 Examen Final + Simulacro Senior + Prep Entrevistas"},{"location":"docs/00_INDICE/#sistema-de-estudio","title":"\ud83e\udde0 Sistema de Estudio","text":"<p>Nota: Las herramientas de estudio (protocolo de repaso, diario de errores, cierre semanal) ahora est\u00e1n integradas en cada m\u00f3dulo y en los checkpoints de fase.</p>"},{"location":"docs/00_INDICE/#rutas-de-aprendizaje","title":"Rutas de Aprendizaje","text":"Si eres... Ruta recomendada Principiante Ruta principal 24 semanas (recomendada). Si vas intensivo: ruta acelerada 8 semanas DS con experiencia Ruta acelerada 8 semanas (reforzando m\u00f3dulos 11\u201318 para \u201cproduction mindset\u201d) Preparando entrevista Ir directo a MAPA 1:1 + m\u00f3dulos 20\u201323 + Simulacros"},{"location":"docs/00_INDICE/#roadmap-visual","title":"\ud83d\udcca Roadmap Visual","text":""},{"location":"docs/00_INDICE/#ruta-principal-24-semanas-6-meses","title":"Ruta principal (24 semanas / 6 meses)","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         RUTA PRINCIPAL (24 SEMANAS / 6 MESES)                    \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551  MES 1 (Sem 1-4):   Fundamentos (01\u201305)                                          \u2551\n\u2551  MES 2 (Sem 5-8):   Datos + DVC + Pipelines (06\u201307)                              \u2551\n\u2551  MES 3 (Sem 9-12):  Features + Training + MLflow (08\u201310)                         \u2551\n\u2551  MES 4 (Sem 13-16): Testing + CI/CD (11\u201312)                                      \u2551\n\u2551  MES 5 (Sem 17-20): Docker + APIs + Dashboard + Observabilidad (13\u201316)           \u2551\n\u2551  MES 6 (Sem 21-24): Deploy + IaC + Docs + Integraci\u00f3n (17\u201323)                    \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/00_INDICE/#ruta-acelerada-8-semanas","title":"Ruta acelerada (8 semanas)","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                             RUTA ACELERADA (8 SEMANAS)                           \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                                  \u2551\n\u2551  FASE 1: FUNDAMENTOS (Semanas 1-2)          FASE 2: ML ENGINEERING (Semanas 3-4) \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2551\n\u2551  [01] Python Moderno \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        [07] sklearn Pipelines \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2551\n\u2551  [02] Dise\u00f1o de Sistemas           \u2502        [08] Feature Engineering        \u2502    \u2551\n\u2551  [03] Estructura de Proyecto       \u251c\u2500\u2500\u2192     [09] Training Profesional  \u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2192 \u2551\n\u2551  [04] Entornos Reproducibles       \u2502        [10] Experiment Tracking        \u2502    \u2551\n\u2551  [05] Git Profesional              \u2502                                        \u2502    \u2551\n\u2551  [06] Versionado de Datos \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                        \u2502    \u2551\n\u2551                                                                             \u2502    \u2551\n\u2551  FASE 3: MLOps CORE (Semanas 5-6)           FASE 4: PRODUCCI\u00d3N (Semana 7)   \u2502    \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502    \u2551\n\u2551  [11] Testing para ML \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500-\u2518    \u2551\n\u2551  [12] CI/CD con GitHub Actions                                                   \u2551\n\u2551  [13] Docker Avanzado                       [17] Estrategias de Despliegue       \u2551\n\u2551  [14] FastAPI para ML                       [18] Infraestructura como C\u00f3digo     \u2551\n\u2551  [15] Streamlit Dashboards                                                       \u2551\n\u2551  [16] Observabilidad                                                             \u2551\n\u2551                                                                                  \u2551\n\u2551  FASE 5: ESPECIALIZACI\u00d3N (Semana 8)                                              \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                              \u2551\n\u2551  [19] Documentaci\u00f3n (Model Cards)           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2551\n\u2551  [20] Observabilidad Avanzada + Drift \u2500\u2500\u2500\u2500\u2500\u2192\u2502  \ud83c\udfaf PORTAFOLIO COMPLETO          \u2502 \u2551\n\u2551  [21] Cloud FinOps                          \u2502     3 proyectos production-ready \u2502 \u2551\n\u2551  [22] IaC Empresarial                       \u2502     CI/CD \u226580% coverage          \u2502 \u2551\n\u2551  [23] Proyecto Integrador \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192\u2502     Listo para entrevistas       \u2502 \u2551\n\u2551                                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2551\n\u2551                                                                                  \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/00_INDICE/#indice-de-modulos","title":"\ud83d\udcd6 \u00cdndice de M\u00f3dulos","text":""},{"location":"docs/00_INDICE/#fase-1-fundamentos-de-ingenieria-semanas-1-2","title":"FASE 1: Fundamentos de Ingenier\u00eda (Semanas 1-2)","text":"<p>Objetivo: Establecer las bases de c\u00f3digo profesional que usar\u00e1s en todo el portafolio.</p> # M\u00f3dulo Qu\u00e9 Aprender\u00e1s Tiempo 01 Python Moderno Type hints, Pydantic, dataclasses, SOLID 4h 02 Dise\u00f1o de Sistemas ML ML Canvas, C4 Model, ADRs, arquitectura 4h 03 Estructura de Proyecto src/ layout, pyproject.toml, Makefile 3h 04 Entornos Reproducibles venv, Poetry, requirements, lockfiles 4h 05 Git Profesional Conventional Commits, pre-commit, branching 4h 06 Versionado de Datos DVC, pipelines de datos, remote storage 4h <p>\ud83d\udce6 Aplicaci\u00f3n en el Portafolio: Todo el c\u00f3digo de <code>common_utils/</code>, <code>pyproject.toml</code> y <code>.pre-commit-config.yaml</code>.</p> <p>\ud83c\udfa4 Checkpoint Junior: Al completar esta fase, practica con Simulacro Junior</p> <p>\ud83d\udccb Examen de Hito: EXAM_01_SETUP</p>"},{"location":"docs/00_INDICE/#fase-2-ml-engineering-semanas-3-4","title":"FASE 2: ML Engineering (Semanas 3-4)","text":"<p>Objetivo: Dominar el core de Machine Learning profesional: pipelines reproducibles y experimentos rastreables.</p> # M\u00f3dulo Qu\u00e9 Aprender\u00e1s Tiempo 07 sklearn Pipelines Pipeline, ColumnTransformer, Custom Transformers 5h 08 Ingenier\u00eda de Features Data leakage, FeatureEngineer class, validaci\u00f3n 4h 09 Training Profesional Clase Trainer, cross-validation, m\u00e9tricas 5h 10 Experiment Tracking MLflow tracking, Model Registry, signatures 4h <p>\ud83d\udce6 Aplicaci\u00f3n en el Portafolio: - <code>BankChurn-Predictor/src/bankchurn/pipeline.py</code> \u2192 Pipeline unificado - <code>CarVision-Market-Intelligence/src/carvision/features.py</code> \u2192 FeatureEngineer class - <code>mlruns/</code> en cada proyecto \u2192 Experimentos MLflow</p>"},{"location":"docs/00_INDICE/#fase-3-mlops-core-semanas-5-6","title":"FASE 3: MLOps Core (Semanas 5-6)","text":"<p>Objetivo: Implementar las pr\u00e1cticas que distinguen un proyecto ML profesional: testing, CI/CD, APIs y observabilidad.</p> # M\u00f3dulo Qu\u00e9 Aprender\u00e1s Tiempo 11 Testing para ML Pir\u00e1mide de testing, fixtures, 80%+ coverage 6h 12 CI/CD con GitHub Actions Matrix testing, coverage gates, security scanning 5h 13 Docker Avanzado Multi-stage builds, non-root, docker-compose 4h 14 FastAPI para ML Schemas Pydantic, /predict, /health, error handling 4h 15 Streamlit Dashboards Caching, tabs, visualizaciones, consumo de API 3h 16 Observabilidad Logging estructurado, Prometheus, drift detection 4h <p>\ud83d\udce6 Aplicaci\u00f3n en el Portafolio: - <code>tests/</code> en cada proyecto \u2192 80%+ coverage - <code>.github/workflows/ci-mlops.yml</code> \u2192 Pipeline CI/CD real - <code>app/fastapi_app.py</code> \u2192 API de predicci\u00f3n - <code>app/streamlit_app.py</code> \u2192 Dashboard interactivo</p> <p>\ud83c\udfa4 Checkpoint Mid: Al completar esta fase, practica con Simulacro Mid</p> <p>\ud83d\udccb Ex\u00e1menes de Hito: EXAM_03_TESTING | EXAM_04_DEPLOYMENT</p>"},{"location":"docs/00_INDICE/#fase-4-produccion-semana-7","title":"FASE 4: Producci\u00f3n (Semana 7)","text":"<p>Objetivo: Entender estrategias de despliegue, infraestructura como c\u00f3digo y control de costos en cloud.</p> # M\u00f3dulo Qu\u00e9 Aprender\u00e1s Tiempo 17 Estrategias de Despliegue Lambda vs ECS vs K8s, blue-green, canary, an\u00e1lisis de costos 4h 18 Infraestructura como C\u00f3digo Terraform basics, Kubernetes intro, Cloud &amp; FinOps (costos en AWS/GCP) 3h <p>\ud83d\udce6 Aplicaci\u00f3n en el Portafolio: - <code>infra/terraform/</code> \u2192 Templates Terraform - <code>k8s/</code> \u2192 Manifests Kubernetes (incluyendo buenas pr\u00e1cticas de costos) - <code>docker-compose.demo.yml</code> \u2192 Orquestaci\u00f3n local</p>"},{"location":"docs/00_INDICE/#fase-5-especializacion-seniorstaff-semana-8","title":"FASE 5: Especializaci\u00f3n Senior/Staff (Semana 8)","text":"<p>Objetivo: Documentaci\u00f3n profesional, observabilidad avanzada, infraestructura empresarial y proyecto integrador.</p> # M\u00f3dulo Qu\u00e9 Aprender\u00e1s Tiempo 19 Documentaci\u00f3n ML Model Cards, Dataset Cards, MkDocs 3h 20 Observabilidad Avanzada y Drift KS-test, PSI, EvidentlyAI, alertas multi-nivel 3h 21 Cloud FinOps Costos ML, Spot vs On-Demand, auto-scaling, TCO 2h 22 IaC Empresarial Terraform state, multi-ambiente, CI/CD para infra 3h 23 Proyecto Integrador R\u00fabrica 100 puntos, checklist final 4h <p>\ud83d\udce6 Aplicaci\u00f3n en el Portafolio: - <code>docs/</code> en cada proyecto \u2192 Model Cards y READMEs profesionales - <code>RUNBOOK.md</code> \u2192 Gu\u00eda de operaciones</p> <p>\ud83c\udfa4 Checkpoint Senior: Al completar toda la gu\u00eda, usa el M\u00f3dulo 23 que incluye el examen final, simulacro senior completo y preparaci\u00f3n de entrevistas integrada.</p>"},{"location":"docs/00_INDICE/#material-complementario","title":"\ud83d\udcda Material Complementario","text":""},{"location":"docs/00_INDICE/#los-4-pilares-pedagogicos","title":"\ud83c\udfdb\ufe0f Los 4 Pilares Pedag\u00f3gicos","text":"<p>Cada semana est\u00e1 estructurada en 4 pilares, ahora integrados directamente en cada m\u00f3dulo:</p> Pilar Ubicaci\u00f3n Descripci\u00f3n 1. Teor\u00eda M\u00f3dulos (<code>01_</code> a <code>23_</code>) Conceptos con analog\u00edas del mundo real 2. Pr\u00e1ctica README.md + m\u00f3dulos C\u00f3digo paso a paso conectado al portafolio 3. La Trampa Secci\u00f3n \"\ud83e\udea4 La Trampa\" en cada m\u00f3dulo 50+ errores t\u00edpicos integrados por tema 4. Evaluaci\u00f3n Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" en cada m\u00f3dulo Quizzes integrados (3 preguntas + 1 ejercicio)"},{"location":"docs/00_INDICE/#preparacion-de-entrevistas","title":"\ud83c\udfa4 Preparaci\u00f3n de Entrevistas","text":"Recurso Descripci\u00f3n Defensa del Portafolio (M\u00f3dulo 23) Preguntas t\u00e9cnicas sobre decisiones de arquitectura Simulacro Junior 50 preguntas nivel entry Simulacro Mid 60 preguntas nivel mid Simulacro Senior P1 + P2 115 preguntas nivel senior"},{"location":"docs/00_INDICE/#material-de-apoyo","title":"\ud83d\udcda Material de Apoyo","text":"Recurso Descripci\u00f3n Glosario MLOps 100+ t\u00e9rminos esenciales Checklist Profesional Verificaci\u00f3n pre-deploy, auditor\u00eda Recursos Externos Libros, cursos, papers, comunidades R\u00fabrica de Evaluaci\u00f3n Criterios 100 puntos Plantillas Templates reutilizables Gu\u00eda Audiovisual C\u00f3mo crear demos y videos Gu\u00eda de Mantenimiento Operaciones y runbooks Scripts Operacionales Scripts de demo, testing, auditor\u00eda <p>Nota: Ejercicios, ex\u00e1menes, simulacros, ADRs y recursos por m\u00f3dulo ahora est\u00e1n integrados directamente en cada m\u00f3dulo. Ver la tabla de Checkpoints de Fase arriba para ubicarlos.</p>"},{"location":"docs/00_INDICE/#planificacion","title":"\ud83d\udcc5 Planificaci\u00f3n","text":"Recurso Descripci\u00f3n SYLLABUS Programa detallado semana a semana Plan de Estudios Cronograma d\u00eda a d\u00eda"},{"location":"docs/00_INDICE/#los-3-proyectos-del-portafolio","title":"\ud83c\udfd7\ufe0f Los 3 Proyectos del Portafolio","text":"<p>Esta gu\u00eda te prepara para construir estos 3 proyectos production-ready:</p>"},{"location":"docs/00_INDICE/#1-bankchurn-predictor","title":"1. BankChurn-Predictor","text":"<p><pre><code>\ud83d\udcc1 BankChurn-Predictor/\n\u251c\u2500\u2500 src/bankchurn/          # C\u00f3digo fuente\n\u2502   \u251c\u2500\u2500 config.py           # Configuraci\u00f3n Pydantic\n\u2502   \u251c\u2500\u2500 pipeline.py         # Pipeline sklearn unificado\n\u2502   \u2514\u2500\u2500 trainer.py          # Clase de entrenamiento\n\u251c\u2500\u2500 app/                    # APIs\n\u2502   \u251c\u2500\u2500 fastapi_app.py\n\u2502   \u2514\u2500\u2500 streamlit_app.py\n\u251c\u2500\u2500 tests/                  # 79%+ coverage\n\u2514\u2500\u2500 Dockerfile              # Multi-stage, non-root\n</code></pre> - Problema: Clasificaci\u00f3n binaria (churn/no-churn) - T\u00e9cnicas: RandomForest, class weighting, SimpleImputer - M\u00f3dulos clave: 07, 09, 11, 14</p>"},{"location":"docs/00_INDICE/#2-carvision-market-intelligence","title":"2. CarVision-Market-Intelligence","text":"<p><pre><code>\ud83d\udcc1 CarVision-Market-Intelligence/\n\u251c\u2500\u2500 src/carvision/\n\u2502   \u251c\u2500\u2500 features.py         # FeatureEngineer centralizado\n\u2502   \u251c\u2500\u2500 data.py             # clean_data parameterizado\n\u2502   \u2514\u2500\u2500 pipeline.py\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 streamlit_app.py    # Dashboard principal\n\u251c\u2500\u2500 tests/                  # 97% coverage\n\u2514\u2500\u2500 configs/config.yaml\n</code></pre> - Problema: Regresi\u00f3n (predicci\u00f3n de precios de autos) - T\u00e9cnicas: Custom FeatureEngineer, RandomForest - M\u00f3dulos clave: 08, 15, 11</p>"},{"location":"docs/00_INDICE/#3-telecomai-customer-intelligence","title":"3. TelecomAI-Customer-Intelligence","text":"<p><pre><code>\ud83d\udcc1 TelecomAI-Customer-Intelligence/\n\u251c\u2500\u2500 src/telecomai/\n\u2502   \u251c\u2500\u2500 data.py\n\u2502   \u2514\u2500\u2500 training.py\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 fastapi_app.py\n\u2502   \u2514\u2500\u2500 example_load.py\n\u251c\u2500\u2500 tests/                  # 97% coverage\n\u2514\u2500\u2500 docs/\n</code></pre> - Problema: Clasificaci\u00f3n multiclase (segmentaci\u00f3n de clientes) - T\u00e9cnicas: LogisticRegression, GradientBoosting - M\u00f3dulos clave: 09, 10, 12</p>"},{"location":"docs/00_INDICE/#quick-start","title":"\u26a1 Quick Start","text":"<pre><code># 1. Clonar el portafolio\ngit clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git\ncd ML-MLOps-Portfolio\n\n# 2. Empezar con BankChurn (proyecto base)\ncd BankChurn-Predictor\npip install -e \".[dev]\"\n\n# 3. Ejecutar el flujo completo\nmake train          # Entrena el modelo\nmake test           # Ejecuta tests (79%+ coverage)\nmake serve          # Inicia API en localhost:8000\n\n# 4. Verificar que todo funciona\ncurl http://localhost:8000/health\n</code></pre>"},{"location":"docs/00_INDICE/#tiempo-estimado","title":"\ud83d\udcc8 Tiempo Estimado","text":"Fase M\u00f3dulos Horas Semanas Fundamentos 01-06 23h 2 ML Engineering 07-10 18h 2 MLOps Core 11-16 26h 2 Producci\u00f3n 17-18 7h 1 Especializaci\u00f3n Senior 19-23 15h 1 TOTAL 23 m\u00f3dulos ~86h 8 semanas <p>Dedicaci\u00f3n sugerida: 10-12 horas/semana</p>"},{"location":"docs/00_INDICE/#convenciones-de-la-guia","title":"\u2705 Convenciones de la Gu\u00eda","text":"S\u00edmbolo Significado \ud83d\udca1 Tip o consejo pr\u00e1ctico \u26a0\ufe0f Advertencia importante \u274c Anti-patr\u00f3n o error com\u00fan \u2705 Buena pr\u00e1ctica recomendada \ud83d\udd27 Ejercicio pr\u00e1ctico \ud83d\udcdd Nota o aclaraci\u00f3n \ud83c\udfaf Objetivo de aprendizaje \ud83d\udce6 C\u00f3mo se us\u00f3 en el portafolio"},{"location":"docs/00_INDICE/#empieza-ahora","title":"\ud83d\ude80 \u00a1Empieza Ahora!","text":"**M\u00f3dulo 1** \u2192 [Python Moderno para MLOps](01_PYTHON_MODERNO.md)  ---  *Tiempo estimado para completar la gu\u00eda: 8 semanas a ritmo moderado*  *\u00daltima actualizaci\u00f3n: Diciembre 2024*"},{"location":"docs/01_PYTHON_MODERNO/","title":"01. Python Moderno para MLOps","text":""},{"location":"docs/01_PYTHON_MODERNO/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Transformar tu c\u00f3digo de \"funciona en un notebook\" a \"pasa code review en una empresa FAANG\".</p> <p>En este portafolio aplicar\u00e1s estos patrones sobre <code>common_utils/</code> y el c\u00f3digo de los tres proyectos (BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence), para que tu Python sea consistente en todo el stack.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551   ANTES (Data Scientist t\u00edpico)          DESPU\u00c9S (MLOps Engineer)            \u2551\n\u2551   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500            \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500           \u2551\n\u2551   \u2022 Un archivo gigante                   \u2022 Paquete instalable                \u2551\n\u2551   \u2022 Sin tipos                            \u2022 Type hints en todo                \u2551\n\u2551   \u2022 Config hardcodeada                   \u2022 Pydantic validation               \u2551\n\u2551   \u2022 \"Funciona en mi m\u00e1quina\"             \u2022 Funciona en cualquier m\u00e1quina     \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Python b\u00e1sico: funciones, clases, m\u00f3dulos.</li> <li>Terminal: ejecutar comandos y navegar carpetas.</li> <li>Entorno listo para ejecutar el portafolio (si todav\u00eda no lo tienes, usa el m\u00f3dulo 04_ENTORNOS).</li> <li>Opcional (pero recomendado): entender qu\u00e9 significa instalar un paquete en modo editable (<code>pip install -e .</code>).</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de leer: abre Protocolo E y define tu output m\u00ednimo de la sesi\u00f3n.</li> <li>Mientras implementas: si te atoras &gt;15 min, registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir en qu\u00e9 mejorar (calidad, reproducibilidad, etc.).</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Type hints en funciones p\u00fablicas (carga de datos, features, train, predict)</li> <li>[ ] <code>mypy</code> corriendo sobre <code>src/</code> sin errores cr\u00edticos</li> <li>[ ] Config con Pydantic (cargando YAML y validando rangos)</li> <li>[ ] <code>src/</code> layout real (paquete instalable)</li> <li>[ ] Instalaci\u00f3n editable: <code>pip install -e \".[dev]\"</code> y <code>pytest</code> corriendo desde ra\u00edz</li> </ul> <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: typing / Pydantic / packaging</li> <li>Archivo: <code>src/&lt;paquete&gt;/config.py</code>, <code>src/&lt;paquete&gt;/training.py</code>, <code>pyproject.toml</code></li> <li>Prueba: <code>mypy src/</code> + <code>pytest</code></li> <li>Evidencia: checklist del m\u00f3dulo + 1 entrada en Diario si hubo bloqueo</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>0.4 Repaso: Fundamentos de Python para MLOps \u2b50 NUEVO</li> <li>Type Hints: Tu Contrato con el Futuro</li> <li>Pydantic: Validaci\u00f3n Autom\u00e1tica</li> <li>src/ Layout: Estructura Profesional</li> <li>Principios SOLID para ML</li> <li>OOP para ML: Protocolos y ABC \u2b50 NUEVO</li> <li>Pandera: Validaci\u00f3n de DataFrames \u2b50 NUEVO</li> <li>Ejercicios Pr\u00e1cticos</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#04-repaso-fundamentos-de-python-para-mlops","title":"0.4 Repaso: Fundamentos de Python para MLOps","text":"<p>Si vienes de Python b\u00e1sico, esta secci\u00f3n te prepara para el salto a c\u00f3digo profesional. Si ya dominas funciones, clases y m\u00f3dulos, puedes saltar a la secci\u00f3n 1.1.</p>"},{"location":"docs/01_PYTHON_MODERNO/#de-notebook-a-codigo-profesional-el-mindset","title":"\ud83c\udfaf De Notebook a C\u00f3digo Profesional: El Mindset","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  EL PROBLEMA DEL DATA SCIENTIST T\u00cdPICO:                                       \u2551\n\u2551                                                                               \u2551\n\u2551  En un notebook:                                                              \u2551\n\u2551  \u2022 Escribes c\u00f3digo en celdas desordenadas                                     \u2551\n\u2551  \u2022 Variables globales por todos lados                                         \u2551\n\u2551  \u2022 \"Funciona\" = \u00e9xito                                                         \u2551\n\u2551  \u2022 Cuando algo falla, reinicias el kernel y vuelves a correr todo             \u2551\n\u2551                                                                               \u2551\n\u2551  En producci\u00f3n:                                                               \u2551\n\u2551  \u2022 El c\u00f3digo debe ser MODULAR (dividido en piezas reutilizables)              \u2551\n\u2551  \u2022 Las dependencias deben ser EXPL\u00cdCITAS (no variables m\u00e1gicas)               \u2551\n\u2551  \u2022 \"Funciona\" = pasa tests + se entiende + se mantiene                        \u2551\n\u2551  \u2022 Cuando algo falla, necesitas DIAGNOSTICAR sin reiniciar                    \u2551\n\u2551                                                                               \u2551\n\u2551  Esta gu\u00eda te lleva del primer mindset al segundo.                            \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#funciones-la-unidad-basica-de-codigo-reutilizable","title":"Funciones: La Unidad B\u00e1sica de C\u00f3digo Reutilizable","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# NIVEL B\u00c1SICO: Funciones simples\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# \u274c C\u00f3digo de notebook (todo en celdas sueltas) - NO HAGAS ESTO\nimport pandas as pd                              # pandas: librer\u00eda para manipular tablas (DataFrames). \"pd\" es la convenci\u00f3n universal.\ndf = pd.read_csv(\"data.csv\")                     # read_csv() lee un archivo CSV y lo convierte en DataFrame (tabla en memoria).\ndf = df.dropna()                                 # dropna() elimina TODAS las filas con alg\u00fan valor faltante (NaN). Peligroso: puedes perder datos.\ndf[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())   # fillna() rellena NaN con un valor; mean() calcula el promedio. Problema: esto ya modific\u00f3 df arriba.\n# ... y as\u00ed 200 l\u00edneas m\u00e1s                       # En notebooks, el c\u00f3digo crece sin estructura \u2192 imposible de mantener/testear.\n\n# \u2705 C\u00f3digo profesional (encapsulado en funciones)\ndef load_and_clean_data(path: str) -&gt; pd.DataFrame:  # def: define una funci\u00f3n. \"path: str\" indica que espera un string. \"-&gt; pd.DataFrame\" indica qu\u00e9 retorna.\n    \"\"\"Carga datos y aplica limpieza b\u00e1sica.         # Docstring: documentaci\u00f3n de la funci\u00f3n. SIEMPRE documenta funciones p\u00fablicas.\n\n    Args:                                            # Args: lista de par\u00e1metros que recibe la funci\u00f3n.\n        path: Ruta al archivo CSV.                   # Describe cada par\u00e1metro con tipo y prop\u00f3sito.\n\n    Returns:                                         # Returns: describe qu\u00e9 devuelve la funci\u00f3n.\n        DataFrame limpio listo para feature engineering.\n\n    Example:                                         # Example: muestra c\u00f3mo usar la funci\u00f3n (doctests ejecutables con pytest).\n        &gt;&gt;&gt; df = load_and_clean_data(\"data/raw/churn.csv\")\n        &gt;&gt;&gt; df.shape\n        (10000, 14)\n    \"\"\"\n    df = pd.read_csv(path)                           # Lee el CSV. La ruta viene como par\u00e1metro \u2192 la funci\u00f3n es REUTILIZABLE.\n    df = df.dropna(subset=[\"target\"])                # subset=[\"target\"]: solo elimina filas donde \"target\" es NaN, no todas las filas.\n    df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median()) # median() es m\u00e1s robusto que mean() frente a outliers.\n    return df                                        # return: devuelve el resultado. Sin return, la funci\u00f3n devuelve None.\n\n# Ahora puedo REUTILIZAR esta funci\u00f3n en cualquier parte\ndf_train = load_and_clean_data(\"data/train.csv\")     # Llamo la funci\u00f3n con datos de entrenamiento \u2192 obtienen misma limpieza.\ndf_test = load_and_clean_data(\"data/test.csv\")       # Llamo con datos de test \u2192 GARANTIZA consistencia entre train y test.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#clases-agrupando-datos-y-comportamiento","title":"Clases: Agrupando Datos y Comportamiento","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# \u00bfPOR QU\u00c9 CLASES? La Analog\u00eda del Formulario\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Imagina que tienes que procesar solicitudes de cr\u00e9dito:\n#\n# SIN CLASES (diccionarios sueltos):\n# solicitud1 = {\"nombre\": \"Juan\", \"edad\": 30, \"salario\": 50000}\n# solicitud2 = {\"nombre\": \"Ana\", \"edad\": None, \"salario\": -1000}  # \u00bfV\u00e1lido?\n#\n# \u00bfC\u00f3mo validas que la edad no sea None?\n# \u00bfC\u00f3mo evitas salarios negativos?\n# \u00bfD\u00f3nde pones la l\u00f3gica de calcular el score crediticio?\n#\n# CON CLASES (estructura + validaci\u00f3n + comportamiento):\n\nfrom dataclasses import dataclass      # dataclass: decorador que genera autom\u00e1ticamente __init__, __repr__, __eq__ para tu clase.\nfrom typing import Optional            # Optional[X] significa \"puede ser X o None\". Equivale a Union[X, None].\n\n@dataclass                             # @dataclass: convierte la clase en una \"data class\" \u2192 menos c\u00f3digo boilerplate.\nclass SolicitudCredito:                # class: define un nuevo tipo de objeto. PascalCase por convenci\u00f3n (primera letra may\u00fascula).\n    \"\"\"Una solicitud de cr\u00e9dito con validaci\u00f3n b\u00e1sica.\"\"\"  # Docstring de la clase: explica su prop\u00f3sito.\n    nombre: str                        # Atributo: nombre de tipo str (texto). dataclass lo convierte en par\u00e1metro del __init__.\n    edad: int                          # Atributo: edad de tipo int (entero). Ser\u00e1 obligatorio al crear la instancia.\n    salario: float                     # Atributo: salario de tipo float (decimal). Tambi\u00e9n obligatorio.\n    historial_crediticio: Optional[float] = None  # Atributo OPCIONAL: tiene valor por defecto None. Puede o no proporcionarse.\n\n    def __post_init__(self):           # __post_init__: m\u00e9todo especial que se ejecuta DESPU\u00c9S de que dataclass crea el objeto.\n        \"\"\"Validaci\u00f3n al crear la instancia.\"\"\"  # Aqu\u00ed ponemos validaciones que deben ocurrir al instanciar.\n        if self.edad &lt; 18:             # self: referencia al objeto actual. self.edad accede al atributo edad de ESTA instancia.\n            raise ValueError(\"Debe ser mayor de edad\")  # raise: lanza una excepci\u00f3n. ValueError: error por valor inv\u00e1lido.\n        if self.salario &lt;= 0:          # Validaci\u00f3n de negocio: salario debe ser positivo.\n            raise ValueError(\"Salario debe ser positivo\")\n\n    def calcular_score(self) -&gt; float: # M\u00e9todo: funci\u00f3n que pertenece a la clase. self siempre es el primer par\u00e1metro.\n        \"\"\"Calcula score crediticio b\u00e1sico.\"\"\"\n        base = min(self.salario / 1000, 100)      # min(a, b): retorna el menor. Limita el score base a 100 m\u00e1ximo.\n        edad_bonus = min(self.edad - 18, 30) * 0.5  # Bonus por edad, m\u00e1ximo 15 puntos (30 * 0.5).\n        return base + edad_bonus       # return: devuelve el resultado del c\u00e1lculo.\n\n# Ahora es IMPOSIBLE crear una solicitud inv\u00e1lida\nsolicitud = SolicitudCredito(nombre=\"Juan\", edad=30, salario=50000)  # Crea instancia: dataclass genera __init__ con estos par\u00e1metros.\nprint(f\"Score: {solicitud.calcular_score()}\")  # f-string: f\"...\" permite insertar {expresiones} dentro del string. Score: 56.0\n\n# Esto FALLA inmediatamente con un error claro\n# solicitud_mala = SolicitudCredito(nombre=\"Ana\", edad=15, salario=-1000)\n# ValueError: Debe ser mayor de edad  # El error es CLARO y ocurre EN LA CREACI\u00d3N, no despu\u00e9s cuando ya es tarde.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#modulos-organizando-codigo-en-archivos","title":"M\u00f3dulos: Organizando C\u00f3digo en Archivos","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# \u00bfPOR QU\u00c9 M\u00d3DULOS? La Analog\u00eda de la Biblioteca\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Una biblioteca tiene SECCIONES (m\u00f3dulos):\n# - Secci\u00f3n de novelas (data.py)\n# - Secci\u00f3n de ciencia (features.py)\n# - Secci\u00f3n de historia (training.py)\n#\n# Cada secci\u00f3n tiene su PROP\u00d3SITO y no mezclas libros de cocina con novelas.\n\n# Estructura t\u00edpica de un proyecto ML:\n#\n# src/bankchurn/\n# \u251c\u2500\u2500 __init__.py      # \"Esta carpeta es un paquete Python\"\n# \u251c\u2500\u2500 config.py        # Configuraci\u00f3n (Pydantic)\n# \u251c\u2500\u2500 data.py          # Carga y limpieza de datos\n# \u251c\u2500\u2500 features.py      # Feature engineering\n# \u251c\u2500\u2500 training.py      # Entrenamiento del modelo\n# \u251c\u2500\u2500 evaluation.py    # M\u00e9tricas y evaluaci\u00f3n\n# \u2514\u2500\u2500 prediction.py    # Inferencia en producci\u00f3n\n\n# Importar desde m\u00f3dulos:\nfrom bankchurn.config import BankChurnConfig\nfrom bankchurn.data import load_and_clean_data\nfrom bankchurn.training import ChurnTrainer\n\n# Esto es MUCHO m\u00e1s claro que tener todo en un archivo de 2000 l\u00edneas\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#decoradores-funciones-que-modifican-funciones","title":"Decoradores: Funciones que Modifican Funciones","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# DECORADORES: Muy usados en MLOps (logging, timing, caching, validaci\u00f3n)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nimport time                            # time: m\u00f3dulo est\u00e1ndar de Python para medir tiempo. time.time() da segundos desde 1970.\nfrom functools import wraps            # wraps: preserva metadatos de la funci\u00f3n original (nombre, docstring) al decorarla.\n\ndef medir_tiempo(func):                # Un decorador es una funci\u00f3n que RECIBE otra funci\u00f3n como par\u00e1metro.\n    \"\"\"Decorador que mide el tiempo de ejecuci\u00f3n de una funci\u00f3n.\"\"\"\n    @wraps(func)                       # @wraps(func): copia __name__, __doc__ de func a wrapper. Sin esto, se pierde el nombre original.\n    def wrapper(*args, **kwargs):      # wrapper: funci\u00f3n interna que \"envuelve\" a la original. *args/**kwargs capturan cualquier argumento.\n        inicio = time.time()           # Guarda el tiempo ANTES de ejecutar la funci\u00f3n.\n        resultado = func(*args, **kwargs)  # Ejecuta la funci\u00f3n original con sus argumentos. func es la funci\u00f3n decorada.\n        fin = time.time()              # Guarda el tiempo DESPU\u00c9S de ejecutar.\n        print(f\"\u23f1\ufe0f {func.__name__} tard\u00f3 {fin - inicio:.2f}s\")  # __name__: nombre de la funci\u00f3n. :.2f formatea a 2 decimales.\n        return resultado               # Retorna lo que retorn\u00f3 la funci\u00f3n original (no \"comerse\" el resultado).\n    return wrapper                     # El decorador retorna la funci\u00f3n wrapper, que reemplaza a la original.\n\n# Uso:\n@medir_tiempo                          # @decorador es equivalente a: entrenar_modelo = medir_tiempo(entrenar_modelo)\ndef entrenar_modelo(X, y):             # Esta funci\u00f3n ahora est\u00e1 \"envuelta\" por wrapper. Al llamarla, ejecuta wrapper.\n    \"\"\"Entrena un modelo (simulado).\"\"\"\n    time.sleep(2)                      # sleep(2): pausa 2 segundos. Simula un proceso que tarda (como entrenar un modelo).\n    return \"modelo_entrenado\"          # Retorna un string (en la realidad ser\u00eda el modelo entrenado).\n\nmodelo = entrenar_modelo(None, None)   # Llamar entrenar_modelo() realmente llama a wrapper(), que mide tiempo y llama a la original.\n# Output: \u23f1\ufe0f entrenar_modelo tard\u00f3 2.00s  # El decorador a\u00f1adi\u00f3 comportamiento (medir tiempo) SIN modificar la funci\u00f3n original.\n\n# En el portafolio ver\u00e1s decoradores para:\n# - Logging autom\u00e1tico de funciones    # Registrar cada llamada a funci\u00f3n con sus par\u00e1metros.\n# - Caching de resultados costosos     # @lru_cache: guarda resultados para no recalcular.\n# - Validaci\u00f3n de inputs/outputs       # Verificar tipos o rangos antes/despu\u00e9s de ejecutar.\n# - Retry de operaciones que pueden fallar  # Reintentar N veces si hay error (\u00fatil para APIs, BD).\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#context-managers-recursos-que-se-limpian-solos","title":"Context Managers: Recursos que se Limpian Solos","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CONTEXT MANAGERS: Cruciales para archivos, conexiones, MLflow runs\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# \u274c PROBLEMA: Si hay un error, el archivo queda abierto\nf = open(\"data.csv\", \"r\")              # open(): abre un archivo. \"r\" = modo lectura. Retorna un objeto file.\ndata = f.read()                        # read(): lee TODO el contenido del archivo a memoria (cuidado con archivos grandes).\n# ... si algo falla aqu\u00ed, f nunca se cierra  # Si ocurre una excepci\u00f3n, el c\u00f3digo salta y f.close() nunca se ejecuta.\nf.close()                              # close(): libera el recurso. Sin cerrar, puedes agotar file descriptors del sistema.\n\n# \u2705 SOLUCI\u00d3N: with garantiza que el archivo se cierre\nwith open(\"data.csv\", \"r\") as f:       # with: inicia un \"context manager\". \"as f\" asigna el archivo a la variable f.\n    data = f.read()                    # El c\u00f3digo dentro del with tiene acceso a f.\n# f se cierra autom\u00e1ticamente, incluso si hay error  # Al salir del with (normal o por excepci\u00f3n), Python llama f.__exit__() que cierra el archivo.\n\n# En MLflow (que usar\u00e1s en el m\u00f3dulo 10):\nimport mlflow                          # mlflow: librer\u00eda para tracking de experimentos ML. Ver\u00e1s m\u00e1s en m\u00f3dulo 10.\n\nwith mlflow.start_run(run_name=\"experimento_1\"):  # start_run(): inicia un \"run\" de MLflow. Es un context manager.\n    mlflow.log_param(\"n_estimators\", 100)         # log_param(): registra un hiperpar\u00e1metro. Se guarda asociado al run.\n    mlflow.log_metric(\"f1_score\", 0.85)           # log_metric(): registra una m\u00e9trica. Puedes ver esto en la UI de MLflow.\n    # El run se cierra autom\u00e1ticamente al salir del with  # MLflow guarda todo y marca el run como finalizado.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#comprehensions-codigo-conciso-y-pythonico","title":"Comprehensions: C\u00f3digo Conciso y Pyth\u00f3nico","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# COMPREHENSIONS: Transformaciones elegantes de datos\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# List comprehension (muy com\u00fan en ML)\ncolumnas = [\"CreditScore\", \"Age\", \"Balance\", \"Exited\"]  # Lista de strings con nombres de columnas.\ncolumnas_numericas = [col for col in columnas if col != \"Exited\"]  # [expresi\u00f3n for variable in iterable if condici\u00f3n]\n# ['CreditScore', 'Age', 'Balance']  # Resultado: lista con todos los elementos EXCEPTO \"Exited\".\n# Equivale a:                        # Es equivalente a un for loop, pero en UNA l\u00ednea:\n# columnas_numericas = []            # result = []\n# for col in columnas:               # for col in columnas:\n#     if col != \"Exited\":            #     if col != \"Exited\":\n#         columnas_numericas.append(col)  #         result.append(col)\n\n# Dict comprehension (\u00fatil para m\u00e9tricas)\nmetricas = {\"accuracy\": 0.85, \"precision\": 0.78, \"recall\": 0.72}  # Diccionario: {clave: valor}.\nmetricas_redondeadas = {k: round(v, 2) for k, v in metricas.items()}  # {clave: valor for clave, valor in dict.items()}\n# items(): retorna pares (clave, valor). round(v, 2): redondea v a 2 decimales.\n\n# Filtrar columnas por tipo (patr\u00f3n com\u00fan en feature engineering)\nimport pandas as pd                  # pandas ya se explic\u00f3 arriba; aqu\u00ed se re-importa por claridad del ejemplo.\ndf = pd.DataFrame({\"A\": [1, 2], \"B\": [\"x\", \"y\"], \"C\": [1.5, 2.5]})  # DataFrame: tabla con 3 columnas.\ncolumnas_numericas = [col for col in df.columns if df[col].dtype in [\"int64\", \"float64\"]]\n# df.columns: lista de nombres de columnas. df[col].dtype: tipo de datos de esa columna.\n# \"int64\", \"float64\": tipos num\u00e9ricos de pandas/numpy. Este patr\u00f3n filtra SOLO columnas num\u00e9ricas.\n\n# Crear diccionario de features categ\u00f3ricas a codificar\ncat_cols = [\"Geography\", \"Gender\"]   # Lista de columnas categ\u00f3ricas que queremos codificar.\nencoding_map = {col: df[col].unique().tolist() for col in cat_cols}\n# unique(): valores \u00fanicos de la columna. tolist(): convierte array a lista Python.\n# Resultado: {\"Geography\": [\"France\", \"Spain\", ...], \"Gender\": [\"Male\", \"Female\"]}\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#manejo-de-excepciones-codigo-que-no-se-rompe","title":"Manejo de Excepciones: C\u00f3digo que No se Rompe","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EXCEPCIONES: Anticipar y manejar errores profesionalmente\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfrom pathlib import Path                # Path: clase para manejar rutas de archivos de forma segura y multiplataforma.\nimport logging                          # logging: m\u00f3dulo est\u00e1ndar para registrar mensajes (mejor que print en producci\u00f3n).\n\nlogger = logging.getLogger(__name__)    # getLogger(__name__): crea un logger con el nombre del m\u00f3dulo actual.\n                                        # __name__ es una variable especial que contiene el nombre del m\u00f3dulo.\n\ndef cargar_modelo(path: Path):          # Funci\u00f3n que recibe un Path (no string) \u2192 m\u00e1s seguro y con autocompletado.\n    \"\"\"Carga un modelo serializado con manejo de errores.\n\n    Args:\n        path: Ruta al archivo .joblib del modelo.\n\n    Returns:\n        Modelo cargado.\n\n    Raises:                              # Raises: documenta qu\u00e9 excepciones puede lanzar esta funci\u00f3n.\n        FileNotFoundError: Si el archivo no existe.\n        ValueError: Si el archivo no contiene un modelo v\u00e1lido.\n    \"\"\"\n    if not path.exists():                # exists(): m\u00e9todo de Path que verifica si el archivo/carpeta existe.\n        raise FileNotFoundError(f\"Modelo no encontrado: {path}\")  # raise: lanza una excepci\u00f3n. El programa se detiene aqu\u00ed.\n\n    try:                                 # try: intenta ejecutar el c\u00f3digo. Si falla, salta al except.\n        import joblib                    # joblib: librer\u00eda para serializar objetos Python (modelos sklearn).\n        modelo = joblib.load(path)       # load(): deserializa el archivo y retorna el objeto Python guardado.\n    except Exception as e:               # except: captura la excepci\u00f3n si algo fall\u00f3 en el try. \"as e\" guarda el error.\n        logger.error(f\"Error cargando modelo: {e}\")  # error(): registra un mensaje de nivel ERROR en el log.\n        raise ValueError(f\"Archivo inv\u00e1lido: {path}\") from e  # from e: encadena excepciones (muestra la causa original).\n\n    # Validar que sea un modelo sklearn\n    if not hasattr(modelo, \"predict\"):   # hasattr(): verifica si el objeto tiene un atributo/m\u00e9todo. Todos los modelos sklearn tienen predict().\n        raise ValueError(f\"El archivo no contiene un modelo v\u00e1lido: {path}\")\n\n    logger.info(f\"Modelo cargado exitosamente: {path}\")  # info(): mensaje informativo (menos grave que error).\n    return modelo                        # Si llegamos aqu\u00ed, todo sali\u00f3 bien. Retornamos el modelo cargado.\n\n# Uso con manejo de error\ntry:                                     # try/except: patr\u00f3n para manejar errores sin que el programa crashee.\n    modelo = cargar_modelo(Path(\"models/pipeline.joblib\"))  # Path(): convierte string a objeto Path.\nexcept FileNotFoundError:                # Captura SOLO FileNotFoundError. Otros errores no se capturan aqu\u00ed.\n    print(\"\u26a0\ufe0f Modelo no encontrado. Ejecuta 'make train' primero.\")  # Mensaje amigable al usuario.\nexcept ValueError as e:                  # Captura ValueError. \"as e\" permite acceder al mensaje de error.\n    print(f\"\u274c Error de validaci\u00f3n: {e}\")  # f-string con el error espec\u00edfico.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-de-auto-evaluacion-estas-listo","title":"\ud83c\udfaf Ejercicio de Auto-evaluaci\u00f3n: \u00bfEst\u00e1s Listo?","text":"<p>Antes de continuar, verifica que puedes responder estas preguntas:</p> <pre><code># 1. \u00bfQu\u00e9 hace este c\u00f3digo?\ndef process(items: list[str]) -&gt; dict[str, int]:\n    return {item: len(item) for item in items if item}\n\n# 2. \u00bfPor qu\u00e9 esto es mejor que usar un diccionario?\n@dataclass\nclass Config:\n    batch_size: int = 32\n    learning_rate: float = 0.001\n\n# 3. \u00bfQu\u00e9 problema evita el \"with\"?\nwith open(\"file.txt\") as f:\n    data = f.read()\n\n# 4. \u00bfQu\u00e9 imprime este c\u00f3digo?\ndef decorator(func):\n    def wrapper():\n        print(\"antes\")\n        func()\n        print(\"despu\u00e9s\")\n    return wrapper\n\n@decorator\ndef hello():\n    print(\"hola\")\n\nhello()\n</code></pre> \ud83d\udd0d Ver respuestas  1. **Crea un diccionario** donde las keys son strings no vac\u00edos y los values son sus longitudes.  2. **Validaci\u00f3n y documentaci\u00f3n autom\u00e1tica**: `@dataclass` genera `__init__`, `__repr__`, y permite type hints. Un diccionario no valida tipos ni tiene autocompletado en el IDE.  3. **Evita dejar archivos abiertos**: Si hay un error dentro del `with`, el archivo se cierra autom\u00e1ticamente.  4. **Imprime**:    <pre><code>antes\nhola\ndespu\u00e9s\n</code></pre>    El decorador \"envuelve\" la funci\u00f3n original.   <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#11-type-hints-tu-contrato-con-el-futuro","title":"1.1 Type Hints: Tu Contrato con el Futuro","text":""},{"location":"docs/01_PYTHON_MODERNO/#la-analogia-del-restaurante","title":"La Analog\u00eda del Restaurante","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83c\udf7d\ufe0f IMAGINA UN RESTAURANTE:                                               \u2551\n\u2551                                                                           \u2551\n\u2551  SIN MEN\u00da (c\u00f3digo sin tipos):                                             \u2551\n\u2551  - \"Tr\u00e1eme algo de comer\"                                                 \u2551\n\u2551  - El chef improvisa                                                      \u2551\n\u2551  - El cliente no sabe qu\u00e9 esperar                                         \u2551\n\u2551  - Resultado: sorpresas (bugs)                                            \u2551\n\u2551                                                                           \u2551\n\u2551  CON MEN\u00da (c\u00f3digo con tipos):                                             \u2551\n\u2551  - \"Quiero el plato #5: Pasta Carbonara\"                                  \u2551\n\u2551  - El chef sabe exactamente qu\u00e9 preparar                                  \u2551\n\u2551  - El cliente sabe qu\u00e9 recibir\u00e1                                           \u2551\n\u2551  - Resultado: consistencia                                                \u2551\n\u2551                                                                           \u2551\n\u2551  TYPE HINTS = El men\u00fa de tu c\u00f3digo                                        \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#codigo-real-del-portafolio-sin-tipos-vs-con-tipos","title":"C\u00f3digo Real del Portafolio: Sin Tipos vs Con Tipos","text":"<pre><code># \u274c ANTES: \u00bfQu\u00e9 recibe? \u00bfQu\u00e9 retorna? \n# (Esto es lo que encontrar\u00edas en un notebook)\n\ndef prepare_features(df, num_cols, cat_cols, target):  # Define una funci\u00f3n sin type hints: no sabemos tipos esperados ni retornos.\n    X = df.drop(columns=[target])  # Separa features (X) eliminando la columna objetivo del DataFrame.\n    y = df[target]  # Extrae el target (y) como una Serie; asume que `target` existe y est\u00e1 bien escrito.\n\n    preprocessor = ColumnTransformer([  # Crea un transformador por columnas: aplica pipelines distintos a columnas num\u00e9ricas vs categ\u00f3ricas.\n        ('num', StandardScaler(), num_cols),  # (nombre, transformer, columnas): escala num\u00e9ricas a media=0, var=1 (ayuda a muchos modelos).\n        ('cat', OneHotEncoder(), cat_cols)  # One-hot a categ\u00f3ricas; por defecto puede fallar si aparece una categor\u00eda nueva en inferencia.\n    ])  # Termina la definici\u00f3n del ColumnTransformer (a\u00fan no se ha entrenado/ajustado).\n\n    X_transformed = preprocessor.fit_transform(X)  # Ajusta (fit) el preprocesador usando X y luego transforma X; devuelve una matriz (a menudo sparse).\n    return X_transformed, y, preprocessor  # Retorna features transformadas, el target y el preprocesador ya ajustado (para usar igual en valid/test/inferencia).\n</code></pre> <pre><code># \u2705 DESPU\u00c9S: C\u00f3digo real de BankChurn-Predictor/src/bankchurn/training.py\n\nfrom __future__ import annotations  # Posponer evaluaci\u00f3n de anotaciones: permite forward refs y reduce problemas de import/ciclos.\n\nfrom pathlib import Path  # Paths tipados/seguros (mejor que strings) para rutas de archivos/directorios.\nfrom typing import List, Tuple  # Tipos gen\u00e9ricos para anotar colecciones y retornos compuestos.\n\nimport numpy as np  # NumPy: arrays y tipos num\u00e9ricos; \u00fatil para tipar dtypes concretos.\nimport pandas as pd  # Pandas: DataFrame/Series, estructuras t\u00edpicas para datos tabulares.\nfrom numpy.typing import NDArray  # Tipo est\u00e1tico para arrays NumPy: ayuda a mypy a entender shapes/dtypes (hasta cierto punto).\nfrom sklearn.compose import ColumnTransformer  # Enrutador de transformaciones por grupo de columnas (num\u00e9ricas/categ\u00f3ricas/etc.).\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler  # Transformadores est\u00e1ndar de scikit-learn.\n\ndef prepare_features(\n    df: pd.DataFrame,  # Input tabular: se asume que contiene features + columna objetivo.\n    num_cols: List[str],  # Lista de nombres de columnas num\u00e9ricas: se usar\u00e1 para escalar.\n    cat_cols: List[str],  # Lista de nombres de columnas categ\u00f3ricas: se usar\u00e1 para one-hot.\n    target: str  # Nombre de la columna objetivo (label) que se va a separar en y.\n) -&gt; Tuple[NDArray[np.float64], pd.Series, ColumnTransformer]:\n    \"\"\"Prepara features para entrenamiento.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame con datos crudos.\n    num_cols : List[str]\n        Nombres de columnas num\u00e9ricas.\n    cat_cols : List[str]\n        Nombres de columnas categ\u00f3ricas.\n    target : str\n        Nombre de la columna objetivo.\n\n    Returns\n    -------\n    Tuple[NDArray, pd.Series, ColumnTransformer]\n        Features transformadas, target, y preprocessor fitted.\n    \"\"\"\n    X = df.drop(columns=[target])  # Construye X eliminando la columna objetivo: evita leakage obvio (target dentro de features).\n    y = df[target]  # Construye y como Serie: etiqueta que el modelo intentar\u00e1 predecir.\n\n    preprocessor = ColumnTransformer([  # Define el pipeline de preprocesamiento: se \u201cfija\u201d aqu\u00ed para ser reproducible.\n        ('num', StandardScaler(), num_cols),  # Escalado num\u00e9rico: \u00fatil para modelos lineales/NN; inofensivo para muchos casos.\n        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # ignore evita crash en inferencia si llega una categor\u00eda nueva.\n    ])  # Nota MLOps: guardar este objeto es clave para que producci\u00f3n use la misma transformaci\u00f3n que entrenamiento.\n\n    X_transformed = preprocessor.fit_transform(X)  # Ajusta el preprocesador (learn stats/categor\u00edas) y transforma X al espacio num\u00e9rico.\n    return X_transformed, y, preprocessor  # Retorna tuple expl\u00edcita y tipada: mypy/IDE verifican contratos y ayudan en refactors.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#los-tipos-esenciales-para-ml","title":"Los Tipos Esenciales para ML","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TIPOS B\u00c1SICOS - Los usar\u00e1s constantemente\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfrom typing import (                   # typing: m\u00f3dulo est\u00e1ndar de Python para anotaciones de tipos.\n    List,       # Lista de elementos: List[str] = [\"a\", \"b\"]  # Lista donde TODOS los elementos son strings.\n    Dict,       # Diccionario: Dict[str, float] = {\"acc\": 0.95}  # Dict con claves str y valores float.\n    Tuple,      # Tupla fija: Tuple[int, int] = (100, 10)  # Tupla de exactamente 2 enteros.\n    Optional,   # Puede ser None: Optional[Path] = None  # Equivale a Union[Path, None].\n    Union,      # M\u00faltiples tipos: Union[str, List[str]]  # Puede ser string O lista de strings.\n    Any,        # Cualquier tipo (evitar si posible)  # Desactiva type checking - \u00fasalo solo si es inevitable.\n    Literal,    # Valores espec\u00edficos: Literal[\"train\", \"eval\"]  # SOLO puede ser \"train\" o \"eval\", nada m\u00e1s.\n)\nfrom pathlib import Path               # Path: ya explicado en excepciones. Mejor que strings para rutas.\n\n# Ejemplos del portafolio real:\n\n# BankChurn: features son listas de strings\nfeatures: List[str] = [\"CreditScore\", \"Age\", \"Balance\"]  # \": List[str]\" indica el tipo. mypy verifica que sea correcto.\n\n# CarVision: m\u00e9tricas son diccionario string-&gt;float\nmetrics: Dict[str, float] = {\"rmse\": 4794.27, \"r2\": 0.77}  # Claves son strings (nombres), valores son floats (n\u00fameros).\n\n# TelecomAI: puede recibir path o None\nmodel_path: Optional[Path] = None      # Optional[X] = puede ser X o None. \u00datil para par\u00e1metros opcionales.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TIPOS PARA ML - Espec\u00edficos de Machine Learning\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nimport pandas as pd                    # pandas: la librer\u00eda est\u00e1ndar para datos tabulares. Ya la vimos antes.\nimport numpy as np                     # numpy: librer\u00eda para arrays num\u00e9ricos de alto rendimiento. Base de sklearn/pandas.\nfrom numpy.typing import NDArray       # NDArray: tipo para arrays numpy. NDArray[np.float64] = array de floats de 64 bits.\nfrom sklearn.base import BaseEstimator # BaseEstimator: clase base de TODOS los modelos sklearn. Garantiza fit/predict.\nfrom sklearn.pipeline import Pipeline  # Pipeline: encadena transformadores + modelo. Lo ver\u00e1s en m\u00f3dulo 07.\n\n# DataFrame de pandas\ndef load_data(path: Path) -&gt; pd.DataFrame:  # Retorna pd.DataFrame: indica que devuelve una tabla de pandas.\n    return pd.read_csv(path)           # read_csv lee el archivo y retorna un DataFrame.\n\n# Array NumPy tipado\ndef predict_proba(X: NDArray[np.float64]) -&gt; NDArray[np.float64]:  # NDArray[np.float64]: array de floats 64-bit.\n    return model.predict_proba(X)[:, 1]  # predict_proba retorna probabilidades. [:, 1] selecciona columna 1 (clase positiva).\n\n# Modelo sklearn\ndef train_model(X: NDArray, y: NDArray) -&gt; BaseEstimator:  # Retorna BaseEstimator: cualquier modelo sklearn.\n    model = RandomForestClassifier()   # Crea instancia del modelo. RandomForest: ensemble de \u00e1rboles de decisi\u00f3n.\n    model.fit(X, y)                    # fit(): entrena el modelo con datos X (features) e y (target).\n    return model                       # Retorna el modelo entrenado (listo para predict).\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TIPOS AVANZADOS - Para c\u00f3digo m\u00e1s robusto\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nfrom typing import TypedDict, Literal  # TypedDict: dict con estructura fija. Literal: valores espec\u00edficos.\n\n# TypedDict: diccionarios con estructura conocida\nclass MetricsDict(TypedDict):          # TypedDict: define un diccionario donde cada clave tiene tipo espec\u00edfico.\n    accuracy: float                    # La clave \"accuracy\" DEBE ser float. mypy lo verifica.\n    precision: float                   # Todas las m\u00e9tricas de clasificaci\u00f3n son floats.\n    recall: float                      # recall: proporci\u00f3n de positivos reales detectados.\n    f1: float                          # f1: media arm\u00f3nica de precision y recall.\n    roc_auc: float                     # roc_auc: \u00e1rea bajo la curva ROC. 1.0 = perfecto.\n\n# Literal: solo valores espec\u00edficos permitidos\nModelType = Literal[\"random_forest\", \"logistic\", \"gradient_boosting\"]  # Crea un \"tipo alias\" que solo acepta estos 3 strings.\n\ndef build_model(model_type: ModelType, seed: int) -&gt; BaseEstimator:  # model_type SOLO puede ser uno de los 3 valores.\n    \"\"\"\n    mypy SABE que model_type solo puede ser estos 3 valores.\n    Si escribes build_model(\"xgboost\", 42), mypy dar\u00e1 error.\n    \"\"\"\n    if model_type == \"random_forest\":  # Compara string. Python permite esto aunque model_type sea Literal.\n        return RandomForestClassifier(random_state=seed)  # random_state: semilla para reproducibilidad.\n    elif model_type == \"logistic\":     # elif: \"else if\" - solo se eval\u00faa si el if anterior fue False.\n        return LogisticRegression(random_state=seed)      # LogisticRegression: modelo lineal para clasificaci\u00f3n.\n    else:  # gradient_boosting         # else: se ejecuta si ning\u00fan if/elif fue True.\n        return GradientBoostingClassifier(random_state=seed)  # GradientBoosting: ensemble de \u00e1rboles secuenciales.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#configurar-mypy","title":"Configurar mypy","text":"<p>A\u00f1ade esto a tu <code>pyproject.toml</code>:</p> <pre><code># pyproject.toml - Configuraci\u00f3n de mypy\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\nwarn_unused_ignores = true\ndisallow_untyped_defs = true      # \u2190 Fuerza tipos en todas las funciones\nignore_missing_imports = true     # \u2190 Para librer\u00edas sin stubs\n\n# Ignorar librer\u00edas de ML que no tienen stubs completos\n[[tool.mypy.overrides]]\nmodule = [\n    \"sklearn.*\",\n    \"pandas.*\", \n    \"numpy.*\",\n    \"mlflow.*\",\n    \"joblib.*\",\n]\nignore_missing_imports = true\n</code></pre> <p>Ejecutar: <pre><code>mypy src/  # Verifica tipos en todo el c\u00f3digo\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-type-hints","title":"\ud83e\udde0 Mapa Mental de Conceptos: Type Hints","text":"<pre><code>                            \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                            \u2551           TYPE HINTS EN PYTHON        \u2551\n                            \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                               \u25bc                               \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  TIPOS B\u00c1SICOS  \u2502             \u2502   TIPOS ML      \u2502             \u2502 TIPOS AVANZADOS \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502                               \u2502                               \u2502\n    \u251c\u2500 str, int, float              \u251c\u2500 pd.DataFrame                  \u251c\u2500 TypedDict\n    \u251c\u2500 bool                         \u251c\u2500 pd.Series                     \u251c\u2500 Literal\n    \u251c\u2500 List[T]                      \u251c\u2500 NDArray[np.float64]           \u251c\u2500 Protocol\n    \u251c\u2500 Dict[K,V]                    \u251c\u2500 BaseEstimator                 \u251c\u2500 TypeVar\n    \u251c\u2500 Tuple[T,...]                 \u251c\u2500 Pipeline                      \u2514\u2500 Generic\n    \u251c\u2500 Optional[T]                  \u2514\u2500 ArrayLike\n    \u2514\u2500 Union[A,B]\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo Type hint Anotaci\u00f3n de tipo en firma de funci\u00f3n <code>def f(x: int) -&gt; str:</code> Generic Tipo parametrizado <code>List[str]</code>, <code>Dict[str, float]</code> Optional Puede ser el tipo o None <code>Optional[Path] = Union[Path, None]</code> Union Varios tipos posibles <code>Union[str, int]</code> Literal Solo valores espec\u00edficos <code>Literal[\"train\", \"eval\"]</code> TypedDict Dict con estructura fija M\u00e9tricas con claves conocidas mypy Verificador est\u00e1tico de tipos Detecta errores antes de ejecutar"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-type-hints-basicos","title":"\ud83d\udcbb Ejercicio Puente: Type Hints B\u00e1sicos","text":"<p>Meta: Antes de tipar c\u00f3digo ML complejo, practica con funciones simples.</p> <p>Ejercicio 1: Funci\u00f3n Calculadora <pre><code># \u274c Sin tipos - \u00bfQu\u00e9 recibe? \u00bfQu\u00e9 retorna?\ndef calcular_promedio(numeros):\n    return sum(numeros) / len(numeros)\n\n# \u2705 TU TAREA: A\u00f1ade type hints a esta funci\u00f3n\n# Pista: numeros es una lista de floats, retorna un float\n</code></pre></p> <p>Ejercicio 2: Funci\u00f3n con M\u00faltiples Retornos <pre><code># \u274c Sin tipos\ndef dividir_dataset(datos, porcentaje):\n    punto_corte = int(len(datos) * porcentaje)\n    return datos[:punto_corte], datos[punto_corte:]\n\n# \u2705 TU TAREA: A\u00f1ade type hints\n# Pista: datos es List[Any], porcentaje es float, retorna Tuple de dos listas\n</code></pre></p> <p>Ejercicio 3: Funci\u00f3n con Par\u00e1metro Opcional <pre><code># \u274c Sin tipos\ndef cargar_datos(ruta, separador=\",\"):\n    import pandas as pd\n    return pd.read_csv(ruta, sep=separador)\n\n# \u2705 TU TAREA: A\u00f1ade type hints usando Path y Optional\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code>from typing import List, Tuple, Any, Optional\nfrom pathlib import Path\nimport pandas as pd\n\n# Ejercicio 1\ndef calcular_promedio(numeros: List[float]) -&gt; float:\n    return sum(numeros) / len(numeros)\n\n# Ejercicio 2\ndef dividir_dataset(datos: List[Any], porcentaje: float) -&gt; Tuple[List[Any], List[Any]]:\n    punto_corte = int(len(datos) * porcentaje)\n    return datos[:punto_corte], datos[punto_corte:]\n\n# Ejercicio 3\ndef cargar_datos(ruta: Path, separador: str = \",\") -&gt; pd.DataFrame:\n    return pd.read_csv(ruta, sep=separador)\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-type-hints-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Type Hints en BankChurn","text":"<p>Tarea: Aplicar type hints al c\u00f3digo real del proyecto BankChurn-Predictor.</p> <p>Paso 1: Identifica las funciones sin tipos <pre><code># Ejecuta mypy para ver qu\u00e9 funciones necesitan tipos\ncd BankChurn-Predictor\nmypy src/bankchurn/ --disallow-untyped-defs\n</code></pre></p> <p>Paso 2: Prioriza las funciones p\u00fablicas - <code>src/bankchurn/training.py</code> \u2192 funciones <code>fit</code>, <code>predict</code>, <code>evaluate</code> - <code>src/bankchurn/config.py</code> \u2192 clase de configuraci\u00f3n - <code>src/bankchurn/data.py</code> \u2192 funciones de carga de datos</p> <p>Paso 3: Aplica el patr\u00f3n (pistas guiadas)</p> <pre><code># En src/bankchurn/training.py\n# ANTES: def prepare_features(df, num_cols, cat_cols, target):\n# \n# DESPU\u00c9S: A\u00f1ade estos tipos:\n# - df: \u00bfQu\u00e9 estructura de datos es? \u2192 pd.______\n# - num_cols, cat_cols: \u00bfListas de qu\u00e9? \u2192 List[___]\n# - target: \u00bfQu\u00e9 tipo simple? \u2192 ___\n# - Retorno: \u00bfQu\u00e9 devuelve? Tuple de (array, series, transformer)\n</code></pre> <p>Paso 4: Verifica con mypy <pre><code>mypy src/bankchurn/ --strict\n# Objetivo: 0 errores en tus archivos\n</code></pre></p> <p>\u274c NO hagas esto: - Copiar tipos de otro lado sin entenderlos - Usar <code>Any</code> para \"resolver\" errores de mypy - Ignorar warnings con <code># type: ignore</code> sin justificaci\u00f3n</p> <p>\u2705 S\u00cd haz esto: - Consulta la documentaci\u00f3n de los tipos que uses - Crea type aliases para tipos repetidos - Documenta por qu\u00e9 un tipo es complejo si lo es</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-type-hints","title":"\u2705 Checkpoint de Conocimiento: Type Hints","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la diferencia entre <code>List[str]</code> y <code>list</code>?</p> <p>A) No hay diferencia, son equivalentes B) <code>List[str]</code> especifica que TODOS los elementos son strings C) <code>list</code> solo funciona en Python 2 D) <code>List[str]</code> es m\u00e1s lento en ejecuci\u00f3n  </p> <p>Pregunta 2: \u00bfQu\u00e9 significa <code>Optional[Path]</code>?</p> <p>A) El par\u00e1metro es obligatorio y debe ser un Path B) El par\u00e1metro puede ser un Path O puede ser None C) El par\u00e1metro se ignora si no se proporciona D) El par\u00e1metro debe tener un valor por defecto  </p> <p>Pregunta 3: \u00bfPor qu\u00e9 usamos <code>Literal[\"train\", \"eval\"]</code> en vez de <code>str</code>?</p> <p>A) Es m\u00e1s r\u00e1pido en ejecuci\u00f3n B) mypy puede verificar que SOLO usemos esos valores exactos C) Ocupa menos memoria D) Es requerido por sklearn  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>def entrenar_modelo(X: pd.DataFrame, y: pd.Series) -&gt; Pipeline:\n    modelo = RandomForestClassifier()\n    modelo.fit(X, y)\n    return modelo  # \u2190 mypy dice: \"Incompatible return type\"\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) `List[str]` especifica que TODOS los elementos son strings.  **Pregunta 2**: B) El par\u00e1metro puede ser un Path O puede ser None.  **Pregunta 3**: B) mypy puede verificar que SOLO usemos esos valores exactos.  **Escenario de Debugging**:  - **Problema**: La funci\u00f3n dice que retorna `Pipeline`, pero `RandomForestClassifier` no es un `Pipeline`. - **Soluci\u00f3n**: Cambiar el tipo de retorno a `BaseEstimator`, o envolver el modelo en un Pipeline real.  <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#12-pydantic-validacion-automatica","title":"1.2 Pydantic: Validaci\u00f3n Autom\u00e1tica","text":""},{"location":"docs/01_PYTHON_MODERNO/#explicacion-teorica-el-guardia-de-seguridad","title":"\ud83c\udf93 Explicaci\u00f3n Te\u00f3rica: El Guardia de Seguridad","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83d\udee1\ufe0f IMAGINA UN EDIFICIO DE OFICINAS:                                      \u2551\n\u2551                                                                           \u2551\n\u2551  SIN GUARDIA (c\u00f3digo sin Pydantic):                                       \u2551\n\u2551  - Cualquiera entra con cualquier cosa                                    \u2551\n\u2551  - Descubres problemas CUANDO YA PASARON                                  \u2551\n\u2551  - \"\u00bfPor qu\u00e9 hay un test_size de 1.5?\" \u2192 Error en producci\u00f3n              \u2551\n\u2551                                                                           \u2551\n\u2551  CON GUARDIA (c\u00f3digo con Pydantic):                                       \u2551\n\u2551  - Verifica credenciales EN LA ENTRADA                                    \u2551\n\u2551  - Problemas detectados ANTES de causar da\u00f1o                              \u2551\n\u2551  - \"test_size debe ser entre 0 y 1\" \u2192 Error inmediato y claro             \u2551\n\u2551                                                                           \u2551\n\u2551  PYDANTIC = El guardia de tu configuraci\u00f3n                                \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#codigo-real-bankchurn-config-nivel-staff","title":"C\u00f3digo Real: BankChurn Config (Nivel Staff)","text":"<p>Este es el archivo <code>src/bankchurn/config.py</code> del portafolio:</p> <pre><code>\"\"\"Configuration management for BankChurn predictor.\n\nEste m\u00f3dulo demuestra Pydantic a nivel profesional:\n- Validaci\u00f3n de rangos con Field\n- Configuraciones anidadas\n- Valores por defecto sensatos\n- Carga desde YAML\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Any, List\n\nimport yaml\nfrom pydantic import BaseModel, Field\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CONFIGURACIONES ANIDADAS - Cada componente tiene su propia config\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclass LogisticRegressionConfig(BaseModel):\n    \"\"\"Hiperpar\u00e1metros de Logistic Regression.\"\"\"\n    C: float = 0.1\n    class_weight: str = \"balanced\"\n    solver: str = \"liblinear\"\n    max_iter: int = 1000\n\n\nclass RandomForestConfig(BaseModel):\n    \"\"\"Hiperpar\u00e1metros de Random Forest.\"\"\"\n    n_estimators: int = 100\n    max_depth: int = 10\n    min_samples_split: int = 10\n    min_samples_leaf: int = 5\n    class_weight: str = \"balanced_subsample\"\n    n_jobs: int = -1\n\n\nclass EnsembleConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n del ensemble.\"\"\"\n    voting: str = Field(\"soft\", pattern=\"^(hard|soft)$\")  # \u2190 Solo permite \"hard\" o \"soft\"\n    weights: List[float] = [0.4, 0.6]\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CONFIGURACI\u00d3N PRINCIPAL - Agrupa todo con validaci\u00f3n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclass ModelConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n de entrenamiento del modelo.\"\"\"\n    type: str = \"ensemble\"\n    test_size: float = Field(0.2, ge=0.0, le=1.0)   # \u2190 VALIDACI\u00d3N: entre 0 y 1\n    random_state: int = 42\n    cv_folds: int = Field(5, ge=2)                   # \u2190 VALIDACI\u00d3N: m\u00ednimo 2\n    resampling_strategy: str = \"none\"\n\n    # Configuraciones de modelos espec\u00edficos (anidadas)\n    ensemble: EnsembleConfig = EnsembleConfig()\n    logistic_regression: LogisticRegressionConfig = LogisticRegressionConfig()\n    random_forest: RandomForestConfig = RandomForestConfig()\n\n\nclass DataConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n de datos.\"\"\"\n    target_column: str = \"Exited\"\n    categorical_features: List[str] = []\n    numerical_features: List[str] = []\n    drop_columns: List[str] = []\n\n\nclass MLflowConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n de MLflow tracking.\"\"\"\n    tracking_uri: str = \"file:./mlruns\"\n    experiment_name: str = \"bankchurn\"\n    enabled: bool = True\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CONFIGURACI\u00d3N RA\u00cdZ - El punto de entrada\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclass BankChurnConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n completa de BankChurn.\n\n    Uso:\n        config = BankChurnConfig.from_yaml(\"configs/config.yaml\")\n        print(config.model.test_size)  # 0.2\n    \"\"\"\n    model: ModelConfig\n    data: DataConfig\n    mlflow: MLflowConfig\n\n    @classmethod\n    def from_yaml(cls, config_path: str | Path) -&gt; BankChurnConfig:\n        \"\"\"Carga configuraci\u00f3n desde archivo YAML.\n\n        Parameters\n        ----------\n        config_path : str or Path\n            Ruta al archivo YAML.\n\n        Returns\n        -------\n        BankChurnConfig\n            Configuraci\u00f3n validada.\n\n        Raises\n        ------\n        FileNotFoundError\n            Si el archivo no existe.\n        ValidationError\n            Si la configuraci\u00f3n es inv\u00e1lida.\n        \"\"\"\n        config_path = Path(config_path)\n\n        if not config_path.exists():\n            raise FileNotFoundError(f\"Config file not found: {config_path}\")\n\n        with open(config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f) or {}\n\n        # Valores por defecto para secciones faltantes\n        if \"model\" not in config_dict:\n            config_dict[\"model\"] = ModelConfig().dict()\n        if \"data\" not in config_dict:\n            config_dict[\"data\"] = DataConfig().dict()\n        if \"mlflow\" not in config_dict:\n            config_dict[\"mlflow\"] = MLflowConfig().dict()\n\n        return cls(**config_dict)  # \u2190 Pydantic valida autom\u00e1ticamente\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#el-yaml-correspondiente","title":"El YAML Correspondiente","text":"<pre><code># configs/config.yaml\nmodel:\n  type: ensemble\n  test_size: 0.2         # Si pones 1.5, Pydantic dar\u00e1 error\n  random_state: 42\n  cv_folds: 5            # Si pones 1, Pydantic dar\u00e1 error\n  resampling_strategy: none\n\n  ensemble:\n    voting: soft         # Si pones \"maybe\", Pydantic dar\u00e1 error\n    weights: [0.4, 0.6]\n\n  random_forest:\n    n_estimators: 200\n    max_depth: 10\n\ndata:\n  target_column: Exited\n  categorical_features:\n    - Geography\n    - Gender\n  numerical_features:\n    - CreditScore\n    - Age\n    - Balance\n  drop_columns:\n    - RowNumber\n    - CustomerId\n    - Surname\n\nmlflow:\n  tracking_uri: \"file:./mlruns\"\n  experiment_name: bankchurn\n  enabled: true\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejemplo-de-error-de-validacion","title":"Ejemplo de Error de Validaci\u00f3n","text":"<pre><code># \u274c Esto FALLA inmediatamente con un error claro\n\nconfig_dict = {\n    \"model\": {\n        \"test_size\": 1.5,  # \u2190 Error: debe ser &lt;= 1.0\n        \"cv_folds\": 1,     # \u2190 Error: debe ser &gt;= 2\n    },\n    \"data\": {},\n    \"mlflow\": {}\n}\n\ntry:\n    config = BankChurnConfig(**config_dict)\nexcept ValidationError as e:\n    print(e)\n    # Output:\n    # 2 validation errors for BankChurnConfig\n    # model -&gt; test_size\n    #   ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)\n    # model -&gt; cv_folds\n    #   ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-pydantic","title":"\ud83e\udde0 Mapa Mental de Conceptos: Pydantic","text":"<pre><code>                         \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                         \u2551      PYDANTIC: VALIDACI\u00d3N DE DATOS     \u2551\n                         \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                           \u2502\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u25bc                               \u25bc                               \u25bc\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502   BaseModel      \u2502            \u2502     Field()      \u2502           \u2502   Validadores    \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                               \u2502                              \u2502\n \u251c\u2500 Herencia                     \u251c\u2500 ge, le (rangos)             \u251c\u2500 @validator\n \u251c\u2500 Anidamiento                  \u251c\u2500 min_length                  \u251c\u2500 @field_validator\n \u251c\u2500 .model_dump()                \u251c\u2500 pattern (regex)             \u251c\u2500 @model_validator\n \u251c\u2500 .model_validate()            \u251c\u2500 default                     \u2514\u2500 ValidationError\n \u2514\u2500 from_yaml()                  \u2514\u2500 description\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo BaseModel Clase base para modelos Pydantic <code>class Config(BaseModel):</code> Field Define restricciones en campos <code>Field(ge=0, le=1.0)</code> ValidationError Excepci\u00f3n cuando datos inv\u00e1lidos Mensaje claro con campo y raz\u00f3n Anidamiento Modelos dentro de modelos <code>ModelConfig</code> dentro de <code>BankChurnConfig</code> Coerci\u00f3n Conversi\u00f3n autom\u00e1tica de tipos <code>\"42\"</code> \u2192 <code>42</code> si el campo es <code>int</code> Literal Solo valores espec\u00edficos <code>Literal[\"soft\", \"hard\"]</code>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-validacion-con-pydantic","title":"\ud83d\udcbb Ejercicio Puente: Validaci\u00f3n con Pydantic","text":"<p>Meta: Antes de validar configs ML complejas, practica con modelos simples.</p> <p>Ejercicio 1: Config de Usuario B\u00e1sica <pre><code>from pydantic import BaseModel, Field\n\n# \u2705 TU TAREA: Crea un modelo UserConfig con:\n# - username: str (m\u00ednimo 3 caracteres)\n# - age: int (entre 18 y 120)\n# - email: str (debe contener \"@\")\n# - is_active: bool (default True)\n\nclass UserConfig(BaseModel):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> <p>Ejercicio 2: Config Anidada <pre><code># \u2705 TU TAREA: Crea dos modelos:\n# 1. DatabaseConfig con: host (str), port (int entre 1-65535), name (str)\n# 2. AppConfig que contenga: app_name (str), database (DatabaseConfig)\n\nclass DatabaseConfig(BaseModel):\n    pass\n\nclass AppConfig(BaseModel):\n    pass\n</code></pre></p> <p>Ejercicio 3: Validador Personalizado <pre><code>from pydantic import BaseModel, field_validator\n\n# \u2705 TU TAREA: Crea PasswordConfig donde:\n# - password debe tener al menos 8 caracteres\n# - password debe contener al menos un n\u00famero\n# Pista: usa @field_validator\n\nclass PasswordConfig(BaseModel):\n    password: str\n\n    # ... tu validador aqu\u00ed\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code>from pydantic import BaseModel, Field, field_validator\nfrom typing import Literal\nimport re\n\n# Ejercicio 1\nclass UserConfig(BaseModel):\n    username: str = Field(..., min_length=3)\n    age: int = Field(..., ge=18, le=120)\n    email: str = Field(..., pattern=r\".*@.*\")\n    is_active: bool = True\n\n# Ejercicio 2\nclass DatabaseConfig(BaseModel):\n    host: str\n    port: int = Field(..., ge=1, le=65535)\n    name: str\n\nclass AppConfig(BaseModel):\n    app_name: str\n    database: DatabaseConfig\n\n# Ejercicio 3\nclass PasswordConfig(BaseModel):\n    password: str = Field(..., min_length=8)\n\n    @field_validator(\"password\")\n    @classmethod\n    def must_contain_number(cls, v: str) -&gt; str:\n        if not re.search(r\"\\d\", v):\n            raise ValueError(\"Password debe contener al menos un n\u00famero\")\n        return v\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-config-pydantic-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Config Pydantic en BankChurn","text":"<p>Tarea: Implementar configuraci\u00f3n validada con Pydantic en BankChurn-Predictor.</p> <p>Paso 1: Identifica qu\u00e9 necesita validaci\u00f3n <pre><code># Revisa el archivo de configuraci\u00f3n actual\ncat BankChurn-Predictor/configs/config.yaml\n</code></pre></p> <p>T\u00edpicamente necesitas validar: - <code>test_size</code>: debe estar entre 0.0 y 1.0 - <code>cv_folds</code>: debe ser &gt;= 2 - <code>random_state</code>: debe ser entero positivo - <code>model_type</code>: solo valores permitidos</p> <p>Paso 2: Crea la estructura anidada (pistas guiadas)</p> <pre><code># src/bankchurn/config.py\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal\n\nclass ModelConfig(BaseModel):\n    # test_size: \u00bfQu\u00e9 restricciones necesita? \u2192 Field(..., ge=___, le=___)\n    # cv_folds: \u00bfCu\u00e1l es el m\u00ednimo v\u00e1lido? \u2192 Field(..., ge=___)\n    # model_type: \u00bfQu\u00e9 valores son v\u00e1lidos? \u2192 Literal[\"___\", \"___\", \"___\"]\n    pass\n\nclass DataConfig(BaseModel):\n    # target_column: str simple\n    # categorical_features: \u00bfLista de qu\u00e9?\n    # numerical_features: \u00bfLista de qu\u00e9?\n    pass\n\nclass BankChurnConfig(BaseModel):\n    model: ModelConfig\n    data: DataConfig\n\n    @classmethod\n    def from_yaml(cls, path: str) -&gt; \"BankChurnConfig\":\n        # \u00bfC\u00f3mo cargas y validas un YAML?\n        pass\n</code></pre> <p>Paso 3: Prueba con datos inv\u00e1lidos <pre><code># Test que DEBE fallar\nconfig_dict = {\n    \"model\": {\"test_size\": 1.5, \"cv_folds\": 1},\n    \"data\": {\"target_column\": \"Exited\"}\n}\n# \u00bfQu\u00e9 error esperas ver?\n</code></pre></p> <p>\u274c NO hagas esto: - Validar \"despu\u00e9s\" de usar los datos - Atrapar <code>ValidationError</code> y continuar con defaults - Hardcodear valores que deber\u00edan venir del YAML</p> <p>\u2705 S\u00cd haz esto: - Fallar r\u00e1pido si la config es inv\u00e1lida - Documentar cada restricci\u00f3n con <code>description=</code> - Crear tests para configs v\u00e1lidas E inv\u00e1lidas</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-pydantic","title":"\u2705 Checkpoint de Conocimiento: Pydantic","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la ventaja de <code>Field(ge=0, le=1)</code> sobre validar manualmente?</p> <p>A) Es m\u00e1s r\u00e1pido en ejecuci\u00f3n B) El error se detecta AL CARGAR la config, no despu\u00e9s C) Ocupa menos memoria D) Es requerido por FastAPI  </p> <p>Pregunta 2: Si tienes <code>ModelConfig</code> anidado dentro de <code>BankChurnConfig</code>, \u00bfqu\u00e9 pasa si <code>ModelConfig</code> tiene un campo inv\u00e1lido?</p> <p>A) Solo <code>ModelConfig</code> falla, <code>BankChurnConfig</code> se crea parcialmente B) Toda la validaci\u00f3n falla con error claro indicando el campo anidado C) Se ignora el error y se usa un default D) Python crashea sin mensaje \u00fatil  </p> <p>Pregunta 3: \u00bfPor qu\u00e9 usar <code>Literal[\"random_forest\", \"logistic\"]</code> en vez de <code>str</code>?</p> <p>A) Es m\u00e1s r\u00e1pido B) Si escribes <code>\"random_forrest\"</code> (typo), Pydantic te avisa inmediatamente C) Es requerido por sklearn D) Ocupa menos memoria  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>class TrainingConfig(BaseModel):\n    epochs: int = Field(10, ge=1)\n    learning_rate: float = Field(0.001, ge=0)\n    batch_size: int = 32\n\nconfig = TrainingConfig(epochs=\"cinco\", learning_rate=-0.01)\n# \u2190 \u00bfQu\u00e9 errores ver\u00e1s y en qu\u00e9 orden?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) El error se detecta AL CARGAR la config, no despu\u00e9s. Esto evita que el error aparezca en medio del entrenamiento.  **Pregunta 2**: B) Toda la validaci\u00f3n falla con error claro indicando el campo anidado. Pydantic muestra la ruta completa: `model -&gt; test_size`.  **Pregunta 3**: B) Si escribes `\"random_forrest\"` (typo), Pydantic te avisa inmediatamente. Esto previene errores silenciosos.  **Escenario de Debugging**:  Pydantic mostrar\u00e1 **2 errores**: 1. `epochs`: Input should be a valid integer, unable to parse string as an integer 2. `learning_rate`: Input should be greater than or equal to 0  Ambos errores se reportan juntos, no uno a la vez.  <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#13-src-layout-estructura-profesional","title":"1.3 src/ Layout: Estructura Profesional","text":""},{"location":"docs/01_PYTHON_MODERNO/#explicacion-teorica-la-casa-organizada","title":"\ud83c\udf93 Explicaci\u00f3n Te\u00f3rica: La Casa Organizada","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83c\udfe0 IMAGINA ORGANIZAR UNA CASA:                                           \u2551\n\u2551                                                                           \u2551\n\u2551  CASA DESORDENADA (c\u00f3digo en ra\u00edz):                                       \u2551\n\u2551  - Todo en el living: ropa, comida, herramientas                          \u2551\n\u2551  - Imposible encontrar algo                                               \u2551\n\u2551  - Invitas a alguien: \"perd\u00f3n por el desorden\"                            \u2551\n\u2551                                                                           \u2551\n\u2551  CASA ORGANIZADA (src/ layout):                                           \u2551\n\u2551  - Cocina para cocinar, ba\u00f1o para ba\u00f1o, closet para ropa                  \u2551\n\u2551  - Cada cosa en su lugar                                                  \u2551\n\u2551  - Invitas a alguien: \"bienvenido, si\u00e9ntate\"                              \u2551\n\u2551                                                                           \u2551\n\u2551  src/ layout = Organizaci\u00f3n profesional de c\u00f3digo                         \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#estructura-del-portafolio","title":"Estructura del Portafolio","text":"<pre><code>BankChurn-Predictor/\n\u251c\u2500\u2500 src/                          # \u2190 TODO el c\u00f3digo fuente aqu\u00ed\n\u2502   \u251c\u2500\u2500 __init__.py               # Hace src/ un paquete\n\u2502   \u2514\u2500\u2500 bankchurn/                # \u2190 El paquete principal\n\u2502       \u251c\u2500\u2500 __init__.py           # Exporta la API p\u00fablica\n\u2502       \u251c\u2500\u2500 config.py             # Configuraci\u00f3n Pydantic\n\u2502       \u251c\u2500\u2500 training.py           # Pipeline de entrenamiento\n\u2502       \u251c\u2500\u2500 evaluation.py         # M\u00e9tricas y evaluaci\u00f3n\n\u2502       \u251c\u2500\u2500 prediction.py         # Inferencia\n\u2502       \u251c\u2500\u2500 models.py             # Custom classifiers\n\u2502       \u2514\u2500\u2500 cli.py                # Interfaz de l\u00ednea de comandos\n\u2502\n\u251c\u2500\u2500 app/                          # \u2190 Aplicaciones (no es un paquete)\n\u2502   \u2514\u2500\u2500 fastapi_app.py            # API REST\n\u2502\n\u251c\u2500\u2500 tests/                        # \u2190 Tests (espejo de src/)\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py               # Fixtures compartidas\n\u2502   \u251c\u2500\u2500 test_config.py            # Tests para config.py\n\u2502   \u251c\u2500\u2500 test_training.py          # Tests para training.py\n\u2502   \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 configs/                      # \u2190 Configuraci\u00f3n externa\n\u2502   \u2514\u2500\u2500 config.yaml\n\u2502\n\u251c\u2500\u2500 data/                         # \u2190 Datos (gitignored)\n\u2502   \u2514\u2500\u2500 raw/\n\u2502       \u2514\u2500\u2500 Churn_Modelling.csv\n\u2502\n\u251c\u2500\u2500 artifacts/                    # \u2190 Artefactos generados (gitignored)\n\u2502   \u251c\u2500\u2500 model.joblib\n\u2502   \u2514\u2500\u2500 training_results.json\n\u2502\n\u251c\u2500\u2500 pyproject.toml                # \u2190 Metadata del proyecto\n\u251c\u2500\u2500 Makefile                      # \u2190 Comandos comunes\n\u251c\u2500\u2500 Dockerfile                    # \u2190 Containerizaci\u00f3n\n\u2514\u2500\u2500 README.md                     # \u2190 Documentaci\u00f3n\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#por-que-src-y-no-codigo-en-la-raiz","title":"\u00bfPor qu\u00e9 src/ y no c\u00f3digo en la ra\u00edz?","text":"<pre><code># \u274c PROBLEMA: Sin src/, Python puede importar c\u00f3digo no instalado\n# Esto causa el famoso \"funciona en mi m\u00e1quina pero no en CI\"\n\n# Estructura plana (problem\u00e1tica):\n# myproject/\n# \u251c\u2500\u2500 mymodule.py\n# \u2514\u2500\u2500 tests/\n#     \u2514\u2500\u2500 test_mymodule.py\n\n# En test_mymodule.py:\nimport mymodule  # \u2190 \u00bfDe d\u00f3nde viene? \u00bfDel directorio actual? \u00bfDe pip?\n\n# \u2705 SOLUCI\u00d3N: Con src/, el c\u00f3digo DEBE estar instalado para importar\n# myproject/\n# \u251c\u2500\u2500 src/\n# \u2502   \u2514\u2500\u2500 mymodule/\n# \u2502       \u2514\u2500\u2500 __init__.py\n# \u2514\u2500\u2500 tests/\n#     \u2514\u2500\u2500 test_mymodule.py\n\n# En test_mymodule.py:\nfrom mymodule import something  # \u2190 Solo funciona si `pip install -e .`\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#pyprojecttoml-el-corazon-del-proyecto","title":"pyproject.toml: El Coraz\u00f3n del Proyecto","text":"<pre><code># pyproject.toml - Configuraci\u00f3n completa del proyecto\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"bankchurn\"\nversion = \"1.0.0\"\ndescription = \"Bank Customer Churn Prediction System\"\nauthors = [\n    {name = \"Daniel Duque\", email = \"duque@example.com\"}\n]\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\nlicense = {text = \"MIT\"}\n\ndependencies = [\n    \"pandas&gt;=2.0.0\",\n    \"scikit-learn&gt;=1.3.0\",\n    \"pydantic&gt;=2.0.0\",\n    \"pyyaml&gt;=6.0\",\n    \"mlflow&gt;=2.9.0\",\n    \"fastapi&gt;=0.104.0\",\n    \"uvicorn&gt;=0.24.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.4.0\",\n    \"pytest-cov&gt;=4.1.0\",\n    \"black&gt;=23.0.0\",\n    \"mypy&gt;=1.7.0\",\n    \"ruff&gt;=0.1.0\",\n]\n\n[project.scripts]\nbankchurn = \"bankchurn.cli:main\"  # \u2190 Comando CLI\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# HERRAMIENTAS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]  # \u2190 Busca paquetes en src/\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\naddopts = \"-v --cov=src/bankchurn --cov-report=term-missing\"\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"tests/*\"]\n\n[tool.coverage.report]\nfail_under = 79  # \u2190 Coverage m\u00ednimo para pasar CI\n\n[tool.black]\nline-length = 100\ntarget-version = [\"py311\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#instalacion-en-modo-editable","title":"Instalaci\u00f3n en Modo Editable","text":"<pre><code># Instalar el paquete en modo editable (para desarrollo)\npip install -e .\n\n# Ahora puedes importar desde cualquier lugar\npython -c \"from bankchurn.config import BankChurnConfig; print('\u2705 Funciona!')\"\n\n# Y los tests tambi\u00e9n funcionan\npytest tests/\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-src-layout","title":"\ud83e\udde0 Mapa Mental de Conceptos: src/ Layout","text":"<pre><code>                        \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                        \u2551    ESTRUCTURA PROFESIONAL DE PROYECTO   \u2551\n                        \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                          \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                               \u25bc                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   src/ layout    \u2502             \u2502  pyproject.toml  \u2502           \u2502   Instalaci\u00f3n    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                               \u2502                              \u2502\n\u251c\u2500 src/&lt;paquete&gt;/               \u251c\u2500 [project]                    \u251c\u2500 pip install -e .\n\u251c\u2500 tests/                       \u251c\u2500 dependencies                 \u251c\u2500 modo editable\n\u251c\u2500 configs/                     \u251c\u2500 [project.scripts]            \u251c\u2500 importable\n\u251c\u2500 data/                        \u251c\u2500 [tool.pytest]                \u2514\u2500 reproducible\n\u2514\u2500 artifacts/                   \u2514\u2500 [tool.mypy]\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo src/ layout C\u00f3digo fuente en carpeta <code>src/</code> <code>src/bankchurn/training.py</code> pyproject.toml Archivo de configuraci\u00f3n del proyecto Define nombre, deps, herramientas Modo editable Instalar paquete para desarrollo <code>pip install -e .</code> init.py Marca una carpeta como paquete Python Permite imports Paquete C\u00f3digo distribuible e importable <code>from bankchurn import ...</code> Makefile Comandos comunes automatizados <code>make train</code>, <code>make test</code>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-crear-estructura-basica","title":"\ud83d\udcbb Ejercicio Puente: Crear Estructura B\u00e1sica","text":"<p>Meta: Antes de estructurar un proyecto ML completo, practica con uno simple.</p> <p>Ejercicio 1: Crear estructura m\u00ednima <pre><code># TU TAREA: Crea esta estructura desde cero\n# mylib/\n# \u251c\u2500\u2500 src/\n# \u2502   \u2514\u2500\u2500 mylib/\n# \u2502       \u251c\u2500\u2500 __init__.py\n# \u2502       \u2514\u2500\u2500 calculator.py   # funci\u00f3n add(a, b) -&gt; int\n# \u251c\u2500\u2500 tests/\n# \u2502   \u2514\u2500\u2500 test_calculator.py\n# \u2514\u2500\u2500 pyproject.toml\n\n# Pista 1: Inicia con estos comandos\nmkdir -p mylib/src/mylib mylib/tests\ntouch mylib/src/mylib/__init__.py\n</code></pre></p> <p>Ejercicio 2: Escribir pyproject.toml m\u00ednimo <pre><code># TU TAREA: Completa este pyproject.toml\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mylib\"\nversion = \"0.1.0\"\n# \u00bfQu\u00e9 m\u00e1s necesitas para que funcione?\n\n[tool.setuptools.packages.find]\n# \u00bfD\u00f3nde busca los paquetes?\n</code></pre></p> <p>Ejercicio 3: Verificar instalaci\u00f3n <pre><code># TU TAREA: Despu\u00e9s de crear la estructura\ncd mylib\npip install -e .\npython -c \"from mylib.calculator import add; print(add(2, 3))\"\n# \u00bfQu\u00e9 deber\u00edas ver? \u00bfQu\u00e9 error obtienes si algo est\u00e1 mal?\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code># Crear estructura\nmkdir -p mylib/src/mylib mylib/tests\ntouch mylib/src/mylib/__init__.py\n\n# calculator.py\ncat &gt; mylib/src/mylib/calculator.py &lt;&lt; 'EOF'\ndef add(a: int, b: int) -&gt; int:\n    \"\"\"Suma dos enteros.\"\"\"\n    return a + b\nEOF\n\n# test_calculator.py\ncat &gt; mylib/tests/test_calculator.py &lt;&lt; 'EOF'\nfrom mylib.calculator import add\n\ndef test_add():\n    assert add(2, 3) == 5\nEOF\n\n# pyproject.toml completo\ncat &gt; mylib/pyproject.toml &lt;&lt; 'EOF'\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mylib\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.10\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\nEOF\n\n# Verificar\ncd mylib\npip install -e .\npython -c \"from mylib.calculator import add; print(add(2, 3))\"  # Output: 5\npytest tests/  # Debe pasar\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-estructura-de-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Estructura de BankChurn","text":"<p>Tarea: Verificar y entender la estructura del proyecto BankChurn-Predictor.</p> <p>Paso 1: Explora la estructura existente <pre><code>cd BankChurn-Predictor\ntree -L 3 --dirsfirst\n# O si no tienes tree:\nfind . -type d -name \"__pycache__\" -prune -o -print | head -40\n</code></pre></p> <p>Paso 2: Verifica los puntos clave (checklist) <pre><code>[ ] \u00bfExiste src/bankchurn/__init__.py?\n[ ] \u00bfExiste pyproject.toml en la ra\u00edz?\n[ ] \u00bfEl pyproject.toml tiene [tool.setuptools.packages.find] where = [\"src\"]?\n[ ] \u00bfPuedes ejecutar: pip install -e . sin errores?\n[ ] \u00bfPuedes ejecutar: python -c \"from bankchurn.config import BankChurnConfig\"?\n</code></pre></p> <p>Paso 3: Si algo falla, diagnostica (pistas guiadas)</p> <pre><code># Error: \"No module named 'bankchurn'\"\n# Diagn\u00f3stico: \u00bfInstalaste en modo editable?\npip list | grep bankchurn\n# Si no aparece \u2192 pip install -e .\n\n# Error: \"ModuleNotFoundError\" en CI pero no local\n# Diagn\u00f3stico: \u00bfTu pyproject.toml tiene where = [\"src\"]?\ngrep -A2 \"packages.find\" pyproject.toml\n</code></pre> <p>\u274c NO hagas esto: - Poner c\u00f3digo Python en la ra\u00edz del proyecto - Hacer imports relativos desde scripts sueltos - Modificar PYTHONPATH manualmente</p> <p>\u2705 S\u00cd haz esto: - Todo c\u00f3digo en <code>src/&lt;paquete&gt;/</code> - Instalar siempre con <code>pip install -e .</code> - Tests que importen el paquete como lo har\u00eda un usuario</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-src-layout","title":"\u2705 Checkpoint de Conocimiento: src/ Layout","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 ponemos el c\u00f3digo en <code>src/</code> en vez de en la ra\u00edz?</p> <p>A) Es m\u00e1s r\u00e1pido de ejecutar B) Fuerza que el c\u00f3digo est\u00e9 INSTALADO para poder importarlo C) Ocupa menos espacio en disco D) Es requerido por GitHub  </p> <p>Pregunta 2: \u00bfQu\u00e9 hace <code>pip install -e .</code>?</p> <p>A) Instala el paquete en modo producci\u00f3n B) Instala el paquete de forma que los cambios se reflejen sin reinstalar C) Elimina el paquete existente D) Crea un archivo ejecutable  </p> <p>Pregunta 3: \u00bfCu\u00e1l es el prop\u00f3sito principal de <code>pyproject.toml</code>?</p> <p>A) Almacenar datos del modelo B) Definir metadata, dependencias y configuraci\u00f3n de herramientas C) Guardar logs de ejecuci\u00f3n D) Contener los tests  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Tu c\u00f3digo funciona perfecto en local.\nEn GitHub Actions ves:\n  ModuleNotFoundError: No module named 'bankchurn'\n\nEl workflow de CI tiene:\n  - name: Install\n    run: pip install -r requirements.txt\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Fuerza que el c\u00f3digo est\u00e9 INSTALADO para poder importarlo. Esto evita el problema \"funciona en mi m\u00e1quina\".  **Pregunta 2**: B) Instala el paquete de forma que los cambios se reflejen sin reinstalar. El `-e` significa \"editable\".  **Pregunta 3**: B) Definir metadata, dependencias y configuraci\u00f3n de herramientas. Es el est\u00e1ndar moderno de Python.  **Escenario de Debugging**:  - **Problema**: El CI solo instala dependencias de `requirements.txt`, pero NO instala TU paquete. - **Soluci\u00f3n**: Cambiar el workflow: <pre><code>- name: Install\n  run: pip install -e \".[dev]\"\n</code></pre> Esto instala tu paquete Y las dependencias de desarrollo.  <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#14-principios-solid-para-ml","title":"1.4 Principios SOLID para ML","text":""},{"location":"docs/01_PYTHON_MODERNO/#explicacion-teorica-un-modulo-una-tarea","title":"\ud83c\udf93 Explicaci\u00f3n Te\u00f3rica: Un M\u00f3dulo, Una Tarea","text":"<pre><code># \u274c ANTES: Un archivo hace TODO\n# training.py (500 l\u00edneas)\ndef train_model(data_path, config_path, output_path):\n    # Carga datos (l\u00edneas 1-50)\n    # Limpia datos (l\u00edneas 51-100)\n    # Feature engineering (l\u00edneas 101-200)\n    # Entrena modelo (l\u00edneas 201-300)\n    # Eval\u00faa modelo (l\u00edneas 301-400)\n    # Guarda artefactos (l\u00edneas 401-450)\n    # Loguea a MLflow (l\u00edneas 451-500)\n    pass\n\n# \u2705 DESPU\u00c9S: Cada archivo tiene UNA responsabilidad\n# src/bankchurn/\n# \u251c\u2500\u2500 data.py         \u2192 Solo carga y valida datos\n# \u251c\u2500\u2500 features.py     \u2192 Solo feature engineering\n# \u251c\u2500\u2500 training.py     \u2192 Solo entrenamiento\n# \u251c\u2500\u2500 evaluation.py   \u2192 Solo m\u00e9tricas\n# \u2514\u2500\u2500 prediction.py   \u2192 Solo inferencia\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#codigo-real-del-portafolio","title":"C\u00f3digo Real del Portafolio","text":"<pre><code># src/bankchurn/training.py - SOLO se encarga de entrenar\nclass ChurnTrainer:\n    \"\"\"Training pipeline - Single Responsibility.\"\"\"\n\n    def __init__(self, config: BankChurnConfig):\n        self.config = config\n\n    def load_data(self, path: Path) -&gt; pd.DataFrame:\n        \"\"\"Delega a m\u00f3dulo de datos.\"\"\"\n        pass\n\n    def prepare_features(self, df: pd.DataFrame) -&gt; Tuple[pd.DataFrame, pd.Series]:\n        \"\"\"Prepara X e y.\"\"\"\n        pass\n\n    def build_pipeline(self) -&gt; Pipeline:\n        \"\"\"Construye el pipeline sklearn.\"\"\"\n        pass\n\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; None:\n        \"\"\"Entrena el modelo.\"\"\"\n        pass\n\n    def cross_validate(self, X: pd.DataFrame, y: pd.Series) -&gt; Dict[str, float]:\n        \"\"\"Valida con CV.\"\"\"\n        pass\n\n# src/bankchurn/evaluation.py - SOLO se encarga de evaluar\ndef evaluate_model(\n    model: Pipeline,\n    X_test: pd.DataFrame,\n    y_test: pd.Series\n) -&gt; Dict[str, float]:\n    \"\"\"Calcula m\u00e9tricas - Single Responsibility.\"\"\"\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    return {\n        \"accuracy\": accuracy_score(y_test, y_pred),\n        \"precision\": precision_score(y_test, y_pred),\n        \"recall\": recall_score(y_test, y_pred),\n        \"f1\": f1_score(y_test, y_pred),\n        \"roc_auc\": roc_auc_score(y_test, y_proba),\n    }\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-solid","title":"\ud83e\udde0 Mapa Mental de Conceptos: SOLID","text":"<pre><code>                   \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                   \u2551    PRINCIPIOS SOLID PARA ML          \u2551\n                   \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                           \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u25bc              \u25bc              \u25bc               \u25bc              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    S    \u2502    \u2502    O    \u2502    \u2502    L    \u2502     \u2502    I    \u2502    \u2502    D    \u2502\n\u2502 Single  \u2502    \u2502  Open   \u2502    \u2502 Liskov  \u2502     \u2502Interface\u2502    \u2502  Dep.   \u2502\n\u2502 Respons \u2502    \u2502 Closed  \u2502    \u2502  Subst  \u2502     \u2502  Segr   \u2502    \u2502  Inv    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502              \u2502              \u2502               \u2502              \u2502\nUna clase      Extender sin   Subclases       Interfaces      Depender de\nuna tarea      modificar      sustituibles    peque\u00f1as        abstracciones\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Principio Significado en ML Ejemplo S - Single Responsibility Un m\u00f3dulo = una tarea <code>data.py</code>, <code>training.py</code>, <code>evaluation.py</code> separados O - Open/Closed Extensible sin modificar A\u00f1adir modelo nuevo sin tocar Trainer L - Liskov Substitution Subclases intercambiables <code>ChurnTrainer</code> funciona donde esperes <code>BaseTrainer</code> I - Interface Segregation Interfaces peque\u00f1as y espec\u00edficas No forzar m\u00e9todos que no se usan D - Dependency Inversion Depender de abstracciones Inyectar modelo, no hardcodear"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-aplicar-single-responsibility","title":"\ud83d\udcbb Ejercicio Puente: Aplicar Single Responsibility","text":"<p>Meta: Antes de refactorizar c\u00f3digo ML complejo, practica separando responsabilidades simples.</p> <p>Ejercicio 1: Separar funciones mezcladas <pre><code># \u274c ANTES: Una funci\u00f3n hace TODO\ndef process_and_train(data_path, output_path):\n    # Carga datos\n    df = pd.read_csv(data_path)\n    # Limpia\n    df = df.dropna()\n    # Entrena\n    model = RandomForestClassifier()\n    X, y = df.drop(\"target\", axis=1), df[\"target\"]\n    model.fit(X, y)\n    # Guarda\n    joblib.dump(model, output_path)\n    return model\n\n# \u2705 TU TAREA: Separa en 3 funciones con responsabilidad \u00fanica\n# 1. load_data(path) -&gt; DataFrame\n# 2. train_model(X, y) -&gt; modelo\n# 3. save_model(model, path) -&gt; None\n</code></pre></p> <p>Ejercicio 2: Identificar violaciones <pre><code># \u00bfQu\u00e9 principio SOLID viola este c\u00f3digo?\nclass DataProcessor:\n    def load_csv(self, path): ...\n    def load_json(self, path): ...\n    def clean_data(self, df): ...\n    def train_model(self, X, y): ...\n    def evaluate_model(self, model, X, y): ...\n    def save_to_database(self, data): ...\n    def send_email_report(self, metrics): ...\n\n# TU TAREA: \u00bfCu\u00e1ntas responsabilidades tiene? \u00bfC\u00f3mo lo separar\u00edas?\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code># Ejercicio 1: Funciones separadas\ndef load_data(path: Path) -&gt; pd.DataFrame:\n    \"\"\"Solo carga y limpia datos.\"\"\"\n    df = pd.read_csv(path)\n    return df.dropna()\n\ndef train_model(X: pd.DataFrame, y: pd.Series) -&gt; BaseEstimator:\n    \"\"\"Solo entrena el modelo.\"\"\"\n    model = RandomForestClassifier()\n    model.fit(X, y)\n    return model\n\ndef save_model(model: BaseEstimator, path: Path) -&gt; None:\n    \"\"\"Solo guarda el modelo.\"\"\"\n    joblib.dump(model, path)\n\n# Ejercicio 2: Viola Single Responsibility\n# Tiene 4+ responsabilidades:\n# 1. Carga de datos (load_csv, load_json)\n# 2. Limpieza (clean_data)\n# 3. ML (train_model, evaluate_model)\n# 4. Persistencia (save_to_database)\n# 5. Notificaciones (send_email_report)\n\n# Separaci\u00f3n correcta:\nclass DataLoader: ...      # Solo cargar\nclass DataCleaner: ...     # Solo limpiar\nclass ModelTrainer: ...    # Solo entrenar/evaluar\nclass DatabaseWriter: ...  # Solo persistir\nclass EmailNotifier: ...   # Solo notificar\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-solid-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: SOLID en BankChurn","text":"<p>Tarea: Verificar que el c\u00f3digo de BankChurn-Predictor sigue principios SOLID.</p> <p>Paso 1: Analiza la estructura actual <pre><code>ls -la BankChurn-Predictor/src/bankchurn/\n# \u00bfCada archivo tiene UNA responsabilidad?\n</code></pre></p> <p>Paso 2: Verifica Single Responsibility (pistas guiadas) <pre><code>Archivo           | \u00bfResponsabilidad \u00fanica?\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nconfig.py         | \u2705 Solo configuraci\u00f3n\ndata.py           | \u00bfSolo carga datos?\ntraining.py       | \u00bfSolo entrena? \u00bfO tambi\u00e9n eval\u00faa?\nevaluation.py     | \u00bfSolo m\u00e9tricas?\nprediction.py     | \u00bfSolo inferencia?\n</code></pre></p> <p>Paso 3: Si encuentras violaciones, prop\u00f3n refactor <pre><code># Ejemplo de violaci\u00f3n com\u00fan:\n# training.py que tambi\u00e9n guarda artefactos y loguea a MLflow\n\n# Pregunta: \u00bfC\u00f3mo separar\u00edas estas responsabilidades?\n# Pista: Considera un archivo artifacts.py y tracking.py\n</code></pre></p> <p>\u274c NO hagas esto: - Crear archivos de 1 l\u00ednea solo \"por seguir SOLID\" - Abstraer prematuramente (YAGNI) - Ignorar la cohesi\u00f3n l\u00f3gica</p> <p>\u2705 S\u00cd haz esto: - Archivos de 50-300 l\u00edneas con prop\u00f3sito claro - Nombres que reflejen la responsabilidad - Poder describir cada m\u00f3dulo en UNA frase</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-solid","title":"\u2705 Checkpoint de Conocimiento: SOLID","text":"<p>Pregunta 1: \u00bfQu\u00e9 significa \"Single Responsibility\" en el contexto de ML?</p> <p>A) Cada funci\u00f3n debe tener solo 1 l\u00ednea B) Cada m\u00f3dulo debe tener UNA raz\u00f3n para cambiar C) Solo una persona puede modificar el c\u00f3digo D) Cada clase debe heredar de una sola clase base  </p> <p>Pregunta 2: Si quieres a\u00f1adir un nuevo modelo (XGBoost) a tu pipeline, \u00bfqu\u00e9 principio te ayuda a hacerlo sin modificar c\u00f3digo existente?</p> <p>A) Single Responsibility B) Open/Closed C) Liskov Substitution D) Interface Segregation  </p> <p>Pregunta 3: \u00bfPor qu\u00e9 separamos <code>data.py</code>, <code>training.py</code> y <code>evaluation.py</code>?</p> <p>A) Para tener m\u00e1s archivos en el proyecto B) Porque cada uno tiene UNA responsabilidad y cambia por razones diferentes C) Porque Python lo requiere D) Para que el c\u00f3digo sea m\u00e1s lento  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code># Tu compa\u00f1ero escribi\u00f3 este c\u00f3digo:\nclass MLPipeline:\n    def run(self, data_path, config_path, model_path, metrics_path, \n            mlflow_uri, slack_webhook, email_list, s3_bucket):\n        # 500 l\u00edneas de c\u00f3digo que hacen TODO\n        ...\n</code></pre> <p>\u00bfQu\u00e9 problemas ves? \u00bfC\u00f3mo lo refactorizar\u00edas siguiendo SOLID?</p> \ufffd\ufffd Ver Respuestas  **Pregunta 1**: B) Cada m\u00f3dulo debe tener UNA raz\u00f3n para cambiar. Si cambian las m\u00e9tricas, solo tocas `evaluation.py`.  **Pregunta 2**: B) Open/Closed. El sistema est\u00e1 abierto a extensi\u00f3n (nuevo modelo) pero cerrado a modificaci\u00f3n (no tocas el Trainer existente).  **Pregunta 3**: B) Porque cada uno tiene UNA responsabilidad y cambia por razones diferentes.  **Escenario de Debugging**:  **Problemas:** 1. Viola Single Responsibility (hace TODO) 2. Viola Interface Segregation (par\u00e1metros que no siempre se usan) 3. 500 l\u00edneas = imposible de testear  **Refactor:** <pre><code>class DataLoader: ...\nclass FeatureEngineer: ...\nclass ModelTrainer: ...\nclass MetricsCalculator: ...\nclass MLflowTracker: ...\nclass SlackNotifier: ...\nclass S3Uploader: ...\n\n# Orquestador ligero que usa los componentes\nclass Pipeline:\n    def __init__(self, loader, trainer, tracker, ...):\n        self.loader = loader\n        ...\n</code></pre> <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#15-oop-para-ml-protocolos-y-clases-abstractas","title":"1.5 OOP para ML: Protocolos y Clases Abstractas","text":"<p>CR\u00cdTICO: Sin entender OOP profesional, NO podr\u00e1s leer el c\u00f3digo del Portafolio.</p>"},{"location":"docs/01_PYTHON_MODERNO/#el-problema-codigo-no-intercambiable","title":"El Problema: C\u00f3digo No Intercambiable","text":"<pre><code># \u274c C\u00d3DIGO JUNIOR: Cada trainer tiene API diferente\nclass TrainerA:\n    def entrenar(self, X, y): ...  # espa\u00f1ol\n    def predecir(self, X): ...\n\nclass TrainerB:\n    def fit_model(self, features, labels): ...  # nombres diferentes\n    def get_predictions(self, features): ...\n\n# \u00bfC\u00f3mo escribo c\u00f3digo gen\u00e9rico que funcione con ambos?\n# Imposible sin reescribir todo.\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#la-solucion-protocol-y-abc","title":"La Soluci\u00f3n: Protocol y ABC","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# PROTOCOL: Duck Typing verificable por mypy (para sklearn y librer\u00edas externas)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nfrom typing import Protocol, runtime_checkable\nfrom numpy.typing import ArrayLike\n\n@runtime_checkable\nclass Predictor(Protocol):\n    \"\"\"Si tiene fit() y predict() con estas firmas, ES un Predictor.\"\"\"\n\n    def fit(self, X: ArrayLike, y: ArrayLike) -&gt; \"Predictor\": ...\n    def predict(self, X: ArrayLike) -&gt; ArrayLike: ...\n\n# sklearn cumple autom\u00e1ticamente sin modificar nada:\nfrom sklearn.ensemble import RandomForestClassifier\nassert isinstance(RandomForestClassifier(), Predictor)  # True!\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# ABC: Contrato que OBLIGA implementaci\u00f3n (para TUS clases)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nfrom abc import ABC, abstractmethod\nimport pandas as pd\n\nclass BaseTrainer(ABC):\n    \"\"\"Clase base para todos los trainers del portafolio.\n\n    BankChurn, CarVision y TelecomAI DEBEN implementar estos m\u00e9todos.\n    Si no lo hacen, Python da error al instanciar.\n    \"\"\"\n\n    @abstractmethod\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"BaseTrainer\":\n        \"\"\"Entrena el modelo.\"\"\"\n        pass\n\n    @abstractmethod\n    def predict(self, X: pd.DataFrame) -&gt; pd.Series:\n        \"\"\"Genera predicciones.\"\"\"\n        pass\n\n    @abstractmethod\n    def evaluate(self, X: pd.DataFrame, y: pd.Series) -&gt; dict[str, float]:\n        \"\"\"Eval\u00faa el modelo.\"\"\"\n        pass\n\n    # M\u00e9todo concreto que usa los abstractos\n    def fit_and_evaluate(\n        self, \n        X_train: pd.DataFrame, y_train: pd.Series,\n        X_test: pd.DataFrame, y_test: pd.Series\n    ) -&gt; dict[str, float]:\n        \"\"\"Entrena y eval\u00faa en un paso.\"\"\"\n        self.fit(X_train, y_train)\n        return self.evaluate(X_test, y_test)\n\n\n# Implementaci\u00f3n concreta:\nclass ChurnTrainer(BaseTrainer):\n    \"\"\"Trainer de BankChurn - DEBE implementar fit, predict, evaluate.\"\"\"\n\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"ChurnTrainer\":\n        self._pipeline = self._build_pipeline()\n        self._pipeline.fit(X, y)\n        return self\n\n    def predict(self, X: pd.DataFrame) -&gt; pd.Series:\n        return pd.Series(self._pipeline.predict(X))\n\n    def evaluate(self, X: pd.DataFrame, y: pd.Series) -&gt; dict[str, float]:\n        y_pred = self.predict(X)\n        return {\"accuracy\": accuracy_score(y, y_pred)}\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-oop-para-ml","title":"\ud83e\udde0 Mapa Mental de Conceptos: OOP para ML","text":"<pre><code>                        \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                        \u2551   OOP PROFESIONAL PARA ML                \u2551\n                        \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                          \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u25bc                             \u25bc                             \u25bc\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502     Protocol     \u2502          \u2502       ABC        \u2502         \u2502   Composici\u00f3n    \u2502\n  \u2502   (Duck Typing)  \u2502          \u2502  (Herencia)      \u2502         \u2502   vs Herencia    \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                             \u2502                            \u2502\n  \u251c\u2500 @runtime_checkable        \u251c\u2500 @abstractmethod            \u251c\u2500 Inyecci\u00f3n\n  \u251c\u2500 Verificable por mypy      \u251c\u2500 Fuerza implementaci\u00f3n      \u251c\u2500 Flexibilidad\n  \u251c\u2500 No requiere herencia      \u251c\u2500 Clase base compartida      \u2514\u2500 Testeable\n  \u2514\u2500 Ideal para sklearn        \u2514\u2500 Ideal para TUS clases\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Cu\u00e1ndo Usar Protocol Interfaz impl\u00edcita (duck typing) Para compatibilidad con sklearn ABC Abstract Base Class Para TUS clases base @abstractmethod M\u00e9todo que DEBE implementarse Forzar contratos @runtime_checkable Verificar en tiempo de ejecuci\u00f3n <code>isinstance()</code> con Protocol Composici\u00f3n \"tiene un\" vs \"es un\" Preferir sobre herencia Inyecci\u00f3n Pasar dependencias como par\u00e1metros Testing y flexibilidad"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-crear-clase-abstracta","title":"\ud83d\udcbb Ejercicio Puente: Crear Clase Abstracta","text":"<p>Meta: Antes de crear jerarqu\u00edas de Trainers, practica con abstracciones simples.</p> <p>Ejercicio 1: Definir un Protocol <pre><code>from typing import Protocol, runtime_checkable\n\n# \u2705 TU TAREA: Crea un Protocol \"Serializable\" que requiera:\n# - save(path: Path) -&gt; None\n# - load(path: Path) -&gt; \"Serializable\"\n\n@runtime_checkable\nclass Serializable(Protocol):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> <p>Ejercicio 2: Crear una ABC <pre><code>from abc import ABC, abstractmethod\n\n# \u2705 TU TAREA: Crea una ABC \"BasePreprocessor\" con:\n# - fit(X) -&gt; \"BasePreprocessor\" (abstracto)\n# - transform(X) -&gt; ndarray (abstracto)\n# - fit_transform(X) -&gt; ndarray (concreto, usa fit y transform)\n\nclass BasePreprocessor(ABC):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> <p>Ejercicio 3: Implementar la ABC <pre><code># \u2705 TU TAREA: Crea \"StandardScalerCustom\" que:\n# - Hereda de BasePreprocessor\n# - Implementa fit() guardando media y std\n# - Implementa transform() normalizando datos\n\nclass StandardScalerCustom(BasePreprocessor):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code>from typing import Protocol, runtime_checkable\nfrom abc import ABC, abstractmethod\nfrom pathlib import Path\nimport numpy as np\nfrom numpy.typing import NDArray\n\n# Ejercicio 1: Protocol\n@runtime_checkable\nclass Serializable(Protocol):\n    def save(self, path: Path) -&gt; None: ...\n    def load(self, path: Path) -&gt; \"Serializable\": ...\n\n# Ejercicio 2: ABC\nclass BasePreprocessor(ABC):\n    @abstractmethod\n    def fit(self, X: NDArray) -&gt; \"BasePreprocessor\":\n        pass\n\n    @abstractmethod\n    def transform(self, X: NDArray) -&gt; NDArray:\n        pass\n\n    def fit_transform(self, X: NDArray) -&gt; NDArray:\n        \"\"\"M\u00e9todo concreto que usa los abstractos.\"\"\"\n        return self.fit(X).transform(X)\n\n# Ejercicio 3: Implementaci\u00f3n\nclass StandardScalerCustom(BasePreprocessor):\n    def __init__(self):\n        self.mean_: NDArray | None = None\n        self.std_: NDArray | None = None\n\n    def fit(self, X: NDArray) -&gt; \"StandardScalerCustom\":\n        self.mean_ = X.mean(axis=0)\n        self.std_ = X.std(axis=0)\n        return self\n\n    def transform(self, X: NDArray) -&gt; NDArray:\n        if self.mean_ is None:\n            raise ValueError(\"Fit first!\")\n        return (X - self.mean_) / self.std_\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-basetrainer-compartido","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: BaseTrainer Compartido","text":"<p>Tarea: Crear una clase base que los 3 proyectos del portafolio puedan usar.</p> <p>Paso 1: Dise\u00f1a la interfaz com\u00fan <pre><code># \u00bfQu\u00e9 m\u00e9todos TODOS los trainers deben tener?\n# - fit(X, y) \u2192 entrena el modelo\n# - predict(X) \u2192 genera predicciones\n# - evaluate(X, y) \u2192 calcula m\u00e9tricas\n# - save(path) \u2192 guarda el modelo\n# - load(path) \u2192 carga el modelo\n</code></pre></p> <p>Paso 2: Crea la ABC (pistas guiadas) <pre><code># common_utils/base.py\n\nfrom abc import ABC, abstractmethod\nimport pandas as pd\nfrom pathlib import Path\n\nclass BaseTrainer(ABC):\n    \"\"\"Clase base para todos los trainers del portafolio.\"\"\"\n\n    @abstractmethod\n    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; \"BaseTrainer\":\n        # \u00bfQu\u00e9 debe hacer? Solo la firma, no implementaci\u00f3n\n        ...\n\n    @abstractmethod\n    def predict(self, X: pd.DataFrame) -&gt; pd.Series:\n        ...\n\n    # \u00bfQu\u00e9 otros m\u00e9todos abstractos necesitas?\n    # \u00bfHay m\u00e9todos concretos que puedas implementar aqu\u00ed?\n</code></pre></p> <p>Paso 3: Implementa en cada proyecto <pre><code># BankChurn-Predictor/src/bankchurn/training.py\nfrom common_utils.base import BaseTrainer\n\nclass ChurnTrainer(BaseTrainer):\n    # \u00bfQu\u00e9 m\u00e9todos DEBES implementar?\n    # \u00bfQu\u00e9 pasa si olvidas implementar uno?\n    pass\n</code></pre></p> <p>\u274c NO hagas esto: - Crear jerarqu\u00edas profundas (m\u00e1s de 2 niveles) - Usar herencia cuando composici\u00f3n es mejor - Forzar m\u00e9todos que no todos usan</p> <p>\u2705 S\u00cd haz esto: - Interfaces peque\u00f1as y cohesivas - Preferir composici\u00f3n sobre herencia - Usar Protocol para compatibilidad con sklearn</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-oop-para-ml","title":"\u2705 Checkpoint de Conocimiento: OOP para ML","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la diferencia entre Protocol y ABC?</p> <p>A) Protocol es m\u00e1s r\u00e1pido B) Protocol no requiere herencia, ABC s\u00ed C) ABC es para Python 2 D) No hay diferencia  </p> <p>Pregunta 2: \u00bfPor qu\u00e9 sklearn usa duck typing en vez de herencia estricta?</p> <p>A) Es m\u00e1s f\u00e1cil de programar B) Permite que CUALQUIER clase con <code>fit()</code> y <code>predict()</code> funcione C) Es requerido por Python D) Ocupa menos memoria  </p> <p>Pregunta 3: \u00bfQu\u00e9 pasa si intentas instanciar una ABC sin implementar todos los m\u00e9todos abstractos?</p> <p>A) Funciona con valores por defecto B) Python lanza TypeError inmediatamente C) Solo falla cuando llamas al m\u00e9todo D) mypy lo ignora  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>class BaseModel(ABC):\n    @abstractmethod\n    def fit(self, X, y): ...\n    @abstractmethod\n    def predict(self, X): ...\n\nclass MyModel(BaseModel):\n    def fit(self, X, y):\n        self.model = RandomForestClassifier()\n        self.model.fit(X, y)\n        return self\n\n    # Olvid\u00e9 implementar predict()\n\nmodel = MyModel()  # \u2190 \u00bfQu\u00e9 error ver\u00e1s?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Protocol no requiere herencia, ABC s\u00ed. Protocol verifica por \"forma\" (duck typing).  **Pregunta 2**: B) Permite que CUALQUIER clase con `fit()` y `predict()` funcione. No importa de qu\u00e9 clase herede.  **Pregunta 3**: B) Python lanza TypeError inmediatamente al intentar instanciar.  **Escenario de Debugging**:  <pre><code>TypeError: Can't instantiate abstract class MyModel with abstract method predict\n</code></pre> El error ocurre EN LA INSTANCIACI\u00d3N, no despu\u00e9s. Esto es intencional: falla r\u00e1pido.  **Soluci\u00f3n**: Implementar el m\u00e9todo faltante: <pre><code>def predict(self, X):\n    return self.model.predict(X)\n</code></pre> <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#16-pandera-validacion-de-dataframes","title":"1.6 Pandera: Validaci\u00f3n de DataFrames","text":"<p>CR\u00cdTICO: Sin Pandera, los errores de datos aparecen en sklearn, no donde ocurrieron.</p>"},{"location":"docs/01_PYTHON_MODERNO/#el-problema-dataframes-que-mienten","title":"El Problema: DataFrames que Mienten","text":"<pre><code># \u274c C\u00d3DIGO JUNIOR: Asume que el DataFrame es correcto\ndef train_model(df: pd.DataFrame) -&gt; Pipeline:\n    X = df.drop(\"Exited\", axis=1)  # \u00bfY si \"Exited\" no existe?\n    y = df[\"Exited\"]               # \u00bfY si tiene valores como 2, -1, None?\n\n    pipeline.fit(X, y)\n    return pipeline\n\n# Todo parece funcionar... hasta que llegan datos corruptos:\nbad_data = pd.DataFrame({\n    \"Age\": [-5, 25, 200],        # Edad negativa y 200 a\u00f1os\n    \"Balance\": [1000, -500, 0],  # Balance negativo\n    \"Exited\": [0, 2, None],      # Valor 2 y None (no binario)\n})\nmodel = train_model(bad_data)  # NO DA ERROR, pero modelo es basura\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#la-solucion-pandera-schema","title":"La Soluci\u00f3n: Pandera Schema","text":"<pre><code>import pandera as pa\nfrom pandera.typing import DataFrame, Series\n\nclass BankChurnSchema(pa.DataFrameModel):\n    \"\"\"Schema para datos de Bank Churn - producci\u00f3n.\"\"\"\n\n    CreditScore: Series[int] = pa.Field(ge=300, le=850, description=\"FICO score\")\n    Age: Series[int] = pa.Field(ge=18, le=100, description=\"Edad del cliente\")\n    Balance: Series[float] = pa.Field(ge=0, description=\"Balance en cuenta\")\n    NumOfProducts: Series[int] = pa.Field(ge=1, le=4)\n    Exited: Series[int] = pa.Field(isin=[0, 1], description=\"Target binario\")\n\n    class Config:\n        strict = True   # Rechaza columnas extra\n        coerce = True   # Convierte tipos autom\u00e1ticamente\n\n\n@pa.check_types  # Decorador que valida entrada autom\u00e1ticamente\ndef train_model(df: DataFrame[BankChurnSchema]) -&gt; Pipeline:\n    \"\"\"DataFrame GARANTIZADO v\u00e1lido por Pandera.\"\"\"\n    X = df.drop(\"Exited\", axis=1)\n    y = df[\"Exited\"]\n    # Ahora podemos confiar en que los datos son correctos\n    ...\n\n\n# Error CLARO si datos son inv\u00e1lidos:\n# SchemaError: Column 'Age' failed check: greater_than_or_equal_to(18)\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#schemas-del-portafolio","title":"Schemas del Portafolio","text":"<pre><code># src/bankchurn/schemas.py\n\nclass RawDataSchema(pa.DataFrameModel):\n    \"\"\"Schema permisivo para datos crudos (permite nulos).\"\"\"\n    CreditScore: Series[float] = pa.Field(nullable=True)\n    Age: Series[float] = pa.Field(nullable=True, ge=0)\n    class Config:\n        strict = False  # Permite columnas extra (RowNumber, etc.)\n\n\nclass ProcessedDataSchema(pa.DataFrameModel):\n    \"\"\"Schema estricto para datos listos para entrenar.\"\"\"\n    CreditScore: Series[int] = pa.Field(ge=300, le=850)\n    Age: Series[int] = pa.Field(ge=18, le=100)\n    Exited: Series[int] = pa.Field(isin=[0, 1])\n    class Config:\n        strict = True  # No permite columnas extra\n\n\n@pa.check_types\ndef preprocess(raw: DataFrame[RawDataSchema]) -&gt; DataFrame[ProcessedDataSchema]:\n    \"\"\"Pipeline validado: entrada permisiva, salida estricta.\"\"\"\n    df = raw.dropna()\n    df = df.drop(columns=[\"RowNumber\", \"CustomerId\", \"Surname\"])\n    return df\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#mapa-mental-de-conceptos-pandera","title":"\ud83e\udde0 Mapa Mental de Conceptos: Pandera","text":"<pre><code>                         \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                         \u2551   PANDERA: VALIDACI\u00d3N DE DATAFRAMES    \u2551\n                         \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                           \u2502\n           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n           \u25bc                               \u25bc                              \u25bc\n \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n \u2502  DataFrameModel  \u2502            \u2502     pa.Field     \u2502           \u2502    Decoradores   \u2502\n \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                               \u2502                              \u2502\n \u251c\u2500 Series[tipo]                 \u251c\u2500 ge, le (rangos)            \u251c\u2500 @pa.check_types\n \u251c\u2500 Config.strict                \u251c\u2500 isin (valores)             \u251c\u2500 @pa.check()\n \u251c\u2500 Config.coerce                \u251c\u2500 nullable                   \u2514\u2500 SchemaError\n \u2514\u2500 Herencia de schemas          \u2514\u2500 regex, custom\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo DataFrameModel Define estructura esperada del DF Columnas, tipos, restricciones Series[type] Tipo de cada columna <code>Series[int]</code>, <code>Series[float]</code> pa.Field Restricciones en columna <code>ge=0</code>, <code>le=100</code>, <code>isin=[0,1]</code> strict=True Rechaza columnas extra Solo las definidas coerce=True Convierte tipos autom\u00e1ticamente <code>\"42\"</code> \u2192 <code>42</code> @pa.check_types Valida entrada/salida de funci\u00f3n Decorador m\u00e1gico SchemaError Error cuando datos inv\u00e1lidos Mensaje claro"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-puente-validacion-basica-con-pandera","title":"\ufffd\ufffd Ejercicio Puente: Validaci\u00f3n B\u00e1sica con Pandera","text":"<p>Meta: Antes de validar datos ML complejos, practica con schemas simples.</p> <p>Ejercicio 1: Schema b\u00e1sico <pre><code>import pandera as pa\nfrom pandera.typing import Series\n\n# \u2705 TU TAREA: Crea un schema \"PersonSchema\" con:\n# - name: str (no nulo)\n# - age: int (entre 0 y 150)\n# - email: str (debe contener \"@\")\n\nclass PersonSchema(pa.DataFrameModel):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> <p>Ejercicio 2: Schema con validaci\u00f3n personalizada <pre><code># \u2705 TU TAREA: Crea un schema \"TransactionSchema\" con:\n# - amount: float (positivo)\n# - currency: str (solo \"USD\", \"EUR\", \"MXN\")\n# - timestamp: datetime\n\nclass TransactionSchema(pa.DataFrameModel):\n    # ... tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre></p> <p>Ejercicio 3: Usar @pa.check_types <pre><code>from pandera.typing import DataFrame\n\n# \u2705 TU TAREA: Decora esta funci\u00f3n para validar entrada y salida\n# Entrada: DataFrame[PersonSchema]\n# Salida: DataFrame con personas mayores de 18\n\ndef filter_adults(df):\n    return df[df[\"age\"] &gt;= 18]\n</code></pre></p> \ud83d\udd0d Ver Soluciones <pre><code>import pandera as pa\nfrom pandera.typing import Series, DataFrame\nfrom datetime import datetime\n\n# Ejercicio 1\nclass PersonSchema(pa.DataFrameModel):\n    name: Series[str] = pa.Field(nullable=False)\n    age: Series[int] = pa.Field(ge=0, le=150)\n    email: Series[str] = pa.Field(regex=r\".*@.*\")\n\n# Ejercicio 2\nclass TransactionSchema(pa.DataFrameModel):\n    amount: Series[float] = pa.Field(gt=0)\n    currency: Series[str] = pa.Field(isin=[\"USD\", \"EUR\", \"MXN\"])\n    timestamp: Series[datetime]\n\n# Ejercicio 3\nclass AdultSchema(PersonSchema):\n    age: Series[int] = pa.Field(ge=18, le=150)\n\n@pa.check_types\ndef filter_adults(df: DataFrame[PersonSchema]) -&gt; DataFrame[AdultSchema]:\n    return df[df[\"age\"] &gt;= 18]\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#practica-del-portafolio-pandera-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Pandera en BankChurn","text":"<p>Tarea: Implementar validaci\u00f3n de datos con Pandera en BankChurn-Predictor.</p> <p>Paso 1: Identifica los datos que necesitan validaci\u00f3n <pre><code># Revisa las columnas del dataset\nhead -1 BankChurn-Predictor/data/raw/Churn_Modelling.csv\n</code></pre></p> <p>Paso 2: Define schemas para cada etapa (pistas guiadas)</p> <pre><code># src/bankchurn/schemas.py\n\nimport pandera as pa\nfrom pandera.typing import Series\n\nclass RawChurnSchema(pa.DataFrameModel):\n    \"\"\"Schema permisivo para datos crudos.\"\"\"\n    # CreditScore: \u00bfQu\u00e9 rango es v\u00e1lido? (FICO: 300-850)\n    # Age: \u00bfPuede ser negativo? \u00bfCu\u00e1l es el m\u00e1ximo razonable?\n    # Balance: \u00bfPuede ser negativo?\n    # Exited: \u00bfQu\u00e9 valores son v\u00e1lidos? (0, 1)\n\n    class Config:\n        strict = False  # \u00bfPor qu\u00e9 False aqu\u00ed?\n\nclass ProcessedChurnSchema(pa.DataFrameModel):\n    \"\"\"Schema estricto para datos listos para entrenar.\"\"\"\n    # Mismos campos pero:\n    # - Sin nullable\n    # - Rangos m\u00e1s estrictos\n\n    class Config:\n        strict = True  # \u00bfPor qu\u00e9 True aqu\u00ed?\n</code></pre> <p>Paso 3: Aplica validaci\u00f3n en el pipeline <pre><code>@pa.check_types\ndef load_and_validate(path: Path) -&gt; DataFrame[RawChurnSchema]:\n    # \u00bfQu\u00e9 error ver\u00e1s si los datos son inv\u00e1lidos?\n    pass\n\n@pa.check_types\ndef preprocess(raw: DataFrame[RawChurnSchema]) -&gt; DataFrame[ProcessedChurnSchema]:\n    # \u00bfQu\u00e9 transformaciones necesitas?\n    pass\n</code></pre></p> <p>\u274c NO hagas esto: - Ignorar SchemaError y continuar - Poner restricciones demasiado estrictas en datos crudos - Validar solo en desarrollo, no en producci\u00f3n</p> <p>\u2705 S\u00cd haz esto: - Schema permisivo para entrada, estricto para salida - Documentar cada restricci\u00f3n - Incluir validaci\u00f3n en tests</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-de-conocimiento-pandera","title":"\u2705 Checkpoint de Conocimiento: Pandera","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la ventaja principal de Pandera sobre validar manualmente?</p> <p>A) Es m\u00e1s r\u00e1pido en ejecuci\u00f3n B) Los errores aparecen EN LA CARGA, no en sklearn despu\u00e9s C) Ocupa menos memoria D) Es requerido por pandas  </p> <p>Pregunta 2: \u00bfQu\u00e9 hace <code>strict=True</code> en Config?</p> <p>A) Hace la validaci\u00f3n m\u00e1s lenta pero segura B) Rechaza DataFrames con columnas NO definidas en el schema C) Convierte tipos autom\u00e1ticamente D) Requiere que todos los valores sean no nulos  </p> <p>Pregunta 3: \u00bfPara qu\u00e9 sirve <code>@pa.check_types</code>?</p> <p>A) Solo documenta los tipos B) Valida entrada Y salida de la funci\u00f3n autom\u00e1ticamente C) Hace la funci\u00f3n m\u00e1s r\u00e1pida D) Solo funciona en clases  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>class ChurnSchema(pa.DataFrameModel):\n    CreditScore: Series[int] = pa.Field(ge=300, le=850)\n    Age: Series[int] = pa.Field(ge=18, le=100)\n    Exited: Series[int] = pa.Field(isin=[0, 1])\n\n# Cargas datos y obtienes:\n# SchemaError: Column 'Age' failed element-wise validator 0:\n#   &lt;Check greater_than_or_equal_to: greater_than_or_equal_to(18)&gt;\n# failure cases:\n#      index  Age\n#   0    127   15\n#   1    890   17\n</code></pre> <p>\u00bfQu\u00e9 significa este error y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Los errores aparecen EN LA CARGA, no en sklearn despu\u00e9s. Esto hace debugging mucho m\u00e1s f\u00e1cil.  **Pregunta 2**: B) Rechaza DataFrames con columnas NO definidas en el schema. \u00datil para evitar columnas inesperadas.  **Pregunta 3**: B) Valida entrada Y salida de la funci\u00f3n autom\u00e1ticamente. Act\u00faa como un contrato.  **Escenario de Debugging**:  - **Significado**: Hay 2 filas (\u00edndices 127 y 890) donde Age es menor que 18. - **Opciones de soluci\u00f3n**:   1. Si son datos inv\u00e1lidos: filtrarlos antes de validar   2. Si son v\u00e1lidos en tu contexto: ajustar el schema `ge=0`   3. Si son errores de captura: revisar la fuente de datos  <pre><code># Opci\u00f3n 1: Filtrar\ndf = df[df[\"Age\"] &gt;= 18]\n\n# Opci\u00f3n 2: Ajustar schema\nAge: Series[int] = pa.Field(ge=0, le=100)  # Permitir menores\n</code></pre> <p></p>"},{"location":"docs/01_PYTHON_MODERNO/#17-ejercicios-practicos","title":"1.7 Ejercicios Pr\u00e1cticos","text":""},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-1-anadir-type-hints","title":"Ejercicio 1: A\u00f1adir Type Hints","text":"<pre><code># \u274c C\u00f3digo sin tipos (t\u00edpico de notebook)\n# Tu tarea: A\u00f1ade type hints completos\n\ndef process_training_data(df, config):\n    target = config[\"target\"]\n    features = config[\"features\"]\n\n    X = df[features]\n    y = df[target]\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=config.get(\"test_size\", 0.2)\n    )\n\n    return X_train, X_test, y_train, y_test\n\n\ndef calculate_metrics(y_true, y_pred):\n    return {\n        \"accuracy\": accuracy_score(y_true, y_pred),\n        \"f1\": f1_score(y_true, y_pred)\n    }\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>from typing import Dict, List, Tuple, Any\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\n\n\ndef process_training_data(\n    df: pd.DataFrame,\n    config: Dict[str, Any]\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n    \"\"\"Procesa datos para entrenamiento.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        DataFrame con datos crudos.\n    config : Dict[str, Any]\n        Configuraci\u00f3n con keys: \"target\", \"features\", \"test_size\" (opcional).\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]\n        X_train, X_test, y_train, y_test\n    \"\"\"\n    target: str = config[\"target\"]\n    features: List[str] = config[\"features\"]\n\n    X: pd.DataFrame = df[features]\n    y: pd.Series = df[target]\n\n    test_size: float = config.get(\"test_size\", 0.2)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=42\n    )\n\n    return X_train, X_test, y_train, y_test\n\n\ndef calculate_metrics(\n    y_true: pd.Series,\n    y_pred: pd.Series\n) -&gt; Dict[str, float]:\n    \"\"\"Calcula m\u00e9tricas de clasificaci\u00f3n.\n\n    Parameters\n    ----------\n    y_true : pd.Series\n        Labels verdaderos.\n    y_pred : pd.Series\n        Predicciones del modelo.\n\n    Returns\n    -------\n    Dict[str, float]\n        Diccionario con accuracy y f1.\n    \"\"\"\n    return {\n        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n        \"f1\": float(f1_score(y_true, y_pred))\n    }\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-2-crear-config-con-pydantic","title":"Ejercicio 2: Crear Config con Pydantic","text":"<pre><code># Tu tarea: Crea una configuraci\u00f3n Pydantic para TelecomAI\n# Requisitos:\n# - project_name: str\n# - random_seed: int (entre 0 y 1000)\n# - test_size: float (entre 0.1 y 0.5)\n# - model_type: solo puede ser \"logreg\", \"random_forest\", o \"gradient_boosting\"\n# - features: lista de strings\n# - target: str\n\n# Escribe tu c\u00f3digo aqu\u00ed:\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal\n\nclass TelecomConfig(BaseModel):\n    # ... tu c\u00f3digo\n    pass\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>from pydantic import BaseModel, Field\nfrom typing import List, Literal, Optional, Dict, Any\nfrom pathlib import Path\nimport yaml\n\n\nclass TelecomConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n para TelecomAI Customer Intelligence.\"\"\"\n\n    project_name: str = Field(..., min_length=1)\n    random_seed: int = Field(42, ge=0, le=1000)\n    test_size: float = Field(0.2, ge=0.1, le=0.5)\n    model_type: Literal[\"logreg\", \"random_forest\", \"gradient_boosting\"] = \"logreg\"\n    features: List[str] = Field(..., min_items=1)\n    target: str\n\n    # Opcionales\n    threshold: float = Field(0.5, ge=0.0, le=1.0)\n    mlflow_enabled: bool = True\n\n    @classmethod\n    def from_yaml(cls, path: str | Path) -&gt; \"TelecomConfig\":\n        with open(path) as f:\n            data = yaml.safe_load(f)\n        return cls(**data)\n\n    class Config:\n        extra = \"forbid\"  # No permite campos extra en el YAML\n\n\n# Uso:\nconfig = TelecomConfig(\n    project_name=\"TelecomAI\",\n    features=[\"calls\", \"minutes\", \"messages\", \"mb_used\"],\n    target=\"is_ultra\"\n)\n\n# Esto FALLA:\n# config = TelecomConfig(\n#     project_name=\"\",  # Error: min_length=1\n#     test_size=0.8,    # Error: le=0.5\n#     model_type=\"xgboost\",  # Error: not in Literal\n#     features=[],      # Error: min_items=1\n# )\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-3-convertir-a-src-layout","title":"Ejercicio 3: Convertir a src/ Layout","text":"<pre><code>Tu tarea: Reorganiza esta estructura plana a src/ layout\n\nANTES:\nmyproject/\n\u251c\u2500\u2500 train.py\n\u251c\u2500\u2500 predict.py\n\u251c\u2500\u2500 utils.py\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 data.csv\n\u2514\u2500\u2500 test_train.py\n\nDESPU\u00c9S:\nmyproject/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 ???\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 ???\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 ???\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 ???\n\u2514\u2500\u2500 pyproject.toml\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>myproject/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 myproject/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 training.py      # Antes: train.py\n\u2502       \u251c\u2500\u2500 prediction.py    # Antes: predict.py\n\u2502       \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py          # Fixtures compartidas\n\u2502   \u2514\u2500\u2500 test_training.py     # Antes: test_train.py\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 config.yaml\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 raw/\n\u2502       \u2514\u2500\u2500 data.csv\n\u251c\u2500\u2500 artifacts/               # Para modelos generados\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#errores-habituales-y-como-depurarlos","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos","text":"<p>En este m\u00f3dulo suelen aparecer siempre los mismos problemas. La idea no es solo evitarlos, sino saber reconocerlos r\u00e1pido en tus propios proyectos.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/01_PYTHON_MODERNO/#1-type-hints-mypy-errores-ruidosos-en-pandassklearn","title":"1) Type hints + mypy: errores ruidosos en pandas/sklearn","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>Function is missing a type annotation for parameter 'df'</code></li> <li><code>Incompatible return value type (got \"DataFrame\", expected \"Series\")</code></li> <li> <p>Cientos de warnings en librer\u00edas externas (<code>pandas.*</code>, <code>sklearn.*</code>). Proceso para identificarlos</p> </li> <li> <p>Ejecuta siempre:   <pre><code>mypy src/  # o mypy src/bankchurn src/carvision src/telecomai\n</code></pre></p> </li> <li>Localiza primero los errores en tu c\u00f3digo (archivos dentro de <code>src/</code>), ignora de momento los de librer\u00edas.</li> <li>Si ves muchos errores en <code>site-packages</code> o m\u00f3dulos externos, revisa tu secci\u00f3n <code>[tool.mypy]</code> del <code>pyproject.toml</code> (ver ejemplo en este mismo m\u00f3dulo).</li> </ul> <p>C\u00f3mo solucionarlos (patr\u00f3n general)</p> <ul> <li>A\u00f1ade tipos a todas las firmas p\u00fablicas (funciones/clases usadas fuera de su archivo).</li> <li>Usa tipos espec\u00edficos para ML:</li> <li><code>pd.DataFrame</code>, <code>pd.Series</code></li> <li><code>NDArray[np.float64]</code></li> <li><code>BaseEstimator</code>, <code>Pipeline</code></li> <li>A\u00edsla tipos muy complejos usando <code>TypedDict</code> o <code>Alias</code>:   <pre><code>class MetricsDict(TypedDict):\n    accuracy: float\n    f1: float\n    roc_auc: float\n</code></pre></li> <li>Para reducir ruido de mypy con librer\u00edas ML:</li> <li>Configura <code>ignore_missing_imports = true</code> y los overrides mostrados en este m\u00f3dulo.</li> <li>Re-lanza <code>mypy</code> y verifica que solo quedan errores en tu c\u00f3digo.</li> </ul> <p>\ud83d\udca1 Regla pr\u00e1ctica: si mypy empieza a gritar en medio de un refactor, reduce el problema a una funci\u00f3n peque\u00f1a, tipa bien esa funci\u00f3n, y despu\u00e9s propaga los tipos al resto.</p>"},{"location":"docs/01_PYTHON_MODERNO/#2-pydantic-validationerror-por-config-mal-definida","title":"2) Pydantic: <code>ValidationError</code> por config mal definida","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Al cargar la configuraci\u00f3n:   <pre><code>pydantic.error_wrappers.ValidationError: 2 validation errors for ModelConfig\nmodel -&gt; test_size\n  ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)\nmodel -&gt; cv_folds\n  ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)\n</code></pre></li> <li>Tu servicio/API no arranca porque falla la lectura de <code>config.yaml</code>.</li> </ul> <p>Proceso para identificarlos</p> <ul> <li>Localiza qu\u00e9 modelo Pydantic est\u00e1 fallando (<code>ModelConfig</code>, <code>BankChurnConfig</code>, <code>TelecomConfig</code>, etc.).</li> <li>Revisa el <code>traceback</code>: casi siempre indica la ruta completa del campo (<code>model -&gt; test_size</code>, <code>data -&gt; categorical_features</code>, etc.).</li> <li>Abre el YAML correspondiente (<code>configs/config.yaml</code>) y compara valor real vs restricci\u00f3n en <code>Field(...)</code>.</li> </ul> <p>C\u00f3mo solucionarlos (patr\u00f3n general)</p> <ul> <li>Ajusta el YAML para respetar los rangos:</li> <li><code>test_size</code> entre <code>0.0</code> y <code>1.0</code>.</li> <li><code>cv_folds</code> \u2265 2.</li> <li>Literales v\u00e1lidos (<code>voting: \"hard\" | \"soft\"</code>, <code>model_type: \"logreg\" | \"random_forest\" | ...</code>).</li> <li>Si el error te parece injustificado, revisa la declaraci\u00f3n del modelo:   <pre><code>test_size: float = Field(0.2, ge=0.0, le=1.0)\n</code></pre>   Quiz\u00e1 necesitas permitir un rango distinto en tu contexto.</li> <li>En desarrollo, falla r\u00e1pido: no atrapes el <code>ValidationError</code> salvo para mostrar un mensaje m\u00e1s amigable; deja que la app se caiga antes que usar una config corrupta.</li> </ul> <p>\ud83d\udd27 Ejercicio mental: rompe a prop\u00f3sito tu <code>configs/config.yaml</code> (pon <code>test_size: 1.5</code>) y observa el error. Luego arr\u00e9glalo. Hazlo una vez y nunca m\u00e1s te asustar\u00e1 un <code>ValidationError</code> en producci\u00f3n.</p>"},{"location":"docs/01_PYTHON_MODERNO/#3-src-layout-e-imports-modulenotfounderror-en-ci-pero-no-en-tu-maquina","title":"3) src/ layout e imports: <code>ModuleNotFoundError</code> en CI pero no en tu m\u00e1quina","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En local \u201ctodo funciona\u201d, pero en GitHub Actions o en otra m\u00e1quina obtienes:   <pre><code>ModuleNotFoundError: No module named 'bankchurn'\n</code></pre></li> <li>Los tests solo pasan si ejecutas <code>pytest</code> desde la ra\u00edz exacta del proyecto.</li> </ul> <p>Proceso para identificarlos</p> <ul> <li>Revisa la estructura de tu proyecto (deber\u00eda parecerse al diagrama de este m\u00f3dulo):</li> <li>C\u00f3digo dentro de <code>src/&lt;paquete&gt;/</code>.</li> <li>Tests bajo <code>tests/</code> usando imports del paquete, no rutas relativas raras.</li> <li>Verifica tu <code>pyproject.toml</code>:</li> <li><code>[project.name]</code> coincide con el paquete (<code>bankchurn</code>, <code>carvision</code>, <code>telecomai</code>).</li> <li><code>[tool.setuptools.packages.find] where = [\"src\"]</code>.</li> <li>Comprueba si instalaste en modo editable:   <pre><code>pip install -e .\npython -c \"import bankchurn; print(bankchurn.__file__)\"\n</code></pre></li> </ul> <p>C\u00f3mo solucionarlos (patr\u00f3n general)</p> <ul> <li>Mueve el c\u00f3digo de ra\u00edz a <code>src/</code> siguiendo el ejemplo de este m\u00f3dulo.</li> <li>Cambia imports tipo:   <pre><code># \u274c from .training import train_model  (desde scripts sueltos)\n# \u2705 from bankchurn.training import train_model\n</code></pre></li> <li>Aseg\u00farate de que los comandos de CI usan instalaci\u00f3n editable:   <pre><code>- name: Install\n  run: pip install -e \".[dev]\"\n</code></pre></li> </ul> <p>\u26a0\ufe0f Bandera roja: si tus tests solo funcionan cuando haces <code>cd src</code> o ajustas manualmente <code>PYTHONPATH</code>, tu layout todav\u00eda no est\u00e1 bien resuelto.</p>"},{"location":"docs/01_PYTHON_MODERNO/#4-patron-general-de-debugging-para-este-modulo","title":"4) Patr\u00f3n general de debugging para este m\u00f3dulo","text":"<ol> <li>Reproduce el error con un comando simple y determinista:</li> <li><code>mypy src/</code></li> <li><code>python -m src.proyecto.training</code></li> <li><code>pytest -k nombre_test</code>.</li> <li>Lee literalmente el mensaje de error (campo, valor, restricci\u00f3n).</li> <li>Conecta el error con el concepto del m\u00f3dulo:</li> <li>Type hints \u2192 firma de funci\u00f3n o tipo de retorno.</li> <li>Pydantic \u2192 <code>Field(...)</code> y YAML.</li> <li>src/ layout \u2192 estructura de carpetas + <code>pyproject.toml</code> + instalaci\u00f3n editable.</li> <li>Aplica el patr\u00f3n de soluci\u00f3n que viste arriba.</li> </ol> <p>Si automatizas este ciclo en tus tres proyectos del portafolio, tu tiempo de debugging se reduce dr\u00e1sticamente y es justo lo que se espera de un perfil Senior/Staff.</p>"},{"location":"docs/01_PYTHON_MODERNO/#checkpoint-completaste-el-modulo","title":"\u2705 Checkpoint: \u00bfCompletaste el M\u00f3dulo?","text":"<p>Antes de continuar, verifica:</p> <ul> <li>[ ] Tu c\u00f3digo tiene type hints en todas las funciones</li> <li>[ ] Puedes ejecutar <code>mypy src/</code> sin errores cr\u00edticos</li> <li>[ ] Tienes al menos una clase Pydantic para configuraci\u00f3n</li> <li>[ ] Tu proyecto tiene estructura src/ layout</li> <li>[ ] Puedes instalar tu paquete con <code>pip install -e .</code></li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#adr-por-que-estas-decisiones","title":"\ud83d\udd17 ADR: \u00bfPor Qu\u00e9 Estas Decisiones?","text":""},{"location":"docs/01_PYTHON_MODERNO/#adr-001-type-hints-obligatorios","title":"ADR-001: Type Hints Obligatorios","text":"<p>Contexto: El c\u00f3digo de ML suele ser dif\u00edcil de mantener porque las funciones aceptan \"cualquier cosa\".</p> <p>Decisi\u00f3n: Requerimos type hints en todas las funciones p\u00fablicas.</p> <p>Consecuencias: - \u2705 El IDE autocompleta correctamente - \u2705 Errores detectados antes de ejecutar - \u2705 Documentaci\u00f3n impl\u00edcita - \u274c M\u00e1s c\u00f3digo que escribir inicialmente - \u274c Curva de aprendizaje para tipos complejos</p>"},{"location":"docs/01_PYTHON_MODERNO/#adr-002-pydantic-para-configuracion","title":"ADR-002: Pydantic para Configuraci\u00f3n","text":"<p>Contexto: Configuraciones en diccionarios son propensas a errores.</p> <p>Decisi\u00f3n: Toda configuraci\u00f3n pasa por Pydantic.</p> <p>Consecuencias: - \u2705 Validaci\u00f3n autom\u00e1tica - \u2705 Errores claros - \u2705 Documentaci\u00f3n de la config - \u274c Dependencia adicional - \u274c M\u00e1s verboso que un dict simple</p>"},{"location":"docs/01_PYTHON_MODERNO/#adr-003-src-layout","title":"ADR-003: src/ Layout","text":"<p>Contexto: C\u00f3digo en ra\u00edz causa problemas de importaci\u00f3n.</p> <p>Decisi\u00f3n: Todo c\u00f3digo en <code>src/&lt;paquete&gt;/</code>.</p> <p>Consecuencias: - \u2705 Importaciones consistentes - \u2705 Funciona igual en desarrollo y CI - \u2705 Est\u00e1ndar de la industria - \u274c Requiere <code>pip install -e .</code> - \u274c Path m\u00e1s largo para imports</p>"},{"location":"docs/01_PYTHON_MODERNO/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>Este m\u00f3dulo se aplica directamente en los 3 proyectos del portafolio. Aqu\u00ed est\u00e1n los archivos reales que implementan cada concepto:</p>"},{"location":"docs/01_PYTHON_MODERNO/#type-hints-en-el-portafolio","title":"Type Hints en el Portafolio","text":"<pre><code># BankChurn-Predictor/src/bankchurn/config.py (l\u00edneas 89-109)\n@classmethod\ndef from_yaml(cls, config_path: str | Path) -&gt; BankChurnConfig:\n    \"\"\"Load configuration from YAML file.\n\n    Parameters\n    ----------\n    config_path : str or Path\n        Path to YAML configuration file.\n\n    Returns\n    -------\n    config : BankChurnConfig\n        Validated configuration object.\n    \"\"\"\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#pydantic-en-el-portafolio","title":"Pydantic en el Portafolio","text":"<p>Cada proyecto tiene su configuraci\u00f3n Pydantic:</p> Proyecto Archivo Clases principales BankChurn <code>src/bankchurn/config.py</code> <code>BankChurnConfig</code>, <code>ModelConfig</code>, <code>DataConfig</code> CarVision <code>src/carvision/config.py</code> <code>CarVisionConfig</code>, <code>FiltersConfig</code> TelecomAI <code>src/telecomai/config.py</code> <code>TelecomConfig</code> <pre><code># Ejemplo real: BankChurn-Predictor/src/bankchurn/config.py\nclass ModelConfig(BaseModel):\n    \"\"\"Model training configuration.\"\"\"\n    type: str = \"ensemble\"\n    test_size: float = Field(0.2, ge=0.0, le=1.0)  # \u2190 Validaci\u00f3n autom\u00e1tica\n    random_state: int = 42\n    cv_folds: int = Field(5, ge=2)  # \u2190 M\u00ednimo 2 folds\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#src-layout-en-el-portafolio","title":"src/ Layout en el Portafolio","text":"<p>Los 3 proyectos siguen exactamente la estructura descrita:</p> <pre><code>BankChurn-Predictor/\n\u251c\u2500\u2500 src/bankchurn/       \u2190 Paquete instalable\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py        \u2190 Pydantic configs\n\u2502   \u251c\u2500\u2500 pipeline.py      \u2190 sklearn Pipeline\n\u2502   \u2514\u2500\u2500 trainer.py       \u2190 Clase de entrenamiento\n\u251c\u2500\u2500 pyproject.toml       \u2190 Metadata y dependencias\n\u2514\u2500\u2500 setup.py             \u2190 Fallback para pip install -e .\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-verifica-en-el-repo-real","title":"\ud83d\udd27 Ejercicio: Verifica en el Repo Real","text":"<pre><code># 1. Ve al proyecto BankChurn\ncd BankChurn-Predictor\n\n# 2. Instala en modo editable\npip install -e \".[dev]\"\n\n# 3. Verifica tipos con mypy\nmypy src/bankchurn/config.py\n\n# 4. Prueba que Pydantic valida correctamente\npython -c \"from bankchurn.config import BankChurnConfig; print(BankChurnConfig.from_yaml('configs/config.yaml'))\"\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/01_PYTHON_MODERNO/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Domina Type Hints: Los entrevistadores valoran c\u00f3digo tipado. Practica explicar por qu\u00e9 <code>def process(data: pd.DataFrame) -&gt; Dict[str, float]</code> es mejor que <code>def process(data)</code>.</p> </li> <li> <p>Conoce Pydantic vs Dataclasses: Pregunta com\u00fan: \"\u00bfCu\u00e1ndo usar\u00edas uno u otro?\" Respuesta: Pydantic para validaci\u00f3n de datos externos (APIs, configs), dataclasses para estructuras internas simples.</p> </li> <li> <p>Demuestra comprensi\u00f3n de <code>__init__.py</code>: Explica c\u00f3mo controla la API p\u00fablica de un paquete y por qu\u00e9 <code>from package import *</code> es peligroso.</p> </li> </ol>"},{"location":"docs/01_PYTHON_MODERNO/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo C\u00f3digo legacy sin tipos A\u00f1ade tipos gradualmente, empezando por funciones p\u00fablicas Validaci\u00f3n de configs Usa Pydantic con <code>model_validator</code> para validaciones cruzadas Logs en producci\u00f3n Usa <code>structlog</code> o <code>loguru</code> en lugar de <code>print()</code> Errores en producci\u00f3n Implementa excepciones personalizadas con contexto \u00fatil"},{"location":"docs/01_PYTHON_MODERNO/#anti-patrones-a-evitar","title":"Anti-patrones a Evitar","text":"<ul> <li>\u274c <code>from typing import *</code> \u2014 importa solo lo que necesitas</li> <li>\u274c <code>except Exception:</code> sin logging \u2014 siempre registra el error</li> <li>\u274c Funciones de m\u00e1s de 50 l\u00edneas \u2014 refactoriza en funciones m\u00e1s peque\u00f1as</li> <li>\u274c Nombres como <code>data</code>, <code>info</code>, <code>result</code> \u2014 usa nombres descriptivos</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/01_PYTHON_MODERNO/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Type Hints in Python ArjanCodes 18 min YouTube \ud83d\udd34 Pydantic V2: The Complete Guide ArjanCodes 25 min YouTube \ud83d\udfe1 Python OOP - Classes and Objects Corey Schafer 15 min YouTube"},{"location":"docs/01_PYTHON_MODERNO/#cursos","title":"\ud83d\udcda Cursos","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Duraci\u00f3n Link \ud83d\udfe2 Modern Python 3 Bootcamp Udemy 30h Udemy"},{"location":"docs/01_PYTHON_MODERNO/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Pydantic Docs Documentaci\u00f3n oficial de Pydantic V2 \ud83d\udfe1 typing Module Documentaci\u00f3n de type hints \ud83d\udfe1 PEP 484 Especificaci\u00f3n de Type Hints"},{"location":"docs/01_PYTHON_MODERNO/#cuando-consultar","title":"\ud83d\udca1 Cu\u00e1ndo Consultar","text":"<ul> <li>Antes de empezar: Ve el video de Type Hints si no los usas regularmente</li> <li>Durante el m\u00f3dulo: Consulta Pydantic docs cuando trabajes con <code>config.py</code></li> <li>Despu\u00e9s: El curso complementario si quieres profundizar en POO</li> </ul>"},{"location":"docs/01_PYTHON_MODERNO/#decisiones-tecnicas-adrs","title":"\u2696\ufe0f Decisiones T\u00e9cnicas (ADRs)","text":""},{"location":"docs/01_PYTHON_MODERNO/#adr-001-python-311","title":"ADR-001: Python 3.11+","text":"<p>Contexto: Necesitamos un lenguaje para todo el stack ML.</p> <p>Decisi\u00f3n: Usar Python 3.11+ como lenguaje principal.</p> <p>Alternativas Consideradas: - R: Mejor para estad\u00edstica, peor para APIs y producci\u00f3n - Julia: M\u00e1s r\u00e1pido, ecosistema menos maduro</p> <p>Consecuencias: - \u2705 Ecosistema ML m\u00e1s completo - \u2705 FastAPI, Pydantic nativos - \u2705 Mayor pool de talento - \u274c M\u00e1s lento que lenguajes compilados</p>"},{"location":"docs/01_PYTHON_MODERNO/#adr-003-pydantic-v2-para-configuracion","title":"ADR-003: Pydantic v2 para Configuraci\u00f3n","text":"<p>Contexto: Necesitamos validar configuraci\u00f3n de forma robusta.</p> <p>Decisi\u00f3n: Usar Pydantic v2 para todas las configuraciones.</p> <p>Alternativas Consideradas: - dataclasses: Sin validaci\u00f3n built-in - attrs: Menos popular, similar funcionalidad - Dict/YAML directo: Sin validaci\u00f3n</p> <p>Consecuencias: - \u2705 Validaci\u00f3n autom\u00e1tica de tipos - \u2705 Errores claros en config inv\u00e1lida - \u2705 Integraci\u00f3n perfecta con FastAPI - \u274c Dependencia adicional</p>"},{"location":"docs/01_PYTHON_MODERNO/#adr-013-ruff-para-linting","title":"ADR-013: Ruff para Linting","text":"<p>Contexto: Necesitamos herramientas de calidad de c\u00f3digo r\u00e1pidas.</p> <p>Decisi\u00f3n: Usar Ruff como linter y formateador unificado.</p> <p>Alternativas Consideradas: - Flake8 + Black + isort: M\u00faltiples herramientas, m\u00e1s lento - Pylint: Muy lento, muchos false positives</p> <p>Consecuencias: - \u2705 10-100x m\u00e1s r\u00e1pido que alternativas - \u2705 Una herramienta = una config - \u2705 Compatible con reglas de Flake8 - \u274c Herramienta relativamente nueva</p>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-11-type-hints","title":"Ejercicio 1.1: Type Hints","text":"<p>Objetivo: A\u00f1adir type hints a funciones existentes. Dificultad: \u2b50\u2b50</p> <pre><code># ANTES (sin tipos)\ndef load_data(path):\n    return pd.read_csv(path)\n\ndef train_model(X, y, params):\n    model = RandomForestClassifier(**params)\n    return model.fit(X, y)\n\n# TU TAREA: A\u00f1adir type hints completos\n# Hint: usa pd.DataFrame, np.ndarray, dict[str, Any]\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from pathlib import Path\nfrom typing import Any\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef load_data(path: Path | str) -&gt; pd.DataFrame:\n    \"\"\"Carga datos desde CSV.\"\"\"\n    return pd.read_csv(path)\n\ndef train_model(\n    X: pd.DataFrame | np.ndarray,\n    y: pd.Series | np.ndarray,\n    params: dict[str, Any]\n) -&gt; RandomForestClassifier:\n    \"\"\"Entrena modelo con par\u00e1metros dados.\"\"\"\n    model = RandomForestClassifier(**params)\n    return model.fit(X, y)\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-12-pydantic-config","title":"Ejercicio 1.2: Pydantic Config","text":"<p>Objetivo: Crear configuraci\u00f3n validada con Pydantic. Dificultad: \u2b50\u2b50</p> <pre><code># Crear una clase ModelConfig que valide:\n# - n_estimators: int entre 10 y 500\n# - max_depth: int opcional, entre 1 y 50\n# - random_state: int, default 42\n\nfrom pydantic import BaseModel, Field\n\nclass ModelConfig(BaseModel):\n    # TU C\u00d3DIGO AQU\u00cd\n    pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from pydantic import BaseModel, Field\n\nclass ModelConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n validada para modelo RandomForest.\"\"\"\n\n    n_estimators: int = Field(\n        default=100,\n        ge=10,\n        le=500,\n        description=\"N\u00famero de \u00e1rboles en el bosque\"\n    )\n    max_depth: int | None = Field(\n        default=None,\n        ge=1,\n        le=50,\n        description=\"Profundidad m\u00e1xima de cada \u00e1rbol\"\n    )\n    random_state: int = Field(\n        default=42,\n        description=\"Semilla para reproducibilidad\"\n    )\n\n# Uso:\nconfig = ModelConfig(n_estimators=200, max_depth=10)\nprint(config.model_dump())  # {'n_estimators': 200, 'max_depth': 10, 'random_state': 42}\n\n# Validaci\u00f3n autom\u00e1tica:\n# ModelConfig(n_estimators=5)  # \u274c ValidationError: ge=10\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-13-src-layout","title":"Ejercicio 1.3: src/ Layout","text":"<p>Objetivo: Reorganizar c\u00f3digo en estructura profesional. Dificultad: \u2b50\u2b50</p> <pre><code># Dado este c\u00f3digo en un solo archivo main.py:\n# - load_data()\n# - preprocess()\n# - train()\n# - predict()\n# - FastAPI app\n\n# TU TAREA: Crear estructura src/ con:\n# src/myproject/data.py\n# src/myproject/training.py\n# src/myproject/prediction.py\n# app/fastapi_app.py\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>myproject/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 myproject/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 data.py          # load_data()\n\u2502       \u251c\u2500\u2500 training.py      # preprocess(), train()\n\u2502       \u2514\u2500\u2500 prediction.py    # predict()\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 fastapi_app.py       # FastAPI app\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 conftest.py\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 Makefile\n</code></pre>  **pyproject.toml m\u00ednimo:** <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"myproject\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"pandas&gt;=2.0\",\n    \"scikit-learn&gt;=1.3\",\n    \"fastapi&gt;=0.100\",\n]\n\n[project.optional-dependencies]\ndev = [\"pytest&gt;=7.0\", \"ruff&gt;=0.1\"]\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Type Hints Anotaciones de tipos en Python que mejoran legibilidad y permiten verificaci\u00f3n est\u00e1tica Pydantic Librer\u00eda para validaci\u00f3n de datos usando type hints de Python src/ Layout Estructura de proyecto donde el c\u00f3digo est\u00e1 en <code>src/nombre_paquete/</code> Ruff Linter y formateador ultrarr\u00e1pido para Python escrito en Rust"},{"location":"docs/01_PYTHON_MODERNO/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/01_PYTHON_MODERNO/#trampa-1-type-hints-que-no-se-verifican","title":"Trampa 1: Type Hints que no se verifican","text":"<p>S\u00edntoma: <pre><code>def train(data: pd.DataFrame) -&gt; Pipeline:\n    return \"esto no es un Pipeline\"  # Python no se queja\n</code></pre></p> <p>Causa ra\u00edz: Python no verifica types en runtime por defecto. Los hints son solo documentaci\u00f3n.</p> <p>Soluci\u00f3n: <pre><code># Ejecutar mypy para verificar\nmypy src/ --strict\n\n# Error: Incompatible return value type (got \"str\", expected \"Pipeline\")\n</code></pre></p> <p>Prevenci\u00f3n: <pre><code># .pre-commit-config.yaml\n- repo: https://github.com/pre-commit/mirrors-mypy\n  hooks:\n    - id: mypy\n      args: [--strict]\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#trampa-2-pydantic-con-valores-mutables-por-defecto","title":"Trampa 2: Pydantic con valores mutables por defecto","text":"<p>S\u00edntoma: <pre><code>class Config(BaseModel):\n    features: list = []  # \u274c PELIGRO: lista compartida entre instancias\n\nc1 = Config()\nc1.features.append(\"age\")\nc2 = Config()\nprint(c2.features)  # [\"age\"] \u2190 \u00a1Contaminado!\n</code></pre></p> <p>Causa ra\u00edz: Objetos mutables (listas, dicts) como defaults se comparten.</p> <p>Soluci\u00f3n: <pre><code>from pydantic import Field\n\nclass Config(BaseModel):\n    features: list = Field(default_factory=list)  # \u2705 Nueva lista cada vez\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#trampa-3-validacion-pydantic-silenciosa-con-coercion","title":"Trampa 3: Validaci\u00f3n Pydantic silenciosa con coerci\u00f3n","text":"<p>S\u00edntoma: <pre><code>class Config(BaseModel):\n    n_estimators: int\n\nconfig = Config(n_estimators=\"100\")  # \u2190 String, no int\nprint(config.n_estimators)  # 100 (int) \u2190 Pydantic lo convirti\u00f3 silenciosamente\n</code></pre></p> <p>Soluci\u00f3n (si necesitas validaci\u00f3n estricta): <pre><code>from pydantic import ConfigDict\n\nclass Config(BaseModel):\n    model_config = ConfigDict(strict=True)  # \u2190 No coerci\u00f3n\n    n_estimators: int\n\nConfig(n_estimators=\"100\")  # \u274c ValidationError\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#trampa-4-abc-sin-abstractmethod-no-obliga-implementacion","title":"Trampa 4: ABC sin @abstractmethod no obliga implementaci\u00f3n","text":"<p>S\u00edntoma: <pre><code>from abc import ABC\n\nclass BaseTrainer(ABC):\n    def fit(self, X, y):  # \u2190 Olvid\u00e9 @abstractmethod\n        pass\n\nclass ChurnTrainer(BaseTrainer):\n    pass  # \u2190 No implement\u00e9 fit, pero Python no se queja\n\ntrainer = ChurnTrainer()  # \u2705 Funciona (mal)\n</code></pre></p> <p>Soluci\u00f3n: <pre><code>from abc import ABC, abstractmethod\n\nclass BaseTrainer(ABC):\n    @abstractmethod  # \u2190 Ahora s\u00ed obliga\n    def fit(self, X, y):\n        pass\n\ntrainer = ChurnTrainer()  # \u274c TypeError: Can't instantiate abstract class\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#trampa-5-settingwithcopywarning-ignorada","title":"Trampa 5: SettingWithCopyWarning ignorada","text":"<p>S\u00edntoma: <pre><code>df_filtered = df[df[\"age\"] &gt; 18]\ndf_filtered[\"category\"] = \"adult\"  # \u26a0\ufe0f SettingWithCopyWarning\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># Opci\u00f3n 1: Copia expl\u00edcita\ndf_filtered = df[df[\"age\"] &gt; 18].copy()\ndf_filtered[\"category\"] = \"adult\"  # \u2705 Siempre funciona\n\n# Opci\u00f3n 2: .loc para modificar en su lugar\ndf.loc[df[\"age\"] &gt; 18, \"category\"] = \"adult\"  # \u2705 Modificaci\u00f3n directa\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#trampa-6-pandera-schema-muy-permisivo","title":"Trampa 6: Pandera schema muy permisivo","text":"<p>S\u00edntoma: <pre><code>class DataSchema(pa.DataFrameModel):\n    age: Series[int]\n    balance: Series[float]\n    # \u2190 Sin Config.strict, permite columnas extra\n\ndf_with_extra = pd.DataFrame({\n    \"age\": [25], \"balance\": [1000.0], \n    \"malicious_column\": [\"payload\"]  # \u2190 Pasa validaci\u00f3n\n})\nDataSchema.validate(df_with_extra)  # \u2705 No falla\n</code></pre></p> <p>Soluci\u00f3n: <pre><code>class DataSchema(pa.DataFrameModel):\n    age: Series[int]\n    balance: Series[float]\n\n    class Config:\n        strict = True  # \u2190 Rechaza columnas extra\n</code></pre></p>"},{"location":"docs/01_PYTHON_MODERNO/#quiz-del-modulo-semanas-1-3","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 1-3","text":""},{"location":"docs/01_PYTHON_MODERNO/#quiz-semana-1-type-hints-pydantic","title":"Quiz Semana 1: Type Hints + Pydantic","text":""},{"location":"docs/01_PYTHON_MODERNO/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfCu\u00e1l es la diferencia entre type hints de Python y la validaci\u00f3n de Pydantic?</p> \u2705 Respuesta  | Aspecto | Type Hints | Pydantic | |---------|-----------|----------| | **Cu\u00e1ndo verifica** | Est\u00e1ticamente (con mypy) | En runtime | | **Qu\u00e9 hace si falla** | mypy reporta error | Lanza ValidationError | | **Coerci\u00f3n** | No convierte tipos | Convierte `\"123\"` \u2192 `123` | | **D\u00f3nde usar** | Todo el c\u00f3digo | Fronteras (APIs, configs) |  **Clave**: Type hints son documentaci\u00f3n verificable; Pydantic es validaci\u00f3n activa."},{"location":"docs/01_PYTHON_MODERNO/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPor qu\u00e9 este c\u00f3digo es peligroso?</p> <pre><code>class Config(BaseModel):\n    features: list = []\n</code></pre> \u2705 Respuesta  La lista `[]` es mutable y se comparte entre todas las instancias. Usar `Field(default_factory=list)` en su lugar."},{"location":"docs/01_PYTHON_MODERNO/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>Explica qu\u00e9 hace <code>Field(ge=0, le=100)</code> en Pydantic.</p> \u2705 Respuesta  Define restricciones de validaci\u00f3n: - `ge=0`: Greater or Equal \u2192 valor \u2265 0 - `le=100`: Less or Equal \u2192 valor \u2264 100"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea un schema Pydantic <code>CustomerInput</code> que valide: - <code>age</code>: entero entre 18 y 100 - <code>balance</code>: float \u2265 0 - <code>tenure</code>: entero \u2265 0 - <code>products</code>: entero entre 1 y 4</p> \u2705 Soluci\u00f3n <pre><code>from pydantic import BaseModel, Field\n\nclass CustomerInput(BaseModel):\n    age: int = Field(..., ge=18, le=100)\n    balance: float = Field(..., ge=0)\n    tenure: int = Field(..., ge=0)\n    products: int = Field(..., ge=1, le=4)\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#quiz-semana-2-oop-y-protocolos","title":"Quiz Semana 2: OOP y Protocolos","text":""},{"location":"docs/01_PYTHON_MODERNO/#pregunta-1-25-pts_1","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfCu\u00e1l es la diferencia entre ABC y Protocol en Python?</p> \u2705 Respuesta  | Aspecto | ABC | Protocol | |---------|-----|----------| | **Herencia** | Requiere `class X(ABC)` | No requiere herencia | | **Verificaci\u00f3n** | Runtime con `isinstance` | Est\u00e1tica con mypy | | **Librer\u00edas externas** | Deben heredar expl\u00edcitamente | Cumplen autom\u00e1ticamente (duck typing) |"},{"location":"docs/01_PYTHON_MODERNO/#pregunta-2-25-pts_1","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPara qu\u00e9 sirve <code>@runtime_checkable</code> en un Protocol?</p> \u2705 Respuesta  Permite usar `isinstance()` con el Protocol en runtime: <pre><code>@runtime_checkable\nclass Predictor(Protocol):\n    def predict(self, X): ...\n\nisinstance(model, Predictor)  # \u2705 Funciona\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#pregunta-3-25-pts_1","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfQu\u00e9 error hay en este c\u00f3digo? <pre><code>from abc import ABC\nclass BaseTrainer(ABC):\n    def fit(self, X, y): pass\n</code></pre></p> \u2705 Respuesta  Falta `@abstractmethod`. Sin \u00e9l, los m\u00e9todos son concretos y heredables, no obliga implementaci\u00f3n."},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-practico-25-pts_1","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea un Protocol <code>DataLoader</code> con m\u00e9todos <code>load(path: str) -&gt; pd.DataFrame</code> y <code>validate(df: pd.DataFrame) -&gt; bool</code>.</p> \u2705 Soluci\u00f3n <pre><code>from typing import Protocol, runtime_checkable\nimport pandas as pd\n\n@runtime_checkable\nclass DataLoader(Protocol):\n    def load(self, path: str) -&gt; pd.DataFrame: ...\n    def validate(self, df: pd.DataFrame) -&gt; bool: ...\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#quiz-semana-3-pandas-de-produccion-pandera","title":"Quiz Semana 3: Pandas de Producci\u00f3n + Pandera","text":""},{"location":"docs/01_PYTHON_MODERNO/#pregunta-1-25-pts_2","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfQu\u00e9 causa <code>SettingWithCopyWarning</code> y c\u00f3mo se evita?</p> \u2705 Respuesta  **Causa**: Modificar un slice que puede ser vista o copia. **Soluci\u00f3n**: Usar `.copy()` expl\u00edcito o `.loc` para asignar."},{"location":"docs/01_PYTHON_MODERNO/#pregunta-2-25-pts_2","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfCu\u00e1l es la diferencia entre <code>strict=True</code> y <code>strict=False</code> en Pandera?</p> \u2705 Respuesta  - `strict=False` (default): Permite columnas adicionales no definidas - `strict=True`: Rechaza cualquier columna no definida en el schema"},{"location":"docs/01_PYTHON_MODERNO/#pregunta-3-25-pts_2","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfC\u00f3mo validar\u00edas que una columna \"email\" tenga formato correcto con Pandera?</p> \u2705 Respuesta <pre><code>email: Series[str] = pa.Field(str_matches=r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\")\n</code></pre>"},{"location":"docs/01_PYTHON_MODERNO/#ejercicio-practico-25-pts_2","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea un schema Pandera <code>BankDataSchema</code> con <code>customer_id</code> (string \u00fanico), <code>credit_score</code> (int 300-850), <code>balance</code> (float \u2265 0), <code>is_active</code> (bool), modo strict.</p> \u2705 Soluci\u00f3n <pre><code>import pandera as pa\nfrom pandera.typing import Series\n\nclass BankDataSchema(pa.DataFrameModel):\n    customer_id: Series[str] = pa.Field(unique=True)\n    credit_score: Series[int] = pa.Field(ge=300, le=850)\n    balance: Series[float] = pa.Field(ge=0)\n    is_active: Series[bool]\n\n    class Config:\n        strict = True\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [02. Dise\u00f1o de Sistemas ML](02_DISENO_SISTEMAS.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/02_DISENO_SISTEMAS/","title":"M\u00d3DULO 02: DISE\u00d1O DE SISTEMAS ML","text":"# \ud83d\udcd0 M\u00d3DULO 02: Dise\u00f1o de Sistemas ML  ### Del Problema de Negocio a la Arquitectura T\u00e9cnica  *\"Un arquitecto Senior no dibuja casas bonitas; dise\u00f1a sistemas que sobreviven* *a terremotos, a cambios de requisitos y a desarrolladores que se van.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **5-6 horas**        | 40%                  | 60%                  |"},{"location":"docs/02_DISENO_SISTEMAS/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 01_PYTHON_MODERNO (al menos type hints + estructura <code>src/</code>).</li> <li>Entender el objetivo de los 3 proyectos del portafolio y qu\u00e9 problema de negocio atacan.</li> <li>Poder leer diagramas simples (cajas y flechas) y discutir trade-offs.</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de dise\u00f1ar: abre Protocolo E y define tu output m\u00ednimo (ej: \u201cML Canvas completo + 2 ADRs\u201d).</li> <li>Mientras lo haces: si te atoras &gt;15 min (ej: m\u00e9tricas, restricciones, diagrama), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir qu\u00e9 mejorar (claridad, trade-offs, consistencia con c\u00f3digo).</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] 1 ML Canvas escrito (1 p\u00e1gina) con m\u00e9tricas de negocio/modelo/sistema.</li> <li>[ ] 1 diagrama de arquitectura (C4: Contexto + Contenedores).</li> <li>[ ] 2 ADRs con alternativas y trade-offs (ej: API vs batch, DVC vs alternativa).</li> </ul> <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: traducci\u00f3n negocio\u2192ML / C4 / ADR</li> <li>Archivo: <code>docs/ML_CANVAS.md</code>, <code>docs/ARCHITECTURE.md</code>, <code>docs/decisions/ADR-001.md</code></li> <li>Evidencia: diagrama + decisiones justificadas + m\u00e9tricas cuantificadas (no \u201cmejorar la experiencia\u201d).</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>ADR de Inicio: \u00bfPor Qu\u00e9 Dise\u00f1ar Antes de Codificar?</li> <li>2.1 Traducci\u00f3n Negocio \u2192 ML</li> <li>2.2 ML Canvas</li> <li>2.3 Arquitectura con el Modelo C4</li> <li>2.4 Diagrama de Flujo de Datos</li> <li>2.5 Architecture Decision Records (ADRs)</li> <li>2.6 Ejercicio Integrador</li> <li>Errores habituales y c\u00f3mo depurarlos</li> <li>2.7 Autoevaluaci\u00f3n</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#adr-de-inicio-por-que-disenar-antes-de-codificar","title":"\ud83c\udfaf ADR de Inicio: \u00bfPor Qu\u00e9 Dise\u00f1ar Antes de Codificar?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  ADR-002: Dise\u00f1o Obligatorio Antes del C\u00f3digo                                 \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  CONTEXTO:                                                                    \u2551\n\u2551  El 73% de proyectos ML que fallan lo hacen por problemas de DISE\u00d1O,          \u2551\n\u2551  no de algoritmos (Sculley et al., \"Hidden Technical Debt in ML Systems\").    \u2551\n\u2551                                                                               \u2551\n\u2551  DECISI\u00d3N:                                                                    \u2551\n\u2551  Todo proyecto debe completar: ML Canvas + Diagrama de Arquitectura +         \u2551\n\u2551  ADRs para decisiones t\u00e9cnicas clave ANTES de escribir c\u00f3digo.                \u2551\n\u2551                                                                               \u2551\n\u2551  CONSECUENCIAS:                                                               \u2551\n\u2551  (+) Alineamiento stakeholders-equipo desde el inicio                         \u2551\n\u2551  (+) Documentaci\u00f3n de trade-offs para futuros desarrolladores                 \u2551\n\u2551  (+) Menor retrabajo por requisitos mal entendidos                            \u2551\n\u2551  (-) A\u00f1ade 1-2 semanas al inicio del proyecto                                 \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#lo-que-lograras-en-este-modulo","title":"Lo Que Lograr\u00e1s en Este M\u00f3dulo","text":"<ol> <li>Traducir problemas de negocio a problemas de ML con m\u00e9tricas claras</li> <li>Completar un ML Canvas profesional</li> <li>Dise\u00f1ar arquitectura usando el modelo C4</li> <li>Documentar decisiones t\u00e9cnicas con ADRs</li> <li>Crear un diagrama de flujo de datos</li> </ol>"},{"location":"docs/02_DISENO_SISTEMAS/#21-traduccion-negocio-ml-el-arte-del-senior","title":"2.1 Traducci\u00f3n Negocio \u2192 ML (El Arte del Senior)","text":""},{"location":"docs/02_DISENO_SISTEMAS/#el-anti-patron-tengo-datos-voy-a-hacer-ml","title":"El Anti-Patr\u00f3n: \"Tengo Datos, Voy a Hacer ML\"","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         \u26a0\ufe0f EL ERROR DEL JUNIOR                                \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   JUNIOR:                                                                     \u2551\n\u2551   \"Tengo datos de clientes \u2192 Voy a probar XGBoost \u2192 Algo saldr\u00e1\"              \u2551\n\u2551                                                                               \u2551\n\u2551   PROBLEMA:                                                                   \u2551\n\u2551   \u2022 No sabe qu\u00e9 m\u00e9trica optimizar (\u00bfaccuracy? \u00bfF1? \u00bfcosto de negocio?)        \u2551\n\u2551   \u2022 No sabe si el modelo genera valor                                         \u2551\n\u2551   \u2022 No puede priorizar features porque no entiende el negocio                 \u2551\n\u2551   \u2022 Cuando el proyecto \"termina\", nadie lo usa                                \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                         \u2705 EL ENFOQUE DEL SENIOR                              \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   SENIOR:                                                                     \u2551\n\u2551   \"El banco pierde $2M/a\u00f1o por churn \u2192 Predecir top 10% de riesgo \u2192           \u2551\n\u2551    Campa\u00f1a de retenci\u00f3n \u2192 ROI esperado $400K \u2192 M\u00e9tricas:                      \u2551\n\u2551    Precision@10% &gt; 50%, AUC &gt; 0.85, Latencia &lt; 100ms\"                         \u2551\n\u2551                                                                               \u2551\n\u2551   VENTAJAS:                                                                   \u2551\n\u2551   \u2022 M\u00e9trica clara conectada a $$$                                             \u2551\n\u2551   \u2022 Sabe cu\u00e1ndo el modelo es \"suficientemente bueno\"                          \u2551\n\u2551   \u2022 Puede justificar inversi\u00f3n en infraestructura                             \u2551\n\u2551   \u2022 El proyecto genera valor medible                                          \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#framework-de-traduccion-negocio-ml-sistema","title":"Framework de Traducci\u00f3n: Negocio \u2192 ML \u2192 Sistema","text":"<pre><code>flowchart LR\n    subgraph Negocio[\"\ud83c\udfe2 NEGOCIO\"]\n        A[Problema de Negocio]\n        B[KPIs de \u00c9xito]\n        C[Restricciones]\n    end\n\n    subgraph ML[\"\ud83e\udde0 ML\"]\n        D[Tipo de Problema]\n        E[M\u00e9tricas T\u00e9cnicas]\n        F[Features Candidatas]\n    end\n\n    subgraph Sistema[\"\u2699\ufe0f SISTEMA\"]\n        G[Requisitos No-Funcionales]\n        H[Arquitectura]\n        I[Stack Tecnol\u00f3gico]\n    end\n\n    A --&gt; D\n    B --&gt; E\n    C --&gt; G\n    D --&gt; H\n    E --&gt; H\n    F --&gt; H\n    G --&gt; I</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#tabla-de-traduccion-ejemplos","title":"Tabla de Traducci\u00f3n (Ejemplos)","text":"Problema de Negocio Tipo ML M\u00e9trica Negocio M\u00e9trica T\u00e9cnica Requisito Sistema Reducir abandono de clientes Clasificaci\u00f3n Binaria $ retenido/a\u00f1o AUC-ROC, Precision@K Batch diario o API &lt; 100ms Estimar precio de veh\u00edculos Regresi\u00f3n % error en valuaci\u00f3n RMSE, MAPE API s\u00edncrona &lt; 200ms Detectar fraude en tarjetas Anomaly Detection $ fraude evitado Precision, Recall Streaming &lt; 50ms Recomendar productos Ranking/RecSys Lift en ventas NDCG@10, MAP API &lt; 100ms, cold-start handling Predecir demanda Series Temporales % reducci\u00f3n stockout MAPE, Bias Batch semanal"},{"location":"docs/02_DISENO_SISTEMAS/#mapa-mental-de-conceptos-traduccion-negocio-ml","title":"\ud83e\udde0 Mapa Mental de Conceptos: Traducci\u00f3n Negocio \u2192 ML","text":"<pre><code>                     \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                     \u2551       TRADUCCI\u00d3N NEGOCIO \u2192 ML \u2192 SISTEMA          \u2551\n                     \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                                   \u25bc                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \ud83c\udfe2 NEGOCIO       \u2502             \u2502  \ud83e\udde0 ML            \u2502             \u2502  \u2699\ufe0f SISTEMA       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 Problema ($$$)              \u251c\u2500 Tipo de problema           \u251c\u2500 Batch vs Real-time\n\u251c\u2500 KPIs de \u00e9xito               \u251c\u2500 M\u00e9trica t\u00e9cnica            \u251c\u2500 Latencia requerida\n\u251c\u2500 Restricciones               \u251c\u2500 Features candidatas        \u251c\u2500 Throughput\n\u2514\u2500 ROI esperado                \u2514\u2500 Baseline                   \u2514\u2500 SLAs\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo Problema de negocio Dolor cuantificable en $$$ \"Perdemos $2M/a\u00f1o por churn\" KPI Indicador clave de rendimiento Retenci\u00f3n, conversi\u00f3n, ARPU M\u00e9trica de negocio C\u00f3mo mides el \u00e9xito $ retenido/a\u00f1o M\u00e9trica t\u00e9cnica Qu\u00e9 optimiza el modelo AUC-ROC, RMSE, Precision@K Baseline Modelo simple de referencia Logistic Regression, promedio SLA Service Level Agreement Latencia &lt; 100ms, uptime 99.5%"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-puente-de-problema-a-solucion-ml","title":"\ud83d\udcbb Ejercicio Puente: De Problema a Soluci\u00f3n ML","text":"<p>Meta: Practica traducir problemas de negocio vagos a especificaciones ML concretas.</p> <p>Ejercicio 1: Cuantifica el problema <pre><code>Problema vago: \"Queremos mejorar la satisfacci\u00f3n del cliente\"\n\nTU TAREA: Convierte esto en un problema cuantificable:\n- \u00bfC\u00f3mo se mide la satisfacci\u00f3n actualmente?\n- \u00bfCu\u00e1l es el valor actual?\n- \u00bfCu\u00e1nto cuesta el problema en $$$?\n</code></pre></p> <p>Ejercicio 2: Elige la m\u00e9trica correcta <pre><code>Escenario: Hospital - predecir riesgo de readmisi\u00f3n\n- El costo de NO detectar un paciente de riesgo es muy alto (vida)\n- Hay pocos pacientes de alto riesgo (~5%)\n\nTU TAREA: \u00bfQu\u00e9 m\u00e9trica priorizar\u00edas?\nA) Accuracy  B) Precision  C) Recall  D) F1\nJustifica tu respuesta.\n</code></pre></p> \ud83d\udd0d Ver Soluciones  **Ejercicio 1:** <pre><code>- M\u00e9trica: NPS (Net Promoter Score) = 32\n- Problema: Clientes detractores (NPS &lt; 7) representan 25% de abandono\n- Costo: $500K/a\u00f1o en churn de detractores\n- Objetivo: Identificar detractores antes de que abandonen \u2192 Intervenci\u00f3n proactiva\n</code></pre>  **Ejercicio 2:**  **C) Recall** es la respuesta correcta. - En casos m\u00e9dicos donde el costo de un falso negativo es muy alto (no detectar un paciente de riesgo), priorizamos Recall. - Preferimos \"falsos positivos\" (revisar pacientes sanos) que perder pacientes en riesgo. - Con desbalanceo del 5%, Accuracy ser\u00eda enga\u00f1osa (95% solo prediciendo \"no riesgo\")."},{"location":"docs/02_DISENO_SISTEMAS/#practica-del-portafolio-traducir-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Traducir BankChurn","text":"<p>Tarea: Documentar la traducci\u00f3n completa para el proyecto BankChurn-Predictor.</p> <p>Paso 1: Identifica los n\u00fameros reales (pistas guiadas) <pre><code># Lee el README del proyecto\ncat BankChurn-Predictor/README.md\n\n# Busca:\n# - \u00bfCu\u00e1l es el churn rate actual?\n# - \u00bfCu\u00e1ntos clientes hay?\n# - \u00bfCu\u00e1l es el valor promedio de un cliente?\n</code></pre></p> <p>Paso 2: Completa esta tabla <pre><code>| Capa      | Pregunta                    | Tu Respuesta           |\n|-----------|-----------------------------|------------------------|\n| NEGOCIO   | \u00bfQu\u00e9 duele?                 | ___________________    |\n| NEGOCIO   | \u00bfCu\u00e1nto cuesta?             | $______/a\u00f1o            |\n| ML        | \u00bfQu\u00e9 tipo de problema?      | Clasificaci\u00f3n _____    |\n| ML        | \u00bfQu\u00e9 m\u00e9trica optimizamos?   | _____________________  |\n| SISTEMA   | \u00bfBatch o real-time?         | _____________________  |\n| SISTEMA   | \u00bfLatencia requerida?        | &lt; _____ ms             |\n</code></pre></p> <p>Paso 3: Crea el archivo <pre><code># Crea docs/PROBLEM_DEFINITION.md en BankChurn-Predictor\ntouch BankChurn-Predictor/docs/PROBLEM_DEFINITION.md\n</code></pre></p>"},{"location":"docs/02_DISENO_SISTEMAS/#checkpoint-de-conocimiento-traduccion-negocio-ml","title":"\u2705 Checkpoint de Conocimiento: Traducci\u00f3n Negocio \u2192 ML","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 es importante cuantificar el problema en $$$?</p> <p>A) Para impresionar a los stakeholders B) Para saber cu\u00e1ndo el modelo es \"suficientemente bueno\" y justificar inversi\u00f3n C) Porque es requisito de sklearn D) Para elegir el algoritmo correcto  </p> <p>Pregunta 2: Un e-commerce quiere predecir qu\u00e9 productos recomendarle a cada usuario. \u00bfQu\u00e9 tipo de problema ML es?</p> <p>A) Clasificaci\u00f3n binaria B) Regresi\u00f3n C) Ranking/RecSys D) Anomaly detection  </p> <p>Pregunta 3: Si el costo de un falso positivo es $1 y el de un falso negativo es $1000, \u00bfqu\u00e9 deber\u00edas priorizar?</p> <p>A) Precision B) Recall C) Accuracy D) F1-score  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Tu modelo tiene AUC = 0.95 (excelente), pero el equipo de negocio dice que \"no sirve\".\n\nAl investigar, descubres:\n- El modelo optimiza para clasificar correctamente a TODOS\n- Pero el negocio solo puede contactar al top 10% de clientes\n\n\u00bfCu\u00e1l es el problema? \u00bfQu\u00e9 m\u00e9trica deber\u00edas haber usado?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Para saber cu\u00e1ndo el modelo es \"suficientemente bueno\" y justificar inversi\u00f3n.  **Pregunta 2**: C) Ranking/RecSys. El objetivo es ordenar productos por relevancia para cada usuario.  **Pregunta 3**: B) Recall. Con costo de FN &gt;&gt;&gt; costo de FP, necesitas minimizar falsos negativos.  **Escenario de Debugging**:  - **Problema**: AUC mide discriminaci\u00f3n global, pero el negocio solo act\u00faa sobre el top 10%. - **Soluci\u00f3n**: Usar **Precision@K** o **Lift@10%** como m\u00e9trica principal. - **Lecci\u00f3n**: Siempre pregunta \"\u00bfc\u00f3mo se USAR\u00c1 el modelo?\" antes de elegir m\u00e9tricas.  <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#22-ml-canvas-el-blueprint-del-proyecto","title":"2.2 ML Canvas: El Blueprint del Proyecto","text":""},{"location":"docs/02_DISENO_SISTEMAS/#que-es-el-ml-canvas","title":"\u00bfQu\u00e9 es el ML Canvas?","text":"<p>El ML Canvas es un framework de 1 p\u00e1gina que captura todas las decisiones clave de un proyecto ML. Es como el Business Model Canvas pero para sistemas de ML.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                      ML CANVAS: BANKCHURN PREDICTOR                                   \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                                                       \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2551\n\u2551  \u2502 1. \ud83c\udfaf PROBLEMA DE NEGOCIO                 \u2502   \u2502 2. \ud83d\udcb0 PROPUESTA DE VALOR                       \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 \u2022 El banco pierde $2M/a\u00f1o por clientes    \u2502   \u2502 \u2022 Reducir churn 20% = $400K ahorro/a\u00f1o          \u2502  \u2551\n\u2551  \u2502   que abandonan sin previo aviso          \u2502   \u2502 \u2022 Identificar top 10% clientes en riesgo        \u2502  \u2551\n\u2551  \u2502 \u2022 Equipo de retenci\u00f3n act\u00faa reactivamente \u2502   \u2502 \u2022 Tiempo de acci\u00f3n: de 0 d\u00edas a 30 d\u00edas previo  \u2502  \u2551\n\u2551  \u2502 \u2022 Costo de adquisici\u00f3n 5x vs retenci\u00f3n    \u2502   \u2502 \u2022 Campa\u00f1as personalizadas por segmento riesgo   \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2551\n\u2551                                                                                                       \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2551\n\u2551  \u2502 3. \ud83d\udcca DATOS DISPONIBLES                   \u2502   \u2502 4. \ud83d\udd27 FEATURES CANDIDATAS                      \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 FUENTE: Sistema CRM (PostgreSQL)          \u2502   \u2502 DEMOGR\u00c1FICAS:                                   \u2502  \u2551\n\u2551  \u2502 \u2022 10,000 registros hist\u00f3ricos (2 a\u00f1os)    \u2502   \u2502 \u2022 Age, Gender, Geography                        \u2502  \u2551\n\u2551  \u2502 \u2022 Label: Exited (0=activo, 1=abandon\u00f3)    \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 \u2022 Frecuencia: Snapshot mensual            \u2502   \u2502 FINANCIERAS:                                    \u2502  \u2551\n\u2551  \u2502 \u2022 Latencia: T-1 d\u00eda                       \u2502   \u2502 \u2022 CreditScore, Balance, EstimatedSalary         \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 CALIDAD:                                  \u2502   \u2502 COMPORTAMIENTO:                                 \u2502  \u2551\n\u2551  \u2502 \u2022 Nulos: &lt; 1%                             \u2502   \u2502 \u2022 Tenure, NumOfProducts, HasCrCard              \u2502  \u2551\n\u2551  \u2502 \u2022 Desbalanceo: 20% churn (manejable)      \u2502   \u2502 \u2022 IsActiveMember                                \u2502  \u2551\n\u2551  \u2502 \u2022 Data drift: Estacional (navidad)        \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 DERIVADAS (Feature Engineering):                \u2502  \u2551\n\u2551  \u2502 RESTRICCIONES LEGALES:                    \u2502   \u2502 \u2022 BalancePerProduct = Balance / NumOfProducts   \u2502  \u2551\n\u2551  \u2502 \u2022 GDPR: Pseudonimizaci\u00f3n requerida        \u2502   \u2502 \u2022 BalanceSalaryRatio = Balance / Salary         \u2502  \u2551\n\u2551  \u2502 \u2022 No usar: Raza, Religi\u00f3n, etc.           \u2502   \u2502 \u2022 TenureAgeRatio = Tenure / Age                 \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2551\n\u2551                                                                                                       \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2551\n\u2551  \u2502 5. \ud83e\udd16 MODELO                              \u2502   \u2502 6. \ud83d\udccf M\u00c9TRICAS DE \u00c9XITO                        \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 TIPO: Clasificaci\u00f3n Binaria               \u2502   \u2502 NEGOCIO:                                        \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 $ Retenido por Campa\u00f1a &gt; $400K/a\u00f1o            \u2502  \u2551\n\u2551  \u2502 BASELINE:                                 \u2502   \u2502 \u2022 Lift vs random &gt; 3x                           \u2502  \u2551\n\u2551  \u2502 \u2022 Logistic Regression (interpretable)     \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 \u2022 Umbral: 50% churn rate                  \u2502   \u2502 MODELO:                                         \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 AUC-ROC &gt; 0.85 (target)                       \u2502  \u2551\n\u2551  \u2502 TARGET:                                   \u2502   \u2502 \u2022 Precision@10% &gt; 50%                           \u2502  \u2551\n\u2551  \u2502 \u2022 Random Forest / XGBoost                 \u2502   \u2502 \u2022 Recall &gt; 60% (no perder churners)             \u2502  \u2551\n\u2551  \u2502 \u2022 Con class_weight='balanced'             \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 SISTEMA:                                        \u2502  \u2551\n\u2551  \u2502 APPROACH:                                 \u2502   \u2502 \u2022 Latencia P99 &lt; 100ms                          \u2502  \u2551\n\u2551  \u2502 \u2022 Train/Test split temporal (no random)   \u2502   \u2502 \u2022 Throughput &gt; 100 req/s                        \u2502  \u2551\n\u2551  \u2502 \u2022 Cross-validation: TimeSeriesSplit       \u2502   \u2502 \u2022 Uptime &gt; 99.5%                                \u2502  \u2551\n\u2551  \u2502 \u2022 Hyperparameter tuning: Optuna           \u2502   \u2502 \u2022 Coverage &gt; 80%                                \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2551\n\u2551                                                                                                       \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2551\n\u2551  \u2502 7. \u26a0\ufe0f RIESGOS Y MITIGACIONES              \u2502   \u2502 8. \ud83d\ude80 PLAN DE DESPLIEGUE                       \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 T\u00c9CNICOS:                                 \u2502   \u2502 MVP (Semana 10):                                \u2502  \u2551\n\u2551  \u2502 \u2022 Desbalanceo \u2192 class_weight, SMOTE       \u2502   \u2502 \u2022 API REST (FastAPI)                            \u2502  \u2551\n\u2551  \u2502 \u2022 Data leakage \u2192 Validaci\u00f3n temporal      \u2502   \u2502 \u2022 Docker container                              \u2502  \u2551\n\u2551  \u2502 \u2022 Overfitting \u2192 Regularizaci\u00f3n, CV        \u2502   \u2502 \u2022 Consumidor: Dashboard BI (PowerBI)            \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 Batch scoring diario                          \u2502  \u2551\n\u2551  \u2502 OPERACIONALES:                            \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 \u2022 Model decay \u2192 Monitoreo + retrain       \u2502   \u2502 V2 (Mes 3):                                     \u2502  \u2551\n\u2551  \u2502 \u2022 Data drift \u2192 Evidently/NannyML          \u2502   \u2502 \u2022 Kubernetes deployment                         \u2502  \u2551\n\u2551  \u2502 \u2022 Latencia alta \u2192 Caching, async          \u2502   \u2502 \u2022 Integraci\u00f3n CRM real-time                     \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 A/B testing framework                         \u2502  \u2551\n\u2551  \u2502 \u00c9TICOS:                                   \u2502   \u2502 \u2022 Reentrenamiento mensual automatizado          \u2502  \u2551\n\u2551  \u2502 \u2022 Sesgo geogr\u00e1fico \u2192 Fairness metrics     \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2502 \u2022 Explicabilidad \u2192 SHAP values            \u2502   \u2502 CONSUMIDORES:                                   \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 Equipo de Retenci\u00f3n (principal)               \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 Dashboard Ejecutivo (secundario)              \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502 \u2022 CRM para campa\u00f1as automatizadas               \u2502  \u2551\n\u2551  \u2502                                           \u2502   \u2502                                                 \u2502  \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2551\n\u2551                                                                                                       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#template-vacio-para-tu-proyecto","title":"Template Vac\u00edo para Tu Proyecto","text":"<pre><code># ML CANVAS: [NOMBRE DEL PROYECTO]\n\n## 1. \ud83c\udfaf Problema de Negocio\n- \u00bfQu\u00e9 duele?\n- \u00bfCu\u00e1nto cuesta el problema actual?\n- \u00bfQui\u00e9n sufre?\n\n## 2. \ud83d\udcb0 Propuesta de Valor\n- \u00bfC\u00f3mo ML alivia el dolor?\n- \u00bfCu\u00e1l es el ROI esperado?\n- \u00bfQu\u00e9 decisiones habilita?\n\n## 3. \ud83d\udcca Datos Disponibles\n- Fuente:\n- Volumen:\n- Frecuencia:\n- Calidad (nulos, duplicados):\n- Restricciones legales:\n\n## 4. \ud83d\udd27 Features Candidatas\n- Demogr\u00e1ficas:\n- Transaccionales:\n- Comportamiento:\n- Derivadas (feature engineering):\n\n## 5. \ud83e\udd16 Modelo\n- Tipo de problema:\n- Baseline:\n- Target:\n- Approach de validaci\u00f3n:\n\n## 6. \ud83d\udccf M\u00e9tricas de \u00c9xito\n- Negocio:\n- Modelo:\n- Sistema:\n\n## 7. \u26a0\ufe0f Riesgos y Mitigaciones\n- T\u00e9cnicos:\n- Operacionales:\n- \u00c9ticos:\n\n## 8. \ud83d\ude80 Plan de Despliegue\n- MVP:\n- V2:\n- Consumidores:\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#mapa-mental-de-conceptos-ml-canvas","title":"\ud83e\udde0 Mapa Mental de Conceptos: ML Canvas","text":"<pre><code>                       \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                       \u2551         ML CANVAS: 8 SECCIONES      \u2551\n                       \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc               \u25bc               \u25bc               \u25bc               \u25bc               \n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1.Prob  \u2502    \u2502 2.Valor \u2502     \u2502 3.Datos \u2502     \u2502 4.Feats \u2502    \u2502 5.Model \u2502\n\u2502 Negocio \u2502    \u2502         \u2502     \u2502         \u2502     \u2502         \u2502    \u2502         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502               \u2502               \u2502               \u2502               \n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u25bc                                                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 6. M\u00e9tricas \u00c9xito   \u2502   \u2502 7. Riesgos          \u2502   \u2502 8. Plan Despliegue  \u2502\n\u2502 (Negocio/ML/Sistema)\u2502   \u2502 (T\u00e9c/Ops/\u00c9ticos)    \u2502   \u2502 (MVP/V2/Consumidor) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Secci\u00f3n Pregunta Clave Error Com\u00fan 1. Problema \u00bfQu\u00e9 duele en $$$? Vago: \"mejorar experiencia\" 2. Valor \u00bfCu\u00e1l es el ROI? Sin n\u00fameros concretos 3. Datos \u00bfFuente, volumen, calidad? Asumir datos perfectos 4. Features \u00bfQu\u00e9 informaci\u00f3n predice? Sin features derivadas 5. Modelo \u00bfBaseline vs target? Saltar directo a XGBoost 6. M\u00e9tricas \u00bfNegocio + ML + Sistema? Solo m\u00e9tricas ML 7. Riesgos \u00bfT\u00e9cnicos, ops, \u00e9ticos? Ignorar data drift 8. Despliegue \u00bfMVP y consumidores? Plan sin fases"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-puente-canvas-simplificado","title":"\ud83d\udcbb Ejercicio Puente: Canvas Simplificado","text":"<p>Meta: Antes de llenar un Canvas completo, practica con las secciones cr\u00edticas.</p> <p>Ejercicio: Uber Eats - Tiempo de Entrega <pre><code>Contexto: Uber Eats quiere predecir el tiempo de entrega para mostrarlo al usuario.\n\nTU TAREA: Completa solo estas 4 secciones:\n\n1. PROBLEMA DE NEGOCIO:\n   - \u00bfQu\u00e9 pasa si el tiempo mostrado es incorrecto?\n   - \u00bfCu\u00e1nto cuesta en t\u00e9rminos de negocio?\n\n2. TIPO DE PROBLEMA ML:\n   - \u00bfClasificaci\u00f3n, regresi\u00f3n, ranking?\n\n3. M\u00c9TRICAS:\n   - Negocio: ____________________\n   - ML: ________________________\n   - Sistema: ___________________\n\n4. RIESGOS:\n   - \u00bfQu\u00e9 puede salir mal?\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code>1. PROBLEMA DE NEGOCIO:\n   - Si subestima: usuario frustrado, mala rese\u00f1a, posible reembolso ($5-15)\n   - Si sobreestima: usuario cancela y va a competidor (p\u00e9rdida de orden $20+)\n   - Costo: ~$X millones/a\u00f1o en cancelaciones y reembolsos\n\n2. TIPO DE PROBLEMA ML:\n   - Regresi\u00f3n (predecir minutos continuos)\n   - O clasificaci\u00f3n en buckets (15-20min, 20-30min, etc.)\n\n3. M\u00c9TRICAS:\n   - Negocio: % \u00f3rdenes entregadas dentro del tiempo mostrado\n   - ML: MAE (Mean Absolute Error) en minutos\n   - Sistema: Latencia &lt;50ms (debe calcular al cargar men\u00fa)\n\n4. RIESGOS:\n   - T\u00e9cnico: Modelo no captura tr\u00e1fico en tiempo real\n   - Operacional: Drift cuando cambian restaurantes/repartidores\n   - \u00c9tico: Discriminaci\u00f3n geogr\u00e1fica en tiempos\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#practica-del-portafolio-ml-canvas-para-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: ML Canvas para BankChurn","text":"<p>Tarea: Crear el ML Canvas completo para BankChurn-Predictor.</p> <p>Paso 1: Usa el template <pre><code># Crea el archivo\ntouch BankChurn-Predictor/docs/ML_CANVAS.md\n\n# Copia el template de esta gu\u00eda\n</code></pre></p> <p>Paso 2: Completa cada secci\u00f3n (pistas guiadas)</p> <pre><code>## 1. \ud83c\udfaf Problema de Negocio\n# Pista: Busca en el README cu\u00e1ntos clientes hay y cu\u00e1l es el churn rate\n# Calcula: clientes * churn_rate * valor_promedio_cliente\n\n## 3. \ud83d\udcca Datos Disponibles\n# Pista: Revisa data/raw/*.csv\n# \u00bfCu\u00e1ntas filas? \u00bfCu\u00e1ntas columnas? \u00bfHay nulos?\n\n## 6. \ud83d\udccf M\u00e9tricas de \u00c9xito\n# NEGOCIO: $ retenido = clientes_salvados * valor_cliente\n# ML: AUC &gt; 0.85, Recall &gt; 60%\n# SISTEMA: Latencia P99 &lt; ___ms\n</code></pre> <p>Paso 3: Revisa con el checklist <pre><code>[ ] \u00bfCada secci\u00f3n tiene N\u00daMEROS, no solo palabras?\n[ ] \u00bfLas m\u00e9tricas de negocio conectan con las de ML?\n[ ] \u00bfIdentificaste al menos 3 riesgos?\n[ ] \u00bfEl plan de despliegue tiene MVP claro?\n</code></pre></p>"},{"location":"docs/02_DISENO_SISTEMAS/#checkpoint-de-conocimiento-ml-canvas","title":"\u2705 Checkpoint de Conocimiento: ML Canvas","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 necesitas 3 tipos de m\u00e9tricas (negocio, ML, sistema)?</p> <p>A) Porque es el est\u00e1ndar de la industria B) Porque cada stakeholder tiene diferentes preocupaciones C) Para tener m\u00e1s documentaci\u00f3n D) Porque sklearn lo requiere  </p> <p>Pregunta 2: \u00bfQu\u00e9 secci\u00f3n del Canvas te ayuda a evitar \"model decay\"?</p> <p>A) Problema de Negocio B) Features Candidatas C) Riesgos y Mitigaciones D) Plan de Despliegue  </p> <p>Pregunta 3: Tu Canvas dice \"mejorar la experiencia del cliente\". \u00bfQu\u00e9 est\u00e1 mal?</p> <p>A) Nada, es un objetivo v\u00e1lido B) Falta cuantificar: \u00bfc\u00f3mo se mide? \u00bfcu\u00e1l es el baseline? C) Deber\u00eda decir \"maximizar ROI\" D) Falta mencionar el algoritmo  </p> <p>\ufffd\ufffd Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Completaste el ML Canvas pero tu manager dice:\n\"Esto est\u00e1 muy bonito pero no me convence de que vale la pena invertir 3 meses de desarrollo\"\n\n\u00bfQu\u00e9 secci\u00f3n del Canvas probablemente est\u00e1 d\u00e9bil?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Porque cada stakeholder tiene diferentes preocupaciones. CEO quiere $$$, Data Scientists quieren AUC, Ops quiere latencia.  **Pregunta 2**: C) Riesgos y Mitigaciones. Aqu\u00ed documentas model decay y c\u00f3mo monitorearlo/reentrenar.  **Pregunta 3**: B) Falta cuantificar. \"Mejorar experiencia\" no es medible. Necesita: \"Reducir NPS detractores de 25% a 15%\".  **Escenario de Debugging**:  Las secciones **1. Problema de Negocio** y **2. Propuesta de Valor** est\u00e1n d\u00e9biles. - Falta el costo actual del problema en $$$ - Falta el ROI esperado de la soluci\u00f3n - Sin estos n\u00fameros, no hay caso de negocio para la inversi\u00f3n  <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#23-arquitectura-con-el-modelo-c4","title":"2.3 Arquitectura con el Modelo C4","text":""},{"location":"docs/02_DISENO_SISTEMAS/#que-es-c4","title":"\u00bfQu\u00e9 es C4?","text":"<p>El modelo C4 (Context, Container, Component, Code) es un framework para documentar arquitectura de software en 4 niveles de zoom.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         MODELO C4: 4 NIVELES DE ZOOM                          \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   NIVEL 1: CONTEXTO (System Context)                                          \u2551\n\u2551   \u2022 Vista de p\u00e1jaro: El sistema y sus usuarios/sistemas externos              \u2551\n\u2551   \u2022 Audiencia: Todos (stakeholders, devs, ops)                                \u2551\n\u2551   \u2022 Pregunta: \"\u00bfQu\u00e9 es esto y qui\u00e9n lo usa?\"                                  \u2551\n\u2551                                                                               \u2551\n\u2551   NIVEL 2: CONTENEDORES (Container)                                           \u2551\n\u2551   \u2022 Zoom in: Aplicaciones, bases de datos, servicios                          \u2551\n\u2551   \u2022 Audiencia: Arquitectos, tech leads                                        \u2551\n\u2551   \u2022 Pregunta: \"\u00bfQu\u00e9 partes tiene el sistema?\"                                 \u2551\n\u2551                                                                               \u2551\n\u2551   NIVEL 3: COMPONENTES (Component)                                            \u2551\n\u2551   \u2022 Zoom in++: M\u00f3dulos dentro de cada contenedor                              \u2551\n\u2551   \u2022 Audiencia: Desarrolladores                                                \u2551\n\u2551   \u2022 Pregunta: \"\u00bfC\u00f3mo est\u00e1 organizado internamente?\"                           \u2551\n\u2551                                                                               \u2551\n\u2551   NIVEL 4: C\u00d3DIGO (Code)                                                      \u2551\n\u2551   \u2022 M\u00e1ximo zoom: Clases, funciones                                            \u2551\n\u2551   \u2022 Audiencia: Desarrolladores (el que va a implementar)                      \u2551\n\u2551   \u2022 Nota: Usualmente se genera desde el c\u00f3digo, no se dibuja                  \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#nivel-1-contexto-del-sistema-bankchurn","title":"Nivel 1: Contexto del Sistema BankChurn","text":"<pre><code>C4Context\n    title Sistema BankChurn - Diagrama de Contexto\n\n    Person(retention_team, \"Equipo Retenci\u00f3n\", \"Act\u00faa sobre predicciones para retener clientes\")\n    Person(data_team, \"Data Team\", \"Monitorea y mejora modelos\")\n\n    System(bankchurn, \"BankChurn Predictor\", \"Predice probabilidad de churn y genera scores de riesgo\")\n\n    System_Ext(crm, \"Sistema CRM\", \"Fuente de datos de clientes\")\n    System_Ext(bi, \"Dashboard BI\", \"Visualiza scores y m\u00e9tricas\")\n    System_Ext(campaign, \"Sistema Campa\u00f1as\", \"Ejecuta acciones de retenci\u00f3n\")\n\n    Rel(retention_team, bankchurn, \"Consulta scores\", \"API/Dashboard\")\n    Rel(data_team, bankchurn, \"Monitorea y retrains\", \"MLflow/Grafana\")\n    Rel(crm, bankchurn, \"Env\u00eda datos clientes\", \"Batch/API\")\n    Rel(bankchurn, bi, \"Env\u00eda predicciones\", \"API\")\n    Rel(bankchurn, campaign, \"Env\u00eda lista de riesgo\", \"API/Webhook\")</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#nivel-2-contenedores","title":"Nivel 2: Contenedores","text":"<pre><code>C4Container\n    title Sistema BankChurn - Diagrama de Contenedores\n\n    Person(user, \"Usuario\", \"Equipo Retenci\u00f3n / Data Team\")\n\n    Container_Boundary(bankchurn, \"BankChurn Predictor\") {\n        Container(api, \"API REST\", \"FastAPI\", \"Expone endpoints de predicci\u00f3n y health\")\n        Container(model, \"ML Pipeline\", \"Sklearn\", \"Pipeline entrenado: preprocessor + model\")\n        Container(mlflow, \"MLflow\", \"Python\", \"Tracking de experimentos y model registry\")\n        ContainerDb(db, \"Model Storage\", \"S3/Local\", \"Artefactos .pkl\")\n    }\n\n    System_Ext(crm, \"CRM\", \"PostgreSQL\")\n    System_Ext(prometheus, \"Prometheus\", \"M\u00e9tricas\")\n    System_Ext(grafana, \"Grafana\", \"Dashboards\")\n\n    Rel(user, api, \"HTTP/JSON\", \"REST\")\n    Rel(api, model, \"Loads\", \"joblib\")\n    Rel(model, db, \"Reads\", \"S3/File\")\n    Rel(mlflow, db, \"Writes\", \"Artifacts\")\n    Rel(crm, api, \"Batch data\", \"CSV/API\")\n    Rel(api, prometheus, \"Exposes /metrics\", \"HTTP\")\n    Rel(prometheus, grafana, \"Scrapes\", \"PromQL\")</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#nivel-3-componentes-api-container","title":"Nivel 3: Componentes (API Container)","text":"<pre><code>C4Component\n    title API REST - Diagrama de Componentes\n\n    Container_Boundary(api, \"API REST (FastAPI)\") {\n        Component(routes, \"Routes\", \"fastapi.APIRouter\", \"Define endpoints: /predict, /health, /metrics\")\n        Component(schemas, \"Schemas\", \"Pydantic\", \"Valida requests y responses\")\n        Component(inference, \"Inference Service\", \"Python Class\", \"Carga modelo y ejecuta predicci\u00f3n\")\n        Component(middleware, \"Middleware\", \"FastAPI\", \"Logging, timing, error handling\")\n        Component(config, \"Config\", \"Pydantic Settings\", \"Lee variables de entorno\")\n    }\n\n    ContainerDb(model_store, \"Model Store\", \"S3\")\n    Container(prometheus, \"Prometheus Client\", \"prometheus_client\")\n\n    Rel(routes, schemas, \"Uses\", \"Type validation\")\n    Rel(routes, inference, \"Calls\", \"predict()\")\n    Rel(inference, model_store, \"Loads\", \"joblib.load()\")\n    Rel(middleware, prometheus, \"Exposes\", \"Counters/Histograms\")\n    Rel(routes, config, \"Reads\", \"Settings\")</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#mapa-mental-de-conceptos-modelo-c4","title":"\ud83e\udde0 Mapa Mental de Conceptos: Modelo C4","text":"<pre><code>                     \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                     \u2551     MODELO C4: 4 NIVELES DE ZOOM      \u2551\n                     \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                           \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                 \u25bc                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  NIVEL 1        \u2502             \u2502  NIVEL 2        \u2502             \u2502  NIVEL 3-4      \u2502\n\u2502  CONTEXTO       \u2502             \u2502  CONTENEDORES   \u2502             \u2502  COMPONENTES    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                               \u2502                               \u2502\n\u251c\u2500 Vista de p\u00e1jaro            \u251c\u2500 Apps, DBs, servicios         \u251c\u2500 M\u00f3dulos internos\n\u251c\u2500 Usuarios externos          \u251c\u2500 Comunicaci\u00f3n entre partes    \u251c\u2500 Clases/funciones\n\u251c\u2500 Sistemas externos          \u251c\u2500 Tecnolog\u00edas espec\u00edficas      \u2514\u2500 (Generado de c\u00f3digo)\n\u2514\u2500 \"\u00bfQu\u00e9 es esto?\"            \u2514\u2500 \"\u00bfQu\u00e9 partes tiene?\"\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Nivel Audiencia Pregunta Elementos T\u00edpicos Contexto Todos \u00bfQu\u00e9 es y qui\u00e9n lo usa? Personas, Sistema, Sistemas Externos Contenedores Arquitectos \u00bfQu\u00e9 partes tiene? API, DB, Queue, Storage Componentes Developers \u00bfC\u00f3mo est\u00e1 organizado? Routes, Services, Repositories C\u00f3digo Implementador \u00bfC\u00f3mo funciona? Clases, Funciones (autodoc)"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-puente-diagrama-de-contexto-simple","title":"\ud83d\udcbb Ejercicio Puente: Diagrama de Contexto Simple","text":"<p>Meta: Antes de diagramar sistemas ML complejos, practica con un sistema simple.</p> <p>Ejercicio: App de Notas <pre><code>Contexto: Una app m\u00f3vil de notas que sincroniza con la nube.\n\nTU TAREA: Dibuja el diagrama de CONTEXTO identificando:\n1. \u00bfQui\u00e9n USA el sistema? (Personas)\n2. \u00bfQu\u00e9 ES el sistema? (Sistema principal)\n3. \u00bfCon qu\u00e9 EXTERNOS se comunica? (Otros sistemas)\n\nUsa este formato ASCII:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Usuario \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502  Notes App  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 Cloud   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502 Storage \u2502\n                                            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code>                    DIAGRAMA DE CONTEXTO: NOTES APP\n\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502   Usuario    \u2502                              \u2502   Google     \u2502\n    \u2502   M\u00f3vil      \u2502                              \u2502   Auth       \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 CRUD notas                                  \u2502 OAuth\n           \u25bc                                             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502                                                          \u2502\n    \u2502                    NOTES APP                             \u2502\n    \u2502             (App m\u00f3vil + Backend)                        \u2502\n    \u2502                                                          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502 Sync\n                               \u25bc\n                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502  Firebase    \u2502\n                        \u2502  Firestore   \u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#practica-del-portafolio-c4-para-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: C4 para BankChurn","text":"<p>Tarea: Crear diagramas C4 para BankChurn-Predictor.</p> <p>Paso 1: Diagrama de Contexto (pistas guiadas) <pre><code>Identifica:\n- PERSONAS: \u00bfQui\u00e9n usa el sistema? (Equipo Retenci\u00f3n, Data Team)\n- SISTEMA: \u00bfQu\u00e9 es BankChurn? (Sistema de predicci\u00f3n de churn)\n- EXTERNOS: \u00bfDe d\u00f3nde vienen los datos? \u00bfA d\u00f3nde van las predicciones?\n</code></pre></p> <p>Paso 2: Diagrama de Contenedores <pre><code>Revisa la estructura real del proyecto:\nls -la BankChurn-Predictor/\n\nIdentifica contenedores:\n- \u00bfHay API? \u2192 app/fastapi_app.py\n- \u00bfHay modelo? \u2192 models/*.pkl\n- \u00bfHay tracking? \u2192 mlruns/\n- \u00bfHay storage? \u2192 data/, artifacts/\n</code></pre></p> <p>Paso 3: Usa Mermaid <pre><code>C4Context\n    title Tu Diagrama Aqu\u00ed\n\n    Person(user, \"Usuario\", \"Descripci\u00f3n\")\n    System(system, \"Tu Sistema\", \"Descripci\u00f3n\")\n    System_Ext(external, \"Sistema Externo\", \"Descripci\u00f3n\")\n\n    Rel(user, system, \"Usa\", \"HTTP\")</code></pre></p> <p>Paso 4: Guarda en docs/ <pre><code># Crea el archivo\ntouch BankChurn-Predictor/docs/ARCHITECTURE.md\n</code></pre></p>"},{"location":"docs/02_DISENO_SISTEMAS/#checkpoint-de-conocimiento-modelo-c4","title":"\u2705 Checkpoint de Conocimiento: Modelo C4","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 C4 tiene 4 niveles en vez de 1?</p> <p>A) Para complicar la documentaci\u00f3n B) Porque diferentes audiencias necesitan diferentes niveles de detalle C) Porque Mermaid lo requiere D) Para cumplir con est\u00e1ndares ISO  </p> <p>Pregunta 2: \u00bfEn qu\u00e9 nivel de C4 mostrar\u00edas \"Prometheus\" y \"Grafana\"?</p> <p>A) Contexto B) Contenedores C) Componentes D) C\u00f3digo  </p> <p>Pregunta 3: Tu diagrama de Contenedores muestra 5 microservicios, pero el c\u00f3digo solo tiene 1 API. \u00bfQu\u00e9 est\u00e1 mal?</p> <p>A) Nada, es la arquitectura futura B) El diagrama no refleja la realidad, confundir\u00e1 a nuevos desarrolladores C) Faltan m\u00e1s microservicios D) C4 siempre requiere microservicios  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Un nuevo developer se une al equipo y mira tu diagrama C4.\nPregunta: \"\u00bfD\u00f3nde est\u00e1 el c\u00f3digo de este contenedor 'Feature Store'?\"\nRespuesta: \"Eh... todav\u00eda no existe, es para el futuro.\"\n\n\u00bfQu\u00e9 regla de C4 est\u00e1s violando?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Porque diferentes audiencias necesitan diferentes niveles de detalle. CEO ve Contexto, Developer ve Componentes.  **Pregunta 2**: B) Contenedores. Son aplicaciones/servicios que forman parte del sistema.  **Pregunta 3**: B) El diagrama no refleja la realidad. Documenta lo que EXISTE hoy, no lo que imaginas.  **Escenario de Debugging**:  Est\u00e1s violando la regla **\"Documenta la realidad, no la aspiraci\u00f3n\"**. - Soluci\u00f3n: Separa claramente \"Arquitectura Actual (MVP)\" de \"Arquitectura Futura (V2)\". - Los nuevos developers deben poder navegar del diagrama al c\u00f3digo 1:1.  <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#24-diagrama-de-flujo-de-datos","title":"2.4 Diagrama de Flujo de Datos","text":""},{"location":"docs/02_DISENO_SISTEMAS/#training-pipeline","title":"Training Pipeline","text":"<pre><code>flowchart LR\n    subgraph Data[\"\ud83d\udce6 DATA\"]\n        RAW[(Raw Data&lt;br/&gt;data/raw/)]\n        PROC[(Processed&lt;br/&gt;data/processed/)]\n    end\n\n    subgraph Training[\"\ud83d\udd04 TRAINING\"]\n        LOAD[Load Data]\n        FE[Feature&lt;br/&gt;Engineering]\n        SPLIT[Train/Test&lt;br/&gt;Split]\n        TRAIN[Train Model]\n        EVAL[Evaluate]\n    end\n\n    subgraph Artifacts[\"\ud83d\udcc1 ARTIFACTS\"]\n        MODEL[(Pipeline.pkl&lt;br/&gt;models/)]\n        METRICS[(Metrics&lt;br/&gt;mlruns/)]\n    end\n\n    subgraph Tracking[\"\ud83d\udcca TRACKING\"]\n        MLFLOW[MLflow&lt;br/&gt;Server]\n    end\n\n    RAW --&gt; LOAD\n    LOAD --&gt; FE\n    FE --&gt; PROC\n    FE --&gt; SPLIT\n    SPLIT --&gt; TRAIN\n    TRAIN --&gt; EVAL\n    EVAL --&gt; MODEL\n    EVAL --&gt; METRICS\n    METRICS --&gt; MLFLOW\n    MODEL --&gt; MLFLOW\n\n    style Data fill:#e1f5fe\n    style Training fill:#fff3e0\n    style Artifacts fill:#e8f5e9\n    style Tracking fill:#f3e5f5</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#inference-pipeline","title":"Inference Pipeline","text":"<pre><code>flowchart LR\n    subgraph Client[\"\ud83d\udc64 CLIENT\"]\n        REQ[JSON Request]\n        RESP[JSON Response]\n    end\n\n    subgraph API[\"\ud83c\udf10 API\"]\n        VALID[Validate&lt;br/&gt;Pydantic]\n        INFER[Inference&lt;br/&gt;Service]\n        FORMAT[Format&lt;br/&gt;Response]\n    end\n\n    subgraph Model[\"\ud83e\udd16 MODEL\"]\n        LOAD[Load&lt;br/&gt;Pipeline]\n        PREDICT[Predict&lt;br/&gt;Proba]\n    end\n\n    subgraph Monitor[\"\ud83d\udcca MONITOR\"]\n        LOGS[Structured&lt;br/&gt;Logs]\n        METRICS[Prometheus&lt;br/&gt;Metrics]\n    end\n\n    REQ --&gt; VALID\n    VALID --&gt; INFER\n    INFER --&gt; LOAD\n    LOAD --&gt; PREDICT\n    PREDICT --&gt; FORMAT\n    FORMAT --&gt; RESP\n\n    INFER --&gt; LOGS\n    INFER --&gt; METRICS\n\n    style Client fill:#e3f2fd\n    style API fill:#fff8e1\n    style Model fill:#e8f5e9\n    style Monitor fill:#fce4ec</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#25-architecture-decision-records-adrs","title":"2.5 Architecture Decision Records (ADRs)","text":""},{"location":"docs/02_DISENO_SISTEMAS/#que-es-un-adr","title":"\u00bfQu\u00e9 es un ADR?","text":"<p>Un ADR documenta una decisi\u00f3n arquitect\u00f3nica importante: el contexto, la decisi\u00f3n tomada, y las consecuencias.</p>"},{"location":"docs/02_DISENO_SISTEMAS/#template-adr","title":"Template ADR","text":"<pre><code># ADR-XXX: [T\u00edtulo de la Decisi\u00f3n]\n\n## Estado\n[Propuesto | Aceptado | Deprecado | Superseded por ADR-YYY]\n\n## Contexto\n\u00bfCu\u00e1l es el problema que estamos tratando de resolver?\n\u00bfQu\u00e9 restricciones tenemos?\n\n## Decisi\u00f3n\n\u00bfQu\u00e9 decidimos hacer?\n\n## Consecuencias\n\n### Positivas\n- \n\n### Negativas\n-\n\n### Neutras\n-\n\n## Alternativas Consideradas\n| Alternativa | Pros | Contras | Raz\u00f3n de Rechazo |\n| ----------- | ---- | ------- | ---------------- |\n|             |      |         |                  |\n\n## Referencias\n- Links a documentaci\u00f3n, papers, etc.\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#adrs-ejemplo-para-bankchurn","title":"ADRs Ejemplo para BankChurn","text":""},{"location":"docs/02_DISENO_SISTEMAS/#adr-003-fastapi-sobre-flask","title":"ADR-003: FastAPI sobre Flask","text":"<pre><code># ADR-003: Usar FastAPI para la API REST\n\n## Estado\nAceptado\n\n## Contexto\nNecesitamos exponer el modelo como API REST. Las opciones principales son:\n- Flask (maduro, amplia adopci\u00f3n)\n- FastAPI (moderno, async, tipado)\n- Django REST (batteries-included, pero pesado)\n\n## Decisi\u00f3n\nUsaremos **FastAPI** para la API REST.\n\n## Consecuencias\n\n### Positivas\n- Validaci\u00f3n autom\u00e1tica con Pydantic (ya usamos para config)\n- Documentaci\u00f3n OpenAPI generada autom\u00e1ticamente\n- Soporte nativo async (mejor performance bajo carga)\n- Type hints forzados (consistente con nuestro c\u00f3digo)\n- Mejor performance que Flask (Starlette + Uvicorn)\n\n### Negativas\n- Menos tutoriales/recursos que Flask (aunque creciendo r\u00e1pidamente)\n- Requiere entender async/await para features avanzados\n- Algunos desarrolladores pueden no estar familiarizados\n\n### Neutras\n- Similar curva de aprendizaje inicial que Flask\n\n## Alternativas Consideradas\n| Alternativa | Pros | Contras | Raz\u00f3n de Rechazo |\n| ----------- | ---- | ------- | ---------------- |\n| Flask | Maduro, muchos recursos | Sin async, sin tipos, docs manual | Performance y DX inferior |\n| Django REST | Batteries-included | Muy pesado para API simple, ORM no necesario | Overkill para nuestro caso |\n\n## Referencias\n- [FastAPI vs Flask Benchmark](https://fastapi.tiangolo.com/benchmarks/)\n- [Why FastAPI](https://fastapi.tiangolo.com/features/)\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#adr-004-dvc-sobre-git-lfs","title":"ADR-004: DVC sobre Git LFS","text":"<pre><code># ADR-004: Usar DVC para Versionado de Datos\n\n## Estado\nAceptado\n\n## Contexto\nNecesitamos versionar:\n- Dataset de entrenamiento (CSV ~50MB)\n- Modelos entrenados (PKL ~10MB)\n- Posible crecimiento a GB en el futuro\n\n## Decisi\u00f3n\nUsaremos **DVC** (Data Version Control) con remote storage en S3/GCS.\n\n## Consecuencias\n\n### Positivas\n- Integraci\u00f3n nativa con Git (cada versi\u00f3n de datos linked a commit)\n- Pipelines declarativos (dvc.yaml)\n- M\u00faltiples backends de storage (local, S3, GCS, Azure)\n- Reproducibilidad con `dvc repro`\n- Comunidad activa, bien documentado\n\n### Negativas\n- Curva de aprendizaje adicional\n- Requiere setup de remote storage para colaboraci\u00f3n\n- Puede ser overkill para datasets muy peque\u00f1os\n\n### Neutras\n- CLI similar a Git (familiar)\n\n## Alternativas Consideradas\n| Alternativa | Pros | Contras | Raz\u00f3n de Rechazo |\n| ----------- | ---- | ------- | ---------------- |\n| Git LFS | Simple, integrado en Git | No soporta pipelines, costoso para archivos grandes | Sin reproducibilidad de pipelines |\n| Delta Lake | Excelente para data lakes | Requiere Spark, overkill para nuestro caso | Complejidad innecesaria |\n| DagsHub | DVC + MLflow hosted | Vendor lock-in, costo | Preferimos self-hosted |\n\n## Referencias\n- [DVC vs Git LFS](https://dvc.org/doc/user-guide/large-dataset-optimization)\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#mapa-mental-de-conceptos-adrs","title":"\ud83e\udde0 Mapa Mental de Conceptos: ADRs","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551    ADR: ARCHITECTURE DECISION RECORD  \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                                 \u25bc                                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    CONTEXTO      \u2502             \u2502    DECISI\u00d3N      \u2502             \u2502  CONSECUENCIAS   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                \u2502                                   \u2502\n\u251c\u2500 \u00bfCu\u00e1l es el problema?        \u251c\u2500 \u00bfQu\u00e9 elegimos?                   \u251c\u2500 Positivas\n\u251c\u2500 \u00bfQu\u00e9 restricciones?          \u251c\u2500 \u00bfPor qu\u00e9?                        \u251c\u2500 Negativas\n\u2514\u2500 \u00bfQu\u00e9 opciones hay?           \u2514\u2500 \u00bfCu\u00e1ndo se decidi\u00f3?              \u2514\u2500 Neutras\n                                                                            \u2502\n                                                                            \u25bc\n                                                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                                   \u2502   ALTERNATIVAS   \u2502\n                                                                   \u2502   RECHAZADAS     \u2502\n                                                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Elemento Prop\u00f3sito Ejemplo Estado \u00bfVigente o superado? Propuesto, Aceptado, Deprecado Contexto \u00bfPor qu\u00e9 decidir esto? \"Necesitamos API REST, opciones: Flask, FastAPI\" Decisi\u00f3n \u00bfQu\u00e9 elegimos? \"Usaremos FastAPI\" Consecuencias \u00bfQu\u00e9 ganamos/perdemos? \"+: Async, Tipos Alternativas \u00bfQu\u00e9 rechazamos y por qu\u00e9? \"Flask: sin async, sin tipos\""},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-puente-tu-primer-adr","title":"\ud83d\udcbb Ejercicio Puente: Tu Primer ADR","text":"<p>Meta: Antes de documentar decisiones ML complejas, practica con decisiones simples.</p> <p>Ejercicio: Base de Datos para App de Notas <pre><code># ADR-001: Elegir Base de Datos\n\n## Contexto\nNecesitamos almacenar notas de usuarios. Opciones:\n- PostgreSQL (relacional)\n- MongoDB (documento)\n- Firebase (serverless)\n\n## TU TAREA: Completa el ADR\n\n## Decisi\u00f3n\n[\u00bfCu\u00e1l elegir\u00edas para una app simple de notas y por qu\u00e9?]\n\n## Consecuencias\n### Positivas\n- ...\n\n### Negativas\n- ...\n\n## Alternativas Rechazadas\n| Alternativa | Raz\u00f3n de Rechazo |\n|-------------|------------------|\n| ...         | ...              |\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code># ADR-001: Usar Firebase Firestore\n\n## Estado\nAceptado\n\n## Contexto\nApp de notas m\u00f3vil simple. Prioridades:\n- Time-to-market r\u00e1pido (MVP en 2 semanas)\n- Sin backend que mantener\n- Sync autom\u00e1tico entre dispositivos\n\n## Decisi\u00f3n\nUsaremos **Firebase Firestore** como base de datos.\n\n## Consecuencias\n### Positivas\n- Zero backend: SDK directo desde app\n- Sync real-time incluido\n- Auth integrado\n- Escalado autom\u00e1tico\n\n### Negativas\n- Vendor lock-in (Google)\n- Queries limitados vs SQL\n- Costos pueden escalar con usuarios\n\n## Alternativas Rechazadas\n| Alternativa | Raz\u00f3n de Rechazo |\n|-------------|------------------|\n| PostgreSQL | Requiere backend, m\u00e1s tiempo de desarrollo |\n| MongoDB | Similar overhead que Postgres para MVP |\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#practica-del-portafolio-adrs-para-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: ADRs para BankChurn","text":"<p>Tarea: Crear al menos 2 ADRs para decisiones clave de BankChurn-Predictor.</p> <p>ADR 1: Framework de API (pistas guiadas) <pre><code># ADR-003: FastAPI sobre Flask\n\n## Contexto\n# Pista: \u00bfPor qu\u00e9 necesitas API? \u00bfQu\u00e9 opciones hay?\n\n## Decisi\u00f3n\n# Pista: \u00bfQu\u00e9 eligi\u00f3 el portafolio?\n\n## Consecuencias\n# Positivas: Pydantic, OpenAPI, async...\n# Negativas: Menos tutoriales, async learning curve...\n\n## Alternativas\n# Flask: \u00bfpor qu\u00e9 no?\n# Django REST: \u00bfpor qu\u00e9 no?\n</code></pre></p> <p>ADR 2: Pipeline Unificado vs Separado <pre><code># ADR-004: Pipeline \u00danico\n\n## Contexto\n# \u00bfGuardar preprocessor.pkl y model.pkl separados, o todo junto?\n\n## Decisi\u00f3n\n# \u00bfQu\u00e9 hace el portafolio?\n\n## Consecuencias\n# \u00bfQu\u00e9 problema resuelve el pipeline \u00fanico?\n</code></pre></p> <p>Paso Final: Guarda en docs/decisions/ <pre><code>mkdir -p BankChurn-Predictor/docs/decisions\ntouch BankChurn-Predictor/docs/decisions/ADR-003-fastapi.md\ntouch BankChurn-Predictor/docs/decisions/ADR-004-pipeline.md\n</code></pre></p>"},{"location":"docs/02_DISENO_SISTEMAS/#checkpoint-de-conocimiento-adrs","title":"\u2705 Checkpoint de Conocimiento: ADRs","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 documentar alternativas RECHAZADAS es tan importante como la decisi\u00f3n tomada?</p> <p>A) Para demostrar que investigaste B) Para que futuros devs no propongan lo mismo sin saber por qu\u00e9 se rechaz\u00f3 C) Porque es el formato est\u00e1ndar D) Para tener m\u00e1s documentaci\u00f3n  </p> <p>Pregunta 2: Un ADR dice \"Estado: Aceptado\" pero hace 2 a\u00f1os que el equipo usa otra tecnolog\u00eda. \u00bfQu\u00e9 deber\u00edas hacer?</p> <p>A) Eliminarlo B) Cambiarlo a \"Deprecado\" o \"Superseded por ADR-XXX\" C) Dejarlo como est\u00e1 D) Crear un nuevo ADR sin mencionar el viejo  </p> <p>Pregunta 3: \u00bfCu\u00e1ndo deber\u00edas crear un nuevo ADR?</p> <p>A) Para cada l\u00ednea de c\u00f3digo B) Para decisiones que afectan arquitectura y son dif\u00edciles de revertir C) Solo cuando el manager lo pide D) Al final del proyecto  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Un nuevo developer pregunta:\n\"\u00bfPor qu\u00e9 usamos DVC y no Git LFS? LFS parece m\u00e1s simple.\"\n\nNo hay ADR documentando esta decisi\u00f3n.\n\n\u00bfQu\u00e9 har\u00edas?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Para que futuros devs no propongan lo mismo sin saber por qu\u00e9 se rechaz\u00f3. Evita discusiones repetidas.  **Pregunta 2**: B) Cambiarlo a \"Deprecado\" o \"Superseded por ADR-XXX\". Mant\u00e9n el historial pero marca que ya no aplica.  **Pregunta 3**: B) Para decisiones que afectan arquitectura y son dif\u00edciles de revertir.  **Escenario de Debugging**:  1. **Ahora**: Explica verbalmente la raz\u00f3n (DVC tiene pipelines, LFS no) 2. **Despu\u00e9s**: Crea el ADR que falta (ADR-004: DVC sobre Git LFS) 3. **Lecci\u00f3n**: Las decisiones t\u00e1citas son deuda de documentaci\u00f3n  <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#26-ejercicio-integrador-disena-tu-sistema","title":"2.6 Ejercicio Integrador: Dise\u00f1a Tu Sistema","text":""},{"location":"docs/02_DISENO_SISTEMAS/#entregables","title":"Entregables","text":"<p>Para tu proyecto elegido, crea los siguientes archivos en <code>docs/</code>:</p> <ol> <li><code>ML_CANVAS.md</code>: ML Canvas completo (usa el template)</li> <li><code>ARCHITECTURE.md</code>: Diagramas C4 (al menos Contexto y Contenedores)</li> <li><code>decisions/ADR-001.md</code>: Al menos 2 ADRs para decisiones clave</li> </ol>"},{"location":"docs/02_DISENO_SISTEMAS/#criterios-de-evaluacion","title":"Criterios de Evaluaci\u00f3n","text":"Criterio B\u00e1sico (60-69) Competente (70-84) Destacado (85-100) ML Canvas Secciones incompletas Todas las secciones, algunos detalles vagos Completo con m\u00e9tricas espec\u00edficas y cuantificadas Diagramas Solo texto descriptivo Diagramas ASCII o b\u00e1sicos Mermaid/PlantUML correctos y claros ADRs Sin ADRs 1 ADR b\u00e1sico 2+ ADRs con alternativas y trade-offs"},{"location":"docs/02_DISENO_SISTEMAS/#errores-habituales-y-como-depurarlos-en-el-diseno-de-sistemas-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en el dise\u00f1o de sistemas ML","text":"<p>Este m\u00f3dulo es de arquitectura y dise\u00f1o, as\u00ed que muchos errores no se ven como stack traces, sino como malas decisiones que explotan meses despu\u00e9s. La idea es aprender a detectarlos temprano.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/02_DISENO_SISTEMAS/#1-ml-canvas-bonito-pero-inutil-problema-de-negocio-vago","title":"1) ML Canvas bonito pero in\u00fatil (problema de negocio vago)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El ML Canvas est\u00e1 lleno de buzzwords: \u201cmejorar la experiencia del usuario\u201d, \u201coptimizar procesos\u201d.</li> <li>No hay n\u00fameros: ni costo actual, ni ROI esperado, ni objetivo cuantitativo.</li> <li>Nadie del negocio puede decir si el modelo \u201cvali\u00f3 la pena\u201d o no.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Relee tus secciones 1. Problema de Negocio y 2. Propuesta de Valor:</li> <li>\u00bfHay cantidades concretas? (<code>$</code>, %, horas, tickets, churn\u2026)</li> <li>\u00bfExiste una hip\u00f3tesis de mejora medible?</li> <li>Preg\u00fantate: \u201csi ma\u00f1ana entrego el modelo, \u00bfc\u00f3mo sabr\u00eda si impact\u00f3 algo?\u201d.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Fuerza al menos:</li> <li>1 m\u00e9trica de negocio actual (ej: churn 20%, tiempo de resoluci\u00f3n 48h).</li> <li>1 objetivo de mejora (reducir churn a 16%, bajar a 24h).</li> <li>1 m\u00e9trica t\u00e9cnica alineada (AUC, RMSE, etc.).</li> <li>Usa como referencia los ejemplos de BankChurn, CarVision y TelecomAI:</li> <li>Revisa sus READMEs y m\u00e9tricas en MLflow para ver c\u00f3mo se conectan a objetivos claros.</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#2-diagramas-c4-que-no-reflejan-el-codigo-real","title":"2) Diagramas C4 que no reflejan el c\u00f3digo real","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El diagrama de contenedores muestra 10 microservicios, pero en el repo solo hay 1 API monol\u00edtica.</li> <li>Aparecen bases de datos o colas que no existen en <code>docker-compose.demo.yml</code> ni en <code>k8s/</code>.</li> <li>Personas nuevas en el equipo se confunden porque \u201cla arquitectura del doc no coincide con la realidad\u201d.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Abre simult\u00e1neamente:</li> <li><code>docs/architecture/*.md</code> en la ra\u00edz del portafolio.</li> <li><code>BankChurn-Predictor/docs/ARCHITECTURE.md</code>, <code>CarVision-Market-Intelligence/docs/ARCHITECTURE.md</code>, <code>TelecomAI-Customer-Intelligence/docs/ARCHITECTURE.md</code>.</li> <li><code>docker-compose.demo.yml</code> y los manifests de <code>k8s/</code>.</li> <li>Recorre tu diagrama C4 y marca:</li> <li>\u00bfExiste un mapeo 1:1 entre contenedores y artefactos reales (servicio Docker, deployment de K8s, app FastAPI/Streamlit)?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Primero, documenta la arquitectura que realmente existe hoy (MVP), no la ideal de dentro de 1 a\u00f1o.</li> <li>Aseg\u00farate de que cada contenedor en el diagrama:</li> <li>Tiene un <code>Dockerfile</code> o entrada en <code>docker-compose.demo.yml</code>.</li> <li>O es un servicio externo claramente etiquetado (MLflow, Prometheus, Grafana, CRM, etc.).</li> <li>Para la arquitectura futura, sep\u00e1rala expl\u00edcitamente como \u201cV2 / visi\u00f3n\u201d para no confundir.</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#3-ignorar-requisitos-no-funcionales-latencia-throughput-observabilidad","title":"3) Ignorar requisitos no funcionales (latencia, throughput, observabilidad)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El modelo en notebook va bien, pero la API en producci\u00f3n tiene:</li> <li>Latencias &gt; 2\u20133s.</li> <li>Timeouts bajo carga.</li> <li>M\u00e9tricas inexistentes o imposibles de interpretar.</li> <li>No hay l\u00edneas claras en el ML Canvas ni en C4 sobre SLAs/SLIs.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa las secciones 6. M\u00e9tricas de \u00c9xito y tus diagramas:</li> <li>\u00bfHablaste de latencia, throughput, uptime, m\u00e9tricas de observabilidad?</li> <li>\u00bfTu diagrama de inferencia incluye Prometheus/Grafana/Logging como en <code>GUIA_AUDIOVISUAL.md</code> y los manifests de <code>k8s/</code>?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>A\u00f1ade expl\u00edcitamente en el ML Canvas:</li> <li>M\u00e9tricas de sistema (latencia P95/P99, QPS, uptime, tiempo de warmup).</li> <li>M\u00e9tricas de monitoreo (errores 5xx, requests por endpoint, uso de CPU/memoria).</li> <li>Refleja esos componentes en C4:</li> <li>Contenedores Prometheus/Grafana.</li> <li>Endpoints <code>/metrics</code> en las APIs FastAPI.</li> <li>Conecta esto al futuro m\u00f3dulo de Observabilidad (16_OBSERVABILIDAD) para que el dise\u00f1o no sea \u201cciego\u201d.</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#4-adrs-inexistentes-o-que-nadie-lee","title":"4) ADRs inexistentes o que nadie lee","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Decisiones importantes viven solo en la cabeza de alguien: \u201ceso lo decidi\u00f3 X hace meses\u201d.</li> <li>Existen ADRs, pero:</li> <li>Est\u00e1n vac\u00edos, sin alternativas ni consecuencias.</li> <li>Nadie los actualiza cuando se revierte una decisi\u00f3n.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa <code>DECISIONES_TECH.md</code> y cualquier carpeta <code>docs/decisions/</code>.</li> <li>Preg\u00fantate para cada secci\u00f3n del sistema:</li> <li>\u00bfPor qu\u00e9 FastAPI y no Flask?</li> <li>\u00bfPor qu\u00e9 DVC y no Git LFS?</li> <li>\u00bfPor qu\u00e9 MLflow y no W&amp;B?</li> <li>Si la respuesta no est\u00e1 escrita en un ADR, tienes una decisi\u00f3n t\u00e1cita peligrosa.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Para cada decisi\u00f3n grande (API, tracking, versionado de datos, infraestructura):</li> <li>Crea un ADR corto siguiendo el template de este m\u00f3dulo.</li> <li>A\u00f1ade al menos 1 alternativa rechazada y la raz\u00f3n.</li> <li>Marca el estado (<code>Aceptado</code>, <code>Deprecado</code>, <code>Superseded</code>) cuando cambies de opini\u00f3n.</li> <li>Enlaza los ADRs desde <code>DECISIONES_TECH.md</code> y desde la documentaci\u00f3n de cada proyecto.</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#5-patron-de-debugging-de-diseno","title":"5) Patr\u00f3n de debugging de dise\u00f1o","text":"<ol> <li>Empieza en el negocio: revisa si el problema y el ROI est\u00e1n cuantificados.</li> <li>Sigue con el Canvas: \u00bfest\u00e1n completas las 8 secciones? \u00bffaltan riesgos o restricciones legales?</li> <li>Baja a C4: verifica que contextos y contenedores existen realmente en c\u00f3digo/infra.</li> <li>Cierra con ADRs: aseg\u00farate de que las decisiones clave no viven solo en la memoria del equipo.</li> </ol> <p>Si recorres este pipeline de pensamiento cada vez que dise\u00f1as (o revisas) un sistema, pensar\u00e1s como un arquitecto Senior incluso en proyectos peque\u00f1os.</p> <p></p>"},{"location":"docs/02_DISENO_SISTEMAS/#27-autoevaluacion","title":"2.7 Autoevaluaci\u00f3n","text":""},{"location":"docs/02_DISENO_SISTEMAS/#checklist","title":"Checklist","text":"<pre><code>TRADUCCI\u00d3N NEGOCIO \u2192 ML:\n[ ] Puedo identificar el problema de negocio detr\u00e1s de un proyecto ML\n[ ] S\u00e9 calcular ROI esperado de una soluci\u00f3n ML\n[ ] Puedo elegir la m\u00e9trica t\u00e9cnica correcta seg\u00fan el problema\n\nML CANVAS:\n[ ] Puedo completar las 8 secciones del ML Canvas\n[ ] S\u00e9 identificar riesgos t\u00e9cnicos, operacionales y \u00e9ticos\n[ ] Puedo definir m\u00e9tricas de negocio, modelo y sistema\n\nARQUITECTURA C4:\n[ ] Entiendo los 4 niveles del modelo C4\n[ ] Puedo dibujar diagramas de Contexto y Contenedores\n[ ] S\u00e9 usar Mermaid para diagramas\n\nADRs:\n[ ] Entiendo el prop\u00f3sito de los ADRs\n[ ] Puedo documentar decisiones con alternativas y trade-offs\n[ ] S\u00e9 cu\u00e1ndo crear un nuevo ADR vs actualizar uno existente\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#preguntas-de-reflexion","title":"Preguntas de Reflexi\u00f3n","text":"<ol> <li>\u00bfPor qu\u00e9 es importante cuantificar el problema de negocio antes de empezar?</li> <li>\u00bfQu\u00e9 pasa si no documentas las decisiones arquitect\u00f3nicas?</li> <li>\u00bfCu\u00e1ndo es apropiado NO usar ML para resolver un problema?</li> </ol>"},{"location":"docs/02_DISENO_SISTEMAS/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El dise\u00f1o de sistemas no es solo teor\u00eda. Aqu\u00ed est\u00e1 c\u00f3mo se aplic\u00f3 en el portafolio real:</p>"},{"location":"docs/02_DISENO_SISTEMAS/#ml-canvas-del-portafolio","title":"ML Canvas del Portafolio","text":"<p>Cada proyecto tiene su Canvas impl\u00edcito en la documentaci\u00f3n:</p> Proyecto Problema de Negocio M\u00e9trica de Negocio M\u00e9trica ML BankChurn Reducir p\u00e9rdida de clientes Retenci\u00f3n +5% AUC-ROC, Recall CarVision Pricing automatizado de autos Error de precio &lt;10% MAE, R\u00b2 TelecomAI Segmentaci\u00f3n de clientes Campa\u00f1as personalizadas Accuracy, F1"},{"location":"docs/02_DISENO_SISTEMAS/#arquitectura-c4-del-portafolio","title":"Arquitectura C4 del Portafolio","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ML-MLOps-Portfolio (CONTEXTO)                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   BankChurn     \u2502  \u2502   CarVision     \u2502  \u2502   TelecomAI     \u2502  \u2502\n\u2502  \u2502   Predictor     \u2502  \u2502   Market Intel  \u2502  \u2502   Customer Int  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502           \u2502                    \u2502                    \u2502           \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502                               \u2502                                 \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502\n\u2502                    \u2502   common_utils/     \u2502                      \u2502\n\u2502                    \u2502   (logger, seed)    \u2502                      \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502\n\u2502                               \u2502                                 \u2502\n\u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502           \u2502          GitHub Actions CI            \u2502             \u2502\n\u2502           \u2502   (ci-mlops.yml, matrix testing)      \u2502             \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#adrs-del-portafolio","title":"ADRs del Portafolio","text":"<p>Las decisiones arquitect\u00f3nicas est\u00e1n documentadas en: - <code>docs/guia_mlops/DECISIONES_TECH.md</code> \u2192 ADRs globales - <code>*/docs/ARCHITECTURE.md</code> \u2192 ADRs por proyecto</p> <p>Ejemplo ADR real del portafolio: <pre><code># ADR-001: Pipeline Unificado vs Artefactos Separados\n\n## Contexto\nInicialmente BankChurn guardaba preprocessor.pkl y model.pkl por separado.\n\n## Decisi\u00f3n\nUnificar todo en un solo pipeline.pkl\n\n## Consecuencias\n\u2705 Elimina training-serving skew\n\u2705 Un solo artefacto para deploy\n\u274c Archivo m\u00e1s grande\n</code></pre></p>"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-revisa-la-arquitectura-real","title":"\ud83d\udd27 Ejercicio: Revisa la Arquitectura Real","text":"<pre><code># Ver la arquitectura de BankChurn\ncat BankChurn-Predictor/docs/architecture.md\n\n# Ver las decisiones t\u00e9cnicas globales\ncat docs/guia_mlops/DECISIONES_TECH.md\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#diagramas-mermaid-de-arquitectura","title":"\ud83d\udcca Diagramas Mermaid de Arquitectura","text":""},{"location":"docs/02_DISENO_SISTEMAS/#flujo-de-datos-mlops","title":"Flujo de Datos MLOps","text":"<pre><code>flowchart LR\n    subgraph Data[\"\ud83d\udcca Data Layer\"]\n        RAW[(Raw Data)]\n        DVC[DVC Storage]\n    end\n\n    subgraph Training[\"\ud83c\udfaf Training\"]\n        PIPE[sklearn Pipeline]\n        MLFLOW[MLflow Tracking]\n        ART[Artifacts]\n    end\n\n    subgraph Serving[\"\ud83d\ude80 Serving\"]\n        API[FastAPI]\n        DASH[Streamlit]\n    end\n\n    subgraph Ops[\"\u2699\ufe0f Operations\"]\n        CI[GitHub Actions]\n        DOCKER[Docker]\n        K8S[Kubernetes]\n    end\n\n    RAW --&gt; DVC\n    DVC --&gt; PIPE\n    PIPE --&gt; MLFLOW\n    PIPE --&gt; ART\n    ART --&gt; API\n    ART --&gt; DASH\n    CI --&gt; DOCKER\n    DOCKER --&gt; K8S\n    K8S --&gt; API</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#pipeline-de-ml-c4-container","title":"Pipeline de ML (C4 - Container)","text":"<pre><code>flowchart TB\n    subgraph Pipeline[\"sklearn Pipeline\"]\n        direction TB\n        FE[FeatureEngineer]\n        CT[ColumnTransformer]\n        MODEL[RandomForest]\n\n        FE --&gt; CT --&gt; MODEL\n    end\n\n    subgraph Preprocessor[\"ColumnTransformer\"]\n        NUM[Numeric: Imputer + Scaler]\n        CAT[Categorical: OneHotEncoder]\n        BIN[Binary: Passthrough]\n    end\n\n    CT -.-&gt; Preprocessor</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code>flowchart LR\n    PUSH[Git Push] --&gt; LINT[Lint &amp; Format]\n    LINT --&gt; TEST[pytest + Coverage]\n    TEST --&gt; SEC[Security Scan]\n    SEC --&gt; BUILD[Docker Build]\n    BUILD --&gt; PUSH_REG[Push to Registry]\n    PUSH_REG --&gt; DEPLOY[Deploy to K8s]\n\n    style PUSH fill:#e1f5fe\n    style DEPLOY fill:#c8e6c9</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/02_DISENO_SISTEMAS/#para-entrevistas-de-system-design","title":"Para Entrevistas de System Design","text":"<ol> <li> <p>Siempre empieza con requisitos: Antes de dibujar, pregunta sobre escala, latencia esperada, y casos de uso principales.</p> </li> <li> <p>Conoce los trade-offs: \"\u00bfPor qu\u00e9 elegiste esta arquitectura?\" es la pregunta que siempre viene. Ten lista tu justificaci\u00f3n.</p> </li> <li> <p>Menciona observabilidad: Pocos candidatos hablan de logs, m\u00e9tricas y alertas. Hacerlo te diferencia.</p> </li> </ol>"},{"location":"docs/02_DISENO_SISTEMAS/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Sistema nuevo Empieza simple (monolito), escala despu\u00e9s Alta disponibilidad Dise\u00f1a para fallos: circuit breakers, retries, fallbacks Decisiones de arquitectura Documenta en ADRs (Architecture Decision Records) Integraci\u00f3n con ML Separa serving de training, usa feature stores"},{"location":"docs/02_DISENO_SISTEMAS/#patrones-que-debes-conocer","title":"Patrones que Debes Conocer","text":"<ul> <li>Batch vs Streaming: Cu\u00e1ndo usar cada uno para ML pipelines</li> <li>Event-Driven: Para sistemas desacoplados y escalables</li> <li>CQRS: Cuando lectura y escritura tienen requisitos muy diferentes</li> <li>Saga Pattern: Para transacciones distribuidas</li> </ul>"},{"location":"docs/02_DISENO_SISTEMAS/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/02_DISENO_SISTEMAS/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 System Design for ML Chip Huyen 45 min YouTube \ud83d\udd34 C4 Model for Software Architecture Simon Brown 50 min YouTube \ud83d\udfe1 ML System Design Interview Data Interview Pro 30 min YouTube"},{"location":"docs/02_DISENO_SISTEMAS/#cursos","title":"\ud83d\udcda Cursos","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Duraci\u00f3n Link \ud83d\udfe1 Machine Learning System Design Educative 8h Educative \ud83d\udfe2 Designing ML Systems O'Reilly (Chip Huyen) Libro O'Reilly"},{"location":"docs/02_DISENO_SISTEMAS/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 ML Canvas Plantilla interactiva \ud83d\udd34 C4 Model Documentaci\u00f3n oficial C4 \ud83d\udfe1 ADR GitHub Templates y ejemplos ADR"},{"location":"docs/02_DISENO_SISTEMAS/#decisiones-tecnicas-del-modulo","title":"\u2696\ufe0f Decisiones T\u00e9cnicas del M\u00f3dulo","text":""},{"location":"docs/02_DISENO_SISTEMAS/#adr-000-metodologia-de-diseno","title":"ADR-000: Metodolog\u00eda de Dise\u00f1o","text":"<p>Contexto: Necesitamos un proceso sistem\u00e1tico para dise\u00f1ar sistemas ML.</p> <p>Decisi\u00f3n: Usar ML Canvas + C4 Model + ADRs.</p> <p>Alternativas Consideradas: - Solo diagramas libres: Inconsistente entre proyectos - UML completo: Overkill para proyectos ML - Sin documentaci\u00f3n: Deuda t\u00e9cnica acumulada</p> <p>Consecuencias: - \u2705 Proceso repetible y consistente - \u2705 Documentaci\u00f3n como c\u00f3digo - \u2705 Decisiones auditables - \u274c Overhead inicial en proyectos peque\u00f1os</p>"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-21-ml-canvas-completo","title":"Ejercicio 2.1: ML Canvas Completo","text":"<p>Objetivo: Documentar un proyecto ML usando ML Canvas. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Completa el ML Canvas para BankChurn-Predictor\n\n## 1. Problema de Negocio\n- \u00bfQu\u00e9 problema resuelve?\n- \u00bfCu\u00e1l es el impacto econ\u00f3mico?\n\n## 2. Fuentes de Datos\n- \u00bfDe d\u00f3nde vienen los datos?\n- \u00bfQu\u00e9 volumen tienen?\n\n## 3. Caracter\u00edsticas del Modelo\n- \u00bfQu\u00e9 features usar\u00e1s?\n- \u00bfQu\u00e9 algoritmo elegir\u00e1s?\n\n## 4. Restricciones\n- \u00bfLatencia m\u00e1xima?\n- \u00bfRequisitos de privacidad?\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># ML Canvas: BankChurn-Predictor\n\n## 1. Problema de Negocio\n- **Problema**: Predecir qu\u00e9 clientes abandonar\u00e1n el banco en los pr\u00f3ximos 30 d\u00edas\n- **Impacto**: Retener 5% de churners \u2192 $2M/a\u00f1o en CLV preservado\n- **KPI**: Reducir churn rate de 20% a 15%\n\n## 2. Fuentes de Datos\n- **Origen**: CRM bancario (tabla customers), transacciones, interacciones\n- **Volumen**: 10K clientes activos, 500K transacciones/mes\n- **Frecuencia**: Batch diario para features, real-time para scoring\n\n## 3. Caracter\u00edsticas del Modelo\n- **Features**: tenure, balance, num_products, is_active, geography, age\n- **Target**: churned (0/1) en ventana de 30 d\u00edas\n- **Algoritmo**: Random Forest (interpretabilidad para compliance)\n- **M\u00e9tricas**: Recall \u2265 0.80, Precision \u2265 0.70\n\n## 4. Restricciones\n- **Latencia**: &lt; 200ms para scoring individual\n- **Privacidad**: No usar datos PII directamente\n- **Compliance**: Modelo explicable para auditor\u00eda bancaria\n- **Infraestructura**: Debe correr en AWS con budget limitado\n\n## 5. Integraci\u00f3n\n- **Input**: API REST recibe customer_id\n- **Output**: probability, risk_level, top_3_factors\n- **Downstream**: Dashboard ejecutivo, CRM alerts\n\n## 6. M\u00e9tricas de \u00c9xito\n- **ML**: F1 \u2265 0.75, AUC \u2265 0.85\n- **Negocio**: Reducci\u00f3n churn 5pp en 6 meses\n- **Sistema**: Uptime 99.5%, P95 latency &lt; 200ms\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#ejercicio-22-escribir-un-adr","title":"Ejercicio 2.2: Escribir un ADR","text":"<p>Objetivo: Documentar una decisi\u00f3n t\u00e9cnica con ADR. Dificultad: \u2b50\u2b50</p> <pre><code># ADR-XXX: [Tu Decisi\u00f3n]\n\n## Contexto\n[\u00bfPor qu\u00e9 necesitas tomar esta decisi\u00f3n?]\n\n## Decisi\u00f3n\n[\u00bfQu\u00e9 decidiste?]\n\n## Alternativas Consideradas\n[\u00bfQu\u00e9 otras opciones evaluaste?]\n\n## Consecuencias\n[\u00bfQu\u00e9 implica esta decisi\u00f3n?]\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># ADR-004: FastAPI para APIs de Inferencia\n\n## Estado\nAceptado\n\n## Contexto\nNecesitamos exponer modelos ML como APIs REST. Los requisitos son:\n- Latencia baja (&lt;100ms overhead)\n- Validaci\u00f3n autom\u00e1tica de inputs\n- Documentaci\u00f3n auto-generada\n- Async para m\u00faltiples requests\n\n## Decisi\u00f3n\nUsar FastAPI como framework para todas las APIs de inferencia.\n\n## Alternativas Consideradas\n\n### Flask\n- \u2705 Simple, ampliamente conocido\n- \u274c Sync por defecto, validaci\u00f3n manual\n- \u274c Docs manuales con Swagger\n\n### Django REST\n- \u2705 Batteries-included, ORM potente\n- \u274c Overkill para microservicios ML\n- \u274c Overhead de performance\n\n### gRPC\n- \u2705 Muy r\u00e1pido, tipado fuerte\n- \u274c M\u00e1s complejo de implementar\n- \u274c Debugging menos intuitivo\n\n## Consecuencias\n\n### Positivas\n- Validaci\u00f3n autom\u00e1tica con Pydantic\n- Docs OpenAPI auto-generadas en /docs\n- Async nativo para alto throughput\n- Type hints = c\u00f3digo autodocumentado\n\n### Negativas\n- Framework relativamente nuevo\n- Menos recursos legacy que Flask\n- Requiere entender async/await\n\n## Referencias\n- [FastAPI Docs](https://fastapi.tiangolo.com/)\n- M\u00f3dulo 14: APIs de Producci\u00f3n\n</code></pre>"},{"location":"docs/02_DISENO_SISTEMAS/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n ML Canvas Template de 1 p\u00e1gina para dise\u00f1ar proyectos ML end-to-end C4 Model Modelo jer\u00e1rquico de arquitectura: Context, Container, Component, Code ADR Architecture Decision Record - documento que captura decisiones t\u00e9cnicas SLA/SLI/SLO Acuerdos, indicadores y objetivos de nivel de servicio   **Siguiente m\u00f3dulo** \u2192 [03. Estructura de Proyecto](03_ESTRUCTURA_PROYECTO.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/03_ESTRUCTURA_PROYECTO/","title":"03. Estructura de Proyecto ML Profesional","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Crear la estructura de proyecto que usar\u00e1s en los 3 proyectos del portafolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  Una buena estructura de proyecto es como los cimientos de una casa:         \u2551\n\u2551  invisible cuando est\u00e1 bien hecha, DESASTROSA cuando est\u00e1 mal.               \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 01_PYTHON_MODERNO (type hints + <code>src/</code> layout).</li> <li>Tener claro qu\u00e9 proyecto del portafolio vas a usar como base (BankChurn, CarVision, TelecomAI).</li> <li>Poder ejecutar comandos b\u00e1sicos (instalar deps, correr tests).</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de tocar el repo: abre Protocolo E y define tu output m\u00ednimo (ej: \u201cestructura + <code>pyproject.toml</code> + Makefile + tests corriendo\u201d).</li> <li>Mientras implementas: si te atoras &gt;15 min (imports, <code>pip install -e</code>, targets del Makefile), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir qu\u00e9 mejorar (DX, reproducibilidad, CI).</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] \u00c1rbol de proyecto consistente con <code>src/</code>, <code>tests/</code>, <code>configs/</code>, <code>data/</code> (gitignored) y <code>artifacts/</code> (gitignored).</li> <li>[ ] Instalaci\u00f3n editable funcionando: <code>pip install -e \".[dev]\"</code>.</li> <li>[ ] Tests ejecutables desde la ra\u00edz: <code>pytest</code>.</li> <li>[ ] Makefile con al menos: <code>install</code>, <code>test</code>, <code>lint</code> (y opcional <code>train</code>, <code>serve</code>).</li> </ul> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: estructura del repo / packaging / DX</li> <li>Archivo: <code>pyproject.toml</code>, <code>Makefile</code>, <code>.gitignore</code>, <code>src/&lt;paquete&gt;/</code>, <code>tests/</code></li> <li>Prueba: <code>pip install -e \".[dev]\"</code> + <code>pytest</code> + <code>ruff check</code> + <code>mypy src/</code></li> <li>Evidencia: un repo que corre igual en tu m\u00e1quina y en CI.</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>La Estructura del Portafolio</li> <li>C\u00f3mo se aplica en este portafolio</li> <li>pyproject.toml completo</li> <li>Makefile</li> <li>.gitignore</li> <li>\ud83d\udd2c Ingenier\u00eda Inversa: Estructura Real</li> <li>Errores habituales y c\u00f3mo depurarlos</li> <li>\ud83d\udcd3 Refactoring: De Notebook a Producci\u00f3n \u2b50 INTEGRADO</li> <li>\ud83d\udce6 Librer\u00edas Compartidas (common_utils) \u2b50 INTEGRADO</li> <li>\ud83c\udf93 Secci\u00f3n Pedag\u00f3gica: Aprende Haciendo \u2b50 NUEVO</li> <li>Consejos Profesionales</li> <li>Recursos Externos Recomendados</li> <li>Referencias del Glosario</li> <li>Plantillas Relacionadas</li> <li>Ejercicios</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#la-estructura-del-portafolio","title":"\ud83d\udccb La Estructura del Portafolio","text":"<pre><code>MiProyecto-ML/\n\u2502\n\u251c\u2500\u2500 src/                          # \ud83d\udce6 C\u00d3DIGO FUENTE (instalable)\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 miproyecto/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 config.py             # Configuraci\u00f3n Pydantic\n\u2502       \u251c\u2500\u2500 data.py               # Carga y validaci\u00f3n de datos\n\u2502       \u251c\u2500\u2500 features.py           # Feature engineering\n\u2502       \u251c\u2500\u2500 training.py           # Pipeline de entrenamiento\n\u2502       \u251c\u2500\u2500 evaluation.py         # M\u00e9tricas y evaluaci\u00f3n\n\u2502       \u251c\u2500\u2500 prediction.py         # Inferencia\n\u2502       \u2514\u2500\u2500 models.py             # Custom models/transformers\n\u2502\n\u251c\u2500\u2500 app/                          # \ud83c\udf10 APLICACIONES\n\u2502   \u251c\u2500\u2500 fastapi_app.py            # API REST\n\u2502   \u2514\u2500\u2500 streamlit_app.py          # Dashboard (opcional)\n\u2502\n\u251c\u2500\u2500 tests/                        # \ud83e\uddea TESTS (espejo de src/)\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py               # Fixtures compartidas\n\u2502   \u251c\u2500\u2500 test_config.py\n\u2502   \u251c\u2500\u2500 test_data.py\n\u2502   \u251c\u2500\u2500 test_features.py\n\u2502   \u251c\u2500\u2500 test_training.py\n\u2502   \u2514\u2500\u2500 test_api.py\n\u2502\n\u251c\u2500\u2500 configs/                      # \u2699\ufe0f CONFIGURACI\u00d3N\n\u2502   \u2514\u2500\u2500 config.yaml               # Hiperpar\u00e1metros, paths, etc.\n\u2502\n\u251c\u2500\u2500 data/                         # \ud83d\udcca DATOS (gitignored)\n\u2502   \u251c\u2500\u2500 raw/                      # Datos originales\n\u2502   \u2514\u2500\u2500 processed/                # Datos procesados (opcional)\n\u2502\n\u251c\u2500\u2500 artifacts/                    # \ud83d\udcc1 ARTEFACTOS (gitignored)\n\u2502   \u251c\u2500\u2500 model.joblib              # Modelo entrenado\n\u2502   \u2514\u2500\u2500 metrics.json              # M\u00e9tricas de entrenamiento\n\u2502\n\u251c\u2500\u2500 scripts/                      # \ud83d\udd27 SCRIPTS AUXILIARES\n\u2502   \u2514\u2500\u2500 run_mlflow.py             # Script de MLflow\n\u2502\n\u251c\u2500\u2500 docs/                         # \ud83d\udcd6 DOCUMENTACI\u00d3N\n\u2502   \u251c\u2500\u2500 model_card.md\n\u2502   \u2514\u2500\u2500 data_card.md\n\u2502\n\u251c\u2500\u2500 infra/                        # \ud83c\udfd7\ufe0f INFRAESTRUCTURA (opcional)\n\u2502   \u2514\u2500\u2500 terraform/\n\u2502\n\u251c\u2500\u2500 pyproject.toml                # \ud83d\udccb METADATA DEL PROYECTO\n\u251c\u2500\u2500 requirements.txt              # \ud83d\udccb DEPENDENCIAS (para CI)\n\u251c\u2500\u2500 Makefile                      # \ud83d\udd28 COMANDOS COMUNES\n\u251c\u2500\u2500 Dockerfile                    # \ud83d\udc33 CONTAINERIZACI\u00d3N\n\u251c\u2500\u2500 .github/workflows/            # \ud83d\udd04 CI/CD\n\u2502   \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 .gitignore                    # \ud83d\udeab ARCHIVOS IGNORADOS\n\u251c\u2500\u2500 .pre-commit-config.yaml       # \ud83d\udd0d HOOKS PRE-COMMIT\n\u2514\u2500\u2500 README.md                     # \ud83d\udcd6 DOCUMENTACI\u00d3N PRINCIPAL\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#mapa-mental-de-conceptos-estructura-de-proyecto","title":"\ud83e\udde0 Mapa Mental de Conceptos: Estructura de Proyecto","text":"<pre><code>                        \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                        \u2551   ESTRUCTURA PROFESIONAL DE PROYECTO ML     \u2551\n                        \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                                   \u25bc                                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \ud83d\udce6 C\u00d3DIGO        \u2502             \u2502  \u2699\ufe0f CONFIG       \u2502             \u2502  \ud83d\udd27 HERRAMIENTAS  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 src/&lt;paquete&gt;/             \u251c\u2500 pyproject.toml               \u251c\u2500 Makefile\n\u251c\u2500 app/                       \u251c\u2500 configs/*.yaml               \u251c\u2500 Dockerfile\n\u251c\u2500 tests/                     \u251c\u2500 .pre-commit                  \u251c\u2500 .github/workflows/\n\u2514\u2500 scripts/                   \u2514\u2500 .gitignore                   \u2514\u2500 README.md\n                                         \u2502\n                                         \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502  \ud83d\udcca DATOS         \u2502\n                              \u2502  (gitignored)     \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                     \u2502\n                              \u251c\u2500 data/raw/\n                              \u251c\u2500 data/processed/\n                              \u251c\u2500 artifacts/\n                              \u2514\u2500 mlruns/\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Directorio Prop\u00f3sito Gitignored? src/ C\u00f3digo fuente instalable No tests/ Tests (espejo de src) No app/ APIs y dashboards No configs/ Configuraci\u00f3n YAML No data/ Datos raw/procesados \u2705 S\u00ed artifacts/ Modelos entrenados \u2705 S\u00ed mlruns/ Experimentos MLflow \u2705 S\u00ed"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#ejercicio-puente-crear-estructura-minima","title":"\ud83d\udcbb Ejercicio Puente: Crear Estructura M\u00ednima","text":"<p>Meta: Antes de estructurar un proyecto ML completo, practica con una estructura m\u00ednima.</p> <p>Ejercicio 1: Estructura desde cero <pre><code># TU TAREA: Crea esta estructura m\u00ednima para un proyecto \"myproject\"\n# \n# myproject/\n# \u251c\u2500\u2500 src/\n# \u2502   \u2514\u2500\u2500 myproject/\n# \u2502       \u251c\u2500\u2500 __init__.py\n# \u2502       \u2514\u2500\u2500 main.py\n# \u251c\u2500\u2500 tests/\n# \u2502   \u2514\u2500\u2500 test_main.py\n# \u251c\u2500\u2500 pyproject.toml\n# \u2514\u2500\u2500 README.md\n#\n# PISTA: Usa mkdir -p y touch\n</code></pre></p> <p>Ejercicio 2: Verificar instalaci\u00f3n <pre><code># Despu\u00e9s de crear la estructura y pyproject.toml m\u00ednimo\ncd myproject\npip install -e .\npython -c \"from myproject import main; print('\u2705 Funciona!')\"\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code># Crear estructura\nmkdir -p myproject/src/myproject myproject/tests\ntouch myproject/src/myproject/__init__.py\ntouch myproject/src/myproject/main.py\ntouch myproject/tests/test_main.py\ntouch myproject/README.md\n\n# Crear pyproject.toml m\u00ednimo\ncat &gt; myproject/pyproject.toml &lt;&lt; 'EOF'\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"myproject\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.10\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\nEOF\n\n# Verificar\ncd myproject\npip install -e .\npython -c \"from myproject import main; print('\u2705 Funciona!')\"\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#practica-del-portafolio-verificar-estructura-de-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Verificar Estructura de BankChurn","text":"<p>Tarea: Verificar que BankChurn-Predictor sigue la estructura profesional.</p> <p>Paso 1: Explora la estructura real <pre><code>cd BankChurn-Predictor\ntree -L 2 --dirsfirst\n# O sin tree: find . -maxdepth 2 -type d | head -20\n</code></pre></p> <p>Paso 2: Checklist de verificaci\u00f3n <pre><code>[ ] \u00bfExiste src/bankchurn/__init__.py?\n[ ] \u00bfExiste tests/conftest.py?\n[ ] \u00bfExiste pyproject.toml con [tool.setuptools.packages.find] where=[\"src\"]?\n[ ] \u00bfExiste Makefile con targets: install, test, lint?\n[ ] \u00bf.gitignore excluye data/, artifacts/, mlruns/?\n</code></pre></p> <p>Paso 3: Ejecuta los comandos del Makefile <pre><code>make install      # Debe funcionar sin errores\nmake test         # Debe ejecutar pytest\nmake lint         # Debe ejecutar ruff/mypy\n</code></pre></p> <p>Paso 4: Si algo falla, documenta <pre><code>\u00bfQu\u00e9 fall\u00f3? ___________________\n\u00bfPor qu\u00e9? ___________________\n\u00bfC\u00f3mo lo arreglaste? ___________________\n</code></pre></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#checkpoint-de-conocimiento-estructura-de-proyecto","title":"\u2705 Checkpoint de Conocimiento: Estructura de Proyecto","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 ponemos el c\u00f3digo en <code>src/</code> en vez de en la ra\u00edz?</p> <p>A) Es m\u00e1s r\u00e1pido B) Fuerza que el c\u00f3digo est\u00e9 INSTALADO para importarlo (evita bugs de imports) C) GitHub lo requiere D) Ocupa menos espacio  </p> <p>Pregunta 2: \u00bfPor qu\u00e9 <code>data/</code> y <code>artifacts/</code> deben estar en .gitignore?</p> <p>A) Son archivos temporales B) Son archivos binarios grandes que no deben versionarse en Git C) Git no soporta esos formatos D) Hace el repo m\u00e1s r\u00e1pido  </p> <p>Pregunta 3: \u00bfCu\u00e1l es el prop\u00f3sito del archivo <code>__init__.py</code>?</p> <p>A) Almacenar configuraci\u00f3n B) Marcar un directorio como paquete Python importable C) Ejecutar tests D) Documentar el proyecto  </p> <p>\ufffd\ufffd Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Ejecutas pytest en CI y obtienes:\n  ModuleNotFoundError: No module named 'bankchurn'\n\nPero en tu m\u00e1quina local funciona perfectamente.\n\nEl workflow de CI tiene:\n  - run: pip install -r requirements.txt\n  - run: pytest\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Fuerza que el c\u00f3digo est\u00e9 INSTALADO para importarlo. Esto evita el problema \"funciona en mi m\u00e1quina\".  **Pregunta 2**: B) Son archivos binarios grandes. Git no est\u00e1 dise\u00f1ado para archivos grandes; usa DVC o storage externo.  **Pregunta 3**: B) Marcar un directorio como paquete Python importable.  **Escenario de Debugging**:  - **Problema**: El CI solo instala dependencias, pero NO instala tu paquete. - **Soluci\u00f3n**: Cambiar el workflow: <pre><code>- run: pip install -e \".[dev]\"  # Instala TU paquete + deps\n- run: pytest\n</code></pre> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<p>Esta estructura no es te\u00f3rica: los 3 proyectos del portafolio la siguen con ligeras variaciones. Esto conecta directamente con los macro-m\u00f3dulos 00 y 01 de la Ruta 0 \u2192 Senior/Staff descrita en el SYLLABUS.</p> Proyecto Carpeta ra\u00edz Paquete principal Archivos clave BankChurn Predictor <code>BankChurn-Predictor/</code> <code>src/bankchurn/</code> <code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code> CarVision Market Intelligence <code>CarVision-Market-Intelligence/</code> <code>src/carvision/</code> <code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code> TelecomAI Customer Intelligence <code>TelecomAI-Customer-Intelligence/</code> <code>src/telecom/</code> <code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code> <p>Para aprovechar este m\u00f3dulo al m\u00e1ximo en el repositorio real:</p> <ul> <li>Compara el \u00e1rbol gen\u00e9rico de <code>MiProyecto-ML/</code> con, por ejemplo,   <code>BankChurn-Predictor/</code> (f\u00edjate especialmente en <code>src/</code>, <code>configs/</code>, <code>tests/</code>,   <code>Makefile</code> y <code>pyproject.toml</code>).</li> <li>Verifica que los comandos que defines aqu\u00ed (<code>make install</code>, <code>make test</code>,   <code>make train</code>, <code>make serve</code>) tienen su equivalente funcional en los Makefiles de   cada proyecto.</li> <li>Usa esta plantilla como referencia si creas un cuarto proyecto durante el   23_PROYECTO_INTEGRADOR.</li> </ul> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#pyprojecttoml-completo","title":"\ud83d\udcc4 pyproject.toml Completo","text":"<pre><code># pyproject.toml - El coraz\u00f3n del proyecto\n\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"bankchurn\"\nversion = \"1.0.0\"\ndescription = \"Bank Customer Churn Prediction System\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\nlicense = {text = \"MIT\"}\nauthors = [\n    {name = \"Tu Nombre\", email = \"tu@email.com\"}\n]\nkeywords = [\"machine-learning\", \"churn\", \"prediction\"]\n\ndependencies = [\n    \"pandas&gt;=2.0.0\",\n    \"numpy&gt;=1.24.0\",\n    \"scikit-learn&gt;=1.3.0\",\n    \"pydantic&gt;=2.0.0\",\n    \"pyyaml&gt;=6.0\",\n    \"joblib&gt;=1.3.0\",\n]\n\n[project.optional-dependencies]\napi = [\n    \"fastapi&gt;=0.104.0\",\n    \"uvicorn&gt;=0.24.0\",\n]\nmlflow = [\n    \"mlflow&gt;=2.9.0\",\n]\ndev = [\n    \"pytest&gt;=7.4.0\",\n    \"pytest-cov&gt;=4.1.0\",\n    \"black&gt;=23.0.0\",\n    \"ruff&gt;=0.1.0\",\n    \"mypy&gt;=1.7.0\",\n    \"pre-commit&gt;=3.5.0\",\n]\nall = [\n    \"bankchurn[api,mlflow,dev]\",\n]\n\n[project.scripts]\nbankchurn = \"bankchurn.cli:main\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# HERRAMIENTAS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\naddopts = \"-v --cov=src/bankchurn --cov-report=term-missing\"\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"tests/*\"]\n\n[tool.coverage.report]\nfail_under = 79\n\n[tool.black]\nline-length = 100\ntarget-version = [\"py311\"]\n\n[tool.ruff]\nline-length = 100\nselect = [\"E\", \"F\", \"I\", \"W\"]\nignore = [\"E501\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nignore_missing_imports = true\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#makefile","title":"\ud83d\udd28 Makefile","text":"<pre><code># Makefile - Comandos comunes del proyecto\n\n.PHONY: install test lint format train serve clean  # .PHONY: declara targets que no son archivos.\n\n# Instalaci\u00f3n\ninstall:                              # Target por defecto para desarrollo.\n    pip install -e \".[all]\"           # -e: editable (cambios se reflejan sin reinstalar). [all]: incluye todas las deps.\n\ninstall-prod:                         # Target para producci\u00f3n (sin deps de desarrollo).\n    pip install -e \".[api]\"           # Solo instala deps de API, no dev/mlflow.\n\n# Testing\ntest:                                 # Ejecuta tests con coverage.\n    pytest --cov=src/ --cov-fail-under=80  # Falla si coverage &lt; 80%.\n\ntest-fast:                            # Tests r\u00e1pidos para desarrollo.\n    pytest -m \"not slow\" -x           # -m \"not slow\": excluye tests lentos. -x: falla al primer error.\n\n# Linting y formato\nlint:                                 # Verifica calidad de c\u00f3digo.\n    ruff check src/ tests/            # Ruff: linter r\u00e1pido.\n    mypy src/                         # mypy: verificaci\u00f3n de tipos.\n\nformat:                               # Auto-formatea c\u00f3digo.\n    black src/ tests/ app/            # Black: formatter est\u00e1ndar de Python.\n    ruff check --fix src/ tests/      # --fix: auto-corrige problemas que puede.\n\n# Entrenamiento\ntrain:                                # Entrena el modelo.\n    python main.py --seed 42 train --config configs/config.yaml --input data/raw/Churn.csv\n\nserve:                                # Inicia servidor de desarrollo.\n    uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000 --reload  # --reload: reinicia con cambios.\n\nserve-prod:                           # Servidor de producci\u00f3n (sin reload).\n    uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000\n\n# Docker\ndocker-build:                         # Construye imagen Docker.\n    docker build -t bankchurn:latest .  # -t: tag. .: contexto actual.\n\ndocker-run:                           # Ejecuta contenedor.\n    docker run -p 8000:8000 bankchurn:latest  # -p host:container: mapea puertos.\n\n# MLflow\nmlflow-ui:                            # Inicia UI de MLflow para ver experimentos.\n    mlflow ui --host 0.0.0.0 --port 5000\n\n# Limpieza\nclean:                                # Elimina archivos generados.\n    rm -rf __pycache__ .pytest_cache .mypy_cache .ruff_cache  # Caches de Python/herramientas.\n    rm -rf *.egg-info build dist      # Archivos de build.\n    rm -rf htmlcov .coverage          # Archivos de coverage.\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#gitignore","title":"\ud83d\udeab .gitignore","text":"<pre><code># Python\n__pycache__/\n*.py[cod]\n*.pyo\n.pytest_cache/\n.mypy_cache/\n*.egg-info/\ndist/\nbuild/\n\n# Entornos\n.venv/\nvenv/\nenv/\n\n# Datos y artefactos (muy grandes para Git)\ndata/\nartifacts/\nmodels/\n*.joblib\n*.pkl\n*.h5\n\n# MLflow\nmlruns/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n\n# OS\n.DS_Store\nThumbs.db\n\n# Logs\n*.log\nlogs/\n\n# Coverage\n.coverage\nhtmlcov/\n\n# Env vars\n.env\n.env.local\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#36-ingenieria-inversa-pedagogica-estructura-real-del-portafolio","title":"3.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Estructura Real del Portafolio","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s de la estructura <code>src/</code> del portafolio.</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#361-el-por-que-arquitectonico","title":"3.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo organizo c\u00f3digo importable desde cualquier lugar?            \u2502\n\u2502  RIESGO: Sin src/, los imports dependen del directorio actual                   \u2502\n\u2502  DECISI\u00d3N: src/&lt;paquete&gt;/ con __init__.py que exporta clases p\u00fablicas           \u2502\n\u2502  RESULTADO: `from bankchurn import ChurnTrainer` funciona siempre               \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo separo responsabilidades sin crear 50 archivos?              \u2502\n\u2502  DECISI\u00d3N: Un archivo por dominio: training, prediction, evaluation, config     \u2502\n\u2502  RESULTADO: 8 archivos manejables con responsabilidad clara                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#362-anatomia-de-__init__py","title":"3.6.2 \ud83d\udd0d Anatom\u00eda de <code>__init__.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/src/bankchurn/__init__.py</code></p> <pre><code>\"\"\"Core BankChurn prediction modules.\"\"\"\nfrom __future__ import annotations\n\nfrom .evaluation import ModelEvaluator\nfrom .prediction import ChurnPredictor\nfrom .training import ChurnTrainer\n\n__all__ = [\"ChurnPredictor\", \"ChurnTrainer\", \"ModelEvaluator\"]\n# __all__ documenta la API p\u00fablica y controla \"import *\"\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#363-troubleshooting-preventivo","title":"3.6.3 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Soluci\u00f3n ModuleNotFoundError en tests pythonpath no configurado <code>pythonpath = [\"src\"]</code> en pyproject.toml Import local OK, CI falla pip install -e . faltante A\u00f1adir al workflow de CI"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#errores-habituales-y-como-depurarlos-en-la-estructura-de-proyecto","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en la estructura de proyecto","text":"<p>Aqu\u00ed los problemas ya no son algoritmos, sino c\u00f3mo est\u00e1 organizado el repo. Son los t\u00edpicos errores que hacen que algo \u201cfuncione en mi m\u00e1quina pero no en CI\u201d o que el repo se vuelva inmanejable.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#1-modulenotfounderror-y-tests-que-solo-funcionan-desde-ciertos-directorios","title":"1) <code>ModuleNotFoundError</code> y tests que solo funcionan desde ciertos directorios","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En local, ejecutar <code>pytest</code> desde la ra\u00edz funciona, pero en CI falla con:   <pre><code>ModuleNotFoundError: No module named 'miproyecto'\n</code></pre></li> <li>Tienes que hacer trucos como <code>cd src</code> o modificar <code>PYTHONPATH</code> para que los imports funcionen.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa tu estructura real:</li> <li>\u00bfEl c\u00f3digo est\u00e1 en <code>src/miproyecto/</code> o repartido por la ra\u00edz?</li> <li>\u00bfLos tests importan el paquete (<code>from miproyecto import ...</code>) o archivos sueltos (<code>import training</code>)?</li> <li>Mira tu <code>pyproject.toml</code>:</li> <li><code>[project.name]</code> \u2192 \u00bfcoincide con el nombre del paquete (<code>miproyecto</code>, <code>bankchurn</code>, etc.)?</li> <li><code>[tool.setuptools.packages.find] where = [\"src\"]</code> \u2192 \u00bfest\u00e1 configurado?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Mueve el c\u00f3digo a <code>src/&lt;nombre_paquete&gt;/</code> siguiendo el \u00e1rbol de este m\u00f3dulo.</li> <li>Aseg\u00farate de que los tests importan siempre el paquete, no rutas relativas.</li> <li>Instala en modo editable durante desarrollo/CI:   <pre><code>pip install -e \".[dev]\"\n</code></pre></li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#2-datos-y-modelos-dentro-de-git-repos-gigantes-e-impracticables","title":"2) Datos y modelos dentro de Git (repos gigantes e impracticables)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El repo pesa cientos de MB porque hay CSVs y modelos <code>.pkl</code>/<code>.joblib</code> versionados.</li> <li><code>git pull</code> y <code>git clone</code> son lentos, y los PRs est\u00e1n llenos de cambios binarios.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Ejecuta <code>git status</code> y revisa si aparecen archivos en <code>data/</code>, <code>artifacts/</code>, <code>models/</code>.</li> <li>Abre tu <code>.gitignore</code> y comprueba si tienes entradas como:</li> <li><code>data/</code>, <code>artifacts/</code>, <code>models/</code>, <code>*.joblib</code>, <code>*.pkl</code>, <code>mlruns/</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>A\u00f1ade las rutas correctas a <code>.gitignore</code> (usa el snippet de este m\u00f3dulo como base).</li> <li>Mant\u00e9n en Git solo:</li> <li>C\u00f3digo (<code>src/</code>, <code>app/</code>, <code>tests/</code>).</li> <li>Config (<code>configs/</code>).</li> <li>Infra y docs.</li> <li>Para datos/modelos usa DVC o un storage externo (se profundiza en <code>06_VERSIONADO_DATOS.md</code>).</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#3-tests-que-no-reflejan-el-arbol-de-src","title":"3) Tests que no reflejan el \u00e1rbol de <code>src/</code>","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Cambias algo en <code>src/miproyecto/features.py</code> y ning\u00fan test falla, aunque has roto l\u00f3gica.</li> <li>Hay tests sueltos sin relaci\u00f3n clara con los m\u00f3dulos de producci\u00f3n.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara \u00e1rboles:</li> <li>En <code>src/miproyecto/</code>: <code>config.py</code>, <code>data.py</code>, <code>features.py</code>, <code>training.py</code>, <code>evaluation.py</code>, <code>prediction.py</code>.</li> <li>En <code>tests/</code>: \u00bfexisten <code>test_config.py</code>, <code>test_data.py</code>, <code>test_features.py</code>, etc.?</li> <li>Revisa el <code>pyproject.toml</code> o <code>pytest.ini</code> para ver qu\u00e9 carpeta se usa como <code>testpaths</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Crea un espejo sencillo: por cada m\u00f3dulo importante en <code>src/</code>, un test correspondiente en <code>tests/</code>.</li> <li>Usa <code>conftest.py</code> para compartir fixtures (datasets peque\u00f1os, config de prueba, etc.).</li> <li>Integra <code>pytest --cov=src/</code> en tu CI para detectar huecos de cobertura.</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#4-makefile-y-comandos-que-no-se-pueden-ejecutar","title":"4) Makefile y comandos que no se pueden ejecutar","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El README dice <code>make train</code>, pero:</li> <li>El target <code>train</code> no existe.</li> <li>O llama a rutas que no existen (<code>data/raw/archivo_que_no_existe.csv</code>).</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Desde la ra\u00edz del proyecto, ejecuta:   <pre><code>make help  # si tienes target de ayuda\nmake train\n</code></pre></li> <li>Observa los comandos reales que se ejecutan y comp\u00e1ralos con:</li> <li>La estructura de carpetas (<code>data/raw</code>, <code>configs/config.yaml</code>).</li> <li>El CLI real (como <code>src/bankchurn/cli.py</code> en BankChurn).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta el <code>Makefile</code> para que:</li> <li>Use rutas reales (<code>data/raw/Churn.csv</code>, etc.).</li> <li>Delegue en el CLI real (<code>python main.py ...</code> o <code>python -m miproyecto.cli ...</code>).</li> <li>Mant\u00e9n el <code>Makefile</code> como fachada del developer experience: pocos comandos (<code>install</code>, <code>test</code>, <code>train</code>, <code>serve</code>) pero s\u00f3lidos.</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#5-patron-general-de-debugging-de-estructura","title":"5) Patr\u00f3n general de debugging de estructura","text":"<ol> <li>Revisa el \u00e1rbol de directorios contra la plantilla de este m\u00f3dulo.</li> <li>Comprueba imports corriendo un <code>python -c</code> que importe tu paquete.</li> <li>Ejecuta los comandos principales (<code>make install</code>, <code>make test</code>, <code>make train</code>, <code>make serve</code>).</li> <li>Asegura que datos/artefactos no est\u00e1n en Git y que <code>.gitignore</code> los protege.</li> </ol> <p>Este checklist de estructura es lo primero que un revisor Senior mira cuando abre un repo ML: si esto est\u00e1 bien, todo lo dem\u00e1s es mucho m\u00e1s f\u00e1cil de mantener.</p> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Explica tu estructura: Los entrevistadores valoran que puedas justificar cada carpeta y archivo de tu proyecto.</p> </li> <li> <p>Cookiecutter es tu amigo: Menciona que usas plantillas estandarizadas para consistencia entre proyectos.</p> </li> <li> <p>Conoce la diferencia <code>src/</code> vs flat: Explica por qu\u00e9 <code>src/</code> layout previene imports accidentales del c\u00f3digo local.</p> </li> </ol>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Proyecto nuevo Usa cookiecutter-data-science o similar como base Equipo grande Documenta convenciones en CONTRIBUTING.md Monorepo vs Multirepo Monorepo para proyectos relacionados, multirepo para independientes Configs Nunca hardcodees: usa archivos YAML + variables de entorno"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#checklist-de-proyecto-profesional","title":"Checklist de Proyecto Profesional","text":"<ul> <li>[ ] README.md con badges, instalaci\u00f3n, y uso r\u00e1pido</li> <li>[ ] pyproject.toml con metadata completa</li> <li>[ ] Makefile con comandos est\u00e1ndar (install, test, lint)</li> <li>[ ] .pre-commit-config.yaml para calidad autom\u00e1tica</li> <li>[ ] tests/ con estructura que refleja src/</li> </ul>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Python Project Structure ArjanCodes 22 min YouTube \ud83d\udfe1 Packaging Python Projects mCoding 18 min YouTube \ud83d\udfe2 Cookiecutter Data Science PyData 35 min YouTube"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 src Layout vs Flat Gu\u00eda oficial de layouts \ud83d\udfe1 pyproject.toml Spec Especificaci\u00f3n oficial"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#decision-tecnica-adr-014-src-layout","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-014 src/ Layout","text":"<p>Contexto: Necesitamos una estructura de proyecto profesional y mantenible.</p> <p>Decisi\u00f3n: Usar <code>src/</code> layout en todos los proyectos.</p> <p>Alternativas Consideradas: - Flat layout: M\u00e1s simple pero riesgo de imports accidentales - Namespace packages: M\u00e1s complejo, necesario solo para paquetes distribuidos</p> <p>Consecuencias: - \u2705 Evita imports del c\u00f3digo local no instalado - \u2705 Tests siempre importan el paquete instalado - \u2705 Est\u00e1ndar profesional reconocido - \u274c Un nivel de directorio adicional</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#ejercicio-31-crear-estructura-de-proyecto","title":"Ejercicio 3.1: Crear Estructura de Proyecto","text":"<p>Objetivo: Crear estructura profesional desde cero. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Crear estructura completa para proyecto \"mymlproject\"\n# Debe incluir: src/, tests/, configs/, data/, artifacts/, docs/\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># Crear estructura\nmkdir -p mymlproject/{src/mymlproject,app,tests,configs,data/{raw,processed},artifacts,scripts,docs}\n\n# Crear archivos Python\ntouch mymlproject/src/mymlproject/__init__.py\ntouch mymlproject/src/mymlproject/{config.py,data.py,training.py,prediction.py}\ntouch mymlproject/app/__init__.py\ntouch mymlproject/app/fastapi_app.py\ntouch mymlproject/tests/__init__.py\ntouch mymlproject/tests/conftest.py\n\n# Crear archivos de proyecto\ntouch mymlproject/{README.md,pyproject.toml,Makefile,.gitignore}\ntouch mymlproject/.pre-commit-config.yaml\n\n# Estructura resultante:\n# mymlproject/\n# \u251c\u2500\u2500 src/mymlproject/\n# \u2502   \u251c\u2500\u2500 __init__.py\n# \u2502   \u251c\u2500\u2500 config.py\n# \u2502   \u251c\u2500\u2500 data.py\n# \u2502   \u251c\u2500\u2500 training.py\n# \u2502   \u2514\u2500\u2500 prediction.py\n# \u251c\u2500\u2500 app/fastapi_app.py\n# \u251c\u2500\u2500 tests/conftest.py\n# \u251c\u2500\u2500 configs/\n# \u251c\u2500\u2500 data/{raw,processed}/\n# \u251c\u2500\u2500 artifacts/\n# \u251c\u2500\u2500 scripts/\n# \u251c\u2500\u2500 docs/\n# \u251c\u2500\u2500 pyproject.toml\n# \u251c\u2500\u2500 Makefile\n# \u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#ejercicio-32-pyprojecttoml-completo","title":"Ejercicio 3.2: pyproject.toml Completo","text":"<p>Objetivo: Configurar pyproject.toml profesional. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Completar pyproject.toml para mymlproject\n[build-system]\n# ???\n\n[project]\nname = \"mymlproject\"\n# ???\n\n[project.optional-dependencies]\n# ???\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mymlproject\"\nversion = \"0.1.0\"\ndescription = \"ML project with professional structure\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\nlicense = {text = \"MIT\"}\nauthors = [{name = \"Tu Nombre\", email = \"tu@email.com\"}]\n\ndependencies = [\n    \"pandas&gt;=2.0\",\n    \"scikit-learn&gt;=1.3\",\n    \"pydantic&gt;=2.0\",\n    \"pyyaml&gt;=6.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.0\",\n    \"pytest-cov&gt;=4.0\",\n    \"ruff&gt;=0.1\",\n    \"pre-commit&gt;=3.0\",\n]\napi = [\n    \"fastapi&gt;=0.100\",\n    \"uvicorn&gt;=0.23\",\n]\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n[tool.ruff]\nline-length = 100\nselect = [\"E\", \"F\", \"I\", \"UP\"]\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\naddopts = \"-v --cov=mymlproject\"\n</code></pre> <p></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#37-refactoring-de-notebook-a-codigo-de-produccion","title":"3.7 \ud83d\udcd3 Refactoring: De Notebook a C\u00f3digo de Producci\u00f3n","text":"<p>Objetivo: Dominar la transici\u00f3n de c\u00f3digo exploratorio en notebooks a m\u00f3dulos Python profesionales, mantenibles y testeables.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \"El notebook es donde nacen las ideas.                                      \u2551\n\u2551   El m\u00f3dulo Python es donde esas ideas se convierten en producto.\"           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#371-por-que-refactorizar-notebooks","title":"3.7.1 \u00bfPor qu\u00e9 Refactorizar Notebooks?","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#problemas-del-codigo-en-notebooks","title":"Problemas del C\u00f3digo en Notebooks","text":"Problema Impacto Soluci\u00f3n Estado global Celdas dependen de orden de ejecuci\u00f3n Funciones puras No testeable Bugs ocultos hasta producci\u00f3n M\u00f3dulos + pytest No versionable Diffs ilegibles en Git .py separados No reutilizable Copy-paste entre proyectos Paquetes Python Sin tipos Errores en runtime Type hints"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#cuando-refactorizar","title":"Cu\u00e1ndo Refactorizar","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CICLO DE VIDA DEL C\u00d3DIGO ML                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \ud83d\udcd3 NOTEBOOK (Exploraci\u00f3n)                                                  \u2502\n\u2502  \u251c\u2500\u2500 EDA r\u00e1pida                                                             \u2502\n\u2502  \u251c\u2500\u2500 Pruebas de hip\u00f3tesis                                                   \u2502\n\u2502  \u251c\u2500\u2500 Iteraci\u00f3n de features                                                  \u2502\n\u2502  \u2514\u2500\u2500 Prototipos de modelos                                                  \u2502\n\u2502       \u2502                                                                     \u2502\n\u2502       \u25bc \u00bfEl c\u00f3digo ser\u00e1 usado m\u00e1s de una vez?                               \u2502\n\u2502       \u2502                                                                     \u2502\n\u2502  \ud83d\udce6 M\u00d3DULO (Producci\u00f3n)                                                    \u2502\n\u2502  \u251c\u2500\u2500 Funciones reutilizables                                                \u2502\n\u2502  \u251c\u2500\u2500 Clases con estado manejado                                             \u2502\n\u2502  \u251c\u2500\u2500 Configuraci\u00f3n externalizada                                            \u2502\n\u2502  \u2514\u2500\u2500 Tests automatizados                                                    \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#372-anatomia-notebook-vs-modulo","title":"3.7.2 Anatom\u00eda: Notebook vs M\u00f3dulo","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#ejemplo-celda-tipica-de-notebook","title":"Ejemplo: Celda T\u00edpica de Notebook","text":"<pre><code># \u274c C\u00f3digo t\u00edpico de notebook (dif\u00edcil de mantener)\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Cargar datos\ndf = pd.read_csv(\"data/churn.csv\")\n\n# Preprocesar (hardcoded)\ndf = df.dropna()\ndf['TenureGroup'] = pd.cut(df['tenure'], bins=[0, 12, 24, 48, 72], labels=['0-1yr', '1-2yr', '2-4yr', '4-6yr'])\n\n# Features y target (hardcoded)\nX = df[['CreditScore', 'Age', 'Balance', 'NumOfProducts']]\ny = df['Exited']\n\n# Split (seed hardcoded)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Entrenar (sin logging)\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Evaluar (print en lugar de return)\nprint(f\"Accuracy: {model.score(X_test, y_test)}\")\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#equivalente-en-modulo-profesional","title":"Equivalente en M\u00f3dulo Profesional","text":"<pre><code># \u2705 src/bankchurn/training.py (c\u00f3digo de producci\u00f3n)\n\"\"\"M\u00f3dulo de entrenamiento para BankChurn.\"\"\"\n\nfrom pathlib import Path                             # Manejo de paths cross-platform.\nfrom typing import Tuple, Dict, Any                  # Type hints.\nimport logging                                       # Logging estructurado.\n\nimport pandas as pd                                  # DataFrames.\nimport numpy as np                                   # Operaciones num\u00e9ricas.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\n\nfrom bankchurn.config import TrainingConfig          # Configuraci\u00f3n externalizada.\n\n\nlogger = logging.getLogger(__name__)                 # Logger del m\u00f3dulo.\n\n\ndef load_data(path: Path) -&gt; pd.DataFrame:\n    \"\"\"\n    Carga datos desde archivo CSV.\n\n    Args:\n        path: Path al archivo CSV.\n\n    Returns:\n        DataFrame con los datos cargados.\n\n    Raises:\n        FileNotFoundError: Si el archivo no existe.\n        pd.errors.EmptyDataError: Si el archivo est\u00e1 vac\u00edo.\n    \"\"\"\n    logger.info(f\"Loading data from {path}\")\n\n    if not path.exists():\n        raise FileNotFoundError(f\"Data file not found: {path}\")\n\n    df = pd.read_csv(path)\n    logger.info(f\"Loaded {len(df)} rows, {len(df.columns)} columns\")\n\n    return df\n\n\ndef preprocess(\n    df: pd.DataFrame,\n    config: TrainingConfig,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Preprocesa datos seg\u00fan configuraci\u00f3n.\n\n    Args:\n        df: DataFrame con datos crudos.\n        config: Configuraci\u00f3n de preprocesamiento.\n\n    Returns:\n        DataFrame preprocesado.\n    \"\"\"\n    logger.info(\"Preprocessing data\")\n\n    # Eliminar NaN seg\u00fan estrategia en config.\n    if config.drop_na:\n        initial_rows = len(df)\n        df = df.dropna()\n        logger.info(f\"Dropped {initial_rows - len(df)} rows with NaN\")\n\n    # Feature engineering configurable.\n    if config.create_tenure_groups:\n        df = df.copy()                               # Evitar SettingWithCopyWarning.\n        df['TenureGroup'] = pd.cut(\n            df['tenure'],\n            bins=config.tenure_bins,\n            labels=config.tenure_labels,\n        )\n\n    return df\n\n\ndef split_data(\n    df: pd.DataFrame,\n    config: TrainingConfig,\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n    \"\"\"\n    Divide datos en train/test.\n\n    Args:\n        df: DataFrame preprocesado.\n        config: Configuraci\u00f3n con features, target y split ratio.\n\n    Returns:\n        Tuple de (X_train, X_test, y_train, y_test).\n    \"\"\"\n    X = df[config.feature_columns]\n    y = df[config.target_column]\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y,\n        test_size=config.test_size,\n        random_state=config.seed,\n        stratify=y if config.stratify else None,     # Estratificaci\u00f3n opcional.\n    )\n\n    logger.info(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n\n    return X_train, X_test, y_train, y_test\n\n\ndef train_model(\n    X_train: pd.DataFrame,\n    y_train: pd.Series,\n    config: TrainingConfig,\n) -&gt; RandomForestClassifier:\n    \"\"\"\n    Entrena modelo con configuraci\u00f3n especificada.\n\n    Args:\n        X_train: Features de entrenamiento.\n        y_train: Target de entrenamiento.\n        config: Configuraci\u00f3n de hiperpar\u00e1metros.\n\n    Returns:\n        Modelo entrenado.\n    \"\"\"\n    logger.info(f\"Training RandomForest with {config.n_estimators} estimators\")\n\n    model = RandomForestClassifier(\n        n_estimators=config.n_estimators,\n        max_depth=config.max_depth,\n        random_state=config.seed,\n        n_jobs=-1,                                   # Usar todos los cores.\n    )\n\n    model.fit(X_train, y_train)\n    logger.info(\"Training completed\")\n\n    return model\n\n\ndef evaluate_model(\n    model: RandomForestClassifier,\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n) -&gt; Dict[str, float]:\n    \"\"\"\n    Eval\u00faa modelo y retorna m\u00e9tricas.\n\n    Args:\n        model: Modelo entrenado.\n        X_test: Features de test.\n        y_test: Target de test.\n\n    Returns:\n        Dict con m\u00e9tricas de evaluaci\u00f3n.\n    \"\"\"\n    y_pred = model.predict(X_test)\n\n    metrics = {\n        \"accuracy\": accuracy_score(y_test, y_pred),\n        \"f1_score\": f1_score(y_test, y_pred),\n    }\n\n    logger.info(f\"Evaluation metrics: {metrics}\")\n\n    return metrics\n\n\ndef run_training_pipeline(config: TrainingConfig) -&gt; Dict[str, Any]:\n    \"\"\"\n    Ejecuta pipeline completo de entrenamiento.\n\n    Esta es la funci\u00f3n principal que orquesta todo el proceso.\n\n    Args:\n        config: Configuraci\u00f3n completa del entrenamiento.\n\n    Returns:\n        Dict con modelo y m\u00e9tricas.\n    \"\"\"\n    # 1. Cargar datos.\n    df = load_data(config.data_path)\n\n    # 2. Preprocesar.\n    df = preprocess(df, config)\n\n    # 3. Split.\n    X_train, X_test, y_train, y_test = split_data(df, config)\n\n    # 4. Entrenar.\n    model = train_model(X_train, y_train, config)\n\n    # 5. Evaluar.\n    metrics = evaluate_model(model, X_test, y_test)\n\n    return {\n        \"model\": model,\n        \"metrics\": metrics,\n        \"config\": config,\n    }\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#373-proceso-de-refactoring-paso-a-paso","title":"3.7.3 Proceso de Refactoring Paso a Paso","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#checklist-de-refactoring","title":"Checklist de Refactoring","text":"<pre><code># refactoring_checklist.py\n\"\"\"Checklist automatizado para refactoring de notebooks.\"\"\"\n\nfrom dataclasses import dataclass\nfrom typing import List\n\n\n@dataclass\nclass RefactoringStep:\n    \"\"\"Paso de refactoring.\"\"\"\n    name: str\n    description: str\n    completed: bool = False\n\n\ndef get_refactoring_checklist() -&gt; List[RefactoringStep]:\n    \"\"\"Retorna checklist de refactoring.\"\"\"\n    return [\n        RefactoringStep(\n            \"identify_functions\",\n            \"Identificar bloques de c\u00f3digo que hacen UNA cosa\"\n        ),\n        RefactoringStep(\n            \"extract_config\",\n            \"Extraer valores hardcoded a configuraci\u00f3n\"\n        ),\n        RefactoringStep(\n            \"add_type_hints\",\n            \"A\u00f1adir type hints a todas las funciones\"\n        ),\n        RefactoringStep(\n            \"add_docstrings\",\n            \"Documentar cada funci\u00f3n con docstring\"\n        ),\n        RefactoringStep(\n            \"add_logging\",\n            \"Reemplazar print() con logging\"\n        ),\n        RefactoringStep(\n            \"add_error_handling\",\n            \"A\u00f1adir manejo de errores apropiado\"\n        ),\n        RefactoringStep(\n            \"remove_global_state\",\n            \"Eliminar variables globales\"\n        ),\n        RefactoringStep(\n            \"create_tests\",\n            \"Crear tests unitarios para cada funci\u00f3n\"\n        ),\n    ]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#mapeo-celdas-de-notebook-modulos","title":"Mapeo: Celdas de Notebook \u2192 M\u00f3dulos","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              MAPEO: CELDAS DE NOTEBOOK \u2192 M\u00d3DULOS                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  Celda de imports           \u2192  (se distribuyen en cada m\u00f3dulo)              \u2502\n\u2502  Celda de carga de datos    \u2192  data.py::load_data()                         \u2502\n\u2502  Celda de limpieza          \u2192  data.py::clean_data()                        \u2502\n\u2502  Celda de feature eng.      \u2192  features.py::create_features()               \u2502\n\u2502  Celda de split             \u2192  training.py::split_data()                    \u2502\n\u2502  Celda de entrenamiento     \u2192  training.py::train_model()                   \u2502\n\u2502  Celda de evaluaci\u00f3n        \u2192  evaluation.py::evaluate_model()              \u2502\n\u2502  Celda de predicci\u00f3n        \u2192  prediction.py::predict()                     \u2502\n\u2502  Celda de visualizaci\u00f3n     \u2192  (queda en notebook o dashboards)             \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#374-patrones-comunes-de-extraccion","title":"3.7.4 Patrones Comunes de Extracci\u00f3n","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#configuracion-externalizada","title":"Configuraci\u00f3n Externalizada","text":"<pre><code># src/bankchurn/config.py\n\"\"\"Configuraci\u00f3n centralizada del proyecto.\"\"\"\n\nfrom pathlib import Path\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field              # Validaci\u00f3n autom\u00e1tica.\nimport yaml                                        # Lectura de archivos YAML.\n\n\nclass TrainingConfig(BaseModel):\n    \"\"\"Configuraci\u00f3n de entrenamiento.\"\"\"\n\n    # Paths.\n    data_path: Path = Field(..., description=\"Path al archivo de datos\")\n    model_output_path: Path = Field(default=Path(\"artifacts/model.joblib\"))\n\n    # Preprocesamiento.\n    drop_na: bool = Field(default=True)\n    create_tenure_groups: bool = Field(default=True)\n    tenure_bins: List[int] = Field(default=[0, 12, 24, 48, 72])\n    tenure_labels: List[str] = Field(default=['0-1yr', '1-2yr', '2-4yr', '4-6yr'])\n\n    # Features.\n    feature_columns: List[str] = Field(\n        default=['CreditScore', 'Age', 'Balance', 'NumOfProducts']\n    )\n    target_column: str = Field(default='Exited')\n\n    # Split.\n    test_size: float = Field(default=0.2, ge=0.0, le=1.0)\n    stratify: bool = Field(default=True)\n\n    # Modelo.\n    n_estimators: int = Field(default=100, ge=1)\n    max_depth: Optional[int] = Field(default=None)\n\n    # Reproducibilidad.\n    seed: int = Field(default=42)\n\n    class Config:\n        extra = \"forbid\"  # Error si hay campos desconocidos.\n\n\ndef load_config(path: Path) -&gt; TrainingConfig:\n    \"\"\"Carga configuraci\u00f3n desde YAML.\"\"\"\n    with open(path) as f:\n        data = yaml.safe_load(f)\n    return TrainingConfig(**data)\n</code></pre> <pre><code># configs/config.yaml\n# Configuraci\u00f3n de entrenamiento.\n\ndata_path: \"data/raw/Churn.csv\"\nmodel_output_path: \"artifacts/model.joblib\"\n\n# Preprocesamiento.\ndrop_na: true\ncreate_tenure_groups: true\n\n# Features.\nfeature_columns:\n  - CreditScore\n  - Age\n  - Balance\n  - NumOfProducts\n  - IsActiveMember\n\ntarget_column: Exited\n\n# Split.\ntest_size: 0.2\nstratify: true\n\n# Modelo.\nn_estimators: 200\nmax_depth: 10\n\n# Reproducibilidad.\nseed: 42\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#de-print-a-logging","title":"De Print a Logging","text":"<pre><code># \u274c Antes (notebook)\nprint(f\"Loaded {len(df)} rows\")\nprint(f\"Training with {n_estimators} trees\")\nprint(f\"Accuracy: {accuracy}\")\n\n# \u2705 Despu\u00e9s (m\u00f3dulo)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nlogger.info(f\"Loaded {len(df)} rows\")\nlogger.info(f\"Training with {n_estimators} trees\")\nlogger.info(f\"Accuracy: {accuracy:.4f}\")\n\n# Configuraci\u00f3n de logging (en __init__.py o main.py)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n    handlers=[\n        logging.StreamHandler(),\n        logging.FileHandler(\"training.log\"),\n    ]\n)\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#de-variables-globales-a-parametros","title":"De Variables Globales a Par\u00e1metros","text":"<pre><code># \u274c Antes (variables globales)\nSEED = 42\nN_ESTIMATORS = 100\ndf = None  # Estado global mutable\n\ndef train():\n    global df  # Dependencia oculta\n    model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=SEED)\n    model.fit(df[features], df[target])\n    return model\n\n# \u2705 Despu\u00e9s (par\u00e1metros expl\u00edcitos)\ndef train(\n    X: pd.DataFrame,\n    y: pd.Series,\n    n_estimators: int = 100,\n    seed: int = 42,\n) -&gt; RandomForestClassifier:\n    \"\"\"Todas las dependencias son expl\u00edcitas.\"\"\"\n    model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)\n    model.fit(X, y)\n    return model\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#38-librerias-compartidas-common_utils","title":"3.8 \ud83d\udce6 Librer\u00edas Compartidas (common_utils)","text":"<p>Objetivo: Aprender a crear y mantener librer\u00edas de utilidades compartidas entre proyectos ML, siguiendo el patr\u00f3n <code>common_utils/</code> del Portfolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \"DRY (Don't Repeat Yourself) no es solo para c\u00f3digo dentro de un proyecto:  \u2551\n\u2551   aplica a toda tu organizaci\u00f3n. common_utils es DRY a nivel de equipo.\"     \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#381-por-que-librerias-compartidas","title":"3.8.1 \u00bfPor qu\u00e9 Librer\u00edas Compartidas?","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#problemas-que-resuelve","title":"Problemas que Resuelve","text":"Problema Sin common_utils Con common_utils Logging Cada proyecto configura diferente Formato consistente Seeds Olvidar setear todas las librer\u00edas Una funci\u00f3n para todo Config Duplicaci\u00f3n de c\u00f3digo Validaci\u00f3n centralizada Utils Copy-paste entre repos Import compartido"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#analisis-del-portfolio","title":"An\u00e1lisis del Portfolio","text":"<pre><code>ML-MLOps-Portfolio/\n\u251c\u2500\u2500 common_utils/              # \u2190 Librer\u00eda compartida\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 logger.py              # Logging consistente\n\u2502   \u2514\u2500\u2500 seed.py                # Reproducibilidad\n\u2502\n\u251c\u2500\u2500 BankChurn-Predictor/\n\u2502   \u2514\u2500\u2500 src/bankchurn/\n\u2502       \u2514\u2500\u2500 training.py        # from common_utils import ...\n\u2502\n\u251c\u2500\u2500 CarVision-Market-Intelligence/\n\u2502   \u2514\u2500\u2500 src/carvision/\n\u2502       \u2514\u2500\u2500 training.py        # from common_utils import ...\n\u2502\n\u2514\u2500\u2500 TelecomAI-Customer-Intelligence/\n    \u2514\u2500\u2500 src/telecom/\n        \u2514\u2500\u2500 training.py        # from common_utils import ...\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#382-estructura-de-common_utils","title":"3.8.2 Estructura de common_utils","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#organizacion-recomendada","title":"Organizaci\u00f3n Recomendada","text":"<pre><code>common_utils/\n\u251c\u2500\u2500 __init__.py           # Exports p\u00fablicos\n\u251c\u2500\u2500 logger.py             # Configuraci\u00f3n de logging\n\u251c\u2500\u2500 seed.py               # Reproducibilidad\n\u251c\u2500\u2500 config.py             # Utilidades de configuraci\u00f3n (opcional)\n\u251c\u2500\u2500 metrics.py            # M\u00e9tricas compartidas (opcional)\n\u251c\u2500\u2500 validators.py         # Validadores comunes (opcional)\n\u2514\u2500\u2500 tests/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 test_logger.py\n    \u2514\u2500\u2500 test_seed.py\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#initpy-api-publica","title":"init.py: API P\u00fablica","text":"<pre><code># common_utils/__init__.py\n\"\"\"\nUtilidades compartidas para proyectos ML.\n\nEste m\u00f3dulo proporciona funcionalidades comunes que se usan\nen m\u00faltiples proyectos del portfolio:\n- Configuraci\u00f3n de logging consistente.\n- Reproducibilidad con seeds.\n\"\"\"\n\nfrom common_utils.logger import setup_logging\nfrom common_utils.seed import set_seed, DEFAULT_SEED\n\n__version__ = \"1.0.0\"\n\n__all__ = [\n    \"setup_logging\",\n    \"set_seed\",\n    \"DEFAULT_SEED\",\n]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#383-modulo-de-logging","title":"3.8.3 M\u00f3dulo de Logging","text":"<pre><code># common_utils/logger.py\n\"\"\"\nConfiguraci\u00f3n centralizada de logging para todos los proyectos.\n\nEste m\u00f3dulo proporciona una funci\u00f3n para configurar logging de manera\nconsistente, evitando que cada proyecto implemente su propia versi\u00f3n.\n\"\"\"\n\nimport logging                                       # Librer\u00eda est\u00e1ndar de logging.\nimport sys                                           # Para stdout.\nfrom typing import Optional                          # Type hints.\n\n\ndef setup_logging(\n    name: str,                                       # Nombre del logger (usualmente __name__).\n    level: int = logging.INFO,                       # Nivel m\u00ednimo de logging.\n    log_format: Optional[str] = None,                # Formato personalizado (opcional).\n) -&gt; logging.Logger:\n    \"\"\"\n    Configura logging consistente para todos los proyectos.\n\n    Esta funci\u00f3n centraliza la configuraci\u00f3n de logging para evitar\n    duplicaci\u00f3n y garantizar formato consistente en logs.\n\n    Args:\n        name: Nombre del logger. Usar __name__ del m\u00f3dulo que llama.\n        level: Nivel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL).\n        log_format: Formato personalizado. Si None, usa formato est\u00e1ndar.\n\n    Returns:\n        Logger configurado y listo para usar.\n\n    Example:\n        &gt;&gt;&gt; from common_utils import setup_logging\n        &gt;&gt;&gt; logger = setup_logging(__name__)\n        &gt;&gt;&gt; logger.info(\"Training started\")\n        2024-01-15 10:30:00 - mymodule - INFO - Training started\n    \"\"\"\n    # Formato por defecto: timestamp - m\u00f3dulo - nivel - mensaje.\n    if log_format is None:\n        log_format = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n\n    # Crear handler para stdout.\n    handler = logging.StreamHandler(sys.stdout)      # Output a stdout (no stderr).\n    formatter = logging.Formatter(log_format)        # Aplicar formato.\n    handler.setFormatter(formatter)\n\n    # Obtener o crear logger.\n    logger = logging.getLogger(name)\n    logger.setLevel(level)\n\n    # Prevenir handlers duplicados si se llama m\u00faltiples veces.\n    # Esto es importante en notebooks donde se puede re-ejecutar celdas.\n    if not logger.handlers:\n        logger.addHandler(handler)\n\n    return logger\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#384-modulo-de-reproducibilidad-seed","title":"3.8.4 M\u00f3dulo de Reproducibilidad (Seed)","text":"<pre><code># common_utils/seed.py\n\"\"\"\nHelper centralizado para reproducibilidad en experimentos ML.\n\nEste m\u00f3dulo configura seeds para todas las librer\u00edas relevantes\n(Python, NumPy, PyTorch, TensorFlow) en una sola llamada.\n\"\"\"\n\nfrom __future__ import annotations                   # Para type hints modernos.\n\nimport os                                            # Variables de entorno.\nimport random                                        # Random de Python.\nfrom typing import Final                             # Constantes tipadas.\n\nimport numpy as np                                   # NumPy.\n\n\n# Seed por defecto si no se especifica.\nDEFAULT_SEED: Final[int] = 42\n\n\ndef set_seed(seed: int | None = None) -&gt; int:\n    \"\"\"\n    Configura seeds globales para reproducibilidad.\n\n    Esta funci\u00f3n setea el seed para:\n    - Python's random module\n    - NumPy\n    - PyTorch (si est\u00e1 instalado)\n    - TensorFlow (si est\u00e1 instalado)\n\n    Orden de resoluci\u00f3n del seed:\n    1. Argumento `seed` si se proporciona.\n    2. Variable de entorno `SEED` si est\u00e1 definida.\n    3. DEFAULT_SEED (42) como fallback.\n\n    Args:\n        seed: Seed a usar. Si None, se resuelve seg\u00fan orden descrito.\n\n    Returns:\n        El seed que fue efectivamente usado.\n\n    Example:\n        &gt;&gt;&gt; from common_utils import set_seed\n        &gt;&gt;&gt; set_seed(42)\n        42\n        &gt;&gt;&gt; # Ahora todos los experimentos ser\u00e1n reproducibles\n\n    Note:\n        Para reproducibilidad completa en GPU, tambi\u00e9n necesitas:\n        - torch.backends.cudnn.deterministic = True\n        - torch.backends.cudnn.benchmark = False\n        Esto se hace autom\u00e1ticamente en esta funci\u00f3n.\n    \"\"\"\n    # Resolver seed seg\u00fan orden de prioridad.\n    if seed is None:\n        env_seed = os.getenv(\"SEED\")                 # Buscar en variable de entorno.\n        seed = int(env_seed) if env_seed is not None else DEFAULT_SEED\n\n    # ========== Core Python / NumPy ==========\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)         # Hash determin\u00edstico.\n    random.seed(seed)                                # Random de Python.\n    np.random.seed(seed)                             # NumPy.\n\n    # ========== PyTorch (opcional) ==========\n    try:\n        import torch\n\n        torch.manual_seed(seed)                      # CPU seed.\n\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)         # GPU seed (todas las GPUs).\n\n        # Hacer operaciones CUDA determin\u00edsticas.\n        if hasattr(torch.backends, \"cudnn\"):\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False   # Desactivar autotuning.\n\n    except ImportError:\n        pass  # PyTorch no instalado, skip.\n    except Exception:\n        pass  # Otros errores (ej: CUDA no disponible).\n\n    # ========== TensorFlow (opcional) ==========\n    try:\n        import tensorflow as tf\n\n        tf.random.set_seed(seed)\n\n    except ImportError:\n        pass  # TensorFlow no instalado, skip.\n    except Exception:\n        pass\n\n    return seed\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#385-patrones-de-uso","title":"3.8.5 Patrones de Uso","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#importacion-desde-proyecto","title":"Importaci\u00f3n desde Proyecto","text":"<pre><code># Opci\u00f3n 1: Import directo (si common_utils est\u00e1 en PYTHONPATH)\nfrom common_utils import setup_logging, set_seed\n\n# Opci\u00f3n 2: Import relativo (si es subm\u00f3dulo)\nfrom ..common_utils import setup_logging, set_seed\n\n# Opci\u00f3n 3: A\u00f1adir al path en runtime\nimport sys\nsys.path.insert(0, \"/path/to/ML-MLOps-Portfolio\")\nfrom common_utils import setup_logging, set_seed\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#configuracion-en-pyprojecttoml","title":"Configuraci\u00f3n en pyproject.toml","text":"<pre><code># pyproject.toml del proyecto que usa common_utils\n\n[project]\nname = \"bankchurn\"\ndependencies = [\n    # ... otras deps ...\n]\n\n[project.optional-dependencies]\ndev = [\n    # ... deps de desarrollo ...\n]\n\n# Si common_utils es un paquete local\n[tool.setuptools.package-dir]\n\"\" = \"src\"\n\"common_utils\" = \"../common_utils\"\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#patron-de-inicializacion","title":"Patr\u00f3n de Inicializaci\u00f3n","text":"<pre><code># src/bankchurn/__init__.py\n\"\"\"\nBankChurn Predictor.\n\nEste m\u00f3dulo inicializa logging y seed al importar.\n\"\"\"\n\nfrom common_utils import setup_logging, set_seed\n\n# Configurar logging al importar el paquete.\n_logger = setup_logging(\"bankchurn\")\n\n# Exportar para uso en subm\u00f3dulos.\n__all__ = [\"setup_logging\", \"set_seed\"]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#386-versionado-y-distribucion","title":"3.8.6 Versionado y Distribuci\u00f3n","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#estructura-para-publicacion","title":"Estructura para Publicaci\u00f3n","text":"<pre><code>common_utils/\n\u251c\u2500\u2500 pyproject.toml        # Metadata del paquete\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 common_utils/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 logger.py\n\u2502       \u2514\u2500\u2500 seed.py\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#pyprojecttoml-para-distribucion","title":"pyproject.toml para Distribuci\u00f3n","text":"<pre><code># common_utils/pyproject.toml\n\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mlops-common-utils\"\nversion = \"1.0.0\"\ndescription = \"Shared utilities for MLOps projects\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\nlicense = {text = \"MIT\"}\n\ndependencies = [\n    \"numpy&gt;=1.24.0\",\n]\n\n[project.optional-dependencies]\ntorch = [\"torch&gt;=2.0.0\"]\ntensorflow = [\"tensorflow&gt;=2.13.0\"]\nall = [\"mlops-common-utils[torch,tensorflow]\"]\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#instalacion-en-proyectos","title":"Instalaci\u00f3n en Proyectos","text":"<pre><code># Desde Git (privado)\npip install git+https://github.com/tu-org/common-utils.git\n\n# Desde path local (desarrollo)\npip install -e /path/to/common_utils\n\n# Desde PyPI (si publicas)\npip install mlops-common-utils\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#39-seccion-pedagogica-aprende-haciendo","title":"3.9 \ud83c\udf93 Secci\u00f3n Pedag\u00f3gica: Aprende Haciendo","text":"<p>Formato: Constructivismo aplicado a MLOps Nivel: Python b\u00e1sico \u2192 Ingeniero MLOps Junior Tiempo estimado: 2-3 horas</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#391-explicacion-teorica-con-analogias","title":"3.9.1 \ud83c\udf93 Explicaci\u00f3n Te\u00f3rica con Analog\u00edas","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#la-estructura-de-proyecto-como-los-planos-de-una-casa","title":"La Estructura de Proyecto como los Planos de una Casa","text":"<p>Imagina que vas a construir una casa. No empiezas poniendo ladrillos al azar \u2014 primero necesitas:</p> <pre><code>\ud83c\udfe0 CONSTRUCCI\u00d3N DE CASA          \ud83d\udce6 PROYECTO ML\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPlanos arquitect\u00f3nicos     \u2192     pyproject.toml (metadata)\nCimientos                  \u2192     src/ layout (base del c\u00f3digo)\nSistema el\u00e9ctrico          \u2192     configs/ (configuraci\u00f3n)\nSistema de plomer\u00eda        \u2192     data/ pipelines (flujo de datos)\nCuartos separados          \u2192     M\u00f3dulos: training.py, prediction.py\nInspecci\u00f3n de calidad      \u2192     tests/ (verificaci\u00f3n)\nManual de la casa          \u2192     README.md, docs/\n</code></pre> <p>\u00bfPor qu\u00e9 importa en la industria?</p> Sin estructura profesional Con estructura profesional \"Funciona en mi m\u00e1quina\" \ud83e\udd37 Funciona en cualquier m\u00e1quina \u2705 Onboarding de 2 semanas Onboarding de 2 d\u00edas Bugs dif\u00edciles de rastrear Bugs localizados r\u00e1pidamente Imposible de escalar Listo para equipo de 10+ personas <p>\ufffd Insight de industria: Los equipos de ML pierden ~40% del tiempo en \"plumbing\" (configuraci\u00f3n, imports rotos, dependencias). Una buena estructura reduce esto a &lt;10%.</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#392-mapa-mental-de-conceptos","title":"3.9.2 \ud83e\udde0 Mapa Mental de Conceptos","text":"<p>Antes de tocar c\u00f3digo, domina estos t\u00e9rminos:</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 ESTRUCTURA ML   \u2502\n                    \u2502   PROFESIONAL   \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                    \u2502                    \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 C\u00d3DIGO  \u2502         \u2502  CONFIG   \u2502        \u2502  CALIDAD  \u2502\n   \u2502  FUENTE \u2502         \u2502   &amp; DATA  \u2502        \u2502           \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                    \u2502                    \u2502\n   \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510        \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 src/    \u2502         \u2502 configs/  \u2502        \u2502 tests/    \u2502\n   \u2502 layout  \u2502         \u2502 data/     \u2502        \u2502 Makefile  \u2502\n   \u2502 __init__\u2502         \u2502 artifacts/\u2502        \u2502 pre-commit\u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Conceptos clave para memorizar:</p> Concepto Definici\u00f3n de 1 l\u00ednea src/ layout C\u00f3digo en <code>src/paquete/</code> para imports limpios pyproject.toml UN archivo para toda la config del proyecto editable install <code>pip install -e .</code> = cambios sin reinstalar Makefile Comandos comunes en un solo lugar .gitignore Archivos que Git debe ignorar (datos, modelos) conftest.py Fixtures compartidas para tests"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#393-ejercicio-puente-scaffolding","title":"3.9.3 \ud83d\udcbb Ejercicio Puente (Scaffolding)","text":"<p>Objetivo: Practicar la estructura ANTES de replicar el portafolio completo.</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#mini-proyecto-calculadora-ml","title":"Mini-Proyecto: Calculadora ML","text":"<p>Crea un proyecto m\u00ednimo con estructura profesional que haga una operaci\u00f3n simple.</p> <pre><code># PASO 1: Crear estructura\nmkdir -p calculadora-ml/src/calculadora\nmkdir -p calculadora-ml/tests\nmkdir -p calculadora-ml/configs\n\n# PASO 2: Crear archivos base\ntouch calculadora-ml/src/calculadora/__init__.py\ntouch calculadora-ml/src/calculadora/operations.py\ntouch calculadora-ml/tests/__init__.py\ntouch calculadora-ml/tests/test_operations.py\ntouch calculadora-ml/pyproject.toml\ntouch calculadora-ml/Makefile\n</code></pre> <p>Tu tarea: Completa estos archivos:</p> <pre><code># src/calculadora/operations.py\n\"\"\"Operaciones matem\u00e1ticas simples.\"\"\"\n\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"Suma dos n\u00fameros.\"\"\"\n    # TODO: Implementar\n    pass\n\ndef multiply(a: float, b: float) -&gt; float:\n    \"\"\"Multiplica dos n\u00fameros.\"\"\"\n    # TODO: Implementar\n    pass\n</code></pre> <pre><code># tests/test_operations.py\n\"\"\"Tests para operaciones.\"\"\"\nimport pytest\nfrom calculadora.operations import add, multiply\n\ndef test_add_positive_numbers():\n    \"\"\"Test suma de positivos.\"\"\"\n    # TODO: Implementar - debe pasar\n    pass\n\ndef test_multiply_by_zero():\n    \"\"\"Test multiplicar por cero.\"\"\"\n    # TODO: Implementar - debe retornar 0\n    pass\n</code></pre> <pre><code># pyproject.toml\n[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"calculadora\"\nversion = \"0.1.0\"\n# TODO: Completar dependencies y tool configs\n</code></pre> <p>Criterio de \u00e9xito:  <pre><code>pip install -e .\npytest  # Debe pasar\n</code></pre></p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#394-practica-del-portafolio-instrucciones-de-replica","title":"3.9.4 \ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio (Instrucciones de R\u00e9plica)","text":"<p>Objetivo: Replicar la estructura de <code>BankChurn-Predictor</code> desde cero.</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#tarea-crear-estructura-para-tu-proyecto","title":"Tarea: Crear estructura para tu proyecto","text":"<p>NO copies el c\u00f3digo \u2014 cr\u00e9alo paso a paso siguiendo estas pistas:</p>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#paso-1-estructura-de-directorios","title":"Paso 1: Estructura de directorios","text":"<pre><code># Pista: Usa el \u00e1rbol de la secci\u00f3n 3.1 como referencia\n# Crea TODOS los directorios y archivos vac\u00edos primero\nmkdir -p mi-proyecto-ml/{src/miproyecto,tests,configs,data/raw,artifacts,docs}\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#paso-2-pyprojecttoml","title":"Paso 2: pyproject.toml","text":"<pre><code># Pista: Responde estas preguntas para completarlo\n# 1. \u00bfCu\u00e1l es el nombre de tu paquete?\n# 2. \u00bfQu\u00e9 librer\u00edas necesitas? (pandas, sklearn, pydantic...)\n# 3. \u00bfD\u00f3nde est\u00e1 el c\u00f3digo fuente? (src/)\n\n[project]\nname = \"???\"\nversion = \"0.1.0\"\ndependencies = [\n    # ??? - lista tus deps\n]\n\n[tool.setuptools.packages.find]\nwhere = [\"???\"]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#paso-3-initpy-con-exports","title":"Paso 3: init.py con exports","text":"<pre><code># src/miproyecto/__init__.py\n# Pista: \u00bfQu\u00e9 clases/funciones quieres que sean p\u00fablicas?\n# Mira el __init__.py de bankchurn como referencia\n\nfrom .??? import ???\n__all__ = [\"???\"]\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#paso-4-makefile-minimo","title":"Paso 4: Makefile m\u00ednimo","text":"<pre><code># Pista: \u00bfCu\u00e1les son los 4 comandos que m\u00e1s usar\u00e1s?\n# install, test, lint, ???\n\n.PHONY: install test\n\ninstall:\n    # ??? - comando para instalar en modo editable\n\ntest:\n    # ??? - comando para correr tests con coverage\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#paso-5-verificacion","title":"Paso 5: Verificaci\u00f3n","text":"<pre><code># Tu proyecto debe pasar estas verificaciones:\npip install -e \".[dev]\"     # \u00bfInstala sin errores?\npython -c \"import miproyecto\"  # \u00bfImporta correctamente?\npytest                       # \u00bfTests pasan?\nmake test                    # \u00bfMakefile funciona?\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#395-checkpoint-de-conocimiento","title":"3.9.5 \u2705 Checkpoint de Conocimiento","text":""},{"location":"docs/03_ESTRUCTURA_PROYECTO/#preguntas-teoricas-opcion-multiple","title":"Preguntas Te\u00f3ricas (Opci\u00f3n M\u00faltiple)","text":"<p>1. \u00bfPor qu\u00e9 usamos <code>src/</code> layout en lugar de poner c\u00f3digo en la ra\u00edz?</p> <ul> <li>A) Es m\u00e1s r\u00e1pido de ejecutar</li> <li>B) Evita que Python importe accidentalmente c\u00f3digo local no instalado</li> <li>C) GitHub lo requiere</li> <li>D) Es solo preferencia est\u00e9tica</li> </ul> Ver respuesta  **Respuesta: B**  Con `src/` layout, Python SIEMPRE importa el paquete instalado, no el c\u00f3digo local. Esto previene el cl\u00e1sico \"funciona en mi m\u00e1quina pero no en CI\".   <p>2. \u00bfCu\u00e1l es el prop\u00f3sito de <code>pip install -e .</code>?</p> <ul> <li>A) Instalar en modo \"enterprise\"</li> <li>B) Instalar una versi\u00f3n espec\u00edfica</li> <li>C) Instalar en modo editable (cambios se reflejan sin reinstalar)</li> <li>D) Instalar con dependencias extra</li> </ul> Ver respuesta  **Respuesta: C**  El flag `-e` (editable) crea un symlink al c\u00f3digo fuente. Cuando modificas tu c\u00f3digo, no necesitas reinstalar \u2014 los cambios se reflejan inmediatamente.   <p>3. \u00bfQu\u00e9 archivos NUNCA deben estar en Git para un proyecto ML?</p> <ul> <li>A) <code>pyproject.toml</code> y <code>Makefile</code></li> <li>B) <code>README.md</code> y <code>docs/</code></li> <li>C) <code>data/</code>, <code>artifacts/</code>, <code>*.joblib</code>, <code>mlruns/</code></li> <li>D) <code>tests/</code> y <code>configs/</code></li> </ul> Ver respuesta  **Respuesta: C**  Datos, modelos entrenados y artifacts de MLflow son demasiado grandes y cambian frecuentemente. Deben estar en `.gitignore` y manejarse con DVC o storage externo."},{"location":"docs/03_ESTRUCTURA_PROYECTO/#escenario-de-debugging","title":"Escenario de Debugging","text":"<p>Situaci\u00f3n: Tu colega te pide ayuda. Su proyecto tiene esta estructura:</p> <pre><code>mi-proyecto/\n\u251c\u2500\u2500 training.py\n\u251c\u2500\u2500 prediction.py\n\u251c\u2500\u2500 config.py\n\u251c\u2500\u2500 test_training.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 data/churn.csv\n</code></pre> <p>Reporta estos problemas: 1. <code>pytest</code> falla con <code>ModuleNotFoundError: No module named 'training'</code> 2. El repo de Git pesa 500MB 3. En CI, los tests fallan aunque en local funcionan</p> <p>Tu diagn\u00f3stico: \u00bfCu\u00e1les son las 3 causas ra\u00edz y c\u00f3mo las solucionar\u00edas?</p> Ver diagn\u00f3stico completo  **Causa 1**: No hay estructura `src/` ni `pyproject.toml` - **S\u00edntoma**: `ModuleNotFoundError` - **Soluci\u00f3n**: Mover c\u00f3digo a `src/miproyecto/`, crear `pyproject.toml`, usar `pip install -e .`  **Causa 2**: `data/` no est\u00e1 en `.gitignore` - **S\u00edntoma**: Repo de 500MB - **Soluci\u00f3n**: A\u00f1adir `data/` a `.gitignore`, usar DVC para datos, `git rm --cached data/`  **Causa 3**: Sin instalaci\u00f3n editable en CI - **S\u00edntoma**: Tests fallan solo en CI - **Soluci\u00f3n**: A\u00f1adir `pip install -e .` al workflow de CI antes de `pytest`  **Estructura corregida**: <pre><code>mi-proyecto/\n\u251c\u2500\u2500 src/miproyecto/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 training.py\n\u2502   \u251c\u2500\u2500 prediction.py\n\u2502   \u2514\u2500\u2500 config.py\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_training.py\n\u251c\u2500\u2500 data/           # En .gitignore\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 Makefile\n\u2514\u2500\u2500 .gitignore\n</code></pre>"},{"location":"docs/03_ESTRUCTURA_PROYECTO/#glosario-del-modulo","title":"\ufffd\ufffd Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n src/ Layout Estructura donde c\u00f3digo est\u00e1 en <code>src/nombre_paquete/</code> pyproject.toml Archivo unificado de configuraci\u00f3n de proyecto Python Makefile Archivo para automatizar comandos comunes del proyecto editable install <code>pip install -e .</code> instala paquete en modo desarrollo Refactoring Proceso de reestructurar c\u00f3digo sin cambiar funcionalidad common_utils Librer\u00eda interna compartida entre proyectos Scaffolding Ejercicio puente que prepara para tareas complejas Constructivismo Aprender haciendo, no solo leyendo   **Siguiente m\u00f3dulo** \u2192 [04. Entornos](04_ENTORNOS.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/04_ENTORNOS/","title":"M\u00d3DULO 04: ENTORNOS PROFESIONALES","text":"# \ud83d\udd27 M\u00d3DULO 04: Entornos Profesionales  ### El Arte de la Reproducibilidad a Nivel de Dependencias  *\"'Funciona en mi m\u00e1quina' es la excusa m\u00e1s cara de la industria.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **4-5 horas**        | 30%                  | 70%                  |"},{"location":"docs/04_ENTORNOS/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 03_ESTRUCTURA_PROYECTO (o al menos entender <code>pyproject.toml</code>, <code>Makefile</code> y <code>requirements*</code>).</li> <li>Poder crear/activar un entorno virtual y ejecutar comandos en terminal.</li> <li>Tener claro el objetivo: reproducibilidad entre tu m\u00e1quina, CI y (eventualmente) Docker.</li> </ul>"},{"location":"docs/04_ENTORNOS/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de configurar: abre Protocolo E y define tu output m\u00ednimo (ej: \u201centorno reproducible + lockfile + CI instala igual\u201d).</li> <li>Mientras depuras: si te atoras &gt;15 min (pip vs python -m pip, conflicto de versiones, lockfiles), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir qu\u00e9 mejorar (pinning, caching en CI, Docker alignment).</li> </ul>"},{"location":"docs/04_ENTORNOS/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Un flujo reproducible de instalaci\u00f3n (documentado en README o Makefile).</li> <li>[ ] Un lockfile que \u201ccongele\u201d versiones (<code>requirements.txt</code>/<code>poetry.lock</code>/<code>environment.lock</code>).</li> <li>[ ] CI instalando el mismo entorno (sin \u201cversion drift\u201d).</li> <li>[ ] Validaci\u00f3n m\u00ednima: <code>python -c \"import pandas; print(pandas.__version__)\"</code> y <code>pytest</code> desde la ra\u00edz.</li> </ul> <p></p>"},{"location":"docs/04_ENTORNOS/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: reproducibilidad / lockfiles / CI caching / alignment con Docker</li> <li>Archivo: <code>requirements.in</code>, <code>requirements.txt</code>, <code>pyproject.toml</code>, <code>poetry.lock</code>, <code>environment.yml</code>, <code>.github/workflows/*.yml</code>, <code>Dockerfile</code></li> <li>Prueba: instalaci\u00f3n limpia + tests (idealmente en CI) sin cambiar versiones manualmente.</li> </ul>"},{"location":"docs/04_ENTORNOS/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>ADR de Inicio</li> <li>4.1 El Problema</li> <li>4.2 Comparativa</li> <li>4.3 venv + pip-tools</li> <li>4.4 Poetry</li> <li>4.5 Conda</li> <li>4.6 Docker Dev</li> <li>4.7 Integraci\u00f3n con CI/CD</li> <li>Errores habituales</li> <li>4.8 Ejercicio Pr\u00e1ctico</li> <li>4.9 Autoevaluaci\u00f3n</li> </ul>"},{"location":"docs/04_ENTORNOS/#adr-de-inicio-por-que-importan-los-entornos","title":"\ud83c\udfaf ADR de Inicio: \u00bfPor Qu\u00e9 Importan los Entornos?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  ADR-005: Gesti\u00f3n de Entornos como Pr\u00e1ctica Obligatoria                       \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  CONTEXTO:                                                                    \u2551\n\u2551  El 30% de bugs en producci\u00f3n ML se deben a diferencias de versiones          \u2551\n\u2551  entre desarrollo y producci\u00f3n (Google ML Engineering Best Practices).        \u2551\n\u2551                                                                               \u2551\n\u2551  DECISI\u00d3N:                                                                    \u2551\n\u2551  Todo proyecto DEBE tener un sistema de gesti\u00f3n de dependencias con           \u2551\n\u2551  versiones pinneadas y un m\u00e9todo documentado de reproducir el entorno.        \u2551\n\u2551                                                                               \u2551\n\u2551  CONSECUENCIAS:                                                               \u2551\n\u2551  (+) Reproducibilidad garantizada entre m\u00e1quinas                              \u2551\n\u2551  (+) Onboarding de nuevos desarrolladores en minutos, no d\u00edas                 \u2551\n\u2551  (+) CI/CD confiable (mismas versiones siempre)                               \u2551\n\u2551  (-) Setup inicial requiere m\u00e1s tiempo                                        \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/04_ENTORNOS/#lo-que-lograras-en-este-modulo","title":"Lo Que Lograr\u00e1s en Este M\u00f3dulo","text":"<ol> <li>Entender las diferencias entre venv, Conda, Poetry y Docker</li> <li>Elegir la herramienta correcta seg\u00fan tu proyecto</li> <li>Configurar un entorno profesional con lockfiles</li> <li>Integrar el entorno con CI/CD</li> </ol>"},{"location":"docs/04_ENTORNOS/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<ul> <li>En BankChurn-Predictor, CarVision-Market-Intelligence y   TelecomAI-Customer-Intelligence ya encontrar\u00e1s:</li> <li>Ficheros <code>requirements-core.txt</code>, <code>requirements.in</code> y <code>requirements.txt</code> para gestionar     dependencias de forma reproducible.</li> <li>Un <code>Makefile</code> con targets como <code>install</code>, <code>test</code> y <code>serve</code> que asumen un entorno activo.</li> <li>Archivos <code>docker-compose.demo.yml</code> y <code>docker-compose.yml</code> que levantan el stack completo     (APIs, MLflow, dashboards).</li> <li>Usa este m\u00f3dulo para entender por qu\u00e9 esas piezas existen y c\u00f3mo recrear el mismo entorno   desde cero en tu m\u00e1quina o en CI/CD.</li> </ul>"},{"location":"docs/04_ENTORNOS/#41-el-problema-funciona-en-mi-maquina","title":"4.1 El Problema: \"Funciona en Mi M\u00e1quina\"","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         \ud83d\ude31 EL HORROR DE LAS DEPENDENCIAS                      \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   ESCENARIO T\u00cdPICO:                                                           \u2551\n\u2551                                                                               \u2551\n\u2551   Developer A (laptop):                                                       \u2551\n\u2551   \u2022 Python 3.11.4                                                             \u2551\n\u2551   \u2022 scikit-learn 1.3.0                                                        \u2551\n\u2551   \u2022 pandas 2.0.3                                                              \u2551\n\u2551   \u2022 numpy 1.24.3                                                              \u2551\n\u2551   \u2192 \"Todo funciona perfecto\" \u2705                                               \u2551\n\u2551                                                                               \u2551\n\u2551   Developer B (otra laptop):                                                  \u2551\n\u2551   \u2022 Python 3.9.7                                                              \u2551\n\u2551   \u2022 scikit-learn 1.0.2                                                        \u2551\n\u2551   \u2022 pandas 1.4.0                                                              \u2551\n\u2551   \u2022 numpy 1.21.0                                                              \u2551\n\u2551   \u2192 \"AttributeError: module 'sklearn' has no attribute 'X'\" \u274c                \u2551\n\u2551                                                                               \u2551\n\u2551   Servidor de producci\u00f3n:                                                     \u2551\n\u2551   \u2022 Python 3.8.10                                                             \u2551\n\u2551   \u2022 Versiones \"whatever pip installed\"                                        \u2551\n\u2551   \u2192 CRASH EN PRODUCCI\u00d3N \ud83d\udca5                                                    \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/04_ENTORNOS/#las-4-capas-de-reproducibilidad","title":"Las 4 Capas de Reproducibilidad","text":"<pre><code>flowchart TB\n    subgraph L4[\"\ud83d\udc33 NIVEL 4: Contenedor\"]\n        D[Docker/Podman]\n    end\n\n    subgraph L3[\"\ud83d\udce6 NIVEL 3: Gestor de Paquetes\"]\n        C[Poetry / pip-tools / Conda]\n    end\n\n    subgraph L2[\"\ud83d\udd12 NIVEL 2: Entorno Virtual\"]\n        B[venv / virtualenv / conda env]\n    end\n\n    subgraph L1[\"\ud83d\udc0d NIVEL 1: Versi\u00f3n Python\"]\n        A[pyenv / conda / asdf]\n    end\n\n    L1 --&gt; L2 --&gt; L3 --&gt; L4\n\n    style L1 fill:#ffecb3\n    style L2 fill:#c8e6c9\n    style L3 fill:#bbdefb\n    style L4 fill:#e1bee7</code></pre>"},{"location":"docs/04_ENTORNOS/#mapa-mental-de-conceptos-entornos-reproducibles","title":"\ud83e\udde0 Mapa Mental de Conceptos: Entornos Reproducibles","text":"<pre><code>                         \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                         \u2551    ENTORNOS REPRODUCIBLES EN ML         \u2551\n                         \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   HERRAMIENTAS   \u2502              \u2502    CONCEPTOS     \u2502              \u2502     ARCHIVOS     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 venv (built-in)               \u251c\u2500 Lockfile                       \u251c\u2500 requirements.txt\n\u251c\u2500 pip-tools                     \u251c\u2500 Pinning                        \u251c\u2500 pyproject.toml\n\u251c\u2500 Poetry                        \u251c\u2500 Reproducibilidad               \u251c\u2500 poetry.lock\n\u251c\u2500 Conda                         \u251c\u2500 Aislamiento                    \u251c\u2500 environment.yml\n\u2514\u2500 Docker                        \u2514\u2500 Version drift                  \u2514\u2500 Dockerfile\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo Entorno virtual Aislamiento de paquetes por proyecto <code>.venv/</code>, <code>conda env</code> Lockfile Archivo con versiones exactas congeladas <code>requirements.txt</code>, <code>poetry.lock</code> Pinning Fijar versi\u00f3n exacta de una dependencia <code>pandas==2.0.3</code> vs <code>pandas&gt;=2.0</code> Version drift Versiones diferentes entre m\u00e1quinas Dev: 1.3.0, Prod: 1.0.2 pip-tools Herramienta para generar lockfiles <code>pip-compile</code>, <code>pip-sync</code>"},{"location":"docs/04_ENTORNOS/#ejercicio-puente-crear-entorno-basico","title":"\ud83d\udcbb Ejercicio Puente: Crear Entorno B\u00e1sico","text":"<p>Meta: Antes de usar herramientas avanzadas, domina lo b\u00e1sico.</p> <p>Ejercicio 1: venv + requirements.txt <pre><code># TU TAREA: Crea un entorno virtual y lockfile desde cero\n# 1. Crear entorno\npython -m venv .venv\n\n# 2. Activar (Linux/Mac)\nsource .venv/bin/activate\n\n# 3. Instalar dependencias\npip install pandas scikit-learn\n\n# 4. Generar lockfile\npip freeze &gt; requirements.txt\n\n# 5. \u00bfQu\u00e9 contiene requirements.txt?\ncat requirements.txt\n</code></pre></p> <p>Ejercicio 2: Reproducir en otra m\u00e1quina (simulado) <pre><code># TU TAREA: Simula \"otra m\u00e1quina\" con entorno nuevo\ndeactivate\nrm -rf .venv\npython -m venv .venv\nsource .venv/bin/activate\n\n# Instalar desde lockfile\npip install -r requirements.txt\n\n# Verificar: \u00bfmismas versiones?\npython -c \"import pandas; print(pandas.__version__)\"\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code># El requirements.txt deber\u00eda tener algo como:\n# numpy==1.24.3\n# pandas==2.0.3\n# scikit-learn==1.3.0\n# (m\u00e1s dependencias transitivas)\n\n# La clave es que las versiones son EXACTAS (==)\n# No rangos (&gt;=), no \"whatever pip decides\"\n</code></pre>"},{"location":"docs/04_ENTORNOS/#practica-del-portafolio-entorno-de-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Entorno de BankChurn","text":"<p>Tarea: Recrear el entorno exacto de BankChurn-Predictor.</p> <p>Paso 1: Examina los archivos de dependencias <pre><code>cd BankChurn-Predictor\nls -la requirements*.txt pyproject.toml\n</code></pre></p> <p>Paso 2: Crea entorno limpio <pre><code># Destruir cualquier entorno existente\nrm -rf .venv\n\n# Crear nuevo\npython -m venv .venv\nsource .venv/bin/activate\n</code></pre></p> <p>Paso 3: Instala con el m\u00e9todo del proyecto <pre><code># Opci\u00f3n 1: Si hay Makefile\nmake install\n\n# Opci\u00f3n 2: Si usa pyproject.toml\npip install -e \".[dev]\"\n\n# Opci\u00f3n 3: Si hay requirements.txt\npip install -r requirements.txt\n</code></pre></p> <p>Paso 4: Verifica <pre><code>pytest  # \u00bfPasan los tests?\npython -c \"from bankchurn import ChurnTrainer; print('\u2705')\"\n</code></pre></p>"},{"location":"docs/04_ENTORNOS/#checkpoint-de-conocimiento-entornos","title":"\u2705 Checkpoint de Conocimiento: Entornos","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la diferencia entre <code>pandas&gt;=2.0</code> y <code>pandas==2.0.3</code>?</p> <p>A) No hay diferencia B) <code>&gt;=2.0</code> permite cualquier versi\u00f3n 2.x+, <code>==2.0.3</code> fija versi\u00f3n exacta C) <code>==2.0.3</code> es m\u00e1s r\u00e1pido D) <code>&gt;=2.0</code> es para producci\u00f3n  </p> <p>Pregunta 2: \u00bfPor qu\u00e9 un lockfile es importante para CI/CD?</p> <p>A) Hace la instalaci\u00f3n m\u00e1s r\u00e1pida B) Garantiza que CI instale EXACTAMENTE las mismas versiones que desarrollo C) GitHub lo requiere D) Reduce el tama\u00f1o del repositorio  </p> <p>Pregunta 3: Developer A tiene <code>numpy 1.24</code>, Developer B tiene <code>numpy 1.21</code>. \u00bfQu\u00e9 problema pueden tener?</p> <p>A) Ninguno, numpy es compatible B) Funciones que existen en 1.24 no existen en 1.21 (c\u00f3digo de A falla en B) C) El c\u00f3digo ser\u00e1 m\u00e1s lento D) Git tendr\u00e1 conflictos  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Ejecutas tu c\u00f3digo en CI y obtienes:\n  AttributeError: module 'sklearn.preprocessing' has no attribute 'TargetEncoder'\n\nPero en tu m\u00e1quina local funciona.\n\nTu requirements.txt tiene:\n  scikit-learn&gt;=1.0\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) `&gt;=2.0` permite cualquier versi\u00f3n 2.x+. Esto causa \"version drift\".  **Pregunta 2**: B) Garantiza que CI instale EXACTAMENTE las mismas versiones.  **Pregunta 3**: B) Funciones que existen en 1.24 no existen en 1.21.  **Escenario de Debugging**:  - **Problema**: `TargetEncoder` se a\u00f1adi\u00f3 en sklearn 1.3. `&gt;=1.0` permite instalar 1.0-1.2 donde no existe. - **Soluci\u00f3n**: Usar versi\u00f3n pinneada: `scikit-learn==1.3.0` - **Mejor pr\u00e1ctica**: Usar `pip-compile` para generar lockfile con versiones exactas.  <p></p>"},{"location":"docs/04_ENTORNOS/#42-comparativa-de-herramientas","title":"4.2 Comparativa de Herramientas","text":""},{"location":"docs/04_ENTORNOS/#matriz-de-decision","title":"Matriz de Decisi\u00f3n","text":"Criterio venv + pip Conda Poetry Docker Dev Simplicidad \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50 Reproducibilidad \u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Deps no-Python \u274c \u2705 \u274c \u2705 Lockfile nativo \u274c (req pip-tools) \u274c \u2705 N/A Speed \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 CI/CD friendly \u2705 \u26a0\ufe0f \u2705 \u2705 Espacio disco Bajo Alto Bajo Medio-Alto Curva aprendizaje Baja Media Baja Media"},{"location":"docs/04_ENTORNOS/#cuando-usar-cada-uno","title":"\u00bfCu\u00e1ndo Usar Cada Uno?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    GU\u00cdA DE SELECCI\u00d3N DE HERRAMIENTA                           \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  USA venv + pip-tools SI:                                                     \u2551\n\u2551  \u2022 Proyecto simple, solo dependencias Python                                  \u2551\n\u2551  \u2022 Equipo peque\u00f1o, ya conoce pip                                              \u2551\n\u2551  \u2022 CI/CD en GitHub Actions (pip es m\u00e1s r\u00e1pido)                                \u2551\n\u2551  \u2022 No necesitas lockfile sofisticado                                          \u2551\n\u2551                                                                               \u2551\n\u2551  USA Conda SI:                                                                \u2551\n\u2551  \u2022 Necesitas librer\u00edas con dependencias C/C++ (CUDA, MKL, OpenCV)             \u2551\n\u2551  \u2022 Trabajas en Data Science pesado (numpy, scipy optimizados)                 \u2551\n\u2551  \u2022 Tu equipo ya usa Conda                                                     \u2551\n\u2551  \u2022 Necesitas m\u00faltiples versiones de Python f\u00e1cilmente                         \u2551\n\u2551                                                                               \u2551\n\u2551  USA Poetry SI:                                                               \u2551\n\u2551  \u2022 Proyecto serio que necesita reproducibilidad exacta                        \u2551\n\u2551  \u2022 Quieres publicar en PyPI                                                   \u2551\n\u2551  \u2022 Valoras lockfiles y dependency resolution robusta                          \u2551\n\u2551  \u2022 Equipo moderno que aprecia herramientas bien dise\u00f1adas                     \u2551\n\u2551                                                                               \u2551\n\u2551  USA Docker Dev Containers SI:                                                \u2551\n\u2551  \u2022 Reproducibilidad TOTAL es cr\u00edtica                                          \u2551\n\u2551  \u2022 M\u00faltiples servicios (DB, Redis, etc.) en desarrollo                        \u2551\n\u2551  \u2022 Onboarding debe ser \"clone &amp; run\"                                          \u2551\n\u2551  \u2022 Equipo usa VS Code con extensi\u00f3n Dev Containers                            \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/04_ENTORNOS/#43-opcion-1-venv-pip-tools-simple-y-efectivo","title":"4.3 Opci\u00f3n 1: venv + pip-tools (Simple y Efectivo)","text":""},{"location":"docs/04_ENTORNOS/#setup-basico","title":"Setup B\u00e1sico","text":"<pre><code># Crear entorno virtual\npython3.11 -m venv .venv              # -m venv: ejecuta m\u00f3dulo venv. .venv: carpeta destino.\n                                      # Crea una copia aislada del int\u00e9rprete Python.\n\n# Activar\nsource .venv/bin/activate             # Linux/Mac: modifica PATH para usar Python del venv.\n# .venv\\Scripts\\activate              # Windows: mismo efecto, sintaxis diferente.\n\n# Instalar pip-tools para lockfiles\npip install pip-tools                 # pip-tools: genera lockfiles con versiones exactas.\n</code></pre>"},{"location":"docs/04_ENTORNOS/#estructura-de-archivos","title":"Estructura de Archivos","text":"<pre><code>project/\n\u251c\u2500\u2500 requirements.in        # Dependencias directas (lo que escribes)\n\u251c\u2500\u2500 requirements.txt       # Lockfile generado (no editar manualmente)\n\u251c\u2500\u2500 requirements-dev.in    # Dependencias de desarrollo\n\u251c\u2500\u2500 requirements-dev.txt   # Lockfile de desarrollo\n\u2514\u2500\u2500 .python-version        # Versi\u00f3n de Python (para pyenv)\n</code></pre>"},{"location":"docs/04_ENTORNOS/#requirementsin-lo-que-escribes","title":"requirements.in (Lo que escribes)","text":"<pre><code># requirements.in - Dependencias directas\n# Solo especifica las que usas directamente, pip-tools resuelve el resto\n\npandas&gt;=2.0.0,&lt;3.0.0\nscikit-learn&gt;=1.3.0\npydantic&gt;=2.0.0\nfastapi&gt;=0.100.0\nmlflow&gt;=2.8.0\npyyaml&gt;=6.0\n</code></pre>"},{"location":"docs/04_ENTORNOS/#generar-lockfile","title":"Generar Lockfile","text":"<pre><code># Genera requirements.txt con TODAS las versiones exactas\npip-compile requirements.in --output-file=requirements.txt  # Lee .in, resuelve deps, genera .txt con versiones exactas.\n\n# Para desarrollo\npip-compile requirements-dev.in --output-file=requirements-dev.txt  # Misma l\u00f3gica para deps de desarrollo.\n\n# Instalar desde lockfile\npip-sync requirements.txt requirements-dev.txt  # Instala EXACTAMENTE lo del lockfile (a\u00f1ade y remueve).\n</code></pre>"},{"location":"docs/04_ENTORNOS/#requirementstxt-generado-no-editar","title":"requirements.txt Generado (NO EDITAR)","text":"<pre><code># This file is autogenerated by pip-compile with Python 3.11\n# Do not edit manually.\n\nannotated-types==0.6.0\n    # via pydantic\nanyio==4.0.0\n    # via\n    #   httpx\n    #   starlette\ncertifi==2023.11.17\n    # via httpx\nfastapi==0.104.1\n    # via -r requirements.in\nnumpy==1.26.2\n    # via\n    #   pandas\n    #   scikit-learn\npandas==2.1.3\n    # via -r requirements.in\npydantic==2.5.2\n    # via\n    #   -r requirements.in\n    #   fastapi\n# ... etc (versiones EXACTAS)\n</code></pre>"},{"location":"docs/04_ENTORNOS/#makefile-para-automatizacion","title":"Makefile para Automatizaci\u00f3n","text":"<pre><code># Makefile\n.PHONY: venv install lock sync clean  # .PHONY: estos targets no son archivos, son comandos.\n\nPYTHON := python3.11                  # Variable: versi\u00f3n de Python a usar.\nVENV := .venv                         # Variable: carpeta del entorno virtual.\nBIN := $(VENV)/bin                    # Variable: ruta a binarios del venv.\n\nvenv:                                 # Target: crear entorno virtual.\n    $(PYTHON) -m venv $(VENV)         # Crea venv con Python especificado.\n    $(BIN)/pip install --upgrade pip pip-tools  # Actualiza pip e instala pip-tools.\n\nlock: venv                            # Target: generar lockfiles. Depende de venv.\n    $(BIN)/pip-compile requirements.in -o requirements.txt  # Genera lockfile principal.\n    $(BIN)/pip-compile requirements-dev.in -o requirements-dev.txt  # Genera lockfile de desarrollo.\n\nsync: venv                            # Target: sincronizar entorno con lockfiles.\n    $(BIN)/pip-sync requirements.txt requirements-dev.txt  # Instala exactamente lo del lockfile.\n\ninstall: venv lock sync               # Target compuesto: ejecuta venv \u2192 lock \u2192 sync en orden.\n\nclean:                                # Target: limpiar todo.\n    rm -rf $(VENV)                    # Elimina carpeta del venv.\n    rm -f requirements.txt requirements-dev.txt  # Elimina lockfiles generados.\n</code></pre>"},{"location":"docs/04_ENTORNOS/#44-opcion-2-poetry-moderno-y-robusto","title":"4.4 Opci\u00f3n 2: Poetry (Moderno y Robusto)","text":""},{"location":"docs/04_ENTORNOS/#instalacion","title":"Instalaci\u00f3n","text":"<pre><code># Instalar Poetry (m\u00e9todo oficial)\ncurl -sSL https://install.python-poetry.org | python3 -  # Descarga e instala Poetry globalmente.\n\n# Verificar\npoetry --version                      # Deber\u00eda mostrar algo como \"Poetry 1.7.0\".\n</code></pre>"},{"location":"docs/04_ENTORNOS/#inicializar-proyecto","title":"Inicializar Proyecto","text":"<pre><code># En proyecto existente\npoetry init                           # Wizard interactivo que crea pyproject.toml.\n\n# O crear nuevo proyecto\npoetry new bankchurn-predictor        # Crea estructura de carpetas + pyproject.toml.\n</code></pre>"},{"location":"docs/04_ENTORNOS/#pyprojecttoml-completo","title":"pyproject.toml Completo","text":"<pre><code>[tool.poetry]                           # Secci\u00f3n de metadata de Poetry.\nname = \"bankchurn\"                      # Nombre del paquete (para pip install).\nversion = \"0.1.0\"                       # Versi\u00f3n sem\u00e1ntica del proyecto.\ndescription = \"Predictor de churn bancario con MLOps\"\nauthors = [\"Tu Nombre &lt;tu@email.com&gt;\"]\nreadme = \"README.md\"                    # Archivo README a incluir en el paquete.\npackages = [{include = \"bankchurn\", from = \"src\"}]  # D\u00f3nde est\u00e1 el c\u00f3digo fuente.\n\n[tool.poetry.dependencies]              # Dependencias de producci\u00f3n.\npython = \"^3.10\"                        # ^3.10: compatible con 3.10, 3.11, 3.12 pero no 4.0.\npandas = \"^2.0.0\"                       # ^ = \"compatible con\" (semver).\nscikit-learn = \"^1.3.0\"\npydantic = \"^2.0.0\"\nfastapi = \"^0.104.0\"\nuvicorn = \"^0.24.0\"                     # Server ASGI para FastAPI.\nmlflow = \"^2.8.0\"\npyyaml = \"^6.0\"\njoblib = \"^1.3.0\"                       # Serializaci\u00f3n de modelos sklearn.\n\n[tool.poetry.group.dev.dependencies]    # Dependencias solo para desarrollo.\npytest = \"^7.4.0\"                       # Framework de testing.\npytest-cov = \"^4.1.0\"                   # Plugin de coverage para pytest.\nmypy = \"^1.6.0\"                         # Type checker.\nruff = \"^0.1.0\"                         # Linter + formatter.\npre-commit = \"^3.5.0\"                   # Hooks de pre-commit.\nipython = \"^8.0.0\"                      # REPL mejorado.\n\n[tool.poetry.group.docs.dependencies]   # Dependencias para documentaci\u00f3n.\nmkdocs = \"^1.5.0\"                       # Generador de documentaci\u00f3n.\nmkdocs-material = \"^9.4.0\"              # Tema popular para MkDocs.\n\n[tool.poetry.scripts]                   # Comandos CLI que se instalan.\nbankchurn-train = \"bankchurn.cli:train\"  # `bankchurn-train` \u2192 ejecuta cli.train().\nbankchurn-predict = \"bankchurn.cli:predict\"\n\n[build-system]                          # Configuraci\u00f3n de build (PEP 517).\nrequires = [\"poetry-core\"]              # Backend de build.\nbuild-backend = \"poetry.core.masonry.api\"\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CONFIGURACI\u00d3N DE HERRAMIENTAS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n[tool.ruff]\nline-length = 100\nselect = [\"E\", \"F\", \"I\", \"W\", \"B\", \"C4\", \"UP\"]\nignore = [\"E501\"]\nsrc = [\"src\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nwarn_return_any = true\ndisallow_untyped_defs = true\nignore_missing_imports = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\naddopts = \"-v --cov=src/bankchurn --cov-report=term-missing\"\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\"tests/*\"]\n</code></pre>"},{"location":"docs/04_ENTORNOS/#comandos-esenciales","title":"Comandos Esenciales","text":"<pre><code># Instalar dependencias (crea poetry.lock autom\u00e1ticamente)\npoetry install\n\n# A\u00f1adir dependencia\npoetry add pandas\npoetry add --group dev pytest\n\n# Actualizar dependencias\npoetry update\n\n# Ejecutar comando en el entorno\npoetry run python src/bankchurn/main.py\npoetry run pytest\n\n# Activar shell en el entorno\npoetry shell\n\n# Exportar a requirements.txt (para Docker)\npoetry export -f requirements.txt --output requirements.txt --without-hashes\n\n# Build del paquete\npoetry build\n</code></pre>"},{"location":"docs/04_ENTORNOS/#poetrylock-generado-automaticamente","title":"poetry.lock (Generado Autom\u00e1ticamente)","text":"<p>El archivo <code>poetry.lock</code> contiene TODAS las versiones exactas de TODAS las dependencias (directas y transitivas). SIEMPRE commitear este archivo.</p> <p></p>"},{"location":"docs/04_ENTORNOS/#45-opcion-3-conda-para-data-science-pesado","title":"4.5 Opci\u00f3n 3: Conda (Para Data Science Pesado)","text":""},{"location":"docs/04_ENTORNOS/#cuando-conda-es-la-mejor-opcion","title":"Cu\u00e1ndo Conda es la Mejor Opci\u00f3n","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         \u2705 USA CONDA SI NECESITAS:                            \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   \u2022 CUDA / cuDNN para GPU computing                                           \u2551\n\u2551   \u2022 NumPy/SciPy compilados con MKL (Intel) o OpenBLAS optimizado              \u2551\n\u2551   \u2022 OpenCV con dependencias de sistema                                        \u2551\n\u2551   \u2022 R + Python en el mismo entorno                                            \u2551\n\u2551   \u2022 Librer\u00edas geoespaciales (GDAL, GEOS, PROJ)                                \u2551\n\u2551   \u2022 Dependencias de sistema que pip no puede instalar                         \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/04_ENTORNOS/#environmentyml","title":"environment.yml","text":"<pre><code># environment.yml\nname: bankchurn\nchannels:\n  - conda-forge  # Preferir conda-forge sobre defaults\n  - defaults\n\ndependencies:\n  # Python version\n  - python=3.11\n\n  # Core data science (optimizados con MKL)\n  - numpy=1.26.*\n  - pandas=2.1.*\n  - scikit-learn=1.3.*\n\n  # Si necesitas GPU\n  # - pytorch\n  # - cudatoolkit=11.8\n\n  # Dependencias que tienen componentes C\n  - pyyaml\n  - joblib\n\n  # pip dependencies (las que no est\u00e1n en conda o prefieres de PyPI)\n  - pip\n  - pip:\n    - pydantic&gt;=2.0.0\n    - fastapi&gt;=0.104.0\n    - uvicorn&gt;=0.24.0\n    - mlflow&gt;=2.8.0\n    - pytest&gt;=7.4.0\n    - mypy&gt;=1.6.0\n    - ruff&gt;=0.1.0\n</code></pre>"},{"location":"docs/04_ENTORNOS/#comandos-conda","title":"Comandos Conda","text":"<pre><code># Crear entorno desde archivo\nconda env create -f environment.yml\n\n# Activar\nconda activate bankchurn\n\n# Exportar entorno exacto (para reproducibilidad)\nconda env export &gt; environment-lock.yml\n\n# Exportar solo dependencias expl\u00edcitas\nconda env export --from-history &gt; environment.yml\n\n# Actualizar entorno\nconda env update -f environment.yml --prune\n\n# Listar entornos\nconda env list\n\n# Eliminar entorno\nconda env remove -n bankchurn\n</code></pre>"},{"location":"docs/04_ENTORNOS/#mamba-conda-acelerado","title":"Mamba: Conda Acelerado","text":"<pre><code># Instalar mamba (resolver mucho m\u00e1s r\u00e1pido)\nconda install -c conda-forge mamba\n\n# Usar mamba en lugar de conda\nmamba env create -f environment.yml\nmamba install numpy\n</code></pre>"},{"location":"docs/04_ENTORNOS/#46-opcion-4-docker-dev-containers","title":"4.6 Opci\u00f3n 4: Docker Dev Containers","text":""},{"location":"docs/04_ENTORNOS/#por-que-docker-para-desarrollo","title":"\u00bfPor Qu\u00e9 Docker para Desarrollo?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                       DOCKER DEV CONTAINERS: PROS/CONS                        \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   \u2705 PROS:                                                                    \u2551\n\u2551   \u2022 Reproducibilidad TOTAL (mismo OS, mismas versiones de todo)               \u2551\n\u2551   \u2022 Onboarding = \"git clone &amp;&amp; code .\" (con VS Code Dev Containers)           \u2551\n\u2551   \u2022 Mismo entorno en dev, CI y producci\u00f3n                                     \u2551\n\u2551   \u2022 Puedes incluir servicios (PostgreSQL, Redis, MLflow server)               \u2551\n\u2551                                                                               \u2551\n\u2551   \u274c CONS:                                                                    \u2551\n\u2551   \u2022 Overhead de Docker (memoria, CPU)                                         \u2551\n\u2551   \u2022 M\u00e1s complejo de configurar inicialmente                                   \u2551\n\u2551   \u2022 Debugging puede ser m\u00e1s dif\u00edcil                                           \u2551\n\u2551   \u2022 Performance de I/O en vol\u00famenes (especialmente macOS)                     \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/04_ENTORNOS/#devcontainerdevcontainerjson","title":".devcontainer/devcontainer.json","text":"<pre><code>{\n    \"name\": \"BankChurn Dev\",\n    \"dockerComposeFile\": \"docker-compose.yml\",\n    \"service\": \"app\",\n    \"workspaceFolder\": \"/workspace\",\n\n    \"customizations\": {\n        \"vscode\": {\n            \"extensions\": [\n                \"ms-python.python\",\n                \"ms-python.vscode-pylance\",\n                \"charliermarsh.ruff\",\n                \"ms-toolsai.jupyter\",\n                \"redhat.vscode-yaml\",\n                \"GitHub.copilot\"\n            ],\n            \"settings\": {\n                \"python.defaultInterpreterPath\": \"/workspace/.venv/bin/python\",\n                \"python.formatting.provider\": \"none\",\n                \"editor.formatOnSave\": true,\n                \"[python]\": {\n                    \"editor.defaultFormatter\": \"charliermarsh.ruff\"\n                }\n            }\n        }\n    },\n\n    \"postCreateCommand\": \"make install\",\n\n    \"forwardPorts\": [8000, 5000, 3000],\n\n    \"remoteUser\": \"vscode\"\n}\n</code></pre>"},{"location":"docs/04_ENTORNOS/#devcontainerdocker-composeyml","title":".devcontainer/docker-compose.yml","text":"<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: ..\n      dockerfile: .devcontainer/Dockerfile\n    volumes:\n      - ..:/workspace:cached\n      - venv:/workspace/.venv\n    environment:\n      - PYTHONDONTWRITEBYTECODE=1\n      - PYTHONUNBUFFERED=1\n    command: sleep infinity\n\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.8.0\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - mlflow-data:/mlflow\n    command: mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root /mlflow/artifacts\n\n  postgres:\n    image: postgres:15\n    environment:\n      POSTGRES_USER: bankchurn\n      POSTGRES_PASSWORD: bankchurn\n      POSTGRES_DB: bankchurn\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n\nvolumes:\n  venv:\n  mlflow-data:\n  postgres-data:\n</code></pre>"},{"location":"docs/04_ENTORNOS/#devcontainerdockerfile","title":".devcontainer/Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\n# Dependencias del sistema\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    git \\\n    curl \\\n    make \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Usuario no-root\nARG USERNAME=vscode\nARG USER_UID=1000\nARG USER_GID=$USER_UID\n\nRUN groupadd --gid $USER_GID $USERNAME \\\n    &amp;&amp; useradd --uid $USER_UID --gid $USER_GID -m $USERNAME\n\n# Workspace\nWORKDIR /workspace\n\n# Cambiar a usuario no-root\nUSER $USERNAME\n\n# Pre-instalar pip-tools\nRUN pip install --user pip-tools\n\nENV PATH=\"/home/${USERNAME}/.local/bin:${PATH}\"\n</code></pre>"},{"location":"docs/04_ENTORNOS/#47-integracion-con-cicd","title":"4.7 Integraci\u00f3n con CI/CD","text":""},{"location":"docs/04_ENTORNOS/#github-actions-con-pip","title":"GitHub Actions con pip","text":"<pre><code># .github/workflows/ci.yml\nname: CI\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'  # Cachea dependencias\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements.txt\n          pip install -r requirements-dev.txt\n\n      - name: Run tests\n        run: pytest tests/ -v --cov\n</code></pre>"},{"location":"docs/04_ENTORNOS/#github-actions-con-poetry","title":"GitHub Actions con Poetry","text":"<pre><code>name: CI\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - name: Install Poetry\n        uses: snok/install-poetry@v1\n        with:\n          version: 1.7.0\n          virtualenvs-create: true\n          virtualenvs-in-project: true\n\n      - name: Load cached venv\n        uses: actions/cache@v3\n        with:\n          path: .venv\n          key: venv-${{ runner.os }}-${{ hashFiles('poetry.lock') }}\n\n      - name: Install dependencies\n        run: poetry install --no-interaction\n\n      - name: Run tests\n        run: poetry run pytest tests/ -v --cov\n</code></pre>"},{"location":"docs/04_ENTORNOS/#errores-habituales-y-como-depurarlos-en-entornos","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en entornos","text":"<p>Los problemas de este m\u00f3dulo se manifiestan como inconsistencias entre m\u00e1quinas: algo funciona en tu laptop pero no en el servidor, o en CI. Aqu\u00ed van los patrones m\u00e1s frecuentes y c\u00f3mo atacarlos.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/04_ENTORNOS/#1-entorno-virtual-mal-activado-pip-instala-en-el-sitio-equivocado","title":"1) Entorno virtual mal activado (<code>pip</code> instala en el sitio equivocado)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Ejecutas <code>pip install</code> y luego <code>python -c \"import pandas\"</code> y obtienes <code>ModuleNotFoundError</code>.</li> <li>Tienes varias versiones de Python (<code>python</code>, <code>python3</code>, <code>pyenv</code>, Conda) y no sabes cu\u00e1l est\u00e1 usando tu proyecto.</li> <li>En CI funciona con una versi\u00f3n de paquete y en local con otra.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Ejecuta:   <pre><code>which python\npython -m pip --version\n</code></pre>   y verifica que ambos apuntan al mismo entorno (<code>.venv/bin/python</code>, por ejemplo).</li> <li>En Windows, revisa la ruta de <code>Scripts</code> y que est\u00e9s en el entorno correcto (<code>(.venv)</code> en el prompt).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa siempre <code>python -m pip</code> en lugar de <code>pip</code> a secas:   <pre><code>python -m pip install -r requirements.txt\n</code></pre></li> <li>Documenta en el README/Makefile c\u00f3mo activar el entorno (<code>source .venv/bin/activate</code>, <code>poetry shell</code>, <code>conda activate ...</code>).</li> <li>Si usas <code>.python-version</code> con <code>pyenv</code>, aseg\u00farate de que coincide con la versi\u00f3n definida en <code>pyproject.toml</code> o <code>environment.yml</code>.</li> </ul>"},{"location":"docs/04_ENTORNOS/#2-lockfiles-ignorados-requirementstxt-poetrylock-environment-lockyml","title":"2) Lockfiles ignorados (<code>requirements.txt</code> / <code>poetry.lock</code> / <code>environment-lock.yml</code>)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Dos personas hacen <code>pip install -r requirements.txt</code> y obtienen versiones distintas de las mismas librer\u00edas.</li> <li>En tu m\u00e1quina funciona con <code>pandas==2.0.3</code> pero en producci\u00f3n falla con <code>pandas==2.2.0</code>.</li> <li><code>poetry.lock</code> o <code>requirements-dev.txt</code> no est\u00e1n commiteados.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el repositorio:</li> <li>\u00bfExiste <code>requirements.txt</code> generado por pip-tools y est\u00e1 en Git?</li> <li>\u00bfExiste <code>poetry.lock</code> y est\u00e1 versionado?</li> <li>\u00bfHay alg\u00fan <code>environment-lock.yml</code> de Conda?</li> <li>Compara lo que dice el lockfile con lo que tienes instalado:   <pre><code>pip freeze | grep pandas\n</code></pre></li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Siempre commitea el lockfile (requirements.txt, poetry.lock, environment-lock.yml).</li> <li>Define una \u00fanica fuente de verdad: si usas pip-tools, no edites <code>requirements.txt</code> a mano, solo <code>requirements.in</code>.</li> <li>En CI, instala desde el lockfile, no desde las dependencias sueltas.</li> </ul>"},{"location":"docs/04_ENTORNOS/#3-mezclar-gestores-pip-conda-poetry-docker-sin-una-estrategia-clara","title":"3) Mezclar gestores (pip + Conda + Poetry + Docker) sin una estrategia clara","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Instalas algo con <code>conda install</code> y luego con <code>pip install</code> y el entorno se rompe.</li> <li>Tienes <code>environment.yml</code>, <code>requirements.txt</code> y <code>pyproject.toml</code> en el mismo proyecto sin que ninguno est\u00e9 claro.</li> <li>El contenedor Docker instala versiones diferentes a las de tu entorno local.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Lista tus archivos de configuraci\u00f3n: \u00bfhay m\u00e1s de un gestor activo a la vez?</li> <li>Revisa el <code>Dockerfile</code>: \u00bfinstala desde <code>requirements.txt</code>, desde <code>pyproject.toml</code> exportado o desde <code>environment.yml</code>?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Elige un flujo principal por proyecto:</li> <li>pip-tools \u2192 <code>requirements.in</code> \u2192 <code>requirements.txt</code> \u2192 Docker/CI.</li> <li>Poetry \u2192 <code>pyproject.toml</code> + <code>poetry.lock</code> \u2192 export a <code>requirements.txt</code> solo para Docker.</li> <li>Conda \u2192 <code>environment.yml</code>/<code>environment-lock.yml</code> \u2192 <code>conda env create</code> en todas partes.</li> <li>Documenta en este m\u00f3dulo (y en el README del proyecto) qu\u00e9 gestor es el can\u00f3nico y qu\u00e9 archivos deben editarse.</li> </ul>"},{"location":"docs/04_ENTORNOS/#4-ci-instala-un-entorno-distinto-al-local","title":"4) CI instala un entorno distinto al local","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En local todo pasa, pero en GitHub Actions los tests fallan por versiones de librer\u00edas.</li> <li>Ves que en CI se instala directamente con <code>pip install -r requirements.txt</code> pero en local usas Poetry o Conda.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Abre el workflow (<code>.github/workflows/*.yml</code>) y verifica:</li> <li>\u00bfEst\u00e1 usando la misma versi\u00f3n de Python que t\u00fa?</li> <li>\u00bfInstala dependencias desde los mismos archivos (<code>requirements.txt</code>, <code>poetry.lock</code>, <code>environment.yml</code>)?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Alinea CI con tu flujo local:</li> <li>pip-tools: usa el snippet de \"GitHub Actions con pip\" de este m\u00f3dulo.</li> <li>Poetry: usa el bloque de \"GitHub Actions con Poetry\" y cachea <code>.venv</code>.</li> <li>Conda: usa <code>conda env create -f environment.yml</code> o <code>mamba</code>.</li> <li>Haz al menos una vez la prueba de clonar en limpio y seguir los pasos de CI en tu m\u00e1quina; esto detecta diferencias.</li> </ul>"},{"location":"docs/04_ENTORNOS/#5-docker-que-no-refleja-el-entorno-real","title":"5) Docker que no refleja el entorno real","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>La aplicaci\u00f3n en Docker falla con <code>ImportError</code> o con versiones diferentes de librer\u00edas.</li> <li>Tu <code>Dockerfile</code> instala con <code>pip install pandas scikit-learn ...</code> en lugar de usar el lockfile.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el <code>Dockerfile</code> (y <code>.devcontainer/Dockerfile</code> si aplica):</li> <li>\u00bfCopia <code>requirements.txt</code> o usa <code>poetry export</code> antes de instalar?</li> <li>\u00bfEspecifica la misma versi\u00f3n de Python que usas localmente?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Haz que Docker derive de tu configuraci\u00f3n de entorno:</li> <li>Con pip-tools: <code>COPY requirements.txt</code> \u2192 <code>pip install -r requirements.txt</code>.</li> <li>Con Poetry: <code>poetry export -f requirements.txt --output requirements.txt</code> y usa eso en la imagen.</li> <li>Mant\u00e9n la versi\u00f3n de Python del contenedor alineada con tu <code>.python-version</code> / <code>pyproject.toml</code> / <code>environment.yml</code>.</li> </ul>"},{"location":"docs/04_ENTORNOS/#patron-general-de-debugging-de-entornos","title":"Patr\u00f3n general de debugging de entornos","text":"<ol> <li>Congela la versi\u00f3n de Python: pyenv, Conda o imagen base de Docker clara.</li> <li>Define un \u00fanico gestor principal (pip-tools, Poetry o Conda) y sigue su flujo.</li> <li>Aseg\u00farate de que CI y Docker consumen el mismo lockfile.</li> <li>Verifica el entorno activado antes de instalar o ejecutar (<code>which python</code>, <code>python -m pip</code>).</li> </ol> <p>Con este patr\u00f3n, \"funciona en mi m\u00e1quina\" se convierte en \"funciona en cualquier m\u00e1quina que siga estos pasos\".</p> <p></p>"},{"location":"docs/04_ENTORNOS/#48-ejercicio-practico-configura-tu-entorno","title":"4.8 Ejercicio Pr\u00e1ctico: Configura Tu Entorno","text":""},{"location":"docs/04_ENTORNOS/#opcion-a-pip-tools-recomendado-para-empezar","title":"Opci\u00f3n A: pip-tools (Recomendado para empezar)","text":"<pre><code># 1. Crear estructura\nmkdir -p bankchurn-predictor &amp;&amp; cd bankchurn-predictor\n\n# 2. Crear archivos\ncat &gt; requirements.in &lt;&lt; 'EOF'\npandas&gt;=2.0.0\nscikit-learn&gt;=1.3.0\npydantic&gt;=2.0.0\nfastapi&gt;=0.104.0\nuvicorn&gt;=0.24.0\nmlflow&gt;=2.8.0\npyyaml&gt;=6.0\njoblib&gt;=1.3.0\nEOF\n\ncat &gt; requirements-dev.in &lt;&lt; 'EOF'\n-r requirements.in\npytest&gt;=7.4.0\npytest-cov&gt;=4.1.0\nmypy&gt;=1.6.0\nruff&gt;=0.1.0\npre-commit&gt;=3.5.0\nEOF\n\n# 3. Crear entorno y lockfiles\npython3.11 -m venv .venv\nsource .venv/bin/activate\npip install pip-tools\npip-compile requirements.in\npip-compile requirements-dev.in\npip-sync requirements.txt requirements-dev.txt\n\n# 4. Verificar\npython -c \"import pandas; print(pandas.__version__)\"\n</code></pre>"},{"location":"docs/04_ENTORNOS/#opcion-b-poetry","title":"Opci\u00f3n B: Poetry","text":"<pre><code># 1. Crear proyecto\npoetry new bankchurn-predictor --src\ncd bankchurn-predictor\n\n# 2. A\u00f1adir dependencias\npoetry add pandas scikit-learn pydantic fastapi uvicorn mlflow pyyaml joblib\npoetry add --group dev pytest pytest-cov mypy ruff pre-commit\n\n# 3. Instalar\npoetry install\n\n# 4. Verificar\npoetry run python -c \"import pandas; print(pandas.__version__)\"\n</code></pre>"},{"location":"docs/04_ENTORNOS/#checklist-de-verificacion","title":"Checklist de Verificaci\u00f3n","text":"<pre><code>[ ] Entorno virtual creado y activable\n[ ] Lockfile generado con versiones exactas\n[ ] Lockfile commiteado en Git\n[ ] Puedo recrear el entorno desde cero\n[ ] CI puede instalar las mismas versiones\n</code></pre>"},{"location":"docs/04_ENTORNOS/#49-autoevaluacion","title":"4.9 Autoevaluaci\u00f3n","text":""},{"location":"docs/04_ENTORNOS/#checklist-de-competencias","title":"Checklist de Competencias","text":"<pre><code>CONCEPTOS:\n[ ] Entiendo la diferencia entre dependencias directas y transitivas\n[ ] S\u00e9 qu\u00e9 es un lockfile y por qu\u00e9 es importante\n[ ] Puedo explicar cu\u00e1ndo usar Conda vs pip vs Poetry\n\npip-tools:\n[ ] Puedo crear requirements.in con restricciones de versi\u00f3n\n[ ] S\u00e9 usar pip-compile y pip-sync\n[ ] Entiendo el formato del lockfile generado\n\nPoetry:\n[ ] Puedo crear un pyproject.toml funcional\n[ ] S\u00e9 a\u00f1adir dependencias y grupos de dependencias\n[ ] Puedo exportar a requirements.txt para Docker\n\nCI/CD:\n[ ] Puedo configurar caching de dependencias en GitHub Actions\n[ ] S\u00e9 c\u00f3mo asegurar reproducibilidad en CI\n</code></pre>"},{"location":"docs/04_ENTORNOS/#preguntas-de-reflexion","title":"Preguntas de Reflexi\u00f3n","text":"<ol> <li>\u00bfPor qu\u00e9 no basta con <code>pip install pandas</code> sin especificar versi\u00f3n?</li> <li>\u00bfCu\u00e1l es la diferencia entre <code>requirements.in</code> y <code>requirements.txt</code>?</li> <li>\u00bfCu\u00e1ndo preferir\u00edas Conda sobre Poetry?</li> <li>\u00bfPor qu\u00e9 es importante cachear dependencias en CI?</li> </ol>"},{"location":"docs/04_ENTORNOS/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>Cada proyecto del portafolio implementa la gesti\u00f3n de entornos descrita:</p>"},{"location":"docs/04_ENTORNOS/#pyprojecttoml-real","title":"pyproject.toml Real","text":"<pre><code># BankChurn-Predictor/pyproject.toml (extracto)\n[project]\nname = \"bankchurn\"\nversion = \"0.1.0\"\nrequires-python = \"&gt;=3.10\"\ndependencies = [\n    \"pandas&gt;=2.0.0\",\n    \"scikit-learn&gt;=1.3.0\",\n    \"pydantic&gt;=2.5.0\",\n    \"mlflow&gt;=2.9.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.4.0\",\n    \"pytest-cov&gt;=4.1.0\",\n    \"ruff&gt;=0.1.9\",\n]\n</code></pre>"},{"location":"docs/04_ENTORNOS/#comandos-make-del-portafolio","title":"Comandos Make del Portafolio","text":"<p>Todos los proyectos tienen Makefile con comandos consistentes:</p> <pre><code># Comandos disponibles en los 3 proyectos\nmake install     # pip install -e \".[dev]\"\nmake test        # pytest con coverage\nmake lint        # ruff check\nmake train       # Entrena el modelo\nmake serve       # Inicia API FastAPI\n</code></pre>"},{"location":"docs/04_ENTORNOS/#estructura-de-dependencias","title":"Estructura de Dependencias","text":"Proyecto Archivo Dependencias Core BankChurn <code>pyproject.toml</code> pandas, sklearn, pydantic, mlflow CarVision <code>pyproject.toml</code> pandas, sklearn, pydantic, pyyaml TelecomAI <code>pyproject.toml</code> pandas, sklearn, pydantic"},{"location":"docs/04_ENTORNOS/#ejercicio-instala-un-proyecto-real","title":"\ud83d\udd27 Ejercicio: Instala un Proyecto Real","text":"<pre><code># 1. Ve a BankChurn\ncd BankChurn-Predictor\n\n# 2. Crea entorno virtual\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# .venv\\Scripts\\activate   # Windows\n\n# 3. Instala con dependencias de desarrollo\npip install -e \".[dev]\"\n\n# 4. Verifica que funciona\npython -c \"from bankchurn.config import BankChurnConfig; print('OK')\"\nmake test\n</code></pre>"},{"location":"docs/04_ENTORNOS/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/04_ENTORNOS/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>\"\u00bfC\u00f3mo manejas dependencias?\": Explica pip-tools, Poetry, o uv. Menciona lock files y reproducibilidad.</p> </li> <li> <p>Containers vs Virtualenvs: Conoce cu\u00e1ndo usar cada uno (dev local vs producci\u00f3n).</p> </li> <li> <p>DevContainers: Menciona que usas VS Code DevContainers para entornos reproducibles.</p> </li> </ol>"},{"location":"docs/04_ENTORNOS/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Conflictos de dependencias Usa pip-compile para resolver y fijar versiones CI/CD Usa la misma imagen Docker en local y CI M\u00faltiples versiones de Python pyenv + tox para testing multi-versi\u00f3n Dependencias de sistema Documenta en Dockerfile o README"},{"location":"docs/04_ENTORNOS/#herramientas-modernas","title":"Herramientas Modernas","text":"<ul> <li>uv: Reemplazo r\u00e1pido de pip (10-100x m\u00e1s r\u00e1pido)</li> <li>pip-tools: pip-compile + pip-sync para reproducibilidad</li> <li>Poetry: Gesti\u00f3n completa de dependencias y publicaci\u00f3n</li> <li>Conda: Para dependencias cient\u00edficas complejas (CUDA, etc.)</li> </ul>"},{"location":"docs/04_ENTORNOS/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/04_ENTORNOS/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Python Virtual Environments Corey Schafer 16 min YouTube \ud83d\udd34 pip-tools for Dependency Management ArjanCodes 15 min YouTube \ud83d\udfe1 uv: The Fast Python Package Manager ArjanCodes 12 min YouTube \ud83d\udfe2 DevContainers in VS Code VS Code 10 min YouTube"},{"location":"docs/04_ENTORNOS/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 venv Documentation Gu\u00eda oficial venv \ud83d\udfe1 pip-tools Docs Documentaci\u00f3n pip-tools \ud83d\udfe2 uv Docs Reemplazo r\u00e1pido de pip"},{"location":"docs/04_ENTORNOS/#decision-tecnica-adr-012-gestion-de-dependencias","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-012 Gesti\u00f3n de Dependencias","text":"<p>Contexto: Necesitamos dependencias reproducibles y f\u00e1ciles de mantener.</p> <p>Decisi\u00f3n: Usar pip-tools (pip-compile + pip-sync) con pyproject.toml.</p> <p>Alternativas Consideradas: - Poetry: M\u00e1s completo pero m\u00e1s complejo - Conda: Mejor para deps cient\u00edficas (CUDA), peor para apps - pip directo: Sin lock file, no reproducible</p> <p>Consecuencias: - \u2705 Lock files para reproducibilidad exacta - \u2705 Compatible con pyproject.toml est\u00e1ndar - \u2705 Sin overhead de herramientas pesadas - \u274c Requiere pip-compile manual cuando actualizas</p>"},{"location":"docs/04_ENTORNOS/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/04_ENTORNOS/#ejercicio-41-entorno-virtual-completo","title":"Ejercicio 4.1: Entorno Virtual Completo","text":"<p>Objetivo: Crear y configurar entorno virtual. Dificultad: \u2b50</p> <pre><code># TU TAREA: Crear entorno, instalar proyecto en modo editable\ncd mi-proyecto\n# ???\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># 1. Crear entorno virtual\npython -m venv .venv\n\n# 2. Activar (Linux/Mac)\nsource .venv/bin/activate\n# Windows: .venv\\Scripts\\activate\n\n# 3. Actualizar pip\npip install --upgrade pip\n\n# 4. Instalar proyecto en modo editable con deps dev\npip install -e \".[dev]\"\n\n# 5. Verificar instalaci\u00f3n\npython -c \"import mymlproject; print('OK')\"\npip list | grep mymlproject\n\n# 6. Desactivar cuando termines\ndeactivate\n</code></pre>"},{"location":"docs/04_ENTORNOS/#ejercicio-42-pip-tools-workflow","title":"Ejercicio 4.2: pip-tools Workflow","text":"<p>Objetivo: Usar pip-compile para lock files. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Generar requirements.txt desde pyproject.toml\npip install pip-tools\n# ??? generar lock file\n# ??? sincronizar entorno\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># Instalar pip-tools\npip install pip-tools\n\n# Generar requirements.txt desde pyproject.toml\npip-compile pyproject.toml -o requirements.txt\n\n# Generar requirements-dev.txt con extras\npip-compile pyproject.toml --extra dev -o requirements-dev.txt\n\n# Sincronizar entorno (instala exactamente lo del lock)\npip-sync requirements.txt requirements-dev.txt\n\n# Actualizar una dependencia espec\u00edfica\npip-compile --upgrade-package pandas pyproject.toml -o requirements.txt\n\n# Makefile target recomendado:\n# requirements.txt: pyproject.toml\n#     pip-compile pyproject.toml -o requirements.txt\n# \n# sync: requirements.txt\n#     pip-sync requirements.txt requirements-dev.txt\n</code></pre>"},{"location":"docs/04_ENTORNOS/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n venv M\u00f3dulo est\u00e1ndar para crear entornos virtuales aislados pip-tools pip-compile (generar locks) + pip-sync (sincronizar entorno) lock file Archivo con versiones exactas de todas las dependencias editable install <code>pip install -e .</code> permite editar c\u00f3digo sin reinstalar   **Siguiente m\u00f3dulo** \u2192 [05. Git Profesional](05_GIT_PROFESIONAL.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/05_GIT_PROFESIONAL/","title":"M\u00d3DULO 05: GIT PROFESIONAL","text":"# \ud83c\udf3f M\u00d3DULO 05: Git Profesional  ### Control de Versiones que Impresiona en Code Review  *\"Un historial de Git limpio es la documentaci\u00f3n que nunca miente.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **4-5 horas**        | 25%                  | 75%                  |"},{"location":"docs/05_GIT_PROFESIONAL/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>Lo que lograr\u00e1s en este m\u00f3dulo</li> <li>5.1 Conventional Commits</li> <li>5.2 Pre-commit Hooks</li> <li>5.3 Estrategias de Branching</li> <li>5.4 Comandos Avanzados</li> <li>5.5 .gitignore profesional</li> <li>5.6 \ud83d\udd2c Ingenier\u00eda Inversa: Git Profesional \u2b50 NUEVO</li> <li>5.7 Ejercicio integrador</li> <li>Errores habituales</li> <li>5.7 Autoevaluaci\u00f3n</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 04_ENTORNOS (o al menos tener un entorno reproducible para correr hooks y CI).</li> <li>Poder ejecutar comandos b\u00e1sicos de terminal.</li> <li>Tener un repo Git inicializado o clonar el portafolio.</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de tocar ramas: abre Protocolo E y define tu output m\u00ednimo (ej: \u201cpre-commit + conv commits + PR limpio\u201d).</li> <li>Mientras haces PRs: si te atoras &gt;15 min (rebase, conflictos, hooks, commitlint), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para mejorar tu DX (menos fricci\u00f3n, m\u00e1s calidad autom\u00e1tica).</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Commits con Conventional Commits consistentes (sin \u201cwip\u201d, \u201cfix\u201d, \u201cfinal_final\u201d).</li> <li>[ ] Pre-commit instalado y pasando en <code>pre-commit run --all-files</code>.</li> <li>[ ] Flujo de ramas: feature branch \u2192 PR \u2192 merge a <code>main</code> (sin commits directos a <code>main</code>).</li> <li>[ ] Capacidad de recuperaci\u00f3n: poder deshacer un error usando <code>reflog</code> o <code>reset --soft</code>.</li> </ul> <p></p>"},{"location":"docs/05_GIT_PROFESIONAL/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: historial legible / prevenci\u00f3n de errores / colaboraci\u00f3n</li> <li>Archivo: <code>.pre-commit-config.yaml</code>, <code>.gitleaks.toml</code>, <code>.github/workflows/*</code>, <code>README.md</code></li> <li>Evidencia: un PR con commits limpios, hooks pasando, y revisi\u00f3n enfocada.</li> </ul> <p></p>"},{"location":"docs/05_GIT_PROFESIONAL/#lo-que-lograras-en-este-modulo","title":"\ud83c\udfaf Lo Que Lograr\u00e1s en Este M\u00f3dulo","text":"<ol> <li>Escribir commits que cuentan una historia clara</li> <li>Configurar pre-commit hooks que previenen errores</li> <li>Aplicar estrategias de branching profesionales</li> <li>Dominar comandos avanzados (rebase, cherry-pick, bisect)</li> </ol>"},{"location":"docs/05_GIT_PROFESIONAL/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<ul> <li>El repositorio <code>ML-MLOps-Portfolio</code> y los tres proyectos   (<code>BankChurn-Predictor</code>, <code>CarVision-Market-Intelligence</code>, <code>TelecomAI-Customer-Intelligence</code>)   ya usan:</li> <li>Historial basado en Conventional Commits.</li> <li>Hooks de pre-commit configurados en <code>.pre-commit-config.yaml</code>.</li> <li>Escaneo de seguridad con Gitleaks v\u00eda <code>.gitleaks.toml</code> y workflows de CI.</li> <li>Usa este m\u00f3dulo como gu\u00eda para entender y ajustar esos flujos en tu propio fork del portafolio   y para mantener un historial que soporte entrevistas t\u00e9cnicas Senior/Staff.</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#51-conventional-commits-el-estandar-de-industria","title":"5.1 Conventional Commits: El Est\u00e1ndar de Industria","text":""},{"location":"docs/05_GIT_PROFESIONAL/#por-que-importa-el-formato-del-commit","title":"\u00bfPor Qu\u00e9 Importa el Formato del Commit?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    \u274c HISTORIAL T\u00cdPICO (CA\u00d3TICO)                              \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   * fix                                                                       \u2551\n\u2551   * wip                                                                       \u2551\n\u2551   * m\u00e1s cambios                                                               \u2551\n\u2551   * asdfgh                                                                    \u2551\n\u2551   * funcionaaaa                                                               \u2551\n\u2551   * ahora s\u00ed                                                                  \u2551\n\u2551   * merge conflict resuelto                                                   \u2551\n\u2551   * updates                                                                   \u2551\n\u2551                                                                               \u2551\n\u2551   PROBLEMAS:                                                                  \u2551\n\u2551   \u2022 Imposible saber qu\u00e9 cambi\u00f3 sin leer el c\u00f3digo                             \u2551\n\u2551   \u2022 No puedes generar changelog autom\u00e1tico                                    \u2551\n\u2551   \u2022 git bisect es in\u00fatil                                                      \u2551\n\u2551   \u2022 Code review es un infierno                                                \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                    \u2705 HISTORIAL PROFESIONAL (CONVENTIONAL)                    \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   * feat(api): add /predict endpoint with batch support                       \u2551\n\u2551   * fix(training): handle NaN values in CreditScore column                    \u2551\n\u2551   * test(pipeline): add integration tests for full pipeline                   \u2551\n\u2551   * docs(readme): update installation instructions                            \u2551\n\u2551   * refactor(config): migrate from dict to Pydantic models                    \u2551\n\u2551   * ci(actions): add caching for pip dependencies                             \u2551\n\u2551   * perf(inference): reduce latency from 150ms to 45ms                        \u2551\n\u2551                                                                               \u2551\n\u2551   BENEFICIOS:                                                                 \u2551\n\u2551   \u2022 Changelog generado autom\u00e1ticamente                                        \u2551\n\u2551   \u2022 Semantic versioning autom\u00e1tico                                            \u2551\n\u2551   \u2022 git bisect encuentra bugs r\u00e1pidamente                                     \u2551\n\u2551   \u2022 Code review enfocado                                                      \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#anatomia-de-un-conventional-commit","title":"Anatom\u00eda de un Conventional Commit","text":"<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#tipos-permitidos","title":"Tipos Permitidos","text":"Tipo Cu\u00e1ndo Usar Ejemplo <code>feat</code> Nueva funcionalidad <code>feat(api): add batch prediction endpoint</code> <code>fix</code> Correcci\u00f3n de bug <code>fix(training): handle missing values in Age</code> <code>docs</code> Solo documentaci\u00f3n <code>docs(readme): add API usage examples</code> <code>style</code> Formato (no afecta l\u00f3gica) <code>style: apply ruff formatting</code> <code>refactor</code> Refactor sin cambio funcional <code>refactor(config): use Pydantic BaseSettings</code> <code>test</code> A\u00f1adir o corregir tests <code>test(inference): add unit tests for predictor</code> <code>perf</code> Mejora de performance <code>perf(pipeline): cache preprocessor transformations</code> <code>ci</code> Cambios en CI/CD <code>ci(actions): add Python 3.12 to test matrix</code> <code>build</code> Cambios en build/deps <code>build(deps): upgrade scikit-learn to 1.4.0</code> <code>chore</code> Mantenimiento general <code>chore: update .gitignore</code>"},{"location":"docs/05_GIT_PROFESIONAL/#scopes-comunes-en-mlops","title":"Scopes Comunes en MLOps","text":"<pre><code># Por componente\nfeat(training): ...\nfeat(inference): ...\nfeat(api): ...\nfeat(config): ...\nfeat(data): ...\n\n# Por capa\nfeat(model): ...\nfeat(features): ...\nfeat(pipeline): ...\n\n# Por herramienta\nci(actions): ...\nci(docker): ...\nci(dvc): ...\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#mapa-mental-de-conceptos-git-profesional","title":"\ud83e\udde0 Mapa Mental de Conceptos: Git Profesional","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551      GIT PROFESIONAL PARA ML         \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  COMMITS         \u2502              \u2502  HOOKS           \u2502              \u2502  BRANCHING       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 Conventional                   \u251c\u2500 pre-commit                    \u251c\u2500 main (protegida)\n\u251c\u2500 At\u00f3micos                       \u251c\u2500 ruff/black                    \u251c\u2500 feature/*\n\u251c\u2500 Descriptivos                   \u251c\u2500 mypy                          \u251c\u2500 fix/*\n\u2514\u2500 Scope                          \u2514\u2500 gitleaks                      \u2514\u2500 PR + Review\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo Conventional Commit Formato est\u00e1ndar de commits <code>feat(api): add endpoint</code> Scope Componente afectado <code>training</code>, <code>api</code>, <code>config</code> Pre-commit Hooks que corren antes del commit Lint, format, type check Feature branch Rama para nueva funcionalidad <code>feature/add-batch-prediction</code> Squash Combinar commits en uno Antes de merge a main"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-puente-escribir-commits-profesionales","title":"\ud83d\udcbb Ejercicio Puente: Escribir Commits Profesionales","text":"<p>Meta: Antes de trabajar en proyectos grandes, practica escribir commits correctos.</p> <p>Ejercicio 1: Convertir commits malos a buenos <pre><code>MALO: \"fix\"\nBUENO: ???\n\nMALO: \"wip\"  \nBUENO: ???\n\nMALO: \"updates\"\nBUENO: ???\n</code></pre></p> <p>Ejercicio 2: Escribir commits para estos cambios <pre><code>1. A\u00f1adiste un endpoint /health a la API\n   \u2192 ???\n\n2. Corregiste un bug donde el modelo fallaba con NaN en Age\n   \u2192 ???\n\n3. A\u00f1adiste tests para el m\u00f3dulo de predicci\u00f3n\n   \u2192 ???\n\n4. Mejoraste la latencia de inferencia de 200ms a 50ms\n   \u2192 ???\n</code></pre></p> \ud83d\udd0d Ver Soluciones  **Ejercicio 1:** <pre><code>\"fix\" \u2192 \"fix(training): handle edge case when dataset is empty\"\n\"wip\" \u2192 \"feat(api): add initial structure for batch endpoint\" (o no hacer commit a\u00fan)\n\"updates\" \u2192 \"docs(readme): update installation instructions for Python 3.11\"\n</code></pre>  **Ejercicio 2:** <pre><code>1. feat(api): add /health endpoint for liveness checks\n2. fix(training): handle NaN values in Age column\n3. test(prediction): add unit tests for ChurnPredictor class\n4. perf(inference): reduce latency from 200ms to 50ms with caching\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#practica-del-portafolio-commits-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Commits en BankChurn","text":"<p>Tarea: Revisar y mejorar el historial de commits de BankChurn.</p> <p>Paso 1: Examina el historial actual <pre><code>cd BankChurn-Predictor\ngit log --oneline -20\n</code></pre></p> <p>Paso 2: Identifica patrones <pre><code>[ ] \u00bfLos commits siguen Conventional Commits?\n[ ] \u00bfHay commits tipo \"fix\" o \"wip\" sin contexto?\n[ ] \u00bfLos scopes son consistentes?\n</code></pre></p> <p>Paso 3: Practica con un cambio real <pre><code># Haz un cambio peque\u00f1o (ej: mejorar un docstring)\ngit checkout -b fix/improve-docstring\n# ... edita un archivo ...\ngit add .\ngit commit -m \"docs(training): improve docstring for ChurnTrainer.fit()\"\n</code></pre></p> <p>Paso 4: Crea un PR (simulado o real) <pre><code>git push origin fix/improve-docstring\n# Crear PR en GitHub con descripci\u00f3n clara\n</code></pre></p>"},{"location":"docs/05_GIT_PROFESIONAL/#checkpoint-de-conocimiento-git-profesional","title":"\u2705 Checkpoint de Conocimiento: Git Profesional","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el formato correcto de Conventional Commit?</p> <p>A) <code>Added new feature for API</code> B) <code>feat(api): add batch prediction endpoint</code> C) <code>FEAT: API batch prediction</code> D) <code>[feat] api - add batch prediction</code> </p> <p>Pregunta 2: \u00bfPor qu\u00e9 es importante el scope (ej: <code>api</code>, <code>training</code>)?</p> <p>A) GitHub lo requiere B) Facilita filtrar commits por componente y entender qu\u00e9 afecta cada cambio C) Hace los commits m\u00e1s largos D) Es obligatorio para CI  </p> <p>Pregunta 3: \u00bfCu\u00e1l commit es MEJOR para un code review?</p> <p>A) <code>fix</code> B) <code>arregl\u00e9 el bug de los datos</code> C) <code>fix(data): handle missing values in Balance column by using median imputation</code> D) <code>fix bug</code> </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Tu c\u00f3digo funcionaba hace 3 d\u00edas pero hoy falla.\nEl historial de Git tiene 50 commits en esos 3 d\u00edas, todos dicen:\n  - \"updates\"\n  - \"fix\"\n  - \"wip\"\n  - \"changes\"\n\n\u00bfC\u00f3mo encontrar\u00edas el commit que introdujo el bug?\n</code></pre> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) `feat(api): add batch prediction endpoint`  **Pregunta 2**: B) Facilita filtrar commits por componente y entender qu\u00e9 afecta cada cambio.  **Pregunta 3**: C) El commit con descripci\u00f3n completa permite entender el cambio sin leer c\u00f3digo.  **Escenario de Debugging**:  - Con commits malos: Tendr\u00edas que revisar CADA commit manualmente. Pesadilla. - **Soluci\u00f3n**: Usar `git bisect` para encontrar el commit, pero con mensajes malos no sabr\u00e1s QU\u00c9 cambi\u00f3. - **Lecci\u00f3n**: Conventional Commits hacen que `git bisect` sea \u00fatil y que encuentres bugs en minutos, no horas.  <p></p>"},{"location":"docs/05_GIT_PROFESIONAL/#52-pre-commit-hooks-prevenir-errores-antes-del-commit","title":"5.2 Pre-commit Hooks: Prevenir Errores Antes del Commit","text":""},{"location":"docs/05_GIT_PROFESIONAL/#que-son-los-pre-commit-hooks","title":"\u00bfQu\u00e9 Son los Pre-commit Hooks?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         PRE-COMMIT: EL GUARDI\u00c1N                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551                        git commit -m \"feat: ...\"                              \u2551\n\u2551                                    \u2502                                          \u2551\n\u2551                                    \u25bc                                          \u2551\n\u2551                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2551\n\u2551                    \u2502      PRE-COMMIT HOOKS         \u2502                          \u2551\n\u2551                    \u2502                               \u2502                          \u2551\n\u2551                    \u2502  \u2713 Formatear c\u00f3digo (ruff)    \u2502                          \u2551\n\u2551                    \u2502  \u2713 Lint (ruff check)          \u2502                          \u2551\n\u2551                    \u2502  \u2713 Type check (mypy)          \u2502                          \u2551\n\u2551                    \u2502  \u2713 Tests r\u00e1pidos              \u2502                          \u2551\n\u2551                    \u2502  \u2713 Validar YAML/JSON          \u2502                          \u2551\n\u2551                    \u2502  \u2713 Detectar secretos          \u2502                          \u2551\n\u2551                    \u2502  \u2713 Validar commit message     \u2502                          \u2551\n\u2551                    \u2502                               \u2502                          \u2551\n\u2551                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2551\n\u2551                                   \u2502                                           \u2551\n\u2551                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                 \u2551\n\u2551                         \u25bc                   \u25bc                                 \u2551\n\u2551                    ALL PASS \u2705          ANY FAIL \u274c                          \u2551\n\u2551                    Commit OK            Commit BLOCKED                        \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#instalacion-y-setup","title":"Instalaci\u00f3n y Setup","text":"<pre><code># Instalar pre-commit\npip install pre-commit                     # Instala el framework de pre-commit hooks.\n\n# Instalar hooks en el repo\npre-commit install                         # Crea .git/hooks/pre-commit que ejecuta los hooks.\npre-commit install --hook-type commit-msg  # A\u00f1ade hook para validar mensaje de commit.\n\n# Ejecutar en todos los archivos (primera vez)\npre-commit run --all-files                 # \u00datil para verificar todo el repo de una vez.\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#pre-commit-configyaml-completo","title":".pre-commit-config.yaml Completo","text":"<pre><code># .pre-commit-config.yaml\nrepos:                                   # Lista de repositorios con hooks.\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # FORMATEO Y LINTING\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/astral-sh/ruff-pre-commit  # Ruff: linter + formatter r\u00e1pido.\n    rev: v0.1.6                          # Versi\u00f3n espec\u00edfica (inmutable).\n    hooks:\n      - id: ruff                         # Hook de linting.\n        args: [--fix, --exit-non-zero-on-fix]  # --fix: auto-corrige; falla si hubo cambios.\n      - id: ruff-format                  # Hook de formateo (reemplaza Black).\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # TYPE CHECKING\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/pre-commit/mirrors-mypy  # mypy: verificador de tipos est\u00e1tico.\n    rev: v1.7.0\n    hooks:\n      - id: mypy\n        args: [--ignore-missing-imports]  # Ignora libs sin stubs de tipos.\n        additional_dependencies:          # Deps adicionales que mypy necesita.\n          - pydantic&gt;=2.0.0              # Para entender modelos Pydantic.\n          - types-PyYAML                 # Stubs de tipos para PyYAML.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # GENERAL\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/pre-commit/pre-commit-hooks  # Hooks b\u00e1sicos oficiales.\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace          # Elimina espacios al final de l\u00edneas.\n      - id: end-of-file-fixer            # Asegura newline al final de archivos.\n      - id: check-yaml                   # Valida sintaxis YAML.\n        args: [--unsafe]                 # Para YAML con tags como !ref.\n      - id: check-json                   # Valida sintaxis JSON.\n      - id: check-toml                   # Valida sintaxis TOML.\n      - id: check-added-large-files      # Previene commits de archivos grandes.\n        args: [--maxkb=1000]             # M\u00e1ximo 1MB.\n      - id: check-merge-conflict         # Detecta marcadores de merge sin resolver.\n      - id: detect-private-key           # Detecta llaves privadas accidentales.\n      - id: no-commit-to-branch          # Bloquea commits directos a branches protegidos.\n        args: [--branch, main, --branch, master]\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # SEGURIDAD\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/Yelp/detect-secrets  # Detecta secretos (API keys, passwords).\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: [--baseline, .secrets.baseline]  # Baseline: secretos conocidos/falsos positivos.\n\n  - repo: https://github.com/PyCQA/bandit         # Bandit: an\u00e1lisis de seguridad de Python.\n    rev: 1.7.5\n    hooks:\n      - id: bandit\n        args: [-c, pyproject.toml]               # Lee config de pyproject.toml.\n        additional_dependencies: [\"bandit[toml]\"] # Soporte para leer TOML.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # CONVENTIONAL COMMITS\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/compilerla/conventional-pre-commit  # Valida formato de commits.\n    rev: v3.0.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]                     # Se ejecuta al escribir mensaje de commit.\n        args: [feat, fix, docs, style, refactor, test, perf, ci, build, chore]  # Tipos permitidos.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # JUPYTER NOTEBOOKS\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/kynan/nbstripout    # Limpia notebooks antes de commit.\n    rev: 0.6.1\n    hooks:\n      - id: nbstripout                           # Elimina outputs \u2192 reduce tama\u00f1o y conflictos.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # DOCKER\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - repo: https://github.com/hadolint/hadolint   # Hadolint: linter para Dockerfiles.\n    rev: v2.12.0\n    hooks:\n      - id: hadolint-docker\n        args: [--ignore, DL3008, --ignore, DL3013]  # Ignora warnings espec\u00edficos.\n\n# Configuraci\u00f3n global\ndefault_language_version:\n  python: python3.11                             # Versi\u00f3n de Python para todos los hooks.\n\nci:                                              # Config para pre-commit.ci (CI en la nube).\n  autofix_commit_msg: \"style: auto-fix by pre-commit hooks\"\n  autoupdate_commit_msg: \"chore: update pre-commit hooks\"\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#pyprojecttoml-seccion-bandit","title":"pyproject.toml Secci\u00f3n Bandit","text":"<pre><code># pyproject.toml\n[tool.bandit]\nexclude_dirs = [\"tests\", \"scripts\"]\nskips = [\"B101\"]  # Skip assert warnings in tests\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#comandos-pre-commit-utiles","title":"Comandos Pre-commit \u00datiles","text":"<pre><code># Ejecutar en archivos staged\npre-commit run                         # Solo verifica archivos en staging (git add).\n\n# Ejecutar en todos los archivos\npre-commit run --all-files             # Verifica TODO el repositorio.\n\n# Ejecutar hook espec\u00edfico\npre-commit run ruff --all-files        # Solo el hook \"ruff\" en todos los archivos.\npre-commit run mypy --all-files        # Solo mypy (\u00fatil para debugging).\n\n# Actualizar hooks a \u00faltimas versiones\npre-commit autoupdate                  # Actualiza rev: a las \u00faltimas versiones.\n\n# Skip hooks temporalmente (emergencia)\ngit commit --no-verify -m \"hotfix: emergency fix\"  # Ignora TODOS los hooks.\n# \u26a0\ufe0f USAR SOLO EN EMERGENCIAS - los hooks existen por una raz\u00f3n.\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#53-estrategias-de-branching","title":"5.3 Estrategias de Branching","text":""},{"location":"docs/05_GIT_PROFESIONAL/#git-flow-vs-github-flow-vs-trunk-based","title":"Git Flow vs GitHub Flow vs Trunk-Based","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         COMPARATIVA DE ESTRATEGIAS                            \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  GIT FLOW (Complejo, releases programados)                                    \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                    \u2551\n\u2551  main \u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500                             \u2551\n\u2551          \\                  / \\              /                                \u2551\n\u2551  develop  \u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf   \u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf                                 \u2551\n\u2551              \\     /                  /                                       \u2551\n\u2551  feature      \u25cf\u2500\u2500\u25cf                   /                                        \u2551\n\u2551                    \\                /                                         \u2551\n\u2551  release            \u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf                                          \u2551\n\u2551                                                                               \u2551\n\u2551  \u2705 Para: Apps con releases programados, equipos grandes                      \u2551\n\u2551  \u274c No para: MLOps (demasiado overhead), startups                             \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  GITHUB FLOW (Simple, CD continuo) \u2190 RECOMENDADO PARA MLOPS                   \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2551\n\u2551  main \u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u25cf\u2500\u2500                                     \u2551\n\u2551          \\  /      \\  /      \\  /                                             \u2551\n\u2551  feature  \u25cf         \u25cf         \u25cf                                               \u2551\n\u2551           PR       PR        PR                                               \u2551\n\u2551                                                                               \u2551\n\u2551  \u2705 Para: MLOps, CI/CD frecuente, equipos peque\u00f1os-medianos                   \u2551\n\u2551  \u2705 Simple: Solo main + feature branches                                      \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  TRUNK-BASED (Avanzado, feature flags)                                        \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                        \u2551\n\u2551  main \u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500\u25cf\u2500\u2500                                        \u2551\n\u2551         \u2502  \u2502  \u2502  \u2502  \u2502  \u2502  \u2502  \u2502  \u2502                                             \u2551\n\u2551         \u2514\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2534\u2500\u2500\u2518                                             \u2551\n\u2551         Commits directos a main (con feature flags)                           \u2551\n\u2551                                                                               \u2551\n\u2551  \u2705 Para: Equipos muy maduros, deploys m\u00faltiples/d\u00eda                          \u2551\n\u2551  \u274c No para: Equipos nuevos, sin feature flags robustos                       \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#github-flow-para-mlops-recomendado","title":"GitHub Flow para MLOps (Recomendado)","text":"<pre><code>gitGraph\n    commit id: \"initial\"\n    branch feature/add-mlflow\n    commit id: \"feat(tracking): add MLflow integration\"\n    commit id: \"test(tracking): add tests for experiment tracking\"\n    checkout main\n    merge feature/add-mlflow id: \"PR #12\"\n    branch feature/api-batch\n    commit id: \"feat(api): add batch prediction endpoint\"\n    checkout main\n    merge feature/api-batch id: \"PR #13\"\n    branch fix/nan-handling\n    commit id: \"fix(training): handle NaN in features\"\n    checkout main\n    merge fix/nan-handling id: \"PR #14\"</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#convenciones-de-naming-para-branches","title":"Convenciones de Naming para Branches","text":"<pre><code># Features\nfeature/add-mlflow-tracking\nfeature/api-batch-prediction\nfeature/JIRA-123-user-auth\n\n# Fixes\nfix/nan-handling\nfix/memory-leak-inference\nfix/JIRA-456-login-error\n\n# Refactors\nrefactor/config-pydantic\nrefactor/training-pipeline\n\n# Experiments (para ML)\nexperiment/xgboost-vs-rf\nexperiment/feature-selection\n\n# Releases (si usas Git Flow)\nrelease/1.2.0\nhotfix/1.2.1\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#54-comandos-avanzados-que-todo-senior-debe-conocer","title":"5.4 Comandos Avanzados que Todo Senior Debe Conocer","text":""},{"location":"docs/05_GIT_PROFESIONAL/#rebase-interactivo-limpiar-historial","title":"Rebase Interactivo: Limpiar Historial","text":"<pre><code># \u00daltimos 3 commits\ngit rebase -i HEAD~3\n\n# Opciones en el editor:\n# pick   = usar commit as-is\n# reword = cambiar mensaje\n# edit   = pausar para editar\n# squash = combinar con anterior\n# fixup  = combinar sin mensaje\n# drop   = eliminar commit\n\n# Ejemplo: Combinar 3 commits WIP en uno\n# pick abc123 feat(api): add endpoint\n# squash def456 wip\n# squash ghi789 fix typo\n# \u2192 Se convierten en un solo commit limpio\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#cherry-pick-traer-commits-especificos","title":"Cherry-pick: Traer Commits Espec\u00edficos","text":"<pre><code># Traer un commit de otra rama\ngit cherry-pick abc123\n\n# Traer varios commits\ngit cherry-pick abc123 def456\n\n# Traer sin commitear (para combinar)\ngit cherry-pick --no-commit abc123\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#bisect-encontrar-el-commit-que-rompio-algo","title":"Bisect: Encontrar el Commit que Rompi\u00f3 Algo","text":"<pre><code># Iniciar bisect\ngit bisect start\n\n# Marcar estado actual como malo\ngit bisect bad\n\n# Marcar un commit conocido como bueno\ngit bisect good v1.0.0\n\n# Git te lleva a un commit intermedio\n# Testear y marcar:\ngit bisect good  # Si funciona\ngit bisect bad   # Si est\u00e1 roto\n\n# Repetir hasta encontrar el commit culpable\n# Al final:\ngit bisect reset\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#stash-guardar-cambios-temporalmente","title":"Stash: Guardar Cambios Temporalmente","text":"<pre><code># Guardar cambios actuales\ngit stash\n\n# Con mensaje descriptivo\ngit stash push -m \"WIP: refactoring config\"\n\n# Listar stashes\ngit stash list\n\n# Aplicar \u00faltimo stash\ngit stash pop\n\n# Aplicar stash espec\u00edfico\ngit stash apply stash@{2}\n\n# Crear branch desde stash\ngit stash branch feature/from-stash\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#reflog-recuperar-lo-perdido","title":"Reflog: Recuperar lo \"Perdido\"","text":"<pre><code># Ver historial de operaciones\ngit reflog\n\n# Recuperar commit \"perdido\" despu\u00e9s de reset\ngit reflog\n# abc123 HEAD@{3}: commit: feat: important change\ngit checkout abc123\n# o\ngit reset --hard abc123\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#55-gitignore-profesional-para-mlops","title":"5.5 .gitignore Profesional para MLOps","text":"<pre><code># .gitignore para proyectos MLOps\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# PYTHON\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# ENTORNOS VIRTUALES\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.venv/\nvenv/\nENV/\nenv/\n.conda/\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# IDEs\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.idea/\n.vscode/\n*.swp\n*.swo\n*~\n.spyderproject\n.spyproject\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# JUPYTER NOTEBOOKS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.ipynb_checkpoints/\n*.ipynb_checkpoints/\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# DATOS Y MODELOS (gestionados por DVC)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndata/raw/*\ndata/processed/*\nmodels/*.pkl\nmodels/*.joblib\n!data/raw/.gitkeep\n!data/processed/.gitkeep\n!models/.gitkeep\n\n# DVC\n/data/*.csv\n/data/*.parquet\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# MLFLOW\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nmlruns/\nmlartifacts/\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SECRETOS Y CONFIGURACI\u00d3N LOCAL\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.env\n.env.*\n!.env.example\n*.pem\n*.key\nsecrets/\ncredentials/\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TESTING Y COVERAGE\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.coverage\n.pytest_cache/\nhtmlcov/\n.tox/\n.nox/\ncoverage.xml\n*.cover\n.hypothesis/\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BUILDS Y DOCS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nsite/\ndocs/_build/\n*.log\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# OS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n.DS_Store\nThumbs.db\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#56-ejercicio-integrador-setup-completo-de-git","title":"5.6 Ejercicio Integrador: Setup Completo de Git","text":""},{"location":"docs/05_GIT_PROFESIONAL/#paso-1-configurar-git-global","title":"Paso 1: Configurar Git Global","text":"<pre><code># Identidad\ngit config --global user.name \"Tu Nombre\"\ngit config --global user.email \"tu@email.com\"\n\n# Editor (VS Code)\ngit config --global core.editor \"code --wait\"\n\n# Alias \u00fatiles\ngit config --global alias.st \"status -sb\"\ngit config --global alias.co \"checkout\"\ngit config --global alias.br \"branch\"\ngit config --global alias.cm \"commit -m\"\ngit config --global alias.lg \"log --oneline --graph --all\"\ngit config --global alias.last \"log -1 HEAD --stat\"\ngit config --global alias.unstage \"reset HEAD --\"\n\n# Auto-setup remote tracking\ngit config --global push.autoSetupRemote true\n\n# Default branch\ngit config --global init.defaultBranch main\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#paso-2-inicializar-proyecto","title":"Paso 2: Inicializar Proyecto","text":"<pre><code># Crear repo\nmkdir bankchurn-predictor &amp;&amp; cd bankchurn-predictor\ngit init\n\n# Crear estructura\nmkdir -p src/bankchurn/{data,models,utils} tests/{unit,integration} configs docs\n\n# Archivos base\ntouch src/bankchurn/__init__.py\ntouch .gitignore .pre-commit-config.yaml pyproject.toml README.md\n\n# Primer commit\ngit add .\ngit commit -m \"chore: initial project structure\"\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#paso-3-configurar-pre-commit","title":"Paso 3: Configurar Pre-commit","text":"<pre><code># Instalar\npip install pre-commit\n\n# Copiar el .pre-commit-config.yaml de la secci\u00f3n 5.2\n\n# Instalar hooks\npre-commit install\npre-commit install --hook-type commit-msg\n\n# Ejecutar en todos los archivos\npre-commit run --all-files\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#paso-4-crear-feature-branch-y-pr","title":"Paso 4: Crear Feature Branch y PR","text":"<pre><code># Crear branch\ngit checkout -b feature/add-config\n\n# Hacer cambios...\n# Commit con conventional commits\ngit commit -m \"feat(config): add Pydantic configuration models\"\n\n# Push\ngit push -u origin feature/add-config\n\n# Crear PR en GitHub\n# (usar template de PR si existe)\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#checklist-de-verificacion","title":"Checklist de Verificaci\u00f3n","text":"<p><pre><code>CONFIGURACI\u00d3N:\n[ ] Git configurado con nombre y email\n[ ] Alias \u00fatiles configurados\n[ ] Default branch es main\n\nPRE-COMMIT:\n[ ] pre-commit instalado\n[ ] Hooks activos (commit + commit-msg)\n[ ] Todos los hooks pasan en --all-files\n\n FLUJO:\n [ ] Puedo crear feature branches correctamente\n [ ] Commits siguen Conventional Commits\n [ ] .gitignore excluye archivos correctos\n ```\n\n---\n&lt;a id=\"56-ingenieria-inversa-git\"&gt;&lt;/a&gt;\n\n## 5.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Git en el Portafolio\n\n&gt; **Objetivo**: Entender las decisiones de Git profesional en el portafolio real.\n\n### 5.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico\n</code></pre> \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502  PROBLEMA 1: \u00bfC\u00f3mo evito commits que rompen CI antes de hacer push?             \u2502 \u2502  DECISI\u00d3N: Pre-commit hooks con linting (flake8, black, isort)                  \u2502 \u2502  RESULTADO: Errores de estilo detectados localmente, no en CI                   \u2502 \u2502                                                                                 \u2502 \u2502  PROBLEMA 2: \u00bfC\u00f3mo mantengo historial legible para code review?                 \u2502 \u2502  DECISI\u00d3N: Conventional Commits (feat:, fix:, docs:, refactor:)                 \u2502 \u2502  RESULTADO: CHANGELOG auto-generado, PRs f\u00e1ciles de revisar                     \u2502 \u2502                                                                                 \u2502 \u2502  PROBLEMA 3: \u00bfC\u00f3mo evito subir secrets o archivos grandes por accidente?        \u2502 \u2502  DECISI\u00d3N: .gitignore exhaustivo + gitleaks en CI                               \u2502 \u2502  RESULTADO: Secrets bloqueados antes de llegar al repo remoto                   \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 <pre><code>### 5.6.2 \ud83d\udd0d Patr\u00f3n de Commits del Portafolio\n\n```bash\n# Ejemplos REALES de commits del portafolio:\nfeat(bankchurn): add ensemble voting classifier\nfix(api): handle missing features gracefully  \ndocs(readme): update installation instructions\nrefactor(training): extract preprocessing to separate method\ntest(integration): add leakage prevention test\nci(workflows): add drift detection schedule\n\n# Estructura: &lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n# - type: feat|fix|docs|refactor|test|ci|chore\n# - scope: proyecto o componente afectado\n# - description: imperativo, min\u00fasculas, sin punto final\n</code></pre></p>"},{"location":"docs/05_GIT_PROFESIONAL/#563-troubleshooting-preventivo","title":"5.6.3 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Soluci\u00f3n Pre-commit falla en black Formato incorrecto <code>black .</code> antes de commit gitleaks bloquea push API key en c\u00f3digo Mover a .env, a\u00f1adir a .gitignore Merge conflict en CI files Ediciones paralelas Rebase frecuente desde main"},{"location":"docs/05_GIT_PROFESIONAL/#errores-habituales-y-como-depurarlos-en-git","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en Git","text":"<p>Git aqu\u00ed no es solo \"guardar versiones\", sino soportar flujos de trabajo profesionales con branches, hooks y CI. Estos son los errores m\u00e1s frecuentes en el portafolio y c\u00f3mo atacarlos.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/05_GIT_PROFESIONAL/#1-commits-que-rompen-el-formato-conventional-commits-commitlint-pre-commit","title":"1) Commits que rompen el formato (Conventional Commits / commitlint / pre-commit)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>git commit</code> falla con mensajes como:   <pre><code>\u29d7   input: fix: arreglos varios\n\u2716   subject may not be empty [subject-empty]\n\u2716   type must be one of [feat, fix, docs, style, ...]\n</code></pre></li> <li>Hooks de <code>conventional-pre-commit</code> o <code>commitlint</code> bloquean el commit.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Mira el mensaje de error completo del hook (no solo la \u00faltima l\u00ednea).</li> <li>Abre <code>commitlint.config.js</code> o <code>.pre-commit-config.yaml</code> y revisa:</li> <li>Tipos permitidos (<code>feat</code>, <code>fix</code>, <code>docs</code>, etc.).</li> <li>Scopes permitidos, si hay regla <code>scope-enum</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta tu mensaje al formato:   <pre><code>git commit -m \"feat(api): add /predict endpoint\"\ngit commit -m \"fix(training): handle NaN in CreditScore\"\n</code></pre></li> <li>Si necesitas un scope nuevo (ej. <code>monitoring</code>), a\u00f1\u00e1delo expl\u00edcitamente a la regla de <code>scope-enum</code> y commitea ese cambio primero.</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#2-hooks-de-pre-commit-que-rompen-todo-o-tardan-demasiado","title":"2) Hooks de pre-commit que \u201crompen todo\u201d o tardan demasiado","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Hacer <code>git commit</code> tarda mucho porque corre todos los tests y linters siempre.</li> <li>No entiendes qu\u00e9 hook falla; solo ves \u201cpre-commit failed\u201d.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Ejecuta manualmente:   <pre><code>pre-commit run --all-files\n</code></pre>   y revisa qu\u00e9 hook est\u00e1 fallando (ruff, mypy, bandit, etc.).</li> <li>Abre <code>.pre-commit-config.yaml</code> y verifica qu\u00e9 rutas cubre cada hook.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Para hooks muy pesados (tests completos, mypy en todo el repo):</li> <li>Limita los paths relevantes (<code>files:</code> o <code>types:</code>) o mu\u00e9velos a CI.</li> <li>Usa <code>pre-commit autoupdate</code> si un hook da errores por versiones muy viejas.</li> <li>Solo en emergencias, puedes hacer <code>git commit --no-verify</code>, pero documenta el motivo y arregla los hooks despu\u00e9s.</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#3-ramas-desincronizadas-y-merges-sucios","title":"3) Ramas desincronizadas y merges sucios","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>git push</code> falla con <code>non-fast-forward</code>.</li> <li>Merge commits llenos de conflictos y mensajes gen\u00e9ricos.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el historial con:   <pre><code>git log --oneline --graph --all\n</code></pre>   y mira si tu rama feature est\u00e1 muy alejada de <code>main</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Mant\u00e9n tu feature branch fresca:   <pre><code>git checkout feature/mi-feature\ngit fetch origin\ngit rebase origin/main\n</code></pre></li> <li>Si el equipo prefiere <code>merge</code> sobre <code>rebase</code>, al menos haz <code>git pull --rebase</code> para evitar merges de \u201cmerge commits vac\u00edos\u201d.</li> <li>Usa PRs peque\u00f1os y frecuentes en lugar de ramas gigantes de semanas.</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#4-archivos-enormes-datos-o-secretos-en-el-historial","title":"4) Archivos enormes, datos o secretos en el historial","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El repo pesa cientos de MB; <code>git clone</code> es lento.</li> <li><code>detect-secrets</code> o <code>gitleaks</code> encuentran claves/API keys en el historial.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Ejecuta:   <pre><code>git lfs track\ngit rev-list --objects --all | sort -k 2 | tail -n 20\n</code></pre>   para ver los blobs m\u00e1s grandes.</li> <li>Corre los hooks de seguridad (<code>detect-secrets</code>, <code>gitleaks</code>) y revisa sus reportes.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>A\u00f1ade en <code>.gitignore</code> lo que no deba ir a Git (<code>data/</code>, <code>artifacts/</code>, <code>mlruns/</code>, etc.).</li> <li>Para secretos ya commiteados:</li> <li>Rota la credencial en el proveedor (AWS, GCP, etc.).</li> <li>Usa herramientas como <code>git filter-repo</code> para limpiar el historial (mencionado solo como referencia; normalmente se hace una vez y con cuidado).</li> </ul>"},{"location":"docs/05_GIT_PROFESIONAL/#5-patron-de-debugging-de-git-en-el-portafolio","title":"5) Patr\u00f3n de debugging de Git en el portafolio","text":"<ol> <li>Inspecciona el historial con <code>git log --oneline --graph --all</code>.</li> <li>Verifica configuraci\u00f3n local (<code>git config --list --show-origin</code>).</li> <li>Reproduce el problema (hook que falla, merge conflict, etc.) y lee el mensaje completo.</li> <li>Conecta el problema con el concepto del m\u00f3dulo:</li> <li>Formato de commits \u2192 Conventional Commits + commitlint.</li> <li>Calidad del c\u00f3digo \u2192 hooks de pre-commit.</li> <li>Flujo de ramas \u2192 GitHub Flow (main + feature branches).</li> <li>Aplica el patr\u00f3n de soluci\u00f3n que ya tienes documentado en este m\u00f3dulo.</li> </ol> <p>Con este enfoque, Git deja de ser \u201cmagia negra\u201d y se convierte en una herramienta predecible y aliada de tu flujo MLOps.</p> <p></p>"},{"location":"docs/05_GIT_PROFESIONAL/#57-autoevaluacion","title":"5.7 Autoevaluaci\u00f3n","text":""},{"location":"docs/05_GIT_PROFESIONAL/#preguntas-de-reflexion","title":"Preguntas de Reflexi\u00f3n","text":"<ol> <li>\u00bfPor qu\u00e9 Conventional Commits permite generar changelogs autom\u00e1ticamente?</li> <li>\u00bfCu\u00e1l es la diferencia entre <code>git rebase</code> y <code>git merge</code>?</li> <li>\u00bfCu\u00e1ndo usar\u00edas <code>git stash</code> vs crear un branch?</li> <li>\u00bfPor qu\u00e9 <code>no-commit-to-branch</code> es un hook \u00fatil?</li> </ol>"},{"location":"docs/05_GIT_PROFESIONAL/#comandos-que-debes-dominar","title":"Comandos que Debes Dominar","text":"<pre><code># B\u00e1sicos\ngit status, add, commit, push, pull\n\n# Branching\ngit branch, checkout -b, merge\n\n# Historial\ngit log --oneline --graph, diff, show\n\n# Avanzados\ngit rebase -i, cherry-pick, bisect, stash, reflog\n\n# Pre-commit\npre-commit run, --all-files, autoupdate\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El portafolio implementa todas las pr\u00e1cticas de Git profesional descritas:</p>"},{"location":"docs/05_GIT_PROFESIONAL/#pre-commit-configyaml-real","title":".pre-commit-config.yaml Real","text":"<pre><code># ML-MLOps-Portfolio/.pre-commit-config.yaml (extracto)\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n        args: ['--maxkb=5000']\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/gitleaks/gitleaks\n    rev: v8.18.1\n    hooks:\n      - id: gitleaks\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#conventional-commits-del-portafolio","title":"Conventional Commits del Portafolio","text":"<p>Ejemplos de commits reales en el historial:</p> <pre><code># Ejemplos del historial real del portafolio\nfeat(bankchurn): add unified sklearn pipeline\nfix(carvision): prevent data leakage in FeatureEngineer\ndocs(guia): add module 11 Testing ML\ntest(telecomai): increase coverage to 97%\nci(actions): add matrix testing for Python 3.10/3.11\nrefactor(config): migrate to Pydantic v2\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#branching-strategy","title":"Branching Strategy","text":"<p>El portafolio usa GitHub Flow simplificado:</p> <pre><code>main \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\n       \u2502                    \u2502\n       \u2514\u2500\u2500 feature/xyz \u2500\u2500\u2500\u2500\u2500\u2518 (PR + CI verde + merge)\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-configura-pre-commit","title":"\ud83d\udd27 Ejercicio: Configura Pre-commit","text":"<pre><code># 1. Ve a la ra\u00edz del portafolio\ncd ML-MLOps-Portfolio\n\n# 2. Instala pre-commit\npip install pre-commit\n\n# 3. Instala los hooks\npre-commit install\n\n# 4. Ejecuta en todos los archivos\npre-commit run --all-files\n\n# 5. Haz un commit y verifica que los hooks se ejecutan\necho \"# test\" &gt;&gt; test.md\ngit add test.md\ngit commit -m \"test: verify pre-commit hooks\"  # Los hooks se ejecutan aqu\u00ed\ngit reset --soft HEAD~1  # Deshaz el commit de prueba\nrm test.md\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/05_GIT_PROFESIONAL/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Conventional Commits: Explica por qu\u00e9 <code>feat:</code>, <code>fix:</code>, <code>docs:</code> facilitan changelogs autom\u00e1ticos.</p> </li> <li> <p>Git Flow vs Trunk-Based: Conoce ambos y cu\u00e1ndo usar cada uno.</p> </li> <li> <p>Rebase vs Merge: Pregunta cl\u00e1sica. Respuesta: rebase para historia limpia, merge para preservar contexto.</p> </li> </ol>"},{"location":"docs/05_GIT_PROFESIONAL/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Commits grandes Divide en commits at\u00f3micos con <code>git add -p</code> Historia sucia Usa <code>git rebase -i</code> antes de PR Secretos en repo Usa git-secrets o gitleaks en pre-commit Colaboraci\u00f3n PRs peque\u00f1os (&lt; 400 l\u00edneas) se revisan mejor"},{"location":"docs/05_GIT_PROFESIONAL/#comandos-que-debes-dominar_1","title":"Comandos que Debes Dominar","text":"<pre><code>git stash push -m \"descripci\u00f3n\"  # Guardar trabajo temporal\ngit bisect start                 # Encontrar commit que introdujo bug\ngit reflog                       # Recuperar commits \"perdidos\"\ngit cherry-pick &lt;commit&gt;         # Aplicar commit espec\u00edfico\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/05_GIT_PROFESIONAL/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Git for Professionals freeCodeCamp 40 min YouTube \ud83d\udd34 Pre-commit Hooks Tutorial ArjanCodes 15 min YouTube \ud83d\udfe1 Git Rebase vs Merge The Modern Coder 12 min YouTube"},{"location":"docs/05_GIT_PROFESIONAL/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Conventional Commits Especificaci\u00f3n oficial \ud83d\udd34 pre-commit.com Framework de hooks \ud83d\udfe1 GitHub Flow Workflow oficial"},{"location":"docs/05_GIT_PROFESIONAL/#decision-tecnica-adr-008-git-workflow","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-008 Git Workflow","text":"<p>Contexto: Necesitamos un flujo de trabajo Git consistente para el equipo.</p> <p>Decisi\u00f3n: Usar GitHub Flow + Conventional Commits + pre-commit hooks.</p> <p>Alternativas Consideradas: - Git Flow: M\u00e1s complejo, mejor para releases programados - Trunk-Based: M\u00e1s r\u00e1pido pero requiere CI muy maduro - Sin convenci\u00f3n: Historial ca\u00f3tico</p> <p>Consecuencias: - \u2705 Historial limpio y navegable - \u2705 Changelogs autom\u00e1ticos posibles - \u2705 PRs peque\u00f1os y revisables - \u274c Overhead en commits r\u00e1pidos</p>"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-51-gitignore-profesional","title":"Ejercicio 5.1: .gitignore Profesional","text":"<p>Objetivo: Configurar .gitignore completo para ML. Dificultad: \u2b50</p> <pre><code># TU TAREA: Crear .gitignore que excluya:\n# - Entornos virtuales\n# - Datos y artefactos\n# - Archivos de IDE\n# - Secretos\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># Entornos virtuales\n.venv/\nvenv/\nenv/\n.conda/\n\n# Datos y artefactos (versionados con DVC)\ndata/\nartifacts/\nmodels/\n*.csv\n*.parquet\n*.joblib\n*.pkl\n\n# MLflow y experimentos\nmlruns/\nmlartifacts/\n\n# IDE\n.idea/\n.vscode/\n*.swp\n.DS_Store\n\n# Python\n__pycache__/\n*.pyc\n*.pyo\n.pytest_cache/\n.coverage\nhtmlcov/\n*.egg-info/\ndist/\nbuild/\n\n# Secretos y configs locales\n.env\n.env.local\n*.pem\nsecrets/\n\n# Jupyter\n.ipynb_checkpoints/\n\n# Terraform\n.terraform/\n*.tfstate\n*.tfstate.*\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-52-pre-commit-hooks","title":"Ejercicio 5.2: pre-commit Hooks","text":"<p>Objetivo: Configurar hooks de calidad autom\u00e1tica. Dificultad: \u2b50\u2b50</p> <pre><code># .pre-commit-config.yaml\n# TU TAREA: Configurar hooks para:\n# - Formateo (ruff)\n# - Linting (ruff)\n# - Type checking (mypy)\n# - Secretos (detect-secrets)\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># .pre-commit-config.yaml\nrepos:\n  # Hooks b\u00e1sicos\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n\n  # Ruff: linting + formatting\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  # Type checking\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-PyYAML, pandas-stubs]\n        args: [--ignore-missing-imports]\n\n  # Detectar secretos\n  - repo: https://github.com/Yelp/detect-secrets\n    rev: v1.4.0\n    hooks:\n      - id: detect-secrets\n        args: ['--baseline', '.secrets.baseline']\n\n  # Conventional commits\n  - repo: https://github.com/compilerla/conventional-pre-commit\n    rev: v3.0.0\n    hooks:\n      - id: conventional-pre-commit\n        stages: [commit-msg]\n\n# Instalar:\n# pip install pre-commit\n# pre-commit install\n# pre-commit install --hook-type commit-msg\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-53-conventional-commits","title":"Ejercicio 5.3: Conventional Commits","text":"<p>Objetivo: Escribir commits con formato est\u00e1ndar. Dificultad: \u2b50</p> <pre><code># Clasifica estos cambios con el tipo correcto:\n# 1. A\u00f1adir endpoint /predict\n# 2. Corregir bug en preprocesamiento\n# 3. Actualizar README\n# 4. Refactorizar funci\u00f3n train()\n# 5. A\u00f1adir tests de integraci\u00f3n\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># 1. Nueva funcionalidad\ngit commit -m \"feat(api): add /predict endpoint with Pydantic validation\"\n\n# 2. Correcci\u00f3n de bug\ngit commit -m \"fix(data): handle missing values in preprocessing step\"\n\n# 3. Documentaci\u00f3n\ngit commit -m \"docs: update README with quick start guide\"\n\n# 4. Refactoring (sin cambio de comportamiento)\ngit commit -m \"refactor(training): extract feature engineering to separate function\"\n\n# 5. Tests\ngit commit -m \"test(integration): add API endpoint tests with pytest\"\n\n# Otros tipos comunes:\n# chore: tareas de mantenimiento (deps, configs)\n# ci: cambios en CI/CD\n# perf: mejoras de rendimiento\n# style: formateo, sin cambio de c\u00f3digo\n</code></pre>"},{"location":"docs/05_GIT_PROFESIONAL/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n pre-commit Framework para ejecutar hooks autom\u00e1ticos antes de cada commit Conventional Commits Especificaci\u00f3n de formato de mensajes: <code>type(scope): description</code> GitHub Flow Workflow simple: main + feature branches + PRs rebase Reescribir historia para aplicar commits sobre otra base"},{"location":"docs/05_GIT_PROFESIONAL/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/05_GIT_PROFESIONAL/#trampa-1-import-que-funciona-en-notebook-pero-no-en-pytest","title":"Trampa 1: Import que funciona en notebook pero no en pytest","text":"<p>S\u00edntoma: <pre><code># En notebook funciona:\nfrom bankchurn.training import train  # \u2705\n\n# En pytest:\n# ModuleNotFoundError: No module named 'bankchurn'\n</code></pre></p> <p>Causa ra\u00edz: El notebook tiene el directorio actual en <code>sys.path</code>. pytest no.</p> <p>Soluci\u00f3n: <pre><code># Instalar paquete en modo editable\npip install -e \".[dev]\"\n\n# Ahora pytest encuentra el m\u00f3dulo\npytest tests/ -v  # \u2705\n</code></pre></p> <p>Prevenci\u00f3n: Siempre usar <code>src/</code> layout y <code>pip install -e .</code> antes de desarrollar.</p>"},{"location":"docs/05_GIT_PROFESIONAL/#trampa-2-gitignore-incompleto-expone-secretos","title":"Trampa 2: .gitignore incompleto expone secretos","text":"<p>S\u00edntoma: <pre><code>git add .\ngit commit -m \"add config\"\n# Oops, .env con API keys est\u00e1 en el commit\n</code></pre></p> <p>Soluci\u00f3n inmediata (si ya commiteaste): <pre><code># 1. Remover del historial (PELIGROSO, requiere force push)\ngit filter-branch --force --index-filter \\\n  \"git rm --cached --ignore-unmatch .env\" HEAD\n\n# 2. Rotar TODAS las credenciales expuestas (no hay vuelta atr\u00e1s)\n</code></pre></p> <p>Prevenci\u00f3n: <pre><code># .gitignore robusto\n.env\n.env.*\n*.pem\n*.key\nsecrets/\ncredentials/\n</code></pre></p>"},{"location":"docs/05_GIT_PROFESIONAL/#trampa-3-pre-commit-hook-que-no-se-ejecuta","title":"Trampa 3: Pre-commit hook que no se ejecuta","text":"<p>S\u00edntoma: <pre><code>git commit -m \"feat: add feature\"\n# Commit pasa, pero c\u00f3digo tiene errores de lint\n</code></pre></p> <p>Causa ra\u00edz: pre-commit no est\u00e1 instalado en este repo.</p> <p>Soluci\u00f3n: <pre><code># Instalar los hooks en el repo actual\npre-commit install\n\n# Verificar que est\u00e1 activo\nls .git/hooks/pre-commit  # Debe existir\n\n# Ejecutar manualmente para probar\npre-commit run --all-files\n</code></pre></p>"},{"location":"docs/05_GIT_PROFESIONAL/#quiz-del-modulo-semana-4","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semana 4","text":""},{"location":"docs/05_GIT_PROFESIONAL/#quiz-semana-4-git-profesional-estructura-de-proyecto","title":"Quiz Semana 4: Git Profesional + Estructura de Proyecto","text":""},{"location":"docs/05_GIT_PROFESIONAL/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfPor qu\u00e9 es importante el \"src/ layout\" en proyectos Python?</p> \u2705 Respuesta  **3 razones principales**:  1. **Fuerza `pip install -e .`**: No puedes importar sin instalar, evitando \"funciona en mi m\u00e1quina\" 2. **Evita conflictos de imports**: El paquete est\u00e1 aislado en `src/` 3. **Separa c\u00f3digo de configuraci\u00f3n**: Tests, configs y docs est\u00e1n fuera de `src/`"},{"location":"docs/05_GIT_PROFESIONAL/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfQu\u00e9 problema resuelven los Conventional Commits?</p> \u2705 Respuesta  1. **Historial legible**: `git log` tiene estructura predecible 2. **Changelogs autom\u00e1ticos**: Herramientas extraen cambios por tipo 3. **Versionado sem\u00e1ntico**: `feat` \u2192 minor, `fix` \u2192 patch, `BREAKING CHANGE` \u2192 major  **Formato**: `(): `"},{"location":"docs/05_GIT_PROFESIONAL/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfPor qu\u00e9 pre-commit debe ejecutarse ANTES del commit, no despu\u00e9s?</p> \u2705 Respuesta  1. **Evita commits rotos**: Si el check falla despu\u00e9s, el commit malo ya est\u00e1 en el historial 2. **Ahorra tiempo de CI**: Problemas se detectan localmente 3. **Feedback inmediato**: Ves el error mientras tienes el contexto fresco"},{"location":"docs/05_GIT_PROFESIONAL/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Configura un <code>.pre-commit-config.yaml</code> que incluya: 1. Verificar archivos YAML v\u00e1lidos 2. Trailing whitespace removal 3. ruff para linting 4. mypy para type checking</p> \u2705 Soluci\u00f3n <pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: check-yaml\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.6\n    hooks:\n      - id: ruff\n        args: [--fix, --exit-non-zero-on-fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.7.0\n    hooks:\n      - id: mypy\n        args: [--ignore-missing-imports]\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [06. Versionado de Datos](06_VERSIONADO_DATOS.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/06_VERSIONADO_DATOS/","title":"M\u00d3DULO 06: INGENIER\u00cdA DE DATOS Y DVC","text":"# \ud83d\udcca M\u00d3DULO 06: Ingenier\u00eda de Datos y DVC  ### El Arte de Versionar lo que Git No Puede  *\"Si no puedo recrear tus datos, no puedo reproducir tu modelo.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **5-6 horas**        | 30%                  | 70%                  |"},{"location":"docs/06_VERSIONADO_DATOS/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 05_GIT_PROFESIONAL (ramas limpias, PRs, <code>.gitignore</code>).</li> <li>Entender que Git NO est\u00e1 hecho para datasets grandes.</li> <li>Tener acceso (o plan) para un remote de DVC (local, GDrive, S3/GCS/Azure).</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de correr comandos: abre Protocolo E y define tu output m\u00ednimo (ej: \u201c<code>dvc.yaml</code> + <code>params.yaml</code> + repro reproducible\u201d).</li> <li>Mientras integras DVC: si te atoras &gt;15 min (remotes, credenciales, <code>dvc repro</code>, <code>dvc checkout</code>), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir qu\u00e9 mejorar (reproducibilidad, estructura del pipeline, naming de stages).</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Datos trackeados por DVC (no en Git), con <code>.dvc/</code> y/o archivos <code>.dvc</code> en el repo.</li> <li>[ ] Remote configurado y flujo b\u00e1sico funcionando: <code>dvc push</code> / <code>dvc pull</code>.</li> <li>[ ] Pipeline reproducible con <code>dvc.yaml</code> + <code>params.yaml</code> y <code>dvc repro</code>.</li> <li>[ ] Evidencia: poder recrear resultados al hacer <code>git checkout &lt;tag&gt;</code> + <code>dvc checkout</code> + <code>dvc pull</code>.</li> </ul> <p></p>"},{"location":"docs/06_VERSIONADO_DATOS/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: versionado de datos / DAG / reproducibilidad</li> <li>Archivo: <code>dvc.yaml</code>, <code>params.yaml</code>, <code>.dvc/config</code>, <code>data/**.dvc</code>, <code>metrics/*.json</code></li> <li>Comandos: <code>dvc status</code>, <code>dvc dag</code>, <code>dvc repro</code>, <code>dvc push</code>, <code>dvc pull</code>, <code>dvc checkout</code></li> <li>Evidencia: resultados reproducibles cuando cambias de commit/tag.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>ADR de Inicio</li> <li>6.1 El Problema</li> <li>6.2 Configuraci\u00f3n Inicial</li> <li>6.3 Versionado B\u00e1sico</li> <li>6.4 Pipelines con dvc.yaml</li> <li>6.5 M\u00e9tricas y Experimentos</li> <li>6.6 \ud83d\udd2c Ingenier\u00eda Inversa: DVC Pipeline Real \u2b50 NUEVO</li> <li>Errores habituales</li> <li>6.7 Ejercicio Integrador</li> <li>6.8 Autoevaluaci\u00f3n</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#adr-de-inicio-cuando-no-usar-dvc","title":"\ud83c\udfaf ADR de Inicio: \u00bfCu\u00e1ndo (NO) Usar DVC?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  ADR-006: Criterios para Usar DVC                                             \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  \u2705 USA DVC SI:                                                               \u2551\n\u2551  \u2022 Datos &gt; 100MB que no caben c\u00f3modamente en Git                              \u2551\n\u2551  \u2022 Necesitas reproducibilidad exacta de datasets                              \u2551\n\u2551  \u2022 Equipo colabora en el mismo pipeline de datos                              \u2551\n\u2551  \u2022 Quieres DAGs declarativos para pipelines                                   \u2551\n\u2551  \u2022 Datos son batch (no streaming)                                             \u2551\n\u2551                                                                               \u2551\n\u2551  \u274c NO USES DVC SI:                                                           \u2551\n\u2551  \u2022 Datos &lt; 50MB y no cambian frecuentemente \u2192 Git LFS o Git directo           \u2551\n\u2551  \u2022 Datos son streaming (Kafka, Kinesis) \u2192 No aplica versionado batch          \u2551\n\u2551  \u2022 Ya tienes Data Lake con Delta Lake/Iceberg \u2192 Usar versionado nativo        \u2551\n\u2551  \u2022 Solo 1 persona trabaja en el proyecto \u2192 Puede ser overkill                 \u2551\n\u2551  \u2022 Pipeline ya est\u00e1 en Airflow/Prefect \u2192 Evitar duplicaci\u00f3n                   \u2551\n\u2551                                                                               \u2551\n\u2551  DECISI\u00d3N PARA BANKCHURN:                                                     \u2551\n\u2551  Usar DVC porque: datos ~50MB con potencial de crecer, equipo colabora,       \u2551\n\u2551  queremos reproducibilidad completa, y el pipeline es batch.                  \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#lo-que-lograras-en-este-modulo","title":"Lo Que Lograr\u00e1s en Este M\u00f3dulo","text":"<ol> <li>Entender el problema del versionado de datos en ML</li> <li>Configurar DVC con remote storage</li> <li>Crear pipelines reproducibles con <code>dvc.yaml</code></li> <li>Dise\u00f1ar DAGs para proyectos complejos</li> </ol>"},{"location":"docs/06_VERSIONADO_DATOS/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<ul> <li>En <code>BankChurn-Predictor/</code> ya tienes configurado DVC con:</li> <li><code>dvc.yaml</code> y <code>params.yaml</code> en la ra\u00edz del proyecto.</li> <li>Carpeta <code>data/</code> con datasets y <code>.dvc/</code> con metadatos de versionado.</li> <li>Desde esa carpeta puedes practicar el flujo completo de este m\u00f3dulo ejecutando:   <pre><code>cd BankChurn-Predictor\ndvc status\ndvc repro\ndvc pull\n</code></pre></li> <li>Aplica los mismos principios a futuros proyectos del portafolio para mantener datos y   pipelines de forma reproducible, especialmente cuando crees el proyecto integrador.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#61-el-problema-git-no-escala-para-datos","title":"6.1 El Problema: Git No Escala para Datos","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    \ud83d\ude31 EL INFIERNO DEL VERSIONADO DE DATOS                     \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   SIN VERSIONADO:                                                             \u2551\n\u2551                                                                               \u2551\n\u2551   data/                                                                       \u2551\n\u2551   \u251c\u2500\u2500 churn.csv                   # \u00bfOriginal o procesado?                    \u2551\n\u2551   \u251c\u2500\u2500 churn_v2.csv                # \u00bfQu\u00e9 cambi\u00f3?                              \u2551\n\u2551   \u251c\u2500\u2500 churn_final.csv             # \u00bfEs realmente el final?                   \u2551\n\u2551   \u251c\u2500\u2500 churn_final_v2.csv          # \ud83d\ude31                                        \u2551\n\u2551   \u251c\u2500\u2500 churn_final_FINAL.csv       # \ud83d\udc80                                        \u2551\n\u2551   \u2514\u2500\u2500 churn_20231115_backup.csv   # ???                                       \u2551\n\u2551                                                                               \u2551\n\u2551   PROBLEMAS:                                                                  \u2551\n\u2551   \u2022 No s\u00e9 qu\u00e9 datos us\u00f3 el modelo v1.2.3                                      \u2551\n\u2551   \u2022 No puedo reproducir resultados de hace 2 meses                            \u2551\n\u2551   \u2022 Git se rompe con archivos grandes                                         \u2551\n\u2551   \u2022 Colaboraci\u00f3n es imposible (\"\u00bftienes el CSV actualizado?\")                 \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   CON DVC:                                                                    \u2551\n\u2551                                                                               \u2551\n\u2551   data/                                                                       \u2551\n\u2551   \u2514\u2500\u2500 raw/                                                                    \u2551\n\u2551       \u2514\u2500\u2500 churn.csv.dvc     # Metadatos en Git, datos en storage              \u2551\n\u2551                                                                               \u2551\n\u2551   git checkout v1.2.3 &amp;&amp; dvc checkout                                         \u2551\n\u2551   \u2192 Tengo EXACTAMENTE los datos de esa versi\u00f3n                                \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#comparativa-de-soluciones","title":"Comparativa de Soluciones","text":"Soluci\u00f3n Tama\u00f1o M\u00e1x Versionado Pipelines Costo Complejidad Git directo ~10MB \u2705 \u274c Gratis Baja Git LFS ~2GB \u2705 \u274c $$$ Baja DVC Ilimitado \u2705 \u2705 Storage Media Delta Lake Ilimitado \u2705 \u274c Spark Alta LakeFS Ilimitado \u2705 \u274c Server Alta"},{"location":"docs/06_VERSIONADO_DATOS/#mapa-mental-de-conceptos-dvc-y-versionado-de-datos","title":"\ud83e\udde0 Mapa Mental de Conceptos: DVC y Versionado de Datos","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551   DVC: DATA VERSION CONTROL          \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  VERSIONADO      \u2502              \u2502  PIPELINES       \u2502              \u2502  REMOTES         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 data/*.dvc                     \u251c\u2500 dvc.yaml                      \u251c\u2500 S3\n\u251c\u2500 .dvc/ (metadatos)              \u251c\u2500 params.yaml                   \u251c\u2500 GCS\n\u251c\u2500 dvc add                        \u251c\u2500 dvc repro                     \u251c\u2500 Azure\n\u251c\u2500 dvc checkout                   \u251c\u2500 dvc dag                       \u251c\u2500 GDrive\n\u2514\u2500 dvc push/pull                  \u2514\u2500 stages                        \u2514\u2500 Local\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Comando dvc add Trackear archivo/carpeta con DVC <code>dvc add data/raw/churn.csv</code> dvc.yaml Pipeline declarativo (DAG) Define stages y dependencias params.yaml Par\u00e1metros del pipeline Hiperpar\u00e1metros, configs dvc repro Ejecutar pipeline reproducible Solo re-ejecuta lo que cambi\u00f3 Remote Storage externo para datos S3, GCS, GDrive, local .dvc file Metadatos del archivo trackeado Hash MD5, tama\u00f1o"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-puente-dvc-basico","title":"\ud83d\udcbb Ejercicio Puente: DVC B\u00e1sico","text":"<p>Meta: Antes de crear pipelines complejos, domina el versionado b\u00e1sico.</p> <p>Ejercicio 1: Inicializar DVC <pre><code># TU TAREA: En un proyecto nuevo\nmkdir my-dvc-project &amp;&amp; cd my-dvc-project\ngit init\ndvc init\n\n# \u00bfQu\u00e9 archivos cre\u00f3 dvc init?\nls -la .dvc/\n</code></pre></p> <p>Ejercicio 2: Trackear un archivo <pre><code># Crea un CSV de prueba\necho \"id,value\" &gt; data.csv\necho \"1,100\" &gt;&gt; data.csv\n\n# TU TAREA: Trackea con DVC\ndvc add data.csv\n\n# \u00bfQu\u00e9 archivos se crearon?\nls -la data.csv*\ncat data.csv.dvc\n</code></pre></p> <p>Ejercicio 3: Simular cambio de versi\u00f3n <pre><code># Commit versi\u00f3n 1\ngit add data.csv.dvc .gitignore\ngit commit -m \"data: add initial dataset v1\"\n\n# Modifica el archivo\necho \"2,200\" &gt;&gt; data.csv\ndvc add data.csv\ngit add data.csv.dvc\ngit commit -m \"data: add new row to dataset v2\"\n\n# TU TAREA: Vuelve a la versi\u00f3n 1\ngit checkout HEAD~1 -- data.csv.dvc\ndvc checkout\ncat data.csv  # \u00bfQu\u00e9 versi\u00f3n tienes?\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code># Ejercicio 1: dvc init crea:\n# .dvc/\n# \u251c\u2500\u2500 .gitignore\n# \u2514\u2500\u2500 config\n\n# Ejercicio 2: dvc add crea:\n# data.csv.dvc  (metadatos con hash MD5)\n# Adem\u00e1s a\u00f1ade \"data.csv\" a .gitignore\n\n# data.csv.dvc contiene algo como:\n# outs:\n# - md5: abc123...\n#   size: 20\n#   hash: md5\n#   path: data.csv\n\n# Ejercicio 3: Despu\u00e9s de checkout\n# Tienes la versi\u00f3n 1 (solo 1 fila de datos)\n# Porque Git restaur\u00f3 el .dvc con el hash antiguo\n# Y dvc checkout descarg\u00f3 esa versi\u00f3n del cache\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#practica-del-portafolio-dvc-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: DVC en BankChurn","text":"<p>Tarea: Explorar y entender la configuraci\u00f3n DVC de BankChurn-Predictor.</p> <p>Paso 1: Examina la estructura <pre><code>cd BankChurn-Predictor\nls -la .dvc/\ncat .dvc/config\nls -la data/\n</code></pre></p> <p>Paso 2: Entiende el pipeline <pre><code># Ver el DAG visual\ndvc dag\n\n# Ver el pipeline completo\ncat dvc.yaml\n\n# Ver los par\u00e1metros\ncat params.yaml\n</code></pre></p> <p>Paso 3: Reproduce el pipeline <pre><code># Ver qu\u00e9 est\u00e1 desactualizado\ndvc status\n\n# Ejecutar pipeline completo\ndvc repro\n\n# \u00bfQu\u00e9 stages se ejecutaron?\n</code></pre></p> <p>Paso 4: Simula un experimento <pre><code># Cambia un par\u00e1metro en params.yaml\n# ej: test_size: 0.3 \u2192 test_size: 0.2\n\n# \u00bfQu\u00e9 stages necesitan re-ejecutarse?\ndvc status\n\n# Ejecuta\ndvc repro\n</code></pre></p>"},{"location":"docs/06_VERSIONADO_DATOS/#checkpoint-de-conocimiento-dvc","title":"\u2705 Checkpoint de Conocimiento: DVC","text":"<p>Pregunta 1: \u00bfQu\u00e9 guarda Git cuando usas DVC para datos?</p> <p>A) El archivo de datos completo B) Solo el archivo .dvc con metadatos (hash MD5) C) Una copia comprimida D) Nada, DVC reemplaza a Git  </p> <p>Pregunta 2: \u00bfCu\u00e1l es la ventaja de <code>dvc repro</code> sobre correr scripts manualmente?</p> <p>A) Es m\u00e1s r\u00e1pido B) Solo re-ejecuta stages cuyas dependencias cambiaron C) Usa menos memoria D) Es m\u00e1s f\u00e1cil de escribir  </p> <p>Pregunta 3: Si haces <code>git checkout v1.0.0</code> pero NO haces <code>dvc checkout</code>, \u00bfqu\u00e9 pasa?</p> <p>A) Tienes c\u00f3digo v1.0.0 pero datos de la versi\u00f3n actual (inconsistente) B) Todo funciona autom\u00e1ticamente C) Git falla D) DVC borra los datos  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code>Situaci\u00f3n: Ejecutas dvc repro y obtienes:\n  ERROR: failed to reproduce 'train': \n  Could not find data/raw/churn.csv\n\nPero el archivo .dvc existe: data/raw/churn.csv.dvc\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Solo el archivo .dvc con metadatos. Los datos reales van al remote storage.  **Pregunta 2**: B) Solo re-ejecuta stages cuyas dependencias cambiaron. Ahorra tiempo y recursos.  **Pregunta 3**: A) Tienes c\u00f3digo v1.0.0 pero datos de la versi\u00f3n actual. SIEMPRE haz `dvc checkout` despu\u00e9s de `git checkout`.  **Escenario de Debugging**:  - **Problema**: El archivo `.dvc` existe, pero los datos reales no est\u00e1n descargados. - **Soluci\u00f3n**:  <pre><code>dvc pull  # Descarga los datos del remote\n# O si no hay remote configurado:\ndvc checkout  # Restaura desde cache local\n</code></pre> - **Prevenci\u00f3n**: Despu\u00e9s de `git clone` siempre ejecuta `dvc pull`.  <p></p>"},{"location":"docs/06_VERSIONADO_DATOS/#62-configuracion-inicial-de-dvc","title":"6.2 Configuraci\u00f3n Inicial de DVC","text":""},{"location":"docs/06_VERSIONADO_DATOS/#instalacion","title":"Instalaci\u00f3n","text":"<pre><code># Con pip\npip install dvc\n\n# Con extras para storage\npip install \"dvc[s3]\"      # Amazon S3\npip install \"dvc[gs]\"      # Google Cloud Storage\npip install \"dvc[azure]\"   # Azure Blob Storage\npip install \"dvc[gdrive]\"  # Google Drive (para proyectos personales)\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#inicializacion","title":"Inicializaci\u00f3n","text":"<pre><code># En un repo Git existente\ncd bankchurn-predictor           # Navega al proyecto (debe ser repo Git).\ndvc init                         # Inicializa DVC en el repositorio.\n\n# Esto crea:\n# .dvc/           - Directorio de configuraci\u00f3n de DVC (como .git para Git).\n# .dvc/.gitignore - Ignora cache local de DVC.\n# .dvc/config     - Configuraci\u00f3n de remotes y opciones.\n# .dvcignore      - Archivos/carpetas que DVC debe ignorar.\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#configurar-remote-storage","title":"Configurar Remote Storage","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# OPCI\u00d3N 1: Local (para desarrollo)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndvc remote add -d localremote /path/to/dvc-storage  # Crea remote llamado \"localremote\".\n# -d = default remote: este remote se usa por defecto en push/pull.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# OPCI\u00d3N 2: Amazon S3\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndvc remote add -d s3remote s3://my-bucket/dvc-storage  # s3://bucket/path formato S3.\ndvc remote modify s3remote region us-east-1            # Configura regi\u00f3n del bucket.\n# Credenciales: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY en variables de entorno.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# OPCI\u00d3N 3: Google Cloud Storage\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndvc remote add -d gcsremote gs://my-bucket/dvc-storage  # gs://bucket/path formato GCS.\n# Credenciales: GOOGLE_APPLICATION_CREDENTIALS apunta a JSON de service account.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# OPCI\u00d3N 4: Google Drive (Gratis, bueno para proyectos personales)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndvc remote add -d gdriveremote gdrive://folder-id      # folder-id: ID de carpeta en Drive.\n# La primera vez pedir\u00e1 autenticaci\u00f3n OAuth en el browser.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Ver configuraci\u00f3n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ncat .dvc/config                                        # Muestra configuraci\u00f3n actual.\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#estructura-de-directorios-recomendada","title":"Estructura de Directorios Recomendada","text":"<pre><code>bankchurn-predictor/\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/                    # Datos originales (DVC tracked)\n\u2502   \u2502   \u251c\u2500\u2500 .gitkeep\n\u2502   \u2502   \u2514\u2500\u2500 churn.csv          # \u2192 churn.csv.dvc en Git\n\u2502   \u251c\u2500\u2500 processed/             # Datos procesados (output de pipeline)\n\u2502   \u2502   \u2514\u2500\u2500 .gitkeep\n\u2502   \u2514\u2500\u2500 external/              # Datos de terceros\n\u2502       \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 models/                    # Modelos entrenados (DVC tracked)\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 .dvc/\n\u2502   \u2514\u2500\u2500 config\n\u251c\u2500\u2500 .dvcignore\n\u2514\u2500\u2500 dvc.yaml                   # Pipeline definition\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#63-versionado-basico-de-archivos","title":"6.3 Versionado B\u00e1sico de Archivos","text":""},{"location":"docs/06_VERSIONADO_DATOS/#anadir-datos-a-dvc","title":"A\u00f1adir Datos a DVC","text":"<pre><code># A\u00f1adir archivo\ndvc add data/raw/churn.csv\n\n# Esto crea:\n# data/raw/churn.csv.dvc   - Metadatos (hash, size)\n# data/raw/.gitignore      - Ignora el CSV en Git\n\n# Ver contenido del .dvc\ncat data/raw/churn.csv.dvc\n</code></pre> <pre><code># data/raw/churn.csv.dvc\nouts:\n- md5: abc123def456...\n  size: 52428800\n  hash: md5\n  path: churn.csv\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#flujo-de-trabajo","title":"Flujo de Trabajo","text":"<pre><code># 1. Modificar datos\n# ... (actualizar churn.csv con nuevos registros)\n\n# 2. Actualizar tracking\ndvc add data/raw/churn.csv\n\n# 3. Commit ambos cambios\ngit add data/raw/churn.csv.dvc data/raw/.gitignore\ngit commit -m \"data(raw): update churn dataset with Q4 2024 data\"\n\n# 4. Push datos a remote\ndvc push\n\n# 5. Push c\u00f3digo a Git\ngit push\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#recuperar-datos-de-version-anterior","title":"Recuperar Datos de Versi\u00f3n Anterior","text":"<pre><code># Ver versiones del archivo\ngit log data/raw/churn.csv.dvc\n\n# Checkout versi\u00f3n espec\u00edfica\ngit checkout v1.0.0 -- data/raw/churn.csv.dvc\ndvc checkout data/raw/churn.csv\n\n# O m\u00e1s simple: checkout todo\ngit checkout v1.0.0\ndvc checkout\n# \u2192 Ahora tienes c\u00f3digo Y datos de v1.0.0\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#64-pipelines-con-dvcyaml-el-poder-real","title":"6.4 Pipelines con dvc.yaml (El Poder Real)","text":""},{"location":"docs/06_VERSIONADO_DATOS/#por-que-pipelines","title":"\u00bfPor Qu\u00e9 Pipelines?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         PIPELINES DVC: REPRODUCIBILIDAD                       \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   SIN PIPELINE:                                                               \u2551\n\u2551   \"Para reproducir, ejecuta preprocess.py, luego train.py, luego...\"          \u2551\n\u2551   \"Ah, pero primero aseg\u00farate de tener los datos correctos...\"                \u2551\n\u2551   \"Y usa los mismos hiperpar\u00e1metros que est\u00e1n en... alg\u00fan lugar...\"           \u2551\n\u2551                                                                               \u2551\n\u2551   CON PIPELINE DVC:                                                           \u2551\n\u2551   $ dvc repro                                                                 \u2551\n\u2551   \u2192 Ejecuta TODO autom\u00e1ticamente, en orden correcto,                          \u2551\n\u2551     saltando stages que no cambiaron.                                         \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#dvcyaml-completo-para-bankchurn","title":"dvc.yaml Completo para BankChurn","text":"<pre><code># dvc.yaml\nstages:\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # STAGE 1: Preparaci\u00f3n de Datos\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  prepare:\n    cmd: python src/bankchurn/data/prepare.py\n    deps:\n      - src/bankchurn/data/prepare.py\n      - data/raw/churn.csv\n      - configs/config.yaml\n    params:\n      - prepare.test_size\n      - prepare.random_state\n    outs:\n      - data/processed/train.csv\n      - data/processed/test.csv\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # STAGE 2: Feature Engineering\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  featurize:\n    cmd: python src/bankchurn/features/build.py\n    deps:\n      - src/bankchurn/features/build.py\n      - data/processed/train.csv\n      - data/processed/test.csv\n      - configs/config.yaml\n    params:\n      - features.numerical\n      - features.categorical\n    outs:\n      - data/processed/train_features.pkl\n      - data/processed/test_features.pkl\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # STAGE 3: Entrenamiento\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  train:\n    cmd: python src/bankchurn/training.py\n    deps:\n      - src/bankchurn/training.py\n      - data/processed/train_features.pkl\n      - configs/config.yaml\n    params:\n      - train.n_estimators\n      - train.max_depth\n      - train.random_state\n    outs:\n      - models/pipeline.pkl\n    metrics:\n      - metrics/train_metrics.json:\n          cache: false\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # STAGE 4: Evaluaci\u00f3n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  evaluate:\n    cmd: python src/bankchurn/evaluate.py\n    deps:\n      - src/bankchurn/evaluate.py\n      - models/pipeline.pkl\n      - data/processed/test_features.pkl\n    metrics:\n      - metrics/eval_metrics.json:\n          cache: false\n    plots:\n      - metrics/roc_curve.json:\n          x: fpr\n          y: tpr\n      - metrics/confusion_matrix.json:\n          template: confusion\n          x: predicted\n          y: actual\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#paramsyaml-configuracion-del-pipeline","title":"params.yaml (Configuraci\u00f3n del Pipeline)","text":"<pre><code># params.yaml\nprepare:\n  test_size: 0.2\n  random_state: 42\n\nfeatures:\n  numerical:\n    - CreditScore\n    - Age\n    - Tenure\n    - Balance\n    - NumOfProducts\n    - EstimatedSalary\n  categorical:\n    - Geography\n    - Gender\n\ntrain:\n  n_estimators: 100\n  max_depth: 10\n  random_state: 42\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#comandos-de-pipeline","title":"Comandos de Pipeline","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# REPRODUCIR PIPELINE\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Ejecutar todo el pipeline\ndvc repro\n\n# Ejecutar stage espec\u00edfico (y sus dependencias)\ndvc repro train\n\n# Forzar re-ejecuci\u00f3n (aunque no haya cambios)\ndvc repro --force\n\n# Ver qu\u00e9 se ejecutar\u00eda sin ejecutar\ndvc repro --dry\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# VISUALIZAR PIPELINE\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Ver DAG en terminal\ndvc dag\n\n# Generar imagen del DAG\ndvc dag --dot | dot -Tpng -o pipeline.png\n\n# Ver dependencias de un stage\ndvc dag --outs train\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#visualizacion-del-dag","title":"Visualizaci\u00f3n del DAG","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                         DVC DAG: BANKCHURN                              \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                         \u2551\n\u2551                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2551\n\u2551                        \u2502  data/raw/*.csv \u2502                              \u2551\n\u2551                        \u2502  configs/*.yaml \u2502                              \u2551\n\u2551                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2551\n\u2551                                 \u2502                                       \u2551\n\u2551                                 \u25bc                                       \u2551\n\u2551                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2551\n\u2551                        \u2502    prepare      \u2502                              \u2551\n\u2551                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2551\n\u2551                                 \u2502                                       \u2551\n\u2551                                 \u25bc                                       \u2551\n\u2551                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                              \u2551\n\u2551                        \u2502   featurize     \u2502                              \u2551\n\u2551                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                              \u2551\n\u2551                                 \u2502                                       \u2551\n\u2551                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2551\n\u2551                     \u25bc                       \u25bc                           \u2551\n\u2551            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2551\n\u2551            \u2502     train       \u2502    \u2502    (test data)  \u2502                   \u2551\n\u2551            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2551\n\u2551                     \u2502                      \u2502                            \u2551\n\u2551                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                            \u2551\n\u2551                                \u25bc                                        \u2551\n\u2551                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2551\n\u2551                       \u2502    evaluate     \u2502                               \u2551\n\u2551                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2551\n\u2551                                \u2502                                        \u2551\n\u2551                                \u25bc                                        \u2551\n\u2551                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                               \u2551\n\u2551                       \u2502    metrics/     \u2502                               \u2551\n\u2551                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                               \u2551\n\u2551                                                                         \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#65-metricas-y-experimentos","title":"6.5 M\u00e9tricas y Experimentos","text":""},{"location":"docs/06_VERSIONADO_DATOS/#tracking-de-metricas","title":"Tracking de M\u00e9tricas","text":"<pre><code># Ver m\u00e9tricas actuales\ndvc metrics show\n\n# Comparar con otra rama/commit\ndvc metrics diff HEAD~1\n\n# Output ejemplo:\n# Path                     Metric    HEAD     HEAD~1   Change\n# metrics/eval_metrics.json  auc_roc   0.8721   0.8534   0.0187\n# metrics/eval_metrics.json  f1        0.7234   0.7012   0.0222\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#experimentos-con-dvc","title":"Experimentos con DVC","text":"<pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# EJECUTAR EXPERIMENTOS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Experimento con cambio de par\u00e1metro\ndvc exp run --set-param train.n_estimators=200\n\n# M\u00faltiples experimentos en paralelo\ndvc exp run --queue --set-param train.n_estimators=100\ndvc exp run --queue --set-param train.n_estimators=200\ndvc exp run --queue --set-param train.n_estimators=300\ndvc exp run --run-all --parallel 3\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# COMPARAR EXPERIMENTOS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Ver todos los experimentos\ndvc exp show\n\n# Output:\n# \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n# \u2503 Experiment    \u2503 auc_roc     \u2503 f1          \u2503 n_estimators   \u2503\n# \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n# \u2502 main          \u2502 0.8721      \u2502 0.7234      \u2502 100            \u2502\n# \u2502 exp-abc123    \u2502 0.8856      \u2502 0.7421      \u2502 200            \u2502\n# \u2502 exp-def456    \u2502 0.8812      \u2502 0.7356      \u2502 300            \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# APLICAR MEJOR EXPERIMENTO\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Aplicar a workspace\ndvc exp apply exp-abc123\n\n# O crear branch\ndvc exp branch exp-abc123 feature/best-model\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#66-patrones-avanzados","title":"6.6 Patrones Avanzados","text":""},{"location":"docs/06_VERSIONADO_DATOS/#multi-output-stages","title":"Multi-Output Stages","text":"<pre><code># dvc.yaml\nstages:\n  split:\n    cmd: python src/split.py\n    deps:\n      - data/raw/full_dataset.csv\n    outs:\n      - data/processed/train.csv\n      - data/processed/val.csv\n      - data/processed/test.csv\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#stages-condicionales-foreach","title":"Stages Condicionales (foreach)","text":"<pre><code># dvc.yaml - Entrenar m\u00faltiples modelos\nstages:\n  train:\n    foreach:\n      - random_forest\n      - xgboost\n      - lightgbm\n    do:\n      cmd: python src/train.py --model ${item}\n      deps:\n        - src/train.py\n        - data/processed/train.csv\n      params:\n        - train.${item}\n      outs:\n        - models/${item}.pkl\n      metrics:\n        - metrics/${item}_metrics.json:\n            cache: false\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#integracion-con-mlflow","title":"Integraci\u00f3n con MLflow","text":"<pre><code># src/bankchurn/training.py\nimport mlflow\nimport dvc.api\nimport yaml\n\ndef train():\n    # Obtener par\u00e1metros de DVC\n    params = dvc.api.params_show()\n\n    with mlflow.start_run():\n        # Log par\u00e1metros\n        mlflow.log_params(params[\"train\"])\n\n        # Entrenar...\n        model = train_model(params[\"train\"])\n\n        # Log m\u00e9tricas\n        metrics = evaluate(model)\n        mlflow.log_metrics(metrics)\n\n        # Guardar m\u00e9tricas para DVC tambi\u00e9n\n        with open(\"metrics/train_metrics.json\", \"w\") as f:\n            json.dump(metrics, f)\n\n        # Log modelo\n        mlflow.sklearn.log_model(model, \"model\")\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#66-ingenieria-inversa-pedagogica-dvc-pipeline-real","title":"6.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: DVC Pipeline Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s del <code>dvc.yaml</code> del portafolio.</p>"},{"location":"docs/06_VERSIONADO_DATOS/#661-el-por-que-arquitectonico","title":"6.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo garantizo que preprocesamiento se re-ejecuta si cambia algo? \u2502\n\u2502  DECISI\u00d3N: deps: [data/raw/Churn.csv, configs/config.yaml, script.py]           \u2502\n\u2502  RESULTADO: DVC detecta cambios y re-ejecuta solo lo necesario                  \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo evito re-entrenar si nada cambi\u00f3?                            \u2502\n\u2502  DECISI\u00d3N: outs: [models/best_model.pkl] + DAG de dependencias                  \u2502\n\u2502  RESULTADO: `dvc repro` es idempotente - solo ejecuta stages afectados          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#662-anatomia-de-dvcyaml","title":"6.6.2 \ud83d\udd0d Anatom\u00eda de <code>dvc.yaml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/dvc.yaml</code></p> <pre><code>stages:\n  preprocess:\n    cmd: python data/preprocess.py --input data/raw/Churn.csv --output data/processed/churn_processed.csv\n    deps:                           # Si CUALQUIERA cambia \u2192 re-ejecutar.\n      - data/raw/Churn.csv          # Datos crudos.\n      - configs/config.yaml         # Par\u00e1metros.\n      - data/preprocess.py          # El script mismo.\n    outs:\n      - data/processed/churn_processed.csv\n\n  train:\n    cmd: python main.py --mode train --seed 42\n    deps:\n      - data/processed/churn_processed.csv  # Output del stage anterior (DAG).\n      - main.py\n    outs:\n      - models/best_model.pkl\n      - artifacts/training_results.json\n\n  evaluate:\n    cmd: python main.py --mode evaluate --model models/best_model.pkl\n    deps:\n      - models/best_model.pkl       # Depende del modelo entrenado.\n    outs:\n      - artifacts/metrics\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#663-troubleshooting-preventivo","title":"6.6.3 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Soluci\u00f3n Stage no se re-ejecuta Script no en <code>deps</code> A\u00f1ade el .py a deps. <code>dvc repro</code> ejecuta TODO Cache corrupto <code>dvc gc -w</code> y re-ejecutar."},{"location":"docs/06_VERSIONADO_DATOS/#errores-habituales-y-como-depurarlos-en-dvc","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en DVC","text":"<p>Aunque DVC parece \u201ccaja negra que falla\u201d, en la pr\u00e1ctica los errores suelen venir de desalineaci\u00f3n entre Git, datos y configuraci\u00f3n.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/06_VERSIONADO_DATOS/#1-datos-no-aparecen-al-clonar-el-repo-dvc-pulldvc-checkout-olvidados","title":"1) Datos no aparecen al clonar el repo (<code>dvc pull</code>/<code>dvc checkout</code> olvidados)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Clonas el repositorio, ejecutas el c\u00f3digo y obtienes errores como:   <pre><code>FileNotFoundError: data/raw/churn.csv not found\n</code></pre></li> <li>La carpeta <code>data/</code> est\u00e1 vac\u00eda o solo tiene <code>.gitkeep</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Ejecuta:   <pre><code>dvc list .\ndvc status\n</code></pre>   para ver qu\u00e9 outs est\u00e1n trackeados.</li> <li>Mira si existen archivos <code>.dvc</code> (<code>data/raw/churn.csv.dvc</code>) pero no los datos reales.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Despu\u00e9s de clonar o cambiar de rama/tag, siempre ejecuta:   <pre><code>dvc pull      # trae los datos desde el remote\ndvc checkout  # sincroniza versiones de datos con los .dvc actuales\n</code></pre></li> <li>Documenta esto en el README del proyecto y en este m\u00f3dulo como parte del flujo est\u00e1ndar.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#2-dvc-committeados-pero-remote-sin-configurar-dvc-push-fallando","title":"2) <code>.dvc</code> committeados pero remote sin configurar (<code>dvc push</code> fallando)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Haces <code>dvc push</code> y ves errores tipo:   <pre><code>ERROR: failed to push data to the cloud - config file error\n</code></pre>   o credenciales faltantes.</li> <li>Compa\u00f1eros de equipo tienen los <code>.dvc</code>, pero <code>dvc pull</code> no trae nada.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa <code>.dvc/config</code> para ver qu\u00e9 remote est\u00e1 configurado (<code>localremote</code>, <code>s3remote</code>, etc.).</li> <li>Ejecuta <code>dvc remote list</code> y valida que el remote por defecto (<code>-d</code>) exista y sea accesible.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de que todos usen el mismo nombre de remote y que est\u00e9 configurado en el repo (no solo en local).</li> <li>Para remotes cloud (S3, GCS): documenta las variables de entorno necesarias (<code>AWS_ACCESS_KEY_ID</code>, etc.).</li> <li>Haz un <code>dvc push</code> de prueba y luego un <code>dvc pull</code> desde otra m\u00e1quina para validar.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#3-dvc-repro-no-ejecuta-stages-que-esperas-cambios-no-detectados","title":"3) <code>dvc repro</code> no ejecuta stages que esperas (cambios no detectados)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Modificas c\u00f3digo o par\u00e1metros, ejecutas <code>dvc repro</code> y ves:   <pre><code>Stage 'train' didn't change, skipping\n</code></pre>   aunque esperabas que volviera a entrenar.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Mira el <code>dvc.yaml</code> y verifica que:</li> <li>El script que cambiaste est\u00e9 en <code>deps:</code> del stage.</li> <li>Los par\u00e1metros que tocaste est\u00e9n en <code>params:</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de listar todas las dependencias reales en <code>deps:</code> (scripts, configs, datos intermedios).</li> <li>Si cambiaste par\u00e1metros en <code>params.yaml</code>, agr\u00e9galos a la lista <code>params:</code> del stage correspondiente.</li> <li>Si quieres forzar una re-ejecuci\u00f3n puntual, usa <code>dvc repro --force train</code>.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#4-conflictos-entre-gitignore-y-dvc-datos-en-git-por-accidente","title":"4) Conflictos entre <code>.gitignore</code> y <code>.dvc</code> (datos en Git por accidente)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Ves archivos grandes (<code>data/raw/*.csv</code>, <code>models/*.pkl</code>) en <code>git status</code>.</li> <li>Existen <code>.dvc</code> pero los datos tambi\u00e9n se han a\u00f1adido a Git.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa <code>data/raw/.gitignore</code> generado por <code>dvc add</code> y el <code>.gitignore</code> del proyecto principal; puede que se est\u00e9n pisando.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Respeta el patr\u00f3n DVC:</li> <li>Los datos no se a\u00f1aden a Git, solo los <code>.dvc</code>.</li> <li>Aseg\u00farate de que <code>.gitignore</code> incluya las carpetas de datos/artefactos y que no contradiga los <code>.gitignore</code> generados por DVC.</li> <li>Si ya has commiteado datos grandes, elim\u00ednalos del historial (o al menos del \u00faltimo commit) y deja solo los <code>.dvc</code>.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#5-dvc-cicd-pipelines-que-fallan-en-github-actions","title":"5) DVC + CI/CD: pipelines que fallan en GitHub Actions","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En CI, <code>dvc repro</code> falla porque no encuentra datos o no tiene acceso al remote.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el workflow de CI y verifica si:</li> <li>Has instalado DVC con los extras correctos (<code>dvc[s3]</code>, etc.).</li> <li>Has configurado variables de entorno con credenciales.</li> <li>Est\u00e1s ejecutando <code>dvc pull</code> antes de correr el pipeline.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>A\u00f1ade pasos en tu workflow:   <pre><code>- name: Install DVC\n  run: pip install \"dvc[s3]\"\n\n- name: Pull data with DVC\n  run: dvc pull\n\n- name: Run pipeline\n  run: dvc repro\n</code></pre></li> <li>Usa <code>dvc repro --dry</code> localmente para ver qu\u00e9 deber\u00eda ejecutarse antes de llevarlo a CI.</li> </ul>"},{"location":"docs/06_VERSIONADO_DATOS/#patron-general-de-debugging-en-dvc","title":"Patr\u00f3n general de debugging en DVC","text":"<ol> <li>Inspecciona el estado con <code>dvc status</code> y <code>dvc dag</code>.</li> <li>Verifica remotes y credenciales (<code>dvc remote list</code>, <code>.dvc/config</code>).</li> <li>Comprueba deps/outs/params en <code>dvc.yaml</code> para el stage problem\u00e1tico.</li> <li>Sincroniza Git + DVC: <code>git checkout &lt;tag/branch&gt;</code> seguido de <code>dvc checkout</code> y <code>dvc pull</code> si hace falta.</li> </ol> <p>Con este checklist, DVC pasa de ser \u201ccaja negra que falla\u201d a una herramienta controlable para reproducir datos y pipelines.</p> <p></p>"},{"location":"docs/06_VERSIONADO_DATOS/#67-ejercicio-integrador","title":"6.7 Ejercicio Integrador","text":""},{"location":"docs/06_VERSIONADO_DATOS/#setup-completo-de-dvc","title":"Setup Completo de DVC","text":"<pre><code># 1. Inicializar DVC\ncd bankchurn-predictor\ndvc init\n\n# 2. Configurar remote (local para empezar)\nmkdir -p ~/dvc-storage\ndvc remote add -d localremote ~/dvc-storage\n\n# 3. Crear estructura de datos\nmkdir -p data/{raw,processed} models metrics\n\n# 4. A\u00f1adir datos raw\n# (asumiendo que tienes churn.csv)\ncp /path/to/churn.csv data/raw/\ndvc add data/raw/churn.csv\n\n# 5. Crear dvc.yaml (copiar del ejemplo anterior)\n\n# 6. Crear params.yaml\n\n# 7. Commit todo\ngit add .\ngit commit -m \"data(dvc): setup DVC pipeline\"\n\n# 8. Ejecutar pipeline\ndvc repro\n\n# 9. Push a remote\ndvc push\ngit push\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#checklist-de-verificacion","title":"Checklist de Verificaci\u00f3n","text":"<pre><code>CONFIGURACI\u00d3N:\n[ ] DVC inicializado\n[ ] Remote configurado y funcionando\n[ ] Datos raw tracked con DVC\n\nPIPELINE:\n[ ] dvc.yaml con stages definidos\n[ ] params.yaml con par\u00e1metros\n[ ] dvc repro ejecuta sin errores\n\nVERSIONADO:\n[ ] Puedo hacer git checkout + dvc checkout a versiones anteriores\n[ ] dvc push/pull funcionan correctamente\n[ ] M\u00e9tricas se trackean con dvc metrics show\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#68-autoevaluacion","title":"6.8 Autoevaluaci\u00f3n","text":""},{"location":"docs/06_VERSIONADO_DATOS/#preguntas-de-reflexion","title":"Preguntas de Reflexi\u00f3n","text":"<ol> <li>\u00bfPor qu\u00e9 DVC usa hashes MD5 en lugar de guardar los archivos?</li> <li>\u00bfQu\u00e9 pasa si cambio <code>params.yaml</code> pero no el c\u00f3digo?</li> <li>\u00bfCu\u00e1ndo DVC salta un stage sin ejecutarlo?</li> <li>\u00bfC\u00f3mo integrar\u00edas DVC con GitHub Actions para CI?</li> </ol>"},{"location":"docs/06_VERSIONADO_DATOS/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El portafolio tiene DVC configurado a nivel global:</p>"},{"location":"docs/06_VERSIONADO_DATOS/#estructura-dvc-del-portafolio","title":"Estructura DVC del Portafolio","text":"<pre><code>ML-MLOps-Portfolio/\n\u251c\u2500\u2500 .dvc/                  # Configuraci\u00f3n DVC\n\u2502   \u2514\u2500\u2500 config             # Remote storage config\n\u251c\u2500\u2500 .dvc-storage/          # Remote local (para demo)\n\u251c\u2500\u2500 .dvcignore            # Archivos a ignorar\n\u2514\u2500\u2500 */data/raw/*.dvc       # Archivos .dvc en cada proyecto\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#archivos-dvc-reales","title":"Archivos .dvc Reales","text":"<pre><code># BankChurn-Predictor/data/raw/bank_churn.csv.dvc\nmd5: abc123def456...\nsize: 1234567\npath: bank_churn.csv\n\n# CarVision-Market-Intelligence/data/raw/car_prices.csv.dvc\nmd5: xyz789ghi012...\nsize: 2345678\npath: car_prices.csv\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#flujo-de-datos-en-el-portafolio","title":"Flujo de Datos en el Portafolio","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FLUJO DE DATOS DVC                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                              \u2502\n\u2502  data/raw/*.csv    \u2192    .dvc files    \u2192    .dvc-storage/     \u2502\n\u2502  (gitignored)           (tracked)          (remote local)    \u2502\n\u2502                                                              \u2502\n\u2502  Para CI/CD:                                                 \u2502\n\u2502  git clone \u2192 dvc pull \u2192 datos disponibles                    \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#comandos-dvc-del-portafolio","title":"Comandos DVC del Portafolio","text":"<pre><code># Ver qu\u00e9 datos est\u00e1n trackeados\ndvc status\n\n# Obtener datos despu\u00e9s de clonar\ndvc pull\n\n# Agregar nuevos datos\ndvc add data/raw/nuevos_datos.csv\ngit add data/raw/nuevos_datos.csv.dvc data/raw/.gitignore\ngit commit -m \"data(dvc): add nuevos_datos\"\ndvc push\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-trabaja-con-dvc-real","title":"\ud83d\udd27 Ejercicio: Trabaja con DVC Real","text":"<pre><code># 1. Ve a la ra\u00edz del portafolio\ncd ML-MLOps-Portfolio\n\n# 2. Verifica estado de DVC\ndvc status\n\n# 3. Obt\u00e9n los datos (si no los tienes)\ndvc pull\n\n# 4. Verifica que los datos existen\nls -la BankChurn-Predictor/data/raw/\nls -la CarVision-Market-Intelligence/data/raw/\n\n# 5. Experimenta: modifica params y reproduce\ncd BankChurn-Predictor\ndvc repro  # Si tienes dvc.yaml configurado\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/06_VERSIONADO_DATOS/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>DVC vs Git LFS: Explica que DVC es espec\u00edfico para ML (pipelines, m\u00e9tricas), LFS es gen\u00e9rico para archivos grandes.</p> </li> <li> <p>Reproducibilidad: Menciona que puedes recrear cualquier experimento con <code>dvc checkout</code> + <code>git checkout</code>.</p> </li> <li> <p>Data Lineage: Explica c\u00f3mo DVC trackea la procedencia de datos transformados.</p> </li> </ol>"},{"location":"docs/06_VERSIONADO_DATOS/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Datos sensibles Usa DVC con storage encriptado (S3 + KMS) Datasets grandes Usa <code>dvc push/pull</code> selectivo por carpeta CI/CD Cachea datos en CI para evitar descargas repetidas Colaboraci\u00f3n Documenta d\u00f3nde est\u00e1 el remote storage"},{"location":"docs/06_VERSIONADO_DATOS/#flujo-profesional-de-datos","title":"Flujo Profesional de Datos","text":"<ol> <li>Raw data \u2192 nunca modificar, solo agregar</li> <li>Processed data \u2192 versionado con DVC</li> <li>Features \u2192 cacheados para reutilizaci\u00f3n</li> <li>Modelos \u2192 versionados con m\u00e9tricas</li> </ol>"},{"location":"docs/06_VERSIONADO_DATOS/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/06_VERSIONADO_DATOS/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 DVC Tutorial - Data Version Control DVCorg 12 min YouTube \ud83d\udd34 DVC Pipelines Deep Dive DVCorg 18 min YouTube \ud83d\udfe1 MLOps with DVC and CML DataTalksClub 45 min YouTube"},{"location":"docs/06_VERSIONADO_DATOS/#cursos","title":"\ud83d\udcda Cursos","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Duraci\u00f3n Link \ud83d\udfe1 Iterative Tools for ML DVCorg 4h Learn.iterative.ai"},{"location":"docs/06_VERSIONADO_DATOS/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 DVC Get Started Tutorial oficial paso a paso \ud83d\udfe1 DVC Remote Storage Configuraci\u00f3n de remotes S3/GCS"},{"location":"docs/06_VERSIONADO_DATOS/#decision-tecnica-adr-009-dvc","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-009 DVC","text":"<p>Contexto: Necesitamos versionar datasets grandes sin guardarlos en Git.</p> <p>Decisi\u00f3n: Usar DVC (Data Version Control).</p> <p>Alternativas Consideradas: - Git LFS: Pago por storage, menos features - S3 directo: Sin versionado sem\u00e1ntico - Delta Lake: Overkill para nuestro tama\u00f1o</p> <p>Consecuencias: - \u2705 Versionado sem\u00e1ntico de datos - \u2705 Pipelines reproducibles con <code>dvc.yaml</code> - \u2705 Integraci\u00f3n con Git (<code>.dvc</code> files) - \u274c Curva de aprendizaje adicional</p>"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-61-inicializar-dvc","title":"Ejercicio 6.1: Inicializar DVC","text":"<p>Objetivo: Configurar DVC en un proyecto. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Ejecutar y documentar cada paso\n\n# 1. Inicializar DVC\ndvc init\n\n# 2. A\u00f1adir remote local (para pr\u00e1ctica)\ndvc remote add -d localremote /tmp/dvc-storage\n\n# 3. Trackear datos\ndvc add data/raw/dataset.csv\n\n# 4. Commitear archivos .dvc\ngit add data/raw/dataset.csv.dvc data/raw/.gitignore\ngit commit -m \"chore(data): track dataset with DVC\"\n\n# PREGUNTA: \u00bfQu\u00e9 archivos se crean? \u00bfQu\u00e9 contiene el .dvc?\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n  **Archivos creados:** - `data/raw/dataset.csv.dvc` \u2014 Metadatos del archivo (hash MD5) - `data/raw/.gitignore` \u2014 Ignora el archivo real, trackea solo el `.dvc`  **Contenido del .dvc:** <pre><code>outs:\n- md5: abc123def456...\n  size: 1234567\n  path: dataset.csv\n</code></pre>  **Flujo completo:** <pre><code># Inicializar\ndvc init\ngit add .dvc .dvcignore\ngit commit -m \"chore: initialize DVC\"\n\n# Configurar remote\ndvc remote add -d myremote s3://my-bucket/dvc-storage\ngit add .dvc/config\ngit commit -m \"chore(dvc): configure S3 remote\"\n\n# Trackear datos\ndvc add data/raw/dataset.csv\ngit add data/raw/dataset.csv.dvc data/raw/.gitignore\ngit commit -m \"chore(data): track dataset with DVC\"\n\n# Push datos al remote\ndvc push\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-62-pipeline-dvc","title":"Ejercicio 6.2: Pipeline DVC","text":"<p>Objetivo: Definir pipeline reproducible. Dificultad: \u2b50\u2b50</p> <pre><code># dvc.yaml\n# TU TAREA: Definir pipeline de 3 stages\n\nstages:\n  prepare:\n    cmd: python src/data.py\n    deps:\n      # \u00bfQu\u00e9 dependencias?\n    outs:\n      # \u00bfQu\u00e9 outputs?\n\n  train:\n    cmd: python src/training.py\n    deps:\n      # ???\n    outs:\n      # ???\n    metrics:\n      # ???\n\n  evaluate:\n    cmd: python src/evaluate.py\n    deps:\n      # ???\n    metrics:\n      # ???\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>stages:\n  prepare:\n    cmd: python src/data.py\n    deps:\n      - src/data.py\n      - data/raw/dataset.csv\n    outs:\n      - data/processed/train.csv\n      - data/processed/test.csv\n\n  train:\n    cmd: python src/training.py\n    deps:\n      - src/training.py\n      - data/processed/train.csv\n    params:\n      - train.n_estimators\n      - train.max_depth\n    outs:\n      - models/model.joblib\n    metrics:\n      - metrics/train_metrics.json:\n          cache: false\n\n  evaluate:\n    cmd: python src/evaluate.py\n    deps:\n      - src/evaluate.py\n      - models/model.joblib\n      - data/processed/test.csv\n    metrics:\n      - metrics/eval_metrics.json:\n          cache: false\n    plots:\n      - plots/confusion_matrix.png\n</code></pre>  **Ejecutar pipeline:** <pre><code>dvc repro          # Ejecuta stages necesarios\ndvc metrics show   # Muestra m\u00e9tricas\ndvc plots show     # Genera visualizaciones\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n DVC Data Version Control - herramienta para versionar datos y pipelines ML Remote Storage Almacenamiento externo (S3, GCS, Azure) para datos versionados dvc.yaml Archivo que define stages de un pipeline reproducible dvc.lock Archivo generado con hashes exactos de cada stage ejecutado"},{"location":"docs/06_VERSIONADO_DATOS/#checkpoint-fase-1-fundamentos-completados","title":"\ud83c\udfc1 CHECKPOINT FASE 1: Fundamentos Completados","text":"<p>\ud83c\udfaf \u00a1Has completado los m\u00f3dulos 01-06!</p> <p>Ahora tienes las bases de un MLOps Engineer profesional: - \u2705 Python moderno con type hints y Pydantic - \u2705 Dise\u00f1o de sistemas ML - \u2705 Estructura de proyectos profesional - \u2705 Entornos reproducibles - \u2705 Git profesional con pre-commit - \u2705 Versionado de datos con DVC</p>"},{"location":"docs/06_VERSIONADO_DATOS/#examen-de-hito-1-setup-profesional","title":"\ud83d\udccb Examen de Hito 1: Setup Profesional","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-de-examen-type-hints-y-estructura","title":"Ejercicio de Examen: Type Hints y Estructura","text":"<p>C\u00f3digo a Revisar: <pre><code># archivo: src/bankchurn/training.py\n\ndef load_data(path):\n    \"\"\"Carga datos desde CSV.\"\"\"\n    import pandas as pd\n    return pd.read_csv(path)\n\ndef prepare_features(df, target_col, features):\n    X = df[features]\n    y = df[target_col]\n    return X, y\n\ndef train_model(X, y, n_estimators=100, max_depth=None):\n    from sklearn.ensemble import RandomForestClassifier\n    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    model.fit(X, y)\n    return model\n</code></pre></p> <p>Tu tarea: Identifica TODOS los errores y prop\u00f3n correcciones.</p> \ud83d\udcdd Ver Soluci\u00f3n del Examen  **Errores Encontrados:**  | # | Problema | Severidad | Correcci\u00f3n | |---|----------|-----------|------------| | 1 | `load_data(path)` sin type hints | \ud83d\udfe1 | `path: str \\| Path` \u2192 `pd.DataFrame` | | 2 | Import dentro de funci\u00f3n | \ud83d\udfe2 | Mover imports al inicio | | 3 | `prepare_features` sin tipos | \ud83d\udfe1 | A\u00f1adir tipos a par\u00e1metros y retorno | | 4 | `train_model` sin tipo retorno | \ud83d\udfe1 | `-&gt; RandomForestClassifier` | | 5 | Sin `random_state` | \ud83d\udfe1 | A\u00f1adir para reproducibilidad |  **C\u00f3digo Corregido:** <pre><code>from pathlib import Path\nfrom typing import Tuple, Sequence, Optional\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\ndef load_data(path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"Carga datos desde CSV.\"\"\"\n    return pd.read_csv(path)\n\ndef prepare_features(\n    df: pd.DataFrame,\n    target_col: str,\n    features: Sequence[str]\n) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"Separa features y target.\"\"\"\n    return df[list(features)], df[target_col]\n\ndef train_model(\n    X: pd.DataFrame,\n    y: pd.Series,\n    n_estimators: int = 100,\n    max_depth: Optional[int] = None\n) -&gt; RandomForestClassifier:\n    \"\"\"Entrena modelo Random Forest.\"\"\"\n    model = RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        random_state=42\n    )\n    return model.fit(X, y)\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#simulacro-de-entrevista-nivel-junior","title":"\ud83c\udfa4 Simulacro de Entrevista: Nivel Junior","text":"<p>50 preguntas para validar fundamentos (M\u00f3dulos 01-06) Tiempo: 60 minutos Objetivo: Preparaci\u00f3n para posiciones Junior ML Engineer</p>"},{"location":"docs/06_VERSIONADO_DATOS/#preguntas-de-muestra","title":"Preguntas de Muestra","text":"<p>Python Moderno (10 preguntas) 1. \u00bfQu\u00e9 son los type hints y por qu\u00e9 usarlos en ML? 2. \u00bfDiferencia entre <code>dataclass</code> y Pydantic <code>BaseModel</code>? 3. \u00bfQu\u00e9 hace <code>Field(ge=0, le=100)</code> en Pydantic?</p> <p>Estructura de Proyecto (8 preguntas) 4. \u00bfPor qu\u00e9 usar <code>src/</code> layout en vez de flat layout? 5. \u00bfQu\u00e9 es <code>pip install -e .</code> y cu\u00e1ndo usarlo? 6. \u00bfQu\u00e9 debe contener un <code>pyproject.toml</code> m\u00ednimo?</p> <p>Git Profesional (8 preguntas) 7. \u00bfQu\u00e9 es un Conventional Commit? Da un ejemplo. 8. \u00bfPara qu\u00e9 sirve pre-commit y qu\u00e9 hooks usar\u00edas? 9. \u00bfDiferencia entre <code>git merge</code> y <code>git rebase</code>?</p> <p>DVC y Datos (8 preguntas) 10. \u00bfPor qu\u00e9 no versionar datos directamente en Git? 11. \u00bfQu\u00e9 contiene un archivo <code>.dvc</code>? 12. \u00bfC\u00f3mo reproducir un experimento con DVC?</p> \ud83d\udca1 Ver Respuestas de Muestra  **1. Type hints en ML:** &gt; Documentan tipos esperados, ayudan al IDE con autocompletado, y permiten validaci\u00f3n est\u00e1tica con mypy. En ML, evitan errores como pasar un `np.array` donde se esperaba `pd.DataFrame`.  **4. src/ layout:** &gt; Evita que Python importe el c\u00f3digo local en vez del paquete instalado. Es el est\u00e1ndar profesional que permite `pip install -e .` y tests aislados.  **7. Conventional Commit:** &gt; `feat(training): add cross-validation support` &gt; - `feat`: nueva funcionalidad &gt; - `(training)`: scope/m\u00f3dulo afectado &gt; - descripci\u00f3n en imperativo  **11. Archivo .dvc:** &gt; Contiene el hash MD5 del archivo real, su tama\u00f1o y path. El archivo real se ignora en Git y se almacena en el remote de DVC.  <p>Ver simulacro completo \u2192</p>"},{"location":"docs/06_VERSIONADO_DATOS/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/06_VERSIONADO_DATOS/#trampa-1-dvc-add-en-archivo-ya-trackeado-por-git","title":"Trampa 1: dvc add en archivo ya trackeado por Git","text":"<p>S\u00edntoma: <pre><code>dvc add data/customers.csv\n# ERROR: data/customers.csv is already tracked by Git\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># 1. Remover de Git (mantener archivo local)\ngit rm --cached data/customers.csv\n\n# 2. Ahora s\u00ed, a\u00f1adir a DVC\ndvc add data/customers.csv\n\n# 3. Commitear el .dvc y .gitignore\ngit add data/customers.csv.dvc data/.gitignore\ngit commit -m \"data: track customers.csv with DVC\"\n</code></pre></p>"},{"location":"docs/06_VERSIONADO_DATOS/#trampa-2-dvc-repro-no-detecta-cambios-en-codigo","title":"Trampa 2: dvc repro no detecta cambios en c\u00f3digo","text":"<p>S\u00edntoma: <pre><code># Modifico train.py\nvim src/bankchurn/train.py\n\ndvc repro\n# \"Stage 'train' didn't change, skipping\"  \u2190 \u00a1Deber\u00eda re-ejecutar!\n</code></pre></p> <p>Causa ra\u00edz: El archivo modificado no est\u00e1 en <code>deps:</code> del stage.</p> <p>Soluci\u00f3n: <pre><code># dvc.yaml\nstages:\n  train:\n    cmd: python src/bankchurn/train.py\n    deps:\n      - src/bankchurn/train.py      # \u2190 El script\n      - src/bankchurn/pipeline.py   # \u2190 Dependencias del script\n      - data/processed/train.csv    # \u2190 Datos\n    outs:\n      - models/model.pkl\n</code></pre></p>"},{"location":"docs/06_VERSIONADO_DATOS/#trampa-3-dvc-pull-falla-silenciosamente","title":"Trampa 3: dvc pull falla silenciosamente","text":"<p>S\u00edntoma: <pre><code>dvc pull\n# (sin output)\nls data/\n# (vac\u00edo o archivos antiguos)\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># Verificar configuraci\u00f3n\ndvc remote list\ndvc remote default\n\n# Pull con verbose\ndvc pull -v\n</code></pre></p>"},{"location":"docs/06_VERSIONADO_DATOS/#quiz-del-modulo-semanas-5-6","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 5-6","text":""},{"location":"docs/06_VERSIONADO_DATOS/#quiz-semana-5-dvc-fundamentos","title":"Quiz Semana 5: DVC Fundamentos","text":""},{"location":"docs/06_VERSIONADO_DATOS/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfCu\u00e1l es la diferencia fundamental entre Git LFS y DVC?</p> \u2705 Respuesta  | Aspecto | Git LFS | DVC | |---------|---------|-----| | **Storage** | GitHub (pago por ancho de banda) | Tu propio storage (S3, GCS, local) | | **Pipelines** | \u274c No | \u2705 `dvc.yaml` con DAGs | | **Experimentos** | \u274c No | \u2705 `dvc exp run` | | **Cache** | \u274c No | \u2705 Reutiliza artefactos |"},{"location":"docs/06_VERSIONADO_DATOS/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfQu\u00e9 hace <code>dvc add data/raw.csv</code> internamente?</p> \u2705 Respuesta  1. **Calcula hash MD5** del archivo 2. **Crea `data/raw.csv.dvc`** (puntero con el hash) 3. **A\u00f1ade `data/raw.csv` a `.gitignore`** 4. **Mueve el archivo al cache** (`.dvc/cache/`)"},{"location":"docs/06_VERSIONADO_DATOS/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfPor qu\u00e9 <code>dvc repro</code> no re-ejecuta si no hay cambios?</p> \u2705 Respuesta  DVC trackea **hashes de deps y outs** en `dvc.lock`. En `dvc repro`: 1. Calcula hashes actuales de deps 2. Compara con `dvc.lock` 3. Si coinciden \u2192 skip 4. Si difieren \u2192 re-ejecuta y actualiza lock"},{"location":"docs/06_VERSIONADO_DATOS/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Escribe un <code>dvc.yaml</code> con dos stages: 1. <code>prepare</code>: lee <code>data/raw.csv</code>, genera <code>data/processed.csv</code> 2. <code>train</code>: lee <code>data/processed.csv</code> + <code>src/train.py</code>, genera <code>models/model.pkl</code></p> \u2705 Soluci\u00f3n <pre><code>stages:\n  prepare:\n    cmd: python src/prepare.py\n    deps:\n      - src/prepare.py\n      - data/raw.csv\n    outs:\n      - data/processed.csv\n\n  train:\n    cmd: python src/train.py\n    deps:\n      - src/train.py\n      - data/processed.csv\n    outs:\n      - models/model.pkl\n    metrics:\n      - metrics.json:\n          cache: false\n</code></pre>"},{"location":"docs/06_VERSIONADO_DATOS/#siguiente-fase-ml-engineering","title":"\ud83d\udd1c Siguiente Fase: ML Engineering","text":"<p>Con los fundamentos completados, es hora de construir pipelines de sklearn avanzados.</p> <p>Comenzar Fase 2 \u2192 M\u00f3dulo 07: sklearn Pipelines</p>   [\u2190 Git Profesional](05_GIT_PROFESIONAL.md) | [Siguiente: sklearn Pipelines \u2192](07_SKLEARN_PIPELINES.md)"},{"location":"docs/07_SKLEARN_PIPELINES/","title":"07. sklearn Pipelines: El Coraz\u00f3n de MLOps","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Dominar el patr\u00f3n m\u00e1s importante de ML profesional: pipelines unificados que garantizan reproducibilidad desde entrenamiento hasta producci\u00f3n.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \ud83d\udea8 EL ERROR #1 EN PRODUCCI\u00d3N ML:                                            \u2551\n\u2551                                                                              \u2551\n\u2551  Entrenar con una transformaci\u00f3n, servir con otra.                           \u2551\n\u2551                                                                              \u2551\n\u2551  Ejemplo real:                                                               \u2551\n\u2551  \u2022 Training: StandardScaler fitted en train set (mean=45000, std=20000)      \u2551\n\u2551  \u2022 Production: StandardScaler fitted en cada request (mean=???, std=???)     \u2551\n\u2551  \u2022 Resultado: Predicciones COMPLETAMENTE diferentes                          \u2551\n\u2551                                                                              \u2551\n\u2551  \ud83d\udee1\ufe0f LA SOLUCI\u00d3N: Pipeline unificado que guarda TODO junto                    \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 01_PYTHON_MODERNO y entender el motivo del <code>src/</code> layout.</li> <li>Tener un proyecto del portafolio a mano (ideal: BankChurn) para ubicar el <code>pipeline.pkl</code> real.</li> <li>Entender el problema de training-serving skew (al menos a nivel conceptual).</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de codificar: abre Protocolo E y define tu output m\u00ednimo (ej: \u201cpipeline serializable + tests b\u00e1sicos\u201d).</li> <li>Mientras debuggeas: si te atoras &gt;15 min (ColumnTransformer, columnas, dtypes, <code>fit/transform</code>), registra el bloqueo en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para decidir qu\u00e9 mejorar (reproducibilidad, tests, DX).</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] 1 pipeline unificado serializado (<code>pipeline.pkl</code>) que incluya preprocesamiento + modelo.</li> <li>[ ] Inferencia consistente: <code>pipeline.predict(X_new)</code> sin re-fit de transformadores.</li> <li>[ ] Checklist de verificaci\u00f3n pasando (secci\u00f3n \u201cCheckpoint\u201d).</li> </ul> <p></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: Pipeline/ColumnTransformer/custom transformers</li> <li>Archivo: <code>src/&lt;paquete&gt;/training.py</code>, <code>src/&lt;paquete&gt;/features.py</code>, <code>models/pipeline.pkl</code></li> <li>Prueba: entrenar una vez, guardar <code>pipeline.pkl</code>, cargarlo y predecir con datos nuevos.</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>\u00bfPor Qu\u00e9 Pipelines?</li> <li>ColumnTransformer: Transformaciones Paralelas</li> <li>Custom Transformers</li> <li>Pipeline Completo: C\u00f3digo Real</li> <li>Ejercicios Pr\u00e1cticos</li> <li>\ud83d\udd2c Ingenier\u00eda Inversa: ColumnTransformer \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#71-por-que-pipelines","title":"7.1 \u00bfPor Qu\u00e9 Pipelines?","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#la-analogia-de-la-linea-de-ensamblaje","title":"La Analog\u00eda de la L\u00ednea de Ensamblaje","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83c\udfed IMAGINA UNA F\u00c1BRICA DE AUTOS:                                         \u2551\n\u2551                                                                           \u2551\n\u2551  SIN L\u00cdNEA DE ENSAMBLAJE (c\u00f3digo suelto):                                 \u2551\n\u2551  \u2022 Trabajador 1 pone ruedas, pero a veces se le olvida                    \u2551\n\u2551  \u2022 Trabajador 2 pinta, pero usa colores diferentes cada d\u00eda               \u2551\n\u2551  \u2022 Trabajador 3 instala motor, pero a veces del modelo equivocado         \u2551\n\u2551  \u2022 Resultado: Cada auto es diferente, imposible de mantener               \u2551\n\u2551                                                                           \u2551\n\u2551  CON L\u00cdNEA DE ENSAMBLAJE (Pipeline):                                      \u2551\n\u2551  \u2022 Paso 1: Chasis \u2192 Paso 2: Motor \u2192 Paso 3: Pintura \u2192 Paso 4: Ruedas      \u2551\n\u2551  \u2022 Cada paso est\u00e1 definido y es SIEMPRE igual                             \u2551\n\u2551  \u2022 El proceso completo es una sola unidad                                 \u2551\n\u2551  \u2022 Resultado: Todos los autos son consistentes                            \u2551\n\u2551                                                                           \u2551\n\u2551  sklearn Pipeline = L\u00ednea de ensamblaje para ML                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#el-problema-real-training-serving-skew","title":"El Problema Real: Training-Serving Skew","text":"<p><pre><code># \u274c C\u00d3DIGO PROBLEM\u00c1TICO (muy com\u00fan en notebooks convertidos a producci\u00f3n)\n\n# === ENTRENAMIENTO ===\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder  # Importa transformadores de sklearn.\n\n# Ajustar scaler en datos de entrenamiento\nscaler = StandardScaler()                                  # Crea instancia: a\u00fan no tiene par\u00e1metros learned.\nX_train_scaled = scaler.fit_transform(X_train[num_cols])   # fit_transform: calcula mean/std Y transforma.\n\nencoder = OneHotEncoder()                                  # Crea encoder para convertir categor\u00edas a binario.\nX_train_encoded = encoder.fit_transform(X_train[cat_cols]) # fit: aprende categor\u00edas \u00fanicas; transform: aplica.\n\n# Entrenar modelo\nmodel = RandomForestClassifier()                           # Crea el modelo de clasificaci\u00f3n.\nmodel.fit(X_train_processed, y_train)                      # Entrena con datos ya transformados.\n\n# Guardar modelo... pero \u00bfy el scaler? \u00bfy el encoder?\njoblib.dump(model, \"model.pkl\")  # \u2190 \u00a1ERROR! Solo guarda el modelo, NO los transformadores.\n\n# === PRODUCCI\u00d3N (meses despu\u00e9s, otro desarrollador) ===\nmodel = joblib.load(\"model.pkl\")                           # Carga solo el modelo.\n\n# \u00bfC\u00f3mo transformo los datos nuevos?\n# \ud83e\udd37 No tengo el scaler ni el encoder fitted             # Los transformadores se perdieron.\n# \ud83e\udd37 Incluso si los tuviera, \u00bfc\u00f3mo s\u00e9 qu\u00e9 columnas usar? # No hay documentaci\u00f3n de las columnas.\n# \ud83e\udd37 \u00bfEra StandardScaler o MinMaxScaler?                 # Imposible saber qu\u00e9 se us\u00f3.\n\n# \"Soluci\u00f3n\" del desarrollador desesperado:\nscaler = StandardScaler()                                  # Crea NUEVO scaler (sin los par\u00e1metros originales).\nX_new_scaled = scaler.fit_transform(X_new[num_cols])       # fit en datos NUEVOS: mean/std DIFERENTES.\n# \u26a0\ufe0f Ahora mean y std son DIFERENTES a los de entrenamiento \u2192 training-serving skew.\n# \u26a0\ufe0f Las predicciones son BASURA porque la escala es inconsistente.\n\n# ============================================================================\n# \u2705 SOLUCI\u00d3N: Pipeline Unificado\n# ============================================================================\n\n# === ENTRENAMIENTO ===\nfrom sklearn.pipeline import Pipeline              # Pipeline: encadena pasos secuenciales.\nfrom sklearn.compose import ColumnTransformer      # ColumnTransformer: aplica transformaciones por grupo de columnas.\n\n# Definir pipeline completo\npipeline = Pipeline([                              # Lista de tuplas (nombre, objeto).\n    ('preprocessor', ColumnTransformer([           # Primer paso: preprocesamiento por columnas.\n        ('num', StandardScaler(), num_cols),       # Escala num\u00e9ricas (aprende mean/std de train).\n        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # One-hot categor\u00edcas; ignore evita crash.\n    ])),\n    ('model', RandomForestClassifier())            # Segundo paso: el modelo.\n])\n\n# Un solo fit entrena TODO\npipeline.fit(X_train, y_train)                     # fit() propaga por todos los pasos: transforma Y entrena.\n\n# Guardar TODO junto\njoblib.dump(pipeline, \"pipeline.pkl\")              # Serializa Scaler + Encoder + Model en UN archivo.\n\n# === PRODUCCI\u00d3N ===\npipeline = joblib.load(\"pipeline.pkl\")             # Carga todo: transformadores YA fitted + modelo.\n\n# Una sola llamada hace TODO (con los par\u00e1metros de entrenamiento)\npredictions = pipeline.predict(X_new)              # predict() internamente transforma X_new y luego predice.\n\n# \u2705 El scaler usa mean/std del entrenamiento      \u2192 Consistencia garantizada.\n# \u2705 El encoder conoce las categor\u00edas del entrenamiento \u2192 No crash por categor\u00edas nuevas.\n# \u2705 Las predicciones son consistentes             \u2192 Sin training-serving skew.\n\n### \ud83e\udde0 Mapa Mental de Conceptos: sklearn Pipelines\n</code></pre>                         \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557                         \u2551      SKLEARN PIPELINES PARA MLOPS        \u2551                         \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d                                             \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u25bc                                  \u25bc                                  \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502    Pipeline      \u2502              \u2502ColumnTransformer \u2502              \u2502 Custom Transform \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502                                 \u2502                                 \u2502 \u251c\u2500 Pasos secuenciales            \u251c\u2500 Transforma paralelo           \u251c\u2500 BaseEstimator \u251c\u2500 fit/transform/predict         \u251c\u2500 Por grupos de columnas        \u251c\u2500 TransformerMixin \u251c\u2500 Serializable como 1 objeto    \u251c\u2500 num/cat/text/etc              \u251c\u2500 fit/transform \u2514\u2500 Evita training-serving skew   \u2514\u2500 Combina resultados            \u2514\u2500 Tu l\u00f3gica custom <pre><code>**T\u00e9rminos clave que debes dominar:**\n\n| T\u00e9rmino | Significado | Ejemplo |\n|---------|-------------|---------|\n| **Pipeline** | Cadena de pasos (transformadores + modelo) | `Pipeline([('scaler', ...), ('model', ...)])` |\n| **ColumnTransformer** | Aplica diferentes transformaciones a diferentes columnas | Num\u00e9ricas \u2192 Scaler, Categ\u00f3ricas \u2192 OneHot |\n| **Training-Serving Skew** | Diferencia entre preprocesamiento en train y producci\u00f3n | Scaler con diferente mean/std |\n| **fit_transform** | Aprende par\u00e1metros Y transforma (solo en training) | `scaler.fit_transform(X_train)` |\n| **transform** | Solo transforma con par\u00e1metros aprendidos (producci\u00f3n) | `scaler.transform(X_new)` |\n\n---\n\n### \ud83d\udcbb Ejercicio Puente: Pipeline B\u00e1sico\n\n&gt; **Meta**: Antes de crear pipelines complejos, domina el patr\u00f3n b\u00e1sico.\n\n**Ejercicio 1: Pipeline m\u00ednimo**\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\n# TU TAREA: Crea un pipeline con scaler + modelo\npipeline = Pipeline([\n    # paso 1: escalar\n    # paso 2: modelo\n])\n\n# Entrenar\npipeline.fit(X_train, y_train)\n\n# Predecir (\u00bfnecesitas transformar X_test manualmente?)\npredictions = pipeline.predict(X_test)\n</code></pre></p> <p>Ejercicio 2: Guardar y cargar <pre><code>import joblib\n\n# Guardar\njoblib.dump(pipeline, \"pipeline.pkl\")\n\n# En otro script/proceso\npipeline_loaded = joblib.load(\"pipeline.pkl\")\n\n# TU TAREA: \u00bfQu\u00e9 contiene pipeline_loaded?\n# \u00bfNecesitas re-entrenar el scaler?\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code># Ejercicio 1\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', LogisticRegression())\n])\n\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)\n# NO necesitas transformar X_test manualmente\n# pipeline.predict() lo hace internamente\n\n# Ejercicio 2\n# pipeline_loaded contiene:\n# - StandardScaler YA fitted (con mean/std de X_train)\n# - LogisticRegression YA entrenado\n# NO necesitas re-entrenar nada\n# Puedes predecir directamente\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#practica-del-portafolio-pipeline-de-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Pipeline de BankChurn","text":"<p>Tarea: Explorar y entender el pipeline de BankChurn-Predictor.</p> <p>Paso 1: Localiza el pipeline <pre><code>cd BankChurn-Predictor\nfind . -name \"*.pkl\" -o -name \"pipeline*\"\n</code></pre></p> <p>Paso 2: Inspecciona la estructura <pre><code>import joblib\n\npipeline = joblib.load(\"artifacts/pipeline.pkl\")  # o ruta correcta\nprint(pipeline)\nprint(pipeline.named_steps)\n</code></pre></p> <p>Paso 3: Entiende los pasos <pre><code># \u00bfQu\u00e9 transformador se usa para num\u00e9ricas?\n# \u00bfQu\u00e9 encoder para categ\u00f3ricas?\n# \u00bfQu\u00e9 modelo final?\n</code></pre></p> <p>Paso 4: Verifica consistencia <pre><code># Carga datos de test\n# \u00bfpipeline.predict() funciona sin preprocesamiento manual?\n</code></pre></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#checkpoint-de-conocimiento-pipelines","title":"\u2705 Checkpoint de Conocimiento: Pipelines","text":"<p>Pregunta 1: \u00bfCu\u00e1l es la ventaja principal de guardar <code>pipeline.pkl</code> vs <code>model.pkl</code>?</p> <p>A) Es m\u00e1s peque\u00f1o B) Incluye preprocesamiento con par\u00e1metros de entrenamiento C) Es m\u00e1s r\u00e1pido D) sklearn lo requiere  </p> <p>Pregunta 2: \u00bfQu\u00e9 hace <code>ColumnTransformer</code>?</p> <p>A) Transforma una columna B) Aplica DIFERENTES transformaciones a DIFERENTES grupos de columnas en paralelo C) Concatena DataFrames D) Filtra columnas  </p> <p>Pregunta 3: Si usas <code>OneHotEncoder(handle_unknown='ignore')</code>, \u00bfqu\u00e9 pasa con una categor\u00eda nueva en producci\u00f3n?</p> <p>A) Error B) Se ignora (todos los valores de esa categor\u00eda ser\u00e1n 0) C) Se crea una nueva columna D) El modelo se reentrena  </p> <p>\ud83d\udd27 Escenario de Debugging:</p> <pre><code># Training\npipeline.fit(X_train, y_train)\njoblib.dump(pipeline, \"pipeline.pkl\")\n\n# Production (meses despu\u00e9s)\npipeline = joblib.load(\"pipeline.pkl\")\nX_new = get_new_data()  # Nuevo request\npred = pipeline.predict(X_new)\n# ERROR: ValueError: columns in X are different from training\n</code></pre> <p>\u00bfCu\u00e1l es el problema y c\u00f3mo lo solucionar\u00edas?</p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Incluye preprocesamiento con par\u00e1metros de entrenamiento. Sin esto, tienes training-serving skew.  **Pregunta 2**: B) Aplica DIFERENTES transformaciones a DIFERENTES grupos de columnas en paralelo.  **Pregunta 3**: B) Se ignora. La fila tendr\u00e1 0s en todas las columnas de esa feature. Mejor que crashear.  **Escenario de Debugging**:  - **Problema**: X_new tiene columnas diferentes (nombre, orden, o cantidad) que X_train. - **Soluci\u00f3n**:    1. Asegurar que X_new tenga EXACTAMENTE las mismas columnas que X_train   2. Usar Pydantic para validar el schema de entrada   3. Documentar las columnas esperadas <pre><code>expected_cols = ['CreditScore', 'Age', 'Balance', ...]\nX_new = X_new[expected_cols]  # Seleccionar y ordenar\n</code></pre> <p><pre><code>---\n\n&lt;a id=\"72-columntransformer-transformaciones-paralelas\"&gt;&lt;/a&gt;\n\n## 7.2 ColumnTransformer: Transformaciones Paralelas\n\n### El Problema: Diferentes Columnas, Diferentes Tratamientos\n</code></pre> Datos de un banco: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 CreditScore \u2502 Geography \u2502 Gender  \u2502   Age   \u2502 Balance\u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502     619     \u2502  France   \u2502  Female \u2502    42   \u2502  10000 \u2502 \u2502     608     \u2502   Spain   \u2502  Female \u2502    41   \u2502  83808 \u2502 \u2502     502     \u2502  France   \u2502  Female \u2502    42   \u2502      0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518</p> <p>Columnas num\u00e9ricas (CreditScore, Age, Balance): \u2192 StandardScaler: normalizar a mean=0, std=1</p> <p>Columnas categ\u00f3ricas (Geography, Gender): \u2192 OneHotEncoder: convertir a columnas binarias <pre><code>### ColumnTransformer: La Soluci\u00f3n Elegante\n\n```python\nfrom sklearn.compose import ColumnTransformer        # Enruta transformaciones por grupos de columnas.\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder  # Transformadores est\u00e1ndar.\nfrom sklearn.impute import SimpleImputer             # Imputa valores faltantes (NaN).\nfrom sklearn.pipeline import Pipeline                # Encadena pasos secuenciales.\n\n# Definir qu\u00e9 columnas son de cada tipo\nnum_cols = [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"NumOfProducts\", \"EstimatedSalary\"]  # Num\u00e9ricas.\ncat_cols = [\"Geography\", \"Gender\"]                   # Categ\u00f3ricas: valores discretos/textuales.\n\n# Pipeline para num\u00e9ricas: Imputar NaN \u2192 Escalar\nnum_pipeline = Pipeline([                            # Pipeline DENTRO de ColumnTransformer.\n    ('imputer', SimpleImputer(strategy='median')),   # Rellena NaN con mediana (robusto a outliers).\n    ('scaler', StandardScaler())                     # Normaliza a mean=0, std=1.\n])\n\n# Pipeline para categ\u00f3ricas: Imputar NaN \u2192 One-Hot\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),  # NaN \u2192 string \"Unknown\".\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # ignore: categor\u00edas nuevas \u2192 vector de ceros.\n])\n\n# ColumnTransformer: Aplica cada pipeline a sus columnas\npreprocessor = ColumnTransformer(\n    transformers=[                                   # Lista de transformadores.\n        ('num', num_pipeline, num_cols),             # (nombre, transformer, columnas_a_transformar).\n        ('cat', cat_pipeline, cat_cols)              # Cada grupo se procesa independientemente.\n    ],\n    remainder='drop'                                 # 'drop': elimina columnas no listadas. 'passthrough': las deja.\n)\n\n# Resultado: Un solo objeto que sabe transformar todo\nX_processed = preprocessor.fit_transform(X_train)   # fit: aprende par\u00e1metros; transform: aplica.\n</code></pre></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#visualizacion-del-flujo","title":"Visualizaci\u00f3n del Flujo","text":"<pre><code>                        ColumnTransformer\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502               \u2502               \u2502\n              \u25bc               \u25bc               \u25bc\n        num_pipeline    cat_pipeline      remainder\n              \u2502               \u2502               \u2502\n              \u2502               \u2502               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502               \u2502\n    \u2502                   \u2502     \u2502               \u2502\n    \u25bc                   \u25bc     \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   drop\n\u2502Imputer  \u2502       \u2502 Scaler  \u2502 \u2502 Imputer \u2502\n\u2502(median) \u2502       \u2502         \u2502 \u2502(Unknown)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                                   \u25bc\n                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                              \u2502 OneHot  \u2502\n                              \u2502 Encoder \u2502\n                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502                    \u2502                    \u2502\n              \u25bc                    \u25bc                    \u25bc\n    [6 columnas num\u00e9ricas]  [3 Geography cols]  [2 Gender cols]\n         escaladas            (France, Spain,     (Female, Male)\n                               Germany)\n\n    Output: 11 columnas totales (6 + 3 + 2)\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#73-custom-transformers-tu-superpoder","title":"7.3 Custom Transformers: Tu Superpoder","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#cuando-crear-un-custom-transformer","title":"\u00bfCu\u00e1ndo Crear un Custom Transformer?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  Crea un Custom Transformer cuando:                                       \u2551\n\u2551                                                                           \u2551\n\u2551  \u2705 Necesitas feature engineering espec\u00edfico del dominio                  \u2551\n\u2551  \u2705 La transformaci\u00f3n debe aplicarse igual en train y producci\u00f3n          \u2551\n\u2551  \u2705 sklearn no tiene un transformer que haga lo que necesitas             \u2551\n\u2551                                                                           \u2551\n\u2551  Ejemplos del portafolio:                                                 \u2551\n\u2551  \u2022 CarVision: Calcular vehicle_age desde model_year                       \u2551\n\u2551  \u2022 CarVision: Extraer brand desde model                                   \u2551\n\u2551  \u2022 BankChurn: Resampling para clases desbalanceadas                       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejemplo-1-featureengineer-carvision","title":"Ejemplo 1: FeatureEngineer (CarVision)","text":"<pre><code># src/carvision/features.py - C\u00f3digo REAL del portafolio\n\nfrom __future__ import annotations\n\nfrom typing import Optional\n\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Centralized feature engineering to ensure consistency across\n    Training, Inference, and Analysis.\n\n    Este transformer garantiza que las mismas transformaciones\n    se apliquen en:\n    1. Entrenamiento (training.py)\n    2. Inferencia API (fastapi_app.py)\n    3. Dashboard (streamlit_app.py)\n\n    Attributes\n    ----------\n    current_year : int, optional\n        A\u00f1o para calcular vehicle_age. Si None, usa a\u00f1o actual.\n\n    Examples\n    --------\n    &gt;&gt;&gt; fe = FeatureEngineer(current_year=2024)\n    &gt;&gt;&gt; df_transformed = fe.fit_transform(df)\n    &gt;&gt;&gt; print(df_transformed.columns)\n    # Incluye: vehicle_age, brand (derivadas de model_year y model)\n    \"\"\"\n\n    def __init__(self, current_year: Optional[int] = None):\n        self.current_year = current_year\n\n    def fit(self, X: pd.DataFrame, y: pd.DataFrame = None) -&gt; \"FeatureEngineer\":\n        \"\"\"Fit no hace nada (stateless transformer).\"\"\"\n        # Este transformer es stateless: no aprende nada de los datos\n        # Solo necesita fit() para ser compatible con Pipeline\n        return self\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Aplica feature engineering.\n\n        Features creadas:\n        - vehicle_age: current_year - model_year\n        - brand: primera palabra de model\n        - price_per_mile: price / odometer (solo si price existe)\n        \"\"\"\n        X = X.copy()  # \u2190 Nunca modificar el input original\n\n        # Usar a\u00f1o configurado o a\u00f1o actual\n        year = self.current_year or pd.Timestamp.now().year\n\n        # Feature: Edad del veh\u00edculo\n        if \"model_year\" in X.columns:\n            X[\"vehicle_age\"] = year - X[\"model_year\"]\n\n        # Feature: Marca (primera palabra del modelo)\n        if \"model\" in X.columns:\n            X[\"brand\"] = X[\"model\"].astype(str).str.split().str[0]\n\n        # Features derivadas (solo en training, no en inferencia)\n        # Porque price no est\u00e1 disponible en inferencia\n        if \"odometer\" in X.columns and \"price\" in X.columns:\n            X[\"price_per_mile\"] = X[\"price\"] / (X[\"odometer\"] + 1)\n\n        return X\n\n    # M\u00e9todos opcionales para mejor introspecci\u00f3n\n    def get_feature_names_out(self, input_features=None):\n        \"\"\"Retorna nombres de features de salida.\"\"\"\n        base = list(input_features) if input_features else []\n        return base + [\"vehicle_age\", \"brand\"]\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejemplo-2-resampleclassifier-bankchurn","title":"Ejemplo 2: ResampleClassifier (BankChurn)","text":"<pre><code># src/bankchurn/models.py - C\u00f3digo REAL del portafolio\n\nfrom __future__ import annotations\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_is_fitted\n\n\nclass ResampleClassifier(BaseEstimator, ClassifierMixin):\n    \"\"\"Custom classifier with resampling for imbalanced datasets.\n\n    Implementa oversampling (SMOTE), undersampling, y class weighting\n    para mejorar performance en clasificaci\u00f3n desbalanceada.\n\n    Este wrapper permite:\n    1. Probar diferentes estrategias de resampling f\u00e1cilmente\n    2. Mantener la interfaz sklearn est\u00e1ndar (fit/predict)\n    3. Ser parte de un Pipeline (incluyendo GridSearchCV)\n\n    Parameters\n    ----------\n    estimator : estimator object, optional\n        Clasificador base. Si None, usa LogisticRegression.\n    strategy : {\"none\", \"oversample\", \"undersample\", \"class_weight\"}\n        Estrategia de resampling:\n        - \"none\": Sin resampling\n        - \"oversample\": SMOTE oversampling de clase minoritaria\n        - \"undersample\": Undersampling de clase mayoritaria\n        - \"class_weight\": Balanceo autom\u00e1tico de pesos\n    random_state : int, default=42\n        Semilla para reproducibilidad.\n\n    Examples\n    --------\n    &gt;&gt;&gt; clf = ResampleClassifier(\n    ...     estimator=RandomForestClassifier(),\n    ...     strategy=\"oversample\",\n    ...     random_state=42\n    ... )\n    &gt;&gt;&gt; clf.fit(X_train, y_train)\n    &gt;&gt;&gt; predictions = clf.predict(X_test)\n    \"\"\"\n\n    def __init__(\n        self,\n        estimator: BaseEstimator | None = None,\n        strategy: str = \"none\",\n        random_state: int = 42,\n    ) -&gt; None:\n        self.estimator = estimator\n        self.strategy = strategy\n        self.random_state = random_state\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -&gt; \"ResampleClassifier\":\n        \"\"\"Entrena el clasificador con resampling opcional.\"\"\"\n        from sklearn.linear_model import LogisticRegression\n\n        # Inicializar estimador si no se proporcion\u00f3\n        if self.estimator is None:\n            self.estimator_ = LogisticRegression(random_state=self.random_state)\n        else:\n            # Clonar para no modificar el original\n            from sklearn.base import clone\n            self.estimator_ = clone(self.estimator)\n\n        # Guardar clases (requerido por sklearn)\n        self.classes_ = np.unique(y)\n\n        # Aplicar estrategia de resampling\n        X_resampled, y_resampled = self._apply_resampling(X, y)\n\n        # Entrenar estimador base\n        self.estimator_.fit(X_resampled, y_resampled)\n\n        return self\n\n    def _apply_resampling(\n        self, X: np.ndarray, y: np.ndarray\n    ) -&gt; tuple[np.ndarray, np.ndarray]:\n        \"\"\"Aplica la estrategia de resampling.\"\"\"\n        if self.strategy == \"none\":\n            return X, y\n\n        elif self.strategy == \"oversample\":\n            try:\n                from imblearn.over_sampling import SMOTE\n                smote = SMOTE(random_state=self.random_state)\n                return smote.fit_resample(X, y)\n            except ImportError:\n                # Si imblearn no est\u00e1 instalado, ignorar\n                return X, y\n\n        elif self.strategy == \"undersample\":\n            try:\n                from imblearn.under_sampling import RandomUnderSampler\n                rus = RandomUnderSampler(random_state=self.random_state)\n                return rus.fit_resample(X, y)\n            except ImportError:\n                return X, y\n\n        elif self.strategy == \"class_weight\":\n            # No modifica datos, el estimador maneja los pesos\n            if hasattr(self.estimator_, 'class_weight'):\n                self.estimator_.set_params(class_weight='balanced')\n            return X, y\n\n        else:\n            raise ValueError(f\"Unknown strategy: {self.strategy}\")\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predice clases.\"\"\"\n        check_is_fitted(self, ['estimator_', 'classes_'])\n        return self.estimator_.predict(X)\n\n    def predict_proba(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predice probabilidades.\"\"\"\n        check_is_fitted(self, ['estimator_', 'classes_'])\n        return self.estimator_.predict_proba(X)\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#la-plantilla-crea-tu-propio-transformer","title":"La Plantilla: Crea Tu Propio Transformer","text":"<pre><code>from sklearn.base import BaseEstimator, TransformerMixin\n\nclass MiTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Plantilla para crear transformers custom.\n\n    REGLAS IMPORTANTES:\n    1. __init__ solo guarda par\u00e1metros (no computa nada)\n    2. fit() aprende de los datos (puede ser no-op)\n    3. transform() aplica la transformaci\u00f3n\n    4. Nunca modificar input, siempre X.copy()\n    \"\"\"\n\n    def __init__(self, param1: str = \"default\", param2: int = 10):\n        # Solo guardar par\u00e1metros, NO computar nada\n        self.param1 = param1\n        self.param2 = param2\n\n    def fit(self, X, y=None):\n        \"\"\"Aprende de los datos (opcional).\n\n        Ejemplos de qu\u00e9 aprender:\n        - Media/std para normalizaci\u00f3n\n        - Vocabulario para encoding\n        - Umbrales para binning\n        \"\"\"\n        # Si el transformer es stateless, solo retorna self\n        # Si aprende algo:\n        # self.learned_param_ = compute_something(X)\n        return self\n\n    def transform(self, X):\n        \"\"\"Aplica la transformaci\u00f3n.\"\"\"\n        X = X.copy()  # \u2190 Siempre copiar\n        # ... tu l\u00f3gica de transformaci\u00f3n ...\n        return X\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#74-pipeline-completo-codigo-real","title":"7.4 Pipeline Completo: C\u00f3digo Real","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#carvision-el-pipeline-de-3-etapas","title":"CarVision: El Pipeline de 3 Etapas","text":"<pre><code># src/carvision/training.py - Pipeline REAL del portafolio\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom src.carvision.features import FeatureEngineer\n\ndef build_pipeline(cfg: dict) -&gt; Pipeline:\n    \"\"\"Construye el pipeline completo de CarVision.\n\n    Estructura: Features \u2192 Preprocessing \u2192 Model\n\n    Esta arquitectura de 3 etapas garantiza:\n    1. Feature engineering consistente (FeatureEngineer)\n    2. Preprocesamiento apropiado por tipo de columna (ColumnTransformer)\n    3. Modelo entrenado con datos correctamente transformados\n    \"\"\"\n    # Par\u00e1metros de configuraci\u00f3n\n    num_cols = cfg[\"preprocessing\"][\"numeric_features\"]\n    cat_cols = cfg[\"preprocessing\"][\"categorical_features\"]\n    dataset_year = cfg.get(\"dataset_year\", 2024)\n    rf_params = cfg[\"training\"].get(\"random_forest_params\", {})\n\n    # Etapa 1: Feature Engineering\n    feature_engineer = FeatureEngineer(current_year=dataset_year)\n\n    # Etapa 2: Preprocessing (despu\u00e9s de feature engineering)\n    # Nota: Las columnas aqu\u00ed son las que EXISTEN despu\u00e9s del FeatureEngineer\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', Pipeline([\n                ('imputer', SimpleImputer(strategy='median')),\n                ('scaler', StandardScaler())\n            ]), num_cols),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n            ]), cat_cols)\n        ],\n        remainder='drop'\n    )\n\n    # Etapa 3: Modelo\n    model = RandomForestRegressor(**rf_params)\n\n    # Pipeline completo: Una sola unidad entrenable/guardable\n    pipeline = Pipeline([\n        ('features', feature_engineer),    # Crea vehicle_age, brand\n        ('pre', preprocessor),              # Escala y encoda\n        ('model', model)                    # Predice\n    ])\n\n    return pipeline\n\n\n# === USO ===\n# Entrenamiento\npipeline = build_pipeline(config)\npipeline.fit(X_train, y_train)\n\n# Guardar TODO junto\njoblib.dump(pipeline, \"artifacts/model.joblib\")\n\n# Producci\u00f3n\npipeline = joblib.load(\"artifacts/model.joblib\")\nprice = pipeline.predict(X_new)  # Una llamada hace TODO\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#bankchurn-pipeline-con-ensemble","title":"BankChurn: Pipeline con Ensemble","text":"<pre><code># src/bankchurn/training.py - Pipeline REAL del portafolio\n\ndef build_pipeline(self) -&gt; Pipeline:\n    \"\"\"Construye el pipeline de BankChurn.\n\n    Estructura:\n    - Preprocessing: ColumnTransformer (num + cat)\n    - Model: VotingClassifier o ResampleClassifier\n    \"\"\"\n    # Columnas desde config\n    num_cols = self.config.data.numerical_features\n    cat_cols = self.config.data.categorical_features\n\n    # Preprocessing\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', Pipeline([\n                ('imputer', SimpleImputer(strategy='median')),\n                ('scaler', StandardScaler())\n            ]), num_cols),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), cat_cols)\n        ]\n    )\n\n    # Modelo: Ensemble o single model\n    if self.config.model.type == \"ensemble\":\n        model = VotingClassifier(\n            estimators=[\n                ('lr', LogisticRegression(\n                    **self.config.model.logistic_regression.dict()\n                )),\n                ('rf', RandomForestClassifier(\n                    **self.config.model.random_forest.dict()\n                ))\n            ],\n            voting=self.config.model.ensemble.voting,\n            weights=self.config.model.ensemble.weights\n        )\n    else:\n        # Con wrapper de resampling\n        model = ResampleClassifier(\n            estimator=RandomForestClassifier(\n                **self.config.model.random_forest.dict()\n            ),\n            strategy=self.config.model.resampling_strategy,\n            random_state=self.random_state\n        )\n\n    # Pipeline final\n    return Pipeline([\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#75-ejercicios-practicos","title":"7.5 Ejercicios Pr\u00e1cticos","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-1-construir-un-columntransformer","title":"Ejercicio 1: Construir un ColumnTransformer","text":"<pre><code># Datos de telecom:\n# - calls: float (num\u00e9rico)\n# - minutes: float (num\u00e9rico)\n# - messages: int (num\u00e9rico)\n# - mb_used: float (num\u00e9rico)\n# - plan_type: str (categ\u00f3rico) - \"basic\", \"premium\"\n# - region: str (categ\u00f3rico) - \"north\", \"south\", \"east\", \"west\"\n\n# Tu tarea: Crea un ColumnTransformer que:\n# 1. Escale las columnas num\u00e9ricas con StandardScaler\n# 2. Encode las columnas categ\u00f3ricas con OneHotEncoder\n# 3. Maneje valores faltantes apropiadamente\n\nnum_cols = [\"calls\", \"minutes\", \"messages\", \"mb_used\"]\ncat_cols = [\"plan_type\", \"region\"]\n\n# Escribe tu c\u00f3digo aqu\u00ed:\npreprocessor = ColumnTransformer(\n    # ...\n)\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\nnum_cols = [\"calls\", \"minutes\", \"messages\", \"mb_used\"]\ncat_cols = [\"plan_type\", \"region\"]\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), num_cols),\n        ('cat', Pipeline([\n            ('imputer', SimpleImputer(strategy='most_frequent')),\n            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n        ]), cat_cols)\n    ],\n    remainder='drop'\n)\n\n# Verificar\nprint(f\"Transformers: {[t[0] for t in preprocessor.transformers]}\")\n# Output: ['num', 'cat']\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-2-crear-un-custom-transformer","title":"Ejercicio 2: Crear un Custom Transformer","text":"<pre><code># Tu tarea: Crea un transformer que calcule ratios de uso de telecom\n# \n# Features a crear:\n# - minutes_per_call = minutes / (calls + 1)\n# - mb_per_message = mb_used / (messages + 1)\n# - total_usage = calls + messages + (mb_used / 1000)\n#\n# Requisitos:\n# - Debe heredar de BaseEstimator y TransformerMixin\n# - fit() debe retornar self\n# - transform() debe retornar DataFrame con nuevas columnas\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass TelecomFeatureEngineer(BaseEstimator, TransformerMixin):\n    # Tu c\u00f3digo aqu\u00ed\n    pass\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\n\n\nclass TelecomFeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Feature engineering para datos de telecom.\"\"\"\n\n    def __init__(self):\n        pass\n\n    def fit(self, X: pd.DataFrame, y=None):\n        \"\"\"No aprende nada (stateless).\"\"\"\n        return self\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"Crea features derivadas.\"\"\"\n        X = X.copy()\n\n        # Minutos por llamada\n        if \"minutes\" in X.columns and \"calls\" in X.columns:\n            X[\"minutes_per_call\"] = X[\"minutes\"] / (X[\"calls\"] + 1)\n\n        # MB por mensaje\n        if \"mb_used\" in X.columns and \"messages\" in X.columns:\n            X[\"mb_per_message\"] = X[\"mb_used\"] / (X[\"messages\"] + 1)\n\n        # Uso total normalizado\n        if all(col in X.columns for col in [\"calls\", \"messages\", \"mb_used\"]):\n            X[\"total_usage\"] = X[\"calls\"] + X[\"messages\"] + (X[\"mb_used\"] / 1000)\n\n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        \"\"\"Retorna nombres de features creadas.\"\"\"\n        return [\"minutes_per_call\", \"mb_per_message\", \"total_usage\"]\n\n\n# Verificar\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"calls\": [50, 100],\n    \"minutes\": [200, 500],\n    \"messages\": [100, 50],\n    \"mb_used\": [5000, 10000]\n})\n\nfe = TelecomFeatureEngineer()\ndf_transformed = fe.fit_transform(df)\nprint(df_transformed.columns.tolist())\n# Output incluye: minutes_per_call, mb_per_message, total_usage\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-3-pipeline-completo-para-telecomai","title":"Ejercicio 3: Pipeline Completo para TelecomAI","text":"<pre><code># Tu tarea: Construye un pipeline completo para TelecomAI\n# \n# Estructura:\n# 1. TelecomFeatureEngineer (del ejercicio anterior)\n# 2. ColumnTransformer para preprocessing\n# 3. LogisticRegression como modelo\n#\n# El pipeline debe ser guardable con joblib\n\n# Tu c\u00f3digo aqu\u00ed:\ndef build_telecom_pipeline():\n    pass\n</code></pre> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\n\n\ndef build_telecom_pipeline(config: dict = None) -&gt; Pipeline:\n    \"\"\"Construye pipeline completo para TelecomAI.\"\"\"\n\n    # Configuraci\u00f3n por defecto\n    if config is None:\n        config = {\n            \"num_cols\": [\"calls\", \"minutes\", \"messages\", \"mb_used\", \n                        \"minutes_per_call\", \"mb_per_message\", \"total_usage\"],\n            \"cat_cols\": [],\n            \"random_state\": 42\n        }\n\n    num_cols = config[\"num_cols\"]\n    cat_cols = config.get(\"cat_cols\", [])\n\n    # Etapa 1: Feature Engineering\n    feature_engineer = TelecomFeatureEngineer()\n\n    # Etapa 2: Preprocessing\n    transformers = [\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), num_cols)\n    ]\n\n    if cat_cols:\n        transformers.append(\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='most_frequent')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), cat_cols)\n        )\n\n    preprocessor = ColumnTransformer(\n        transformers=transformers,\n        remainder='drop'\n    )\n\n    # Etapa 3: Modelo\n    model = LogisticRegression(\n        random_state=config.get(\"random_state\", 42),\n        max_iter=1000\n    )\n\n    # Pipeline completo\n    pipeline = Pipeline([\n        ('features', feature_engineer),\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n\n    return pipeline\n\n\n# Uso\npipeline = build_telecom_pipeline()\n# pipeline.fit(X_train, y_train)\n# joblib.dump(pipeline, \"artifacts/model.joblib\")\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#76-ingenieria-inversa-pedagogica-columntransformer-real","title":"7.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: ColumnTransformer Real","text":"<p>Objetivo: Entender las decisiones del preprocesamiento del portafolio.</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#761-el-por-que-arquitectonico","title":"7.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo manejo NaN en categ\u00f3ricas vs num\u00e9ricas?                      \u2502\n\u2502  DECISI\u00d3N: Pipeline separado: median para num, \"missing\" para cat               \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfQu\u00e9 pasa si llega una categor\u00eda nueva en producci\u00f3n?              \u2502\n\u2502  DECISI\u00d3N: OneHotEncoder(handle_unknown=\"ignore\") \u2192 ceros                       \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo guardo preprocesador + modelo juntos?                        \u2502\n\u2502  DECISI\u00d3N: Pipeline(preprocessor + classifier) como unidad at\u00f3mica              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#762-anatomia-del-columntransformer","title":"7.6.2 \ud83d\udd0d Anatom\u00eda del ColumnTransformer","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/src/bankchurn/training.py</code></p> <pre><code># Pipeline CATEG\u00d3RICO: maneja variables como Geography, Gender, etc.\ndef _build_categorical_pipeline(self) -&gt; Pipeline:\n    return Pipeline([\n        (\"imputer\", SimpleImputer(                # Paso 1: Imputar NaN.\n            strategy=\"constant\",                  # Estrategia: valor constante.\n            fill_value=\"missing\"                  # NaN \u2192 \"missing\" (nueva categor\u00eda).\n        )),\n        (\"onehot\", OneHotEncoder(                 # Paso 2: One-hot encoding.\n            drop=\"first\",                         # Evita dummy variable trap.\n            handle_unknown=\"ignore\",              # CR\u00cdTICO: categor\u00edas nuevas \u2192 ceros.\n        )),\n    ])\n\n# Pipeline NUM\u00c9RICO: maneja variables como Age, Balance, CreditScore.\ndef _build_numerical_pipeline(self) -&gt; Pipeline:\n    return Pipeline([\n        (\"imputer\", SimpleImputer(                # Paso 1: Imputar NaN.\n            strategy=\"median\"                     # Mediana: robusta a outliers.\n        )),\n        (\"scaler\", StandardScaler()),             # Paso 2: Normalizar a media=0, std=1.\n    ])\n\n# ColumnTransformer: aplica pipelines a columnas espec\u00edficas.\nreturn ColumnTransformer(\n    transformers=transformers,                    # Lista de (nombre, pipeline, columnas).\n    remainder=\"drop\"                              # IMPORTANTE: ignora columnas no listadas.\n)\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#763-troubleshooting","title":"7.6.3 \ud83d\udea8 Troubleshooting","text":"S\u00edntoma Soluci\u00f3n \"X has N features, expecting M\" <code>remainder=\"drop\"</code> + orden fijo \"unknown categories\" <code>handle_unknown=\"ignore\"</code>"},{"location":"docs/07_SKLEARN_PIPELINES/#errores-habituales-y-como-depurarlos-en-sklearn-pipelines","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en sklearn Pipelines","text":"<p>Los errores en este m\u00f3dulo rara vez son \u201cfallos ex\u00f3ticos\u201d del algoritmo; casi siempre son desalineaciones entre datos, columnas, transformers y c\u00f3mo guardas/cargas el pipeline.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#1-valueerror-number-of-features-does-not-match-mismatch-entre-train-e-inference","title":"1) <code>ValueError: number of features does not match</code> (mismatch entre train e inference)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En entrenamiento todo bien, pero al predecir obtienes:   <pre><code>ValueError: X has 15 features, but StandardScaler is expecting 12 features as input.\n</code></pre></li> <li>O bien errores de \u00edndice similares en <code>OneHotEncoder</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica que usas el mismo pipeline serializado en training e inference:</li> <li>\u00bfGuardas y cargas <code>pipeline.pkl</code>/<code>model.joblib</code>, o solo el modelo suelto?</li> <li>Comprueba que las columnas de entrada en producci\u00f3n tienen el mismo orden y nombres que en entrenamiento.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>En el portafolio, siempre serializa el pipeline completo:   <pre><code>joblib.dump(pipeline, \"artifacts/model.joblib\")\npipeline = joblib.load(\"artifacts/model.joblib\")\n</code></pre></li> <li>Aseg\u00farate de que el orden y nombres de columnas que construyes en la API/Streamlit coincidan con las listas <code>num_cols</code> y <code>cat_cols</code> del pipeline.</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#2-data-leakage-por-features-que-usan-el-target-especialmente-en-carvision","title":"2) Data leakage por features que usan el target (especialmente en CarVision)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>M\u00e9tricas en training/validation son sospechosamente altas, pero en producci\u00f3n caen.</li> <li>Features como <code>price_per_mile</code> o <code>price_category</code> dependen de la variable objetivo (<code>price</code>).</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Examina tu <code>FeatureEngineer</code> y lista de columnas que entran al modelo:</li> <li>\u00bfEst\u00e1s incluyendo columnas derivadas del target en el <code>ColumnTransformer</code>?</li> <li>Revisa tu config (<code>cfg[\"preprocessing\"][\"numeric_features\"]</code>, etc.) y confirma que solo incluyes features v\u00e1lidos.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de que features que dependen del target no se usen como input del modelo.</li> <li>En CarVision, por ejemplo, <code>price_per_mile</code> y <code>price_category</code> se calculan solo para an\u00e1lisis, pero se excluyen de <code>num_cols</code> para el pipeline.</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#3-custom-transformers-que-modifican-el-input-in-place-o-no-respetan-la-api-sklearn","title":"3) Custom transformers que modifican el input in-place o no respetan la API sklearn","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores del tipo:   <pre><code>TypeError: __init__() takes 1 positional argument but 2 were given\n</code></pre>   o   <pre><code>AttributeError: 'MiTransformer' object has no attribute 'fit'\n</code></pre></li> <li>Comportamientos raros donde un transformer \u201censucia\u201d los datos para otros steps.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa que tu transformer:</li> <li>Herede de <code>BaseEstimator</code> y <code>TransformerMixin</code>.</li> <li>Tenga <code>__init__</code>, <code>fit</code>, <code>transform</code> con las firmas est\u00e1ndar.</li> <li>Use <code>X = X.copy()</code> dentro de <code>transform</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa la plantilla de este m\u00f3dulo (<code>MiTransformer</code>) como referencia.</li> <li>Evita l\u00f3gica pesada en <code>__init__</code>; ah\u00ed solo se guardan par\u00e1metros.</li> <li>A\u00f1ade tests unitarios simples (<code>fit_transform</code> sobre un <code>DataFrame</code> peque\u00f1o) para validar que mantiene columnas esperadas.</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#4-pipelines-diferentes-en-training-y-en-la-api","title":"4) Pipelines diferentes en training y en la API","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El pipeline usado en <code>training.py</code> no coincide con el que se monta en <code>fastapi_app.py</code> o <code>streamlit_app.py</code>.</li> <li>Bugs donde la API aplica transformaciones manuales adem\u00e1s del pipeline.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Busca en el proyecto si est\u00e1s construyendo pipelines duplicados:</li> <li>En CarVision, la \u00fanica fuente de verdad debe ser <code>build_pipeline</code> en <code>src/carvision/training.py</code>.</li> <li>La API y Streamlit solo deber\u00edan cargar el pipeline serializado, no recrearlo a mano.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Centraliza la construcci\u00f3n del pipeline en una funci\u00f3n (<code>build_pipeline</code> / <code>build_telecom_pipeline</code>).</li> <li>En la API/Streamlit, no replicar l\u00f3gicas de preprocesado; limitarse a cargar y usar el pipeline.</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#5-patron-general-de-debugging-para-pipelines","title":"5) Patr\u00f3n general de debugging para pipelines","text":"<ol> <li>Reproduce el error con un input m\u00ednimo (1\u20132 filas de <code>DataFrame</code>).</li> <li>Inspecciona shapes y columnas tras cada etapa:</li> <li>Usa <code>pipeline.named_steps[\"pre\"].transform(X_sample)</code> o similares.</li> <li>Verifica la serializaci\u00f3n: guarda, vuelve a cargar, y compara predicciones en un mismo batch.</li> <li>Conecta el problema con el concepto del m\u00f3dulo:</li> <li>Training-serving skew \u2192 pipeline parcial o mal serializado.</li> <li>Mismatch de columnas \u2192 listas <code>num_cols</code>/<code>cat_cols</code> desincronizadas.</li> <li>Transformers rotos \u2192 no respetan <code>fit</code>/<code>transform</code>.</li> </ol> <p>Con este enfoque, los pipelines dejan de ser una \u201ccaja negra m\u00e1gica\u201d y se convierten en una l\u00ednea de ensamblaje transparente y depurable.</p> <p></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#checkpoint-completaste-el-modulo","title":"\u2705 Checkpoint: \u00bfCompletaste el M\u00f3dulo?","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#checklist","title":"Checklist","text":"<ul> <li>[ ] Sabes usar ColumnTransformer para diferentes tipos de columnas</li> <li>[ ] Puedes crear un Custom Transformer con fit/transform</li> <li>[ ] Has construido un pipeline de 3 etapas (features \u2192 preprocessing \u2192 model)</li> <li>[ ] Puedes guardar y cargar un pipeline completo con joblib</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#adr-decisiones-de-arquitectura","title":"\ud83d\udd17 ADR: Decisiones de Arquitectura","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#adr-007-pipeline-unificado-obligatorio","title":"ADR-007: Pipeline Unificado Obligatorio","text":"<p>Contexto: Transformaciones separadas causan inconsistencias en producci\u00f3n.</p> <p>Decisi\u00f3n: Todo el flujo (features \u2192 preprocessing \u2192 model) debe estar en un solo Pipeline.</p> <p>Consecuencias: - \u2705 Una sola serializaci\u00f3n guarda todo - \u2705 Imposible olvidar una transformaci\u00f3n - \u2705 Reproducibilidad garantizada - \u274c M\u00e1s complejo de debuggear (caja negra) - \u274c Requiere entender sklearn profundamente</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#adr-008-custom-transformers-para-feature-engineering","title":"ADR-008: Custom Transformers para Feature Engineering","text":"<p>Contexto: sklearn no tiene transformers para l\u00f3gica de negocio espec\u00edfica.</p> <p>Decisi\u00f3n: Crear FeatureEngineer como TransformerMixin.</p> <p>Consecuencias: - \u2705 Reutilizable en train, API, y dashboard - \u2705 Testeable unitariamente - \u2705 Documentaci\u00f3n clara de features derivadas - \u274c M\u00e1s c\u00f3digo que escribir - \u274c Requiere entender BaseEstimator/TransformerMixin</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>Los pipelines sklearn son el coraz\u00f3n de los 3 proyectos del portafolio:</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#pipeline-unificado-de-bankchurn","title":"Pipeline Unificado de BankChurn","text":"<pre><code># BankChurn-Predictor/src/bankchurn/pipeline.py (estructura real)\ndef build_pipeline(config: BankChurnConfig) -&gt; Pipeline:\n    \"\"\"Pipeline completo de 3 etapas.\"\"\"\n    return Pipeline([\n        ('preprocessor', ColumnTransformer([\n            ('num', Pipeline([\n                ('imputer', SimpleImputer(strategy='median')),\n                ('scaler', StandardScaler())\n            ]), config.data.numerical_features),\n            ('cat', Pipeline([\n                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n            ]), config.data.categorical_features)\n        ])),\n        ('model', get_model(config))\n    ])\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#featureengineer-de-carvision","title":"FeatureEngineer de CarVision","text":"<pre><code># CarVision-Market-Intelligence/src/carvision/features.py\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Custom transformer para features de autos.\"\"\"\n\n    def __init__(self, current_year: int = None):\n        self.current_year = current_year\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        # vehicle_age, brand, mileage_category, etc.\n        return X\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#archivos-clave-por-proyecto","title":"Archivos Clave por Proyecto","text":"Proyecto Pipeline Features Artefacto BankChurn <code>src/bankchurn/pipeline.py</code> En preprocessor <code>artifacts/pipeline.joblib</code> CarVision <code>src/carvision/pipeline.py</code> <code>src/carvision/features.py</code> <code>artifacts/pipeline.joblib</code> TelecomAI <code>src/telecomai/training.py</code> En pipeline <code>artifacts/model.joblib</code>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-explora-los-pipelines-reales","title":"\ud83d\udd27 Ejercicio: Explora los Pipelines Reales","text":"<pre><code># 1. Ve a BankChurn y carga el pipeline\ncd BankChurn-Predictor\npython -c \"\nimport joblib\npipe = joblib.load('artifacts/pipeline.joblib')\nprint('Steps:', [name for name, _ in pipe.steps])\nprint('Preprocessor:', pipe.named_steps['preprocessor'])\n\"\n\n# 2. Inspecciona el FeatureEngineer de CarVision\ncat CarVision-Market-Intelligence/src/carvision/features.py\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>\u00bfPor qu\u00e9 Pipelines?: Evitan data leakage, garantizan reproducibilidad, simplifican deployment.</p> </li> <li> <p>Custom Transformers: Demuestra que puedes crear transformadores con <code>fit()</code> y <code>transform()</code>.</p> </li> <li> <p>ColumnTransformer: Explica c\u00f3mo aplicar diferentes transformaciones a diferentes columnas.</p> </li> </ol>"},{"location":"docs/07_SKLEARN_PIPELINES/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Features nuevas A\u00f1ade transformadores al pipeline, no c\u00f3digo suelto Debugging Usa <code>pipeline.named_steps</code> para inspeccionar etapas Producci\u00f3n Serializa el pipeline completo, no solo el modelo Testing Testea cada transformador individualmente"},{"location":"docs/07_SKLEARN_PIPELINES/#patrones-avanzados","title":"Patrones Avanzados","text":"<ul> <li>FeatureUnion: Combinar features de diferentes fuentes</li> <li>Pipeline dentro de Pipeline: Para transformaciones complejas</li> <li>make_pipeline: Sintaxis simplificada sin nombres</li> <li>clone: Para cross-validation sin modificar original</li> </ul>"},{"location":"docs/07_SKLEARN_PIPELINES/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Sklearn Pipeline Tutorial Data School 28 min YouTube \ud83d\udd34 ColumnTransformer Explained Data School 35 min YouTube \ud83d\udfe1 Custom Transformers in Sklearn PyData 32 min YouTube \ud83d\udfe2 Sklearn Pipeline Best Practices PyData Berlin 45 min YouTube"},{"location":"docs/07_SKLEARN_PIPELINES/#cursos","title":"\ud83d\udcda Cursos","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Duraci\u00f3n Link \ud83d\udd34 ML Pipelines with scikit-learn DataCamp 4h DataCamp \ud83d\udfe1 Feature Engineering for ML Coursera (Google) 5 weeks Coursera"},{"location":"docs/07_SKLEARN_PIPELINES/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 sklearn Pipeline User Guide Gu\u00eda oficial de pipelines \ud83d\udfe1 Custom Transformers C\u00f3mo crear transformers custom"},{"location":"docs/07_SKLEARN_PIPELINES/#decision-tecnica-adr-002-scikit-learn","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-002 scikit-learn","text":"<p>Contexto: Necesitamos un framework ML para clasificaci\u00f3n/regresi\u00f3n tabular.</p> <p>Decisi\u00f3n: Usar scikit-learn como framework principal.</p> <p>Alternativas Consideradas: - XGBoost/LightGBM: M\u00e1s performance, menos integraci\u00f3n con pipelines - PyTorch: Overkill para datos tabulares</p> <p>Consecuencias: - \u2705 Pipelines unificados con <code>Pipeline</code> y <code>ColumnTransformer</code> - \u2705 F\u00e1cil de testear y serializar - \u2705 Documentaci\u00f3n excelente - \u274c Menos performance que gradient boosting dedicado</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-71-pipeline-basico","title":"Ejercicio 7.1: Pipeline B\u00e1sico","text":"<p>Objetivo: Crear un pipeline con preprocesamiento. Dificultad: \u2b50\u2b50</p> <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n# TU TAREA: Crear pipeline con:\n# 1. StandardScaler para features num\u00e9ricas\n# 2. RandomForestClassifier\n\npipe = Pipeline([\n    # TU C\u00d3DIGO\n])\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('classifier', RandomForestClassifier(\n        n_estimators=100,\n        random_state=42\n    ))\n])\n\n# Uso:\npipe.fit(X_train, y_train)\npredictions = pipe.predict(X_test)\n\n# Serializaci\u00f3n:\nimport joblib\njoblib.dump(pipe, 'artifacts/pipeline.joblib')\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-72-columntransformer","title":"Ejercicio 7.2: ColumnTransformer","text":"<p>Objetivo: Procesar columnas num\u00e9ricas y categ\u00f3ricas por separado. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># Dado un DataFrame con:\n# - numeric_cols = ['age', 'balance', 'salary']\n# - categorical_cols = ['geography', 'gender']\n\n# TU TAREA: Crear ColumnTransformer que:\n# - Aplique StandardScaler a num\u00e9ricas\n# - Aplique OneHotEncoder a categ\u00f3ricas\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\npreprocessor = ColumnTransformer([\n    # TU C\u00d3DIGO\n])\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\n\nnumeric_cols = ['age', 'balance', 'salary']\ncategorical_cols = ['geography', 'gender']\n\n# Pipelines individuales para cada tipo\nnumeric_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# ColumnTransformer combina ambos\npreprocessor = ColumnTransformer([\n    ('num', numeric_transformer, numeric_cols),\n    ('cat', categorical_transformer, categorical_cols)\n])\n\n# Pipeline completo con modelo\nfull_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(random_state=42))\n])\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-73-custom-transformer","title":"Ejercicio 7.3: Custom Transformer","text":"<p>Objetivo: Crear un transformer personalizado. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code>from sklearn.base import BaseEstimator, TransformerMixin\n\n# TU TAREA: Crear AgeGroupTransformer que:\n# - A\u00f1ada columna 'age_group' basada en rangos de edad\n# - 0-30: 'young', 31-50: 'middle', 51+: 'senior'\n\nclass AgeGroupTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        # TU C\u00d3DIGO\n        return self\n\n    def transform(self, X):\n        # TU C\u00d3DIGO\n        pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass AgeGroupTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Transformer que a\u00f1ade categor\u00eda de edad.\"\"\"\n\n    def __init__(self, age_column: str = 'age'):\n        self.age_column = age_column\n\n    def fit(self, X, y=None):\n        # No hay nada que aprender\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n\n        # Crear bins de edad\n        bins = [0, 30, 50, np.inf]\n        labels = ['young', 'middle', 'senior']\n\n        X['age_group'] = pd.cut(\n            X[self.age_column],\n            bins=bins,\n            labels=labels\n        )\n        return X\n\n    def get_feature_names_out(self, input_features=None):\n        \"\"\"Para compatibilidad con sklearn &gt;= 1.0\"\"\"\n        return list(input_features) + ['age_group']\n\n\n# Uso en pipeline:\npipeline = Pipeline([\n    ('age_groups', AgeGroupTransformer(age_column='age')),\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier())\n])\n</code></pre>"},{"location":"docs/07_SKLEARN_PIPELINES/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Pipeline Cadena de transformaciones + modelo que se serializa como unidad ColumnTransformer Aplica diferentes transformaciones a diferentes columnas en paralelo Data Leakage Filtraci\u00f3n de informaci\u00f3n del target al training, causando m\u00e9tricas infladas fit_transform M\u00e9todo que aprende par\u00e1metros y transforma en un solo paso"},{"location":"docs/07_SKLEARN_PIPELINES/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#trampa-1-data-leakage-con-fit_transform-en-todo-el-dataset","title":"Trampa 1: Data leakage con fit_transform en todo el dataset","text":"<p>S\u00edntoma: M\u00e9tricas de cross-validation: 0.95, m\u00e9tricas en producci\u00f3n: 0.72</p> <p>Causa ra\u00edz: <pre><code># \u274c LEAKAGE\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # fit en TODO X (incluye test)\nX_train, X_test = train_test_split(X_scaled)\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># \u2705 SIN LEAKAGE\nX_train, X_test = train_test_split(X)  # Split PRIMERO\npipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"model\", RandomForestClassifier())\n])\npipeline.fit(X_train, y_train)  # fit SOLO en train\n</code></pre></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#trampa-2-columntransformer-pierde-nombres-de-columnas","title":"Trampa 2: ColumnTransformer pierde nombres de columnas","text":"<p>S\u00edntoma: <pre><code>X_transformed = preprocessor.fit_transform(X)\nprint(type(X_transformed))  # numpy.ndarray \u2190 \u00a1Perd\u00ed los nombres!\n</code></pre></p> <p>Soluci\u00f3n (sklearn &gt;= 1.2): <pre><code>preprocessor.set_output(transform=\"pandas\")  # \u2190 Retorna DataFrame\n</code></pre></p>"},{"location":"docs/07_SKLEARN_PIPELINES/#trampa-3-custom-transformer-sin-retornar-self-en-fit","title":"Trampa 3: Custom Transformer sin retornar self en fit","text":"<p>S\u00edntoma: <pre><code>def fit(self, X, y=None):\n    self.mean_ = X.mean()\n    # \u2190 Olvid\u00e9 return self\n\n# AttributeError: 'NoneType' object has no attribute 'transform'\n</code></pre></p> <p>Soluci\u00f3n: Siempre <code>return self</code> en el m\u00e9todo <code>fit()</code>.</p>"},{"location":"docs/07_SKLEARN_PIPELINES/#quiz-del-modulo-semanas-7-8","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 7-8","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#quiz-semana-7-sklearn-pipelines","title":"Quiz Semana 7: sklearn Pipelines","text":""},{"location":"docs/07_SKLEARN_PIPELINES/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfQu\u00e9 problema resuelve sklearn <code>Pipeline</code>?</p> \u2705 Respuesta  1. **Data leakage**: Encapsula fit/transform para que siempre se apliquen correctamente 2. **Reproducibilidad**: Un solo objeto `.pkl` contiene todo el preprocesamiento + modelo 3. **C\u00f3digo m\u00e1s limpio**: Una llamada a `pipeline.predict()` en lugar de 10 l\u00edneas 4. **Cross-validation correcto**: `cross_val_score(pipeline, X, y)` hace fit/transform por fold"},{"location":"docs/07_SKLEARN_PIPELINES/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPor qu\u00e9 <code>ColumnTransformer</code> es necesario?</p> \u2705 Respuesta  Columnas diferentes necesitan transformaciones diferentes: - **Num\u00e9ricas**: Imputar \u2192 Escalar - **Categ\u00f3ricas**: Imputar \u2192 OneHot/Target Encode  ColumnTransformer aplica cada pipeline al subset correcto de columnas."},{"location":"docs/07_SKLEARN_PIPELINES/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfQu\u00e9 hace <code>handle_unknown=\"ignore\"</code> en <code>OneHotEncoder</code>?</p> \u2705 Respuesta  En producci\u00f3n pueden llegar categor\u00edas no vistas en training: - `\"error\"` (default): Lanza error si ve categor\u00eda nueva - `\"ignore\"`: Pone 0 en todas las columnas one-hot - **Recomendaci\u00f3n**: Siempre usar `\"ignore\"` para producci\u00f3n."},{"location":"docs/07_SKLEARN_PIPELINES/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea un Pipeline que impute num\u00e9ricas con mediana, escale, impute categ\u00f3ricas con moda, one-hot encode, y use RandomForestClassifier.</p> \u2705 Soluci\u00f3n <pre><code>from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer([\n    (\"num\", num_pipeline, numerical_cols),\n    (\"cat\", cat_pipeline, categorical_cols)\n])\n\npipeline = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"classifier\", RandomForestClassifier(class_weight=\"balanced\"))\n])\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [08. Ingenier\u00eda de Features](08_INGENIERIA_FEATURES.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/08_INGENIERIA_FEATURES/","title":"08. Ingenier\u00eda de Features para ML","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Dominar la creaci\u00f3n de features sin introducir data leakage, el error m\u00e1s peligroso y dif\u00edcil de detectar en ML.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \ud83d\udea8 DATA LEAKAGE: El Asesino Silencioso de Modelos                           \u2551\n\u2551                                                                              \u2551\n\u2551  Tu modelo tiene 99% accuracy en validaci\u00f3n...                               \u2551\n\u2551  ...pero 50% en producci\u00f3n.                                                  \u2551\n\u2551                                                                              \u2551\n\u2551  \u00bfPor qu\u00e9? Porque durante el entrenamiento, el modelo \"vio\" informaci\u00f3n      \u2551\n\u2551  que NO tendr\u00e1 disponible cuando haga predicciones reales.                   \u2551\n\u2551                                                                              \u2551\n\u2551  Es como estudiar para un examen con las respuestas en la mano.              \u2551\n\u2551  Sacas 100 en el examen de pr\u00e1ctica, pero 0 en el real.                      \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p></p>"},{"location":"docs/08_INGENIERIA_FEATURES/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 07_SKLEARN_PIPELINES (pipelines unificados, serializaci\u00f3n).</li> <li>Entender que un score alto en validaci\u00f3n puede ser enga\u00f1oso si hay leakage.</li> <li>Tener claro cu\u00e1l es tu target por proyecto (BankChurn: churn, CarVision: price, Telecom: churn/upsell).</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de crear features: abre Protocolo E y define tu output m\u00ednimo (ej: lista de features seguras + reglas anti-leakage).</li> <li>Mientras depuras leakage: si te atoras &gt;15 min (m\u00e9tricas irreales, features sospechosas, splits temporales), registra el caso en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para auditar tu dataset y tu pipeline de features.</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Checklist anti-leakage aplicada (qu\u00e9 se permite / qu\u00e9 se proh\u00edbe).</li> <li>[ ] Features seguras integradas dentro del pipeline (no c\u00f3digo suelto).</li> <li>[ ] Evidencia: explicaci\u00f3n breve de por qu\u00e9 tus features no usan informaci\u00f3n del target/futuro.</li> </ul> <p></p>"},{"location":"docs/08_INGENIERIA_FEATURES/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: leakage (target/temporal/contaminaci\u00f3n)</li> <li>Archivo: <code>src/&lt;paquete&gt;/features.py</code>, <code>src/&lt;paquete&gt;/training.py</code>, <code>configs/*.yaml</code></li> <li>Prueba: comparar m\u00e9tricas con/ sin feature sospechosa y justificar la decisi\u00f3n.</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>\u00bfQu\u00e9 es Data Leakage?</li> <li>Tipos de Leakage en ML</li> <li>Caso Real: CarVision</li> <li>Prevenci\u00f3n con Pipelines</li> <li>Feature Engineering Seguro</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#81-que-es-data-leakage","title":"8.1 \u00bfQu\u00e9 es Data Leakage?","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#la-analogia-del-detective","title":"La Analog\u00eda del Detective","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83d\udd0d IMAGINA UN DETECTIVE RESOLVIENDO UN CASO:                             \u2551\n\u2551                                                                           \u2551\n\u2551  SIN LEAKAGE (correcto):                                                  \u2551\n\u2551  \u2022 El detective solo tiene las pistas disponibles AL MOMENTO del crimen   \u2551\n\u2551  \u2022 Debe deducir qui\u00e9n es el culpable con informaci\u00f3n limitada             \u2551\n\u2551  \u2022 Es dif\u00edcil, pero es la realidad                                        \u2551\n\u2551                                                                           \u2551\n\u2551  CON LEAKAGE (trampa):                                                    \u2551\n\u2551  \u2022 El detective tiene acceso al informe FINAL del caso                    \u2551\n\u2551  \u2022 Ya sabe qui\u00e9n es el culpable antes de investigar                       \u2551\n\u2551  \u2022 \"Resuelve\" el caso f\u00e1cilmente, pero no aprendi\u00f3 nada                   \u2551\n\u2551                                                                           \u2551\n\u2551  EN ML:                                                                   \u2551\n\u2551  \u2022 El modelo debe predecir usando SOLO informaci\u00f3n disponible             \u2551\n\u2551    en el momento de la predicci\u00f3n                                         \u2551\n\u2551  \u2022 Si usas informaci\u00f3n del futuro o del target, es TRAMPA                 \u2551\n\u2551                                                                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#mapa-mental-de-conceptos-feature-engineering-seguro","title":"\ud83e\udde0 Mapa Mental de Conceptos: Feature Engineering Seguro","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551    FEATURE ENGINEERING SIN LEAKAGE   \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  TIPOS LEAKAGE   \u2502              \u2502  FEATURES OK     \u2502              \u2502  PREVENCI\u00d3N      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 Target leakage                \u251c\u2500 Datos del pasado            \u251c\u2500 Split temporal\n\u251c\u2500 Temporal leakage              \u251c\u2500 Info disponible             \u251c\u2500 Pipeline unificado\n\u251c\u2500 Contaminaci\u00f3n train/test      \u2502   en producci\u00f3n              \u251c\u2500 Validaci\u00f3n cruzada\n\u2514\u2500 Agregados con futuro          \u2514\u2500 Features derivadas          \u2514\u2500 Checklist audit\n                                     de features OK\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> Tipo de Leakage Descripci\u00f3n Ejemplo Target leakage Feature calculada usando el target <code>price_per_mile = price / odometer</code> Temporal leakage Usar datos del futuro Media de ventas incluyendo ma\u00f1ana Contaminaci\u00f3n Train/test comparten info Normalizar antes de split"},{"location":"docs/08_INGENIERIA_FEATURES/#ejercicio-puente-detectar-leakage","title":"\ud83d\udcbb Ejercicio Puente: Detectar Leakage","text":"<p>Meta: Antes de crear features complejas, aprende a detectar leakage.</p> <p>Ejercicio: \u00bfCu\u00e1les tienen leakage? <pre><code>Contexto: Predecir si un cliente abandonar\u00e1 (churn)\n\nFeature 1: edad_cliente\nFeature 2: dias_desde_ultimo_login  \nFeature 3: razon_cancelacion (motivo que dio al cancelar)\nFeature 4: productos_activos\nFeature 5: promedio_transacciones_futuras (pr\u00f3ximos 30 d\u00edas)\n\nTU TAREA: Marca cu\u00e1les tienen leakage y por qu\u00e9\n</code></pre></p> \ud83d\udd0d Ver Soluci\u00f3n <pre><code>Feature 1: edad_cliente \u2192 \u2705 OK (disponible en producci\u00f3n)\nFeature 2: dias_desde_ultimo_login \u2192 \u2705 OK (disponible)\nFeature 3: razon_cancelacion \u2192 \u274c LEAKAGE (solo existe SI ya cancel\u00f3)\nFeature 4: productos_activos \u2192 \u2705 OK (disponible)\nFeature 5: promedio_transacciones_futuras \u2192 \u274c LEAKAGE TEMPORAL (info del futuro)\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#checkpoint-de-conocimiento-feature-engineering","title":"\u2705 Checkpoint de Conocimiento: Feature Engineering","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 <code>price_per_mile = price / odometer</code> es leakage si quieres predecir <code>price</code>?</p> <p>A) Porque usa demasiadas columnas B) Porque la feature CONTIENE informaci\u00f3n del target C) Porque es muy f\u00e1cil de calcular D) Porque sklearn no lo soporta  </p> <p>Pregunta 2: Si tu modelo tiene 99% accuracy en validaci\u00f3n pero 50% en producci\u00f3n, \u00bfqu\u00e9 es lo m\u00e1s probable?</p> <p>A) El modelo es muy bueno B) Hay data leakage en las features o el split C) Producci\u00f3n tiene m\u00e1s datos D) sklearn tiene un bug  </p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) La feature CONTIENE informaci\u00f3n del target. El modelo \"aprende\" a despejar, no a predecir.  **Pregunta 2**: B) Hay data leakage. Performance irreal en validaci\u00f3n + ca\u00edda en producci\u00f3n = se\u00f1al cl\u00e1sica de leakage."},{"location":"docs/08_INGENIERIA_FEATURES/#ejemplo-clasico-predecir-precio-con-precio_per_mile","title":"Ejemplo Cl\u00e1sico: Predecir Precio con precio_per_mile","text":"<pre><code># \u274c LEAKAGE: Usando feature derivada del target\n\n# Datos originales\ndf = pd.DataFrame({\n    'price': [15000, 25000, 35000],      # Target a predecir (lo que queremos estimar).\n    'odometer': [80000, 50000, 20000],   # Feature leg\u00edtima (disponible en producci\u00f3n).\n})\n\n# Feature engineering INCORRECTO\ndf['price_per_mile'] = df['price'] / df['odometer']  # \u2190 LEAKAGE! Usa el target.\n\n# \u00bfPor qu\u00e9 es leakage?\n# price_per_mile = price / odometer       # La feature CONTIENE informaci\u00f3n del target.\n# Por lo tanto: price = price_per_mile * odometer  # El modelo solo aprende a despejar.\n# El modelo \"aprende\" a multiplicar, no a predecir precios reales.\n\n# En producci\u00f3n:\n# - No tienes el price (es lo que quieres predecir)  # No puedes usar lo que no conoces.\n# - No puedes calcular price_per_mile               # Feature imposible de crear.\n# - El modelo no sabe qu\u00e9 hacer                     # Crash o predicci\u00f3n sin sentido.\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#82-tipos-de-leakage","title":"8.2 Tipos de Leakage","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#1-target-leakage-feature-contiene-informacion-del-target","title":"1. Target Leakage (Feature contiene informaci\u00f3n del target)","text":"<pre><code># \u274c MALO: Feature calculada con el target\ndf['price_category'] = pd.cut(df['price'], bins=[0, 10000, 50000, inf])  # pd.cut: discretiza valores continuos.\n\n# El modelo aprende: \"si price_category es 'alto', predice price alto\"  # Correlaci\u00f3n perfecta = trampa.\n# Pero en producci\u00f3n NO tienes price_category porque no tienes price    # Feature inexistente en inferencia.\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#2-train-test-contamination-datos-de-test-filtrados-a-train","title":"2. Train-Test Contamination (Datos de test \"filtrados\" a train)","text":"<pre><code># \u274c MALO: Normalizar ANTES de split\nscaler = StandardScaler()             # Crea el scaler.\nX_scaled = scaler.fit_transform(X)    # fit_transform en TODO X: aprende mean/std de train+test.\nX_train, X_test = train_test_split(X_scaled)  # Split DESPU\u00c9S de transformar.\n# El scaler \"vio\" datos de test durante fit   # Contaminaci\u00f3n: test influye en transformaci\u00f3n.\n\n# \u2705 CORRECTO: Normalizar DESPU\u00c9S de split\nX_train, X_test = train_test_split(X)         # Split PRIMERO.\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)  # fit solo en train: aprende mean/std de train.\nX_test_scaled = scaler.transform(X_test)        # transform (no fit): usa params de train.\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#3-temporal-leakage-usar-informacion-del-futuro","title":"3. Temporal Leakage (Usar informaci\u00f3n del futuro)","text":"<pre><code># \u274c MALO: Predecir churn de enero usando datos de febrero\ndf['avg_purchases_next_month'] = ...  # Informaci\u00f3n del futuro: imposible conocerla al predecir.\n\n# \u2705 CORRECTO: Solo usar informaci\u00f3n disponible al momento de predicci\u00f3n\ndf['avg_purchases_last_3_months'] = ...  # Informaci\u00f3n del pasado: siempre disponible.\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#83-caso-real-carvision","title":"8.3 Caso Real: CarVision","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#el-problema-original","title":"El Problema Original","text":"<p>En CarVision, ten\u00edamos features que causaban leakage:</p> <pre><code># src/carvision/features.py - ANTES (con leakage potencial)\n\nclass FeatureEngineer:\n    def transform(self, X):\n        X = X.copy()\n\n        # \u2705 OK: vehicle_age no depende del target\n        X['vehicle_age'] = 2024 - X['model_year']\n\n        # \u2705 OK: brand no depende del target\n        X['brand'] = X['model'].str.split().str[0]\n\n        # \u26a0\ufe0f PELIGRO: price_per_mile DEPENDE de price (target)\n        X['price_per_mile'] = X['price'] / (X['odometer'] + 1)\n\n        # \u26a0\ufe0f PELIGRO: price_category DEPENDE de price (target)\n        X['price_category'] = pd.cut(X['price'], ...)\n\n        return X\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#la-solucion-drop_columns-en-config","title":"La Soluci\u00f3n: drop_columns en Config","text":"<pre><code># configs/config.yaml\n\npreprocessing:\n  numeric_features:\n    - odometer\n    - vehicle_age\n  categorical_features:\n    - fuel\n    - transmission\n    - brand\n  drop_columns:           # \u2190 Features que causan leakage\n    - price_per_mile      # Depende de price\n    - price_category      # Depende de price\n</code></pre> <pre><code># src/carvision/data.py\n\ndef infer_feature_types(df, target, drop_columns=None, ...):\n    \"\"\"Infiere tipos de features, excluyendo las que causan leakage.\"\"\"\n\n    # Columnas a excluir\n    exclude = {target}  # Siempre excluir el target\n    if drop_columns:\n        exclude.update(drop_columns)  # Excluir features con leakage\n\n    # Inferir tipos solo de columnas seguras\n    for col in df.columns:\n        if col in exclude:\n            continue  # Saltar columnas peligrosas\n        # ... resto de la l\u00f3gica\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#por-que-no-eliminamos-price_per_mile-del-featureengineer","title":"\u00bfPor qu\u00e9 NO eliminamos price_per_mile del FeatureEngineer?","text":"<pre><code># La feature EXISTE en el transformer, pero se ELIMINA antes del modelo\n\n# Motivo: price_per_mile es \u00fatil para AN\u00c1LISIS (no para predicci\u00f3n)\n# En el dashboard de Streamlit, usamos price_per_mile para visualizaciones\n# Pero en el modelo de predicci\u00f3n, la eliminamos\n\n# Flujo:\n# 1. FeatureEngineer crea price_per_mile (para an\u00e1lisis)\n# 2. Config especifica drop_columns = [price_per_mile]\n# 3. ColumnTransformer NO incluye price_per_mile en sus transformers\n# 4. Modelo entrena sin price_per_mile\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#84-prevencion-con-pipelines","title":"8.4 Prevenci\u00f3n con Pipelines","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#el-pipeline-como-barrera-anti-leakage","title":"El Pipeline como Barrera Anti-Leakage","text":"<pre><code># \u2705 CORRECTO: Pipeline garantiza orden correcto\n\nfrom sklearn.pipeline import Pipeline       # Pipeline: encadena pasos de forma segura.\nfrom sklearn.compose import ColumnTransformer  # ColumnTransformer: transforma por grupos de columnas.\n\n# Definir QU\u00c9 columnas usar (excluyendo las peligrosas)\nnum_cols = ['odometer', 'vehicle_age']      # Features num\u00e9ricas SEGURAS (sin leakage).\ncat_cols = ['fuel', 'transmission', 'brand']  # Features categ\u00f3ricas SEGURAS.\n\n# Pipeline aplica transformaciones EN ORDEN\npipeline = Pipeline([                        # Lista de tuplas (nombre, transformador).\n    ('features', FeatureEngineer()),         # Paso 1: crea vehicle_age, brand, etc.\n    ('pre', ColumnTransformer([              # Paso 2: transforma solo columnas SEGURAS.\n        ('num', StandardScaler(), num_cols), # Escala num\u00e9ricas (aprende mean/std de train).\n        ('cat', OneHotEncoder(), cat_cols)   # One-hot encodes categ\u00f3ricas.\n    ])),\n    ('model', RandomForestRegressor())       # Paso 3: el modelo.\n])\n\n# fit() entrena todo con datos de TRAIN solamente\npipeline.fit(X_train, y_train)               # fit propaga por todos los pasos secuencialmente.\n\n# predict() aplica las MISMAS transformaciones\n# usando par\u00e1metros aprendidos de TRAIN\npredictions = pipeline.predict(X_test)       # predict: transforma X_test con params de train, luego predice.\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#diagrama-del-flujo-seguro","title":"Diagrama del Flujo Seguro","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     FLUJO ANTI-LEAKAGE CON PIPELINE                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  ENTRENAMIENTO:                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502 X_train  \u2502\u2500\u2500\u2500\u25ba\u2502FeatureEng      \u2502\u2500\u2500\u2500\u25ba\u2502DropDanger  \u2502\u2500\u2500\u2500\u25ba\u2502 Scaler   \u2502       \u2502\n\u2502  \u2502          \u2502    \u2502 (crea features)\u2502    \u2502 (elimina   \u2502    \u2502 fit()    \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  leakage)  \u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502             \u2502\n\u2502                                                               \u25bc             \u2502\n\u2502                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502                                                        \u2502  Model   \u2502         \u2502\n\u2502                                                        \u2502  fit()   \u2502         \u2502\n\u2502                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                                                                             \u2502\n\u2502  PREDICCI\u00d3N:                                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502  \u2502 X_new    \u2502\u2500\u2500\u2500\u25ba\u2502FeatureEng    \u2502\u2500\u2500\u2500\u25ba\u2502DropDanger  \u2502\u2500\u2500\u2500\u25ba\u2502 Scaler   \u2502         \u2502\n\u2502  \u2502          \u2502    \u2502 (mismas feat)\u2502    \u2502 (mismas    \u2502    \u2502transform \u2502         \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502  columnas) \u2502    \u2502 (NO fit) \u2502         \u2502\n\u2502                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                                                             \u2502               \u2502\n\u2502                                                             \u25bc               \u2502\n\u2502                                                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502                                                      \u2502  Model   \u2502           \u2502\n\u2502                                                      \u2502 predict()\u2502           \u2502\n\u2502                                                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#85-feature-engineering-seguro","title":"8.5 Feature Engineering Seguro","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#checklist-anti-leakage","title":"Checklist Anti-Leakage","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \u2705 CHECKLIST ANTES DE CREAR UNA FEATURE                                  \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                           \u2551\n\u2551  1. \u00bfEsta feature estar\u00e1 disponible en producci\u00f3n?                        \u2551\n\u2551     \u25a1 S\u00cd \u2192 OK                                                             \u2551\n\u2551     \u25a1 NO \u2192 \u274c NO USAR para predicci\u00f3n                                     \u2551\n\u2551                                                                           \u2551\n\u2551  2. \u00bfEsta feature usa informaci\u00f3n del target (directa o indirectamente)?  \u2551\n\u2551     \u25a1 NO \u2192 OK                                                             \u2551\n\u2551     \u25a1 S\u00cd \u2192 \u274c LEAKAGE - eliminar o recalcular sin target                  \u2551\n\u2551                                                                           \u2551\n\u2551  3. \u00bfEsta feature usa informaci\u00f3n del futuro?                             \u2551\n\u2551     \u25a1 NO \u2192 OK                                                             \u2551\n\u2551     \u25a1 S\u00cd \u2192 \u274c TEMPORAL LEAKAGE - usar solo datos pasados                  \u2551\n\u2551                                                                           \u2551\n\u2551  4. \u00bfLas estad\u00edsticas de esta feature se calcularon con datos de test?    \u2551\n\u2551     \u25a1 NO \u2192 OK                                                             \u2551\n\u2551     \u25a1 S\u00cd \u2192 \u274c TRAIN-TEST CONTAMINATION - recalcular solo con train        \u2551\n\u2551                                                                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#features-seguras-vs-peligrosas","title":"Features Seguras vs Peligrosas","text":"Feature Segura Motivo <code>vehicle_age = 2024 - model_year</code> \u2705 No depende del target <code>brand = model.split()[0]</code> \u2705 No depende del target <code>is_luxury = brand in ['bmw', 'mercedes']</code> \u2705 No depende del target <code>price_per_mile = price / odometer</code> \u274c Usa el target (price) <code>price_category = cut(price)</code> \u274c Usa el target (price) <code>avg_price_by_brand</code> (calculado con todo el dataset) \u274c Contamina train/test"},{"location":"docs/08_INGENIERIA_FEATURES/#codigo-feature-engineering-seguro","title":"C\u00f3digo: Feature Engineering Seguro","text":"<pre><code># src/carvision/features.py - Versi\u00f3n SEGURA\n\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Feature engineering sin leakage.\"\"\"\n\n    def __init__(self, current_year: int = None):\n        self.current_year = current_year\n\n    def fit(self, X, y=None):\n        # Stateless: no aprende nada que pueda causar leakage\n        return self\n\n    def transform(self, X):\n        X = X.copy()\n        year = self.current_year or pd.Timestamp.now().year\n\n        # \u2705 SEGURO: Solo usa columnas de entrada (no target)\n        if 'model_year' in X.columns:\n            X['vehicle_age'] = year - X['model_year']\n\n        if 'model' in X.columns:\n            X['brand'] = X['model'].astype(str).str.split().str[0]\n\n        # \u26a0\ufe0f CONDICIONAL: Solo crear si price existe (para an\u00e1lisis)\n        # El modelo NO usar\u00e1 estas features (drop_columns en config)\n        if 'price' in X.columns and 'odometer' in X.columns:\n            X['price_per_mile'] = X['price'] / (X['odometer'] + 1)\n\n        return X\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#checkpoint","title":"\u2705 Checkpoint","text":"<p>Si alg\u00fan punto de esta lista te tom\u00f3 &gt;15 minutos (o te dio un falso positivo de m\u00e9tricas), reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p> <ul> <li>[ ] Entiendes qu\u00e9 es data leakage y por qu\u00e9 es peligroso</li> <li>[ ] Puedes identificar los 3 tipos de leakage</li> <li>[ ] Sabes c\u00f3mo usar <code>drop_columns</code> para eliminar features peligrosas</li> <li>[ ] Entiendes por qu\u00e9 el Pipeline previene leakage</li> <li>[ ] Puedes aplicar el checklist anti-leakage a nuevas features</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El proyecto CarVision es el ejemplo principal de feature engineering seguro:</p>"},{"location":"docs/08_INGENIERIA_FEATURES/#featureengineer-centralizado","title":"FeatureEngineer Centralizado","text":"<pre><code># CarVision-Market-Intelligence/src/carvision/features.py\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Centraliza TODO el feature engineering.\n\n    Usado en: training, FastAPI, Streamlit - siempre igual.\n    \"\"\"\n\n    def __init__(self, current_year: int = None):\n        self.current_year = current_year\n\n    def transform(self, X):\n        X = X.copy()\n        year = self.current_year or pd.Timestamp.now().year\n\n        # \u2705 Features SEGURAS (no usan target)\n        X['vehicle_age'] = year - X['model_year']\n        X['brand'] = X['model'].str.split().str[0]\n        X['mileage_category'] = pd.cut(X['odometer'], bins=[0, 50000, 100000, float('inf')])\n\n        return X\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#prevencion-de-leakage-en-config","title":"Prevenci\u00f3n de Leakage en Config","text":"<pre><code># CarVision-Market-Intelligence/configs/config.yaml\ndata:\n  target_column: price\n  drop_columns:\n    - price_per_mile    # \u274c Usa target\n    - price_category    # \u274c Usa target\n    - id                # No predictivo\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#caso-real-bug-corregido","title":"Caso Real: Bug Corregido","text":"<p>El portafolio tuvo un bug de leakage que fue corregido:</p> <pre><code># \u274c ANTES (con leakage)\nX['price_per_mile'] = X['price'] / X['odometer']  # Usaba el target!\n\n# \u2705 DESPU\u00c9S (sin leakage)\n# price_per_mile se elimina en drop_columns\n# Solo se calcula para an\u00e1lisis exploratorio, NO para el modelo\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#archivos-clave","title":"Archivos Clave","text":"Proyecto Feature Engineering Anti-Leakage CarVision <code>src/carvision/features.py</code> <code>drop_columns</code> en config BankChurn En <code>ColumnTransformer</code> Sin features derivadas del target TelecomAI En pipeline Sin features peligrosas"},{"location":"docs/08_INGENIERIA_FEATURES/#ejercicio-audita-carvision","title":"\ud83d\udd27 Ejercicio: Audita CarVision","text":"<pre><code># 1. Revisa el FeatureEngineer\ncat CarVision-Market-Intelligence/src/carvision/features.py\n\n# 2. Verifica drop_columns en config\ncat CarVision-Market-Intelligence/configs/config.yaml | grep -A5 \"drop_columns\"\n\n# 3. Ejecuta tests para verificar que no hay leakage\ncd CarVision-Market-Intelligence\npytest tests/test_features.py -v\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/08_INGENIERIA_FEATURES/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Feature Store: Explica por qu\u00e9 centralizar features mejora consistencia training/serving.</p> </li> <li> <p>Data Leakage: Da ejemplos concretos (usar target en features, informaci\u00f3n del futuro).</p> </li> <li> <p>Feature Selection: Conoce m\u00e9todos (mutual information, RFE, importancia de modelo).</p> </li> </ol>"},{"location":"docs/08_INGENIERIA_FEATURES/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Features temporales Cuidado con leakage: no uses info futura Categor\u00edas nuevas Usa <code>handle_unknown='ignore'</code> en encoders Features de texto TF-IDF para baseline, embeddings para avanzado Interacciones PolynomialFeatures con grado 2 m\u00e1ximo"},{"location":"docs/08_INGENIERIA_FEATURES/#checklist-de-feature-engineering","title":"Checklist de Feature Engineering","text":"<ul> <li>[ ] Sin data leakage verificado</li> <li>[ ] Transformaciones aplicadas consistentemente train/serve</li> <li>[ ] Features documentadas (significado, fuente, transformaci\u00f3n)</li> <li>[ ] Outliers manejados (clip, winsorize, o flag)</li> <li>[ ] Missing values con estrategia clara</li> </ul>"},{"location":"docs/08_INGENIERIA_FEATURES/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/08_INGENIERIA_FEATURES/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Feature Engineering for ML Krish Naik 35 min YouTube \ud83d\udd34 Avoiding Data Leakage StatQuest 15 min YouTube \ud83d\udfe1 Feature Stores Explained Feast 25 min YouTube"},{"location":"docs/08_INGENIERIA_FEATURES/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 sklearn Preprocessing Transformaciones est\u00e1ndar \ud83d\udfe1 Feature Engine Librer\u00eda de feature engineering"},{"location":"docs/08_INGENIERIA_FEATURES/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/08_INGENIERIA_FEATURES/#ejercicio-81-detectar-data-leakage","title":"Ejercicio 8.1: Detectar Data Leakage","text":"<p>Objetivo: Identificar fugas de informaci\u00f3n en features. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># \u00bfCu\u00e1les de estas features tienen data leakage para predecir churn?\nfeatures = [\n    'tenure',           # Meses como cliente\n    'monthly_charges',  # Cargo mensual\n    'total_charges',    # Total pagado\n    'contract_end_date',# Fecha fin contrato\n    'churn_reason',     # Raz\u00f3n de baja\n    'support_tickets',  # Tickets de soporte\n    'days_since_churn', # D\u00edas desde la baja\n]\n# TU TAREA: Clasifica cada feature como SAFE o LEAKAGE\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>features_analysis = {\n    'tenure': 'SAFE',           # Info disponible antes del churn\n    'monthly_charges': 'SAFE',  # Info disponible antes\n    'total_charges': 'SAFE',    # Calculable antes del churn\n    'contract_end_date': 'SAFE',# Conocido de antemano\n    'churn_reason': 'LEAKAGE',  # Solo existe DESPU\u00c9S del churn\n    'support_tickets': 'SAFE',  # Hist\u00f3rico antes del churn\n    'days_since_churn': 'LEAKAGE', # Informaci\u00f3n del futuro\n}\n\n# Regla: Si la feature solo puede conocerse DESPU\u00c9S del evento\n# que intentas predecir, es data leakage.\n\n# Casos sutiles de leakage:\n# - 'avg_monthly_charges_next_3_months' \u2192 Futuro\n# - 'last_login_before_churn' \u2192 Implica conocer cu\u00e1ndo fue el churn\n# - 'customer_segment_based_on_churn' \u2192 Derivada del target\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#ejercicio-82-pipeline-anti-leakage","title":"Ejercicio 8.2: Pipeline Anti-Leakage","text":"<p>Objetivo: Crear pipeline que evite leakage. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: \u00bfQu\u00e9 est\u00e1 mal en este c\u00f3digo?\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # Todo el dataset\n\nX_train, X_test = train_test_split(X_scaled, test_size=0.2)\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># PROBLEMA: El scaler ve datos de test antes del split\n# Esto es data leakage porque la media/std incluye test\n\n# CORRECTO: Fit solo en train\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# Opci\u00f3n 1: Split primero, luego fit\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)  # Fit en train\nX_test_scaled = scaler.transform(X_test)        # Solo transform en test\n\n# Opci\u00f3n 2 (mejor): Usar Pipeline\npipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', RandomForestClassifier())\n])\n\n# El pipeline hace fit solo en train autom\u00e1ticamente\npipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test)\n\n# En cross-validation, el pipeline garantiza\n# que cada fold hace fit solo en su train\ncross_val_score(pipeline, X, y, cv=5)  # Correcto!\n</code></pre>"},{"location":"docs/08_INGENIERIA_FEATURES/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Data Leakage Usar informaci\u00f3n del futuro o del target para crear features Feature Engineering Proceso de crear variables predictivas a partir de datos raw Feature Store Sistema centralizado para almacenar y servir features Target Encoding Codificar categor\u00edas usando la media del target (riesgo de leakage)   **Siguiente m\u00f3dulo** \u2192 [09. Training Profesional](09_TRAINING_PROFESIONAL.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/09_TRAINING_PROFESIONAL/","title":"09. Training Profesional","text":""},{"location":"docs/09_TRAINING_PROFESIONAL/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Implementar un pipeline de entrenamiento robusto, reproducible y loggeable como <code>ChurnTrainer</code> de BankChurn.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  NOTEBOOK T\u00cdPICO:                    C\u00d3DIGO PROFESIONAL:                     \u2551 \n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                    \u2551\n\u2551  \u2022 500 l\u00edneas en un archivo          \u2022 Clases modulares                      \u2551\n\u2551  \u2022 Variables globales                \u2022 Configuraci\u00f3n externa                 \u2551\n\u2551  \u2022 Sin logging                       \u2022 Logging estructurado                  \u2551\n\u2551  \u2022 \"Funcion\u00f3... creo\"                \u2022 M\u00e9tricas rastreadas                   \u2551\n\u2551  \u2022 Imposible reproducir              \u2022 100% reproducible                     \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<ul> <li>Este m\u00f3dulo se apoya directamente en el c\u00f3digo real de BankChurn-Predictor:</li> <li><code>src/bankchurn/training.py</code> (<code>ChurnTrainer</code>).</li> <li><code>configs/config.yaml</code> (config Pydantic usada en el trainer).</li> <li>Carpeta <code>artifacts/</code> donde se guardan <code>model.joblib</code> y <code>training_results.json</code>.</li> <li>Tambi\u00e9n establece el patr\u00f3n que luego deber\u00e1s replicar en CarVision y TelecomAI   (por ejemplo, implementando tu propio <code>PriceTrainer</code> o <code>TelecomTrainer</code>) y que se conecta   con los m\u00f3dulos de Experiment Tracking (MLflow) y CI/CD.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado 07_SKLEARN_PIPELINES (pipeline unificado, serializaci\u00f3n).</li> <li>Tener claro el target y el esquema de columnas del dataset.</li> <li>Entender el rol de CV, split, y seeds para reproducibilidad.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de entrenar: abre Protocolo E y define tu output m\u00ednimo (ej: <code>Trainer.run()</code> que deja artefactos + m\u00e9tricas).</li> <li>Durante el debugging: si te atoras &gt;15 min (splits, CV, m\u00e9tricas raras, MLflow), registra el caso en Diario de Errores.</li> <li>Al cerrar la semana: usa Cierre Semanal para auditar reproducibilidad y trazabilidad (artefactos + logs).</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<p>Al terminar este m\u00f3dulo, deber\u00edas poder mostrar (en al menos 1 proyecto del portafolio):</p> <ul> <li>[ ] Un <code>Trainer</code> con m\u00e9todo <code>run()</code> que produce artefactos en un directorio (<code>model.joblib</code>, <code>training_results.json</code>).</li> <li>[ ] Reproducibilidad: misma semilla \u2192 m\u00e9tricas consistentes (dentro de ruido razonable).</li> <li>[ ] Logging \u00fatil (split sizes, m\u00e9tricas CV/test, paths de salida).</li> </ul> <p></p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<p>Para que esto cuente como progreso real, fuerza este mapeo:</p> <ul> <li>Concepto: pipeline de entrenamiento auditable</li> <li>Archivo: <code>src/&lt;paquete&gt;/training.py</code>, <code>configs/config.yaml</code>, <code>artifacts/*</code></li> <li>Prueba: correr <code>Trainer.run()</code> dos veces con misma config/seed y comparar outputs.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>Arquitectura de una Clase Trainer</li> <li>Carga y Validaci\u00f3n de Datos</li> <li>Cross-Validation Profesional</li> <li>Gesti\u00f3n de Artefactos</li> <li>Logging y M\u00e9tricas</li> <li>\ud83d\udd2c Ingenier\u00eda Inversa: ChurnTrainer Real \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Ejercicio: Implementar tu Trainer</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#mapa-mental-de-conceptos-91-arquitectura-de-una-clase-trainer","title":"\ud83e\udde0 Mapa Mental de Conceptos: 9.1 Arquitectura de una Clase Trainer","text":"<p>T\u00e9rminos clave que debes dominar para este tema: - Revisa los conceptos principales en la secci\u00f3n siguiente - Practica con los ejercicios del portafolio - Aplica los conocimientos en BankChurn-Predictor</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#91-arquitectura-de-una-clase-trainer","title":"9.1 Arquitectura de una Clase Trainer","text":""},{"location":"docs/09_TRAINING_PROFESIONAL/#codigo-real-churntrainer-bankchurn","title":"C\u00f3digo Real: ChurnTrainer (BankChurn)","text":"<pre><code># src/bankchurn/training.py - Estructura REAL del portafolio\n\nfrom __future__ import annotations       # Permite usar tipos como \"Pipeline | None\" en Python 3.10+.\n\nimport logging                           # Logging para trazabilidad del entrenamiento.\nfrom pathlib import Path                 # Manejo de rutas multiplataforma.\nfrom typing import Dict, Tuple           # Type hints para documentar tipos.\n\nimport joblib                            # Serializaci\u00f3n de modelos sklearn.\nimport mlflow                            # Tracking de experimentos.\nimport numpy as np                       # Arrays num\u00e9ricos.\nimport pandas as pd                      # DataFrames para datos tabulares.\nfrom sklearn.model_selection import StratifiedKFold, train_test_split  # Split y CV.\nfrom sklearn.pipeline import Pipeline    # Pipeline unificado.\n\nfrom .config import BankChurnConfig      # Configuraci\u00f3n Pydantic del proyecto.\n\nlogger = logging.getLogger(__name__)     # Logger con nombre del m\u00f3dulo.\n\n\nclass ChurnTrainer:\n    \"\"\"Pipeline de entrenamiento para predicci\u00f3n de churn.\n\n    Esta clase encapsula TODO el flujo de entrenamiento:\n    1. Carga y validaci\u00f3n de datos\n    2. Preparaci\u00f3n de features\n    3. Construcci\u00f3n del pipeline\n    4. Entrenamiento con cross-validation\n    5. Evaluaci\u00f3n final\n    6. Guardado de artefactos\n\n    Parameters\n    ----------\n    config : BankChurnConfig\n        Configuraci\u00f3n validada con Pydantic.\n    random_state : int, optional\n        Semilla para reproducibilidad.\n\n    Attributes\n    ----------\n    model_ : Pipeline\n        Pipeline entrenado (disponible despu\u00e9s de fit).\n    cv_results_ : dict\n        Resultados de cross-validation.\n    test_results_ : dict\n        Resultados en test set.\n\n    Examples\n    --------\n    &gt;&gt;&gt; config = BankChurnConfig.from_yaml(\"configs/config.yaml\")\n    &gt;&gt;&gt; trainer = ChurnTrainer(config)\n    &gt;&gt;&gt; trainer.run(\"data/raw/churn.csv\", \"artifacts/\")\n    \"\"\"\n\n    def __init__(self, config: BankChurnConfig, random_state: int = None):\n        self.config = config\n        self.random_state = random_state or config.model.random_state\n\n        # Atributos que se llenan durante entrenamiento\n        self.model_: Pipeline | None = None\n        self.cv_results_: Dict[str, float] | None = None\n        self.test_results_: Dict[str, float] | None = None\n\n        # Configurar MLflow si est\u00e1 habilitado\n        if self.config.mlflow.enabled:\n            self._setup_mlflow()\n\n    def _setup_mlflow(self) -&gt; None:\n        \"\"\"Configura MLflow tracking.\"\"\"\n        try:\n            mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)\n            mlflow.set_experiment(self.config.mlflow.experiment_name)\n            logger.info(f\"MLflow tracking: {self.config.mlflow.tracking_uri}\")\n        except Exception as e:\n            logger.warning(f\"MLflow setup failed: {e}\")\n\n    def run(self, input_path: str | Path, output_dir: str | Path) -&gt; Dict:\n        \"\"\"Ejecuta el pipeline completo de entrenamiento.\n\n        Parameters\n        ----------\n        input_path : str or Path\n            Ruta al CSV de entrada.\n        output_dir : str or Path\n            Directorio para guardar artefactos.\n\n        Returns\n        -------\n        dict\n            Resultados de entrenamiento y evaluaci\u00f3n.\n        \"\"\"\n        output_dir = Path(output_dir)\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n        logger.info(\"=\" * 60)\n        logger.info(\"INICIANDO ENTRENAMIENTO\")\n        logger.info(\"=\" * 60)\n\n        # 1. Cargar datos\n        data = self.load_data(input_path)\n\n        # 2. Preparar features\n        X, y = self.prepare_features(data)\n\n        # 3. Split train/test\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y,\n            test_size=self.config.model.test_size,\n            random_state=self.random_state,\n            stratify=y  # Mantener proporci\u00f3n de clases\n        )\n        logger.info(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n\n        # 4. Construir pipeline\n        self.model_ = self.build_pipeline()\n\n        # 5. Cross-validation\n        self.cv_results_ = self.cross_validate(X_train, y_train)\n\n        # 6. Entrenar modelo final\n        self.model_.fit(X_train, y_train)\n\n        # 7. Evaluar en test\n        self.test_results_ = self.evaluate(X_test, y_test)\n\n        # 8. Guardar artefactos\n        self.save_artifacts(output_dir)\n\n        # 9. Log a MLflow\n        if self.config.mlflow.enabled:\n            self._log_to_mlflow()\n\n        logger.info(\"=\" * 60)\n        logger.info(\"ENTRENAMIENTO COMPLETADO\")\n        logger.info(\"=\" * 60)\n\n        return {\n            \"cv_results\": self.cv_results_,\n            \"test_results\": self.test_results_,\n        }\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#diagrama-del-flujo","title":"Diagrama del Flujo","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        ChurnTrainer.run() Flow                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502   \u2502 Config  \u2502\u2500\u2500\u2500\u25ba\u2502  Load   \u2502\u2500\u2500\u2500\u25ba\u2502 Prepare \u2502\u2500\u2500\u2500\u25ba\u2502  Split   \u2502             \u2502\n\u2502   \u2502  YAML   \u2502    \u2502  Data   \u2502    \u2502Features \u2502    \u2502Train/Test\u2502             \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502                                                     \u2502                   \u2502\n\u2502                                                     \u25bc                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502   \u2502 MLflow  \u2502\u25c4\u2500\u2500\u2500\u2502  Save   \u2502\u25c4\u2500\u2500\u2500\u2502Evaluate \u2502\u25c4\u2500\u2500\u2500\u2502  Train  \u2502              \u2502\n\u2502   \u2502  Log    \u2502    \u2502Artifacts\u2502    \u2502 (Test)  \u2502    \u2502 + CV    \u2502              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                                                         \u2502\n\u2502   OUTPUT:                                                               \u2502\n\u2502   \u2022 model.joblib (Pipeline completo)                                    \u2502\n\u2502   \u2022 training_results.json (m\u00e9tricas)                                    \u2502\n\u2502   \u2022 MLflow run (experimento rastreado)                                  \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#92-carga-y-validacion-de-datos","title":"9.2 Carga y Validaci\u00f3n de Datos","text":"<pre><code># Continuaci\u00f3n de ChurnTrainer\n\ndef load_data(self, input_path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"Carga y valida datos de entrada.\n\n    Parameters\n    ----------\n    input_path : str or Path\n        Ruta al archivo CSV.\n\n    Returns\n    -------\n    pd.DataFrame\n        Datos cargados y validados.\n\n    Raises\n    ------\n    FileNotFoundError\n        Si el archivo no existe.\n    ValueError\n        Si faltan columnas requeridas.\n    \"\"\"\n    input_path = Path(input_path)\n\n    if not input_path.exists():\n        raise FileNotFoundError(f\"Archivo no encontrado: {input_path}\")\n\n    # Cargar CSV\n    data = pd.read_csv(input_path)\n    logger.info(f\"Datos cargados: {data.shape[0]} filas, {data.shape[1]} columnas\")\n\n    # Validar columnas requeridas\n    required = {self.config.data.target_column}\n    required.update(self.config.data.numerical_features)\n    required.update(self.config.data.categorical_features)\n\n    missing = required - set(data.columns)\n    if missing:\n        raise ValueError(f\"Columnas faltantes: {missing}\")\n\n    # Log de estad\u00edsticas b\u00e1sicas\n    target = self.config.data.target_column\n    class_dist = data[target].value_counts(normalize=True)\n    logger.info(f\"Distribuci\u00f3n de clases:\\n{class_dist}\")\n\n    # Alertar si hay desbalance severo\n    minority_pct = class_dist.min()\n    if minority_pct &lt; 0.1:\n        logger.warning(f\"\u26a0\ufe0f Desbalance severo: clase minoritaria = {minority_pct:.1%}\")\n\n    return data\n\n\ndef prepare_features(self, data: pd.DataFrame) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"Prepara features y target.\n\n    Aplica:\n    1. Eliminaci\u00f3n de columnas innecesarias (drop_columns)\n    2. Separaci\u00f3n de X e y\n    \"\"\"\n    # Columnas a eliminar\n    drop_cols = self.config.data.drop_columns + [self.config.data.target_column]\n    drop_cols = [c for c in drop_cols if c in data.columns]\n\n    X = data.drop(columns=drop_cols)\n    y = data[self.config.data.target_column]\n\n    logger.info(f\"Features: {X.shape[1]}, Target: {y.name}\")\n\n    return X, y\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#93-cross-validation-profesional","title":"9.3 Cross-Validation Profesional","text":"<pre><code>def cross_validate(self, X: pd.DataFrame, y: pd.Series) -&gt; Dict[str, float]:\n    \"\"\"Ejecuta cross-validation estratificada.\n\n    Stratified K-Fold mantiene la proporci\u00f3n de clases en cada fold,\n    crucial para datasets desbalanceados.\n    \"\"\"\n    from sklearn.metrics import f1_score, roc_auc_score\n\n    cv = StratifiedKFold(\n        n_splits=self.config.model.cv_folds,\n        shuffle=True,\n        random_state=self.random_state\n    )\n\n    f1_scores = []\n    auc_scores = []\n\n    logger.info(f\"Cross-validation con {self.config.model.cv_folds} folds...\")\n\n    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):\n        X_train_cv = X.iloc[train_idx]\n        X_val_cv = X.iloc[val_idx]\n        y_train_cv = y.iloc[train_idx]\n        y_val_cv = y.iloc[val_idx]\n\n        # Clonar pipeline para este fold\n        from sklearn.base import clone\n        fold_pipeline = clone(self.model_)\n\n        # Entrenar en este fold\n        fold_pipeline.fit(X_train_cv, y_train_cv)\n\n        # Evaluar\n        y_pred = fold_pipeline.predict(X_val_cv)\n        y_proba = fold_pipeline.predict_proba(X_val_cv)[:, 1]\n\n        f1 = f1_score(y_val_cv, y_pred)\n        auc = roc_auc_score(y_val_cv, y_proba)\n\n        f1_scores.append(f1)\n        auc_scores.append(auc)\n\n        logger.info(f\"  Fold {fold}: F1={f1:.4f}, AUC={auc:.4f}\")\n\n    results = {\n        \"f1_mean\": np.mean(f1_scores),\n        \"f1_std\": np.std(f1_scores),\n        \"auc_mean\": np.mean(auc_scores),\n        \"auc_std\": np.std(auc_scores),\n    }\n\n    logger.info(f\"CV Results: F1={results['f1_mean']:.4f} \u00b1 {results['f1_std']:.4f}\")\n    logger.info(f\"CV Results: AUC={results['auc_mean']:.4f} \u00b1 {results['auc_std']:.4f}\")\n\n    return results\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#94-gestion-de-artefactos","title":"9.4 Gesti\u00f3n de Artefactos","text":"<pre><code>def save_artifacts(self, output_dir: Path) -&gt; None:\n    \"\"\"Guarda modelo y resultados.\"\"\"\n    import json\n\n    # 1. Guardar modelo (pipeline completo)\n    model_path = output_dir / \"model.joblib\"\n    joblib.dump(self.model_, model_path)\n    logger.info(f\"Modelo guardado: {model_path}\")\n\n    # 2. Guardar resultados como JSON\n    results = {\n        \"cv_results\": self.cv_results_,\n        \"test_results\": self.test_results_,\n        \"config\": {\n            \"model_type\": self.config.model.type,\n            \"test_size\": self.config.model.test_size,\n            \"cv_folds\": self.config.model.cv_folds,\n            \"random_state\": self.random_state,\n        }\n    }\n\n    results_path = output_dir / \"training_results.json\"\n    with open(results_path, \"w\") as f:\n        json.dump(results, f, indent=2, default=str)\n    logger.info(f\"Resultados guardados: {results_path}\")\n\n\ndef evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -&gt; Dict:\n    \"\"\"Eval\u00faa en test set.\"\"\"\n    from sklearn.metrics import (\n        accuracy_score, precision_score, recall_score,\n        f1_score, roc_auc_score, confusion_matrix\n    )\n\n    y_pred = self.model_.predict(X_test)\n    y_proba = self.model_.predict_proba(X_test)[:, 1]\n\n    results = {\n        \"metrics\": {\n            \"accuracy\": accuracy_score(y_test, y_pred),\n            \"precision\": precision_score(y_test, y_pred),\n            \"recall\": recall_score(y_test, y_pred),\n            \"f1_score\": f1_score(y_test, y_pred),\n            \"roc_auc\": roc_auc_score(y_test, y_proba),\n        },\n        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist(),\n    }\n\n    logger.info(\"Test Results:\")\n    for metric, value in results[\"metrics\"].items():\n        logger.info(f\"  {metric}: {value:.4f}\")\n\n    return results\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#95-logging-y-metricas","title":"9.5 Logging y M\u00e9tricas","text":""},{"location":"docs/09_TRAINING_PROFESIONAL/#configurar-logging-profesional","title":"Configurar Logging Profesional","text":"<pre><code># src/bankchurn/__init__.py o en el m\u00f3dulo principal\n\nimport logging\nimport sys\n\ndef setup_logging(level: str = \"INFO\") -&gt; None:\n    \"\"\"Configura logging estructurado.\"\"\"\n\n    # Formato profesional\n    fmt = \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n    datefmt = \"%Y-%m-%d %H:%M:%S\"\n\n    logging.basicConfig(\n        level=getattr(logging, level.upper()),\n        format=fmt,\n        datefmt=datefmt,\n        handlers=[\n            logging.StreamHandler(sys.stdout),\n            logging.FileHandler(\"training.log\", mode=\"a\"),\n        ]\n    )\n\n    # Reducir verbosidad de librer\u00edas externas\n    logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n    logging.getLogger(\"mlflow\").setLevel(logging.WARNING)\n\n\n# Uso\nsetup_logging(\"INFO\")\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#integracion-con-mlflow","title":"Integraci\u00f3n con MLflow","text":"<pre><code>def _log_to_mlflow(self) -&gt; None:\n    \"\"\"Loguea m\u00e9tricas y artefactos a MLflow.\"\"\"\n    with mlflow.start_run(run_name=\"training\"):\n        # Par\u00e1metros\n        mlflow.log_params({\n            \"model_type\": self.config.model.type,\n            \"test_size\": self.config.model.test_size,\n            \"cv_folds\": self.config.model.cv_folds,\n            \"random_state\": self.random_state,\n        })\n\n        # M\u00e9tricas de CV\n        if self.cv_results_:\n            mlflow.log_metrics({\n                f\"cv_{k}\": v for k, v in self.cv_results_.items()\n            })\n\n        # M\u00e9tricas de test\n        if self.test_results_:\n            mlflow.log_metrics({\n                f\"test_{k}\": v \n                for k, v in self.test_results_[\"metrics\"].items()\n            })\n\n        # Artefactos\n        mlflow.log_artifact(\"artifacts/training_results.json\")\n\n        logger.info(f\"MLflow run logged: {mlflow.active_run().info.run_id}\")\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#96-ingenieria-inversa-pedagogica-churntrainer-real","title":"9.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: ChurnTrainer Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s del <code>ChurnTrainer</code> del portafolio.</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#961-el-por-que-arquitectonico","title":"9.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo hago que el training sea reproducible entre ejecuciones?     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: \"Funciona en mi m\u00e1quina\" pero m\u00e9tricas diferentes en CI                \u2502\n\u2502  DECISI\u00d3N: random_state expl\u00edcito en constructor + config externa               \u2502\n\u2502  RESULTADO: Misma semilla \u2192 mismas m\u00e9tricas (\u00b10.01%)                            \u2502\n\u2502  REFERENCIA: training.py l\u00edneas 57-63                                           \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo detecto autom\u00e1ticamente tipos de features?                   \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Hardcodear columnas \u2192 falla si el schema cambia                        \u2502\n\u2502  DECISI\u00d3N: Auto-detecci\u00f3n con fallback a config expl\u00edcita                       \u2502\n\u2502  RESULTADO: Funciona con nuevos datasets, pero permite override                 \u2502\n\u2502  REFERENCIA: training.py::_detect_feature_types (l\u00edneas 136-158)                \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo integro MLflow sin acoplar el c\u00f3digo?                        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: MLflow falla \u2192 training crashea                                        \u2502\n\u2502  DECISI\u00d3N: config.mlflow.enabled + try/except en setup                          \u2502\n\u2502  RESULTADO: Training funciona sin MLflow, pero lo usa si est\u00e1 disponible        \u2502\n\u2502  REFERENCIA: training.py l\u00edneas 65-71                                           \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#962-anatomia-de-churntrainer","title":"9.6.2 \ud83d\udd0d Anatom\u00eda de <code>ChurnTrainer</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/src/bankchurn/training.py</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Constructor con Configuraci\u00f3n Externalizada\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nclass ChurnTrainer:\n    def __init__(self, config: BankChurnConfig, random_state: int | None = None):\n        self.config = config                           # Config Pydantic validada.\n        self.random_state = random_state or config.model.random_state\n        # \u00bfPor qu\u00e9 `or`?\n        # - Permite override desde c\u00f3digo (\u00fatil para tests).\n        # - Si no se pasa, usa el valor de config (para reproducibilidad).\n\n        self.model_: Pipeline | None = None            # Modelo entrenado (None hasta fit).\n        self.preprocessor_: ColumnTransformer | None = None\n\n        # Configurar MLflow si est\u00e1 habilitado\n        if self.config.mlflow.enabled:\n            try:\n                mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)\n                mlflow.set_experiment(self.config.mlflow.experiment_name)\n            except Exception as e:\n                logger.warning(f\"Failed to configure MLflow: {e}\")\n                # NO crashea. Training contin\u00faa sin tracking.\n# \u00bfPor qu\u00e9 try/except para MLflow?\n# - MLflow puede no estar disponible (server down, sin permisos, etc.).\n# - El training es m\u00e1s importante que el tracking.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Carga de Datos con Validaci\u00f3n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    def load_data(self, input_path: str | Path) -&gt; pd.DataFrame:\n        input_path = Path(input_path)\n\n        if not input_path.exists():\n            raise FileNotFoundError(f\"Input file not found: {input_path}\")\n\n        data = pd.read_csv(input_path)\n        logger.info(f\"Loaded data: {data.shape[0]} rows, {data.shape[1]} columns\")\n\n        # Validar columnas requeridas\n        required = [self.config.data.target_column]\n        missing = set(required) - set(data.columns)\n        if missing:\n            raise ValueError(f\"Missing required columns: {missing}\")\n\n        return data\n# \u00bfPor qu\u00e9 validar columnas antes de entrenar?\n# - Fail fast: detectar errores de datos ANTES de gastar compute.\n# - Mensajes claros: \"Missing column X\" vs \"KeyError\" cr\u00edptico.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: Detecci\u00f3n Autom\u00e1tica de Tipos\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    def _detect_feature_types(self, X: pd.DataFrame) -&gt; tuple[list[str], list[str]]:\n        cat_config = self.config.data.categorical_features\n        num_config = self.config.data.numerical_features\n\n        # Usa config si est\u00e1 presente, sino auto-detecta\n        if cat_config:\n            cat_features = [c for c in cat_config if c in X.columns]\n        else:\n            cat_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\n        if num_config:\n            num_features = [c for c in num_config if c in X.columns]\n        else:\n            num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n\n        return cat_features, num_features\n# \u00bfPor qu\u00e9 este patr\u00f3n \"config or auto-detect\"?\n# - Flexibilidad: funciona sin config (desarrollo r\u00e1pido).\n# - Control: config expl\u00edcita para producci\u00f3n (evita sorpresas).\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#963-laboratorio-de-replicacion","title":"9.6.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Crear tu propio Trainer siguiendo el patr\u00f3n del portafolio.</p> <pre><code># src/mi_proyecto/training.py\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport pandas as pd\nimport joblib\nfrom sklearn.pipeline import Pipeline\n\n@dataclass\nclass TrainerConfig:\n    target_column: str\n    random_state: int = 42\n    test_size: float = 0.2\n\nclass MiTrainer:\n    def __init__(self, config: TrainerConfig):\n        self.config = config\n        self.model_: Pipeline | None = None\n\n    def load_data(self, path: Path) -&gt; pd.DataFrame:\n        if not path.exists():\n            raise FileNotFoundError(f\"No existe: {path}\")\n        return pd.read_csv(path)\n\n    def train(self, data: pd.DataFrame) -&gt; dict:\n        # Tu l\u00f3gica de training aqu\u00ed\n        ...\n        return {\"f1\": 0.85, \"auc\": 0.90}\n\n    def save(self, path: Path) -&gt; None:\n        joblib.dump(self.model_, path)\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#964-troubleshooting-preventivo","title":"9.6.4 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n M\u00e9tricas diferentes entre ejecuciones random_state no fijado en todos los lugares Pasa random_state a train_test_split, modelo, y CV. KeyError en columna target Config no actualizada con nombre correcto Valida <code>config.data.target_column</code> contra <code>df.columns</code>. MLflow \"experiment not found\" set_experiment antes de set_tracking_uri Llama siempre <code>set_tracking_uri</code> primero. Pipeline no serializable Custom transformer sin <code>__getstate__</code> Usa solo transformers de sklearn o implementa serializaci\u00f3n."},{"location":"docs/09_TRAINING_PROFESIONAL/#errores-habituales-y-como-depurarlos-en-training","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en training","text":"<p>En este m\u00f3dulo, casi todos los problemas vienen de datos mal preparados, splits inconsistentes o logging incompleto. Aqu\u00ed est\u00e1n los patrones m\u00e1s frecuentes.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#1-keyerror-o-valueerror-al-cargar-datos-columnasconfig-mal-alineadas","title":"1) <code>KeyError</code> o <code>ValueError</code> al cargar datos (columnas/config mal alineadas)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>ValueError: Columnas faltantes: {'CreditScore', 'Age', ...}</code></li> <li><code>KeyError: 'Exited'</code> al intentar acceder al target.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara <code>self.config.data.*</code> con las columnas reales del CSV.</li> <li>Usa <code>load_data</code> como punto \u00fanico de verdad y revisa sus logs (n\u00famero de filas/columnas, distribuci\u00f3n de clases).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta <code>configs/config.yaml</code> para que <code>target_column</code>, <code>numerical_features</code>, <code>categorical_features</code> reflejen exactamente el dataset.</li> <li>Mant\u00e9n <code>prepare_features</code> simple: usar solo <code>drop_columns</code> + separaci\u00f3n de <code>X</code> e <code>y</code>.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#2-resultados-no-reproducibles-semilla-mal-gestionada","title":"2) Resultados no reproducibles (semilla mal gestionada)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Cada ejecuci\u00f3n de <code>ChurnTrainer.run</code> produce m\u00e9tricas distintas sin raz\u00f3n aparente.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa la inicializaci\u00f3n de <code>ChurnTrainer</code> y el uso de <code>random_state</code> en:</li> <li><code>train_test_split</code>.</li> <li><code>StratifiedKFold</code>.</li> <li>Modelos base (<code>RandomForest</code>, etc.).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de que la semilla venga de un solo lugar (config) y se pase a todos los componentes relevantes.</li> <li>Si usas utilidades como <code>common_utils.seed.set_seed</code>, llama a esa funci\u00f3n al inicio de <code>run</code> o en el CLI.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#3-cross-validation-enganosa-leakage-entre-folds-o-cv-desalineado-con-test","title":"3) Cross-validation enga\u00f1osa (leakage entre folds o CV desalineado con test)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>M\u00e9tricas de CV muy buenas, pero test set mucho peor.</li> <li>Folds con distribuci\u00f3n de clases muy desigual.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica que usas <code>StratifiedKFold</code> para clasificaci\u00f3n desbalanceada.</li> <li>Aseg\u00farate de clonar el pipeline (<code>clone(self.model_)</code>) en cada fold, no reutilizar el mismo objeto.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Mant\u00e9n el orden: definir pipeline completo antes de CV y clonar dentro del loop.</li> <li>No mezcles datos de test en CV; usa <code>train_test_split</code> una sola vez, luego CV solo en <code>X_train, y_train</code>.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#4-artefactos-inconsistentes-modelo-y-metricas-que-no-corresponden","title":"4) Artefactos inconsistentes (modelo y m\u00e9tricas que no corresponden)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>training_results.json</code> y <code>model.joblib</code> provienen de ejecuciones distintas.</li> <li>MLflow muestra m\u00e9tricas que no coinciden con los artefactos locales.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa que <code>save_artifacts</code> se llama despu\u00e9s de entrenar el modelo final y evaluar en test.</li> <li>Comprueba timestamps y contenido de <code>artifacts/model.joblib</code> y <code>artifacts/training_results.json</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Asegura el orden en <code>run</code>: CV \u2192 <code>fit</code> final \u2192 <code>evaluate</code> \u2192 <code>save_artifacts</code> \u2192 <code>_log_to_mlflow</code>.</li> <li>No reutilices artefactos viejos; limpia la carpeta <code>artifacts/</code> antes de grandes cambios.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#5-mlflow-no-registra-nada-o-registra-en-el-lugar-equivocado","title":"5) MLflow no registra nada o registra en el lugar equivocado","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Corres <code>ChurnTrainer.run</code> pero no ves runs nuevos en la UI de MLflow.</li> <li>M\u00e9tricas aparecen en otro experimento o en otro tracking URI.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Imprime/inspecciona <code>self.config.mlflow.tracking_uri</code> y <code>experiment_name</code>.</li> <li>Verifica variables de entorno (<code>MLFLOW_TRACKING_URI</code>) si las usas en scripts aparte (<code>run_mlflow.py</code>).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Centraliza la configuraci\u00f3n en <code>BankChurnConfig</code> y <code>_setup_mlflow</code>, evitando <code>mlflow.set_tracking_uri</code> dispersos en el c\u00f3digo.</li> <li>En <code>run_mlflow.py</code>, aseg\u00farate de usar el mismo <code>tracking_uri</code> y <code>experiment</code> que usaste durante el entrenamiento.</li> </ul>"},{"location":"docs/09_TRAINING_PROFESIONAL/#patron-general-de-debugging-para-training","title":"Patr\u00f3n general de debugging para training","text":"<ol> <li>Empieza por los datos: confirma que <code>load_data</code> y <code>prepare_features</code> producen <code>X, y</code> con las formas y columnas esperadas.</li> <li>Verifica el split: revisa distribuci\u00f3n de clases en <code>train/test</code> y en cada fold.</li> <li>Comprueba los artefactos: que <code>model.joblib</code> y <code>training_results.json</code> se regeneren juntos.</li> <li>Sincroniza con MLflow: compara m\u00e9tricas locales con lo que ves en la UI.</li> </ol> <p>Con este enfoque, el entrenamiento deja de ser \u201ccaja negra\u201d y se convierte en un pipeline controlado y auditable, como se espera en un rol Senior/Staff.</p> <p></p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicio-implementar-tu-trainer","title":"\u2705 Ejercicio: Implementar tu Trainer","text":"<p>Crea una clase <code>PriceTrainer</code> para CarVision siguiendo el patr\u00f3n:</p> <pre><code>class PriceTrainer:\n    \"\"\"Tu tarea: implementar siguiendo el patr\u00f3n de ChurnTrainer.\"\"\"\n\n    def __init__(self, config: dict):\n        # TODO: Inicializar atributos\n        pass\n\n    def run(self, input_path: Path, output_dir: Path) -&gt; dict:\n        # TODO: Implementar flujo completo\n        pass\n\n    def load_data(self, path: Path) -&gt; pd.DataFrame:\n        # TODO: Cargar y validar\n        pass\n\n    def build_pipeline(self) -&gt; Pipeline:\n        # TODO: Construir pipeline [features -&gt; pre -&gt; model]\n        pass\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#_1","title":"09 \u2014 Training Profesional","text":""},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicio-puente-entrenamiento","title":"\ud83d\udcbb Ejercicio Puente: Entrenamiento","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: - Revisa el c\u00f3digo de ejemplo en la secci\u00f3n siguiente - Identifica los patrones clave - Replica el patr\u00f3n en un proyecto simple</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#practica-del-portafolio-training-profesional-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Training Profesional en BankChurn","text":"<p>Tarea: Aplicar los conceptos de este m\u00f3dulo en BankChurn-Predictor.</p> <p>Pasos: 1. Navega al proyecto: <code>cd BankChurn-Predictor</code> 2. Localiza el c\u00f3digo relevante en <code>src/bankchurn/</code> 3. Verifica la implementaci\u00f3n actual 4. Aplica mejoras seg\u00fan las buenas pr\u00e1cticas de este m\u00f3dulo</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#checkpoint-de-conocimiento-training-profesional","title":"\u2705 Checkpoint de Conocimiento: Training Profesional","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el concepto m\u00e1s importante de este m\u00f3dulo? - Revisa el mapa mental y la secci\u00f3n principal</p> <p>Pregunta 2: \u00bfC\u00f3mo se aplica en el portafolio? - Examina el c\u00f3digo de BankChurn-Predictor</p> <p>\ud83d\udd27 Escenario de Debugging: - Identifica un problema com\u00fan en este tema - Practica la soluci\u00f3n con el c\u00f3digo del portafolio</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El proyecto BankChurn implementa el patr\u00f3n de training profesional completo:</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#clase-churntrainer-real","title":"Clase ChurnTrainer Real","text":"<pre><code># BankChurn-Predictor/src/bankchurn/trainer.py (estructura)\nclass ChurnTrainer:\n    \"\"\"Entrenador profesional con CV, MLflow y artefactos.\"\"\"\n\n    def __init__(self, config: BankChurnConfig):\n        self.config = config\n        self.model_ = None\n        self.metrics_ = {}\n\n    def run(self, input_path: Path, output_dir: Path) -&gt; dict:\n        \"\"\"Flujo completo: load \u2192 split \u2192 CV \u2192 train \u2192 evaluate \u2192 save.\"\"\"\n        df = self.load_data(input_path)\n        X, y = self.prepare_features(df)\n        X_train, X_test, y_train, y_test = self.split_data(X, y)\n\n        # Cross-validation\n        cv_scores = self.cross_validate(X_train, y_train)\n\n        # Entrenamiento final\n        self.model_ = self.build_pipeline()\n        self.model_.fit(X_train, y_train)\n\n        # Evaluaci\u00f3n\n        self.metrics_ = self.evaluate(X_test, y_test)\n\n        # Guardar artefactos\n        self.save_artifacts(output_dir)\n\n        return self.metrics_\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#flujo-de-entrenamiento","title":"Flujo de Entrenamiento","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FLUJO DE TRAINING                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                               \u2502\n\u2502  load_data \u2192 prepare_features \u2192 split_data                    \u2502\n\u2502      \u2502              \u2502               \u2502                         \u2502\n\u2502      \u25bc              \u25bc               \u25bc                         \u2502\n\u2502  DataFrame     X, y arrays    train/test split                \u2502\n\u2502                                     \u2502                         \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n\u2502                    \u2502                                 \u2502        \u2502\n\u2502              cross_validate                    build_pipeline \u2502\n\u2502                    \u2502                                 \u2502        \u2502\n\u2502              cv_scores                          Pipeline      \u2502\n\u2502                    \u2502                                 \u2502        \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n\u2502                                     \u2502                         \u2502\n\u2502                              model_.fit()                     \u2502\n\u2502                                     \u2502                         \u2502\n\u2502                              evaluate()                       \u2502\n\u2502                                     \u2502                         \u2502\n\u2502                           save_artifacts()                    \u2502\n\u2502                                     \u2502                         \u2502\n\u2502                       pipeline.joblib + metrics.json          \u2502\n\u2502                                                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#archivos-de-training-por-proyecto","title":"Archivos de Training por Proyecto","text":"Proyecto Trainer Config Artefactos BankChurn <code>src/bankchurn/trainer.py</code> <code>configs/config.yaml</code> <code>artifacts/</code> CarVision <code>main.py</code> <code>configs/config.yaml</code> <code>artifacts/</code> TelecomAI <code>src/telecomai/training.py</code> <code>configs/config.yaml</code> <code>artifacts/</code>"},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicio-ejecuta-training-real","title":"\ud83d\udd27 Ejercicio: Ejecuta Training Real","text":"<pre><code># 1. Ve a BankChurn\ncd BankChurn-Predictor\n\n# 2. Entrena el modelo\npython main.py --config configs/config.yaml\n\n# 3. Verifica artefactos generados\nls -la artifacts/\ncat artifacts/training_results.json\n\n# 4. Verifica MLflow\nmlflow ui  # Abre http://localhost:5000\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Cross-Validation: Explica stratified k-fold, time series split, y cu\u00e1ndo usar cada uno.</p> </li> <li> <p>Hyperparameter Tuning: RandomSearch vs GridSearch vs Bayesian (Optuna).</p> </li> <li> <p>M\u00e9tricas de negocio: Traduce m\u00e9tricas t\u00e9cnicas a impacto de negocio.</p> </li> </ol>"},{"location":"docs/09_TRAINING_PROFESIONAL/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Clases desbalanceadas SMOTE, class_weight, o threshold tuning Overfitting Early stopping, regularizaci\u00f3n, m\u00e1s datos Modelo en producci\u00f3n Entrena con todos los datos al final Reproducibilidad Fija seeds en todos los componentes"},{"location":"docs/09_TRAINING_PROFESIONAL/#pipeline-de-training-profesional","title":"Pipeline de Training Profesional","text":"<pre><code>1. Split estratificado (train/val/test)\n2. Feature engineering solo en train\n3. Hyperparameter tuning con val\n4. Evaluaci\u00f3n final en test (una sola vez)\n5. Re-entrenamiento con todos los datos\n6. Versionado de modelo + m\u00e9tricas\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/09_TRAINING_PROFESIONAL/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Cross-Validation Explained StatQuest 12 min YouTube \ud83d\udd34 Hyperparameter Tuning Krish Naik 25 min YouTube \ud83d\udfe1 Optuna Tutorial Weights &amp; Biases 30 min YouTube"},{"location":"docs/09_TRAINING_PROFESIONAL/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 sklearn Cross-validation Gu\u00eda oficial CV \ud83d\udfe1 Optuna Docs Hyperparameter optimization"},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicio-91-trainer-class","title":"Ejercicio 9.1: Trainer Class","text":"<p>Objetivo: Implementar clase de entrenamiento profesional. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: Completa la clase Trainer\n\nclass Trainer:\n    def __init__(self, config):\n        self.config = config\n        self.model_ = None\n\n    def cross_validate(self, X, y):\n        \"\"\"Ejecuta CV estratificado.\"\"\"\n        # ???\n\n    def train(self, X, y):\n        \"\"\"Entrena modelo final.\"\"\"\n        # ???\n\n    def save(self, path):\n        \"\"\"Guarda modelo y m\u00e9tricas.\"\"\"\n        # ???\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from pathlib import Path\nimport json\nimport joblib\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\n\nclass Trainer:\n    def __init__(self, config: dict):\n        self.config = config\n        self.model_ = None\n        self.cv_scores_ = None\n        self.metrics_ = {}\n\n    def cross_validate(self, X, y, cv: int = 5) -&gt; dict:\n        \"\"\"Ejecuta CV estratificado.\"\"\"\n        pipeline = self._build_pipeline()\n\n        cv_strategy = StratifiedKFold(\n            n_splits=cv,\n            shuffle=True,\n            random_state=self.config.get('random_state', 42)\n        )\n\n        self.cv_scores_ = cross_val_score(\n            pipeline, X, y,\n            cv=cv_strategy,\n            scoring='f1'\n        )\n\n        return {\n            'cv_mean': self.cv_scores_.mean(),\n            'cv_std': self.cv_scores_.std(),\n            'cv_scores': self.cv_scores_.tolist()\n        }\n\n    def train(self, X, y):\n        \"\"\"Entrena modelo final con todos los datos.\"\"\"\n        self.model_ = self._build_pipeline()\n        self.model_.fit(X, y)\n        return self\n\n    def evaluate(self, X_test, y_test) -&gt; dict:\n        \"\"\"Eval\u00faa en test set.\"\"\"\n        from sklearn.metrics import f1_score, accuracy_score\n\n        y_pred = self.model_.predict(X_test)\n        self.metrics_ = {\n            'f1': f1_score(y_test, y_pred),\n            'accuracy': accuracy_score(y_test, y_pred)\n        }\n        return self.metrics_\n\n    def save(self, output_dir: Path):\n        \"\"\"Guarda modelo y m\u00e9tricas.\"\"\"\n        output_dir = Path(output_dir)\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n        # Guardar modelo\n        joblib.dump(self.model_, output_dir / 'model.joblib')\n\n        # Guardar m\u00e9tricas\n        results = {\n            'cv_scores': self.cv_scores_.tolist() if self.cv_scores_ is not None else None,\n            'test_metrics': self.metrics_,\n            'config': self.config\n        }\n        with open(output_dir / 'results.json', 'w') as f:\n            json.dump(results, f, indent=2)\n\n    def _build_pipeline(self) -&gt; Pipeline:\n        \"\"\"Construye pipeline seg\u00fan config.\"\"\"\n        from sklearn.preprocessing import StandardScaler\n        from sklearn.ensemble import RandomForestClassifier\n\n        return Pipeline([\n            ('scaler', StandardScaler()),\n            ('model', RandomForestClassifier(\n                n_estimators=self.config.get('n_estimators', 100),\n                max_depth=self.config.get('max_depth'),\n                random_state=self.config.get('random_state', 42)\n            ))\n        ])\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#ejercicio-92-reproducibilidad","title":"Ejercicio 9.2: Reproducibilidad","text":"<p>Objetivo: Garantizar resultados reproducibles. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: \u00bfQu\u00e9 falta para garantizar reproducibilidad?\n\ndef train_model(X, y):\n    model = RandomForestClassifier(n_estimators=100)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    model.fit(X_train, y_train)\n    return model\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import numpy as np\nimport random\n\ndef set_seeds(seed: int = 42):\n    \"\"\"Fija todas las semillas para reproducibilidad.\"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    # Si usas PyTorch: torch.manual_seed(seed)\n    # Si usas TensorFlow: tf.random.set_seed(seed)\n\ndef train_model(X, y, random_state: int = 42):\n    # 1. Fijar semillas globales\n    set_seeds(random_state)\n\n    # 2. random_state en el modelo\n    model = RandomForestClassifier(\n        n_estimators=100,\n        random_state=random_state  # \u2190 IMPORTANTE\n    )\n\n    # 3. random_state en el split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y,\n        test_size=0.2,\n        random_state=random_state,  # \u2190 IMPORTANTE\n        stratify=y  # \u2190 Mantiene distribuci\u00f3n de clases\n    )\n\n    model.fit(X_train, y_train)\n    return model\n\n# Checklist de reproducibilidad:\n# \u2705 random_state en train_test_split\n# \u2705 random_state en modelo\n# \u2705 random_state en cross-validation\n# \u2705 Versi\u00f3n de dependencias fijada (requirements.txt)\n# \u2705 Datos versionados (DVC)\n# \u2705 C\u00f3digo versionado (Git commit)\n</code></pre>"},{"location":"docs/09_TRAINING_PROFESIONAL/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Cross-Validation T\u00e9cnica para evaluar modelo dividiendo datos en K folds Stratified K-Fold CV que mantiene proporci\u00f3n de clases en cada fold Hyperparameter Tuning B\u00fasqueda de mejores par\u00e1metros del modelo random_state Semilla para reproducibilidad de resultados aleatorios   **Siguiente m\u00f3dulo** \u2192 [10. Experiment Tracking](10_EXPERIMENT_TRACKING.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/10_EXPERIMENT_TRACKING/","title":"10. Experiment Tracking con MLflow","text":"<p>## 0.0 Prerrequisitos</p> <ul> <li>Tener al menos 1 proyecto del portafolio con:</li> <li><code>artifacts/training_results.json</code> (o equivalente)</li> <li>Un modelo serializado (<code>model.pkl</code>, <code>model.joblib</code>, etc.)</li> <li>Poder instalar MLflow en tu entorno del proyecto.</li> </ul> <p></p> <p>## 0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</p> <ul> <li>Antes de empezar: abre Protocolo E y define tu output m\u00ednimo (1 run visible y comparable).</li> <li>Durante el debugging: si te atoras &gt;15 min (tracking_uri, artifacts, registry), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar trazabilidad (runs, params, m\u00e9tricas, artifacts).</li> </ul> <p></p> <p>## 0.2 \u2705 Entregables verificables (m\u00ednimo viable)</p> <ul> <li>[ ] Un experimento MLflow con:</li> <li>params (ej. hiperpar\u00e1metros o <code>run_type</code>)</li> <li>m\u00e9tricas (ej. <code>test_f1</code>, <code>test_auc</code>)</li> <li>artifacts (ej. <code>training_results.json</code>, <code>config.yaml</code>)</li> <li>[ ] Evidencia (UI o <code>mlflow ui</code>) de poder comparar 2 runs.</li> <li>[ ] 1 entrada en Diario de Errores si hubo bloqueo real.</li> </ul> <p></p> <p>## 0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</p> <ul> <li>Concepto: experiment tracking (params/metrics/artifacts + comparaci\u00f3n + registry)</li> <li>Archivo: <code>scripts/run_mlflow.py</code>, <code>docker-compose.mlflow.yml</code>, <code>configs/config.yaml</code></li> <li>Prueba: entrenar \u2192 loguear \u2192 abrir UI \u2192 comparar runs</li> </ul> <p>## \ud83c\udfaf Objetivo del M\u00f3dulo</p> <p>Implementar tracking de experimentos como lo hace el portafolio con <code>run_mlflow.py</code>.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  SIN MLFLOW:                           CON MLFLOW:                           \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                          \u2551\n\u2551  \"\u00bfQu\u00e9 hiperpar\u00e1metros us\u00e9 hace        \"MLflow run abc123: RF con            \u2551\n\u2551   2 semanas cuando obtuve F1=0.85?\"    n_estimators=200, F1=0.85\"            \u2551\n\u2551                                                                              \u2551\n\u2551  \"\u00bfD\u00f3nde guard\u00e9 ese modelo bueno?\"     \"Artifacts en run abc123/model.pkl\"   \u2551\n\u2551                                                                              \u2551\n\u2551  \"\u00bfPor qu\u00e9 este modelo es peor?\"       \"Comparar runs en UI: diff params\"    \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#como-se-aplica-en-este-portafolio","title":"\ud83e\udde9 C\u00f3mo se aplica en este portafolio","text":"<ul> <li>En BankChurn-Predictor ya tienes:</li> <li><code>scripts/run_mlflow.py</code> como script de logging posterior al entrenamiento.</li> <li>Configuraci\u00f3n de MLflow en <code>configs/config.yaml</code> y <code>src/bankchurn/config.py</code>.</li> <li>El archivo <code>docker-compose.mlflow.yml</code> en la ra\u00edz del repo levanta un servidor MLflow    real que puedes usar para practicar este m\u00f3dulo.</li> <li>El mismo patr\u00f3n de logging puedes aplicarlo a CarVision y TelecomAI, usando    sus <code>artifacts/</code> y modelos entrenados como fuente de m\u00e9tricas y artifacts.</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>Conceptos de MLflow</li> <li>Setup y Configuraci\u00f3n</li> <li>Logging de Experimentos</li> <li>Model Registry</li> <li>C\u00f3digo Real del Portafolio</li> <li>\ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: MLflow Producci\u00f3n \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#mapa-mental-de-conceptos-101-conceptos-de-mlflow","title":"\ud83e\udde0 Mapa Mental de Conceptos: 10.1 Conceptos de MLflow","text":"<p>T\u00e9rminos clave que debes dominar para este tema: - Revisa los conceptos principales en la secci\u00f3n siguiente - Practica con los ejercicios del portafolio - Aplica los conocimientos en BankChurn-Predictor</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#101-conceptos-de-mlflow","title":"10.1 Conceptos de MLflow","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#los-4-componentes","title":"Los 4 Componentes","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          MLFLOW COMPONENTS                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  1. TRACKING                    2. PROJECTS                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                \u2502\n\u2502  \u2022 Log params, metrics          \u2022 Empaquetar c\u00f3digo                         \u2502\n\u2502  \u2022 Guardar artifacts            \u2022 MLproject file                            \u2502\n\u2502  \u2022 Comparar runs                \u2022 Reproducibilidad                          \u2502\n\u2502                                                                             \u2502\n\u2502  3. MODELS                      4. REGISTRY                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                               \u2502\n\u2502  \u2022 Formato est\u00e1ndar             \u2022 Versionado de modelos                     \u2502\n\u2502  \u2022 Flavors (sklearn, pytorch)   \u2022 Staging \u2192 Production                      \u2502\n\u2502  \u2022 Serving                      \u2022 Aprobaciones                              \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nEN ESTE PORTAFOLIO USAMOS: Tracking + Registry\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#jerarquia-de-mlflow","title":"Jerarqu\u00eda de MLflow","text":"<pre><code>MLflow Server\n\u2514\u2500\u2500 Experiment: \"BankChurn\"\n    \u251c\u2500\u2500 Run: abc123 (2024-01-15)\n    \u2502   \u251c\u2500\u2500 Parameters: {n_estimators: 200, max_depth: 10}\n    \u2502   \u251c\u2500\u2500 Metrics: {f1: 0.65, auc: 0.88}\n    \u2502   \u2514\u2500\u2500 Artifacts: [model.pkl, config.yaml]\n    \u2502\n    \u251c\u2500\u2500 Run: def456 (2024-01-16)\n    \u2502   \u251c\u2500\u2500 Parameters: {n_estimators: 200, max_depth: 15}\n    \u2502   \u251c\u2500\u2500 Metrics: {f1: 0.62, auc: 0.86}\n    \u2502   \u2514\u2500\u2500 Artifacts: [model.pkl, config.yaml]\n    \u2502\n    \u2514\u2500\u2500 Run: ghi789 (2024-01-17) \u2190 MEJOR\n        \u251c\u2500\u2500 Parameters: {n_estimators: 200, max_depth: 10}\n        \u251c\u2500\u2500 Metrics: {f1: 0.65, auc: 0.88}\n        \u2514\u2500\u2500 Artifacts: [model.pkl, config.yaml]\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#102-setup-y-configuracion","title":"10.2 Setup y Configuraci\u00f3n","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#opcion-1-local-file-store","title":"Opci\u00f3n 1: Local (File Store)","text":"<pre><code># M\u00e1s simple, para desarrollo local\nimport mlflow\n\nmlflow.set_tracking_uri(\"file:./mlruns\")  # Guarda en carpeta local\nmlflow.set_experiment(\"my-experiment\")  # Crea o selecciona un experimento existente.\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#opcion-2-servidor-mlflow-produccion","title":"Opci\u00f3n 2: Servidor MLflow (Producci\u00f3n)","text":"<pre><code># docker-compose.mlflow.yml del portafolio\nservices:\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.2\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - mlflow-artifacts:/mlflow\n    command: &gt;\n      mlflow server\n      --backend-store-uri sqlite:///mlflow/mlflow.db\n      --default-artifact-root /mlflow/artifacts\n      --host 0.0.0.0\n      --port 5000\n</code></pre> <pre><code># Conectar al servidor\nimport mlflow\n\nmlflow.set_tracking_uri(\"http://localhost:5000\")  # URL del servidor MLflow (local o remoto).\nmlflow.set_experiment(\"BankChurn\")\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#configuracion-en-el-portafolio","title":"Configuraci\u00f3n en el Portafolio","text":"<pre><code># configs/config.yaml (BankChurn)\nmlflow:\n  tracking_uri: \"file:./mlruns\"      # Local para desarrollo\n  experiment_name: \"bankchurn\"\n  enabled: true\n</code></pre> <pre><code># src/bankchurn/config.py\nclass MLflowConfig(BaseModel):\n    \"\"\"MLflow tracking configuration.\"\"\"\n    tracking_uri: str = \"file:./mlruns\"  # URI donde se guardan los experimentos (archivo local).\n    experiment_name: str = \"bankchurn\"\n    enabled: bool = True\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#103-logging-de-experimentos","title":"10.3 Logging de Experimentos","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#api-basica","title":"API B\u00e1sica","text":"<pre><code>import mlflow                            # Cliente de MLflow para tracking.\n\n# Iniciar un run\nwith mlflow.start_run(run_name=\"experiment-1\"):  # Context manager: auto-cierra el run al salir.\n\n    # 1. LOG PARAMETERS (hiperpar\u00e1metros, config)\n    mlflow.log_param(\"n_estimators\", 200)        # log_param: registra UN par\u00e1metro (key-value).\n    mlflow.log_param(\"max_depth\", 10)            # Los params son strings/n\u00fameros, no objetos.\n    mlflow.log_params({                          # log_params: registra M\u00daLTIPLES a la vez.\n        \"learning_rate\": 0.1,\n        \"model_type\": \"random_forest\"\n    })\n\n    # 2. LOG METRICS (resultados)\n    mlflow.log_metric(\"f1_score\", 0.65)          # log_metric: registra UNA m\u00e9trica num\u00e9rica.\n    mlflow.log_metric(\"auc_roc\", 0.88)           # Las m\u00e9tricas se pueden comparar en la UI.\n    mlflow.log_metrics({                         # log_metrics: m\u00faltiples a la vez.\n        \"precision\": 0.70,\n        \"recall\": 0.61\n    })\n\n    # 3. LOG ARTIFACTS (archivos)\n    mlflow.log_artifact(\"configs/config.yaml\")   # log_artifact: sube archivo al servidor MLflow.\n    mlflow.log_artifact(\"artifacts/training_results.json\")  # \u00datil para reproducir el experimento.\n\n    # 4. LOG MODEL (modelo serializado con metadata)\n    mlflow.sklearn.log_model(                    # sklearn: \"flavor\" espec\u00edfico para modelos sklearn.\n        pipeline,                                # El objeto Pipeline fitted.\n        artifact_path=\"model\",                   # Subcarpeta dentro de artifacts del run.\n        registered_model_name=\"BankChurnClassifier\"  # Si existe, crea nueva versi\u00f3n; si no, lo crea.\n    )\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#metricas-por-epocapaso","title":"M\u00e9tricas por \u00c9poca/Paso","text":"<pre><code># Para modelos que entrenan por \u00e9pocas\nfor epoch in range(100):\n    train_loss = train_one_epoch()\n    val_loss = validate()\n\n    mlflow.log_metrics({\n        \"train_loss\": train_loss,\n        \"val_loss\": val_loss\n    }, step=epoch)  # \u2190 step permite graficar evoluci\u00f3n\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#104-model-registry","title":"10.4 Model Registry","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#registrar-un-modelo","title":"Registrar un Modelo","text":"<pre><code># Durante el run\nmlflow.sklearn.log_model(\n    pipeline,\n    artifact_path=\"model\",\n    registered_model_name=\"BankChurnClassifier\"  # \u2190 Registra autom\u00e1ticamente\n)\n\n# O despu\u00e9s del run\nmlflow.register_model(\n    model_uri=f\"runs:/{run_id}/model\",\n    name=\"BankChurnClassifier\"\n)\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#transiciones-de-estado","title":"Transiciones de Estado","text":"<pre><code>from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\n# Promover a Staging\nclient.transition_model_version_stage(\n    name=\"BankChurnClassifier\",\n    version=1,\n    stage=\"Staging\"\n)\n\n# Promover a Production (despu\u00e9s de validaci\u00f3n)\nclient.transition_model_version_stage(\n    name=\"BankChurnClassifier\",\n    version=1,\n    stage=\"Production\"\n)\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#cargar-modelo-desde-registry","title":"Cargar Modelo desde Registry","text":"<pre><code># Cargar versi\u00f3n espec\u00edfica\nmodel = mlflow.sklearn.load_model(\"models:/BankChurnClassifier/1\")\n\n# Cargar stage espec\u00edfico\nmodel = mlflow.sklearn.load_model(\"models:/BankChurnClassifier/Production\")\n\n# Cargar \u00faltimo modelo (latest)\nmodel = mlflow.sklearn.load_model(\"models:/BankChurnClassifier/latest\")\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#105-codigo-real-del-portafolio","title":"10.5 C\u00f3digo Real del Portafolio","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#scriptsrun_mlflowpy-bankchurn","title":"scripts/run_mlflow.py (BankChurn)","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"Log training results to MLflow.\n\nEste script se ejecuta DESPU\u00c9S del entrenamiento para:\n1. Leer resultados de artifacts/training_results.json\n2. Calcular m\u00e9tricas de negocio (revenue saved, etc.)\n3. Loguear todo a MLflow\n4. Opcionalmente registrar el modelo\n\nUso:\n    python scripts/run_mlflow.py\n\nEnvironment Variables:\n    MLFLOW_TRACKING_URI: URI del servidor MLflow\n    MLFLOW_EXPERIMENT_NAME: Nombre del experimento\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport os\nfrom pathlib import Path\n\nimport joblib\n\ntry:\n    import mlflow\n    import mlflow.sklearn\n    from mlflow.tracking import MlflowClient\nexcept ImportError:\n    mlflow = None\n\nfrom sklearn.pipeline import Pipeline\n\n\ndef main() -&gt; None:\n    # Configuraci\u00f3n desde environment\n    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"file:./mlruns\")\n    experiment = os.getenv(\"MLFLOW_EXPERIMENT_NAME\", \"BankChurn\")\n\n    # Cargar resultados del entrenamiento\n    results_path = Path(\"artifacts/training_results.json\")\n    if not results_path.exists():\n        print(f\"No se encontr\u00f3 {results_path}. Ejecuta training primero.\")\n        return\n\n    data = json.loads(results_path.read_text())\n\n    # Extraer m\u00e9tricas\n    cv = data.get(\"cv_results\", {})\n    test = data.get(\"test_results\", {}).get(\"metrics\", {})\n\n    metrics = {}\n    for k, v in cv.items():\n        if isinstance(v, (int, float)):\n            metrics[f\"cv_{k}\"] = float(v)\n    for k, v in test.items():\n        if isinstance(v, (int, float)):\n            metrics[f\"test_{k}\"] = float(v)\n\n    # Calcular m\u00e9tricas de negocio\n    cm = data.get(\"test_results\", {}).get(\"confusion_matrix\")\n    if cm and len(cm) == 2:\n        tn, fp = cm[0]\n        fn, tp = cm[1]\n\n        # Par\u00e1metros de negocio (configurables)\n        clv = float(os.getenv(\"BC_CLV_USD\", \"2300\"))  # Customer Lifetime Value\n        retention_rate = float(os.getenv(\"BC_RETENTION_RATE\", \"0.3\"))\n\n        saved_customers = tp * retention_rate\n        saved_revenue = saved_customers * clv\n\n        metrics.update({\n            \"biz_detected_churners\": float(tp),\n            \"biz_saved_customers\": saved_customers,\n            \"biz_saved_revenue_usd\": saved_revenue,\n            \"biz_false_positives\": float(fp),\n            \"biz_missed_churners\": float(fn),\n        })\n\n    if mlflow is None:\n        print(\"MLflow no instalado. M\u00e9tricas:\", metrics)\n        return\n\n    # Configurar MLflow\n    mlflow.set_tracking_uri(tracking_uri)\n    mlflow.set_experiment(experiment)\n\n    # Crear run\n    with mlflow.start_run(run_name=\"demo-logging\"):\n        # Log par\u00e1metros\n        mlflow.log_params({\n            \"run_type\": \"demo\",\n            \"source\": \"run_mlflow.py\"\n        })\n\n        # Log m\u00e9tricas\n        mlflow.log_metrics(metrics)\n\n        # Log artifacts\n        for artifact in [\n            Path(\"artifacts/training_results.json\"),\n            Path(\"configs/config.yaml\"),\n        ]:\n            if artifact.exists():\n                try:\n                    mlflow.log_artifact(str(artifact))\n                except PermissionError:\n                    print(f\"Skipping {artifact}: permission denied\")\n\n        # Log modelo si existe\n        model_path = Path(\"models/model_v1.0.0.pkl\")\n        if model_path.exists():\n            try:\n                obj = joblib.load(model_path)\n                if isinstance(obj, dict) and \"pipeline\" in obj:\n                    pipe = obj[\"pipeline\"]\n                elif isinstance(obj, Pipeline):\n                    pipe = obj\n                else:\n                    pipe = None\n\n                if pipe:\n                    mlflow.sklearn.log_model(\n                        pipe,\n                        artifact_path=\"model\",\n                        registered_model_name=\"BankChurnClassifier\"\n                    )\n            except Exception as e:\n                print(f\"Model logging skipped: {e}\")\n\n        print(f\"\u2705 MLflow run logged to {tracking_uri}\")\n        print(f\"   Experiment: {experiment}\")\n        print(f\"   Metrics: {len(metrics)} logged\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#makefile-integration","title":"Makefile Integration","text":"<pre><code># Makefile\n.PHONY: mlflow-demo mlflow-ui\n\nmlflow-demo:\n@echo \"Logging to MLflow...\"\nMLFLOW_TRACKING_URI=file:./mlruns python scripts/run_mlflow.py\n\nmlflow-ui:\n@echo \"Starting MLflow UI at http://localhost:5000\"\nmlflow ui --host 0.0.0.0 --port 5000\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#106-ingenieria-inversa-pedagogica-mlflow-en-produccion-real","title":"10.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: MLflow en Producci\u00f3n Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n arquitect\u00f3nica detr\u00e1s del setup de MLflow del portafolio.</p> <p>Esta secci\u00f3n aplica el m\u00e9todo de \"Shadow Coder Senior\": diseccionamos la infraestructura MLflow real que soporta los 3 proyectos del portafolio.</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1061-el-por-que-arquitectonico","title":"10.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 el portafolio usa un <code>docker-compose.mlflow.yml</code> separado en lugar de un simple <code>mlflow ui</code>?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: `mlflow ui` guarda todo en archivos locales (SQLite + filesystem)  \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: P\u00e9rdida de datos, no escalable, no colaborativo                        \u2502\n\u2502  DECISI\u00d3N: PostgreSQL como backend store                                        \u2502\n\u2502  RESULTADO: Persistencia robusta, queries SQL, backups f\u00e1ciles                  \u2502\n\u2502  REFERENCIA: docker-compose.mlflow.yml l\u00edneas 8-24                              \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: Artifacts grandes (modelos) saturan el disco del servidor          \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Sin espacio, artifacts perdidos, no replicable a la nube               \u2502\n\u2502  DECISI\u00d3N: MinIO (S3-compatible) como artifact store                            \u2502\n\u2502  RESULTADO: Storage ilimitado, compatible con AWS S3, UI para navegar           \u2502\n\u2502  REFERENCIA: docker-compose.mlflow.yml l\u00edneas 27-46                             \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: Equipos necesitan compartir experimentos y modelos                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: \"Funciona en mi m\u00e1quina\", modelos duplicados, sin trazabilidad         \u2502\n\u2502  DECISI\u00d3N: Servidor MLflow centralizado con Model Registry                      \u2502\n\u2502  RESULTADO: Un solo punto de verdad, promoci\u00f3n Staging\u2192Production               \u2502\n\u2502  REFERENCIA: docker-compose.mlflow.yml l\u00edneas 66-97                             \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1062-anatomia-de-docker-composemlflowyml","title":"10.6.2 \ud83d\udd0d Anatom\u00eda de <code>docker-compose.mlflow.yml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/docker-compose.mlflow.yml</code></p> <pre><code>version: '3.8'\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SERVICIO 1: PostgreSQL (Backend Store)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nservices:\n  postgres:\n    image: postgres:13-alpine                    # Alpine = imagen ligera (~50MB vs 300MB).\n    container_name: mlflow-postgres\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER:-mlflow}   # ${VAR:-default}: usa variable de entorno o default.\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-mlflow_password}\n      - POSTGRES_DB=${POSTGRES_DB:-mlflow}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data  # Volumen nombrado: persiste datos entre reinicios.\n    healthcheck:                                 # Docker verifica que Postgres est\u00e9 LISTO.\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER:-mlflow}\"]\n      interval: 10s                              # Chequea cada 10 segundos.\n      timeout: 5s                                # Falla si no responde en 5s.\n      retries: 5                                 # 5 intentos antes de declarar \"unhealthy\".\n    networks:\n      - mlflow-network                           # Red interna: a\u00edsla servicios del host.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SERVICIO 2: MinIO (Artifact Store S3-Compatible)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  minio:\n    image: minio/minio:latest\n    container_name: mlflow-minio\n    ports:\n      - \"9000:9000\"                              # API: donde MLflow sube/descarga artifacts.\n      - \"9001:9001\"                              # Console: UI web para navegar buckets.\n    environment:\n      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}\n      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}\n    volumes:\n      - minio_data:/data                         # Artifacts persisten aqu\u00ed.\n    command: server /data --console-address \":9001\"  # Inicia servidor con UI en 9001.\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n# \u00bfPor qu\u00e9 curl y no un comando interno? MinIO expone health checks HTTP nativamente.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SERVICIO 3: Bucket Creator (Init Container)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  minio-create-bucket:\n    image: minio/mc:latest                       # mc = MinIO Client (CLI).\n    container_name: mlflow-minio-setup\n    depends_on:\n      - minio                                    # Espera a que MinIO arranque.\n    entrypoint: &gt;                                # Script inline (patr\u00f3n com\u00fan en docker-compose).\n      /bin/sh -c \"\n      sleep 10;                                  # Espera adicional (MinIO puede tardar).\n      /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin;\n      /usr/bin/mc mb myminio/mlflow-artifacts --ignore-existing;  # Crea bucket si no existe.\n      /usr/bin/mc anonymous set download myminio/mlflow-artifacts;  # Permite descargas.\n      exit 0;\n      \"\n# \u00bfPor qu\u00e9 un contenedor separado? Patr\u00f3n \"init container\": ejecuta una vez y termina.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SERVICIO 4: MLflow Server\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:latest\n    container_name: mlflow-server\n    ports:\n      - \"5000:5000\"                              # UI y API en el mismo puerto.\n    environment:\n      # Backend store: d\u00f3nde guardar metadata (runs, params, metrics).\n      - MLFLOW_BACKEND_STORE_URI=postgresql://mlflow:mlflow_password@postgres:5432/mlflow\n      # Artifact store: d\u00f3nde guardar archivos grandes (modelos, plots).\n      - MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlflow-artifacts/\n      # Credenciales para MinIO (simula AWS S3).\n      - AWS_ACCESS_KEY_ID=minioadmin\n      - AWS_SECRET_ACCESS_KEY=minioadmin\n      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000  # CR\u00cdTICO: apunta a MinIO, no a AWS.\n    depends_on:\n      postgres:\n        condition: service_healthy               # Espera a que Postgres est\u00e9 healthy.\n      minio:\n        condition: service_healthy\n      minio-create-bucket:\n        condition: service_completed_successfully  # Espera a que el bucket exista.\n    command: &gt;\n      mlflow server\n      --backend-store-uri postgresql://mlflow:mlflow_password@postgres:5432/mlflow\n      --default-artifact-root s3://mlflow-artifacts/\n      --host 0.0.0.0                             # Escucha en todas las interfaces.\n      --port 5000\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1063-anatomia-de-scriptsrun_mlflowpy","title":"10.6.3 \ud83d\udd0d Anatom\u00eda de <code>scripts/run_mlflow.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/scripts/run_mlflow.py</code></p> <p>Este script es el puente entre el entrenamiento local y el servidor MLflow centralizado.</p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Configuraci\u00f3n Flexible v\u00eda Variables de Entorno\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef main() -&gt; None:\n    tracking_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"file:./mlruns\")\n    # \u00bfPor qu\u00e9 os.getenv con default?\n    # - En desarrollo: usa \"file:./mlruns\" (local, sin servidor).\n    # - En CI/CD: setea MLFLOW_TRACKING_URI=http://mlflow:5000.\n    # - En producci\u00f3n: apunta al servidor real.\n\n    experiment = os.getenv(\"MLFLOW_EXPERIMENT_NAME\") or \"BankChurn\"\n    # Patr\u00f3n \"or\": si la variable est\u00e1 vac\u00eda (\"\"), usa el default.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Carga y Transformaci\u00f3n de M\u00e9tricas\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    results_path = Path(\"artifacts/training_results.json\")\n    if results_path.exists():\n        data = json.loads(results_path.read_text())\n\n        # Extraer m\u00e9tricas de CV (cross-validation)\n        cv = data.get(\"cv_results\", {})\n        for k, v in cv.items():\n            if isinstance(v, (int, float)):      # Solo loguea valores num\u00e9ricos.\n                metrics[f\"cv_{k}\"] = float(v)    # Prefijo \"cv_\" para distinguir.\n\n        # Extraer m\u00e9tricas de test\n        test_metrics = data.get(\"test_results\", {}).get(\"metrics\", {})\n        for k, v in test_metrics.items():\n            metrics[f\"test_{k}\"] = float(v)      # Prefijo \"test_\" para distinguir.\n# \u00bfPor qu\u00e9 prefijos? En MLflow UI puedes filtrar por \"cv_*\" vs \"test_*\".\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: M\u00e9tricas de Negocio (Lo que distingue a un Senior)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n        cm = test_results.get(\"confusion_matrix\")  # [[TN, FP], [FN, TP]]\n        if cm:\n            tn, fp = cm[0]\n            fn, tp = cm[1]\n\n            clv = float(os.getenv(\"BC_CLV_USD\", \"2300\"))  # Customer Lifetime Value.\n            retention_rate = float(os.getenv(\"BC_RETENTION_RATE\", \"0.3\"))\n\n            saved_customers = float(tp) * retention_rate\n            saved_revenue = saved_customers * clv\n\n            business_metrics = {\n                \"biz_saved_customers_proxy\": saved_customers,\n                \"biz_saved_revenue_proxy_usd\": saved_revenue,\n            }\n# \u00bfPor qu\u00e9 m\u00e9tricas de negocio?\n# - \"F1=0.85\" no significa nada para el negocio.\n# - \"$690,000 en revenue salvado\" s\u00ed justifica el proyecto.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 4: Logging con Manejo Robusto de Errores\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    with mlflow.start_run(run_name=\"demo-logging\"):\n        mlflow.log_params({\"run_type\": \"demo\"})\n        mlflow.log_metrics(metrics)\n        mlflow.log_metrics(business_metrics)\n\n        # Artifacts: best-effort (puede fallar si el store no es accesible)\n        for p in [Path(\"artifacts/training_results.json\"), Path(\"configs/config.yaml\")]:\n            if p.exists():\n                try:\n                    mlflow.log_artifact(str(p))\n                except PermissionError:\n                    print(f\"Skipping artifact {p}: permission denied\")\n                    # NO crashea el script, solo advierte.\n# \u00bfPor qu\u00e9 try/except en artifacts?\n# - En CI/CD, el artifact store puede no ser accesible desde el runner.\n# - Mejor loguear m\u00e9tricas (cr\u00edtico) que fallar por artifacts (nice-to-have).\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1064-anatomia-de-scriptspromote_modelpy","title":"10.6.4 \ud83d\udd0d Anatom\u00eda de <code>scripts/promote_model.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/scripts/promote_model.py</code></p> <p>Este script implementa el flujo CD para modelos: validaci\u00f3n \u2192 registro \u2192 promoci\u00f3n.</p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Configuraci\u00f3n Multi-Proyecto\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nPROJECT_CONFIGS = {\n    \"bankchurn\": {\n        \"dir\": \"BankChurn-Predictor\",\n        \"model_name\": \"BankChurn-Classifier\",\n        \"model_path\": \"models/best_model.pkl\",\n        \"metrics_path\": \"artifacts/metrics.json\",\n        \"default_thresholds\": {\"f1\": 0.50, \"auc\": 0.75},  # Umbrales m\u00ednimos.\n    },\n    \"carvision\": {...},\n    \"telecom\": {...},\n}\n# \u00bfPor qu\u00e9 un dict de configs?\n# - Un solo script maneja los 3 proyectos del portafolio.\n# - Cada proyecto tiene sus propios umbrales (clasificaci\u00f3n vs regresi\u00f3n).\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Validaci\u00f3n de M\u00e9tricas (Quality Gate)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef validate_metrics(metrics: dict, thresholds: dict) -&gt; tuple[bool, list[str]]:\n    failures = []\n    for threshold_name, threshold_value in thresholds.items():\n        actual_value = metrics.get(threshold_name)\n        if actual_value is not None:\n            # RMSE: menor es mejor. Otros: mayor es mejor.\n            if threshold_name == \"rmse\":\n                if actual_value &gt; threshold_value:\n                    failures.append(f\"{threshold_name}: {actual_value:.4f} &gt; {threshold_value}\")\n            else:\n                if actual_value &lt; threshold_value:\n                    failures.append(f\"{threshold_name}: {actual_value:.4f} &lt; {threshold_value}\")\n    return len(failures) == 0, failures\n# \u00bfPor qu\u00e9 validar antes de promover?\n# - Evita poner en producci\u00f3n un modelo que empeor\u00f3.\n# - Es el \"quality gate\" del flujo CD para ML.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: Promoci\u00f3n Condicional\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nif promote and passed:\n    client = MlflowClient()\n    versions = client.search_model_versions(f\"name='{model_name}'\")\n    if versions:\n        latest_version = max(versions, key=lambda v: int(v.version))\n        client.transition_model_version_stage(\n            name=model_name,\n            version=latest_version.version,\n            stage=\"Production\",\n            archive_existing_versions=True,  # Archiva la versi\u00f3n anterior.\n        )\n# \u00bfPor qu\u00e9 archive_existing_versions=True?\n# - Solo una versi\u00f3n puede estar en \"Production\" a la vez.\n# - Las versiones anteriores se mueven a \"Archived\" (no se borran).\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1065-laboratorio-de-replicacion","title":"10.6.5 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Levantar el stack MLflow completo y registrar tu primer modelo.</p> <ol> <li> <p>Levanta la infraestructura:    <pre><code>cd /ruta/a/ML-MLOps-Portfolio\ndocker-compose -f docker-compose.mlflow.yml up -d\n\n# Verifica que todo est\u00e9 healthy\ndocker-compose -f docker-compose.mlflow.yml ps\n</code></pre></p> </li> <li> <p>Accede a las UIs:</p> </li> <li>MLflow: http://localhost:5000</li> <li> <p>MinIO Console: http://localhost:9001 (user: minioadmin, pass: minioadmin)</p> </li> <li> <p>Conecta desde Python:    <pre><code>import mlflow\nmlflow.set_tracking_uri(\"http://localhost:5000\")  # URL del servidor MLflow (local o remoto).\nmlflow.set_experiment(\"mi-primer-experimento\")\n\nwith mlflow.start_run():\n    mlflow.log_param(\"test\", \"valor\")\n    mlflow.log_metric(\"accuracy\", 0.95)\n    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n</code></pre></p> </li> <li> <p>Verifica en la UI que el run aparece con params y m\u00e9tricas.</p> </li> </ol>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1066-troubleshooting-preventivo","title":"10.6.6 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n \"Connection refused\" al conectar a MLflow Servidor no arranc\u00f3 o puerto bloqueado <code>docker-compose logs mlflow</code> para ver errores. Verifica que puerto 5000 est\u00e9 libre. \"Unable to upload artifact\" MinIO no accesible o credenciales incorrectas Verifica <code>MLFLOW_S3_ENDPOINT_URL</code> apunta a MinIO. Revisa user/pass. Artifacts visibles en UI pero no descargables Bucket sin permisos de lectura Ejecuta <code>mc anonymous set download myminio/mlflow-artifacts</code>. Runs no aparecen en el experimento correcto <code>set_experiment()</code> no llamado antes de <code>start_run()</code> Siempre llama <code>mlflow.set_experiment(\"nombre\")</code> antes. \"Model registry is not available\" Backend store es file-based El registry requiere una DB real (PostgreSQL/MySQL). No funciona con <code>file:./mlruns</code>."},{"location":"docs/10_EXPERIMENT_TRACKING/#errores-habituales-y-como-depurarlos-en-mlflow","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en MLflow","text":"<p>MLflow a\u00f1ade una capa extra (servidor, rutas, artefactos), as\u00ed que muchos errores son de configuraci\u00f3n m\u00e1s que de c\u00f3digo puro.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#1-runs-que-no-aparecen-en-la-ui-tracking_uriexperimento-incorrectos","title":"1) Runs que no aparecen en la UI (tracking_uri/experimento incorrectos)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Ejecutas training o <code>run_mlflow.py</code> y no ves nada nuevo en <code>http://localhost:5000</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Imprime <code>mlflow.get_tracking_uri()</code> y el experimento actual (<code>mlflow.get_experiment_by_name(...)</code>).</li> <li>Verifica si est\u00e1s usando <code>file:./mlruns</code> mientras tienes un servidor en Docker (<code>http://localhost:5000</code>).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Define claramente en config:</li> <li>Desarrollo local \u2192 <code>tracking_uri: \"file:./mlruns\"</code>.</li> <li>Demo/stack Docker \u2192 <code>tracking_uri: \"http://mlflow:5000\"</code> o <code>http://localhost:5000</code>.</li> <li>Aseg\u00farate de que tanto <code>ChurnTrainer</code> como <code>scripts/run_mlflow.py</code> lean del mismo origen (YAML/env vars).</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#2-errores-al-registrar-modelos-mlflowexception-permisos-backend","title":"2) Errores al registrar modelos (<code>MlflowException</code>, permisos, backend)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Al llamar <code>mlflow.sklearn.log_model(..., registered_model_name=...)</code> obtienes errores sobre base de datos o registry no configurado.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Si usas solo <code>file:./mlruns</code> sin servidor, el registry completo no est\u00e1 disponible.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Para desarrollo ligero, limita el uso de registry (puedes usar solo tracking + artifacts).</li> <li>Para un registry completo, usa el <code>docker-compose.mlflow.yml</code> del portafolio con backend SQLite/postgres y apunta <code>MLFLOW_TRACKING_URI</code> al servidor.</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#3-artifacts-que-no-se-encuentran-o-no-se-suben","title":"3) Artifacts que no se encuentran o no se suben","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores tipo <code>FileNotFoundError</code> al hacer <code>mlflow.log_artifact</code>.</li> <li>No ves <code>training_results.json</code> ni <code>config.yaml</code> en la pesta\u00f1a de artifacts.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa rutas relativas en <code>run_mlflow.py</code> y aseg\u00farate de que ejecutas el script desde la ra\u00edz del proyecto.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa rutas consistentes (por ejemplo <code>artifacts/training_results.json</code>) y verifica que el archivo exista antes de loguearlo.</li> <li>Si corres dentro de Docker, revisa que el volumen monte correctamente <code>artifacts/</code> y <code>configs/</code>.</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#4-problemas-con-mlflow-en-docker-puertos-hostnames-permisos","title":"4) Problemas con MLflow en Docker (puertos, hostnames, permisos)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>ConnectionError</code> al intentar conectar a <code>http://localhost:5000</code> desde un contenedor.</li> <li>Logs que muestran errores de permisos en <code>/mlflow</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Examina <code>docker-compose.mlflow.yml</code> y las variables de entorno de tus servicios.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Dentro de un contenedor, usa el hostname del servicio (<code>http://mlflow:5000</code>) en lugar de <code>localhost</code>.</li> <li>Aseg\u00farate de que el volumen <code>mlflow-artifacts</code> tenga permisos de escritura correctos (usuario del contenedor).</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#patron-general-de-debugging-en-mlflow","title":"Patr\u00f3n general de debugging en MLflow","text":"<ol> <li>Comprueba tracking_uri y experimento antes de iniciar el run.</li> <li>Valida artifacts y modelos: que los paths existen y se cargan correctamente.</li> <li>Reproduce localmente con file store (<code>file:./mlruns</code>) antes de ir a servidor Docker.</li> <li>Verifica desde la UI que params, metrics y artifacts coincidan con lo que esperas de tu c\u00f3digo.</li> </ol> <p>Con este patr\u00f3n, MLflow pasa de ser \u201ccaja negra\u201d a una herramienta confiable para explicar, comparar y promover modelos.</p> <p></p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-integrar-mlflow-en-telecomai","title":"\u2705 Ejercicio: Integrar MLflow en TelecomAI","text":"<ol> <li>Crea <code>scripts/run_mlflow.py</code> para TelecomAI</li> <li>Log las m\u00e9tricas: accuracy, f1, precision, recall, roc_auc</li> <li>Calcula m\u00e9tricas de negocio (customers retained, revenue saved)</li> <li>Registra el modelo como \"TelecomPlanClassifier\"</li> </ol>"},{"location":"docs/10_EXPERIMENT_TRACKING/#checkpoint","title":"\u2705 Checkpoint","text":"<ul> <li>[ ] Puedo correr un run end-to-end y verlo en la UI (o en <code>mlflow ui</code>).</li> <li>[ ] Puedo explicar d\u00f3nde quedan:</li> <li>params</li> <li>metrics</li> <li>artifacts</li> <li>[ ] Puedo comparar 2 runs y justificar qu\u00e9 cambi\u00f3 (params \u2192 m\u00e9tricas).</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#_1","title":"10 \u2014 Experiment Tracking","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-puente-mlflow","title":"\ud83d\udcbb Ejercicio Puente: MLflow","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: - Revisa el c\u00f3digo de ejemplo en la secci\u00f3n siguiente - Identifica los patrones clave - Replica el patr\u00f3n en un proyecto simple</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#practica-del-portafolio-experiment-tracking-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Experiment Tracking en BankChurn","text":"<p>Tarea: Aplicar los conceptos de este m\u00f3dulo en BankChurn-Predictor.</p> <p>Pasos: 1. Navega al proyecto: <code>cd BankChurn-Predictor</code> 2. Localiza el c\u00f3digo relevante en <code>src/bankchurn/</code> 3. Verifica la implementaci\u00f3n actual 4. Aplica mejoras seg\u00fan las buenas pr\u00e1cticas de este m\u00f3dulo</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#checkpoint-de-conocimiento-experiment-tracking","title":"\u2705 Checkpoint de Conocimiento: Experiment Tracking","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el concepto m\u00e1s importante de este m\u00f3dulo? - Revisa el mapa mental y la secci\u00f3n principal</p> <p>Pregunta 2: \u00bfC\u00f3mo se aplica en el portafolio? - Examina el c\u00f3digo de BankChurn-Predictor</p> <p>\ud83d\udd27 Escenario de Debugging: - Identifica un problema com\u00fan en este tema - Practica la soluci\u00f3n con el c\u00f3digo del portafolio</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>MLflow est\u00e1 integrado en los 3 proyectos del portafolio:</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#configuracion-mlflow-en-bankchurn","title":"Configuraci\u00f3n MLflow en BankChurn","text":"<pre><code># BankChurn-Predictor/src/bankchurn/config.py\nclass MLflowConfig(BaseModel):\n    \"\"\"MLflow tracking configuration.\"\"\"\n    tracking_uri: str = \"file:./mlruns\"  # URI donde se guardan los experimentos (archivo local).  # Local por defecto\n    experiment_name: str = \"bankchurn\"\n    enabled: bool = True\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#integracion-en-trainer","title":"Integraci\u00f3n en Trainer","text":"<pre><code># BankChurn-Predictor/src/bankchurn/trainer.py (extracto)\ndef _log_to_mlflow(self):\n    \"\"\"Log experimento a MLflow.\"\"\"\n    if not self.config.mlflow.enabled:\n        return\n\n    mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)\n    mlflow.set_experiment(self.config.mlflow.experiment_name)\n\n    with mlflow.start_run():\n        # Par\u00e1metros\n        mlflow.log_params({\n            \"model_type\": self.config.model.type,\n            \"test_size\": self.config.model.test_size,\n            \"cv_folds\": self.config.model.cv_folds,\n        })\n\n        # M\u00e9tricas\n        mlflow.log_metrics(self.metrics_)\n\n        # Modelo\n        mlflow.sklearn.log_model(self.model_, \"model\")\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#estructura-de-mlruns","title":"Estructura de mlruns/","text":"<pre><code>BankChurn-Predictor/\n\u2514\u2500\u2500 mlruns/\n    \u251c\u2500\u2500 0/                    # Default experiment\n    \u2514\u2500\u2500 123456789/            # bankchurn experiment\n        \u2514\u2500\u2500 abc123def456/     # Run ID\n            \u251c\u2500\u2500 artifacts/\n            \u2502   \u2514\u2500\u2500 model/\n            \u251c\u2500\u2500 metrics/\n            \u2502   \u251c\u2500\u2500 accuracy\n            \u2502   \u251c\u2500\u2500 f1_score\n            \u2502   \u2514\u2500\u2500 roc_auc\n            \u251c\u2500\u2500 params/\n            \u2502   \u251c\u2500\u2500 model_type\n            \u2502   \u2514\u2500\u2500 cv_folds\n            \u2514\u2500\u2500 meta.yaml\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#mlflow-por-proyecto","title":"MLflow por Proyecto","text":"Proyecto Tracking URI Experiment M\u00e9tricas Principales BankChurn <code>file:./mlruns</code> <code>bankchurn</code> accuracy, f1, roc_auc CarVision <code>file:./mlruns</code> <code>carvision</code> mae, rmse, r2 TelecomAI <code>file:./mlruns</code> <code>telecomai</code> accuracy, f1_weighted"},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-explora-mlflow-real","title":"\ud83d\udd27 Ejercicio: Explora MLflow Real","text":"<pre><code># 1. Ve a BankChurn\ncd BankChurn-Predictor\n\n# 2. Entrena con MLflow habilitado\npython main.py --config configs/config.yaml\n\n# 3. Inicia la UI de MLflow\nmlflow ui --backend-store-uri file:./mlruns\n\n# 4. Abre en navegador\n# http://localhost:5000\n\n# 5. Explora:\n# - Compara runs\n# - Ve artifacts\n# - Registra modelo en Model Registry\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>MLflow vs W&amp;B vs Neptune: Conoce trade-offs (MLflow open-source, W&amp;B mejor UI, Neptune escalabilidad).</p> </li> <li> <p>Model Registry: Explica stages (Staging \u2192 Production \u2192 Archived).</p> </li> <li> <p>Reproducibilidad: C\u00f3mo reconstruir cualquier experimento desde el tracking.</p> </li> </ol>"},{"location":"docs/10_EXPERIMENT_TRACKING/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Equipo distribuido Usa servidor MLflow centralizado Muchos experimentos Organiza con tags y naming conventions Modelos grandes Usa artifact storage externo (S3, GCS) Comparaci\u00f3n Siempre registra baseline para comparar"},{"location":"docs/10_EXPERIMENT_TRACKING/#que-trackear-siempre","title":"Qu\u00e9 Trackear Siempre","text":"<ul> <li>Params: Hiperpar\u00e1metros, versiones de datos</li> <li>Metrics: Train/val/test, m\u00e9tricas de negocio</li> <li>Artifacts: Modelo, configs, plots, requirements.txt</li> <li>Tags: Git commit, autor, dataset version</li> </ul>"},{"location":"docs/10_EXPERIMENT_TRACKING/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 MLflow Tutorial Krish Naik 40 min YouTube \ud83d\udd34 MLflow Complete Course DataTalksClub 1.5h YouTube \ud83d\udfe1 Weights &amp; Biases Quickstart W&amp;B 20 min YouTube"},{"location":"docs/10_EXPERIMENT_TRACKING/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 MLflow Tracking Gu\u00eda oficial tracking \ud83d\udd34 MLflow Model Registry Registro de modelos"},{"location":"docs/10_EXPERIMENT_TRACKING/#decision-tecnica-adr-010-mlflow","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-010 MLflow","text":"<p>Contexto: Necesitamos trackear experimentos y versionar modelos.</p> <p>Decisi\u00f3n: Usar MLflow para experiment tracking y model registry.</p> <p>Alternativas Consideradas: - Weights &amp; Biases: Mejor UI pero SaaS (costo) - Neptune: Escalable pero pago - TensorBoard: Solo para deep learning</p> <p>Consecuencias: - \u2705 Open source, self-hosted - \u2705 Model Registry integrado - \u2705 Integraci\u00f3n con sklearn, PyTorch, etc. - \u274c UI menos pulida que W&amp;B</p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-101-mlflow-basico","title":"Ejercicio 10.1: MLflow B\u00e1sico","text":"<p>Objetivo: Trackear un experimento con MLflow. Dificultad: \u2b50\u2b50</p> <pre><code>import mlflow\n\n# TU TAREA: Completar el tracking\ndef train_with_mlflow(X_train, y_train, X_test, y_test, params):\n    # 1. Iniciar run\n    # 2. Log params\n    # 3. Entrenar modelo\n    # 4. Log metrics\n    # 5. Log model\n    pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import mlflow\nimport mlflow.sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, accuracy_score\n\ndef train_with_mlflow(X_train, y_train, X_test, y_test, params: dict):\n    \"\"\"Entrena modelo con tracking completo en MLflow.\"\"\"\n\n    # Configurar experimento\n    mlflow.set_experiment(\"bankchurn-classifier\")\n\n    with mlflow.start_run():\n        # 1. Log par\u00e1metros\n        mlflow.log_params(params)\n\n        # 2. Entrenar modelo\n        model = RandomForestClassifier(\n            n_estimators=params['n_estimators'],\n            max_depth=params.get('max_depth'),\n            random_state=42\n        )\n        model.fit(X_train, y_train)\n\n        # 3. Evaluar\n        y_pred = model.predict(X_test)\n        metrics = {\n            'f1': f1_score(y_test, y_pred),\n            'accuracy': accuracy_score(y_test, y_pred)\n        }\n\n        # 4. Log m\u00e9tricas\n        mlflow.log_metrics(metrics)\n\n        # 5. Log modelo\n        mlflow.sklearn.log_model(\n            model,\n            \"model\",\n            registered_model_name=\"bankchurn-rf\"\n        )\n\n        # 6. Log artifacts adicionales\n        # mlflow.log_artifact(\"configs/config.yaml\")\n\n        print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n        return model, metrics\n\n# Uso:\nparams = {'n_estimators': 100, 'max_depth': 10}\nmodel, metrics = train_with_mlflow(X_train, y_train, X_test, y_test, params)\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-102-comparar-experimentos","title":"Ejercicio 10.2: Comparar Experimentos","text":"<p>Objetivo: Ejecutar y comparar m\u00faltiples configuraciones. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: Ejecutar grid de experimentos y encontrar el mejor\n\nconfigs = [\n    {'n_estimators': 50, 'max_depth': 5},\n    {'n_estimators': 100, 'max_depth': 10},\n    {'n_estimators': 200, 'max_depth': 15},\n]\n\n# \u00bfC\u00f3mo organizar\u00edas estos experimentos en MLflow?\n# \u00bfC\u00f3mo encontrar\u00edas el mejor?\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import mlflow\nfrom mlflow.tracking import MlflowClient\n\ndef run_experiments(X_train, y_train, X_test, y_test, configs: list):\n    \"\"\"Ejecuta m\u00faltiples configuraciones y las compara.\"\"\"\n\n    mlflow.set_experiment(\"bankchurn-hyperparameter-search\")\n\n    results = []\n    for config in configs:\n        with mlflow.start_run():\n            # Tag para identificar el experimento\n            mlflow.set_tag(\"config_name\", f\"rf_{config['n_estimators']}_{config['max_depth']}\")\n\n            # Entrenar y evaluar\n            model, metrics = train_model(X_train, y_train, X_test, y_test, config)\n\n            results.append({\n                'run_id': mlflow.active_run().info.run_id,\n                'config': config,\n                'f1': metrics['f1']\n            })\n\n    return results\n\ndef find_best_run(experiment_name: str, metric: str = \"f1\"):\n    \"\"\"Encuentra el mejor run de un experimento.\"\"\"\n    client = MlflowClient()\n    experiment = client.get_experiment_by_name(experiment_name)\n\n    runs = client.search_runs(\n        experiment_ids=[experiment.experiment_id],\n        order_by=[f\"metrics.{metric} DESC\"],\n        max_results=1\n    )\n\n    if runs:\n        best = runs[0]\n        print(f\"Best run: {best.info.run_id}\")\n        print(f\"Best {metric}: {best.data.metrics[metric]}\")\n        print(f\"Params: {best.data.params}\")\n        return best\n    return None\n\n# Ejecutar experimentos\nresults = run_experiments(X_train, y_train, X_test, y_test, configs)\n\n# Encontrar el mejor\nbest_run = find_best_run(\"bankchurn-hyperparameter-search\", \"f1\")\n\n# Promover a producci\u00f3n\nclient = MlflowClient()\nclient.transition_model_version_stage(\n    name=\"bankchurn-rf\",\n    version=1,\n    stage=\"Production\"\n)\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n MLflow Plataforma open source para gesti\u00f3n del ciclo de vida ML Run Una ejecuci\u00f3n de un experimento con par\u00e1metros espec\u00edficos Model Registry Sistema para versionar y gestionar modelos en producci\u00f3n Artifact Archivo guardado junto con un run (modelo, plots, configs)"},{"location":"docs/10_EXPERIMENT_TRACKING/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#trampa-1-mlflow-run-sin-cerrar","title":"Trampa 1: MLflow run sin cerrar","text":"<p>S\u00edntoma: <pre><code>mlflow.start_run()\nmlflow.log_param(\"lr\", 0.01)\n# Script termina sin mlflow.end_run()\n\n# Siguiente ejecuci\u00f3n:\nmlflow.start_run()\n# Exception: Run already active\n</code></pre></p> <p>Soluci\u00f3n: Siempre usar context manager: <pre><code>with mlflow.start_run():\n    mlflow.log_param(\"lr\", 0.01)\n    # Se cierra autom\u00e1ticamente\n</code></pre></p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#trampa-2-mlflow-log_model-sin-signature","title":"Trampa 2: MLflow log_model sin signature","text":"<p>S\u00edntoma: En producci\u00f3n, el modelo acepta cualquier input y falla cr\u00edpicamente.</p> <p>Soluci\u00f3n: <pre><code>from mlflow.models import infer_signature\n\nsignature = infer_signature(X_train, model.predict(X_train))\nmlflow.sklearn.log_model(model, \"model\", signature=signature)\n</code></pre></p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#trampa-3-mlflow-tracking-uri-incorrecto","title":"Trampa 3: MLflow tracking URI incorrecto","text":"<p>S\u00edntoma: <code>mlflow.log_metric()</code> no aparece en mlflow ui.</p> <p>Soluci\u00f3n: <pre><code>print(mlflow.get_tracking_uri())  # Verificar\nmlflow.set_tracking_uri(\"file:./mlruns\")  # Configurar expl\u00edcitamente\n</code></pre></p>"},{"location":"docs/10_EXPERIMENT_TRACKING/#quiz-del-modulo-semanas-11-12","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 11-12","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#quiz-semana-11-mlflow-tracking","title":"Quiz Semana 11: MLflow Tracking","text":""},{"location":"docs/10_EXPERIMENT_TRACKING/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfCu\u00e1l es la diferencia entre un Experiment y un Run en MLflow?</p> \u2705 Respuesta  - **Experiment**: Contenedor de runs relacionados (un proyecto o hip\u00f3tesis) - **Run**: Una ejecuci\u00f3n individual de training (un intento/iteraci\u00f3n)  <pre><code>Experiment: bankchurn-classifier\n\u251c\u2500\u2500 Run 1: baseline (accuracy=0.82)\n\u251c\u2500\u2500 Run 2: con feature engineering (accuracy=0.85)\n\u2514\u2500\u2500 Run 3: hyperparameter tuning (accuracy=0.87)\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPor qu\u00e9 es importante <code>mlflow.log_model</code> con signature?</p> \u2705 Respuesta  La signature define el contrato de entrada/salida del modelo: 1. **Documentaci\u00f3n ejecutable**: Sabes qu\u00e9 features espera 2. **Validaci\u00f3n en serving**: MLflow valida input autom\u00e1ticamente 3. **Compatibilidad**: Evita errores de tipos en producci\u00f3n"},{"location":"docs/10_EXPERIMENT_TRACKING/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfC\u00f3mo cargar\u00edas un modelo del Model Registry para producci\u00f3n?</p> \u2705 Respuesta <pre><code># Por nombre y stage\nmodel = mlflow.pyfunc.load_model(\"models:/BankChurn/Production\")\n\n# Por nombre y versi\u00f3n espec\u00edfica\nmodel = mlflow.pyfunc.load_model(\"models:/BankChurn/3\")\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Escribe un script que configure experiment, loguee par\u00e1metros y m\u00e9tricas, y registre el modelo con signature.</p> \u2705 Soluci\u00f3n <pre><code>import mlflow\nfrom mlflow.models import infer_signature\n\nmlflow.set_experiment(\"my-classifier\")\n\nwith mlflow.start_run(run_name=\"rf-training\"):\n    mlflow.log_params({\"n_estimators\": 100, \"max_depth\": 10})\n\n    model = RandomForestClassifier(n_estimators=100, max_depth=10)\n    model.fit(X_train, y_train)\n\n    mlflow.log_metrics({\"accuracy\": 0.85, \"f1\": 0.82})\n\n    signature = infer_signature(X_train, model.predict(X_train))\n    mlflow.sklearn.log_model(model, \"model\", signature=signature,\n                             registered_model_name=\"MyClassifier\")\n</code></pre>"},{"location":"docs/10_EXPERIMENT_TRACKING/#fin-de-fase-2-ml-engineering","title":"\ud83c\udfc1 FIN DE FASE 2: ML Engineering","text":"<p>\ud83c\udfaf \u00a1Has completado los m\u00f3dulos 07-10!</p> <p>Ahora dominas las t\u00e9cnicas de ML Engineering profesional: - \u2705 Pipelines sklearn reproducibles - \u2705 Feature engineering sin data leakage - \u2705 Training profesional con cross-validation - \u2705 Experiment tracking con MLflow</p> <p>Siguiente: Fase 3 - MLOps Core (Testing, CI/CD, Docker, APIs)</p>   **Siguiente m\u00f3dulo** \u2192 [11. Testing ML](11_TESTING_ML.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/11_TESTING_ML/","title":"11. Testing para Machine Learning","text":""},{"location":"docs/11_TESTING_ML/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Tener <code>pytest</code> y <code>pytest-cov</code> disponibles en tu entorno.</li> <li>Haber revisado la estructura <code>src/</code> + <code>tests/</code> en al menos 1 proyecto del portafolio.</li> </ul>"},{"location":"docs/11_TESTING_ML/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de empezar: abre Protocolo E y define tu output m\u00ednimo (una suite que corre en CI).</li> <li>Durante el debugging: si te atoras &gt;15 min (fixtures, flaky tests, coverage), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar si tus tests realmente protegen el pipeline.</li> </ul>"},{"location":"docs/11_TESTING_ML/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] Un <code>tests/</code> con:</li> <li><code>conftest.py</code> con fixtures reutilizables</li> <li>unit tests para features/transformers</li> <li>data tests (rango, NaN, schema)</li> <li>al menos 1 integraci\u00f3n (pipeline o API)</li> <li>[ ] Coverage <code>&gt;= 80%</code> (en al menos 1 proyecto).</li> <li>[ ] 1 entrada en Diario de Errores si hubo bloqueo real.</li> </ul>"},{"location":"docs/11_TESTING_ML/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Concepto: testing por capas (unit/data/model/integration/e2e) + coverage</li> <li>Archivo: <code>tests/</code>, <code>pyproject.toml</code> (pytest), workflows CI</li> <li>Prueba: <code>pytest -v --cov=src/&lt;paquete&gt; --cov-report=term-missing</code></li> </ul>"},{"location":"docs/11_TESTING_ML/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Dominar el testing en proyectos ML para alcanzar 80%+ de coverage sin tests fr\u00e1giles ni falsos positivos.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \ud83d\udea8 LA REALIDAD DEL ML SIN TESTS:                                            \u2551\n\u2551                                                                              \u2551\n\u2551  \"El modelo funcionaba ayer, hoy da predicciones random\"                     \u2551\n\u2551  \"Cambi\u00e9 una l\u00ednea y romp\u00ed todo el pipeline\"                                 \u2551\n\u2551  \"No s\u00e9 si el bug est\u00e1 en los datos, el preprocesamiento, o el modelo\"       \u2551\n\u2551                                                                              \u2551\n\u2551  \ud83d\udee1\ufe0f LA REALIDAD CON TESTS:                                                   \u2551\n\u2551                                                                              \u2551\n\u2551  \"CI me avis\u00f3 que romp\u00ed algo antes de hacer merge\"                           \u2551\n\u2551  \"S\u00e9 exactamente qu\u00e9 componente fall\u00f3\"                                       \u2551\n\u2551  \"Puedo refactorizar con confianza\"                                          \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p></p>"},{"location":"docs/11_TESTING_ML/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>11.1 La Pir\u00e1mide de Testing en ML</li> <li>11.2 Fixtures y conftest.py</li> <li>11.3 Unit Tests: Funciones Individuales</li> <li>11.4 Data Tests: Validaci\u00f3n de Datos</li> <li>11.5 Model Tests: Comportamiento del Modelo</li> <li>11.6 Integration Tests: Pipeline Completo</li> <li>11.7 Alcanzar 80% Coverage</li> <li>11.8 \ud83d\udd2c Ingenier\u00eda Inversa: Tests de Producci\u00f3n \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/11_TESTING_ML/#111-la-piramide-de-testing-en-ml","title":"11.1 La Pir\u00e1mide de Testing en ML","text":""},{"location":"docs/11_TESTING_ML/#analogia-inspeccion-de-un-avion","title":"Analog\u00eda: Inspecci\u00f3n de un Avi\u00f3n","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \u2708\ufe0f ANTES DE CADA VUELO, SE INSPECCIONA:                                  \u2551\n\u2551                                                                           \u2551\n\u2551  NIVEL 1 - Componentes individuales (Unit Tests):                         \u2551\n\u2551  \u2022 Cada tornillo est\u00e1 apretado                                            \u2551\n\u2551  \u2022 Cada cable est\u00e1 conectado                                              \u2551\n\u2551  \u2022 Cada sensor funciona                                                   \u2551\n\u2551                                                                           \u2551\n\u2551  NIVEL 2 - Sistemas (Integration Tests):                                  \u2551\n\u2551  \u2022 El motor arranca correctamente                                         \u2551\n\u2551  \u2022 Los flaps responden a los controles                                    \u2551\n\u2551  \u2022 El sistema hidr\u00e1ulico mantiene presi\u00f3n                                 \u2551\n\u2551                                                                           \u2551\n\u2551  NIVEL 3 - Vuelo de prueba (E2E Tests):                                   \u2551\n\u2551  \u2022 El avi\u00f3n despega, vuela, y aterriza                                    \u2551\n\u2551  \u2022 Todo funciona junto bajo condiciones reales                            \u2551\n\u2551                                                                           \u2551\n\u2551  EN ML ES IGUAL: Testeas componentes \u2192 sistemas \u2192 pipeline completo       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/11_TESTING_ML/#la-piramide-especifica-para-ml","title":"La Pir\u00e1mide Espec\u00edfica para ML","text":"<pre><code>                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502    E2E Tests    \u2502 \u2190 5-10% de tests\n                        \u2502   (API real)    \u2502   Lentos, costosos\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   test_api_e2e.py\n                                 \u2502\n                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                     \u2502   Integration Tests   \u2502 \u2190 15-20% de tests\n                     \u2502  (pipeline.fit())     \u2502   Verifican interacci\u00f3n\n                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   test_training.py\n                                 \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502           Model Tests               \u2502 \u2190 20-25% de tests\n              \u2502  (predicciones, m\u00e9tricas, shapes)   \u2502   Espec\u00edficos de ML\n              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   test_model_logic.py\n                                 \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                 Data Tests                      \u2502 \u2190 20-25% de tests\n        \u2502    (schema, rangos, NaN, schema)                \u2502   Validan datos\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   test_data.py\n                                 \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           Unit Tests                                    \u2502 \u2190 30-40% de tests\n\u2502              (funciones individuales, transformers)                     \u2502   R\u00e1pidos, muchos\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   test_features.py\n</code></pre>"},{"location":"docs/11_TESTING_ML/#mapa-mental-de-conceptos-testing-ml","title":"\ud83e\udde0 Mapa Mental de Conceptos: Testing ML","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551      TESTING PROFESIONAL EN ML       \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  TIPOS DE TESTS  \u2502              \u2502  HERRAMIENTAS    \u2502              \u2502  M\u00c9TRICAS        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 Unit tests                     \u251c\u2500 pytest                        \u251c\u2500 Coverage &gt;= 80%\n\u251c\u2500 Data tests                     \u251c\u2500 pytest-cov                    \u251c\u2500 Tests por m\u00f3dulo\n\u251c\u2500 Model tests                    \u251c\u2500 fixtures                      \u251c\u2500 Tiempo de ejecuci\u00f3n\n\u251c\u2500 Integration tests              \u251c\u2500 conftest.py                   \u2514\u2500 Flaky rate\n\u2514\u2500 E2E tests                      \u2514\u2500 markers (@slow)\n</code></pre> <p>T\u00e9rminos clave que debes dominar:</p> T\u00e9rmino Significado Ejemplo Unit test Prueba funci\u00f3n individual <code>test_calculate_age()</code> Data test Valida estructura de datos Schema, rangos, NaN Fixture Datos/objetos reutilizables <code>@pytest.fixture</code> Coverage % c\u00f3digo cubierto por tests <code>pytest --cov</code> Marker Etiqueta tests <code>@pytest.mark.slow</code>"},{"location":"docs/11_TESTING_ML/#ejercicio-puente-tests-basicos","title":"\ud83d\udcbb Ejercicio Puente: Tests B\u00e1sicos","text":"<p>Meta: Antes de crear suites complejas, domina pytest b\u00e1sico.</p> <p>Ejercicio 1: Tu primer test <pre><code># tests/test_example.py\ndef add(a, b):\n    return a + b\n\ndef test_add():\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n\n# TU TAREA: Ejecuta con pytest\n# pytest tests/test_example.py -v\n</code></pre></p> <p>Ejercicio 2: Fixture b\u00e1sica <pre><code>import pytest\n\n@pytest.fixture\ndef sample_data():\n    return {\"name\": \"test\", \"value\": 42}\n\ndef test_with_fixture(sample_data):\n    assert sample_data[\"value\"] == 42\n</code></pre></p> \ud83d\udd0d Ver Comandos \u00datiles <pre><code># Ejecutar todos los tests\npytest\n\n# Con verbose\npytest -v\n\n# Con coverage\npytest --cov=src/\n\n# Solo tests r\u00e1pidos\npytest -m \"not slow\"\n\n# Parar al primer fallo\npytest -x\n</code></pre>"},{"location":"docs/11_TESTING_ML/#checkpoint-de-conocimiento-testing","title":"\u2705 Checkpoint de Conocimiento: Testing","text":"<p>Pregunta 1: \u00bfPor qu\u00e9 los Unit tests est\u00e1n en la base de la pir\u00e1mide?</p> <p>A) Son los m\u00e1s importantes B) Son r\u00e1pidos, baratos, y detectan errores temprano C) pytest los ejecuta primero D) Son m\u00e1s f\u00e1ciles de escribir  </p> <p>Pregunta 2: \u00bfQu\u00e9 valida un Data test?</p> <p>A) Que el modelo predice bien B) Que los datos tienen el schema correcto, rangos v\u00e1lidos, sin NaN inesperados C) Que la API responde D) Que el c\u00f3digo est\u00e1 formateado  </p> \ud83d\udd0d Ver Respuestas  **Pregunta 1**: B) Son r\u00e1pidos, baratos, y detectan errores temprano. Por eso hay muchos.  **Pregunta 2**: B) Schema correcto, rangos v\u00e1lidos, sin NaN inesperados. Validaci\u00f3n de datos."},{"location":"docs/11_TESTING_ML/#coverage-del-portafolio-real","title":"Coverage del Portafolio Real","text":"Proyecto Coverage Tests Tipo Principal BankChurn 79.5% 45+ Unit + Integration CarVision 97% 50+ Unit + Data + Model TelecomAI 97% 35+ Unit + Integration"},{"location":"docs/11_TESTING_ML/#ejercicio-puente-pytest-y-coverage","title":"\ud83d\udcbb Ejercicio Puente: Pytest y Coverage","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/11_TESTING_ML/#practica-del-portafolio-testing-ml-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Testing ML en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Pytest y Coverage\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/11_TESTING_ML/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Testing ML?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Pytest y Coverage, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/11_TESTING_ML/#112-fixtures-y-conftestpy","title":"11.2 Fixtures y conftest.py","text":""},{"location":"docs/11_TESTING_ML/#que-es-una-fixture","title":"\u00bfQu\u00e9 es una Fixture?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83e\uddea FIXTURE = Datos o recursos preparados para tests                      \u2551\n\u2551                                                                           \u2551\n\u2551  Analog\u00eda del laboratorio:                                                \u2551\n\u2551  \u2022 Antes de cada experimento, preparas tus instrumentos                   \u2551\n\u2551  \u2022 Los instrumentos son los mismos para varios experimentos               \u2551\n\u2551  \u2022 No los preparas desde cero cada vez                                    \u2551\n\u2551                                                                           \u2551\n\u2551  En pytest:                                                               \u2551\n\u2551  \u2022 Fixture prepara datos/modelos/configs                                  \u2551\n\u2551  \u2022 Se reutiliza en m\u00faltiples tests                                        \u2551\n\u2551  \u2022 Se limpia autom\u00e1ticamente despu\u00e9s                                      \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/11_TESTING_ML/#conftestpy-del-portafolio-carvision","title":"conftest.py del Portafolio (CarVision)","text":"<pre><code># tests/conftest.py - C\u00f3digo REAL del portafolio\n\nimport pytest                            # Framework de testing para Python.\nimport pandas as pd                      # DataFrames para datos de prueba.\nimport numpy as np                       # Arrays num\u00e9ricos y generaci\u00f3n aleatoria.\nfrom pathlib import Path                 # Rutas de archivos.\nimport tempfile                          # Directorios temporales para tests.\nimport yaml                              # Cargar/guardar configuraciones.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FIXTURES DE DATOS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@pytest.fixture                          # Decorador: convierte funci\u00f3n en fixture reutilizable.\ndef sample_data() -&gt; pd.DataFrame:       # Fixture que retorna un DataFrame de prueba.\n    \"\"\"DataFrame peque\u00f1o para tests r\u00e1pidos.\n\n    Este fixture se usa en MUCHOS tests:\n    - test_data.py: Verificar carga y limpieza\n    - test_features.py: Verificar feature engineering\n    - test_model.py: Verificar predicciones\n    \"\"\"\n    return pd.DataFrame({                # DataFrame peque\u00f1o: tests r\u00e1pidos.\n        \"price\": [15000, 25000, 35000, 45000, 55000],  # Target (lo que predecimos).\n        \"model_year\": [2015, 2018, 2020, 2019, 2021],  # Feature num\u00e9rica.\n        \"odometer\": [80000, 45000, 20000, 30000, 10000],\n        \"model\": [\"ford f-150\", \"toyota camry\", \"honda civic\", \n                  \"chevrolet silverado\", \"ford mustang\"],  # Feature categ\u00f3rica.\n        \"fuel\": [\"gas\", \"gas\", \"gas\", \"diesel\", \"gas\"],\n        \"transmission\": [\"automatic\", \"automatic\", \"manual\", \n                        \"automatic\", \"manual\"],\n        \"condition\": [\"good\", \"excellent\", \"like new\", \n                     \"good\", \"excellent\"],\n    })\n\n\n@pytest.fixture\ndef sample_data_with_nulls() -&gt; pd.DataFrame:\n    \"\"\"DataFrame con valores faltantes para probar imputaci\u00f3n.\"\"\"\n    return pd.DataFrame({\n        \"price\": [15000, None, 35000, 45000, None],\n        \"model_year\": [2015, 2018, None, 2019, 2021],\n        \"odometer\": [80000, None, 20000, 30000, 10000],\n        \"model\": [\"ford f-150\", None, \"honda civic\", None, \"ford mustang\"],\n        \"fuel\": [\"gas\", \"gas\", None, \"diesel\", \"gas\"],\n        \"transmission\": [None, \"automatic\", \"manual\", \"automatic\", None],\n    })\n\n\n@pytest.fixture\ndef large_sample_data() -&gt; pd.DataFrame:\n    \"\"\"DataFrame m\u00e1s grande para tests de performance.\"\"\"\n    np.random.seed(42)\n    n = 1000\n    return pd.DataFrame({\n        \"price\": np.random.uniform(5000, 80000, n),\n        \"model_year\": np.random.randint(2010, 2024, n),\n        \"odometer\": np.random.uniform(0, 200000, n),\n        \"model\": np.random.choice([\"ford f-150\", \"toyota camry\", \"honda civic\"], n),\n        \"fuel\": np.random.choice([\"gas\", \"diesel\", \"electric\"], n),\n        \"transmission\": np.random.choice([\"automatic\", \"manual\"], n),\n    })\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FIXTURES DE CONFIGURACI\u00d3N\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@pytest.fixture\ndef sample_config() -&gt; dict:\n    \"\"\"Configuraci\u00f3n m\u00ednima para tests.\"\"\"\n    return {\n        \"seed\": 42,\n        \"dataset_year\": 2024,\n        \"paths\": {\n            \"data_path\": \"data/raw/vehicles_us.csv\",\n            \"artifacts_dir\": \"artifacts\",\n            \"model_path\": \"artifacts/model.joblib\",\n        },\n        \"preprocessing\": {\n            \"numeric_features\": [\"odometer\", \"vehicle_age\"],\n            \"categorical_features\": [\"fuel\", \"transmission\", \"brand\"],\n            \"drop_columns\": [\"price_per_mile\", \"price_category\"],\n            \"filters\": {\n                \"price_min\": 1000,\n                \"price_max\": 100000,\n            }\n        },\n        \"training\": {\n            \"target\": \"price\",\n            \"test_size\": 0.2,\n            \"val_size\": 0.1,\n            \"shuffle\": True,\n            \"model\": \"random_forest\",\n            \"random_forest_params\": {\n                \"n_estimators\": 10,  # Pocos para tests r\u00e1pidos\n                \"max_depth\": 5,\n                \"random_state\": 42,\n            }\n        }\n    }\n\n\n@pytest.fixture\ndef temp_config_file(sample_config, tmp_path) -&gt; Path:\n    \"\"\"Crea archivo config temporal para tests de carga.\"\"\"\n    config_path = tmp_path / \"config.yaml\"\n    with open(config_path, \"w\") as f:\n        yaml.dump(sample_config, f)\n    return config_path\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FIXTURES DE MODELO\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@pytest.fixture\ndef fitted_pipeline(sample_data, sample_config):\n    \"\"\"Pipeline entrenado para tests de predicci\u00f3n.\"\"\"\n    from src.carvision.training import build_pipeline\n    from src.carvision.features import FeatureEngineer\n\n    # Preparar datos\n    fe = FeatureEngineer(current_year=2024)\n    df = fe.transform(sample_data)\n\n    X = df.drop(columns=[\"price\"])\n    y = df[\"price\"]\n\n    # Construir y entrenar pipeline\n    # Nota: Usamos config simplificada para velocidad\n    pipeline = build_pipeline(sample_config)\n    pipeline.fit(X, y)\n\n    return pipeline\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FIXTURES ESPECIALES\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@pytest.fixture\ndef temp_artifacts_dir(tmp_path) -&gt; Path:\n    \"\"\"Directorio temporal para artefactos.\"\"\"\n    artifacts = tmp_path / \"artifacts\"\n    artifacts.mkdir()\n    return artifacts\n\n\n@pytest.fixture(scope=\"module\")\ndef slow_fixture():\n    \"\"\"Fixture que tarda en crearse - se reutiliza en todo el m\u00f3dulo.\n\n    scope=\"module\" significa que se crea UNA vez por archivo de test,\n    no una vez por cada test.\n    \"\"\"\n    import time\n    time.sleep(0.1)  # Simula operaci\u00f3n lenta\n    return {\"expensive_resource\": True}\n</code></pre>"},{"location":"docs/11_TESTING_ML/#uso-de-fixtures-en-tests","title":"Uso de Fixtures en Tests","text":"<pre><code># tests/test_features.py\n\ndef test_feature_engineer_creates_vehicle_age(sample_data):\n    \"\"\"Test que usa la fixture sample_data.\"\"\"\n    from src.carvision.features import FeatureEngineer\n\n    fe = FeatureEngineer(current_year=2024)\n    result = fe.transform(sample_data)\n\n    assert \"vehicle_age\" in result.columns\n    assert result[\"vehicle_age\"].iloc[0] == 2024 - 2015  # 9 a\u00f1os\n\n\ndef test_pipeline_predicts_positive_prices(fitted_pipeline, sample_data):\n    \"\"\"Test que usa DOS fixtures.\"\"\"\n    X = sample_data.drop(columns=[\"price\"])\n    predictions = fitted_pipeline.predict(X)\n\n    assert all(predictions &gt; 0), \"Precios deben ser positivos\"\n</code></pre>"},{"location":"docs/11_TESTING_ML/#113-unit-tests-funciones-individuales","title":"11.3 Unit Tests: Funciones Individuales","text":""},{"location":"docs/11_TESTING_ML/#que-testear-en-unit-tests","title":"Qu\u00e9 Testear en Unit Tests","text":"<pre><code># tests/test_features.py - C\u00f3digo REAL del portafolio\n\nimport pytest\nimport pandas as pd\nfrom src.carvision.features import FeatureEngineer\n\n\nclass TestFeatureEngineer:\n    \"\"\"Tests unitarios para FeatureEngineer.\"\"\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Creaci\u00f3n de features\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_creates_vehicle_age(self, sample_data):\n        \"\"\"Verifica que vehicle_age se calcula correctamente.\"\"\"\n        fe = FeatureEngineer(current_year=2024)\n        result = fe.transform(sample_data)\n\n        assert \"vehicle_age\" in result.columns\n        # 2024 - 2015 = 9 a\u00f1os para el primer registro\n        assert result.loc[0, \"vehicle_age\"] == 9\n\n    def test_creates_brand_from_model(self, sample_data):\n        \"\"\"Verifica que brand extrae la primera palabra de model.\"\"\"\n        fe = FeatureEngineer(current_year=2024)\n        result = fe.transform(sample_data)\n\n        assert \"brand\" in result.columns\n        assert result.loc[0, \"brand\"] == \"ford\"  # \"ford f-150\" \u2192 \"ford\"\n        assert result.loc[1, \"brand\"] == \"toyota\"  # \"toyota camry\" \u2192 \"toyota\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Manejo de edge cases\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_handles_missing_model_year(self):\n        \"\"\"Verifica comportamiento con model_year faltante.\"\"\"\n        df = pd.DataFrame({\n            \"price\": [15000],\n            \"model\": [\"ford f-150\"],\n            # Sin model_year\n        })\n\n        fe = FeatureEngineer(current_year=2024)\n        result = fe.transform(df)\n\n        # No debe crear vehicle_age si no hay model_year\n        assert \"vehicle_age\" not in result.columns\n\n    def test_handles_missing_model_column(self):\n        \"\"\"Verifica comportamiento sin columna model.\"\"\"\n        df = pd.DataFrame({\n            \"price\": [15000],\n            \"model_year\": [2015],\n            # Sin model\n        })\n\n        fe = FeatureEngineer(current_year=2024)\n        result = fe.transform(df)\n\n        # No debe crear brand si no hay model\n        assert \"brand\" not in result.columns\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Inmutabilidad\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_does_not_modify_input(self, sample_data):\n        \"\"\"Verifica que el DataFrame original no se modifica.\"\"\"\n        original_columns = sample_data.columns.tolist()\n        original_values = sample_data.copy()\n\n        fe = FeatureEngineer(current_year=2024)\n        _ = fe.transform(sample_data)\n\n        # Columnas originales sin cambio\n        assert sample_data.columns.tolist() == original_columns\n        # Valores originales sin cambio\n        pd.testing.assert_frame_equal(sample_data, original_values)\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Compatibilidad con sklearn\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_fit_returns_self(self, sample_data):\n        \"\"\"Verifica que fit() retorna self (requerido por sklearn).\"\"\"\n        fe = FeatureEngineer(current_year=2024)\n        result = fe.fit(sample_data)\n\n        assert result is fe\n\n    def test_works_in_pipeline(self, sample_data):\n        \"\"\"Verifica que funciona dentro de un Pipeline sklearn.\"\"\"\n        from sklearn.pipeline import Pipeline\n        from sklearn.preprocessing import StandardScaler\n\n        pipe = Pipeline([\n            (\"features\", FeatureEngineer(current_year=2024)),\n            (\"scaler\", StandardScaler())\n        ])\n\n        # No debe lanzar excepci\u00f3n\n        # (Solo probamos que no falla, no el resultado)\n        try:\n            # Seleccionar solo columnas num\u00e9ricas para StandardScaler\n            numeric_cols = [\"price\", \"model_year\", \"odometer\"]\n            result = pipe.fit_transform(sample_data[numeric_cols])\n            assert result is not None\n        except Exception as e:\n            pytest.fail(f\"Pipeline fall\u00f3: {e}\")\n</code></pre>"},{"location":"docs/11_TESTING_ML/#114-data-tests-validacion-de-datos","title":"11.4 Data Tests: Validaci\u00f3n de Datos","text":""},{"location":"docs/11_TESTING_ML/#tests-de-schema-y-calidad-de-datos","title":"Tests de Schema y Calidad de Datos","text":"<pre><code># tests/test_data.py - C\u00f3digo REAL del portafolio\n\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom src.carvision.data import load_data, clean_data\n\n\nclass TestDataLoading:\n    \"\"\"Tests de carga y validaci\u00f3n de datos.\"\"\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Schema validation\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_required_columns_exist(self, sample_data):\n        \"\"\"Verifica que existen las columnas requeridas.\"\"\"\n        required = [\"price\", \"model_year\", \"odometer\", \"model\", \"fuel\"]\n\n        for col in required:\n            assert col in sample_data.columns, f\"Falta columna: {col}\"\n\n    def test_column_types(self, sample_data):\n        \"\"\"Verifica tipos de datos correctos.\"\"\"\n        # Num\u00e9ricas\n        assert pd.api.types.is_numeric_dtype(sample_data[\"price\"])\n        assert pd.api.types.is_numeric_dtype(sample_data[\"model_year\"])\n        assert pd.api.types.is_numeric_dtype(sample_data[\"odometer\"])\n\n        # Categ\u00f3ricas/String\n        assert pd.api.types.is_object_dtype(sample_data[\"model\"])\n        assert pd.api.types.is_object_dtype(sample_data[\"fuel\"])\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Value ranges\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_price_is_positive(self, sample_data):\n        \"\"\"Verifica que precios son positivos.\"\"\"\n        assert (sample_data[\"price\"] &gt; 0).all(), \"Hay precios &lt;= 0\"\n\n    def test_price_in_reasonable_range(self, sample_data):\n        \"\"\"Verifica que precios est\u00e1n en rango razonable.\"\"\"\n        assert sample_data[\"price\"].min() &gt;= 100, \"Precio muy bajo (posible error)\"\n        assert sample_data[\"price\"].max() &lt;= 500000, \"Precio muy alto (posible error)\"\n\n    def test_model_year_in_range(self, sample_data):\n        \"\"\"Verifica que a\u00f1os son razonables.\"\"\"\n        current_year = pd.Timestamp.now().year\n\n        assert sample_data[\"model_year\"].min() &gt;= 1900, \"A\u00f1o muy antiguo\"\n        assert sample_data[\"model_year\"].max() &lt;= current_year + 1, \"A\u00f1o futuro\"\n\n    def test_odometer_is_non_negative(self, sample_data):\n        \"\"\"Verifica que odometer no es negativo.\"\"\"\n        assert (sample_data[\"odometer\"] &gt;= 0).all(), \"Hay odometer negativo\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Categorical values\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_fuel_valid_values(self, sample_data):\n        \"\"\"Verifica que fuel tiene valores v\u00e1lidos.\"\"\"\n        valid_fuels = {\"gas\", \"diesel\", \"electric\", \"hybrid\", \"other\"}\n        actual_fuels = set(sample_data[\"fuel\"].dropna().unique())\n\n        invalid = actual_fuels - valid_fuels\n        assert len(invalid) == 0, f\"Valores de fuel inv\u00e1lidos: {invalid}\"\n\n    def test_transmission_valid_values(self, sample_data):\n        \"\"\"Verifica que transmission tiene valores v\u00e1lidos.\"\"\"\n        valid = {\"automatic\", \"manual\", \"other\"}\n        actual = set(sample_data[\"transmission\"].dropna().unique())\n\n        invalid = actual - valid\n        assert len(invalid) == 0, f\"Valores de transmission inv\u00e1lidos: {invalid}\"\n\n\nclass TestDataCleaning:\n    \"\"\"Tests de limpieza de datos.\"\"\"\n\n    def test_clean_data_removes_invalid_prices(self, sample_data):\n        \"\"\"Verifica que clean_data filtra precios fuera de rango.\"\"\"\n        # A\u00f1adir registro con precio inv\u00e1lido\n        bad_data = pd.concat([\n            sample_data,\n            pd.DataFrame({\"price\": [100], \"model_year\": [2020], \n                         \"odometer\": [1000], \"model\": [\"test\"],\n                         \"fuel\": [\"gas\"], \"transmission\": [\"automatic\"],\n                         \"condition\": [\"good\"]})\n        ], ignore_index=True)\n\n        filters = {\"price_min\": 1000, \"price_max\": 100000}\n        cleaned = clean_data(bad_data, filters=filters)\n\n        # El registro con price=100 debe ser eliminado\n        assert len(cleaned) == len(sample_data)\n        assert (cleaned[\"price\"] &gt;= 1000).all()\n\n    def test_clean_data_handles_nulls(self, sample_data_with_nulls):\n        \"\"\"Verifica que clean_data no falla con NaN.\"\"\"\n        # No debe lanzar excepci\u00f3n\n        filters = {\"price_min\": 1000}\n        cleaned = clean_data(sample_data_with_nulls, filters=filters)\n\n        assert cleaned is not None\n        # Registros con price=None deben ser eliminados o manejados\n        assert len(cleaned) &lt;= len(sample_data_with_nulls)\n</code></pre>"},{"location":"docs/11_TESTING_ML/#115-model-tests-comportamiento-del-modelo","title":"11.5 Model Tests: Comportamiento del Modelo","text":""},{"location":"docs/11_TESTING_ML/#tests-especificos-de-ml","title":"Tests Espec\u00edficos de ML","text":"<pre><code># tests/test_model_logic.py - C\u00f3digo REAL del portafolio\n\nimport pytest\nimport numpy as np\nimport pandas as pd\n\n\nclass TestModelPredictions:\n    \"\"\"Tests de comportamiento del modelo.\"\"\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Output shape y tipo\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_predict_returns_correct_shape(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que predict retorna un array del tama\u00f1o correcto.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n        predictions = fitted_pipeline.predict(X)\n\n        assert len(predictions) == len(X), \"N\u00famero de predicciones incorrecto\"\n\n    def test_predict_returns_numeric(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que predicciones son num\u00e9ricas.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n        predictions = fitted_pipeline.predict(X)\n\n        assert np.issubdtype(predictions.dtype, np.number), \"Predicciones no son num\u00e9ricas\"\n\n    def test_predict_no_nan(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que no hay NaN en predicciones.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n        predictions = fitted_pipeline.predict(X)\n\n        assert not np.isnan(predictions).any(), \"Hay NaN en predicciones\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Rangos razonables\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_predictions_are_positive(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que precios predichos son positivos.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n        predictions = fitted_pipeline.predict(X)\n\n        assert (predictions &gt; 0).all(), \"Hay predicciones &lt;= 0\"\n\n    def test_predictions_in_training_range(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que predicciones est\u00e1n en rango similar al training.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n        y = sample_data[\"price\"]\n        predictions = fitted_pipeline.predict(X)\n\n        # Predicciones deben estar dentro de un margen razonable\n        min_price = y.min() * 0.1  # 10% del m\u00ednimo\n        max_price = y.max() * 3.0  # 300% del m\u00e1ximo\n\n        assert predictions.min() &gt;= min_price, \"Predicci\u00f3n muy baja\"\n        assert predictions.max() &lt;= max_price, \"Predicci\u00f3n muy alta\"\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Consistencia (determinismo)\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_predictions_are_deterministic(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que mismos inputs dan mismos outputs.\"\"\"\n        X = sample_data.drop(columns=[\"price\"])\n\n        pred1 = fitted_pipeline.predict(X)\n        pred2 = fitted_pipeline.predict(X)\n\n        np.testing.assert_array_equal(pred1, pred2, \n            \"Predicciones no son determin\u00edsticas\")\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # TEST: Sensibilidad a features\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n    def test_higher_odometer_lower_price(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que mayor odometer tiende a menor precio.\n\n        Este es un test de \"sanity check\": verifica que el modelo\n        aprendi\u00f3 relaciones b\u00e1sicas del dominio.\n        \"\"\"\n        X = sample_data.drop(columns=[\"price\"]).copy()\n\n        # Predicci\u00f3n con odometer original\n        pred_low_odo = fitted_pipeline.predict(X)\n\n        # Aumentar odometer significativamente\n        X_high_odo = X.copy()\n        X_high_odo[\"odometer\"] = X[\"odometer\"] * 3\n        pred_high_odo = fitted_pipeline.predict(X_high_odo)\n\n        # En promedio, mayor odometer \u2192 menor precio\n        # (No requiere que TODOS sean menores, solo el promedio)\n        assert pred_high_odo.mean() &lt; pred_low_odo.mean(), \\\n            \"Modelo no aprendi\u00f3 que mayor odometer = menor precio\"\n\n    def test_newer_car_higher_price(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que autos m\u00e1s nuevos tienden a mayor precio.\"\"\"\n        X = sample_data.drop(columns=[\"price\"]).copy()\n\n        # Predicci\u00f3n con model_year original\n        pred_original = fitted_pipeline.predict(X)\n\n        # Hacer autos 5 a\u00f1os m\u00e1s nuevos\n        X_newer = X.copy()\n        X_newer[\"model_year\"] = X[\"model_year\"] + 5\n        pred_newer = fitted_pipeline.predict(X_newer)\n\n        # En promedio, m\u00e1s nuevo \u2192 mayor precio\n        assert pred_newer.mean() &gt; pred_original.mean(), \\\n            \"Modelo no aprendi\u00f3 que autos nuevos cuestan m\u00e1s\"\n\n\nclass TestModelMetrics:\n    \"\"\"Tests de m\u00e9tricas del modelo.\"\"\"\n\n    def test_rmse_below_threshold(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que RMSE est\u00e1 por debajo de umbral aceptable.\"\"\"\n        from sklearn.metrics import mean_squared_error\n\n        X = sample_data.drop(columns=[\"price\"])\n        y = sample_data[\"price\"]\n        predictions = fitted_pipeline.predict(X)\n\n        rmse = np.sqrt(mean_squared_error(y, predictions))\n\n        # RMSE debe ser menor que el 50% del precio promedio\n        # (umbral arbitrario para sample data peque\u00f1o)\n        threshold = y.mean() * 0.5\n        assert rmse &lt; threshold, f\"RMSE={rmse:.2f} &gt; threshold={threshold:.2f}\"\n\n    def test_r2_above_threshold(self, fitted_pipeline, sample_data):\n        \"\"\"Verifica que R\u00b2 est\u00e1 por encima de umbral m\u00ednimo.\"\"\"\n        from sklearn.metrics import r2_score\n\n        X = sample_data.drop(columns=[\"price\"])\n        y = sample_data[\"price\"]\n        predictions = fitted_pipeline.predict(X)\n\n        r2 = r2_score(y, predictions)\n\n        # R\u00b2 debe ser positivo (mejor que predecir la media)\n        # Nota: Con sample data peque\u00f1o, R\u00b2 puede ser bajo\n        assert r2 &gt; 0.0, f\"R\u00b2={r2:.3f} &lt;= 0 (peor que baseline)\"\n</code></pre>"},{"location":"docs/11_TESTING_ML/#116-integration-tests-pipeline-completo","title":"11.6 Integration Tests: Pipeline Completo","text":""},{"location":"docs/11_TESTING_ML/#tests-end-to-end","title":"Tests End-to-End","text":"<pre><code># tests/test_main_workflow.py - C\u00f3digo REAL del portafolio\n\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport tempfile\nimport joblib\n\n\nclass TestTrainingWorkflow:\n    \"\"\"Tests de integraci\u00f3n del flujo completo de entrenamiento.\"\"\"\n\n    def test_full_training_pipeline(self, sample_data, sample_config, tmp_path):\n        \"\"\"Test end-to-end: datos \u2192 entrenamiento \u2192 modelo guardado.\"\"\"\n        from src.carvision.training import train_model\n\n        # Configurar paths temporales\n        sample_config[\"paths\"][\"artifacts_dir\"] = str(tmp_path)\n        sample_config[\"paths\"][\"model_path\"] = str(tmp_path / \"model.joblib\")\n\n        # Guardar datos temporales\n        data_path = tmp_path / \"data.csv\"\n        sample_data.to_csv(data_path, index=False)\n        sample_config[\"paths\"][\"data_path\"] = str(data_path)\n\n        # Ejecutar entrenamiento\n        result = train_model(sample_config)\n\n        # Verificaciones\n        assert \"rmse\" in result, \"Falta m\u00e9trica RMSE\"\n        assert result[\"rmse\"] &gt; 0, \"RMSE debe ser positivo\"\n\n        # Verificar que modelo se guard\u00f3\n        model_path = Path(sample_config[\"paths\"][\"model_path\"])\n        assert model_path.exists(), \"Modelo no se guard\u00f3\"\n\n        # Verificar que modelo se puede cargar\n        model = joblib.load(model_path)\n        assert model is not None, \"Modelo no se puede cargar\"\n\n    def test_training_creates_all_artifacts(self, sample_data, sample_config, tmp_path):\n        \"\"\"Verifica que entrenamiento crea todos los artefactos esperados.\"\"\"\n        from src.carvision.training import train_model\n\n        # Setup\n        sample_config[\"paths\"][\"artifacts_dir\"] = str(tmp_path)\n        sample_config[\"paths\"][\"model_path\"] = str(tmp_path / \"model.joblib\")\n        sample_config[\"paths\"][\"metrics_path\"] = str(tmp_path / \"metrics.json\")\n\n        data_path = tmp_path / \"data.csv\"\n        sample_data.to_csv(data_path, index=False)\n        sample_config[\"paths\"][\"data_path\"] = str(data_path)\n\n        # Train\n        train_model(sample_config)\n\n        # Verificar artefactos\n        assert (tmp_path / \"model.joblib\").exists(), \"Falta model.joblib\"\n        # metrics.json es opcional en algunos configs\n\n    def test_loaded_model_predicts_correctly(self, sample_data, sample_config, tmp_path):\n        \"\"\"Verifica que modelo guardado predice igual que antes de guardar.\"\"\"\n        from src.carvision.training import train_model, build_pipeline\n        from src.carvision.features import FeatureEngineer\n\n        # Setup y entrenamiento\n        sample_config[\"paths\"][\"artifacts_dir\"] = str(tmp_path)\n        model_path = tmp_path / \"model.joblib\"\n        sample_config[\"paths\"][\"model_path\"] = str(model_path)\n\n        data_path = tmp_path / \"data.csv\"\n        sample_data.to_csv(data_path, index=False)\n        sample_config[\"paths\"][\"data_path\"] = str(data_path)\n\n        train_model(sample_config)\n\n        # Cargar modelo\n        loaded_model = joblib.load(model_path)\n\n        # Predecir con nuevo dato\n        new_data = pd.DataFrame({\n            \"model_year\": [2020],\n            \"odometer\": [30000],\n            \"model\": [\"ford f-150\"],\n            \"fuel\": [\"gas\"],\n            \"transmission\": [\"automatic\"],\n        })\n\n        prediction = loaded_model.predict(new_data)\n\n        # Verificaciones b\u00e1sicas\n        assert len(prediction) == 1\n        assert prediction[0] &gt; 0\n        assert not np.isnan(prediction[0])\n\n\nclass TestAPIWorkflow:\n    \"\"\"Tests de integraci\u00f3n del API.\"\"\"\n\n    @pytest.mark.slow\n    def test_api_prediction_endpoint(self, fitted_pipeline, tmp_path):\n        \"\"\"Test E2E del endpoint de predicci\u00f3n.\"\"\"\n        from fastapi.testclient import TestClient\n        import sys\n\n        # Guardar modelo para el API\n        model_path = tmp_path / \"model.joblib\"\n        joblib.dump(fitted_pipeline, model_path)\n\n        # Importar app (puede requerir configuraci\u00f3n de paths)\n        # Este test asume que ARTIFACTS_DIR est\u00e1 configurado\n        import os\n        os.environ[\"ARTIFACTS_DIR\"] = str(tmp_path)\n\n        try:\n            from app.fastapi_app import app\n            client = TestClient(app)\n\n            # Request de predicci\u00f3n\n            response = client.post(\"/predict\", json={\n                \"model_year\": 2020,\n                \"odometer\": 30000,\n                \"model\": \"ford f-150\",\n                \"fuel\": \"gas\",\n                \"transmission\": \"automatic\"\n            })\n\n            assert response.status_code == 200\n            data = response.json()\n            assert \"prediction\" in data\n            assert data[\"prediction\"] &gt; 0\n        except ImportError:\n            pytest.skip(\"FastAPI app not available\")\n</code></pre>"},{"location":"docs/11_TESTING_ML/#118-ingenieria-inversa-pedagogica-suite-de-tests-de-produccion","title":"11.8 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Suite de Tests de Producci\u00f3n","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s de los tests reales del portafolio.</p> <p>Esta secci\u00f3n disecciona los tests de BankChurn-Predictor que detectan problemas cr\u00edticos como data leakage.</p>"},{"location":"docs/11_TESTING_ML/#1181-el-por-que-arquitectonico","title":"11.8.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 el portafolio tiene tests espec\u00edficos para leakage y no solo para accuracy?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo detecto data leakage antes de que llegue a producci\u00f3n?       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Leakage = m\u00e9tricas infladas en dev, modelo in\u00fatil en producci\u00f3n        \u2502\n\u2502  DECISI\u00d3N: Test que verifica que el scaler se ajusta SOLO con datos de train    \u2502\n\u2502  RESULTADO: CI falla si el preprocesador \"ve\" datos de test                     \u2502\n\u2502  REFERENCIA: test_integration.py::test_leakage_prevention                       \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo aseguro que el pipeline completo funciona end-to-end?        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Unit tests pasan pero el flujo completo falla                          \u2502\n\u2502  DECISI\u00d3N: Test que hace Train \u2192 Save \u2192 Load \u2192 Predict en secuencia             \u2502\n\u2502  RESULTADO: Detecta incompatibilidades entre componentes                        \u2502\n\u2502  REFERENCIA: test_integration.py::test_full_pipeline_flow                       \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo mantengo reproducibilidad entre ejecuciones?                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Tests flaky por aleatoriedad en datos/modelos                          \u2502\n\u2502  DECISI\u00d3N: Fixture autouse que setea seed global para todos los tests           \u2502\n\u2502  RESULTADO: Mismos resultados en local y CI                                     \u2502\n\u2502  REFERENCIA: conftest.py::deterministic_seed                                    \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/11_TESTING_ML/#1182-anatomia-de-test_integrationpy","title":"11.8.2 \ud83d\udd0d Anatom\u00eda de <code>test_integration.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/tests/test_integration.py</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TEST 1: Detecci\u00f3n de Data Leakage (El test m\u00e1s importante del portafolio)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef test_leakage_prevention():\n    \"\"\"Ensure preprocessor is NOT fitted on test data.\"\"\"\n\n    # 1. Crear datos sint\u00e9ticos con un outlier conocido\n    df = pd.DataFrame({\n        \"feat1\": [0.0] * 9 + [1000.0],   # 9 ceros + 1 outlier gigante.\n        \"cat1\": [\"a\"] * 10,\n        \"target\": [0,0,0,0,0,1,1,1,1,1],  # Balanceado para stratify.\n    })\n    # \u00bfPor qu\u00e9 este dise\u00f1o?\n    # - Si el outlier (1000.0) est\u00e1 en TEST y hay leakage, el scaler\n    #   tendr\u00e1 un mean alto (~100). Sin leakage, mean \u2248 0.\n\n    # 2. Dividir datos manualmente para saber d\u00f3nde est\u00e1 el outlier\n    X_train, X_test, _, _ = train_test_split(\n        X, y, test_size=0.5, random_state=42, stratify=y\n    )\n    outlier_in_train = 1000.0 in X_train[\"feat1\"].values\n\n    # 3. Entrenar el modelo\n    trainer = ChurnTrainer(config, random_state=42)\n    model, metrics = trainer.train(df, df[\"target\"], use_cv=False)\n\n    # 4. Extraer el mean del scaler (StandardScaler guarda mean_)\n    scaler = trainer.preprocessor_.named_transformers_[\"num\"][\"scaler\"]\n    scaler_mean = scaler.mean_[0]\n\n    # 5. Calcular means esperados\n    expected_mean = X_train[\"feat1\"].mean()  # Mean de SOLO train.\n    global_mean = df[\"feat1\"].mean()          # Mean de TODO (leakage).\n\n    # 6. ASSERT: Scaler debe matchear Train, NO Global\n    np.testing.assert_almost_equal(\n        scaler_mean,\n        expected_mean,\n        decimal=5,\n        err_msg=\"Scaler mean should match Train mean\"\n    )\n\n    # 7. Detectar leakage: si scaler_mean == global_mean, hay leak\n    if expected_mean != global_mean:\n        assert scaler_mean != global_mean, \"Leakage detected!\"\n# \u00bfPor qu\u00e9 este test es cr\u00edtico?\n# - Data leakage es el error #1 en ML: m\u00e9tricas perfectas en dev, basura en prod.\n# - Este test lo detecta ANTES de que llegue a CI/producci\u00f3n.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TEST 2: Pipeline Completo End-to-End\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ndef test_full_pipeline_flow(sample_data, sample_config, tmp_path):\n    \"\"\"Test complete flow: Train -&gt; Save -&gt; Load -&gt; Predict.\"\"\"\n\n    # 1. TRAIN\n    trainer = ChurnTrainer(sample_config)\n    X, y = trainer.prepare_features(sample_data)\n    model, metrics = trainer.train(X, y, use_cv=False)\n\n    assert model is not None\n    assert \"train_f1\" in metrics\n\n    # 2. SAVE\n    model_path = tmp_path / \"model.pkl\"      # tmp_path: fixture de pytest (dir temporal).\n    trainer.save_model(model_path, None)\n    assert model_path.exists()\n\n    # Verificar que es un Pipeline sklearn\n    loaded_obj = joblib.load(model_path)\n    assert isinstance(loaded_obj, Pipeline)\n    assert \"preprocessor\" in loaded_obj.named_steps\n    assert \"classifier\" in loaded_obj.named_steps\n\n    # 3. LOAD usando el Predictor de producci\u00f3n\n    predictor = ChurnPredictor.from_files(model_path, None)\n\n    # 4. PREDICT\n    predictions = predictor.predict(X, include_proba=True)\n    assert len(predictions) == len(X)\n    assert \"prediction\" in predictions.columns\n    assert \"probability\" in predictions.columns\n\n    # 5. EVALUATE\n    evaluator = ModelEvaluator.from_files(model_path, None)\n    eval_metrics = evaluator.evaluate(X, y)\n    assert \"accuracy\" in eval_metrics\n# \u00bfPor qu\u00e9 este test es importante?\n# - Verifica que TODOS los componentes trabajan juntos.\n# - Detecta incompatibilidades de versiones/formatos.\n# - Usa tmp_path para no contaminar el filesystem.\n</code></pre>"},{"location":"docs/11_TESTING_ML/#1183-anatomia-de-conftestpy","title":"11.8.3 \ud83d\udd0d Anatom\u00eda de <code>conftest.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/tests/conftest.py</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# FIXTURE: Seed Determin\u00edstico para Reproducibilidad\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n@pytest.fixture(autouse=True)           # autouse=True: se ejecuta en TODOS los tests.\ndef deterministic_seed() -&gt; Generator[None, None, None]:\n    \"\"\"Set a deterministic global seed for every test.\n\n    Resolution order:\n    1. TEST_SEED env var if defined.\n    2. SEED env var if defined.\n    3. Fallback to 42.\n    \"\"\"\n    seed = int(os.getenv(\"TEST_SEED\", os.getenv(\"SEED\", \"42\")))\n    set_seed(seed)                       # Setea seed para numpy, random, torch, etc.\n    yield                                # Test se ejecuta aqu\u00ed.\n    # Cleanup (opcional) despu\u00e9s del test.\n# \u00bfPor qu\u00e9 autouse=True?\n# - Garantiza que CADA test tiene el mismo seed inicial.\n# - Evita flaky tests por aleatoriedad.\n# - Permite override v\u00eda variable de entorno para debugging.\n\n# \u00bfPor qu\u00e9 set_seed y no solo np.random.seed?\n# - ML usa m\u00faltiples fuentes de aleatoriedad: numpy, random, torch, sklearn.\n# - set_seed() (de common_utils) los setea TODOS de una vez.\n</code></pre>"},{"location":"docs/11_TESTING_ML/#1184-laboratorio-de-replicacion","title":"11.8.4 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Implementar un test de leakage para tu proyecto.</p> <ol> <li> <p>Crea un test de leakage b\u00e1sico:    <pre><code># tests/test_leakage.py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndef test_no_leakage_in_preprocessing():\n    \"\"\"Verifica que el scaler no ve datos de test.\"\"\"\n    # Datos con outlier conocido\n    X = pd.DataFrame({\"feature\": [1, 2, 3, 4, 100]})\n    y = [0, 0, 1, 1, 1]\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.4, random_state=42\n    )\n\n    # Fit scaler SOLO en train\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n\n    # Verificar que mean es de train, no de todo\n    train_mean = X_train[\"feature\"].mean()\n    global_mean = X[\"feature\"].mean()\n\n    assert abs(scaler.mean_[0] - train_mean) &lt; 0.01, \"Scaler should use train mean\"\n    if train_mean != global_mean:\n        assert scaler.mean_[0] != global_mean, \"Leakage detected!\"\n</code></pre></p> </li> <li> <p>A\u00f1ade fixture de seed a tu conftest.py:    <pre><code># tests/conftest.py\nimport pytest\nimport numpy as np\nimport random\n\n@pytest.fixture(autouse=True)\ndef set_seed():\n    seed = 42\n    np.random.seed(seed)\n    random.seed(seed)\n    yield\n</code></pre></p> </li> <li> <p>Ejecuta y verifica:    <pre><code>pytest tests/test_leakage.py -v\n</code></pre></p> </li> </ol>"},{"location":"docs/11_TESTING_ML/#1185-troubleshooting-preventivo","title":"11.8.5 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n Test de leakage pasa pero modelo falla en prod Test no cubre el preprocesador real Usa el mismo c\u00f3digo de training que usas en producci\u00f3n. Tests pasan localmente pero fallan en CI Seeds diferentes o dependencias de orden Usa <code>autouse=True</code> en fixture de seed. Ejecuta con <code>--randomly-seed=42</code>. Fixture no se ejecuta No est\u00e1 en <code>conftest.py</code> o scope incorrecto Verifica que <code>conftest.py</code> est\u00e1 en <code>tests/</code>. tmp_path no existe Versi\u00f3n antigua de pytest <code>pip install --upgrade pytest</code> (tmp_path requiere pytest &gt;= 3.9). Import errors en tests <code>src/</code> no est\u00e1 en sys.path A\u00f1ade path manipulation al inicio del test file."},{"location":"docs/11_TESTING_ML/#errores-habituales-y-como-depurarlos-en-testing-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en testing ML","text":"<p>Aunque pytest es muy potente, en ML es f\u00e1cil caer en tests fr\u00e1giles o enga\u00f1osos. Estos son los patrones m\u00e1s comunes y c\u00f3mo atacarlos.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/11_TESTING_ML/#1-tests-que-dependen-de-datos-reales-o-externos","title":"1) Tests que dependen de datos reales o externos","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Tests que leen de <code>data/raw/...</code> o llaman APIs externas.</li> <li>Fallan solo en CI o solo en ciertas m\u00e1quinas.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Busca en tests accesos directos a rutas del proyecto o a recursos externos.</li> <li>Revisa que tus fixtures (<code>sample_data</code>, <code>sample_config</code>, etc.) no lean de archivos reales salvo cuando se prueban funciones de I/O.</li> <li>Deja el acceso a disco/red solo en tests de integraci\u00f3n marcados (<code>@pytest.mark.integration</code> o <code>@pytest.mark.slow</code>).</li> </ul>"},{"location":"docs/11_TESTING_ML/#1161-load-testing-con-locust","title":"11.6.1 Load Testing con Locust","text":"<p>Referencia del portafolio: <code>tests/load/locustfile.py</code></p> <pre><code># tests/load/locustfile.py\nfrom locust import HttpUser, task, between\n\nclass MLAPIUser(HttpUser):\n    wait_time = between(0.5, 2)\n\n    @task(3)\n    def health_check(self):\n        self.client.get(\"/health\")\n\n    @task(1)\n    def predict(self):\n        self.client.post(\"/api/v1/predict\", json={\n            \"CreditScore\": 650, \"Age\": 35, \"Tenure\": 5\n        })\n</code></pre> <pre><code># Ejecutar pruebas de carga\nlocust -f tests/load/locustfile.py --host=http://localhost:8000\n\n# Headless para CI\nlocust -f tests/load/locustfile.py --host=http://localhost:8000 \\\n    --users 50 --spawn-rate 5 --run-time 1m --headless --csv=reports/load\n</code></pre> M\u00e9trica SLO Target Umbral cr\u00edtico P95 Latency &lt; 200ms &lt; 500ms Error Rate &lt; 0.1% &lt; 1% <p></p>"},{"location":"docs/11_TESTING_ML/#117-alcanzar-80-coverage","title":"11.7 Alcanzar 80% Coverage","text":""},{"location":"docs/11_TESTING_ML/#configuracion-de-pytest-cov","title":"Configuraci\u00f3n de pytest-cov","text":"<pre><code># pyproject.toml\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\naddopts = [\n    \"-v\",\n    \"--cov=src/carvision\",\n    \"--cov-report=term-missing\",\n    \"--cov-report=html\",\n    \"--cov-fail-under=80\",\n]\nmarkers = [\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: marks tests as integration tests\",\n]\n\n[tool.coverage.run]\nsource = [\"src\"]\nomit = [\n    \"tests/*\",\n    \"*/__init__.py\",\n    \"*/visualization.py\",  # Excluir c\u00f3digo de UI\n]\n\n[tool.coverage.report]\nfail_under = 80\nexclude_lines = [\n    \"pragma: no cover\",\n    \"if __name__ == .__main__.:\",\n    \"raise NotImplementedError\",\n]\n</code></pre>"},{"location":"docs/11_TESTING_ML/#ejecutar-tests-con-coverage","title":"Ejecutar Tests con Coverage","text":"<pre><code># Tests r\u00e1pidos (sin slow)\npytest -m \"not slow\"\n\n# Todos los tests con coverage\npytest --cov=src/carvision --cov-report=term-missing\n\n# Solo ver coverage sin ejecutar tests\npytest --cov=src/carvision --cov-report=html\n# Abre htmlcov/index.html en el navegador\n\n# Verificar que pasa el threshold\npytest --cov-fail-under=80\n</code></pre>"},{"location":"docs/11_TESTING_ML/#estrategias-para-aumentar-coverage","title":"Estrategias para Aumentar Coverage","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83d\udcc8 C\u00d3MO PASAR DE 60% A 80% COVERAGE                                      \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                           \u2551\n\u2551  1. IDENTIFICAR GAPS                                                      \u2551\n\u2551     pytest --cov-report=term-missing                                      \u2551\n\u2551     \u2192 Muestra l\u00edneas NO cubiertas                                         \u2551\n\u2551                                                                           \u2551\n\u2551  2. PRIORIZAR                                                             \u2551\n\u2551     \u2022 L\u00f3gica de negocio cr\u00edtica (training, prediction)                    \u2551\n\u2551     \u2022 C\u00f3digo que maneja errores                                           \u2551\n\u2551     \u2022 Branches condicionales (if/else)                                    \u2551\n\u2551                                                                           \u2551\n\u2551  3. EXCLUIR LO QUE NO VALE LA PENA                                        \u2551\n\u2551     \u2022 C\u00f3digo de visualizaci\u00f3n (Streamlit, plots)                          \u2551\n\u2551     \u2022 Scripts de utilidad one-off                                         \u2551\n\u2551     \u2022 C\u00f3digo de terceros                                                  \u2551\n\u2551                                                                           \u2551\n\u2551  4. TESTEAR EDGE CASES                                                    \u2551\n\u2551     \u2022 \u00bfQu\u00e9 pasa con NaN?                                                  \u2551\n\u2551     \u2022 \u00bfQu\u00e9 pasa con lista vac\u00eda?                                          \u2551\n\u2551     \u2022 \u00bfQu\u00e9 pasa con tipos incorrectos?                                    \u2551\n\u2551                                                                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/11_TESTING_ML/#checkpoint-completaste-el-modulo","title":"\u2705 Checkpoint: \u00bfCompletaste el M\u00f3dulo?","text":"<p>Antes de continuar, verifica:</p> <ul> <li>[ ] Tienes <code>tests/conftest.py</code> con fixtures reutilizables</li> <li>[ ] Tienes tests unitarios para tus transformers</li> <li>[ ] Tienes tests de validaci\u00f3n de datos</li> <li>[ ] Tienes tests de comportamiento del modelo</li> <li>[ ] Tienes al menos un test de integraci\u00f3n</li> <li>[ ] Tu coverage es &gt;= 80%</li> </ul> <p></p>"},{"location":"docs/11_TESTING_ML/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>Los 3 proyectos del portafolio implementan testing profesional con 80%+ coverage:</p>"},{"location":"docs/11_TESTING_ML/#coverage-por-proyecto","title":"Coverage por Proyecto","text":"Proyecto Coverage Tests Archivos Clave BankChurn 79%+ 45+ <code>tests/conftest.py</code>, <code>test_pipeline.py</code> CarVision 97% 50+ <code>tests/test_features.py</code>, <code>test_data.py</code> TelecomAI 97% 35+ <code>tests/test_training.py</code>"},{"location":"docs/11_TESTING_ML/#conftestpy-real-carvision","title":"conftest.py Real (CarVision)","text":"<pre><code># CarVision-Market-Intelligence/tests/conftest.py\nimport pytest\nimport pandas as pd\n\n@pytest.fixture\ndef sample_df():\n    \"\"\"DataFrame de prueba con datos realistas.\"\"\"\n    return pd.DataFrame({\n        'model': ['Ford F-150', 'Toyota Camry'],\n        'model_year': [2020, 2019],\n        'odometer': [50000, 30000],\n        'price': [35000, 25000]\n    })\n\n\n@pytest.fixture\ndef config():\n    \"\"\"Configuraci\u00f3n de prueba.\"\"\"\n    return {\n        'data': {'target_column': 'price'},\n        'model': {'random_state': 42}\n    }\n</code></pre>"},{"location":"docs/11_TESTING_ML/#estructura-de-tests","title":"Estructura de Tests","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py           # Fixtures compartidas\n\u251c\u2500\u2500 test_config.py        # Tests de configuraci\u00f3n\n\u251c\u2500\u2500 test_data.py          # Tests de carga/validaci\u00f3n\n\u251c\u2500\u2500 test_features.py      # Tests de FeatureEngineer\n\u251c\u2500\u2500 test_pipeline.py      # Tests de pipeline\n\u251c\u2500\u2500 test_training.py      # Tests de entrenamiento\n\u2514\u2500\u2500 test_api.py           # Tests de FastAPI\n</code></pre>"},{"location":"docs/11_TESTING_ML/#ejercicio-ejecuta-tests-reales","title":"\ud83d\udd27 Ejercicio: Ejecuta Tests Reales","text":"<pre><code># 1. Ejecuta tests de CarVision\ncd CarVision-Market-Intelligence\npytest tests/ -v --cov=src/carvision --cov-report=term-missing\n\n# 2. Ve qu\u00e9 l\u00edneas NO est\u00e1n cubiertas\npytest --cov-report=html  # Genera htmlcov/index.html\n\n# 3. Compara con BankChurn\ncd ../BankChurn-Predictor\npytest tests/ -v --cov=src/bankchurn\n</code></pre>"},{"location":"docs/11_TESTING_ML/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/11_TESTING_ML/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Testing ML es diferente: Explica tests de datos, modelo, y serving (no solo c\u00f3digo).</p> </li> <li> <p>Great Expectations: Menciona que usas validaci\u00f3n de datos como parte del pipeline.</p> </li> <li> <p>Coverage no es todo: Un modelo con 100% coverage puede fallar en producci\u00f3n.</p> </li> </ol>"},{"location":"docs/11_TESTING_ML/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Tipo de Test Qu\u00e9 Verificar Data Tests Schema, rangos, distribuciones, nulls Model Tests M\u00e9tricas m\u00ednimas, overfitting, invariancia Integration Pipeline end-to-end, API responses Performance Latencia, throughput, memory"},{"location":"docs/11_TESTING_ML/#estrategia-de-testing-ml","title":"Estrategia de Testing ML","text":"<pre><code>Unit Tests:     Transformadores individuales\nIntegration:    Pipeline completo con datos sint\u00e9ticos\nValidation:     M\u00e9tricas en holdout real\nMonitoring:     Drift detection en producci\u00f3n\n</code></pre>"},{"location":"docs/11_TESTING_ML/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/11_TESTING_ML/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 pytest Tutorial ArjanCodes 25 min YouTube \ud83d\udd34 Testing for Data Science PyData 45 min YouTube \ud83d\udfe1 Great Expectations Tutorial DataTalksClub 30 min YouTube"},{"location":"docs/11_TESTING_ML/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 pytest Documentation Gu\u00eda oficial \ud83d\udfe1 Great Expectations Data validation"},{"location":"docs/11_TESTING_ML/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/11_TESTING_ML/#ejercicio-111-test-de-validacion-de-datos","title":"Ejercicio 11.1: Test de Validaci\u00f3n de Datos","text":"<p>Objetivo: Crear test que valide schema de datos. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Crear test que verifique:\n# - Columnas esperadas existen\n# - No hay nulls en columnas cr\u00edticas\n# - Valores est\u00e1n en rangos v\u00e1lidos\n\ndef test_data_validation(sample_data):\n    # ???\n    pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import pytest\nimport pandas as pd\n\n@pytest.fixture\ndef sample_data():\n    return pd.DataFrame({\n        'age': [25, 35, 45],\n        'balance': [1000, 2500, 5000],\n        'churned': [0, 1, 0]\n    })\n\ndef test_schema_has_required_columns(sample_data):\n    \"\"\"Verifica columnas requeridas.\"\"\"\n    required = ['age', 'balance', 'churned']\n    missing = set(required) - set(sample_data.columns)\n    assert not missing, f\"Missing columns: {missing}\"\n\ndef test_no_nulls_in_critical_columns(sample_data):\n    \"\"\"Verifica no hay nulls en columnas cr\u00edticas.\"\"\"\n    critical = ['age', 'churned']\n    for col in critical:\n        null_count = sample_data[col].isnull().sum()\n        assert null_count == 0, f\"Nulls in {col}: {null_count}\"\n\ndef test_age_in_valid_range(sample_data):\n    \"\"\"Verifica edad en rango v\u00e1lido.\"\"\"\n    assert sample_data['age'].min() &gt;= 18\n    assert sample_data['age'].max() &lt;= 120\n\ndef test_target_is_binary(sample_data):\n    \"\"\"Verifica target es binario.\"\"\"\n    unique_values = sample_data['churned'].unique()\n    assert set(unique_values).issubset({0, 1})\n</code></pre>"},{"location":"docs/11_TESTING_ML/#ejercicio-112-test-de-pipeline-ml","title":"Ejercicio 11.2: Test de Pipeline ML","text":"<p>Objetivo: Testear que pipeline produce predicciones v\u00e1lidas. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: Crear test que verifique:\n# - Pipeline puede entrenarse\n# - Predicciones tienen shape correcto\n# - Predicciones est\u00e1n en rango v\u00e1lido\n\ndef test_pipeline_predictions(trained_pipeline, sample_data):\n    # ???\n    pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import pytest\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\n@pytest.fixture\ndef trained_pipeline(sample_data):\n    \"\"\"Pipeline entrenado para tests.\"\"\"\n    X = sample_data[['age', 'balance']]\n    y = sample_data['churned']\n\n    pipe = Pipeline([\n        ('scaler', StandardScaler()),\n        ('model', RandomForestClassifier(n_estimators=10, random_state=42))\n    ])\n    pipe.fit(X, y)\n    return pipe\n\ndef test_pipeline_can_predict(trained_pipeline, sample_data):\n    \"\"\"Pipeline puede hacer predicciones.\"\"\"\n    X = sample_data[['age', 'balance']]\n    predictions = trained_pipeline.predict(X)\n    assert predictions is not None\n\ndef test_predictions_shape(trained_pipeline, sample_data):\n    \"\"\"Predicciones tienen shape correcto.\"\"\"\n    X = sample_data[['age', 'balance']]\n    predictions = trained_pipeline.predict(X)\n    assert len(predictions) == len(X)\n\ndef test_predictions_are_binary(trained_pipeline, sample_data):\n    \"\"\"Predicciones son binarias.\"\"\"\n    X = sample_data[['age', 'balance']]\n    predictions = trained_pipeline.predict(X)\n    assert set(np.unique(predictions)).issubset({0, 1})\n\ndef test_predict_proba_in_range(trained_pipeline, sample_data):\n    \"\"\"Probabilidades est\u00e1n en [0, 1].\"\"\"\n    X = sample_data[['age', 'balance']]\n    probas = trained_pipeline.predict_proba(X)\n    assert probas.min() &gt;= 0\n    assert probas.max() &lt;= 1\n</code></pre>"},{"location":"docs/11_TESTING_ML/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n conftest.py Archivo para fixtures compartidas entre tests Coverage Porcentaje de c\u00f3digo ejecutado por tests Fixture Funci\u00f3n que provee datos/setup reutilizable para tests Data Test Test que valida schema, rangos y distribuciones de datos"},{"location":"docs/11_TESTING_ML/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/11_TESTING_ML/#trampa-1-test-que-pasa-localmente-pero-falla-en-ci","title":"Trampa 1: Test que pasa localmente pero falla en CI","text":"<p>S\u00edntoma: <pre><code># Local: pytest tests/  # \u2705 All passed\n# CI: pytest tests/  # \u274c FileNotFoundError: data/test.csv\n</code></pre></p> <p>Causa ra\u00edz: Path hardcodeado que solo existe en tu m\u00e1quina.</p> <p>Soluci\u00f3n: Usar paths relativos y fixtures: <pre><code>from pathlib import Path\nDATA_PATH = Path(__file__).parent.parent / \"data\" / \"test.csv\"\n\n# O mejor: fixture que genera datos\n@pytest.fixture\ndef sample_data():\n    return pd.DataFrame({\"age\": [25, 45], \"balance\": [1000, 5000]})\n</code></pre></p>"},{"location":"docs/11_TESTING_ML/#trampa-2-test-con-efectos-secundarios","title":"Trampa 2: Test con efectos secundarios","text":"<p>S\u00edntoma: Test 1 solo \u2705, todos los tests \u274c (test_predict falla porque test_train dej\u00f3 un archivo).</p> <p>Soluci\u00f3n: Usar directorios temporales: <pre><code>@pytest.fixture\ndef temp_model_dir(tmp_path):\n    model_dir = tmp_path / \"models\"\n    model_dir.mkdir()\n    yield model_dir\n    # tmp_path se limpia autom\u00e1ticamente\n</code></pre></p>"},{"location":"docs/11_TESTING_ML/#trampa-3-mock-que-no-mockea-lo-correcto","title":"Trampa 3: Mock que no mockea lo correcto","text":"<p>S\u00edntoma: El mock no funciona porque mockeaste donde se define, no donde se usa.</p> <p>Soluci\u00f3n: Mockear donde se USA: <pre><code># Si mymodule.py hace: import requests\n@patch('mymodule.requests.get')  # \u2705 Donde se usa\ndef test_fetch(mock_get):\n    mock_get.return_value.json.return_value = {\"data\": [1, 2, 3]}\n</code></pre></p>"},{"location":"docs/11_TESTING_ML/#quiz-del-modulo-semanas-13-14","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 13-14","text":""},{"location":"docs/11_TESTING_ML/#quiz-semana-13-testing-para-ml","title":"Quiz Semana 13: Testing para ML","text":""},{"location":"docs/11_TESTING_ML/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfQu\u00e9 es un pytest fixture y para qu\u00e9 sirve?</p> \u2705 Respuesta  Un fixture es una funci\u00f3n que provee datos o setup reutilizable para tests: <pre><code>@pytest.fixture\ndef sample_data():\n    return pd.DataFrame({\"age\": [25, 45], \"balance\": [1000, 5000]})\n\ndef test_pipeline(sample_data):  # \u2190 Inyectado autom\u00e1ticamente\n    pipeline.fit(sample_data, [0, 1])\n</code></pre> **Beneficios**: Reutilizaci\u00f3n, cleanup autom\u00e1tico con `yield`, scopes."},{"location":"docs/11_TESTING_ML/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPor qu\u00e9 80% coverage y no 100%?</p> \u2705 Respuesta  - **&lt; 60%**: Probablemente faltan tests cr\u00edticos - **80%**: Balance pragm\u00e1tico (cubre lo importante) - **100%**: Costo marginal alto, puede forzar tests de bajo valor  **Lo importante**: Cubrir paths cr\u00edticos (predicci\u00f3n, validaci\u00f3n), no getters triviales."},{"location":"docs/11_TESTING_ML/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfC\u00f3mo testeas que no hay data leakage?</p> \u2705 Respuesta <pre><code>def test_no_data_leakage():\n    pipeline.fit(X_train, y_train)\n    scaler = pipeline.named_steps['preprocessor'].transformers_[0][1].named_steps['scaler']\n\n    expected_mean = X_train[numerical_cols].mean()\n    actual_mean = scaler.mean_\n\n    np.testing.assert_array_almost_equal(actual_mean, expected_mean)\n</code></pre>"},{"location":"docs/11_TESTING_ML/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea una pir\u00e1mide de fixtures: <code>minimal_data</code> (4 filas), <code>realistic_data</code> (1000 filas), <code>edge_case_data</code> (NaN, outliers).</p> \u2705 Soluci\u00f3n <pre><code>@pytest.fixture\ndef minimal_data():\n    return pd.DataFrame({\"age\": [25, 45, 35, 60], \"balance\": [1000, 5000, 0, 10000]})\n\n@pytest.fixture\ndef realistic_data():\n    return pd.read_csv(\"tests/fixtures/sample_1000.csv\")\n\n@pytest.fixture\ndef edge_case_data():\n    return pd.DataFrame({\n        \"age\": [18, 100, None, 45],  # L\u00edmites y NaN\n        \"balance\": [-100, 0, 1e9, 5000]  # Outliers\n    })\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [12. CI/CD](12_CI_CD.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/12_CI_CD/","title":"12. CI/CD con GitHub Actions","text":"<p>## 0.0 Prerrequisitos</p> <ul> <li>Tener una cuenta de GitHub y saber abrir Pull Requests.</li> <li>Haber ejecutado <code>pytest</code> localmente al menos una vez en un proyecto del portafolio.</li> <li>Conocer la ubicaci\u00f3n del workflow real: <code>.github/workflows/ci-mlops.yml</code>.</li> </ul> <p></p> <p>## 0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</p> <ul> <li>Antes de empezar: abre Protocolo E y define el output m\u00ednimo (un workflow que corre en PR).</li> <li>Durante el debugging: si te atoras &gt;15 min (YAML, permisos, paths, matrix), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para evaluar si CI te protege de regressions.</li> </ul> <p></p> <p>## 0.2 \u2705 Entregables verificables (m\u00ednimo viable)</p> <ul> <li>[ ] Un workflow que corre en <code>push</code> y <code>pull_request</code>.</li> <li>[ ] Matrix con (m\u00ednimo) 2 versiones de Python.</li> <li>[ ] Tests con coverage y threshold (<code>--cov-fail-under</code>).</li> <li>[ ] Al menos 1 check de seguridad (Bandit o secret scanning).</li> <li>[ ] Evidencia en GitHub Actions (runs verdes + artifacts si aplica).</li> </ul> <p></p> <p>## 0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</p> <ul> <li>Concepto: CI (validaci\u00f3n autom\u00e1tica) + gates (coverage/security) + CD (build/push)</li> <li>Archivo: <code>.github/workflows/ci-mlops.yml</code></li> <li>Prueba: abre un PR y verifica que corran jobs por <code>project</code> y <code>python-version</code>.</li> </ul> <p>## \ud83c\udfaf Objetivo del M\u00f3dulo</p> <p>Implementar un pipeline CI/CD profesional que valide autom\u00e1ticamente tu c\u00f3digo en cada push, como el workflow <code>ci-mlops.yml</code> del portafolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \ud83d\udd04 CI/CD = Tu Guardi\u00e1n Autom\u00e1tico                                          \u2551\n\u2551                                                                              \u2551\n\u2551  ANTES (sin CI/CD):                                                          \u2551\n\u2551  \u2022 \"Olvid\u00e9 correr los tests antes de mergear\"                                \u2551\n\u2551  \u2022 \"Romp\u00ed producci\u00f3n con un cambio peque\u00f1o\"                                  \u2551\n\u2551  \u2022 \"No sab\u00eda que mi c\u00f3digo no pasaba linting\"                                \u2551\n\u2551                                                                              \u2551\n\u2551  DESPU\u00c9S (con CI/CD):                                                        \u2551\n\u2551  \u2022 Cada push ejecuta tests autom\u00e1ticamente                                   \u2551\n\u2551  \u2022 No puedes mergear si los tests fallan                                     \u2551\n\u2551  \u2022 Coverage, linting, y seguridad verificados siempre                        \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/12_CI_CD/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>12.1 Anatom\u00eda de un Workflow</li> <li>12.2 Matrix Testing: M\u00faltiples Versiones</li> <li>12.3 Coverage Enforcement</li> <li>12.4 Security Scanning</li> <li>12.5 Docker Build y Push</li> <li>12.6 El Workflow Completo del Portafolio</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/12_CI_CD/#121-anatomia-de-un-workflow","title":"12.1 Anatom\u00eda de un Workflow","text":""},{"location":"docs/12_CI_CD/#estructura-basica","title":"Estructura B\u00e1sica","text":"<pre><code># .github/workflows/ci.yml\n\nname: CI Pipeline                    # Nombre visible en GitHub\n\non:                                   # \u00bfCu\u00e1ndo ejecutar?\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:                                 # \u00bfQu\u00e9 ejecutar?\n  test:\n    runs-on: ubuntu-latest           # Sistema operativo\n    steps:                           # Pasos secuenciales\n      - uses: actions/checkout@v4    # Paso 1: Descargar c\u00f3digo\n      - uses: actions/setup-python@v5 # Paso 2: Configurar Python\n        with:\n          python-version: '3.11'\n      - run: pip install -r requirements.txt  # Paso 3: Instalar deps\n      - run: pytest                           # Paso 4: Correr tests\n</code></pre>"},{"location":"docs/12_CI_CD/#analogia-la-linea-de-inspeccion-de-calidad","title":"Analog\u00eda: La L\u00ednea de Inspecci\u00f3n de Calidad","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \ud83c\udfed IMAGINA UNA F\u00c1BRICA DE AUTOS:                                         \u2551\n\u2551                                                                           \u2551\n\u2551  Workflow = L\u00ednea de inspecci\u00f3n de calidad                                \u2551\n\u2551                                                                           \u2551\n\u2551  on (trigger):                                                            \u2551\n\u2551  \u2192 \"Cada vez que un auto nuevo llega a la l\u00ednea\"                          \u2551\n\u2551                                                                           \u2551\n\u2551  jobs:                                                                    \u2551\n\u2551  \u2192 Diferentes estaciones de inspecci\u00f3n                                    \u2551\n\u2551                                                                           \u2551\n\u2551  steps:                                                                   \u2551\n\u2551  \u2192 Tareas espec\u00edficas en cada estaci\u00f3n                                    \u2551\n\u2551                                                                           \u2551\n\u2551  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2551\n\u2551  \u2502 Checkout\u2502\u2500\u2500\u25ba\u2502 Install \u2502\u2500\u2500\u25ba\u2502  Test   \u2502\u2500\u2500\u25ba\u2502  Build  \u2502                    \u2551\n\u2551  \u2502  (get   \u2502   \u2502  (prep  \u2502   \u2502  (run   \u2502   \u2502 (create \u2502                    \u2551\n\u2551  \u2502  code)  \u2502   \u2502  tools) \u2502   \u2502  tests) \u2502   \u2502 Docker) \u2502                    \u2551\n\u2551  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2551\n\u2551                                                                           \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/12_CI_CD/#mapa-mental-de-conceptos-cicd","title":"\ud83e\udde0 Mapa Mental de Conceptos: CI/CD","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551   CI/CD CON GITHUB ACTIONS           \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502       CI         \u2502              \u2502       CD         \u2502              \u2502  COMPONENTES     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 Lint (ruff)                   \u251c\u2500 Docker build                   \u251c\u2500 on: (triggers)\n\u251c\u2500 Test (pytest)                 \u251c\u2500 Push to registry               \u251c\u2500 jobs:\n\u251c\u2500 Coverage                      \u251c\u2500 Deploy                         \u251c\u2500 steps:\n\u2514\u2500 Security scan                 \u2514\u2500 Rollback                       \u2514\u2500 matrix:\n</code></pre> <p>T\u00e9rminos clave: workflow, trigger, job, step, matrix, secrets</p>"},{"location":"docs/12_CI_CD/#ejercicio-puente-github-actions","title":"\ud83d\udcbb Ejercicio Puente: GitHub Actions","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/12_CI_CD/#practica-del-portafolio-cicd-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: CI/CD en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con GitHub Actions\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/12_CI_CD/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de CI/CD?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en GitHub Actions, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/12_CI_CD/#122-matrix-testing-multiples-versiones","title":"12.2 Matrix Testing: M\u00faltiples Versiones","text":""},{"location":"docs/12_CI_CD/#el-problema-funciona-en-mi-version-de-python","title":"El Problema: \"Funciona en mi versi\u00f3n de Python\"","text":"<pre><code># \u274c ANTES: Solo pruebas con una versi\u00f3n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'  # \u00bfY si alguien usa 3.12?\n</code></pre>"},{"location":"docs/12_CI_CD/#la-solucion-matrix-strategy","title":"La Soluci\u00f3n: Matrix Strategy","text":"<pre><code># \u2705 DESPU\u00c9S: Pruebas con m\u00faltiples versiones\n# C\u00f3digo REAL de ci-mlops.yml del portafolio\n\njobs:\n  tests:\n    name: Tests &amp; Coverage               # Nombre visible en GitHub Actions UI.\n    runs-on: ubuntu-latest               # Runner: m\u00e1quina virtual donde corre el job.\n    strategy:\n      fail-fast: false                   # false: sigue ejecutando otros jobs aunque uno falle.\n      matrix:\n        python-version: ['3.11', '3.12'] # Matrix: ejecuta el job con cada valor.\n        project:                         # Segundo eje del matrix: proyectos.\n          - BankChurn-Predictor\n          - CarVision-Market-Intelligence\n          - TelecomAI-Customer-Intelligence\n\n    # Esto crea 2 x 3 = 6 jobs paralelos:\n    # - BankChurn con Python 3.11        # Cada combinaci\u00f3n es un job independiente.\n    # - BankChurn con Python 3.12\n    # - CarVision con Python 3.11\n    # - CarVision con Python 3.12\n    # - TelecomAI con Python 3.11\n    # - TelecomAI con Python 3.12\n\n    steps:\n      - name: Checkout code              # Paso: clona el repositorio.\n        uses: actions/checkout@v4        # Action oficial de GitHub para checkout.\n\n      - name: Set up Python ${{ matrix.python-version }}  # ${{ }}: expresi\u00f3n de GitHub Actions.\n        uses: actions/setup-python@v5    # Instala Python en el runner.\n        with:\n          python-version: ${{ matrix.python-version }}  # Usa el valor del matrix.\n          cache: 'pip'                   # Cachea ~/.cache/pip \u2192 installs m\u00e1s r\u00e1pidos.\n\n      - name: Install dependencies\n        working-directory: ${{ matrix.project }}  # cd al proyecto antes de ejecutar.\n        run: |                           # run: ejecuta comandos shell.\n          python -m pip install --upgrade pip      # Actualiza pip primero.\n          pip install -r requirements.txt          # Instala dependencias del proyecto.\n          pip install pytest pytest-cov            # Instala herramientas de testing.\n\n      - name: Run tests\n        working-directory: ${{ matrix.project }}\n        run: pytest --cov=src/ --cov-fail-under=80  # --cov-fail-under: falla si coverage &lt; 80%.\n</code></pre>"},{"location":"docs/12_CI_CD/#visualizacion-del-matrix","title":"Visualizaci\u00f3n del Matrix","text":"<pre><code>                    Python 3.11          Python 3.12\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\nBankChurn         \u2502   Job 1     \u2502      \u2502   Job 2     \u2502\n                  \u2502   \u2705 Pass   \u2502      \u2502   \u2705 Pass  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\nCarVision         \u2502   Job 3     \u2502      \u2502   Job 4     \u2502\n                  \u2502   \u2705 Pass   \u2502      \u2502   \u2705 Pass  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\nTelecomAI         \u2502   Job 5     \u2502      \u2502   Job 6     \u2502\n                  \u2502   \u2705 Pass   \u2502      \u2502   \u2705 Pass  \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nTotal: 6 jobs ejecut\u00e1ndose EN PARALELO\n</code></pre>"},{"location":"docs/12_CI_CD/#123-coverage-enforcement","title":"12.3 Coverage Enforcement","text":""},{"location":"docs/12_CI_CD/#thresholds-por-proyecto","title":"Thresholds por Proyecto","text":"<pre><code># C\u00f3digo REAL de ci-mlops.yml\n\n- name: Run tests with coverage\n  working-directory: ${{ matrix.project }}\n  run: |\n    # Cada proyecto puede tener diferente threshold\n    if [ \"${{ matrix.project }}\" = \"BankChurn-Predictor\" ]; then\n      COV_TARGET=\"src\"\n      THRESHOLD=79\n    elif [ \"${{ matrix.project }}\" = \"CarVision-Market-Intelligence\" ]; then\n      COV_TARGET=\"src/carvision\"\n      THRESHOLD=80\n    else\n      COV_TARGET=\"src/telecom\"\n      THRESHOLD=80\n    fi\n\n    pytest --maxfail=1 --disable-warnings -q \\\n      -m \"not slow\" \\\n      --cov=$COV_TARGET \\\n      --cov-report=xml \\\n      --cov-report=term-missing \\\n      --cov-fail-under=$THRESHOLD  # \u2190 FALLA si est\u00e1 por debajo\n</code></pre>"},{"location":"docs/12_CI_CD/#upload-de-coverage-a-codecov","title":"Upload de Coverage a Codecov","text":"<pre><code>- name: Upload coverage to Codecov\n  uses: codecov/codecov-action@v5\n  with:\n    files: ${{ matrix.project }}/coverage.xml\n    flags: ${{ matrix.project }}\n    name: ${{ matrix.project }}-coverage-${{ matrix.python-version }}\n    fail_ci_if_error: false  # No fallar si Codecov tiene problemas\n\n- name: Upload coverage artifact\n  uses: actions/upload-artifact@v5\n  with:\n    name: coverage-${{ matrix.project }}-py${{ matrix.python-version }}\n    path: ${{ matrix.project }}/coverage.xml\n    retention-days: 30\n</code></pre>"},{"location":"docs/12_CI_CD/#124-security-scanning","title":"12.4 Security Scanning","text":""},{"location":"docs/12_CI_CD/#multiples-capas-de-seguridad","title":"M\u00faltiples Capas de Seguridad","text":"<pre><code># Job de seguridad - C\u00f3digo REAL del portafolio\n\nsecurity-scan:\n  name: Security Scan\n  runs-on: ubuntu-latest\n  needs: [tests]  # Solo corre si tests pasan\n\n  steps:\n    - uses: actions/checkout@v4\n      with:\n        fetch-depth: 0  # Necesario para gitleaks (analiza historial)\n\n    # 1. GITLEAKS: Detecta secretos en el c\u00f3digo\n    - name: Gitleaks (Secret Detection)\n      uses: gitleaks/gitleaks-action@v2\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n    # 2. BANDIT: An\u00e1lisis de seguridad de Python\n    - name: Set up Python\n      uses: actions/setup-python@v5\n      with:\n        python-version: '3.12'\n\n    - name: Run Bandit\n      run: |\n        pip install bandit\n        for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n          echo \"Scanning $project...\"\n          bandit -r \"$project/src\" -f json -o \"bandit-$project.json\" || true\n        done\n\n    # 3. PIP-AUDIT: Vulnerabilidades en dependencias\n    - name: Run pip-audit\n      run: |\n        pip install pip-audit\n        for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n          echo \"Auditing $project...\"\n          pip-audit -r \"$project/requirements.txt\" --format json || true\n        done\n</code></pre>"},{"location":"docs/12_CI_CD/#trivy-escaneo-de-imagenes-docker","title":"TRIVY: Escaneo de Im\u00e1genes Docker","text":"<pre><code>docker-security:\n  name: Docker Security Scan\n  runs-on: ubuntu-latest\n  needs: [docker-build]\n\n  steps:\n    - name: Run Trivy vulnerability scanner\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: 'ml-portfolio-bankchurn:latest'\n        format: 'sarif'\n        output: 'trivy-results.sarif'\n        severity: 'CRITICAL,HIGH'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v3\n      with:\n        sarif_file: 'trivy-results.sarif'\n</code></pre>"},{"location":"docs/12_CI_CD/#125-docker-build-y-push","title":"12.5 Docker Build y Push","text":""},{"location":"docs/12_CI_CD/#build-multi-proyecto","title":"Build Multi-Proyecto","text":"<pre><code>docker-build:\n  name: Docker Build\n  runs-on: ubuntu-latest\n  needs: [tests, quality-gates]\n  if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n  strategy:\n    matrix:\n      include:\n        - project: BankChurn-Predictor\n          image: ml-portfolio-bankchurn\n        - project: CarVision-Market-Intelligence\n          image: ml-portfolio-carvision\n        - project: TelecomAI-Customer-Intelligence\n          image: ml-portfolio-telecom\n\n  steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n\n    - name: Login to GitHub Container Registry\n      uses: docker/login-action@v3\n      with:\n        registry: ghcr.io\n        username: ${{ github.actor }}\n        password: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: Build and push\n      uses: docker/build-push-action@v5\n      with:\n        context: ./${{ matrix.project }}\n        push: true\n        tags: |\n          ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:latest\n          ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:${{ github.sha }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n</code></pre>"},{"location":"docs/12_CI_CD/#126-el-workflow-completo-del-portafolio","title":"12.6 El Workflow Completo del Portafolio","text":""},{"location":"docs/12_CI_CD/#diagrama-del-pipeline","title":"Diagrama del Pipeline","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         CI/CD Pipeline: ci-mlops.yml                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  TRIGGER: push to main/develop OR pull_request to main                      \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                         JOB 1: tests                                \u2502    \u2502\n\u2502  \u2502  Matrix: Python 3.11/3.12 \u00d7 3 proyectos = 6 jobs paralelos          \u2502    \u2502\n\u2502  \u2502                                                                     \u2502    \u2502\n\u2502  \u2502  Steps:                                                             \u2502    \u2502\n\u2502  \u2502  1. Checkout code                                                   \u2502    \u2502\n\u2502  \u2502  2. Setup Python (con cache)                                        \u2502    \u2502\n\u2502  \u2502  3. Install dependencies                                            \u2502    \u2502\n\u2502  \u2502  4. Run linting (flake8, black, isort)                              \u2502    \u2502\n\u2502  \u2502  5. Run tests with coverage                                         \u2502    \u2502\n\u2502  \u2502  6. Upload coverage to Codecov                                      \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                              \u2502\n\u2502                              \u25bc                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      JOB 2: quality-gates                           \u2502    \u2502\n\u2502  \u2502  needs: [tests]                                                     \u2502    \u2502\n\u2502  \u2502                                                                     \u2502    \u2502\n\u2502  \u2502  Steps:                                                             \u2502    \u2502\n\u2502  \u2502  1. Check Black formatting                                          \u2502    \u2502\n\u2502  \u2502  2. Check import sorting (isort)                                    \u2502    \u2502\n\u2502  \u2502  3. Run flake8 strict                                               \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                              \u2502\n\u2502                              \u25bc                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      JOB 3: security-scan                           \u2502    \u2502\n\u2502  \u2502  needs: [tests]                                                     \u2502    \u2502\n\u2502  \u2502                                                                     \u2502    \u2502\n\u2502  \u2502  Steps:                                                             \u2502    \u2502\n\u2502  \u2502  1. Gitleaks (secretos)                                             \u2502    \u2502\n\u2502  \u2502  2. Bandit (c\u00f3digo Python)                                          \u2502    \u2502\n\u2502  \u2502  3. pip-audit (dependencias)                                        \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                              \u2502\n\u2502                              \u25bc                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                      JOB 4: docker-build                            \u2502    \u2502\n\u2502  \u2502  needs: [tests, quality-gates]                                      \u2502    \u2502\n\u2502  \u2502  if: push to main                                                   \u2502    \u2502\n\u2502  \u2502                                                                     \u2502    \u2502\n\u2502  \u2502  Steps:                                                             \u2502    \u2502\n\u2502  \u2502  1. Setup Docker Buildx                                             \u2502    \u2502\n\u2502  \u2502  2. Login to GHCR                                                   \u2502    \u2502\n\u2502  \u2502  3. Build multi-stage images                                        \u2502    \u2502\n\u2502  \u2502  4. Push to registry                                                \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                              \u2502                                              \u2502\n\u2502                              \u25bc                                              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502                        JOB 5: e2e-test                              \u2502    \u2502\n\u2502  \u2502  needs: [docker-build]                                              \u2502    \u2502\n\u2502  \u2502                                                                     \u2502    \u2502\n\u2502  \u2502  Steps:                                                             \u2502    \u2502\n\u2502  \u2502  1. Start Docker Compose stack                                      \u2502    \u2502\n\u2502  \u2502  2. Wait for services                                               \u2502    \u2502\n\u2502  \u2502  3. Run API health checks                                           \u2502    \u2502\n\u2502  \u2502  4. Run integration tests                                           \u2502    \u2502\n\u2502  \u2502  5. Cleanup                                                         \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/12_CI_CD/#el-archivo-completo","title":"El Archivo Completo","text":"<pre><code># .github/workflows/ci-mlops.yml - Versi\u00f3n simplificada del portafolio\n\nname: CI/CD MLOps Portfolio\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\npermissions:\n  actions: read\n  contents: read\n  security-events: write\n  packages: write\n\nenv:\n  PYTHON_VERSION: '3.12'\n\njobs:\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # JOB 1: Tests con Coverage\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  tests:\n    name: Tests &amp; Coverage\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version: ['3.11', '3.12']\n        project:\n          - BankChurn-Predictor\n          - CarVision-Market-Intelligence\n          - TelecomAI-Customer-Intelligence\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n\n      - name: Install dependencies\n        working-directory: ${{ matrix.project }}\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt 2&gt;/dev/null || pip install -e .\n          pip install pytest pytest-cov flake8 black isort mypy\n\n      - name: Run linting\n        working-directory: ${{ matrix.project }}\n        run: |\n          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics || true\n          black --check src/ || true\n\n      - name: Run tests with coverage\n        working-directory: ${{ matrix.project }}\n        run: |\n          # Determinar threshold por proyecto\n          if [ \"${{ matrix.project }}\" = \"BankChurn-Predictor\" ]; then\n            THRESHOLD=79\n          else\n            THRESHOLD=80\n          fi\n\n          pytest -m \"not slow\" \\\n            --cov=src/ \\\n            --cov-report=xml \\\n            --cov-report=term-missing \\\n            --cov-fail-under=$THRESHOLD\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v5\n        with:\n          files: ${{ matrix.project }}/coverage.xml\n          flags: ${{ matrix.project }}\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # JOB 2: Quality Gates\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  quality-gates:\n    name: Quality Gates\n    runs-on: ubuntu-latest\n    needs: [tests]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install tools\n        run: pip install black flake8 isort\n\n      - name: Check formatting\n        run: |\n          for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n            echo \"Checking $project...\"\n            black --check \"$project/src\" \"$project/app\" 2&gt;/dev/null || true\n            isort --check-only \"$project/src\" 2&gt;/dev/null || true\n          done\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # JOB 3: Security Scan\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  security-scan:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    needs: [tests]\n\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Gitleaks\n        uses: gitleaks/gitleaks-action@v2\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Run Bandit\n        run: |\n          pip install bandit\n          bandit -r */src/ -f json -o bandit-report.json || true\n\n      - name: Upload security report\n        uses: actions/upload-artifact@v5\n        with:\n          name: security-reports\n          path: bandit-report.json\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # JOB 4: Docker Build (solo en main)\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  docker-build:\n    name: Docker Build\n    runs-on: ubuntu-latest\n    needs: [tests, quality-gates]\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    strategy:\n      matrix:\n        include:\n          - project: BankChurn-Predictor\n            image: ml-portfolio-bankchurn\n          - project: CarVision-Market-Intelligence\n            image: ml-portfolio-carvision\n          - project: TelecomAI-Customer-Intelligence\n            image: ml-portfolio-telecom\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Login to GHCR\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          context: ./${{ matrix.project }}\n          push: true\n          tags: |\n            ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:latest\n            ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:${{ github.sha }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n</code></pre>"},{"location":"docs/12_CI_CD/#127-workflows-avanzados-de-mlops-nuevo","title":"12.7 Workflows Avanzados de MLOps \u2b50 NUEVO","text":"<p>El portafolio incluye workflows especializados para ML que van m\u00e1s all\u00e1 del CI/CD tradicional. Estos workflows automatizan tareas cr\u00edticas como detecci\u00f3n de drift, reentrenamiento y comparaci\u00f3n de modelos.</p>"},{"location":"docs/12_CI_CD/#workflows-disponibles-en-el-portafolio","title":"Workflows Disponibles en el Portafolio","text":"<pre><code>.github/workflows/\n\u251c\u2500\u2500 ci-mlops.yml              # CI/CD principal (ya cubierto)\n\u251c\u2500\u2500 drift-detection.yml       # Detecta drift de datos/modelo\n\u251c\u2500\u2500 drift-bankchurn.yml       # Drift espec\u00edfico para BankChurn\n\u251c\u2500\u2500 retrain-bankchurn.yml     # Reentrenamiento autom\u00e1tico\n\u251c\u2500\u2500 cml-training-comparison.yml # Comparaci\u00f3n de runs con CML\n\u2514\u2500\u2500 docs.yml                  # Build de documentaci\u00f3n\n</code></pre>"},{"location":"docs/12_CI_CD/#1271-drift-detection-monitoreo-automatico","title":"12.7.1 Drift Detection: Monitoreo Autom\u00e1tico","text":"<pre><code># .github/workflows/drift-detection.yml (simplificado)\nname: Drift Detection\n\non:\n  schedule:\n    - cron: '0 6 * * 1'  # Cada lunes a las 6 AM\n  workflow_dispatch:      # Tambi\u00e9n manual\n\njobs:\n  detect-drift:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        project: [BankChurn-Predictor, CarVision-Market-Intelligence]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        run: |\n          pip install evidently pandas scikit-learn joblib\n\n      - name: Run drift detection\n        working-directory: ${{ matrix.project }}\n        run: |\n          python scripts/detect_drift.py \\\n            --reference data/reference.csv \\\n            --current data/production.csv \\\n            --output reports/drift_report.html\n\n      - name: Upload drift report\n        uses: actions/upload-artifact@v5\n        with:\n          name: drift-report-${{ matrix.project }}\n          path: ${{ matrix.project }}/reports/drift_report.html\n\n      - name: Create issue if drift detected\n        if: failure()\n        uses: actions/github-script@v7\n        with:\n          script: |\n            github.rest.issues.create({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              title: '\u26a0\ufe0f Drift detectado en ${{ matrix.project }}',\n              body: 'El workflow de drift detection ha detectado cambios significativos. Ver artifacts para detalles.',\n              labels: ['drift', 'ml-ops', 'automated']\n            })\n</code></pre>"},{"location":"docs/12_CI_CD/#1272-retrain-automatico-cuando-el-modelo-necesita-actualizacion","title":"12.7.2 Retrain Autom\u00e1tico: Cuando el Modelo Necesita Actualizaci\u00f3n","text":"<pre><code># .github/workflows/retrain-bankchurn.yml (simplificado)\nname: Retrain BankChurn Model\n\non:\n  workflow_dispatch:\n    inputs:\n      reason:\n        description: 'Raz\u00f3n del reentrenamiento'\n        required: true\n        default: 'scheduled-retrain'\n      promote_if_better:\n        description: '\u00bfPromover autom\u00e1ticamente si mejora m\u00e9tricas?'\n        required: true\n        default: 'false'\n        type: boolean\n\nenv:\n  PROJECT: BankChurn-Predictor\n  MLFLOW_TRACKING_URI: http://localhost:5000\n\njobs:\n  retrain:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n\n      - name: Install dependencies\n        working-directory: ${{ env.PROJECT }}\n        run: pip install -r requirements.txt\n\n      - name: Train new model\n        working-directory: ${{ env.PROJECT }}\n        run: |\n          python main.py --mode train \\\n            --experiment-name \"retrain-${{ github.run_id }}\" \\\n            --run-name \"${{ inputs.reason }}\"\n\n      - name: Evaluate model\n        working-directory: ${{ env.PROJECT }}\n        id: evaluate\n        run: |\n          python scripts/evaluate_model.py \\\n            --model artifacts/model.joblib \\\n            --test-data data/test.csv \\\n            --output metrics.json\n\n          # Exportar m\u00e9tricas para comparaci\u00f3n\n          F1=$(jq '.f1_score' metrics.json)\n          echo \"f1_score=$F1\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Compare with production model\n        id: compare\n        run: |\n          PROD_F1=$(cat production_metrics.json | jq '.f1_score')\n          NEW_F1=${{ steps.evaluate.outputs.f1_score }}\n\n          if (( $(echo \"$NEW_F1 &gt; $PROD_F1\" | bc -l) )); then\n            echo \"is_better=true\" &gt;&gt; $GITHUB_OUTPUT\n            echo \"\u2705 Nuevo modelo es mejor: $NEW_F1 &gt; $PROD_F1\"\n          else\n            echo \"is_better=false\" &gt;&gt; $GITHUB_OUTPUT\n            echo \"\u274c Nuevo modelo no mejora: $NEW_F1 &lt;= $PROD_F1\"\n          fi\n\n      - name: Promote model (if better and enabled)\n        if: steps.compare.outputs.is_better == 'true' &amp;&amp; inputs.promote_if_better\n        run: |\n          python scripts/promote_model.py \\\n            --model artifacts/model.joblib \\\n            --stage production \\\n            --run-id ${{ github.run_id }}\n\n      - name: Upload training artifacts\n        uses: actions/upload-artifact@v5\n        with:\n          name: retrain-artifacts-${{ github.run_id }}\n          path: |\n            ${{ env.PROJECT }}/artifacts/\n            ${{ env.PROJECT }}/metrics.json\n</code></pre>"},{"location":"docs/12_CI_CD/#1273-cml-continuous-machine-learning","title":"12.7.3 CML: Continuous Machine Learning","text":"<p>CML permite generar reportes visuales de entrenamiento directamente en PRs. El portafolio lo usa para comparar runs de MLflow:</p> <pre><code># .github/workflows/cml-training-comparison.yml (simplificado)\nname: CML Training Report\n\non:\n  pull_request:\n    paths:\n      - '**/src/**'\n      - '**/configs/**'\n\njobs:\n  train-and-report:\n    runs-on: ubuntu-latest\n    container: ghcr.io/iterative/cml:0-dvc2-base1\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Train model\n        run: |\n          pip install -r BankChurn-Predictor/requirements.txt\n          cd BankChurn-Predictor\n          python main.py --mode train\n\n      - name: Generate CML report\n        env:\n          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          # Crear reporte markdown\n          echo \"## \ud83d\udcca Training Report\" &gt;&gt; report.md\n          echo \"\" &gt;&gt; report.md\n\n          # Agregar m\u00e9tricas\n          echo \"### Metrics\" &gt;&gt; report.md\n          cat BankChurn-Predictor/artifacts/training_results.json | \\\n            python -c \"import json,sys; d=json.load(sys.stdin); print(f'- **F1**: {d[\\\"f1\\\"]:.4f}')\" &gt;&gt; report.md\n\n          # Agregar gr\u00e1ficos si existen\n          if [ -f BankChurn-Predictor/artifacts/confusion_matrix.png ]; then\n            echo \"### Confusion Matrix\" &gt;&gt; report.md\n            cml-publish BankChurn-Predictor/artifacts/confusion_matrix.png --md &gt;&gt; report.md\n          fi\n\n          # Publicar como comentario en PR\n          cml comment create report.md\n</code></pre>"},{"location":"docs/12_CI_CD/#1274-diagrama-de-workflows-mlops-integrados","title":"12.7.4 Diagrama de Workflows MLOps Integrados","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    WORKFLOWS MLOPS DEL PORTAFOLIO                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  DESARROLLO                           OPERACI\u00d3N                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                 \u2502\n\u2502                                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502  \u2502 Push/PR      \u2502                     \u2502 Schedule     \u2502                          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502 (cron)       \u2502                          \u2502\n\u2502         \u2502                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502         \u25bc                                    \u2502                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                            \u25bc                                  \u2502\n\u2502  \u2502 ci-mlops.yml \u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502  \u2502              \u2502                     \u2502 drift-       \u2502                          \u2502\n\u2502  \u2502 \u2022 Tests      \u2502                     \u2502 detection    \u2502                          \u2502\n\u2502  \u2502 \u2022 Coverage   \u2502                     \u2502              \u2502                          \u2502\n\u2502  \u2502 \u2022 Security   \u2502                     \u2502 \u2022 Compare    \u2502                          \u2502\n\u2502  \u2502 \u2022 Docker     \u2502                     \u2502   reference  \u2502                          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502   vs current \u2502                          \u2502\n\u2502         \u2502                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502         \u25bc                                    \u2502                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                            \u25bc                                  \u2502\n\u2502  \u2502 cml-report   \u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502  \u2502              \u2502    \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2502 \u00bfDrift?      \u2502                          \u2502\n\u2502  \u2502 \u2022 Metrics    \u2502        NO           \u2502              \u2502                          \u2502\n\u2502  \u2502   comparison \u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502  \u2502 \u2022 Plots in   \u2502                            \u2502 S\u00cd                               \u2502\n\u2502  \u2502   PR comment \u2502                            \u25bc                                  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u2502\n\u2502                                       \u2502 retrain-     \u2502                          \u2502\n\u2502                                       \u2502 bankchurn    \u2502                          \u2502\n\u2502                                       \u2502              \u2502                          \u2502\n\u2502                                       \u2502 \u2022 Train new  \u2502                          \u2502\n\u2502                                       \u2502 \u2022 Compare    \u2502                          \u2502\n\u2502                                       \u2502 \u2022 Promote?   \u2502                          \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/12_CI_CD/#ejercicio-implementar-drift-detection-basico","title":"\ud83d\udd27 Ejercicio: Implementar Drift Detection B\u00e1sico","text":"<pre><code># 1. Crear script de drift detection\ncat &gt; scripts/detect_drift.py &lt;&lt; 'EOF'\n\"\"\"Drift detection b\u00e1sico usando Evidently.\"\"\"\nimport argparse\nimport pandas as pd\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--reference\", required=True)\n    parser.add_argument(\"--current\", required=True)\n    parser.add_argument(\"--output\", default=\"drift_report.html\")\n    args = parser.parse_args()\n\n    reference = pd.read_csv(args.reference)\n    current = pd.read_csv(args.current)\n\n    report = Report(metrics=[DataDriftPreset()])\n    report.run(reference_data=reference, current_data=current)\n    report.save_html(args.output)\n\n    # Exit con c\u00f3digo de error si hay drift significativo\n    drift_share = report.as_dict()[\"metrics\"][0][\"result\"][\"share_of_drifted_columns\"]\n    if drift_share &gt; 0.3:  # &gt;30% de columnas con drift\n        print(f\"\u26a0\ufe0f Drift detectado: {drift_share:.1%} de columnas\")\n        exit(1)\n    print(f\"\u2705 Sin drift significativo: {drift_share:.1%} de columnas\")\n\nif __name__ == \"__main__\":\n    main()\nEOF\n\n# 2. Crear workflow b\u00e1sico de drift\nmkdir -p .github/workflows\ncat &gt; .github/workflows/drift-check.yml &lt;&lt; 'EOF'\nname: Weekly Drift Check\non:\n  schedule:\n    - cron: '0 8 * * 1'  # Lunes 8 AM\n  workflow_dispatch:\n\njobs:\n  drift:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.12'\n      - run: pip install evidently pandas\n      - run: python scripts/detect_drift.py --reference data/train.csv --current data/new_data.csv\nEOF\n</code></pre>"},{"location":"docs/12_CI_CD/#128-ingenieria-inversa-pedagogica-el-pipeline-cicd-real","title":"12.8 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: El Pipeline CI/CD Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n t\u00e9cnica detr\u00e1s del workflow <code>.github/workflows/ci-mlops.yml</code> del portafolio.</p> <p>Esta secci\u00f3n aplica el m\u00e9todo de \"Shadow Coder Senior\": diseccionamos el pipeline real que orquesta los 3 proyectos del portafolio.</p>"},{"location":"docs/12_CI_CD/#1281-el-por-que-arquitectonico","title":"12.8.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 el portafolio usa un workflow tan complejo (500+ l\u00edneas) en lugar de un simple <code>pytest</code>?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: Tenemos 3 proyectos (BankChurn, CarVision, Telecom) en un repo     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: Matrix Strategy con variable `project`                               \u2502\n\u2502  RESULTADO: Un solo workflow gestiona 3 proyectos en paralelo                   \u2502\n\u2502  REFERENCIA: ci-mlops.yml l\u00edneas 34-38                                          \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: Incompatibilidad de versiones de Python entre dev y prod           \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: Matrix de `python-version: ['3.11', '3.12']`                         \u2502\n\u2502  RESULTADO: Validamos compatibilidad futura autom\u00e1ticamente                     \u2502\n\u2502  REFERENCIA: ci-mlops.yml l\u00ednea 34                                              \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: Instalar dependencias toma 2 minutos por job (x6 jobs = 12 min)    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: `cache: 'pip'` en setup-python                                       \u2502\n\u2502  RESULTADO: Builds bajan de 15 min a 3 min                                      \u2502\n\u2502  REFERENCIA: ci-mlops.yml l\u00ednea 65                                              \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 4: Tests de integraci\u00f3n requieren base de datos real (MLflow)         \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: Service containers (Postgres) en el runner                           \u2502\n\u2502  RESULTADO: Tests reales sin mocks para la DB                                   \u2502\n\u2502  REFERENCIA: ci-mlops.yml l\u00edneas 40-53                                          \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/12_CI_CD/#1282-anatomia-linea-por-linea-ci-mlopsyml","title":"12.8.2 \ud83d\udd0d Anatom\u00eda L\u00ednea por L\u00ednea: <code>ci-mlops.yml</code>","text":"<p>Analicemos los bloques cr\u00edticos que distinguen a un Senior MLOps Engineer.</p> <pre><code># .github/workflows/ci-mlops.yml\n\n# BLOQUE 1: Disparadores Inteligentes\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\non:\n  push:\n    branches: [ main, develop ]   # Corre en ramas principales\n  pull_request:\n    branches: [ main ]            # Corre en PRs hacia main\n  workflow_dispatch:              # Permite ejecuci\u00f3n manual desde UI\n    inputs:\n      run_integration:\n        description: 'Run full integration tests'\n        required: false\n        default: 'true'\n        type: boolean\n# \u00bfPor qu\u00e9? workflow_dispatch es vital para debuggear CI sin hacer commits vac\u00edos.\n\n# BLOQUE 2: Matrix Strategy (El coraz\u00f3n del monorepo)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false            # CR\u00cdTICO: Si falla BankChurn, NO canceles CarVision\n      matrix:\n        python-version: ['3.11', '3.12']\n        project:\n          - BankChurn-Predictor\n          - CarVision-Market-Intelligence\n          - TelecomAI-Customer-Intelligence\n# \u00bfPor qu\u00e9? Esto genera 6 jobs (2 versiones * 3 proyectos).\n# fail-fast: false nos permite ver TODOS los errores de una vez.\n\n# BLOQUE 3: Servicios para Tests de Integraci\u00f3n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_DB: mlflow\n          POSTGRES_USER: mlflow\n          POSTGRES_PASSWORD: mlflow_test\n        options: &gt;-\n          --health-cmd \"pg_isready -U mlflow\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n# \u00bfPor qu\u00e9? MLflow necesita backend. Usar mocks oculta errores de integraci\u00f3n real.\n# El health-cmd asegura que Postgres est\u00e9 LISTO antes de iniciar los tests.\n\n# BLOQUE 4: Instalaci\u00f3n Inteligente de Dependencias\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n      - name: Install dependencies\n        working-directory: ${{ matrix.project }}  # cd al directorio del proyecto actual\n        run: |\n          # Manejo h\u00edbrido de requirements.txt vs .in\n          if [ -f requirements.in ]; then\n            pip install -r requirements.in\n          elif [ -f requirements.txt ]; then\n            # Hack para limpiar hashes si causan conflictos en CI\n            grep -v '^[[:space:]]*--hash=' requirements.txt ... &gt; requirements_no_hash.txt\n            pip install -r requirements_no_hash.txt\n          fi\n# \u00bfPor qu\u00e9? En un monorepo, cada proyecto tiene sus propias deps.\n# El `working-directory` es clave aqu\u00ed.\n\n# BLOQUE 5: Thresholds de Coverage Din\u00e1micos\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n      - name: Run tests with coverage\n        working-directory: ${{ matrix.project }}\n        run: |\n          # L\u00f3gica condicional en Bash dentro del YAML\n          if [ \"${{ matrix.project }}\" = \"BankChurn-Predictor\" ]; then\n            THRESHOLD=79\n          else\n            THRESHOLD=80\n          fi\n\n          pytest ... --cov-fail-under=$THRESHOLD\n# \u00bfPor qu\u00e9? No todos los proyectos maduran igual. BankChurn puede ser legacy (79%)\n# mientras CarVision es nuevo (80%). No bajes la vara del nuevo por culpa del viejo.\n</code></pre>"},{"location":"docs/12_CI_CD/#1283-laboratorio-de-replicacion","title":"12.8.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Crear un mini-pipeline matrix que pruebe 2 carpetas ficticias.</p> <ol> <li> <p>Crea la estructura:    <pre><code>mkdir -p labs/ci-matrix/{api-a,api-b}\ntouch labs/ci-matrix/api-a/test_a.py\ntouch labs/ci-matrix/api-b/test_b.py\n</code></pre></p> </li> <li> <p>Crea el workflow <code>.github/workflows/lab-matrix.yml</code>:    <pre><code>name: Lab Matrix\non: workflow_dispatch\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        service: [api-a, api-b]\n    steps:\n      - uses: actions/checkout@v4\n      - name: Test ${{ matrix.service }}\n        working-directory: labs/ci-matrix/${{ matrix.service }}\n        run: echo \"Running tests for ${{ matrix.service }}\"\n</code></pre></p> </li> <li> <p>Ejec\u00fatalo manualmente y observa c\u00f3mo se crean 2 jobs paralelos.</p> </li> </ol>"},{"location":"docs/12_CI_CD/#1284-troubleshooting-preventivo","title":"12.8.4 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n \"Process completed with exit code 1\" en <code>pip install</code> Conflicto de hashes en <code>requirements.txt</code> entre OS (Linux CI vs Mac Local) Usar el script <code>sed</code> para limpiar hashes o usar <code>pip-compile</code> multiplataforma. Tests pasan pero Coverage falla El threshold es muy alto para el estado actual Ajustar <code>THRESHOLD</code> en el bloque condicional bash. Postgres connection refused El servicio no estaba listo cuando pytest arranc\u00f3 Verificar <code>options: --health-cmd</code> en la definici\u00f3n del servicio. \"ModuleNotFoundError\" en CI <code>working-directory</code> incorrecto Asegurar que <code>working-directory: ${{ matrix.project }}</code> est\u00e9 en CADA paso que use archivos del proyecto."},{"location":"docs/12_CI_CD/#errores-habituales-y-como-depurarlos-en-cicd","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en CI/CD","text":"<p>En este m\u00f3dulo los problemas suelen venir de triggers mal configurados, rutas incorrectas o jobs mal encadenados.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/12_CI_CD/#1-el-workflow-no-se-dispara","title":"1) El workflow no se dispara","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Haces push o abres un PR y GitHub no muestra ning\u00fan run nuevo.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa la secci\u00f3n <code>on:</code> del workflow:</li> <li>\u00bfIncluye las ramas correctas (<code>main</code>, <code>develop</code>, feature branches)?</li> <li>\u00bfEst\u00e1s haciendo push a una rama no contemplada?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta los triggers a tu flujo real:   <pre><code>on:\n  push:\n    branches: [main, develop, \"feature/*\"]\n  pull_request:\n    branches: [main]\n</code></pre></li> </ul>"},{"location":"docs/12_CI_CD/#2-falla-solo-en-un-proyecto-o-en-una-version-de-python","title":"2) Falla solo en un proyecto o en una versi\u00f3n de Python","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En la matrix, solo falla <code>CarVision</code> en Python 3.12, el resto pasa.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Mira los logs filtrando por <code>matrix.project</code> y <code>matrix.python-version</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ejecuta localmente con la misma versi\u00f3n de Python y el mismo directorio (<code>working-directory</code>) que en el job.</li> <li>Aseg\u00farate de que los paths (<code>src/</code>, <code>app/</code>, <code>requirements.txt</code>) sean correctos para cada proyecto en la matrix.</li> </ul>"},{"location":"docs/12_CI_CD/#3-coverage-o-linting-no-respetan-el-threshold-esperado","title":"3) Coverage o linting no respetan el threshold esperado","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Crees haber configurado <code>--cov-fail-under</code>, pero el job pasa aunque el coverage sea bajo.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica la l\u00ednea exacta del comando <code>pytest</code> en el workflow.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de que el par\u00e1metro <code>--cov-fail-under</code> se pase realmente al comando que se ejecuta (no a un alias intermedio).</li> <li>Diferencia claramente entre thresholds por proyecto usando condiciones <code>if</code> en el script del job.</li> </ul>"},{"location":"docs/12_CI_CD/#4-jobs-que-fallan-por-falta-de-dependencias-o-rutas","title":"4) Jobs que fallan por falta de dependencias o rutas","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores como <code>ModuleNotFoundError</code> en CI pero no en local.</li> <li><code>pip install -r requirements.txt</code> falla porque el archivo no existe en ese directorio.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica el <code>working-directory</code> de cada <code>step</code>.</li> <li>Revisa la estructura real del repo y compara con las rutas usadas en el workflow.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta <code>working-directory</code> para que apunte al proyecto correcto (<code>BankChurn-Predictor</code>, etc.).</li> <li>Si un proyecto no tiene <code>requirements.txt</code>, instala en modo editable con <code>pip install -e .</code> como fallback.</li> </ul>"},{"location":"docs/12_CI_CD/#5-patron-general-de-debugging-en-github-actions","title":"5) Patr\u00f3n general de debugging en GitHub Actions","text":"<ol> <li>Reproduce localmente el comando exacto que falla (<code>pytest</code>, <code>docker build</code>, etc.).</li> <li>Verifica <code>on:</code> y <code>matrix</code> para asegurarte de que el job se ejecuta en los contextos esperados.</li> <li>Usa <code>working-directory</code> y rutas relativas coherentes con la estructura del repo.</li> <li>Encadena bien los jobs usando <code>needs</code> para que la l\u00f3gica del pipeline sea clara.</li> </ol> <p>Con este enfoque, CI/CD pasa de ser una caja negra \u201cque a veces falla\u201d a un pipeline confiable que te protege al hacer cambios en el portafolio.</p> <p></p>"},{"location":"docs/12_CI_CD/#ejercicio-crear-tu-propio-workflow","title":"\u2705 Ejercicio: Crear Tu Propio Workflow","text":""},{"location":"docs/12_CI_CD/#paso-1-workflow-minimo","title":"Paso 1: Workflow M\u00ednimo","text":"<p>Crea <code>.github/workflows/ci.yml</code>:</p> <pre><code>name: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n      - run: pip install pytest\n      - run: pytest\n</code></pre>"},{"location":"docs/12_CI_CD/#paso-2-anadir-coverage","title":"Paso 2: A\u00f1adir Coverage","text":"<pre><code>      - run: pip install pytest pytest-cov\n      - run: pytest --cov=src/ --cov-fail-under=80\n</code></pre>"},{"location":"docs/12_CI_CD/#paso-3-anadir-matrix","title":"Paso 3: A\u00f1adir Matrix","text":"<pre><code>    strategy:\n      matrix:\n        python-version: ['3.11', '3.12']\n</code></pre>"},{"location":"docs/12_CI_CD/#paso-4-anadir-security","title":"Paso 4: A\u00f1adir Security","text":"<p>A\u00f1ade un job nuevo con Bandit y Gitleaks.</p> <p></p>"},{"location":"docs/12_CI_CD/#checkpoint","title":"\u2705 Checkpoint","text":"<ul> <li>[ ] Tienes un workflow b\u00e1sico que ejecuta tests</li> <li>[ ] El workflow usa matrix testing (m\u00faltiples versiones Python)</li> <li>[ ] Coverage est\u00e1 enforced con threshold</li> <li>[ ] Tienes al menos un scan de seguridad</li> <li>[ ] Los artifacts se suben correctamente</li> </ul>"},{"location":"docs/12_CI_CD/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>El portafolio tiene un workflow CI/CD real en <code>.github/workflows/ci-mlops.yml</code>:</p>"},{"location":"docs/12_CI_CD/#workflow-real-del-portafolio","title":"Workflow Real del Portafolio","text":"<pre><code># .github/workflows/ci-mlops.yml (extracto)\nname: CI/CD MLOps Portfolio\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        project: [BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence]\n        python-version: ['3.10', '3.11']\n\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: |\n          cd ${{ matrix.project }}\n          pip install -e \".[dev]\"\n\n      - name: Run tests with coverage\n        run: |\n          cd ${{ matrix.project }}\n          pytest tests/ --cov=src/ --cov-fail-under=79\n</code></pre>"},{"location":"docs/12_CI_CD/#features-del-cicd","title":"Features del CI/CD","text":"Feature Implementaci\u00f3n Matrix Testing 3 proyectos \u00d7 2 versiones Python Coverage Gate <code>--cov-fail-under=79</code> Security Scan gitleaks en pre-commit Artifacts Coverage reports"},{"location":"docs/12_CI_CD/#ejercicio-revisa-el-ci-real","title":"\ud83d\udd27 Ejercicio: Revisa el CI Real","text":"<pre><code># 1. Ve el workflow real\ncat .github/workflows/ci-mlops.yml\n\n# 2. Simula localmente con act (opcional)\nact -j test --matrix project:BankChurn-Predictor\n\n# 3. Ve los runs en GitHub\n# https://github.com/DuqueOM/ML-MLOps-Portfolio/actions\n</code></pre>"},{"location":"docs/12_CI_CD/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/12_CI_CD/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>CI vs CD: CI = integrar c\u00f3digo frecuentemente, CD = desplegar autom\u00e1ticamente.</p> </li> <li> <p>GitHub Actions vs Jenkins vs GitLab CI: Trade-offs de cada uno.</p> </li> <li> <p>ML-specific CI: Explica c\u00f3mo CI para ML incluye validaci\u00f3n de datos y modelos.</p> </li> </ol>"},{"location":"docs/12_CI_CD/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Secrets Usa GitHub Secrets, nunca hardcodees Caching Cachea dependencias y datos para velocidad Paralelizaci\u00f3n Matriz de tests para m\u00faltiples versiones Rollback Siempre ten estrategia de rollback"},{"location":"docs/12_CI_CD/#pipeline-cicd-para-ml","title":"Pipeline CI/CD para ML","text":"<pre><code>1. Lint + Format (ruff, black)\n2. Unit Tests (pytest)\n3. Integration Tests\n4. Security Scan (gitleaks, bandit)\n5. Build Docker Image\n6. Model Validation\n7. Deploy to Staging\n8. Smoke Tests\n9. Deploy to Production\n</code></pre>"},{"location":"docs/12_CI_CD/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/12_CI_CD/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 GitHub Actions Tutorial TechWorld Nana 1h YouTube \ud83d\udfe1 CI/CD for ML Made With ML 45 min MadeWithML \ud83d\udfe2 GitHub Actions for Python mCoding 20 min YouTube"},{"location":"docs/12_CI_CD/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 GitHub Actions Documentaci\u00f3n oficial \ud83d\udfe1 Actions Marketplace Acciones reutilizables"},{"location":"docs/12_CI_CD/#decision-tecnica-adr-005-github-actions","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-005 GitHub Actions","text":"<p>Contexto: Necesitamos automatizar testing, linting y deployment.</p> <p>Decisi\u00f3n: Usar GitHub Actions como plataforma CI/CD.</p> <p>Alternativas Consideradas: - Jenkins: M\u00e1s flexible pero requiere infraestructura propia - GitLab CI: Excelente pero vendor lock-in - CircleCI: Potente pero con l\u00edmites en free tier</p> <p>Consecuencias: - \u2705 Integraci\u00f3n nativa con GitHub - \u2705 Free tier generoso para open source - \u2705 Marketplace con acciones reutilizables - \u274c Menos flexible que Jenkins para casos complejos</p>"},{"location":"docs/12_CI_CD/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/12_CI_CD/#ejercicio-121-github-actions-basico","title":"Ejercicio 12.1: GitHub Actions B\u00e1sico","text":"<p>Objetivo: Crear workflow de CI para proyecto ML. Dificultad: \u2b50\u2b50</p> <pre><code># .github/workflows/ci.yml\n# TU TAREA: Completar workflow que:\n# 1. Ejecute en push y PR\n# 2. Instale dependencias\n# 3. Ejecute tests con coverage\n# 4. Falle si coverage &lt; 80%\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>name: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n          cache: 'pip'\n\n      - name: Install dependencies\n        run: |\n          pip install -e \".[dev]\"\n\n      - name: Run linting\n        run: |\n          ruff check .\n          ruff format --check .\n\n      - name: Run tests with coverage\n        run: |\n          pytest tests/ -v \\\n            --cov=src \\\n            --cov-report=xml \\\n            --cov-fail-under=80\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n</code></pre>"},{"location":"docs/12_CI_CD/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n CI Continuous Integration - integrar c\u00f3digo frecuentemente CD Continuous Deployment - desplegar autom\u00e1ticamente Workflow Archivo YAML que define jobs y steps Matrix Ejecutar mismo job con diferentes configuraciones   **Siguiente m\u00f3dulo** \u2192 [13. Docker](13_DOCKER.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/13_DOCKER/","title":"13. Docker Avanzado para ML","text":"<p>## 0.0 Prerrequisitos</p> <ul> <li>Tener Docker instalado y funcionando (<code>docker --version</code>).</li> <li>Poder construir y correr contenedores (<code>docker build</code>, <code>docker run</code>).</li> <li>Conocer la estructura <code>src/</code>, <code>app/</code> y <code>configs/</code> usada en los proyectos del portafolio.</li> </ul> <p></p> <p>## 0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</p> <ul> <li>Antes de empezar: abre Protocolo E y define el output m\u00ednimo (una imagen <code>slim</code> que levanta la API).</li> <li>Durante el debugging: si te atoras &gt;15 min (permisos, build lento, rutas/artefactos), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar si tu Dockerfile es reproducible y seguro.</li> </ul> <p></p> <p>## 0.2 \u2705 Entregables verificables (m\u00ednimo viable)</p> <ul> <li>[ ] Un Dockerfile optimizado (base <code>slim</code>, orden de layers, <code>.dockerignore</code>).</li> <li>[ ] Multi-stage build (builder + runtime) o justificaci\u00f3n si no aplica.</li> <li>[ ] Contenedor corriendo como non-root.</li> <li>[ ] Imagen con tama\u00f1o razonable (objetivo: &lt; 500MB).</li> <li>[ ] <code>docker run</code> levanta el servicio y responde en <code>/health</code>.</li> </ul> <p></p> <p>## 0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</p> <ul> <li>Concepto: im\u00e1genes peque\u00f1as + reproducibles + seguras (no-root) + healthchecks</li> <li>Archivo: <code>Dockerfile</code>, <code>.dockerignore</code>, <code>docker-compose*.yml</code></li> <li>Prueba: <code>docker build -t &lt;img&gt; .</code> y <code>docker run -p 8000:8000 &lt;img&gt;</code></li> </ul> <p>## \ud83c\udfaf Objetivo del M\u00f3dulo</p> <p>Construir im\u00e1genes Docker optimizadas, seguras y peque\u00f1as como las del portafolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  NIVEL 1: Funcional       NIVEL 2: Optimizado      NIVEL 3: Production       \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        \u2551\n\u2551  FROM python:3.11         Multi-stage build        Distroless/Alpine         \u2551\n\u2551  COPY . .                 Slim base                Non-root user             \u2551\n\u2551  pip install              Layer caching            CVE scanning              \u2551\n\u2551                                                                              \u2551\n\u2551  ~1.2GB                   ~400MB                   ~150MB                    \u2551\n\u2551  \u26a0\ufe0f B\u00e1sica                 \u2705 Mejor                  \ud83d\udee1\ufe0f Hardened            \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/13_DOCKER/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>13.1 Dockerfile B\u00e1sico vs Optimizado</li> <li>13.2 Multi-Stage Builds</li> <li>13.3 Mejores Pr\u00e1cticas</li> <li>13.4 Dockerfile Real del Portafolio</li> <li>13.5 Docker Compose para ML</li> <li>13.6 Docker Compose Avanzado para MLOps</li> <li>13.7 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Dockerfile del Portafolio \u2b50 NUEVO</li> <li>13.7.1 El \"Por Qu\u00e9\" Arquitect\u00f3nico</li> <li>13.7.2 Anatom\u00eda L\u00ednea por L\u00ednea</li> <li>13.7.3 Laboratorio de Replicaci\u00f3n</li> <li>13.7.4 Troubleshooting Preventivo</li> <li>13.7.5 Checklist de Replicaci\u00f3n</li> <li>13.7.6 Anatom\u00eda del .dockerignore</li> <li>13.7.7 Conexi\u00f3n Docker \u2192 Kubernetes</li> <li>13.7.8 M\u00e9tricas de \u00c9xito</li> <li>Errores habituales</li> <li>\u2705 Checkpoint</li> <li>\u2705 Ejercicio</li> </ul>"},{"location":"docs/13_DOCKER/#mapa-mental-de-conceptos-docker-para-ml","title":"\ud83e\udde0 Mapa Mental de Conceptos: Docker para ML","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551      DOCKER PROFESIONAL PARA ML      \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   DOCKERFILE     \u2502              \u2502  OPTIMIZACI\u00d3N    \u2502              \u2502   SEGURIDAD      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 FROM (base image)              \u251c\u2500 Multi-stage build            \u251c\u2500 Non-root user\n\u251c\u2500 COPY (archivos)                \u251c\u2500 Layer caching                \u251c\u2500 .dockerignore\n\u251c\u2500 RUN (comandos)                 \u251c\u2500 Slim/Alpine base             \u251c\u2500 CVE scanning\n\u251c\u2500 CMD (entrypoint)               \u251c\u2500 .dockerignore                \u2514\u2500 Secrets mgmt\n\u2514\u2500 EXPOSE (puertos)               \u2514\u2500 Reduce tama\u00f1o\n</code></pre> <p>T\u00e9rminos clave:</p> T\u00e9rmino Significado Ejemplo Multi-stage Compilar en una imagen, correr en otra Builder + Runtime Layer Cada instrucci\u00f3n crea una capa Cacheable Slim Imagen base reducida <code>python:3.11-slim</code> .dockerignore Archivos a no copiar <code>.git</code>, <code>data/</code>, <code>__pycache__</code>"},{"location":"docs/13_DOCKER/#ejercicio-puente-dockerfile-minimo","title":"\ud83d\udcbb Ejercicio Puente: Dockerfile M\u00ednimo","text":"<p>TU TAREA: Crea un Dockerfile b\u00e1sico para una API FastAPI <pre><code>FROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\nCOPY src/ ./src/\nCOPY app/ ./app/\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\"]\n</code></pre></p>"},{"location":"docs/13_DOCKER/#ejercicio-puente-containerizacion","title":"\ud83d\udcbb Ejercicio Puente: Containerizaci\u00f3n","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/13_DOCKER/#practica-del-portafolio-docker-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Docker en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Containerizaci\u00f3n\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/13_DOCKER/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Docker?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Containerizaci\u00f3n, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/13_DOCKER/#131-dockerfile-basico-vs-optimizado","title":"13.1 Dockerfile B\u00e1sico vs Optimizado","text":""},{"location":"docs/13_DOCKER/#nivel-1-basico-no-usar-en-produccion","title":"\u274c Nivel 1: B\u00e1sico (No usar en producci\u00f3n)","text":"<pre><code># Dockerfile MALO - Solo para demos r\u00e1pidas\nFROM python:3.11\n\nWORKDIR /app\nCOPY . .\n\nRUN pip install -r requirements.txt\n\nCMD [\"python\", \"main.py\"]\n\n# Problemas:\n# - Imagen de ~1.2GB\n# - Incluye herramientas de desarrollo innecesarias\n# - Cache de pip no aprovechado\n# - Corre como root (inseguro)\n# - Copia archivos innecesarios (.git, tests, etc.)\n</code></pre>"},{"location":"docs/13_DOCKER/#nivel-2-optimizado","title":"\u2705 Nivel 2: Optimizado","text":"<pre><code># Dockerfile MEJOR - Para staging/desarrollo\n\n# 1. Usar slim para reducir tama\u00f1o\nFROM python:3.11-slim\n\n# 2. Establecer directorio de trabajo\nWORKDIR /app\n\n# 3. Copiar SOLO requirements primero (aprovecha cache)\nCOPY requirements.txt .\n\n# 4. Instalar dependencias (capa cacheada si requirements no cambia)\nRUN pip install --no-cache-dir -r requirements.txt\n\n# 5. Copiar c\u00f3digo fuente\nCOPY src/ ./src/\nCOPY app/ ./app/\nCOPY configs/ ./configs/\n\n# 6. Usuario no-root\nRUN useradd -m appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# 7. Puerto y comando\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n\n# Mejoras:\n# - ~400MB (slim base)\n# - Cache de layers optimizado\n# - No corre como root\n# - Solo archivos necesarios\n</code></pre>"},{"location":"docs/13_DOCKER/#132-multi-stage-builds","title":"13.2 Multi-Stage Builds","text":""},{"location":"docs/13_DOCKER/#el-concepto","title":"El Concepto","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         MULTI-STAGE BUILD                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  STAGE 1: Builder                    STAGE 2: Runtime                       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                    \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                       \u2502\n\u2502  \u2022 Imagen completa                   \u2022 Imagen m\u00ednima                        \u2502\n\u2502  \u2022 Compila c\u00f3digo                    \u2022 Solo runtime                         \u2502\n\u2502  \u2022 Instala dependencias              \u2022 Copia solo binarios                  \u2502\n\u2502  \u2022 Genera wheels                     \u2022 Sin compiladores                     \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502  \u2502 python:3.11     \u2502                 \u2502 python:3.11-slim \u2502                   \u2502\n\u2502  \u2502 + gcc, make     \u2502                 \u2502                  \u2502                   \u2502\n\u2502  \u2502 + pip wheel     \u2502   \u2500\u2500COPY\u2500\u2500\u25ba     \u2502 + wheels only    \u2502                   \u2502\n\u2502  \u2502 = 1.2GB         \u2502                 \u2502 = 150-400MB      \u2502                   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502                                                                             \u2502\n\u2502  Se DESCARTA                         Se USA en producci\u00f3n                   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/13_DOCKER/#implementacion","title":"Implementaci\u00f3n","text":"<pre><code># Dockerfile Multi-Stage - Nivel 3 (Producci\u00f3n)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 1: Builder - Compila dependencias\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim AS builder          # AS builder: nombra este stage para referenciarlo despu\u00e9s.\n\nWORKDIR /build                            # Directorio de trabajo para compilaci\u00f3n.\n\n# Instalar herramientas de compilaci\u00f3n (temporales)\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\  # --no-install-recommends: solo deps esenciales.\n    gcc \\                                 # Compilador C (para paquetes con c\u00f3digo nativo).\n    python3-dev \\                         # Headers de Python (para compilar extensiones).\n    &amp;&amp; rm -rf /var/lib/apt/lists/*        # Limpia cache apt \u2192 reduce tama\u00f1o.\n\n# Copiar requirements\nCOPY requirements.txt .                   # Solo requirements para aprovechar cache.\n\n# Crear wheels (binarios precompilados)\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt  # Genera .whl en /wheels.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 2: Runtime - Imagen final m\u00ednima\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim AS runtime          # Nueva imagen limpia, sin gcc ni herramientas de build.\n\nWORKDIR /app                              # Directorio de la aplicaci\u00f3n.\n\n# Copiar SOLO los wheels del builder\nCOPY --from=builder /wheels /wheels       # --from=builder: copia desde el stage anterior.\n\n# Instalar desde wheels (sin compilaci\u00f3n)\nRUN pip install --no-cache-dir /wheels/* &amp;&amp; rm -rf /wheels  # Instala y limpia wheels.\n\n# Copiar c\u00f3digo\nCOPY src/ ./src/                          # C\u00f3digo fuente.\nCOPY app/ ./app/                          # Aplicaci\u00f3n FastAPI/Streamlit.\nCOPY configs/ ./configs/                  # Archivos de configuraci\u00f3n.\n\n# Copiar modelo pre-entrenado si existe\nCOPY artifacts/model.joblib ./artifacts/model.joblib 2&gt;/dev/null || true  # || true: no falla si no existe.\n\n# Crear usuario no-root\nRUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app  # Seguridad: nunca correr como root.\nUSER appuser                              # Cambia a usuario sin privilegios.\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\  # Docker verifica salud autom\u00e1ticamente.\n    CMD curl -f http://localhost:8000/health || exit 1  # Falla si /health no responde 200.\n\n# Exponer puerto\nEXPOSE 8000                               # Documenta el puerto (no lo publica).\n\n# Comando de inicio\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]  # Ejecuta la API.\n</code></pre>"},{"location":"docs/13_DOCKER/#133-mejores-practicas","title":"13.3 Mejores Pr\u00e1cticas","text":""},{"location":"docs/13_DOCKER/#dockerignore","title":".dockerignore","text":"<pre><code># .dockerignore - Excluir archivos innecesarios\n\n# Git\n.git\n.gitignore\n\n# Python\n__pycache__\n*.py[cod]\n*.pyo\n.pytest_cache\n.mypy_cache\n.coverage\nhtmlcov/\n.venv/\nvenv/\n*.egg-info/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n\n# Tests (no necesarios en producci\u00f3n)\ntests/\n*_test.py\ntest_*.py\nconftest.py\n\n# Documentaci\u00f3n\ndocs/\n*.md\n!README.md\n\n# Datos (montar como volumen, no copiar)\ndata/\n*.csv\n*.parquet\n\n# Notebooks\n*.ipynb\nnotebooks/\n\n# Logs y temporales\n*.log\nlogs/\ntmp/\n</code></pre>"},{"location":"docs/13_DOCKER/#layer-caching","title":"Layer Caching","text":"<pre><code># \u274c MALO: Cualquier cambio en c\u00f3digo invalida cache de pip\nCOPY . .\nRUN pip install -r requirements.txt\n\n# \u2705 BUENO: requirements separado para aprovechar cache\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY src/ ./src/  # Cambios aqu\u00ed NO invalidan pip install\n</code></pre>"},{"location":"docs/13_DOCKER/#security-non-root-user","title":"Security: Non-Root User","text":"<pre><code># Crear usuario con UID espec\u00edfico (evita conflictos de permisos)\nRUN useradd -m -u 1000 appuser\n\n# Dar permisos al directorio de trabajo\nRUN chown -R appuser:appuser /app\n\n# Cambiar a usuario no-root ANTES de CMD\nUSER appuser\n\n# Ahora el proceso corre como appuser, no como root\n</code></pre>"},{"location":"docs/13_DOCKER/#134-dockerfile-real-del-portafolio","title":"13.4 Dockerfile Real del Portafolio","text":""},{"location":"docs/13_DOCKER/#bankchurn-predictordockerfile","title":"BankChurn-Predictor/Dockerfile","text":"<pre><code># BankChurn-Predictor Production Dockerfile\n# Multi-stage build optimizado para ML\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Stage 1: Builder\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim AS builder\n\nWORKDIR /build\n\n# Dependencias de sistema para compilaci\u00f3n\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    gcc \\\n    python3-dev \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copiar requirements\nCOPY requirements.txt .\n\n# Crear wheels\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Stage 2: Runtime\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim\n\n# Labels para metadata\nLABEL maintainer=\"duqueom@example.com\"\nLABEL version=\"1.0.0\"\nLABEL description=\"BankChurn Predictor API\"\n\nWORKDIR /app\n\n# Instalar curl para healthcheck\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Instalar dependencias desde wheels\nCOPY --from=builder /wheels /wheels\nRUN pip install --no-cache-dir /wheels/* &amp;&amp; rm -rf /wheels\n\n# Copiar c\u00f3digo fuente\nCOPY src/ ./src/\nCOPY app/ ./app/\nCOPY configs/ ./configs/\n\n# Copiar modelo (si existe)\nCOPY models/ ./models/ 2&gt;/dev/null || mkdir -p ./models\n\n# Crear usuario no-root\nRUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# Variables de entorno\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nENV PORT=8000\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=10s --start-period=45s --retries=3 \\\n    CMD curl -f http://localhost:${PORT}/health || exit 1\n\nEXPOSE ${PORT}\n\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"docs/13_DOCKER/#135-docker-compose-para-ml","title":"13.5 Docker Compose para ML","text":""},{"location":"docs/13_DOCKER/#docker-composedemoyml-portafolio","title":"docker-compose.demo.yml (Portafolio)","text":"<pre><code># Docker Compose para demo completa del portafolio\nversion: \"3.8\"\n\nservices:\n  # MLflow Server (central)\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.2\n    container_name: mlflow-server\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - mlflow-data:/mlflow\n    command: &gt;\n      mlflow server\n      --backend-store-uri sqlite:///mlflow/mlflow.db\n      --default-artifact-root /mlflow/artifacts\n      --host 0.0.0.0\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:5000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    networks:\n      - ml-network\n\n  # BankChurn API\n  bankchurn:\n    build:\n      context: ./BankChurn-Predictor\n      dockerfile: Dockerfile\n    container_name: bankchurn-api\n    ports:\n      - \"8001:8000\"\n    volumes:\n      - ./BankChurn-Predictor/models:/app/models:ro\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000\n    depends_on:\n      mlflow:\n        condition: service_healthy\n    networks:\n      - ml-network\n\n  # CarVision API\n  carvision:\n    build:\n      context: ./CarVision-Market-Intelligence\n      dockerfile: Dockerfile\n    container_name: carvision-api\n    ports:\n      - \"8002:8000\"\n    volumes:\n      - ./CarVision-Market-Intelligence/artifacts:/app/artifacts:ro\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000\n    depends_on:\n      mlflow:\n        condition: service_healthy\n    networks:\n      - ml-network\n\n  # TelecomAI API\n  telecom:\n    build:\n      context: ./TelecomAI-Customer-Intelligence\n      dockerfile: Dockerfile\n    container_name: telecom-api\n    ports:\n      - \"8003:8000\"\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000\n    depends_on:\n      mlflow:\n        condition: service_healthy\n    networks:\n      - ml-network\n\nvolumes:\n  mlflow-data:\n\nnetworks:\n  ml-network:\n    driver: bridge\n</code></pre>"},{"location":"docs/13_DOCKER/#comandos-utiles","title":"Comandos \u00datiles","text":"<pre><code># Construir todas las im\u00e1genes\ndocker compose -f docker-compose.demo.yml build\n\n# Iniciar todos los servicios\ndocker compose -f docker-compose.demo.yml up -d\n\n# Ver logs\ndocker compose -f docker-compose.demo.yml logs -f bankchurn\n\n# Parar todo\ndocker compose -f docker-compose.demo.yml down\n\n# Limpiar vol\u00famenes tambi\u00e9n\ndocker compose -f docker-compose.demo.yml down -v\n</code></pre>"},{"location":"docs/13_DOCKER/#136-docker-compose-avanzado-para-mlops-nuevo","title":"13.6 Docker Compose Avanzado para MLOps \u2b50 NUEVO","text":"<p>El portafolio usa patrones avanzados de Docker Compose que debes conocer para orquestar stacks ML complejos.</p>"},{"location":"docs/13_DOCKER/#1361-profiles-servicios-opcionales","title":"13.6.1 Profiles: Servicios Opcionales","text":"<p>Los profiles permiten tener servicios que solo se inician cuando los necesitas (ej: monitoreo):</p> <pre><code># docker-compose.demo.yml del portafolio (extracto)\nservices:\n  # Servicios principales (sin profile = siempre se inician)\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.2\n    ports:\n      - \"5000:5000\"\n    # ...\n\n  bankchurn:\n    build: ./BankChurn-Predictor\n    ports:\n      - \"8001:8000\"\n    # ...\n\n  # Servicios de monitoreo (profile = monitoring)\n  prometheus:\n    image: prom/prometheus:v2.48.0\n    container_name: prometheus\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./infra/prometheus-config.yaml:/etc/prometheus/prometheus.yml:ro\n      - prometheus-data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n    networks:\n      - ml-network\n    profiles:\n      - monitoring  # \u2190 Solo se inicia con --profile monitoring\n\n  grafana:\n    image: grafana/grafana:10.2.2\n    container_name: grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    profiles:\n      - monitoring  # \u2190 Solo se inicia con --profile monitoring\n</code></pre> <p>Uso de profiles:</p> <pre><code># Solo servicios principales (sin monitoreo)\ndocker compose -f docker-compose.demo.yml up -d\n\n# Con monitoreo (Prometheus + Grafana)\ndocker compose -f docker-compose.demo.yml --profile monitoring up -d\n\n# Ver qu\u00e9 est\u00e1 corriendo\ndocker compose -f docker-compose.demo.yml ps\n</code></pre>"},{"location":"docs/13_DOCKER/#1362-healthchecks-avanzados-y-dependencies","title":"13.6.2 Healthchecks Avanzados y Dependencies","text":"<pre><code>services:\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.2\n    healthcheck:\n      test: [\"CMD\", \"python\", \"-c\", \"import urllib.request; urllib.request.urlopen('http://localhost:5000/health')\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 30s  # \u2190 Da tiempo para que el servicio arranque\n\n  bankchurn:\n    build: ./BankChurn-Predictor\n    depends_on:\n      mlflow:\n        condition: service_healthy  # \u2190 Espera a que MLflow est\u00e9 healthy\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 45s  # \u2190 El modelo tarda en cargar\n\n  carvision-dashboard:\n    image: ml-portfolio-carvision:latest\n    command: [\"streamlit\", \"run\", \"app/streamlit_app.py\", \"--server.port\", \"8501\"]\n    depends_on:\n      - carvision  # \u2190 Espera a que la API est\u00e9 disponible (no healthy)\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8501/_stcore/health\"]\n      interval: 30s\n      timeout: 10s\n      start_period: 60s  # \u2190 Streamlit tarda m\u00e1s\n</code></pre>"},{"location":"docs/13_DOCKER/#1363-networking-para-microservicios-ml","title":"13.6.3 Networking para Microservicios ML","text":"<pre><code>services:\n  # Servicios internos se comunican por nombre\n  bankchurn:\n    networks:\n      - ml-network\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000  # \u2190 Usa nombre del servicio\n\n  carvision:\n    networks:\n      - ml-network\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000\n\nnetworks:\n  ml-network:\n    driver: bridge\n    name: ml-mlops-network  # \u2190 Nombre expl\u00edcito para debugging\n</code></pre> <p>Debugging de networking:</p> <pre><code># Ver la red y sus contenedores\ndocker network inspect ml-mlops-network\n\n# Probar conectividad desde un contenedor\ndocker exec -it bankchurn-api curl http://mlflow:5000/health\n\n# Ver logs de un servicio espec\u00edfico\ndocker compose logs -f bankchurn\n</code></pre>"},{"location":"docs/13_DOCKER/#1364-volumes-para-persistencia-y-desarrollo","title":"13.6.4 Volumes para Persistencia y Desarrollo","text":"<pre><code>services:\n  mlflow:\n    volumes:\n      # Named volume para persistencia (sobrevive a `down`)\n      - mlflow-artifacts:/mlflow\n      # Bind mount para acceder a runs locales\n      - ./mlruns:/mlruns\n\n  bankchurn:\n    volumes:\n      # Read-only para datos (evita modificaciones accidentales)\n      - ./BankChurn-Predictor/data:/app/data:ro\n      # Read-only para modelos\n      - ./BankChurn-Predictor/models:/app/models:ro\n\n  # Para DESARROLLO: hot-reload del c\u00f3digo\n  bankchurn-dev:\n    build: ./BankChurn-Predictor\n    volumes:\n      # Monta c\u00f3digo fuente para hot-reload\n      - ./BankChurn-Predictor/src:/app/src\n      - ./BankChurn-Predictor/app:/app/app\n    command: [\"uvicorn\", \"app.fastapi_app:app\", \"--reload\", \"--host\", \"0.0.0.0\"]\n    profiles:\n      - dev\n\nvolumes:\n  mlflow-artifacts:\n    driver: local\n  prometheus-data:\n    driver: local\n  grafana-data:\n    driver: local\n</code></pre>"},{"location":"docs/13_DOCKER/#1365-variables-de-entorno-y-secrets","title":"13.6.5 Variables de Entorno y Secrets","text":"<pre><code>services:\n  bankchurn:\n    environment:\n      # Variables inline\n      - PYTHONUNBUFFERED=1\n      - LOG_LEVEL=INFO\n      # Variables desde archivo .env\n      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI:-http://mlflow:5000}\n    env_file:\n      - .env  # \u2190 Carga todas las variables de .env\n\n# .env (NO commitear a Git)\n# MLFLOW_TRACKING_URI=http://mlflow:5000\n# DB_PASSWORD=supersecret\n</code></pre>"},{"location":"docs/13_DOCKER/#1366-el-stack-completo-del-portafolio","title":"13.6.6 El Stack Completo del Portafolio","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    STACK DOCKER COMPOSE DEL PORTAFOLIO                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  SERVICIOS PRINCIPALES (siempre activos):                                       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                      \u2502\n\u2502                                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502  \u2502 MLflow       \u2502     \u2502 BankChurn    \u2502     \u2502 CarVision    \u2502                     \u2502\n\u2502  \u2502 :5000        \u2502\u25c4\u2500\u2500\u2500\u2500\u2502 API :8001    \u2502     \u2502 API :8002    \u2502                     \u2502\n\u2502  \u2502              \u2502     \u2502              \u2502     \u2502              \u2502                     \u2502\n\u2502  \u2502 Tracking +   \u2502     \u2502 /predict     \u2502     \u2502 /predict     \u2502                     \u2502\n\u2502  \u2502 Artifacts    \u2502\u25c4\u2500\u2500\u2500\u2500\u2524 /health      \u2502     \u2502 /health      \u2502                     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502         \u25b2                                         \u2502                             \u2502\n\u2502         \u2502                                         \u25bc                             \u2502\n\u2502         \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502         \u2502             \u2502 TelecomAI    \u2502     \u2502 CarVision    \u2502                     \u2502\n\u2502         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 API :8003    \u2502     \u2502 Dashboard    \u2502                     \u2502\n\u2502                       \u2502              \u2502     \u2502 :8501        \u2502                     \u2502\n\u2502                       \u2502 /predict     \u2502     \u2502              \u2502                     \u2502\n\u2502                       \u2502 /health      \u2502     \u2502 Streamlit    \u2502                     \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                                                                                 \u2502\n\u2502  SERVICIOS DE MONITOREO (--profile monitoring):                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                 \u2502\n\u2502                                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                          \u2502\n\u2502  \u2502 Prometheus   \u2502\u2500\u2500\u2500\u2500\u25ba\u2502 Grafana      \u2502                                          \u2502\n\u2502  \u2502 :9090        \u2502     \u2502 :3000        \u2502                                          \u2502\n\u2502  \u2502              \u2502     \u2502              \u2502                                          \u2502\n\u2502  \u2502 Scrape       \u2502     \u2502 Dashboards   \u2502                                          \u2502\n\u2502  \u2502 /metrics     \u2502     \u2502 + Alertas    \u2502                                          \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                          \u2502\n\u2502                                                                                 \u2502\n\u2502  RED: ml-mlops-network (bridge)                                                 \u2502\n\u2502  VOLUMES: mlflow-artifacts, prometheus-data, grafana-data                       \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/13_DOCKER/#ejercicio-crear-tu-stack-docker-compose","title":"\ud83d\udd27 Ejercicio: Crear Tu Stack Docker Compose","text":"<pre><code># 1. Crear estructura b\u00e1sica\nmkdir -p my-ml-stack/{api,data,models}\n\n# 2. Crear docker-compose.yml\ncat &gt; my-ml-stack/docker-compose.yml &lt;&lt; 'EOF'\nservices:\n  api:\n    build: ./api\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./models:/app/models:ro\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      start_period: 30s\n    environment:\n      - MODEL_PATH=/app/models/model.joblib\n\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.2\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - mlflow-data:/mlflow\n    command: mlflow server --host 0.0.0.0 --port 5000\n\nvolumes:\n  mlflow-data:\nEOF\n\n# 3. Probar el stack\ndocker compose up -d\ndocker compose ps\ndocker compose logs -f api\n</code></pre>"},{"location":"docs/13_DOCKER/#137-ingenieria-inversa-pedagogica-dockerfile-del-portafolio","title":"13.7 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Dockerfile del Portafolio","text":"<p>Objetivo: Entender EXACTAMENTE por qu\u00e9 cada l\u00ednea existe en el Dockerfile real de <code>BankChurn-Predictor/Dockerfile</code> del portafolio.</p> <p>Esta secci\u00f3n aplica el m\u00e9todo de \"Shadow Coder Senior\": no solo vemos la herramienta, sino las decisiones arquitect\u00f3nicas tomadas en producci\u00f3n.</p>"},{"location":"docs/13_DOCKER/#1371-el-por-que-arquitectonico","title":"13.7.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>Antes de escribir una sola l\u00ednea de Docker, preg\u00fantate: \u00bfqu\u00e9 problema estoy resolviendo?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: Im\u00e1genes de 1.5GB que tardan 10min en desplegar                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: Multi-stage build con python:3.11-slim                               \u2502\n\u2502  RESULTADO: Imagen final de ~350MB (77% m\u00e1s peque\u00f1a)                            \u2502\n\u2502  REFERENCIA: BankChurn-Predictor/Dockerfile l\u00edneas 1-40                         \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: Contenedores comprometidos = acceso root al host                   \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: Usuario non-root con UID 1000 (appuser)                              \u2502\n\u2502  RESULTADO: Atacante limitado a permisos de usuario sin privilegios             \u2502\n\u2502  REFERENCIA: BankChurn-Predictor/Dockerfile l\u00edneas 55-74                        \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: Orquestadores no saben si la API est\u00e1 lista                        \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: HEALTHCHECK que valida /health cada 30s                              \u2502\n\u2502  RESULTADO: K8s/Docker Compose esperan a que el modelo cargue                   \u2502\n\u2502  REFERENCIA: BankChurn-Predictor/Dockerfile l\u00edneas 79-81                        \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 4: Cache de Docker invalidado en cada cambio de c\u00f3digo                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  DECISI\u00d3N: COPY requirements.txt ANTES de COPY c\u00f3digo fuente                    \u2502\n\u2502  RESULTADO: pip install cacheado si solo cambias c\u00f3digo                         \u2502\n\u2502  REFERENCIA: BankChurn-Predictor/Dockerfile l\u00edneas 25-37                        \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>\ud83e\udd14 Pregunta para reflexionar: \u00bfPor qu\u00e9 NO usamos <code>python:3.11-alpine</code> en el portafolio?</p> \ud83d\udca1 Ver respuesta  Alpine usa `musl` en lugar de `glibc`. Muchas librer\u00edas de ML (NumPy, pandas, scikit-learn) tienen binarios precompilados para `glibc` pero NO para `musl`. Esto significa: - Compilaci\u00f3n desde source \u2192 builds de 20+ minutos - Posibles errores de compatibilidad con extensiones C - `slim` es solo ~50MB m\u00e1s grande pero 100% compatible  **Decisi\u00f3n del portafolio**: Preferimos `slim` por compatibilidad garantizada."},{"location":"docs/13_DOCKER/#1372-anatomia-linea-por-linea-bankchurn-predictordockerfile","title":"13.7.2 \ud83d\udd0d Anatom\u00eda L\u00ednea por L\u00ednea: <code>BankChurn-Predictor/Dockerfile</code>","text":"<p>A continuaci\u00f3n, el Dockerfile REAL del portafolio con explicaci\u00f3n de CADA l\u00ednea cr\u00edtica y qu\u00e9 pasa si la omites.</p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 1: BUILDER - Compila dependencias en entorno temporal\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# L\u00ednea 1-3: Imagen base para compilaci\u00f3n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FROM python:3.11-slim AS builder\n#   \u251c\u2500 python:3.11-slim  \u2192 Imagen Debian m\u00ednima (~150MB vs ~1GB de python:3.11)\n#   \u251c\u2500 AS builder        \u2192 Nombra este stage para referenciarlo despu\u00e9s\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin AS? \u2192 No podr\u00edas hacer COPY --from=builder m\u00e1s adelante\nFROM python:3.11-slim AS builder\n\n# L\u00edneas 5-8: Metadatos de la imagen (LABEL)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# LABEL maintainer=\"...\"\n#   \u251c\u2500 Documenta qui\u00e9n mantiene la imagen\n#   \u251c\u2500 Visible con: docker inspect &lt;imagen&gt;\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Funciona, pero pierdes trazabilidad en producci\u00f3n\nLABEL maintainer=\"Daniel Duque &lt;daniel.duque@example.com&gt;\"\nLABEL version=\"1.0.0\"\nLABEL description=\"BankChurn Predictor - Sistema de predicci\u00f3n de abandono bancario\"\n\n# L\u00edneas 10-14: Variables de entorno de build\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# ENV PYTHONUNBUFFERED=1\n#   \u251c\u2500 PYTHONUNBUFFERED=1  \u2192 Logs se muestran inmediatamente (sin buffering)\n#   \u251c\u2500 PYTHONDONTWRITEBYTECODE=1 \u2192 No genera __pycache__/*.pyc (imagen m\u00e1s limpia)\n#   \u251c\u2500 PIP_NO_CACHE_DIR=1  \u2192 pip no guarda cache (reduce tama\u00f1o de imagen)\n#   \u2514\u2500 PIP_DISABLE_PIP_VERSION_CHECK=1 \u2192 No verifica actualizaciones (build m\u00e1s r\u00e1pido)\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nENV PIP_NO_CACHE_DIR=1\nENV PIP_DISABLE_PIP_VERSION_CHECK=1\n\n# L\u00ednea 16: Directorio de trabajo para compilaci\u00f3n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# WORKDIR /build\n#   \u251c\u2500 Crea /build si no existe y lo establece como CWD\n#   \u251c\u2500 Separado de /app para claridad (build vs runtime)\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Archivos van a / (ra\u00edz), muy desordenado\nWORKDIR /build\n\n# L\u00edneas 18-23: Instalar dependencias de compilaci\u00f3n (TEMPORALES)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN apt-get update &amp;&amp; apt-get install -y ...\n#   \u251c\u2500 gcc, g++, build-essential \u2192 Compiladores para paquetes con c\u00f3digo C/C++\n#   \u251c\u2500 --no-install-recommends   \u2192 Solo deps esenciales (reduce 200MB+)\n#   \u251c\u2500 rm -rf /var/lib/apt/lists/* \u2192 Elimina cache de apt (reduce ~30MB)\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin gcc? \u2192 Paquetes como numpy, pandas fallan al instalar\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    gcc \\\n    g++ \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# L\u00edneas 25-26: Copiar requirements (ANTES del c\u00f3digo)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# COPY requirements.txt requirements.in* ./\n#   \u251c\u2500 requirements.txt  \u2192 Archivo principal de dependencias\n#   \u251c\u2500 requirements.in*  \u2192 Asterisco = copia si existe, no falla si no\n#   \u251c\u2500 Orden cr\u00edtico: requirements ANTES de c\u00f3digo fuente\n#   \u2514\u2500 \u00bfPor qu\u00e9? \u2192 Si solo cambias c\u00f3digo, esta capa est\u00e1 cacheada \u2192 build 10x m\u00e1s r\u00e1pido\nCOPY requirements.txt requirements.in* ./\n\n# L\u00edneas 28-37: Crear virtualenv e instalar dependencias\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN python -m venv /opt/venv &amp;&amp; ...\n#   \u251c\u2500 /opt/venv \u2192 Virtualenv aislado en ubicaci\u00f3n est\u00e1ndar\n#   \u251c\u2500 . /opt/venv/bin/activate \u2192 Activa el venv para pip install\n#   \u251c\u2500 sed ... requirements_clean.txt \u2192 Limpia hashes y l\u00edneas vac\u00edas\n#   \u251c\u2500 pip install --no-cache-dir \u2192 Instala sin guardar cache\n#   \u2514\u2500 \u00bfPor qu\u00e9 virtualenv? \u2192 F\u00e1cil de copiar a runtime stage con COPY --from\nRUN python -m venv /opt/venv &amp;&amp; \\\n    . /opt/venv/bin/activate &amp;&amp; \\\n    pip install --upgrade pip setuptools wheel &amp;&amp; \\\n    if [ -f requirements.in ]; then \\\n        sed -e '/--hash=/d' -e 's/ \\\\$//' -e '/^[[:space:]]*#/d' -e '/^[[:space:]]*$/d' requirements.in &gt; requirements_clean.txt; \\\n    else \\\n        sed -e '/--hash=/d' -e 's/ \\\\$//' -e '/^[[:space:]]*#/d' -e '/^[[:space:]]*$/d' requirements.txt &gt; requirements_clean.txt; \\\n    fi &amp;&amp; \\\n    pip install --no-cache-dir -r requirements_clean.txt\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 2: RUNTIME - Imagen final ligera sin compiladores\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# L\u00ednea 40: Nueva imagen limpia para runtime\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# FROM python:3.11-slim AS runtime\n#   \u251c\u2500 Nueva imagen desde cero (SIN gcc, g++, build-essential)\n#   \u251c\u2500 Solo contiene lo que expl\u00edcitamente copiamos\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin multi-stage? \u2192 Imagen final de 1.2GB con compiladores innecesarios\nFROM python:3.11-slim AS runtime\n\n# L\u00edneas 42-46: Variables de entorno de runtime\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# ENV PYTHONPATH=/app\n#   \u251c\u2500 PYTHONPATH=/app \u2192 Python puede importar desde /app (import src.bankchurn)\n#   \u251c\u2500 PATH=\"/opt/venv/bin:$PATH\" \u2192 Comandos del venv disponibles sin activar\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin PYTHONPATH? \u2192 ImportError: No module named 'src'\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONPATH=/app\nENV PATH=\"/opt/venv/bin:$PATH\"\n\n# L\u00edneas 48-53: Dependencias m\u00ednimas de runtime\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends curl ...\n#   \u251c\u2500 curl \u2192 Necesario para HEALTHCHECK (CMD curl -f http://...)\n#   \u251c\u2500 ca-certificates \u2192 Para conexiones HTTPS (MLflow, APIs externas)\n#   \u251c\u2500 apt-get clean \u2192 Limpia cache adicional\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin curl? \u2192 HEALTHCHECK falla \u2192 contenedor marcado \"unhealthy\"\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    curl \\\n    ca-certificates \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; apt-get clean\n\n# L\u00edneas 55-57: SEGURIDAD - Crear usuario non-root\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN groupadd -r appuser --gid=1000 &amp;&amp; useradd ...\n#   \u251c\u2500 groupadd -r \u2192 Crea grupo \"system\" (sin home dir por defecto)\n#   \u251c\u2500 --gid=1000 \u2192 GID espec\u00edfico para consistencia con vol\u00famenes del host\n#   \u251c\u2500 useradd -r -g appuser \u2192 Usuario del grupo appuser\n#   \u251c\u2500 --uid=1000 \u2192 UID espec\u00edfico (match t\u00edpico con usuario host)\n#   \u251c\u2500 --home-dir=/app \u2192 Home directory del usuario\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Contenedor corre como root \u2192 vulnerabilidad cr\u00edtica\nRUN groupadd -r appuser --gid=1000 &amp;&amp; \\\n    useradd -r -g appuser --uid=1000 --home-dir=/app appuser\n\n# L\u00ednea 59: Directorio de trabajo de la aplicaci\u00f3n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nWORKDIR /app\n\n# L\u00ednea 62: COPIAR virtualenv desde builder\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# COPY --from=builder --chown=appuser:appuser /opt/venv /opt/venv\n#   \u251c\u2500 --from=builder \u2192 Copia desde el stage anterior (no de contexto local)\n#   \u251c\u2500 --chown=appuser:appuser \u2192 Asigna propiedad al usuario non-root\n#   \u251c\u2500 /opt/venv \u2192 Todo el virtualenv con paquetes instalados\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin --chown? \u2192 appuser no puede leer paquetes \u2192 PermissionError\nCOPY --from=builder --chown=appuser:appuser /opt/venv /opt/venv\n\n# L\u00ednea 64: Instalar uvicorn (servidor ASGI)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN . /opt/venv/bin/activate &amp;&amp; pip install \"uvicorn&gt;=0.18.0\"\n#   \u251c\u2500 uvicorn \u2192 Servidor ASGI de alta performance para FastAPI\n#   \u251c\u2500 &gt;=0.18.0 \u2192 Versi\u00f3n m\u00ednima con features necesarios\n#   \u2514\u2500 \u00bfPor qu\u00e9 aqu\u00ed y no en requirements? \u2192 Separar deps de app vs runtime\nRUN . /opt/venv/bin/activate &amp;&amp; pip install --no-cache-dir \"uvicorn&gt;=0.18.0\"\n\n# L\u00ednea 67: Copiar c\u00f3digo fuente completo\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# COPY --chown=appuser:appuser . .\n#   \u251c\u2500 Copia TODO el contexto (respetando .dockerignore)\n#   \u251c\u2500 --chown \u2192 appuser es due\u00f1o de todos los archivos\n#   \u251c\u2500 Esta l\u00ednea va AL FINAL \u2192 cambios de c\u00f3digo no invalidan cache de pip\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin .dockerignore? \u2192 Copia .git, tests, data (imagen 2x m\u00e1s grande)\nCOPY --chown=appuser:appuser . .\n\n# L\u00edneas 69-71: Crear directorios con permisos correctos\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# RUN mkdir -p logs data/raw data/processed models results ...\n#   \u251c\u2500 mkdir -p \u2192 Crea directorios y padres si no existen\n#   \u251c\u2500 logs, data/*, models, results \u2192 Directorios que la app espera\n#   \u251c\u2500 chown -R \u2192 Asegura que appuser pueda escribir en ellos\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 FileNotFoundError al escribir logs o guardar modelos\nRUN mkdir -p logs data/raw data/processed models results &amp;&amp; \\\n    chown -R appuser:appuser /app\n\n# L\u00ednea 74: CAMBIAR a usuario non-root (CR\u00cdTICO)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# USER appuser\n#   \u251c\u2500 A partir de aqu\u00ed, TODO corre como appuser (no root)\n#   \u251c\u2500 CMD, ENTRYPOINT, docker exec \u2192 todos como appuser\n#   \u251c\u2500 IMPORTANTE: Esta l\u00ednea DESPU\u00c9S de mkdir/chown\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Contenedor corre como root \u2192 CIS Benchmark falla\nUSER appuser\n\n# L\u00ednea 77: Exponer puerto (documentaci\u00f3n)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# EXPOSE 8000\n#   \u251c\u2500 Documenta que la app escucha en puerto 8000\n#   \u251c\u2500 NO publica el puerto (eso es -p en docker run)\n#   \u251c\u2500 \u00datil para: docker inspect, docker-compose, K8s\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Funciona, pero pierdes documentaci\u00f3n\nEXPOSE 8000\n\n# L\u00edneas 79-81: HEALTHCHECK para orquestadores\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# HEALTHCHECK --interval=30s --timeout=10s --start-period=15s --retries=3 ...\n#   \u251c\u2500 --interval=30s \u2192 Cada 30s ejecuta el check\n#   \u251c\u2500 --timeout=10s \u2192 Si no responde en 10s, falla\n#   \u251c\u2500 --start-period=15s \u2192 Espera 15s antes del primer check (carga de modelo)\n#   \u251c\u2500 --retries=3 \u2192 3 fallos consecutivos \u2192 \"unhealthy\"\n#   \u251c\u2500 CMD curl -f http://localhost:8000/health \u2192 Verifica endpoint /health\n#   \u251c\u2500 -f \u2192 curl falla con exit 22 si HTTP != 2xx/3xx\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin HEALTHCHECK? \u2192 K8s/Compose no saben si la API est\u00e1 lista\nHEALTHCHECK --interval=30s --timeout=10s --start-period=15s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# L\u00edneas 83-84: Comando por defecto (API)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# CMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--workers\", \"1\"]\n#   \u251c\u2500 uvicorn \u2192 Servidor ASGI\n#   \u251c\u2500 app.fastapi_app:app \u2192 Ruta al objeto FastAPI (app/fastapi_app.py)\n#   \u251c\u2500 --host 0.0.0.0 \u2192 Escucha en todas las interfaces (necesario en contenedor)\n#   \u251c\u2500 --port 8000 \u2192 Puerto que matchea con EXPOSE\n#   \u251c\u2500 --workers 1 \u2192 Un solo worker (escalar con r\u00e9plicas, no workers)\n#   \u2514\u2500 \u00bfQu\u00e9 pasa con --host 127.0.0.1? \u2192 Solo accesible desde dentro del contenedor\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--workers\", \"1\"]\n</code></pre>"},{"location":"docs/13_DOCKER/#1373-laboratorio-de-replicacion-escribe-el-dockerfile-tu-mismo","title":"13.7.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n: Escribe el Dockerfile T\u00fa Mismo","text":"<p>Instrucciones: NO copies y pegues. Escribe cada secci\u00f3n a mano para interiorizar los conceptos.</p>"},{"location":"docs/13_DOCKER/#paso-1-estructura-base-del-builder-stage","title":"Paso 1: Estructura Base del Builder Stage","text":"<p>Abre tu editor y crea un archivo <code>Dockerfile</code>:</p> <pre><code># Paso 1.1: Crear el archivo vac\u00edo\ntouch BankChurn-Predictor/Dockerfile\n\n# Paso 1.2: Abrirlo en tu editor preferido\ncode BankChurn-Predictor/Dockerfile  # o vim, nano, etc.\n</code></pre> <p>Escribe el Stage 1 (Builder):</p> <pre><code># Paso 1.3: Escribe el encabezado y la imagen base\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfPor qu\u00e9 usamos python:3.11-slim y no python:3.11?\n# Respuesta: ______________________ (escr\u00edbela antes de continuar)\n\nFROM python:3.11-slim AS builder\n# \u2191 AS builder: nombra este stage para poder hacer COPY --from=builder despu\u00e9s\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-2-variables-de-entorno-y-dependencias-de-build","title":"Paso 2: Variables de Entorno y Dependencias de Build","text":"<pre><code># Paso 2.1: A\u00f1ade las variables de entorno\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfQu\u00e9 hace PYTHONUNBUFFERED=1?\n# Respuesta: ______________________ (logs sin buffering = visibles inmediatamente)\n\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nENV PIP_NO_CACHE_DIR=1\n\n# Paso 2.2: Establece el directorio de trabajo\nWORKDIR /build\n\n# Paso 2.3: Instala compiladores (SOLO para build)\n# Pregunta: \u00bfPor qu\u00e9 hacemos rm -rf /var/lib/apt/lists/*?\n# Respuesta: ______________________ (elimina cache de apt = imagen m\u00e1s peque\u00f1a)\n\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    gcc \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-3-copiar-e-instalar-dependencias","title":"Paso 3: Copiar e Instalar Dependencias","text":"<pre><code># Paso 3.1: Copia SOLO requirements (aprovecha cache de Docker)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfPor qu\u00e9 copiamos requirements.txt ANTES del c\u00f3digo fuente?\n# Respuesta: ______________________ (si solo cambias c\u00f3digo, pip install est\u00e1 cacheado)\n\nCOPY requirements.txt .\n\n# Paso 3.2: Crea virtualenv e instala dependencias\nRUN python -m venv /opt/venv &amp;&amp; \\\n    . /opt/venv/bin/activate &amp;&amp; \\\n    pip install --upgrade pip &amp;&amp; \\\n    pip install --no-cache-dir -r requirements.txt\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-4-stage-2-runtime","title":"Paso 4: Stage 2 - Runtime","text":"<pre><code># Paso 4.1: Inicia una imagen NUEVA y limpia\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Nota: Esta imagen NO tiene gcc, build-essential, ni nada del stage anterior\n\nFROM python:3.11-slim AS runtime\n\n# Paso 4.2: Variables de entorno de runtime\nENV PYTHONUNBUFFERED=1\nENV PYTHONPATH=/app\nENV PATH=\"/opt/venv/bin:$PATH\"\n# \u2191 PATH: permite usar python, pip, uvicorn del venv sin activarlo expl\u00edcitamente\n\n# Paso 4.3: Dependencias m\u00ednimas de runtime\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n# \u2191 curl: necesario para HEALTHCHECK\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-5-seguridad-usuario-non-root","title":"Paso 5: Seguridad - Usuario Non-Root","text":"<pre><code># Paso 5.1: Crear usuario y grupo sin privilegios\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfPor qu\u00e9 usamos UID 1000?\n# Respuesta: ______________________ (match t\u00edpico con usuarios del host = menos problemas de permisos)\n\nRUN groupadd -r appuser --gid=1000 &amp;&amp; \\\n    useradd -r -g appuser --uid=1000 --home-dir=/app appuser\n\nWORKDIR /app\n\n# Paso 5.2: Copiar virtualenv DESDE el builder\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Nota: --chown asigna propiedad a appuser (sin esto, root es el due\u00f1o)\n\nCOPY --from=builder --chown=appuser:appuser /opt/venv /opt/venv\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-6-codigo-fuente-y-directorios","title":"Paso 6: C\u00f3digo Fuente y Directorios","text":"<pre><code># Paso 6.1: Copiar c\u00f3digo fuente\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Nota: Esta l\u00ednea va AL FINAL para maximizar cache\n\nCOPY --chown=appuser:appuser . .\n\n# Paso 6.2: Crear directorios que la aplicaci\u00f3n necesita\nRUN mkdir -p logs models data &amp;&amp; \\\n    chown -R appuser:appuser /app\n\n# Paso 6.3: CAMBIAR a usuario non-root (CR\u00cdTICO)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfPor qu\u00e9 USER va DESPU\u00c9S de mkdir/chown?\n# Respuesta: ______________________ (appuser no tiene permisos para crear dirs)\n\nUSER appuser\n</code></pre>"},{"location":"docs/13_DOCKER/#paso-7-healthcheck-y-comando","title":"Paso 7: Healthcheck y Comando","text":"<pre><code># Paso 7.1: Documentar puerto\nEXPOSE 8000\n\n# Paso 7.2: Configurar healthcheck\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Pregunta: \u00bfQu\u00e9 hace --start-period?\n# Respuesta: ______________________ (tiempo de gracia para que cargue el modelo)\n\nHEALTHCHECK --interval=30s --timeout=10s --start-period=15s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Paso 7.3: Comando de inicio\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"docs/13_DOCKER/#verificacion-del-laboratorio","title":"Verificaci\u00f3n del Laboratorio","text":"<pre><code># Construir la imagen\ndocker build -t bankchurn:lab .\n\n# Verificar tama\u00f1o (objetivo: &lt; 500MB)\ndocker images bankchurn:lab\n\n# Ejecutar y probar\ndocker run -d -p 8000:8000 --name bankchurn-test bankchurn:lab\n\n# Esperar 20 segundos y verificar health\nsleep 20\ndocker inspect --format='{{.State.Health.Status}}' bankchurn-test\n# Esperado: healthy\n\n# Verificar que corre como non-root\ndocker exec bankchurn-test whoami\n# Esperado: appuser\n\n# Cleanup\ndocker stop bankchurn-test &amp;&amp; docker rm bankchurn-test\n</code></pre>"},{"location":"docs/13_DOCKER/#1374-troubleshooting-preventivo-los-5-errores-mas-comunes","title":"13.7.4 \ud83d\udea8 Troubleshooting Preventivo: Los 5 Errores M\u00e1s Comunes","text":"<p>Estos son los errores que encontrar\u00e1s al intentar replicar el Dockerfile del portafolio. L\u00e9elos ANTES de empezar para ahorrar horas de debugging.</p>"},{"location":"docs/13_DOCKER/#error-1-modulenotfounderror-no-module-named-src","title":"Error 1: <code>ModuleNotFoundError: No module named 'src'</code>","text":"<p>Cu\u00e1ndo ocurre: Al ejecutar <code>docker run</code> o <code>uvicorn</code>.</p> <p>Causa ra\u00edz: Falta <code>ENV PYTHONPATH=/app</code> o el c\u00f3digo no est\u00e1 en <code>/app</code>.</p> <p>Diagn\u00f3stico: <pre><code># Verificar estructura dentro del contenedor\ndocker exec -it &lt;container&gt; ls -la /app\n# \u00bfExiste /app/src/? \u00bf/app/app/?\n\n# Verificar PYTHONPATH\ndocker exec -it &lt;container&gt; printenv PYTHONPATH\n# Esperado: /app\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># A\u00f1adir en el runtime stage\nENV PYTHONPATH=/app\n\n# O cambiar el CMD para especificar la ruta\nCMD [\"python\", \"-m\", \"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\"]\n</code></pre></p>"},{"location":"docs/13_DOCKER/#error-2-permissionerror-errno-13-permission-denied-applogsapplog","title":"Error 2: <code>PermissionError: [Errno 13] Permission denied: '/app/logs/app.log'</code>","text":"<p>Cu\u00e1ndo ocurre: La API intenta escribir logs pero falla.</p> <p>Causa ra\u00edz: El directorio <code>/app/logs</code> pertenece a <code>root</code>, pero el proceso corre como <code>appuser</code>.</p> <p>Diagn\u00f3stico: <pre><code># Verificar permisos\ndocker exec -it &lt;container&gt; ls -la /app\n# \u00bfEl owner es appuser o root?\n\n# Verificar usuario actual\ndocker exec -it &lt;container&gt; whoami\n# Esperado: appuser\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># ANTES de USER appuser, crear directorios y asignar permisos\nRUN mkdir -p logs data models &amp;&amp; \\\n    chown -R appuser:appuser /app\n\nUSER appuser  # \u2190 DESPU\u00c9S de chown\n</code></pre></p>"},{"location":"docs/13_DOCKER/#error-3-container-unhealthy-pero-la-api-funciona","title":"Error 3: Container <code>unhealthy</code> pero la API funciona","text":"<p>Cu\u00e1ndo ocurre: <code>docker ps</code> muestra \"(unhealthy)\" pero <code>curl localhost:8000/health</code> funciona.</p> <p>Causa ra\u00edz: El HEALTHCHECK usa <code>curl</code> pero <code>curl</code> no est\u00e1 instalado en la imagen.</p> <p>Diagn\u00f3stico: <pre><code># Verificar si curl existe\ndocker exec -it &lt;container&gt; which curl\n# Si no hay output, curl no est\u00e1 instalado\n\n# Verificar logs del healthcheck\ndocker inspect &lt;container&gt; --format='{{json .State.Health}}'\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># Instalar curl en el runtime stage\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre></p>"},{"location":"docs/13_DOCKER/#error-4-build-tarda-15-minutos-cache-no-funciona","title":"Error 4: Build tarda 15+ minutos (cache no funciona)","text":"<p>Cu\u00e1ndo ocurre: Cada cambio de c\u00f3digo dispara reinstalaci\u00f3n de pip.</p> <p>Causa ra\u00edz: <code>COPY . .</code> est\u00e1 ANTES de <code>pip install</code>.</p> <p>Diagn\u00f3stico: <pre><code># Observar output del build\ndocker build -t test .\n# \u00bfVes \"CACHED\" en el step de pip install?\n# Si no, el cache est\u00e1 roto\n</code></pre></p> <p>Soluci\u00f3n: <pre><code># \u274c MALO: Cualquier cambio invalida todo\nCOPY . .\nRUN pip install -r requirements.txt\n\n# \u2705 BUENO: requirements primero, c\u00f3digo despu\u00e9s\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .  # \u2190 Cambios aqu\u00ed NO invalidan pip\n</code></pre></p>"},{"location":"docs/13_DOCKER/#error-5-imagen-de-15gb-despues-del-multi-stage","title":"Error 5: Imagen de 1.5GB despu\u00e9s del multi-stage","text":"<p>Cu\u00e1ndo ocurre: Usaste multi-stage pero la imagen sigue enorme.</p> <p>Causa ra\u00edz: El <code>.dockerignore</code> no excluye datos, notebooks, o <code>.git</code>.</p> <p>Diagn\u00f3stico: <pre><code># Ver historial de layers\ndocker history bankchurn:latest --format \"{{.Size}}\\t{{.CreatedBy}}\" | head -20\n# \u00bfHay layers de 500MB+? \u00bfQu\u00e9 comando las cre\u00f3?\n\n# Verificar qu\u00e9 est\u00e1 copiando\ndocker build -t test . 2&gt;&amp;1 | grep \"COPY\"\n</code></pre></p> <p>Soluci\u00f3n: Crear/actualizar <code>.dockerignore</code>: <pre><code># .dockerignore - CR\u00cdTICO para im\u00e1genes peque\u00f1as\n.git\n.gitignore\ndata/\nnotebooks/\ntests/\n*.md\n*.ipynb\n__pycache__\n.venv/\nmlruns/\n.dvc/\n</code></pre></p>"},{"location":"docs/13_DOCKER/#1375-checklist-de-replicacion-completa","title":"13.7.5 \ud83d\udccb Checklist de Replicaci\u00f3n Completa","text":"<p>Usa esta lista para verificar que tu Dockerfile replica correctamente el del portafolio:</p> <pre><code># Checklist: Dockerfile BankChurn-Predictor\n\n## Arquitectura\n- [ ] Multi-stage build (builder + runtime)\n- [ ] Base image: python:3.11-slim (NO alpine, NO full)\n- [ ] Builder: instala gcc, build-essential\n- [ ] Runtime: NO tiene compiladores\n\n## Optimizaci\u00f3n\n- [ ] .dockerignore excluye: .git, data/, tests/, notebooks/, __pycache__\n- [ ] COPY requirements.txt ANTES de COPY c\u00f3digo\n- [ ] pip install --no-cache-dir\n- [ ] rm -rf /var/lib/apt/lists/* despu\u00e9s de apt-get\n- [ ] Imagen final &lt; 500MB (verificar con docker images)\n\n## Seguridad\n- [ ] Usuario non-root creado (appuser con UID 1000)\n- [ ] USER appuser DESPU\u00c9S de crear directorios\n- [ ] --chown=appuser:appuser en COPY\n- [ ] Directorios logs/, data/, models/ con permisos correctos\n\n## Observabilidad\n- [ ] HEALTHCHECK configurado (interval, timeout, start-period, retries)\n- [ ] curl instalado en runtime (para HEALTHCHECK)\n- [ ] EXPOSE 8000 documentado\n\n## Verificaci\u00f3n Final\n- [ ] docker build completa sin errores\n- [ ] docker run levanta el contenedor\n- [ ] curl localhost:8000/health retorna 200\n- [ ] docker exec &lt;container&gt; whoami retorna \"appuser\"\n- [ ] container aparece como \"healthy\" en docker ps\n</code></pre>"},{"location":"docs/13_DOCKER/#1376-anatomia-del-dockerignore-real-del-portafolio","title":"13.7.6 \ud83d\udcc1 Anatom\u00eda del <code>.dockerignore</code> Real del Portafolio","text":"<p>El archivo <code>.dockerignore</code> es TAN importante como el <code>Dockerfile</code>. Sin \u00e9l, tu imagen puede pasar de 350MB a 2GB.</p> <p>Archivo: <code>BankChurn-Predictor/.dockerignore</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# .dockerignore del Portafolio - Comentado l\u00ednea por l\u00ednea\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n# Secci\u00f3n 1: Control de Versiones\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# .git\n#   \u251c\u2500 Excluye el directorio .git completo (~50-500MB en proyectos grandes)\n#   \u251c\u2500 El historial de commits NO es necesario en el contenedor\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Imagen 500MB m\u00e1s grande sin beneficio\n.git\n.gitignore\n.dvc\n.dvcignore\n# \u2191 DVC tambi\u00e9n tiene su propio directorio pesado con cache de datos\n\n# Secci\u00f3n 2: Python - Archivos Generados\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# __pycache__\n#   \u251c\u2500 Bytecode compilado de Python (*.pyc)\n#   \u251c\u2500 Se regenera autom\u00e1ticamente cuando Python importa el m\u00f3dulo\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Archivos innecesarios + posibles conflictos de versi\u00f3n\n__pycache__\n*.pyc\n*.pyo\n*.pyd\n.Python\n\n# Secci\u00f3n 3: Entornos Virtuales\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# env/, venv/, .venv/\n#   \u251c\u2500 El virtualenv del HOST no debe ir al contenedor\n#   \u251c\u2500 El contenedor tiene su PROPIO venv en /opt/venv\n#   \u251c\u2500 Tama\u00f1o t\u00edpico: 200MB-1GB dependiendo de las dependencias\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Conflictos de rutas + imagen enorme\nenv/\nvenv/\n.venv/\npip-log.txt\npip-delete-this-directory.txt\n\n# Secci\u00f3n 4: Testing y Calidad de C\u00f3digo\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# tests/\n#   \u251c\u2500 Los tests NO se ejecutan en producci\u00f3n\n#   \u251c\u2500 pytest, coverage, etc. solo para desarrollo/CI\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 C\u00f3digo innecesario en producci\u00f3n (attack surface mayor)\n.tox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.log\n.pytest_cache/\n.mypy_cache/\n.flake8\ntests/\n# \u2191 IMPORTANTE: Excluir tests/ reduce imagen Y attack surface\n\n# Secci\u00f3n 5: Datos y Artefactos Pesados\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# data/, models/, results/, mlruns/\n#   \u251c\u2500 Datos se montan como VOL\u00daMENES, no se copian a la imagen\n#   \u251c\u2500 models/ se monta en runtime: -v ./models:/app/models:ro\n#   \u251c\u2500 mlruns/ es el directorio de MLflow (puede ser GB de experimentos)\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Imagen de 5GB+ con datos de entrenamiento\ndata/\nmodels/\nresults/\nmlruns/\n\n# Secci\u00f3n 6: Notebooks y Documentaci\u00f3n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# notebooks/, *.ipynb\n#   \u251c\u2500 Notebooks son para exploraci\u00f3n, no para producci\u00f3n\n#   \u251c\u2500 Pueden contener outputs pesados (im\u00e1genes, tablas)\n#   \u2514\u2500 \u00bfQu\u00e9 pasa sin esto? \u2192 Notebooks de 50MB+ innecesarios en imagen\nnotebooks/\ndocs/\n*.md\n# \u2191 Excluimos .md EXCEPTO README.md si lo necesitas (ver patr\u00f3n negativo abajo)\n# Para incluir README.md: a\u00f1adir l\u00ednea \"!README.md\" DESPU\u00c9S de \"*.md\"\n</code></pre> <p>Patrones Avanzados de <code>.dockerignore</code>:</p> <pre><code># Patr\u00f3n 1: Excluir TODO excepto algo espec\u00edfico\n*.md\n!README.md\n# \u2191 Excluye todos los .md EXCEPTO README.md\n\n# Patr\u00f3n 2: Excluir subdirectorios pero no el directorio mismo\ndata/*\n!data/.gitkeep\n# \u2191 Excluye contenido de data/ pero mantiene el directorio\n\n# Patr\u00f3n 3: Excluir por profundidad\n**/__pycache__\n# \u2191 Excluye __pycache__ en CUALQUIER nivel de profundidad\n\n# Patr\u00f3n 4: Excluir archivos temporales\n*.tmp\n*.temp\n*~\n.DS_Store\n# \u2191 Archivos del sistema operativo que no deben ir al contenedor\n</code></pre>"},{"location":"docs/13_DOCKER/#1377-conexion-docker-kubernetes-de-imagen-a-produccion","title":"13.7.7 \ud83d\udd17 Conexi\u00f3n Docker \u2192 Kubernetes: De Imagen a Producci\u00f3n","text":"<p>El Dockerfile que construyes es solo el primer paso. En producci\u00f3n, esa imagen se despliega en Kubernetes. Veamos c\u00f3mo se conectan:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FLUJO: DOCKERFILE \u2192 KUBERNETES                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  1. BUILD                          2. PUSH                        3. DEPLOY     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2500\u2500\u2500\u2500\u2500                          \u2500\u2500\u2500\u2500\u2500\u2500\u2500       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Dockerfile   \u2502  docker build   \u2502 Image        \u2502  docker push \u2502 K8s        \u2502  \u2502\n\u2502  \u2502              \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 bankchurn    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502 Deployment \u2502  \u2502\n\u2502  \u2502 Multi-stage  \u2502                 \u2502 :v2.0.0      \u2502              \u2502            \u2502  \u2502\n\u2502  \u2502 ~350MB       \u2502                 \u2502              \u2502              \u2502 3 replicas \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                           \u2502                            \u2502        \u2502\n\u2502  BankChurn-Predictor/                     \u2502                            \u2502        \u2502\n\u2502  Dockerfile                        Registry                   k8s/bankchurn-    \u2502\n\u2502                                   (DockerHub/                 deployment.yaml   \u2502\n\u2502                                    GitHub)                                      \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Extracto de <code>k8s/bankchurn-deployment.yaml</code> del Portafolio:</p> <pre><code># k8s/bankchurn-deployment.yaml - C\u00f3mo Kubernetes usa tu imagen Docker\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bankchurn-predictor\n  namespace: ml-portfolio\n  # \u2191 namespace: a\u00edsla recursos del resto del cluster\nspec:\n  replicas: 3\n  # \u2191 replicas: 3 instancias del contenedor para alta disponibilidad\n  #   \u00bfPor qu\u00e9 3? \u2192 Tolerancia a fallos: si 1 cae, quedan 2\n\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1       # \u2190 M\u00e1ximo 1 pod extra durante update\n      maxUnavailable: 1 # \u2190 M\u00e1ximo 1 pod no disponible durante update\n    # \u2191 RollingUpdate: depliegue sin downtime (pods se actualizan uno a uno)\n\n  template:\n    spec:\n      containers:\n      - name: bankchurn-api\n        image: duqueom/bankchurn-predictor:v2.0.0\n        # \u2191 ESTA es la imagen que construiste con tu Dockerfile\n        #   El tag :v2.0.0 permite rollback a versiones anteriores\n\n        imagePullPolicy: Always\n        # \u2191 Always: siempre descarga la imagen (\u00fatil para latest o CI/CD)\n        #   IfNotPresent: solo si no existe localmente (m\u00e1s r\u00e1pido)\n\n        ports:\n        - containerPort: 8000\n          # \u2191 Mismo puerto que EXPOSE 8000 en Dockerfile\n\n        env:\n        - name: MODEL_PATH\n          value: \"/app/models/model.pkl\"\n          # \u2191 Variables de entorno inyectadas en runtime (no hardcodeadas en imagen)\n\n        resources:\n          requests:\n            memory: \"512Mi\"  # \u2190 M\u00ednimo garantizado de RAM\n            cpu: \"250m\"      # \u2190 M\u00ednimo garantizado de CPU (250 millicores = 0.25 cores)\n          limits:\n            memory: \"1Gi\"    # \u2190 M\u00e1ximo permitido de RAM\n            cpu: \"1000m\"     # \u2190 M\u00e1ximo permitido de CPU (1 core)\n          # \u2191 resources: K8s usa esto para scheduling y evitar que un pod \"mate\" al nodo\n\n        livenessProbe:\n          httpGet:\n            path: /health    # \u2190 Mismo endpoint que HEALTHCHECK en Dockerfile\n            port: 8000\n          initialDelaySeconds: 30  # \u2190 Espera 30s antes del primer check\n          periodSeconds: 10        # \u2190 Cada 10s\n          failureThreshold: 3      # \u2190 3 fallos = reinicia el pod\n          # \u2191 livenessProbe: K8s reinicia el pod si /health no responde\n\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 10  # \u2190 Menos tiempo que liveness\n          periodSeconds: 5\n          # \u2191 readinessProbe: K8s no env\u00eda tr\u00e1fico hasta que el pod est\u00e9 ready\n\n        volumeMounts:\n        - name: model-storage\n          mountPath: /app/models  # \u2190 Misma ruta que MODEL_PATH\n          readOnly: true          # \u2190 Solo lectura (seguridad)\n          # \u2191 volumeMounts: modelos NO van en la imagen, se montan en runtime\n\n      volumes:\n      - name: model-storage\n        persistentVolumeClaim:\n          claimName: ml-models-pvc\n          # \u2191 PVC: almacenamiento persistente para modelos (sobrevive a reinicios)\n</code></pre> <p>Conexiones clave Dockerfile \u2194 K8s:</p> Dockerfile Kubernetes Deployment <code>EXPOSE 8000</code> <code>containerPort: 8000</code> <code>HEALTHCHECK</code> <code>livenessProbe</code> + <code>readinessProbe</code> <code>USER appuser</code> <code>securityContext.runAsUser: 1000</code> <code>ENV MODEL_PATH</code> <code>env: - name: MODEL_PATH</code> <code>CMD [\"uvicorn\"...]</code> (hereda del Dockerfile) <code>mkdir -p models</code> <code>volumeMounts.mountPath: /app/models</code>"},{"location":"docs/13_DOCKER/#1378-metricas-de-exito-como-saber-que-lo-hiciste-bien","title":"13.7.8 \ud83d\udcca M\u00e9tricas de \u00c9xito: \u00bfC\u00f3mo Saber que lo Hiciste Bien?","text":"<p>Despu\u00e9s de completar el laboratorio, verifica estas m\u00e9tricas:</p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Script de verificaci\u00f3n: check_docker_quality.sh\n# Ejecuta despu\u00e9s de construir tu imagen\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n#!/bin/bash\n# Script para verificar la calidad de tu imagen Docker\n# Uso: bash check_docker_quality.sh bankchurn:latest\n\nIMAGE_NAME=${1:-\"bankchurn:latest\"}\n\necho \"\ud83d\udd0d Verificando imagen: $IMAGE_NAME\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\n# 1. Verificar tama\u00f1o de imagen\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nSIZE=$(docker images $IMAGE_NAME --format \"{{.Size}}\")\necho \"\ud83d\udce6 Tama\u00f1o de imagen: $SIZE\"\n# Objetivo: &lt; 500MB para im\u00e1genes de ML\n\n# 2. Verificar que NO tiene compiladores\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\necho \"\"\necho \"\ud83d\udd27 Verificando ausencia de compiladores...\"\ndocker run --rm $IMAGE_NAME which gcc 2&gt;/dev/null\nif [ $? -eq 0 ]; then\n    echo \"   \u274c PROBLEMA: gcc encontrado en imagen runtime\"\nelse\n    echo \"   \u2705 OK: gcc no presente (multi-stage funcion\u00f3)\"\nfi\n\n# 3. Verificar usuario non-root\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\necho \"\"\necho \"\ud83d\udc64 Verificando usuario...\"\nUSER=$(docker run --rm $IMAGE_NAME whoami)\necho \"   Usuario actual: $USER\"\nif [ \"$USER\" == \"appuser\" ]; then\n    echo \"   \u2705 OK: Corre como non-root\"\nelse\n    echo \"   \u274c PROBLEMA: Corre como $USER (deber\u00eda ser appuser)\"\nfi\n\n# 4. Verificar PYTHONPATH\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\necho \"\"\necho \"\ud83d\udc0d Verificando PYTHONPATH...\"\nPYPATH=$(docker run --rm $IMAGE_NAME printenv PYTHONPATH)\necho \"   PYTHONPATH: $PYPATH\"\nif [ \"$PYPATH\" == \"/app\" ]; then\n    echo \"   \u2705 OK: PYTHONPATH configurado\"\nelse\n    echo \"   \u274c PROBLEMA: PYTHONPATH incorrecto o no configurado\"\nfi\n\n# 5. Verificar estructura de directorios\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\necho \"\"\necho \"\ud83d\udcc1 Verificando estructura...\"\ndocker run --rm $IMAGE_NAME ls -la /app | head -10\n\n# 6. Verificar healthcheck\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\necho \"\"\necho \"\ud83d\udc93 Verificando HEALTHCHECK configurado...\"\nHEALTH=$(docker inspect $IMAGE_NAME --format='{{.Config.Healthcheck}}')\nif [ \"$HEALTH\" != \"&lt;nil&gt;\" ]; then\n    echo \"   \u2705 OK: HEALTHCHECK presente\"\n    echo \"   Configuraci\u00f3n: $HEALTH\"\nelse\n    echo \"   \u274c PROBLEMA: Sin HEALTHCHECK configurado\"\nfi\n\necho \"\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"\u2705 Verificaci\u00f3n completada\"\n</code></pre> <p>Tabla de M\u00e9tricas Objetivo:</p> M\u00e9trica \u274c Malo \u26a0\ufe0f Aceptable \u2705 Excelente Tama\u00f1o de imagen &gt; 1GB 500MB-1GB &lt; 500MB Tiempo de build (con cache) &gt; 5min 1-5min &lt; 1min Tiempo de build (sin cache) &gt; 15min 5-15min &lt; 5min Usuario en runtime root - appuser (non-root) HEALTHCHECK ausente presente sin start-period completo Layers de imagen &gt; 20 10-20 &lt; 10 <p></p>"},{"location":"docs/13_DOCKER/#errores-habituales-y-como-depurarlos-en-docker-para-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en Docker para ML","text":"<p>En ML es muy com\u00fan tener im\u00e1genes gigantes, problemas de permisos o contenedores que \u201cfuncionan en mi m\u00e1quina pero no en producci\u00f3n\u201d.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/13_DOCKER/#1-imagenes-demasiado-grandes","title":"1) Im\u00e1genes demasiado grandes","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li><code>docker images</code> muestra tama\u00f1os &gt; 1GB.</li> <li>Push/pull al registry tarda mucho o falla por timeout.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara tu Dockerfile con los ejemplos <code>python:3.11</code> vs <code>python:3.11-slim</code> del m\u00f3dulo.</li> <li>Revisa si est\u00e1s copiando todo el repo (<code>COPY . .</code>) sin <code>.dockerignore</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa bases <code>slim</code> y multi-stage builds.</li> <li>A\u00f1ade un <code>.dockerignore</code> que excluya datos, notebooks, tests y <code>.venv</code>.</li> </ul>"},{"location":"docs/13_DOCKER/#2-errores-de-permisos-al-correr-como-non-root","title":"2) Errores de permisos al correr como non-root","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El contenedor arranca pero falla al leer modelos, logs o escribir en directorios.</li> <li>Mensajes tipo <code>Permission denied: '/app/models/model.joblib'</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica que despu\u00e9s de copiar archivos hagas <code>chown</code> al usuario de la app.</li> <li>Revisa que <code>USER appuser</code> aparezca despu\u00e9s de ajustar permisos.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de:   <pre><code>RUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n</code></pre></li> <li>Monta vol\u00famenes con permisos compatibles (por ejemplo, propiedad UID 1000 en host).</li> </ul>"},{"location":"docs/13_DOCKER/#3-modelo-o-artefactos-no-encontrados-dentro-del-contenedor","title":"3) Modelo o artefactos no encontrados dentro del contenedor","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>La API levanta pero responde 500 porque no encuentra el modelo (<code>FileNotFoundError</code>).</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa las rutas de <code>COPY</code> en el Dockerfile y las rutas que tu c\u00f3digo usa (<code>./models</code>, <code>./artifacts</code>).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Copia los artefactos a la ruta esperada o monta un volumen de solo lectura:   <pre><code>volumes:\n  - ./BankChurn-Predictor/models:/app/models:ro\n</code></pre></li> </ul>"},{"location":"docs/13_DOCKER/#4-contenedores-que-arrancan-pero-el-healthcheck-falla","title":"4) Contenedores que arrancan pero el healthcheck falla","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El servicio aparece como \"unhealthy\" en <code>docker ps</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Examina el <code>HEALTHCHECK</code> y verifica que la URL y puerto sean correctos.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Aseg\u00farate de que el endpoint <code>/health</code> exista y escuche en el mismo puerto que expones.</li> <li>Ajusta tiempos de <code>start-period</code> si el modelo tarda m\u00e1s en cargar.</li> </ul>"},{"location":"docs/13_DOCKER/#5-patron-general-de-debugging-con-docker","title":"5) Patr\u00f3n general de debugging con Docker","text":"<ol> <li>Inspecciona el contenedor en ejecuci\u00f3n con <code>docker exec -it &lt;container&gt; /bin/bash</code>.</li> <li>Navega por <code>/app</code> para verificar que el c\u00f3digo, modelos y configs est\u00e9n donde esperas.</li> <li>Comprueba permisos (<code>ls -l</code>) y usuario actual (<code>whoami</code>).</li> <li>Si la imagen es muy grande, revisa el historial de capas con <code>docker history</code>.</li> </ol> <p>Con este enfoque, tus im\u00e1genes Docker ser\u00e1n reproducibles, ligeras y listas para producci\u00f3n.</p> <p></p>"},{"location":"docs/13_DOCKER/#checkpoint","title":"\u2705 Checkpoint","text":"<ul> <li>[ ] Tu Dockerfile usa base <code>slim</code> (o alternativa justificada) y evita <code>COPY . .</code> sin <code>.dockerignore</code></li> <li>[ ] Tienes <code>.dockerignore</code> que excluye <code>data/</code>, <code>notebooks/</code>, <code>tests/</code>, <code>.venv/</code></li> <li>[ ] El contenedor corre como usuario no-root</li> <li>[ ] Puedes construir y correr la imagen (<code>docker build</code> + <code>docker run</code>)</li> <li>[ ] La API responde a <code>/health</code> (o endpoint equivalente)</li> </ul>"},{"location":"docs/13_DOCKER/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/13_DOCKER/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Multi-stage builds: Explica c\u00f3mo reducen tama\u00f1o de imagen.</p> </li> <li> <p>Layer caching: Por qu\u00e9 el orden de instrucciones importa.</p> </li> <li> <p>Security: No correr como root, no incluir secrets en imagen.</p> </li> </ol>"},{"location":"docs/13_DOCKER/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Im\u00e1genes grandes Multi-stage + slim base images Secrets Usa build args o secrets mounting Debugging Usa <code>docker exec -it container bash</code> Producci\u00f3n Healthchecks obligatorios"},{"location":"docs/13_DOCKER/#dockerfile-optimizado","title":"Dockerfile Optimizado","text":"<pre><code># Stage 1: Build\nFROM python:3.11-slim AS builder\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir -r requirements.txt\n\n# Stage 2: Runtime\nFROM python:3.11-slim\nCOPY --from=builder /wheels /wheels\nRUN pip install --no-cache /wheels/*\nCOPY src/ /app/src/\nUSER nobody\nHEALTHCHECK CMD curl -f http://localhost:8000/health\n</code></pre>"},{"location":"docs/13_DOCKER/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/13_DOCKER/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Docker Tutorial for Beginners TechWorld Nana 2.5h YouTube \ud83d\udd34 Multi-stage Docker Builds Docker 15 min YouTube \ud83d\udfe1 Docker Compose Tutorial TechWorld Nana 1h YouTube"},{"location":"docs/13_DOCKER/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Dockerfile Best Practices Gu\u00eda oficial \ud83d\udfe1 Multi-stage Builds Optimizaci\u00f3n de im\u00e1genes"},{"location":"docs/13_DOCKER/#decision-tecnica-adr-006-docker-multi-stage","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-006 Docker Multi-stage","text":"<p>Contexto: Necesitamos im\u00e1genes Docker peque\u00f1as y seguras para producci\u00f3n.</p> <p>Decisi\u00f3n: Usar multi-stage builds con bases slim.</p> <p>Alternativas Consideradas: - Single-stage: M\u00e1s simple pero im\u00e1genes ~2GB - Distroless: M\u00e1s seguro pero dif\u00edcil de debuggear - Alpine: M\u00e1s peque\u00f1o pero problemas con algunas libs Python</p> <p>Consecuencias: - \u2705 Im\u00e1genes de ~500MB vs ~2GB - \u2705 Sin herramientas de build en runtime - \u2705 M\u00e1s r\u00e1pido de desplegar - \u274c Dockerfiles m\u00e1s complejos</p>"},{"location":"docs/13_DOCKER/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/13_DOCKER/#ejercicio-131-dockerfile-multi-stage","title":"Ejercicio 13.1: Dockerfile Multi-stage","text":"<p>Objetivo: Crear Dockerfile optimizado para ML API. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: Crear Dockerfile que:\n# 1. Use multi-stage build\n# 2. Instale dependencias en stage 1\n# 3. Copie solo lo necesario a stage 2\n# 4. Use usuario non-root\n# 5. Incluya healthcheck\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code># Stage 1: Builder\nFROM python:3.11-slim AS builder\n\nWORKDIR /build\n\n# Instalar dependencias de build\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copiar solo requirements primero (mejor cache)\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt\n\n# Stage 2: Runtime\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Instalar wheels pre-compilados\nCOPY --from=builder /wheels /wheels\nRUN pip install --no-cache-dir /wheels/* &amp;&amp; rm -rf /wheels\n\n# Crear usuario non-root\nRUN useradd -m -u 1000 appuser &amp;&amp; \\\n    chown -R appuser:appuser /app\n\n# Copiar c\u00f3digo\nCOPY --chown=appuser:appuser src/ ./src/\nCOPY --chown=appuser:appuser app/ ./app/\nCOPY --chown=appuser:appuser artifacts/ ./artifacts/\n\n# Cambiar a non-root\nUSER appuser\n\n# Variables de entorno\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Puerto\nEXPOSE 8000\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Comando\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"docs/13_DOCKER/#ejercicio-132-docker-compose-stack","title":"Ejercicio 13.2: Docker Compose Stack","text":"<p>Objetivo: Orquestar servicios ML con docker-compose. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># docker-compose.yml\n# TU TAREA: Crear stack con:\n# - API ML\n# - MLflow server\n# - Prometheus\n# - Vol\u00famenes persistentes\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>version: '3.8'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./artifacts:/app/artifacts:ro\n    environment:\n      - MLFLOW_TRACKING_URI=http://mlflow:5000\n    depends_on:\n      - mlflow\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  mlflow:\n    image: ghcr.io/mlflow/mlflow:v2.9.0\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - mlflow_data:/mlflow\n    command: &gt;\n      mlflow server\n      --host 0.0.0.0\n      --port 5000\n      --backend-store-uri sqlite:///mlflow/mlflow.db\n      --default-artifact-root /mlflow/artifacts\n\n  prometheus:\n    image: prom/prometheus:v2.47.0\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus_data:/prometheus\n\nvolumes:\n  mlflow_data:\n  prometheus_data:\n</code></pre>"},{"location":"docs/13_DOCKER/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Multi-stage Build Dockerfile con m\u00faltiples FROM para separar build y runtime Docker Compose Herramienta para definir y ejecutar multi-container apps Non-root User Usuario sin privilegios para mayor seguridad Healthcheck Comando que verifica que el contenedor est\u00e1 healthy"},{"location":"docs/13_DOCKER/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/13_DOCKER/#trampa-1-dockerfile-que-solo-funciona-en-tu-maquina","title":"Trampa 1: Dockerfile que solo funciona en tu m\u00e1quina","text":"<p>S\u00edntoma: Build falla en CI con \"No module named 'src'\"</p> <p>Causa ra\u00edz: <code>.dockerignore</code> no existe o est\u00e1 mal configurado.</p> <p>Soluci\u00f3n: <pre><code># .dockerignore\n.git\n.venv\n__pycache__\n*.pyc\n.pytest_cache\n</code></pre></p>"},{"location":"docs/13_DOCKER/#trampa-2-container-que-muere-sin-logs","title":"Trampa 2: Container que muere sin logs","text":"<p>S\u00edntoma: Container se ejecuta y muere inmediatamente, sin output.</p> <p>Causa ra\u00edz: Python bufferea stdout por defecto.</p> <p>Soluci\u00f3n: <pre><code>ENV PYTHONUNBUFFERED=1\n</code></pre></p>"},{"location":"docs/13_DOCKER/#trampa-3-imagen-docker-gigante-2gb","title":"Trampa 3: Imagen Docker gigante (2GB+)","text":"<p>S\u00edntoma: <code>docker images</code> muestra 2.3GB.</p> <p>Soluci\u00f3n: <pre><code># 1. Base slim\nFROM python:3.11-slim  # 150MB vs 900MB\n\n# 2. Multi-stage\nFROM python:3.11 as builder\nRUN pip wheel -r requirements.txt -w /wheels\n\nFROM python:3.11-slim as runtime\nCOPY --from=builder /wheels /wheels\nRUN pip install /wheels/*.whl &amp;&amp; rm -rf /wheels\n</code></pre></p>"},{"location":"docs/13_DOCKER/#quiz-del-modulo-semanas-17-18","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 17-18","text":""},{"location":"docs/13_DOCKER/#quiz-semana-17-docker","title":"Quiz Semana 17: Docker","text":""},{"location":"docs/13_DOCKER/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfPor qu\u00e9 usas multi-stage builds en el Dockerfile?</p> \u2705 Respuesta  Multi-stage separa **construcci\u00f3n** de **ejecuci\u00f3n**: - Stage 1 (builder): Tiene compiladores, herramientas (~900MB) - Stage 2 (runtime): Solo lo necesario (~150MB)  **Resultado**: De ~2GB a ~300MB, menor superficie de ataque."},{"location":"docs/13_DOCKER/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfPor qu\u00e9 creas un usuario no-root en el Dockerfile?</p> \u2705 Respuesta  Ejecutar como root es un **riesgo de seguridad**: - Si un atacante escapa del container, tiene root en el host - Vulnerabilidades en dependencias pueden ser explotadas  <pre><code>RUN useradd --create-home appuser\nUSER appuser\n</code></pre>"},{"location":"docs/13_DOCKER/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfC\u00f3mo manejas el caching de dependencias en Docker?</p> \u2705 Respuesta  **Orden de capas importa**. Docker cachea cada capa; si una cambia, invalida las siguientes.  <pre><code># \u2705 BUENO: requirements rara vez cambia\nCOPY requirements.txt /app/\nRUN pip install -r requirements.txt\n# Esta capa se cachea si requirements no cambi\u00f3\n\nCOPY . /app  # Esta capa cambia frecuentemente\n</code></pre>"},{"location":"docs/13_DOCKER/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Escribe un Dockerfile multi-stage para una app FastAPI con usuario no-root.</p> \u2705 Soluci\u00f3n <pre><code>FROM python:3.11-slim as builder\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir -r requirements.txt -w /wheels\n\nFROM python:3.11-slim as runtime\nWORKDIR /app\n\nRUN useradd --create-home appuser\nCOPY --from=builder /wheels /wheels\nRUN pip install --no-cache /wheels/*.whl &amp;&amp; rm -rf /wheels\n\nCOPY --chown=appuser:appuser . .\nUSER appuser\n\nENV PYTHONUNBUFFERED=1\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [14. FastAPI](14_FASTAPI.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/14_FASTAPI/","title":"14. FastAPI para Producci\u00f3n","text":""},{"location":"docs/14_FASTAPI/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Tener un proyecto con FastAPI ejecutable (local o en contenedor).</li> <li>Conocer validaci\u00f3n con Pydantic (modelos request/response).</li> <li>Haber completado el m\u00f3dulo 13 (Docker) para empaquetar y ejecutar la API.</li> </ul>"},{"location":"docs/14_FASTAPI/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de empezar: abre Protocolo E y define el output m\u00ednimo: un servicio que levanta y responde en <code>/health</code> y <code>/predict</code>.</li> <li>Durante el debugging: si te atoras &gt;15 min (schema, serializaci\u00f3n, modelo no carga, 4xx/5xx), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar documentaci\u00f3n (OpenAPI), manejo de errores y compatibilidad training-serving.</li> </ul>"},{"location":"docs/14_FASTAPI/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] Endpoint <code>/health</code> estable (sin depender de c\u00f3mputo pesado).</li> <li>[ ] Endpoint <code>/predict</code> con request/response validados (Pydantic).</li> <li>[ ] Documentaci\u00f3n accesible en <code>/docs</code> (Swagger) y <code>/openapi.json</code>.</li> <li>[ ] Manejo de errores consistente (<code>HTTPException</code> + c\u00f3digos).</li> <li>[ ] Conversi\u00f3n expl\u00edcita a tipos nativos (<code>float</code>, <code>int</code>) para evitar problemas de serializaci\u00f3n.</li> </ul>"},{"location":"docs/14_FASTAPI/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Concepto: contrato API (schemas) + loading de modelo (startup) + observabilidad b\u00e1sica</li> <li>Archivo: <code>app/fastapi_app.py</code>, <code>app/schemas.py</code></li> <li>Prueba: <code>uvicorn app.fastapi_app:app --reload</code> y <code>curl http://localhost:8000/health</code></li> </ul>"},{"location":"docs/14_FASTAPI/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Construir APIs de ML robustas, documentadas y production-ready como las del portafolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  FastAPI = El framework ideal para ML APIs                                   \u2551\n\u2551                                                                              \u2551\n\u2551  \u2705 Type hints nativos (Pydantic)                                            \u2551\n\u2551  \u2705 Documentaci\u00f3n autom\u00e1tica (Swagger/OpenAPI)                               \u2551\n\u2551  \u2705 Async support (alto throughput)                                          \u2551\n\u2551  \u2705 Validaci\u00f3n autom\u00e1tica de requests                                        \u2551\n\u2551  \u2705 Dependency Injection built-in                                            \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/14_FASTAPI/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>14.1 Estructura de una API ML</li> <li>14.2 Schemas con Pydantic</li> <li>14.3 Endpoints de Predicci\u00f3n</li> <li>14.4 Error Handling</li> <li>14.5 C\u00f3digo Real del Portafolio</li> <li>14.6 \ud83d\udd2c Ingenier\u00eda Inversa: API Producci\u00f3n Real \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Checkpoint</li> <li>\u2705 Ejercicio</li> </ul>"},{"location":"docs/14_FASTAPI/#mapa-mental-de-conceptos-fastapi-para-ml","title":"\ud83e\udde0 Mapa Mental de Conceptos: FastAPI para ML","text":"<pre><code>                          \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n                          \u2551      FASTAPI PARA ML PRODUCTION      \u2551\n                          \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n                                            \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                                  \u25bc                                  \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    ENDPOINTS     \u2502              \u2502    SCHEMAS       \u2502              \u2502   LIFECYCLE      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                 \u2502                                 \u2502\n\u251c\u2500 /health                        \u251c\u2500 PredictionRequest          \u251c\u2500 Startup: load model\n\u251c\u2500 /predict                       \u251c\u2500 PredictionResponse         \u251c\u2500 Shutdown: cleanup\n\u251c\u2500 /batch                         \u251c\u2500 Validaci\u00f3n Pydantic        \u2514\u2500 Global state\n\u2514\u2500 /docs (auto)                   \u2514\u2500 OpenAPI spec\n</code></pre> <p>T\u00e9rminos clave:</p> T\u00e9rmino Significado Ejemplo Schema Modelo Pydantic para validar I/O <code>PredictionRequest</code> Lifespan Startup/shutdown hooks Cargar modelo una vez HTTPException Error HTTP estructurado <code>HTTPException(404, \"Not found\")</code> Dependency Inyecci\u00f3n de dependencias Conexi\u00f3n DB, auth"},{"location":"docs/14_FASTAPI/#ejercicio-puente-api-minima","title":"\ud83d\udcbb Ejercicio Puente: API M\u00ednima","text":"<pre><code>from fastapi import FastAPI\n\napp = FastAPI()  # Crea la aplicaci\u00f3n FastAPI.\n\n@app.get(\"/health\")  # Endpoint GET para health check.\ndef health():\n    return {\"status\": \"healthy\"}  # Respuesta JSON indicando que el servicio est\u00e1 activo.\n\n@app.post(\"/predict\")  # Endpoint POST para predicciones.\ndef predict(data: dict):\n    # TU TAREA: Cargar modelo y predecir\n    return {\"prediction\": 0.85}  # Respuesta con la predicci\u00f3n del modelo.\n</code></pre> <p>Ejecutar: <code>uvicorn app:app --reload</code> Ver docs: <code>http://localhost:8000/docs</code></p>"},{"location":"docs/14_FASTAPI/#ejercicio-puente-apis-ml","title":"\ud83d\udcbb Ejercicio Puente: APIs ML","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/14_FASTAPI/#practica-del-portafolio-fastapi-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: FastAPI en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con APIs ML\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/14_FASTAPI/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de FastAPI?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en APIs ML, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/14_FASTAPI/#141-estructura-de-una-api-ml","title":"14.1 Estructura de una API ML","text":""},{"location":"docs/14_FASTAPI/#anatomia-tipica","title":"Anatom\u00eda T\u00edpica","text":"<pre><code># app/fastapi_app.py - Estructura profesional\n\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\n\nimport joblib\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\n\nfrom .schemas import PredictionRequest, PredictionResponse, HealthResponse\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LIFECYCLE: Cargar modelo al iniciar\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nmodel = None                             # Variable global: accesible desde todos los endpoints.\n\n@asynccontextmanager                     # Decorador para crear context manager async.\nasync def lifespan(app: FastAPI):        # Funci\u00f3n que gestiona startup/shutdown de la app.\n    \"\"\"Lifecycle: carga modelo al iniciar, limpia al cerrar.\"\"\"\n    global model                         # global: permite modificar la variable global desde aqu\u00ed.\n\n    # Startup: cargar modelo\n    model_path = Path(\"artifacts/model.joblib\")  # Ruta al modelo serializado.\n    if model_path.exists():              # Verifica que el archivo existe antes de cargar.\n        model = joblib.load(model_path)  # Deserializa el pipeline completo.\n        print(f\"\u2705 Modelo cargado: {model_path}\")\n    else:\n        print(f\"\u26a0\ufe0f Modelo no encontrado: {model_path}\")  # Warning, no crash.\n\n    yield                                # yield: aqu\u00ed la app est\u00e1 corriendo y recibiendo requests.\n\n    # Shutdown: limpiar recursos\n    model = None                         # Libera memoria al cerrar.\n    print(\"\ud83d\uded1 App cerrada\")\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# APP SETUP\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\napp = FastAPI(                           # Crea instancia de la aplicaci\u00f3n FastAPI.\n    title=\"BankChurn Predictor API\",     # T\u00edtulo en Swagger UI (/docs).\n    description=\"API para predicci\u00f3n de churn de clientes bancarios\",\n    version=\"1.0.0\",                     # Versi\u00f3n de la API (semver).\n    lifespan=lifespan,                   # Asocia el lifecycle manager definido arriba.\n)\n\n# CORS para permitir requests desde frontend\napp.add_middleware(                      # Middleware: procesa requests antes/despu\u00e9s de endpoints.\n    CORSMiddleware,                      # Cross-Origin Resource Sharing: permite requests desde otros dominios.\n    allow_origins=[\"*\"],                 # \"*\" permite todo. En prod: [\"https://midominio.com\"].\n    allow_credentials=True,              # Permite enviar cookies/auth headers.\n    allow_methods=[\"*\"],                 # Permite todos los m\u00e9todos HTTP (GET, POST, etc.).\n    allow_headers=[\"*\"],                 # Permite todos los headers.\n)\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# ENDPOINTS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@app.get(\"/health\", response_model=HealthResponse)  # GET /health \u2192 devuelve HealthResponse.\nasync def health_check():                # async: permite I/O no bloqueante (mejor concurrencia).\n    \"\"\"Health check endpoint para load balancers/k8s.\"\"\"\n    return HealthResponse(               # Pydantic valida que el response cumpla el schema.\n        status=\"healthy\" if model is not None else \"degraded\",  # Ternario: condici\u00f3n ? si : no.\n        model_loaded=model is not None,\n        version=\"1.0.0\"\n    )\n\n\n@app.post(\"/predict\", response_model=PredictionResponse)  # POST /predict con body JSON.\nasync def predict(request: PredictionRequest):  # request: Pydantic valida el body autom\u00e1ticamente.\n    \"\"\"Predice probabilidad de churn para un cliente.\"\"\"\n    if model is None:                    # Verificaci\u00f3n defensiva.\n        raise HTTPException(status_code=503, detail=\"Modelo no disponible\")  # 503: Service Unavailable.\n\n    # Convertir request a DataFrame\n    import pandas as pd                  # Import dentro de funci\u00f3n (lazy load, ok en endpoints).\n    df = pd.DataFrame([request.dict()])  # dict(): convierte Pydantic model a diccionario.\n\n    # Predecir\n    proba = model.predict_proba(df)[0, 1]  # [0, 1]: fila 0, columna 1 (prob clase positiva).\n    prediction = int(proba &gt;= 0.5)       # Umbral 0.5: convierte probabilidad a 0/1.\n\n    return PredictionResponse(           # Response tipado y validado.\n        prediction=prediction,\n        probability=round(proba, 4),     # round: 4 decimales de precisi\u00f3n.\n        risk_level=\"high\" if proba &gt;= 0.7 else \"medium\" if proba &gt;= 0.3 else \"low\"  # Ternario encadenado.\n    )\n</code></pre>"},{"location":"docs/14_FASTAPI/#142-schemas-con-pydantic","title":"14.2 Schemas con Pydantic","text":""},{"location":"docs/14_FASTAPI/#requestresponse-models","title":"Request/Response Models","text":"<pre><code># app/schemas.py\n\nfrom typing import Literal, Optional       # Literal: valores espec\u00edficos; Optional: puede ser None.\nfrom pydantic import BaseModel, Field, validator  # BaseModel: clase base para schemas.\n\n\nclass PredictionRequest(BaseModel):        # Hereda de BaseModel: obtiene validaci\u00f3n autom\u00e1tica.\n    \"\"\"Schema para request de predicci\u00f3n.\n\n    Pydantic valida autom\u00e1ticamente:\n    - Tipos correctos\n    - Rangos v\u00e1lidos\n    - Valores permitidos\n    \"\"\"\n\n    CreditScore: int = Field(..., ge=300, le=850, description=\"Credit score del cliente\")\n    # Field(...): ... significa REQUERIDO. ge=300: mayor o igual. le=850: menor o igual.\n    Geography: Literal[\"France\", \"Germany\", \"Spain\"] = Field(..., description=\"Pa\u00eds\")\n    # Literal: SOLO acepta estos 3 valores exactos. Otros \u2192 ValidationError.\n    Gender: Literal[\"Male\", \"Female\"] = Field(..., description=\"G\u00e9nero\")\n    Age: int = Field(..., ge=18, le=100, description=\"Edad\")\n    Tenure: int = Field(..., ge=0, le=10, description=\"A\u00f1os como cliente\")\n    Balance: float = Field(..., ge=0, description=\"Balance en cuenta\")  # ge=0: no negativo.\n    NumOfProducts: int = Field(..., ge=1, le=4, description=\"N\u00famero de productos\")\n    HasCrCard: Literal[0, 1] = Field(..., description=\"Tiene tarjeta de cr\u00e9dito\")  # Binario.\n    IsActiveMember: Literal[0, 1] = Field(..., description=\"Es miembro activo\")\n    EstimatedSalary: float = Field(..., ge=0, description=\"Salario estimado\")\n\n    class Config:                          # Config: configuraci\u00f3n del modelo Pydantic.\n        json_schema_extra = {              # Ejemplo para Swagger UI (/docs).\n            \"example\": {\n                \"CreditScore\": 650,\n                \"Geography\": \"France\",\n                \"Gender\": \"Female\",\n                \"Age\": 40,\n                \"Tenure\": 3,\n                \"Balance\": 60000.0,\n                \"NumOfProducts\": 2,\n                \"HasCrCard\": 1,\n                \"IsActiveMember\": 1,\n                \"EstimatedSalary\": 50000.0\n            }\n        }\n\n\nclass PredictionResponse(BaseModel):\n    \"\"\"Schema para response de predicci\u00f3n.\"\"\"\n\n    prediction: Literal[0, 1] = Field(..., description=\"0=No churn, 1=Churn\")\n    probability: float = Field(..., ge=0, le=1, description=\"Probabilidad de churn\")\n    risk_level: Literal[\"low\", \"medium\", \"high\"] = Field(..., description=\"Nivel de riesgo\")\n\n\nclass HealthResponse(BaseModel):\n    \"\"\"Schema para health check.\"\"\"\n\n    status: Literal[\"healthy\", \"degraded\", \"unhealthy\"]\n    model_loaded: bool\n    version: str\n\n\nclass BatchPredictionRequest(BaseModel):\n    \"\"\"Schema para predicci\u00f3n en batch.\"\"\"\n\n    customers: list[PredictionRequest] = Field(\n        ..., \n        min_items=1, \n        max_items=1000,\n        description=\"Lista de clientes (m\u00e1x 1000)\"\n    )\n\n\nclass BatchPredictionResponse(BaseModel):\n    \"\"\"Schema para response de batch.\"\"\"\n\n    predictions: list[PredictionResponse]\n    processed: int\n    errors: int = 0\n</code></pre>"},{"location":"docs/14_FASTAPI/#143-endpoints-de-prediccion","title":"14.3 Endpoints de Predicci\u00f3n","text":""},{"location":"docs/14_FASTAPI/#single-prediction","title":"Single Prediction","text":"<pre><code>@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    \"\"\"\n    Predice probabilidad de churn para UN cliente.\n\n    - **CreditScore**: Score crediticio (300-850)\n    - **Geography**: Pa\u00eds (France, Germany, Spain)\n    - **Gender**: G\u00e9nero\n    - **Age**: Edad (18-100)\n    - ... etc\n\n    Returns:\n    - **prediction**: 0 (no churn) o 1 (churn)\n    - **probability**: Probabilidad [0, 1]\n    - **risk_level**: low/medium/high\n    \"\"\"\n    if model is None:\n        raise HTTPException(\n            status_code=503, \n            detail=\"Modelo no disponible. Reinicie el servicio.\"\n        )\n\n    try:\n        import pandas as pd\n        df = pd.DataFrame([request.model_dump()])\n\n        proba = model.predict_proba(df)[0, 1]\n        prediction = int(proba &gt;= 0.5)\n\n        if proba &gt;= 0.7:\n            risk = \"high\"\n        elif proba &gt;= 0.3:\n            risk = \"medium\"\n        else:\n            risk = \"low\"\n\n        return PredictionResponse(\n            prediction=prediction,\n            probability=round(float(proba), 4),\n            risk_level=risk\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error en predicci\u00f3n: {str(e)}\")\n</code></pre>"},{"location":"docs/14_FASTAPI/#batch-prediction","title":"Batch Prediction","text":"<pre><code>@app.post(\"/predict/batch\", response_model=BatchPredictionResponse)\nasync def predict_batch(request: BatchPredictionRequest):\n    \"\"\"\n    Predice churn para m\u00faltiples clientes (m\u00e1x 1000).\n\n    \u00datil para scoring masivo de cartera.\n    \"\"\"\n    if model is None:\n        raise HTTPException(status_code=503, detail=\"Modelo no disponible\")\n\n    import pandas as pd\n\n    results = []\n    errors = 0\n\n    # Convertir todos los requests a DataFrame (m\u00e1s eficiente)\n    data = [c.model_dump() for c in request.customers]\n    df = pd.DataFrame(data)\n\n    try:\n        probas = model.predict_proba(df)[:, 1]\n\n        for proba in probas:\n            prediction = int(proba &gt;= 0.5)\n            risk = \"high\" if proba &gt;= 0.7 else \"medium\" if proba &gt;= 0.3 else \"low\"\n\n            results.append(PredictionResponse(\n                prediction=prediction,\n                probability=round(float(proba), 4),\n                risk_level=risk\n            ))\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error en batch: {str(e)}\")\n\n    return BatchPredictionResponse(\n        predictions=results,\n        processed=len(results),\n        errors=errors\n    )\n</code></pre>"},{"location":"docs/14_FASTAPI/#144-error-handling","title":"14.4 Error Handling","text":""},{"location":"docs/14_FASTAPI/#custom-exception-handlers","title":"Custom Exception Handlers","text":"<pre><code>from fastapi import Request\nfrom fastapi.responses import JSONResponse\n\nclass ModelNotLoadedError(Exception):\n    \"\"\"Modelo no cargado.\"\"\"\n    pass\n\nclass InvalidInputError(Exception):\n    \"\"\"Input inv\u00e1lido.\"\"\"\n    pass\n\n\n@app.exception_handler(ModelNotLoadedError)\nasync def model_not_loaded_handler(request: Request, exc: ModelNotLoadedError):\n    return JSONResponse(\n        status_code=503,\n        content={\n            \"error\": \"service_unavailable\",\n            \"message\": \"El modelo no est\u00e1 cargado. Intente m\u00e1s tarde.\",\n            \"retry_after\": 30\n        }\n    )\n\n\n@app.exception_handler(InvalidInputError)\nasync def invalid_input_handler(request: Request, exc: InvalidInputError):\n    return JSONResponse(\n        status_code=400,\n        content={\n            \"error\": \"invalid_input\",\n            \"message\": str(exc),\n            \"hint\": \"Verifique que todos los campos tengan valores v\u00e1lidos\"\n        }\n    )\n\n\n# Catch-all para errores no manejados\n@app.exception_handler(Exception)\nasync def generic_exception_handler(request: Request, exc: Exception):\n    return JSONResponse(\n        status_code=500,\n        content={\n            \"error\": \"internal_error\",\n            \"message\": \"Error interno del servidor\",\n            \"detail\": str(exc) if app.debug else None\n        }\n    )\n</code></pre>"},{"location":"docs/14_FASTAPI/#145-codigo-real-del-portafolio","title":"14.5 C\u00f3digo Real del Portafolio","text":""},{"location":"docs/14_FASTAPI/#appfastapi_apppy-bankchurn-simplificado","title":"app/fastapi_app.py (BankChurn - Simplificado)","text":"<pre><code>\"\"\"FastAPI application for BankChurn prediction service.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\nfrom typing import Literal\n\nimport joblib\nimport pandas as pd\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# SCHEMAS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclass CustomerInput(BaseModel):\n    CreditScore: int = Field(..., ge=300, le=850)\n    Geography: str\n    Gender: str\n    Age: int = Field(..., ge=18, le=100)\n    Tenure: int = Field(..., ge=0, le=10)\n    Balance: float = Field(..., ge=0)\n    NumOfProducts: int = Field(..., ge=1, le=4)\n    HasCrCard: int = Field(..., ge=0, le=1)\n    IsActiveMember: int = Field(..., ge=0, le=1)\n    EstimatedSalary: float = Field(..., ge=0)\n\n\nclass PredictionOutput(BaseModel):\n    prediction: int\n    probability: float\n    risk_level: str\n\n\nclass HealthOutput(BaseModel):\n    status: str\n    model_loaded: bool\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# APP\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nmodel = None\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    global model\n\n    # Buscar modelo en varias ubicaciones\n    paths = [\n        Path(\"models/model_v1.0.0.pkl\"),\n        Path(\"artifacts/model.joblib\"),\n        Path(os.getenv(\"MODEL_PATH\", \"model.joblib\")),\n    ]\n\n    for path in paths:\n        if path.exists():\n            model = joblib.load(path)\n            logger.info(f\"Modelo cargado: {path}\")\n            break\n\n    if model is None:\n        logger.warning(\"\u26a0\ufe0f Ning\u00fan modelo encontrado\")\n\n    yield\n    model = None\n\n\napp = FastAPI(\n    title=\"BankChurn Predictor\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.get(\"/health\", response_model=HealthOutput)\nasync def health():\n    return HealthOutput(\n        status=\"healthy\" if model else \"degraded\",\n        model_loaded=model is not None\n    )\n\n\n@app.post(\"/predict\", response_model=PredictionOutput)\nasync def predict(customer: CustomerInput):\n    if model is None:\n        raise HTTPException(503, \"Modelo no disponible\")\n\n    df = pd.DataFrame([customer.model_dump()])\n    proba = model.predict_proba(df)[0, 1]\n\n    return PredictionOutput(\n        prediction=int(proba &gt;= 0.5),\n        probability=round(proba, 4),\n        risk_level=\"high\" if proba &gt;= 0.7 else \"medium\" if proba &gt;= 0.3 else \"low\"\n    )\n\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"docs/14_FASTAPI/#146-ingenieria-inversa-pedagogica-api-de-produccion-real","title":"14.6 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: API de Producci\u00f3n Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s de la API FastAPI del portafolio.</p> <p>Esta secci\u00f3n disecciona <code>app/fastapi_app.py</code> de BankChurn-Predictor, una API ML de producci\u00f3n real.</p>"},{"location":"docs/14_FASTAPI/#1461-el-por-que-arquitectonico","title":"14.6.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 la API del portafolio est\u00e1 dise\u00f1ada as\u00ed?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo cargo el modelo una sola vez sin bloquearlo en cada request? \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Cargar modelo (~500MB) en cada request = 2-5s de latencia              \u2502\n\u2502  DECISI\u00d3N: Cargar en `lifespan` (startup), guardar en variable global           \u2502\n\u2502  RESULTADO: Primera carga ~3s, requests subsecuentes ~50ms                      \u2502\n\u2502  REFERENCIA: fastapi_app.py l\u00edneas 100-107                                      \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo valido inputs complejos (10+ features) sin c\u00f3digo manual?    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Validaci\u00f3n manual = bugs, inconsistencias, c\u00f3digo repetido             \u2502\n\u2502  DECISI\u00d3N: Pydantic con Field validators para cada feature                      \u2502\n\u2502  RESULTADO: Validaci\u00f3n autom\u00e1tica, errores descriptivos, docs auto-generadas    \u2502\n\u2502  REFERENCIA: fastapi_app.py l\u00edneas 128-155 (CustomerData)                       \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo expongo m\u00e9tricas para Prometheus sin acoplar el c\u00f3digo?      \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Sin m\u00e9tricas = volar ciego en producci\u00f3n                               \u2502\n\u2502  DECISI\u00d3N: prometheus_client con try/except (graceful degradation)              \u2502\n\u2502  RESULTADO: M\u00e9tricas si est\u00e1 disponible, fallback a JSON si no                  \u2502\n\u2502  REFERENCIA: fastapi_app.py l\u00edneas 25-46, 284-297                               \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/14_FASTAPI/#1462-anatomia-de-appfastapi_apppy","title":"14.6.2 \ud83d\udd0d Anatom\u00eda de <code>app/fastapi_app.py</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/BankChurn-Predictor/app/fastapi_app.py</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Importaciones con Graceful Degradation\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ntry:\n    from prometheus_client import Counter, Histogram, generate_latest\n    PROMETHEUS_AVAILABLE = True\n\n    REQUEST_COUNT = Counter(\n        \"bankchurn_requests_total\",        # Nombre de la m\u00e9trica.\n        \"Total HTTP requests\",             # Descripci\u00f3n.\n        [\"method\", \"endpoint\", \"status\"],  # Labels para filtrar.\n    )\n    REQUEST_LATENCY = Histogram(\n        \"bankchurn_request_duration_seconds\",\n        \"Request latency in seconds\",\n        [\"endpoint\"],\n        buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],  # Buckets para percentiles.\n    )\nexcept ImportError:\n    PROMETHEUS_AVAILABLE = False\n# \u00bfPor qu\u00e9 try/except para m\u00e9tricas?\n# - prometheus_client es opcional (puede no estar instalado en dev).\n# - La API sigue funcionando sin m\u00e9tricas, pero las tiene si est\u00e1n disponibles.\n# - Patr\u00f3n \"graceful degradation\": funcionalidad reducida pero sin crash.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Lifecycle Management (Carga de Modelo)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\npredictor: Optional[ChurnPredictor] = None   # Variable global para el modelo.\n\n@contextlib.asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Manage application lifecycle.\"\"\"\n    global predictor\n    success = load_model_logic()            # Carga modelo al iniciar.\n    if not success:\n        logger.warning(\"Application started without model loaded.\")\n        # NO crashea la app. Endpoint /predict devolver\u00e1 503.\n    yield                                    # App corriendo.\n    # Cleanup al cerrar (opcional).\n# \u00bfPor qu\u00e9 lifespan y no @app.on_event(\"startup\")?\n# - on_event est\u00e1 deprecated en FastAPI &gt;= 0.93.\n# - lifespan es el patr\u00f3n moderno recomendado.\n# - Permite cleanup al cerrar (conexiones DB, etc.).\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: Schemas Pydantic con Validaci\u00f3n Estricta\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nclass CustomerData(BaseModel):\n    \"\"\"Schema para datos de cliente.\"\"\"\n\n    CreditScore: int = Field(..., ge=300, le=850)  # ...: required. ge/le: rangos.\n    Geography: str = Field(...)\n    Gender: str = Field(...)\n    Age: int = Field(..., ge=18, le=100)\n    Balance: float = Field(..., ge=0)\n    # ... m\u00e1s campos ...\n\n    @validator(\"Geography\")\n    def validate_geography(cls, v):\n        valid = [\"France\", \"Spain\", \"Germany\"]\n        if v not in valid:\n            raise ValueError(f\"Geography must be one of: {valid}\")\n        return v\n# \u00bfPor qu\u00e9 validators personalizados?\n# - Field solo valida tipos y rangos num\u00e9ricos.\n# - @validator permite validaci\u00f3n de dominio (pa\u00edses v\u00e1lidos, formatos, etc.).\n# - Error messages claros para el consumidor de la API.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 4: Endpoint /health (Liveness + Readiness)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n@app.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    uptime = time.time() - start_time\n    return HealthResponse(\n        status=\"healthy\" if predictor is not None else \"degraded\",\n        model_loaded=predictor is not None,  # Kubernetes readiness check usa esto.\n        uptime_seconds=uptime,\n        version=\"1.0.0\",\n    )\n# \u00bfPor qu\u00e9 \"degraded\" en lugar de \"unhealthy\"?\n# - \"unhealthy\" har\u00eda que K8s mate el pod (liveness fail).\n# - \"degraded\" indica que funciona pero con capacidad reducida.\n# - El pod sigue vivo, el equipo puede investigar.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 5: Endpoint /predict con M\u00e9tricas\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict_churn(customer: CustomerData):\n    if predictor is None:\n        if PROMETHEUS_AVAILABLE:\n            REQUEST_COUNT.labels(method=\"POST\", endpoint=\"/predict\", status=\"503\").inc()\n        raise HTTPException(status_code=503, detail=\"Model not available\")\n\n    start_pred = time.time()\n    try:\n        customer_dict = customer.dict()      # Pydantic model \u2192 dict.\n        df = pd.DataFrame([customer_dict])   # dict \u2192 DataFrame (1 fila).\n\n        results = predictor.predict(df, include_proba=True)\n\n        prob = float(results.iloc[0][\"probability\"])  # float() evita numpy.float64.\n        pred = int(results.iloc[0][\"prediction\"])     # int() evita numpy.int64.\n\n        pred_time = time.time() - start_pred\n\n        # Track metrics\n        if PROMETHEUS_AVAILABLE:\n            REQUEST_COUNT.labels(method=\"POST\", endpoint=\"/predict\", status=\"200\").inc()\n            REQUEST_LATENCY.labels(endpoint=\"/predict\").observe(pred_time)\n\n        return PredictionResponse(...)\n    except Exception as e:\n        logger.error(f\"Prediction error: {e}\")\n        raise HTTPException(status_code=500, detail=str(e))\n# \u00bfPor qu\u00e9 float() y int() expl\u00edcitos?\n# - numpy.float64 no es JSON-serializable directamente.\n# - FastAPI/Pydantic pueden fallar al serializar tipos numpy.\n# - Convertir a tipos nativos de Python evita \"Object of type float64 is not JSON serializable\".\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 6: Endpoint /predict_batch (Optimizaci\u00f3n para Volumen)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n@app.post(\"/predict_batch\", response_model=BatchPredictionResponse)\nasync def predict_batch(batch_data: BatchCustomerData):\n    # Vectoriza predicciones para eficiencia.\n    df = pd.DataFrame([c.dict() for c in batch_data.customers])\n    results = predictor.predict(df, include_proba=True)  # 1 llamada, N resultados.\n    # ...\n# \u00bfPor qu\u00e9 endpoint separado para batch?\n# - 1 request con 1000 clientes es m\u00e1s eficiente que 1000 requests de 1.\n# - El modelo puede vectorizar (GPU/CPU SIMD) las predicciones.\n# - Menor overhead de red y serializaci\u00f3n.\n</code></pre>"},{"location":"docs/14_FASTAPI/#1463-laboratorio-de-replicacion","title":"14.6.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Implementar tu propia API de predicci\u00f3n con m\u00e9tricas.</p> <ol> <li> <p>Crea el schema de request:    <pre><code># schemas.py\nfrom pydantic import BaseModel, Field, validator\n\nclass CustomerRequest(BaseModel):\n    credit_score: int = Field(..., ge=300, le=850)\n    age: int = Field(..., ge=18, le=100)\n    # A\u00f1ade m\u00e1s campos seg\u00fan tu modelo\n\n    @validator(\"credit_score\")\n    def score_must_be_realistic(cls, v):\n        if v &lt; 300:\n            raise ValueError(\"Credit score too low\")\n        return v\n</code></pre></p> </li> <li> <p>Implementa el lifecycle:    <pre><code># app.py\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    global model\n    model = joblib.load(\"models/best_model.pkl\")\n    yield\n    model = None  # Cleanup\n\napp = FastAPI(lifespan=lifespan)\n</code></pre></p> </li> <li> <p>A\u00f1ade m\u00e9tricas Prometheus:    <pre><code>from prometheus_client import Counter, generate_latest\n\nPREDICTIONS = Counter(\"predictions_total\", \"Total predictions\", [\"result\"])\n\n@app.post(\"/predict\")  # Endpoint POST para predicciones.\nasync def predict(request: CustomerRequest):\n    # ... predicci\u00f3n ...\n    PREDICTIONS.labels(result=\"churn\" if pred == 1 else \"no_churn\").inc()\n    return {\"prediction\": pred}\n</code></pre></p> </li> </ol>"},{"location":"docs/14_FASTAPI/#1464-troubleshooting-preventivo","title":"14.6.4 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n \"Object of type float64 is not JSON serializable\" Retornas tipos numpy sin convertir Usa <code>float(value)</code>, <code>int(value)</code> antes de retornar. 503 \"Model not available\" Modelo no se carg\u00f3 en startup Verifica path del modelo y logs de startup. 422 Unprocessable Entity Request no cumple schema Pydantic Revisa el error detallado en response body. Latencia alta en /predict Modelo se carga en cada request Mueve carga a <code>lifespan</code>, guarda en variable global. M\u00e9tricas no aparecen en /metrics prometheus_client no instalado <code>pip install prometheus_client</code> o verifica try/except."},{"location":"docs/14_FASTAPI/#errores-habituales-y-como-depurarlos-en-fastapi-para-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en FastAPI para ML","text":"<p>FastAPI te da mucho \u201cgratis\u201d, pero en APIs de ML los fallos suelen venir de modelos no cargados, esquemas desalineados o problemas de tipos/serializaci\u00f3n.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/14_FASTAPI/#1-el-modelo-no-se-carga-503-constantes","title":"1) El modelo no se carga (503 constantes)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El endpoint <code>/predict</code> responde <code>503 Modelo no disponible</code>.</li> <li>Logs con mensajes tipo <code>Modelo no encontrado</code> o <code>Ning\u00fan modelo encontrado</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa la funci\u00f3n <code>lifespan</code> o c\u00f3digo de startup: \u00bfla ruta del modelo (<code>models/</code>, <code>artifacts/</code>) existe dentro del contenedor?</li> <li>Comprueba variables de entorno como <code>MODEL_PATH</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Asegura rutas consistentes entre entrenamiento, Dockerfile y FastAPI.</li> <li>En local, imprime (<code>logger.info</code>) la ruta exacta desde la que intentas cargar y verifica que el archivo est\u00e9 ah\u00ed.</li> </ul>"},{"location":"docs/14_FASTAPI/#2-esquema-pydantic-desalineado-con-el-pipeline","title":"2) Esquema Pydantic desalineado con el pipeline","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores <code>KeyError</code> o <code>Column not found</code> al predecir.</li> <li>El modelo espera columnas con ciertos nombres pero el <code>PredictionRequest</code> usa otros.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara los campos del schema (<code>CreditScore</code>, <code>Geography</code>, etc.) con las columnas que el pipeline de sklearn espera.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa los mismos nombres de features que en el training pipeline.</li> <li>Si renombraste columnas en feature engineering, refleja esos cambios en el schema y en la transformaci\u00f3n de entrada antes de llamar al modelo.</li> </ul>"},{"location":"docs/14_FASTAPI/#3-problemas-de-tipos-y-serializacion","title":"3) Problemas de tipos y serializaci\u00f3n","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores <code>TypeError: Object of type ... is not JSON serializable</code>.</li> <li>Respuestas con valores <code>NaN</code> o <code>Infinity</code> que rompen el cliente.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el tipo real de lo que devuelves en <code>PredictionResponse</code> (por ejemplo, <code>numpy.float32</code> en vez de <code>float</code>).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Convierte expl\u00edcitamente a tipos nativos de Python (<code>float</code>, <code>int</code>, <code>str</code>).</li> <li>Aseg\u00farate de que no devuelves <code>NaN</code> o <code>inf</code> (redondea o reemplaza por valores v\u00e1lidos).</li> </ul>"},{"location":"docs/14_FASTAPI/#4-cors-o-healthcheck-mal-configurados","title":"4) CORS o healthcheck mal configurados","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El frontend no puede llamar al API por errores de CORS.</li> <li>Kubernetes/Compose marcan el servicio como unhealthy.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa configuraci\u00f3n de <code>CORSMiddleware</code> y el endpoint <code>/health</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>En desarrollo puedes usar <code>allow_origins=[\"*\"]</code>, pero en producci\u00f3n limita a tus dominios.</li> <li>Verifica que <code>/health</code> no dependa de modelos pesados para responder r\u00e1pido y con 200.</li> </ul>"},{"location":"docs/14_FASTAPI/#5-patron-general-de-debugging-en-apis-de-ml","title":"5) Patr\u00f3n general de debugging en APIs de ML","text":"<ol> <li>Llama al endpoint con <code>curl</code> o <code>httpie</code> usando el <code>example</code> del schema.</li> <li>Mira los logs del servidor (uvicorn) para ver tracebacks completos.</li> <li>Verifica rutas de modelo y variables de entorno que afectan al loading.</li> <li>Aseg\u00farate de que lo que entra/sale del API coincide con lo que tu modelo entrenado espera.</li> </ol> <p>Con esta disciplina, tu API FastAPI pasar\u00e1 de \u201cfunciona solo en local\u201d a estar lista para producci\u00f3n.</p> <p></p>"},{"location":"docs/14_FASTAPI/#ejercicio","title":"\u2705 Ejercicio","text":"<ol> <li>Implementa <code>/predict/batch</code> para procesar m\u00faltiples clientes</li> <li>A\u00f1ade endpoint <code>/model/info</code> que retorne metadata del modelo</li> <li>Implementa rate limiting b\u00e1sico</li> </ol>"},{"location":"docs/14_FASTAPI/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se Us\u00f3 en el Portafolio","text":"<p>Cada proyecto tiene una API FastAPI en <code>app/fastapi_app.py</code>:</p>"},{"location":"docs/14_FASTAPI/#api-de-bankchurn","title":"API de BankChurn","text":"<pre><code># BankChurn-Predictor/app/fastapi_app.py (estructura)\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(title=\"BankChurn Predictor API\")\n\nclass PredictionRequest(BaseModel):\n    CreditScore: int\n    Geography: str\n    Gender: str\n    Age: int\n    Balance: float\n    # ... m\u00e1s features\n\nclass PredictionResponse(BaseModel):\n    prediction: int\n    probability: float\n    risk_level: str\n\n@app.get(\"/health\")  # Endpoint GET para health check.\nasync def health():\n    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n\n@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    features = request.dict()\n    df = pd.DataFrame([features])\n    prediction = pipeline.predict(df)[0]\n    probability = pipeline.predict_proba(df)[0, 1]\n    return PredictionResponse(\n        prediction=int(prediction),\n        probability=float(probability),\n        risk_level=\"high\" if probability &gt; 0.7 else \"low\"\n    )\n</code></pre>"},{"location":"docs/14_FASTAPI/#apis-por-proyecto","title":"APIs por Proyecto","text":"Proyecto Endpoint Principal Tipo BankChurn <code>/predict</code> Clasificaci\u00f3n binaria CarVision <code>/predict</code> Regresi\u00f3n TelecomAI <code>/predict</code> Clasificaci\u00f3n multiclase"},{"location":"docs/14_FASTAPI/#ejercicio-prueba-las-apis-reales","title":"\ud83d\udd27 Ejercicio: Prueba las APIs Reales","text":"<pre><code># 1. Inicia API de BankChurn\ncd BankChurn-Predictor\nuvicorn app.fastapi_app:app --reload\n\n# 2. Prueba con curl\ncurl http://localhost:8000/health\n\ncurl -X POST http://localhost:8000/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"CreditScore\": 650, \"Geography\": \"France\", ...}'\n\n# 3. Ve docs interactivos\n# http://localhost:8000/docs\n</code></pre>"},{"location":"docs/14_FASTAPI/#checkpoint","title":"\u2705 Checkpoint","text":"<ul> <li>[ ] <code>/health</code> responde r\u00e1pido (no hace inferencia ni carga pesada)</li> <li>[ ] <code>/predict</code> valida request/response con Pydantic</li> <li>[ ] Devuelves tipos nativos (sin <code>numpy.float32</code>, sin <code>NaN/inf</code>)</li> <li>[ ] Errores esperables se manejan con <code>HTTPException</code> y c\u00f3digos correctos</li> <li>[ ] <code>/docs</code> y <code>/openapi.json</code> son accesibles</li> </ul>"},{"location":"docs/14_FASTAPI/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/14_FASTAPI/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Pydantic + FastAPI: Explica c\u00f3mo la validaci\u00f3n autom\u00e1tica reduce c\u00f3digo.</p> </li> <li> <p>Async vs Sync: Cu\u00e1ndo usar cada uno (IO-bound vs CPU-bound).</p> </li> <li> <p>OpenAPI/Swagger: Documentaci\u00f3n autom\u00e1tica como feature de FastAPI.</p> </li> </ol>"},{"location":"docs/14_FASTAPI/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo ML Serving Carga modelo en startup, no en cada request Validaci\u00f3n Usa Pydantic para input/output schemas Errores HTTPException con c\u00f3digos y mensajes claros Producci\u00f3n Gunicorn + Uvicorn workers"},{"location":"docs/14_FASTAPI/#endpoints-esenciales-para-ml","title":"Endpoints Esenciales para ML","text":"<pre><code>/health          \u2192 Liveness check\n/ready           \u2192 Readiness check (modelo cargado)\n/predict         \u2192 Inferencia principal\n/predict/batch   \u2192 Inferencia batch\n/model/info      \u2192 Versi\u00f3n, m\u00e9tricas, metadata\n</code></pre>"},{"location":"docs/14_FASTAPI/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/14_FASTAPI/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 FastAPI Full Course Sebasti\u00e1n Ram\u00edrez 1h YouTube \ud83d\udd34 ML APIs with FastAPI ArjanCodes 30 min YouTube \ud83d\udfe1 Pydantic V2 Tutorial ArjanCodes 25 min YouTube"},{"location":"docs/14_FASTAPI/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 FastAPI Docs Documentaci\u00f3n oficial \ud83d\udfe1 Pydantic v2 Validaci\u00f3n de datos"},{"location":"docs/14_FASTAPI/#decision-tecnica-adr-004-fastapi","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-004 FastAPI","text":"<p>Contexto: Necesitamos framework para APIs de inferencia ML.</p> <p>Decisi\u00f3n: Usar FastAPI como framework para todas las APIs.</p> <p>Alternativas Consideradas: - Flask: Simple pero sync, validaci\u00f3n manual - Django REST: Overkill para microservicios ML - gRPC: M\u00e1s r\u00e1pido pero m\u00e1s complejo</p> <p>Consecuencias: - \u2705 Validaci\u00f3n autom\u00e1tica con Pydantic - \u2705 Docs OpenAPI auto-generadas - \u2705 Async nativo para alto throughput - \u274c Framework relativamente nuevo</p>"},{"location":"docs/14_FASTAPI/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/14_FASTAPI/#ejercicio-141-schemas-pydantic","title":"Ejercicio 14.1: Schemas Pydantic","text":"<p>Objetivo: Definir schemas de request/response. Dificultad: \u2b50\u2b50</p> <pre><code>from pydantic import BaseModel, Field\n\n# TU TAREA: Crear schemas para endpoint /predict\n# Request: customer features\n# Response: prediction + probability + model_version\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass PredictRequest(BaseModel):\n    \"\"\"Schema de entrada para predicci\u00f3n.\"\"\"\n    credit_score: int = Field(..., ge=300, le=850, description=\"Credit score\")\n    age: int = Field(..., ge=18, le=100, description=\"Customer age\")\n    tenure: int = Field(..., ge=0, le=50, description=\"Years as customer\")\n    balance: float = Field(..., ge=0, description=\"Account balance\")\n    num_products: int = Field(..., ge=1, le=4, description=\"Number of products\")\n    has_credit_card: bool = Field(default=True)\n    is_active_member: bool = Field(default=True)\n\n    model_config = {\n        \"json_schema_extra\": {\n            \"examples\": [{\n                \"credit_score\": 650,\n                \"age\": 35,\n                \"tenure\": 5,\n                \"balance\": 50000.0,\n                \"num_products\": 2,\n                \"has_credit_card\": True,\n                \"is_active_member\": True\n            }]\n        }\n    }\n\nclass PredictResponse(BaseModel):\n    \"\"\"Schema de salida para predicci\u00f3n.\"\"\"\n    prediction: int = Field(..., description=\"0=No churn, 1=Churn\")\n    probability: float = Field(..., ge=0, le=1, description=\"Churn probability\")\n    risk_level: str = Field(..., description=\"low/medium/high\")\n    model_version: str = Field(..., description=\"Model version used\")\n\n    model_config = {\n        \"json_schema_extra\": {\n            \"examples\": [{\n                \"prediction\": 1,\n                \"probability\": 0.73,\n                \"risk_level\": \"high\",\n                \"model_version\": \"1.2.0\"\n            }]\n        }\n    }\n</code></pre>"},{"location":"docs/14_FASTAPI/#ejercicio-142-endpoint-completo","title":"Ejercicio 14.2: Endpoint Completo","text":"<p>Objetivo: Implementar endpoint /predict con manejo de errores. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># TU TAREA: Implementar endpoint que:\n# 1. Reciba PredictRequest validado\n# 2. Cargue modelo (cached)\n# 3. Haga predicci\u00f3n\n# 4. Devuelva PredictResponse\n# 5. Maneje errores apropiadamente\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>from fastapi import FastAPI, HTTPException\nfrom functools import lru_cache\nimport joblib\n\napp = FastAPI(title=\"Churn Prediction API\")\n\n@lru_cache()\ndef load_model():\n    \"\"\"Carga modelo una sola vez.\"\"\"\n    try:\n        return joblib.load(\"artifacts/model.joblib\")\n    except FileNotFoundError:\n        raise RuntimeError(\"Model not found\")\n\n@app.get(\"/health\")  # Endpoint GET para health check.\nasync def health():\n    return {\"status\": \"healthy\"}  # Respuesta JSON indicando que el servicio est\u00e1 activo.\n\n@app.post(\"/predict\", response_model=PredictResponse)\nasync def predict(request: PredictRequest):\n    \"\"\"Predice probabilidad de churn.\"\"\"\n    try:\n        model = load_model()\n    except RuntimeError as e:\n        raise HTTPException(status_code=503, detail=str(e))\n\n    # Preparar features\n    features = [[\n        request.credit_score,\n        request.age,\n        request.tenure,\n        request.balance,\n        request.num_products,\n        int(request.has_credit_card),\n        int(request.is_active_member)\n    ]]\n\n    try:\n        prediction = int(model.predict(features)[0])\n        probability = float(model.predict_proba(features)[0][1])\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Prediction error: {e}\")\n\n    # Determinar nivel de riesgo\n    risk_level = \"high\" if probability &gt; 0.7 else \"medium\" if probability &gt; 0.3 else \"low\"\n\n    return PredictResponse(\n        prediction=prediction,\n        probability=probability,\n        risk_level=risk_level,\n        model_version=\"1.0.0\"\n    )\n</code></pre>"},{"location":"docs/14_FASTAPI/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n FastAPI Framework web async para APIs Python con validaci\u00f3n autom\u00e1tica Pydantic Librer\u00eda de validaci\u00f3n de datos usando type hints OpenAPI Especificaci\u00f3n est\u00e1ndar para documentar APIs (antes Swagger) @lru_cache Decorator para cachear resultados de funciones"},{"location":"docs/14_FASTAPI/#la-trampa-errores-comunes-de-este-modulo","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes de Este M\u00f3dulo","text":""},{"location":"docs/14_FASTAPI/#trampa-1-api-sin-validacion-de-entrada","title":"Trampa 1: API sin validaci\u00f3n de entrada","text":"<p>S\u00edntoma: <pre><code>@app.post(\"/predict\")\ndef predict(data: dict):  # \u274c Acepta cualquier cosa\n    return model.predict(data[\"features\"])\n</code></pre></p> <p>Soluci\u00f3n: <pre><code>from pydantic import BaseModel, Field\n\nclass PredictRequest(BaseModel):\n    features: list[float] = Field(..., min_items=4, max_items=4)\n\n@app.post(\"/predict\")\ndef predict(request: PredictRequest):  # \u2705 Validado\n    return model.predict([request.features])\n</code></pre></p>"},{"location":"docs/14_FASTAPI/#trampa-2-modelo-cargado-en-cada-request","title":"Trampa 2: Modelo cargado en cada request","text":"<p>S\u00edntoma: API lenta porque carga el modelo en cada request.</p> <p>Soluci\u00f3n: <pre><code>@app.on_event(\"startup\")\nasync def load_model():\n    global model\n    model = joblib.load(\"model.pkl\")\n\n# O con dependency injection\nfrom functools import lru_cache\n\n@lru_cache\ndef get_model():\n    return joblib.load(\"model.pkl\")\n\n@app.post(\"/predict\")\ndef predict(request: PredictRequest, model = Depends(get_model)):\n    return model.predict(...)\n</code></pre></p>"},{"location":"docs/14_FASTAPI/#trampa-3-logs-sin-contexto-de-request","title":"Trampa 3: Logs sin contexto de request","text":"<p>S\u00edntoma: Logs sin forma de correlacionar qu\u00e9 request fall\u00f3.</p> <p>Soluci\u00f3n: A\u00f1adir request_id con middleware: <pre><code>class RequestIDMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request, call_next):\n        request_id = str(uuid.uuid4())[:8]\n        with logger.contextualize(request_id=request_id):\n            response = await call_next(request)\n            response.headers[\"X-Request-ID\"] = request_id\n        return response\n</code></pre></p>"},{"location":"docs/14_FASTAPI/#quiz-del-modulo-semanas-19-20","title":"\ud83d\udcdd Quiz del M\u00f3dulo \u2014 Semanas 19-20","text":""},{"location":"docs/14_FASTAPI/#quiz-semana-19-fastapi","title":"Quiz Semana 19: FastAPI","text":""},{"location":"docs/14_FASTAPI/#pregunta-1-25-pts","title":"Pregunta 1 (25 pts)","text":"<p>\u00bfPor qu\u00e9 usar Pydantic schemas en lugar de <code>dict</code> para requests?</p> \u2705 Respuesta  1. **Validaci\u00f3n autom\u00e1tica**: Tipos, rangos, formatos 2. **Documentaci\u00f3n**: OpenAPI generada autom\u00e1ticamente 3. **Seguridad**: Rechaza payloads malformados antes de llegar al c\u00f3digo 4. **Autocompletado**: IDE sabe qu\u00e9 campos existen"},{"location":"docs/14_FASTAPI/#pregunta-2-25-pts","title":"Pregunta 2 (25 pts)","text":"<p>\u00bfC\u00f3mo evitas cargar el modelo en cada request?</p> \u2705 Respuesta  Usar `@app.on_event(\"startup\")` o `@lru_cache`: <pre><code>@lru_cache\ndef get_model():\n    return joblib.load(\"model.pkl\")\n\n@app.post(\"/predict\")\ndef predict(model = Depends(get_model)):\n    ...\n</code></pre>"},{"location":"docs/14_FASTAPI/#pregunta-3-25-pts","title":"Pregunta 3 (25 pts)","text":"<p>\u00bfPor qu\u00e9 es importante el endpoint <code>/health</code>?</p> \u2705 Respuesta  1. **Load balancers**: Verifican si el servicio est\u00e1 vivo 2. **Kubernetes**: Probes de readiness/liveness 3. **Monitoring**: Alertas si el servicio no responde 4. **Debugging**: Verificar conectividad b\u00e1sica"},{"location":"docs/14_FASTAPI/#ejercicio-practico-25-pts","title":"\ud83d\udd27 Ejercicio Pr\u00e1ctico (25 pts)","text":"<p>Crea un endpoint <code>/predict</code> con schema de entrada validado (age 18-100, balance \u22650) y respuesta estructurada (prediction, probability, risk_level).</p> \u2705 Soluci\u00f3n <pre><code>from pydantic import BaseModel, Field\nfrom fastapi import FastAPI\n\nclass PredictRequest(BaseModel):\n    age: int = Field(..., ge=18, le=100)\n    balance: float = Field(..., ge=0)\n\nclass PredictResponse(BaseModel):\n    prediction: int\n    probability: float\n    risk_level: str\n\n@app.post(\"/predict\", response_model=PredictResponse)\ndef predict(request: PredictRequest):\n    features = [[request.age, request.balance]]\n    pred = model.predict(features)[0]\n    prob = model.predict_proba(features)[0][1]\n    risk = \"high\" if prob &gt; 0.7 else \"medium\" if prob &gt; 0.3 else \"low\"\n    return PredictResponse(prediction=pred, probability=prob, risk_level=risk)\n</code></pre>   **Siguiente m\u00f3dulo** \u2192 [15. Streamlit](15_STREAMLIT.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/15_STREAMLIT/","title":"15. Streamlit Dashboards para ML","text":""},{"location":"docs/15_STREAMLIT/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Tener Streamlit instalado y poder levantar una app (<code>streamlit run app/streamlit_app.py</code>).</li> <li>Conocer lo b\u00e1sico de pandas para cargar/filtrar DataFrames.</li> <li>Haber completado el m\u00f3dulo 14 (FastAPI) si tu dashboard consume un API (opcional, pero recomendado).</li> </ul>"},{"location":"docs/15_STREAMLIT/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de empezar: abre Protocolo E y define el output m\u00ednimo: un dashboard con caching y un predictor que responde.</li> <li>Durante el debugging: si te atoras &gt;15 min (caching, rutas de artefactos, reruns, performance), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar UX, performance y reproducibilidad (Docker/requirements).</li> </ul>"},{"location":"docs/15_STREAMLIT/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] App Streamlit levanta localmente y en contenedor (si aplica).</li> <li>[ ] Caching correcto: datos con <code>@st.cache_data</code> y modelo con <code>@st.cache_resource</code>.</li> <li>[ ] UI organizada (tabs o p\u00e1ginas) con al menos 2 vistas.</li> <li>[ ] Un predictor (formulario) que ejecuta inferencia y muestra salida.</li> <li>[ ] Visualizaci\u00f3n interactiva (ideal: Plotly) para m\u00e9tricas o an\u00e1lisis.</li> </ul>"},{"location":"docs/15_STREAMLIT/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Concepto: UX + performance (caching) + separaci\u00f3n carga/visualizaci\u00f3n</li> <li>Archivo: <code>app/streamlit_app.py</code></li> <li>Prueba: <code>streamlit run app/streamlit_app.py</code></li> </ul>"},{"location":"docs/15_STREAMLIT/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Construir dashboards interactivos profesionales como el de CarVision. <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  Streamlit = La forma m\u00e1s r\u00e1pida de crear UIs para ML                        \u2551\n\u2551                                                                              \u2551\n\u2551  \u2705 Python puro (sin HTML/CSS/JS)                                            \u2551\n\u2551  \u2705 Reactivo (cambios autom\u00e1ticos)                                           \u2551\n\u2551  \u2705 Widgets interactivos                                                     \u2551\n\u2551  \u2705 Integraci\u00f3n con pandas/plotly                                            \u2551\n\u2551  \u2705 Deploy f\u00e1cil                                                             \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n\n---\n\n## \ud83d\udccb Contenido\n\n - **0.0** [Prerrequisitos](#00-prerrequisitos)\n - **0.1** [Protocolo E: C\u00f3mo estudiar este m\u00f3dulo](#01-protocolo-e-como-estudiar-este-modulo)\n - **0.2** [Entregables verificables (m\u00ednimo viable)](#02-entregables-verificables-minimo-viable)\n - **0.3** [Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)](#03-puente-teoria-codigo-portafolio)\n - **15.1** [Estructura de un Dashboard ML](#151-estructura-de-un-dashboard-ml)\n - **15.2** [Caching para Performance](#152-caching-para-performance)\n - **15.3** [Tabs y Secciones](#153-tabs-y-secciones)\n - **15.4** [Visualizaciones con Plotly](#154-visualizaciones-con-plotly)\n - **15.5** [Predictor Interactivo](#155-predictor-interactivo)\n - **15.6** [Dashboard Avanzado: Visualizaciones Profesionales](#156-dashboard-avanzado-visualizaciones-profesionales)\n - [Errores habituales](#errores-habituales)\n - [\u2705 Checkpoint](#checkpoint)\n - [\u2705 Ejercicio](#ejercicio)\n\n---\n\n&lt;a id=\"151-estructura-de-un-dashboard-ml\"&gt;&lt;/a&gt;\n\n\n### \ud83e\udde0 Mapa Mental de Conceptos: 15.1 Estructura de un Dashboard ML\n\n**T\u00e9rminos clave que debes dominar para este tema:**\n- Revisa los conceptos principales en la secci\u00f3n siguiente\n- Practica con los ejercicios del portafolio\n- Aplica los conocimientos en BankChurn-Predictor\n\n---\n\n\n\n### \ud83d\udcbb Ejercicio Puente: Dashboards\n\n&gt; **Meta**: Practica el concepto antes de aplicarlo al portafolio.\n\n**Ejercicio b\u00e1sico:**\n1. Lee la secci\u00f3n te\u00f3rica siguiente\n2. Identifica los patrones clave del c\u00f3digo de ejemplo\n3. Replica el patr\u00f3n en un proyecto de prueba\n\n---\n\n### \ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Streamlit en BankChurn\n\n&gt; **Tarea**: Aplicar este m\u00f3dulo en BankChurn-Predictor.\n\n```bash\ncd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Dashboards\n</code></pre></p> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/15_STREAMLIT/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Streamlit?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Dashboards, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/15_STREAMLIT/#151-estructura-de-un-dashboard-ml","title":"15.1 Estructura de un Dashboard ML","text":""},{"location":"docs/15_STREAMLIT/#arquitectura-del-dashboard-carvision","title":"Arquitectura del Dashboard CarVision","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     CarVision Dashboard                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u2502\n\u2502  \u2502  Overview   \u2502 \u2502   Market    \u2502 \u2502   Model     \u2502 \u2502    Price    \u2502            \u2502\n\u2502  \u2502   (KPIs)    \u2502 \u2502  Analysis   \u2502 \u2502  Metrics    \u2502 \u2502  Predictor  \u2502            \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2502\n\u2502                                                                             \u2502\n\u2502  TAB 1: Overview                TAB 2: Market Analysis                      \u2502\n\u2502  \u2022 Total vehicles               \u2022 Investment recommendations                \u2502\n\u2502  \u2022 Average price                \u2022 Risk assessment                           \u2502\n\u2502  \u2022 Price distribution           \u2022 Market trends                             \u2502\n\u2502                                                                             \u2502\n\u2502  TAB 3: Model Metrics           TAB 4: Price Predictor                      \u2502\n\u2502  \u2022 RMSE, MAE, R\u00b2, MAPE         \u2022 Input form                                 \u2502\n\u2502  \u2022 Bootstrap confidence         \u2022 Single prediction                         \u2502\n\u2502  \u2022 Temporal backtest            \u2022 Gauge visualization                       \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/15_STREAMLIT/#codigo-base","title":"C\u00f3digo Base","text":"<pre><code># app/streamlit_app.py - Estructura b\u00e1sica\n\nimport streamlit as st                   # Framework para dashboards interactivos.\nimport pandas as pd                      # DataFrames para datos.\nimport joblib                            # Cargar modelos serializados.\nfrom pathlib import Path                 # Rutas multiplataforma.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# PAGE CONFIG (debe ser la primera llamada Streamlit)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nst.set_page_config(                      # Configura metadata de la p\u00e1gina.\n    page_title=\"CarVision Market Intelligence\",  # T\u00edtulo en tab del browser.\n    page_icon=\"\ud83d\ude97\",                      # Favicon.\n    layout=\"wide\",                       # Usa todo el ancho de pantalla.\n    initial_sidebar_state=\"expanded\"     # Sidebar abierto por defecto.\n)\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CACHING: Cargar datos y modelo UNA vez\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@st.cache_data                           # Decorator: cachea resultado de la funci\u00f3n.\ndef load_data():                         # Se ejecuta UNA vez; luego retorna del cache.\n    \"\"\"Carga dataset - cached para performance.\"\"\"\n    path = Path(\"data/raw/vehicles_us.csv\")  # Ruta al archivo de datos.\n    if path.exists():\n        return pd.read_csv(path)         # CSV \u2192 DataFrame.\n    return None                          # None si no existe (manejo graceful).\n\n\n@st.cache_resource                       # cache_resource: para objetos no serializables.\ndef load_model():                        # Modelos, conexiones DB, etc.\n    \"\"\"Carga modelo - cached para no recargar en cada interacci\u00f3n.\"\"\"\n    path = Path(\"artifacts/model.joblib\")  # Ruta al modelo serializado.\n    if path.exists():\n        return joblib.load(path)         # Deserializa el pipeline completo.\n    return None\n\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# MAIN APP\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ndef main():\n    st.title(\"\ud83d\ude97 CarVision Market Intelligence\")  # T\u00edtulo principal H1.\n    st.markdown(\"*An\u00e1lisis de mercado y predicci\u00f3n de precios de veh\u00edculos*\")\n\n    # Cargar datos (desde cache despu\u00e9s de primera carga)\n    df = load_data()                     # Instant\u00e1neo gracias al cache.\n    model = load_model()\n\n    if df is None:                       # Validaci\u00f3n defensiva.\n        st.error(\"\u274c No se encontr\u00f3 el dataset\")  # Muestra error en rojo.\n        return\n\n    # Tabs para organizar contenido\n    tab1, tab2, tab3, tab4 = st.tabs([   # Crea 4 pesta\u00f1as.\n        \"\ud83d\udcca Overview\",\n        \"\ud83d\udcc8 Market Analysis\", \n        \"\ud83c\udfaf Model Metrics\",\n        \"\ud83d\udcb0 Price Predictor\"\n    ])\n\n    with tab1:                           # Context manager: contenido del tab.\n        render_overview(df)\n\n    with tab2:\n        render_market_analysis(df)\n\n    with tab3:\n        render_model_metrics()\n\n    with tab4:\n        render_price_predictor(model, df)\n\n\nif __name__ == \"__main__\":               # Solo ejecuta si es script principal.\n    main()\n</code></pre>"},{"location":"docs/15_STREAMLIT/#152-caching-para-performance","title":"15.2 Caching para Performance","text":""},{"location":"docs/15_STREAMLIT/#stcache_data-vs-stcache_resource","title":"@st.cache_data vs @st.cache_resource","text":"<pre><code># @st.cache_data: Para DATOS (DataFrames, listas, dicts)\n# Se serializa y almacena. Inmutable.\n\n@st.cache_data(ttl=3600)                 # ttl=3600: cache expira despu\u00e9s de 1 hora (segundos).\ndef load_data():\n    df = pd.read_csv(\"data.csv\")         # Operaci\u00f3n costosa: solo se ejecuta 1 vez.\n    return df                            # Resultado se serializa y almacena.\n\n@st.cache_data                           # Sin ttl: cache infinito hasta reiniciar app.\ndef compute_statistics(df):              # df es parte del \"cache key\".\n    \"\"\"C\u00e1lculos pesados - cached.\"\"\"\n    return {                             # Diccionario serializable.\n        \"mean\": df[\"price\"].mean(),\n        \"median\": df[\"price\"].median(),\n        \"std\": df[\"price\"].std(),\n    }\n\n\n# @st.cache_resource: Para RECURSOS (modelos, conexiones DB)\n# No se serializa. Se mantiene la referencia al objeto.\n\n@st.cache_resource                       # Para objetos que NO se pueden serializar.\ndef load_model():\n    return joblib.load(\"model.joblib\")   # Pipeline sklearn: objeto complejo.\n\n@st.cache_resource                       # Conexiones DB: mantener viva la conexi\u00f3n.\ndef get_db_connection():\n    return create_engine(\"postgresql://...\")  # Engine SQLAlchemy.\n</code></pre>"},{"location":"docs/15_STREAMLIT/#patron-separar-carga-de-visualizacion","title":"Patr\u00f3n: Separar Carga de Visualizaci\u00f3n","text":"<pre><code># \u274c MALO: Carga datos cada vez que cambia un widget\ndef main():\n    filter_year = st.slider(\"A\u00f1o\", 2010, 2024)\n    df = pd.read_csv(\"data.csv\")  # Se ejecuta en cada interacci\u00f3n!\n    filtered = df[df[\"year\"] &gt;= filter_year]\n    st.dataframe(filtered)\n\n\n# \u2705 BUENO: Datos cargados una vez, filtrado es r\u00e1pido\n@st.cache_data\ndef load_data():\n    return pd.read_csv(\"data.csv\")\n\ndef main():\n    df = load_data()  # Cached - instant\u00e1neo despu\u00e9s de la primera carga\n\n    filter_year = st.slider(\"A\u00f1o\", 2010, 2024)\n    filtered = df[df[\"year\"] &gt;= filter_year]  # Operaci\u00f3n r\u00e1pida en memoria\n    st.dataframe(filtered)\n</code></pre>"},{"location":"docs/15_STREAMLIT/#153-tabs-y-secciones","title":"15.3 Tabs y Secciones","text":""},{"location":"docs/15_STREAMLIT/#tab-1-overview","title":"Tab 1: Overview","text":"<pre><code>def render_overview(df: pd.DataFrame):\n    \"\"\"Tab de resumen con KPIs principales.\"\"\"\n\n    st.header(\"\ud83d\udcca Portfolio Overview\")\n\n    # KPIs en columnas\n    col1, col2, col3, col4 = st.columns(4)\n\n    with col1:\n        st.metric(\n            label=\"Total Vehicles\",\n            value=f\"{len(df):,}\",\n            delta=None\n        )\n\n    with col2:\n        avg_price = df[\"price\"].mean()\n        st.metric(\n            label=\"Average Price\",\n            value=f\"${avg_price:,.0f}\",\n            delta=None\n        )\n\n    with col3:\n        median_price = df[\"price\"].median()\n        st.metric(\n            label=\"Median Price\",\n            value=f\"${median_price:,.0f}\",\n            delta=f\"{((avg_price - median_price) / median_price * 100):+.1f}% vs avg\"\n        )\n\n    with col4:\n        avg_age = 2024 - df[\"model_year\"].mean()\n        st.metric(\n            label=\"Avg Vehicle Age\",\n            value=f\"{avg_age:.1f} years\",\n            delta=None\n        )\n\n    st.divider()\n\n    # Distribuci\u00f3n de precios\n    st.subheader(\"Price Distribution\")\n\n    import plotly.express as px\n    fig = px.histogram(\n        df, \n        x=\"price\", \n        nbins=50,\n        title=\"Vehicle Price Distribution\"\n    )\n    fig.update_layout(\n        xaxis_title=\"Price ($)\",\n        yaxis_title=\"Count\"\n    )\n    st.plotly_chart(fig, use_container_width=True)\n</code></pre>"},{"location":"docs/15_STREAMLIT/#tab-3-model-metrics","title":"Tab 3: Model Metrics","text":"<pre><code>def render_model_metrics():\n    \"\"\"Tab de m\u00e9tricas del modelo.\"\"\"\n\n    st.header(\"\ud83c\udfaf Model Performance\")\n\n    # Cargar m\u00e9tricas\n    metrics_path = Path(\"artifacts/metrics.json\")\n    if not metrics_path.exists():\n        st.warning(\"\u26a0\ufe0f M\u00e9tricas no disponibles. Entrene el modelo primero.\")\n        return\n\n    import json\n    metrics = json.loads(metrics_path.read_text())\n\n    # Mostrar m\u00e9tricas principales\n    col1, col2, col3, col4 = st.columns(4)\n\n    with col1:\n        st.metric(\"RMSE\", f\"${metrics['rmse']:,.0f}\")\n    with col2:\n        st.metric(\"MAE\", f\"${metrics['mae']:,.0f}\")\n    with col3:\n        st.metric(\"R\u00b2\", f\"{metrics['r2']:.3f}\")\n    with col4:\n        st.metric(\"MAPE\", f\"{metrics['mape']:.1f}%\")\n\n    # Explicaci\u00f3n de m\u00e9tricas\n    with st.expander(\"\u2139\ufe0f \u00bfQu\u00e9 significan estas m\u00e9tricas?\"):\n        st.markdown(\"\"\"\n        - **RMSE** (Root Mean Square Error): Error promedio en d\u00f3lares. Menor es mejor.\n        - **MAE** (Mean Absolute Error): Error absoluto promedio. M\u00e1s interpretable que RMSE.\n        - **R\u00b2** (Coefficient of Determination): % de varianza explicada. 1.0 es perfecto.\n        - **MAPE** (Mean Absolute Percentage Error): Error porcentual promedio.\n        \"\"\")\n</code></pre>"},{"location":"docs/15_STREAMLIT/#154-visualizaciones-con-plotly","title":"15.4 Visualizaciones con Plotly","text":""},{"location":"docs/15_STREAMLIT/#graficos-interactivos","title":"Gr\u00e1ficos Interactivos","text":"<pre><code>import plotly.express as px\nimport plotly.graph_objects as go\n\ndef create_price_by_brand(df: pd.DataFrame):\n    \"\"\"Box plot de precios por marca.\"\"\"\n\n    # Top 10 marcas por volumen\n    top_brands = df[\"brand\"].value_counts().head(10).index\n    df_top = df[df[\"brand\"].isin(top_brands)]\n\n    fig = px.box(\n        df_top,\n        x=\"brand\",\n        y=\"price\",\n        title=\"Price Distribution by Brand (Top 10)\",\n        color=\"brand\"\n    )\n\n    fig.update_layout(\n        xaxis_title=\"Brand\",\n        yaxis_title=\"Price ($)\",\n        showlegend=False\n    )\n\n    return fig\n\n\ndef create_price_gauge(predicted_price: float, min_price: float, max_price: float):\n    \"\"\"Gauge para mostrar predicci\u00f3n de precio.\"\"\"\n\n    fig = go.Figure(go.Indicator(\n        mode=\"gauge+number+delta\",\n        value=predicted_price,\n        domain={\"x\": [0, 1], \"y\": [0, 1]},\n        title={\"text\": \"Predicted Price\", \"font\": {\"size\": 24}},\n        number={\"prefix\": \"$\", \"font\": {\"size\": 40}},\n        gauge={\n            \"axis\": {\"range\": [min_price, max_price], \"tickprefix\": \"$\"},\n            \"bar\": {\"color\": \"darkblue\"},\n            \"steps\": [\n                {\"range\": [min_price, min_price + (max_price-min_price)*0.33], \"color\": \"lightgreen\"},\n                {\"range\": [min_price + (max_price-min_price)*0.33, min_price + (max_price-min_price)*0.66], \"color\": \"yellow\"},\n                {\"range\": [min_price + (max_price-min_price)*0.66, max_price], \"color\": \"salmon\"},\n            ],\n            \"threshold\": {\n                \"line\": {\"color\": \"red\", \"width\": 4},\n                \"thickness\": 0.75,\n                \"value\": predicted_price\n            }\n        }\n    ))\n\n    fig.update_layout(height=300)\n    return fig\n</code></pre>"},{"location":"docs/15_STREAMLIT/#155-predictor-interactivo","title":"15.5 Predictor Interactivo","text":"<p>### Tab 4: Price Predictor</p> <pre><code>def render_price_predictor(model, df: pd.DataFrame):\n    \"\"\"Tab de predicci\u00f3n interactiva de precios.\"\"\"\n\n    st.header(\"\ud83d\udcb0 Price Predictor\")\n\n    if model is None:\n        st.error(\"\u274c Modelo no cargado. Entrene el modelo primero.\")\n        return\n\n    st.markdown(\"Ingrese las caracter\u00edsticas del veh\u00edculo para obtener una estimaci\u00f3n de precio.\")\n\n    # Form para inputs\n    with st.form(\"prediction_form\"):\n        col1, col2 = st.columns(2)\n\n        with col1:\n            model_year = st.number_input(\n                \"Model Year\",\n                min_value=1990,\n                max_value=2024,\n                value=2018,\n                help=\"A\u00f1o del modelo del veh\u00edculo\"\n            )\n\n            odometer = st.number_input(\n                \"Odometer (miles)\",\n                min_value=0,\n                max_value=500000,\n                value=50000,\n                step=1000,\n                help=\"Millaje del veh\u00edculo\"\n            )\n\n            # Obtener opciones \u00fanicas del dataset\n            models = sorted(df[\"model\"].dropna().unique())\n            selected_model = st.selectbox(\n                \"Model\",\n                options=models[:100],  # Limitar para performance\n                index=0\n            )\n\n        with col2:\n            fuel_options = df[\"fuel\"].dropna().unique().tolist()\n            fuel = st.selectbox(\"Fuel Type\", options=fuel_options)\n\n            trans_options = df[\"transmission\"].dropna().unique().tolist()\n            transmission = st.selectbox(\"Transmission\", options=trans_options)\n\n            condition_options = [\"new\", \"like new\", \"excellent\", \"good\", \"fair\", \"salvage\"]\n            condition = st.selectbox(\"Condition\", options=condition_options, index=3)\n\n        submitted = st.form_submit_button(\"\ud83d\udd2e Predict Price\", use_container_width=True)\n\n    # Hacer predicci\u00f3n cuando se env\u00eda el form\n    if submitted:\n        # Preparar datos para predicci\u00f3n\n        input_data = pd.DataFrame([{\n            \"model_year\": model_year,\n            \"odometer\": odometer,\n            \"model\": selected_model,\n            \"fuel\": fuel,\n            \"transmission\": transmission,\n            \"condition\": condition,\n        }])\n\n        try:\n            # Predecir\n            prediction = model.predict(input_data)[0]\n\n            # Mostrar resultado\n            st.success(f\"### \ud83d\udcb5 Estimated Price: **${prediction:,.0f}**\")\n\n            # Gauge de visualizaci\u00f3n\n            min_price = df[\"price\"].quantile(0.05)\n            max_price = df[\"price\"].quantile(0.95)\n\n            fig = create_price_gauge(prediction, min_price, max_price)\n            st.plotly_chart(fig, use_container_width=True)\n\n            # Contexto de mercado\n            percentile = (df[\"price\"] &lt; prediction).mean() * 100\n            st.info(f\"\ud83d\udcca Este precio est\u00e1 en el percentil {percentile:.0f} del mercado.\")\n\n        except Exception as e:\n            st.error(f\"Error en predicci\u00f3n: {str(e)}\")\n ---\n\n &lt;a id=\"errores-habituales\"&gt;&lt;/a&gt;\n\n ## \ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en Streamlit para ML\n\n En dashboards de ML es f\u00e1cil mezclar l\u00f3gica pesada con UI y terminar con apps lentas o que se rompen al m\u00ednimo cambio.\n\n Si alguno de estos errores te tom\u00f3 **&gt;15 minutos**, reg\u00edstralo en el **[Diario de Errores](study_tools/DIARIO_ERRORES.md)** y aplica el flujo de **rescate cognitivo** de **[Protocolo E](study_tools/PROTOCOLO_E.md)**.\n\n ### 1) App muy lenta o que recalcula todo en cada interacci\u00f3n\n\n**S\u00edntomas t\u00edpicos**\n\n- Cada vez que mueves un slider, tarda varios segundos.\n- Ves en logs que se vuelve a leer el CSV o cargar el modelo a cada cambio.\n\n### 2) Errores al filtrar o mapear columnas (DataFrame desalineado)\n\n**S\u00edntomas t\u00edpicos**\n\n- Errores tipo `KeyError: 'price'` o columnas que no existen en ciertos entornos.\n\n**C\u00f3mo identificarlo**\n\n- Verifica que el dataset que usas en Streamlit tenga la misma estructura que el usado en entrenamiento.\n\n**C\u00f3mo corregirlo**\n\n- Centraliza la carga y preprocesado b\u00e1sico en una funci\u00f3n (ej. `load_data`) y reutil\u00edzala en todas las tabs.\n- A\u00f1ade checks defensivos (`if 'price' not in df.columns: ...`).\n\n---\n\n### 3) Modelo o artefactos que no se encuentran desde Streamlit\n\n**S\u00edntomas t\u00edpicos**\n\n- El predictor muestra `Modelo no cargado. Entrene el modelo primero.` aunque sabes que existe un modelo.\n\n**C\u00f3mo identificarlo**\n\n- Inspecciona la ruta usada en `load_model` y comp\u00e1rala con la estructura real del proyecto / contenedor.\n\n**C\u00f3mo corregirlo**\n\n- Alinea las rutas (`artifacts/`, `models/`) entre training, Docker y Streamlit.\n- Si corres en Docker, monta los artefactos en la misma ruta que espera la app.\n\n---\n\n### 4) Comportamiento raro por estado oculto o re-runs\n\n**S\u00edntomas t\u00edpicos**\n\n- Formularios que se env\u00edan varias veces.\n- Widgets que vuelven a su valor inicial sin raz\u00f3n aparente.\n\n**C\u00f3mo identificarlo**\n\n- Revisa el uso de `st.session_state` y de formularios (`st.form`).\n\n **C\u00f3mo corregirlo**\n\n - Usa `st.form` para agrupar inputs y ejecutar l\u00f3gica solo cuando el usuario pulsa el bot\u00f3n de submit.\n - Cuando necesites estado, usa `st.session_state` de forma expl\u00edcita y documenta qu\u00e9 claves manejas.\n\n ---\n\n ### 5) Patr\u00f3n general de debugging en Streamlit\n\n 1. Reproduce el problema con un **m\u00ednimo ejemplo** (quita tabs/funciones hasta aislar el fallo).\n 2. A\u00f1ade logs (`st.write`, `print`) temporales para ver en qu\u00e9 orden se ejecuta el c\u00f3digo.\n 3. Verifica qu\u00e9 funciones deber\u00edan estar cacheadas y cu\u00e1les no.\n 4. Aseg\u00farate de que las dependencias clave (datos, modelo) est\u00e1n disponibles antes de renderizar la UI.\n\n Con este enfoque, tus dashboards ser\u00e1n r\u00e1pidos, robustos y mantenibles.\n\n ---\n\n &lt;a id=\"156-dashboard-avanzado-visualizaciones-profesionales\"&gt;&lt;/a&gt;\n\n ## 15.6 Dashboard Avanzado: Visualizaciones Profesionales\n\n ### Gauge Chart para Predicciones\n\n ```python\n import plotly.graph_objects as go\n\n def create_price_gauge(predicted_price: float, min_price: float = 0, max_price: float = 100000):\n     \"\"\"Crea un gauge chart para visualizar predicci\u00f3n de precio.\"\"\"\n\n     # Determinar color seg\u00fan rango\n     if predicted_price &lt; max_price * 0.3:\n         color = \"green\"\n     elif predicted_price &lt; max_price * 0.7:\n         color = \"orange\"\n     else:\n         color = \"red\"\n\n     fig = go.Figure(go.Indicator(\n         mode=\"gauge+number+delta\",\n         value=predicted_price,\n         domain={'x': [0, 1], 'y': [0, 1]},\n         title={'text': \"Predicted Price\", 'font': {'size': 24}},\n         number={'prefix': \"$\", 'font': {'size': 40}},\n         gauge={\n             'axis': {'range': [min_price, max_price], 'tickwidth': 1},\n             'bar': {'color': color},\n             'bgcolor': \"white\",\n             'borderwidth': 2,\n             'steps': [\n                 {'range': [0, max_price * 0.3], 'color': 'lightgreen'},\n                 {'range': [max_price * 0.3, max_price * 0.7], 'color': 'lightyellow'},\n                 {'range': [max_price * 0.7, max_price], 'color': 'lightcoral'}\n             ],\n             'threshold': {\n                 'line': {'color': \"black\", 'width': 4},\n                 'thickness': 0.75,\n                 'value': predicted_price\n             }\n         }\n     ))\n\n     fig.update_layout(height=300)\n     return fig\n\n # Uso en Streamlit\n if prediction is not None:\n     gauge = create_price_gauge(prediction, min_price=0, max_price=80000)\n     st.plotly_chart(gauge, use_container_width=True)\n ```\n\n### M\u00e9tricas con Confianza (Bootstrap)\n\n```python\ndef display_model_metrics(metrics: dict):\n    \"\"\"Muestra m\u00e9tricas del modelo con intervalos de confianza.\"\"\"\n\n    col1, col2, col3, col4 = st.columns(4)\n\n    with col1:\n        st.metric(\n            label=\"RMSE\",\n            value=f\"${metrics['rmse']:,.0f}\",\n            delta=f\"\u00b1{metrics.get('rmse_ci', 500):,.0f}\",\n            delta_color=\"inverse\"  # Menor es mejor\n        )\n\n    with col2:\n        st.metric(\n            label=\"MAE\",\n            value=f\"${metrics['mae']:,.0f}\",\n            delta=f\"\u00b1{metrics.get('mae_ci', 300):,.0f}\",\n            delta_color=\"inverse\"\n        )\n\n    with col3:\n        st.metric(\n            label=\"R\u00b2\",\n            value=f\"{metrics['r2']:.3f}\",\n            delta=f\"{metrics.get('r2_improvement', 0):.1%} vs baseline\",\n            delta_color=\"normal\"\n        )\n\n    with col4:\n        st.metric(\n            label=\"MAPE\",\n            value=f\"{metrics['mape']:.1%}\",\n            delta=f\"\u00b1{metrics.get('mape_ci', 0.02):.1%}\",\n            delta_color=\"inverse\"\n        )\n</code></pre>"},{"location":"docs/15_STREAMLIT/#feature-importance-interactivo","title":"Feature Importance Interactivo","text":"<pre><code>import plotly.express as px\n\ndef plot_feature_importance(model, feature_names: list, top_n: int = 15):\n    \"\"\"Gr\u00e1fico interactivo de importancia de features.\"\"\"\n\n    # Extraer importancias (asume RandomForest o similar)\n    if hasattr(model, 'feature_importances_'):\n        importances = model.feature_importances_\n    elif hasattr(model, 'named_steps'):\n        # Pipeline sklearn\n        clf = model.named_steps.get('classifier') or model.named_steps.get('model')\n        importances = clf.feature_importances_\n    else:\n        st.warning(\"Modelo no soporta feature_importances_\")\n        return None\n\n    # Crear DataFrame y ordenar\n    df_imp = pd.DataFrame({\n        'feature': feature_names,\n        'importance': importances\n    }).sort_values('importance', ascending=True).tail(top_n)\n\n    # Gr\u00e1fico horizontal\n    fig = px.bar(\n        df_imp, \n        x='importance', \n        y='feature',\n        orientation='h',\n        title=f'Top {top_n} Feature Importances',\n        labels={'importance': 'Importance', 'feature': 'Feature'},\n        color='importance',\n        color_continuous_scale='Viridis'\n    )\n\n    fig.update_layout(height=400, showlegend=False)\n    return fig\n\n# Uso\nwith st.expander(\"\ud83d\udd0d Feature Importance\", expanded=True):\n    fig = plot_feature_importance(model, feature_names)\n    if fig:\n        st.plotly_chart(fig, use_container_width=True)\n</code></pre>"},{"location":"docs/15_STREAMLIT/#multi-page-app-con-navigation","title":"Multi-page App con Navigation","text":"<pre><code># pages/1_\ud83d\udcca_Overview.py\nimport streamlit as st\n\nst.set_page_config(page_title=\"Overview\", page_icon=\"\ud83d\udcca\")\nst.title(\"\ud83d\udcca Dashboard Overview\")\n\n# ... contenido de overview\n\n# pages/2_\ud83d\udd2e_Predictor.py\nimport streamlit as st\n\nst.set_page_config(page_title=\"Predictor\", page_icon=\"\ud83d\udd2e\")\nst.title(\"\ud83d\udd2e Price Predictor\")\n\n# ... contenido de predictor\n\n# Estructura de archivos:\n# app/\n# \u251c\u2500\u2500 streamlit_app.py       # Main entry point\n# \u2514\u2500\u2500 pages/\n#     \u251c\u2500\u2500 1_\ud83d\udcca_Overview.py\n#     \u251c\u2500\u2500 2_\ud83d\udcc8_Analysis.py\n#     \u2514\u2500\u2500 3_\ud83d\udd2e_Predictor.py\n</code></pre>"},{"location":"docs/15_STREAMLIT/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se us\u00f3 en el Portafolio","text":"<p>El dashboard de CarVision (<code>CarVision-Market-Intelligence/app/streamlit_app.py</code>) implementa:</p> Componente L\u00edneas T\u00e9cnica 4 Tabs navegables 150-600 <code>st.tabs()</code> KPIs ejecutivos 200-250 <code>st.metric()</code> con delta Gauge de predicci\u00f3n 450-500 Plotly <code>go.Indicator</code> Feature importance 350-400 Plotly <code>px.bar</code> horizontal Bootstrap validation 400-430 M\u00e9tricas con intervalos Caching de modelo 50-80 <code>@st.cache_resource</code>"},{"location":"docs/15_STREAMLIT/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/15_STREAMLIT/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Streamlit vs Gradio vs Dash: Trade-offs (Streamlit simple, Gradio para ML demos, Dash para dashboards complejos).</p> </li> <li> <p>Session State: Explica c\u00f3mo mantener estado entre reruns.</p> </li> <li> <p>Caching: <code>@st.cache_data</code> vs <code>@st.cache_resource</code>.</p> </li> </ol>"},{"location":"docs/15_STREAMLIT/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Modelo pesado Usa <code>@st.cache_resource</code> para cargarlo una vez Datos grandes Pagina o muestra samples Deployment Streamlit Cloud para demos, Docker para producci\u00f3n UX A\u00f1ade spinners y progress bars"},{"location":"docs/15_STREAMLIT/#estructura-de-app-profesional","title":"Estructura de App Profesional","text":"<pre><code>app/\n\u251c\u2500\u2500 streamlit_app.py   # Entry point limpio\n\u251c\u2500\u2500 pages/             # Multi-page app\n\u251c\u2500\u2500 components/        # Widgets reutilizables\n\u2514\u2500\u2500 utils/             # L\u00f3gica de negocio\n</code></pre>"},{"location":"docs/15_STREAMLIT/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/15_STREAMLIT/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Streamlit Crash Course Patrick Loeber 45 min YouTube \ud83d\udfe1 Streamlit Multi-page Apps Streamlit 20 min YouTube \ud83d\udfe2 30 Days of Streamlit Streamlit Curso 30days"},{"location":"docs/15_STREAMLIT/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Streamlit Docs Documentaci\u00f3n oficial \ud83d\udfe1 Streamlit Gallery Ejemplos de apps"},{"location":"docs/15_STREAMLIT/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/15_STREAMLIT/#ejercicio-151-dashboard-de-prediccion","title":"Ejercicio 15.1: Dashboard de Predicci\u00f3n","text":"<p>Objetivo: Crear dashboard interactivo para modelo ML. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code>import streamlit as st\n\n# TU TAREA: Crear dashboard con:\n# 1. Sidebar con inputs para features\n# 2. Bot\u00f3n de predicci\u00f3n\n# 3. Mostrar resultado con gauge chart\n# 4. Explicaci\u00f3n de factores (feature importance)\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import streamlit as st\nimport joblib\nimport plotly.graph_objects as go\n\nst.set_page_config(page_title=\"Churn Predictor\", layout=\"wide\")\n\n@st.cache_resource\ndef load_model():\n    return joblib.load(\"artifacts/model.joblib\")\n\ndef create_gauge(probability: float) -&gt; go.Figure:\n    \"\"\"Crea gauge chart para probabilidad.\"\"\"\n    color = \"red\" if probability &gt; 0.7 else \"orange\" if probability &gt; 0.3 else \"green\"\n\n    fig = go.Figure(go.Indicator(\n        mode=\"gauge+number\",\n        value=probability * 100,\n        title={\"text\": \"Churn Risk\"},\n        gauge={\n            \"axis\": {\"range\": [0, 100]},\n            \"bar\": {\"color\": color},\n            \"steps\": [\n                {\"range\": [0, 30], \"color\": \"lightgreen\"},\n                {\"range\": [30, 70], \"color\": \"lightyellow\"},\n                {\"range\": [70, 100], \"color\": \"lightcoral\"}\n            ]\n        }\n    ))\n    return fig\n\n# Sidebar - Inputs\nst.sidebar.header(\"Customer Features\")\ncredit_score = st.sidebar.slider(\"Credit Score\", 300, 850, 650)\nage = st.sidebar.slider(\"Age\", 18, 80, 35)\ntenure = st.sidebar.slider(\"Tenure (years)\", 0, 20, 5)\nbalance = st.sidebar.number_input(\"Balance\", 0, 250000, 50000)\nnum_products = st.sidebar.selectbox(\"Products\", [1, 2, 3, 4])\nhas_credit_card = st.sidebar.checkbox(\"Has Credit Card\", True)\nis_active = st.sidebar.checkbox(\"Is Active Member\", True)\n\n# Main content\nst.title(\"\ud83d\udd2e Churn Prediction Dashboard\")\n\nif st.sidebar.button(\"Predict\", type=\"primary\"):\n    model = load_model()\n\n    features = [[credit_score, age, tenure, balance, \n                 num_products, int(has_credit_card), int(is_active)]]\n\n    probability = model.predict_proba(features)[0][1]\n    prediction = model.predict(features)[0]\n\n    col1, col2 = st.columns(2)\n\n    with col1:\n        st.plotly_chart(create_gauge(probability), use_container_width=True)\n\n    with col2:\n        risk = \"\ud83d\udd34 HIGH\" if probability &gt; 0.7 else \"\ud83d\udfe1 MEDIUM\" if probability &gt; 0.3 else \"\ud83d\udfe2 LOW\"\n        st.metric(\"Risk Level\", risk)\n        st.metric(\"Probability\", f\"{probability:.1%}\")\n\n        if probability &gt; 0.5:\n            st.warning(\"\u26a0\ufe0f Customer at risk of churning!\")\n        else:\n            st.success(\"\u2705 Customer likely to stay\")\n</code></pre>"},{"location":"docs/15_STREAMLIT/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Streamlit Framework Python para crear dashboards web r\u00e1pidamente @st.cache_resource Decorator para cachear modelos y recursos pesados Plotly Librer\u00eda para gr\u00e1ficos interactivos Multi-page App Estructura con m\u00faltiples p\u00e1ginas en Streamlit"},{"location":"docs/15_STREAMLIT/#fin-de-fase-3-mlops-core","title":"\ud83c\udfc1 FIN DE FASE 3: MLOps Core","text":"<p>\ud83c\udfaf \u00a1Has completado los m\u00f3dulos 11-16!</p> <p>Ahora dominas MLOps Core: - \u2705 Testing profesional para ML - \u2705 CI/CD con GitHub Actions - \u2705 Containerizaci\u00f3n con Docker - \u2705 APIs con FastAPI - \u2705 Dashboards con Streamlit - \u2705 Observabilidad b\u00e1sica</p> <p>Siguiente: Fase 4 - Producci\u00f3n (Despliegue, Infraestructura)</p>   **Siguiente m\u00f3dulo** \u2192 [16. Observabilidad](16_OBSERVABILIDAD.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/16_OBSERVABILIDAD/","title":"16. Observabilidad para ML","text":""},{"location":"docs/16_OBSERVABILIDAD/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado el m\u00f3dulo 14 (FastAPI) y entender endpoints <code>/health</code> y <code>/predict</code>.</li> <li>Haber completado el m\u00f3dulo 13 (Docker) para poder levantar servicios en contenedores.</li> <li>Conocer logging b\u00e1sico en Python.</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de empezar: abre Protocolo E y define el output m\u00ednimo: m\u00e9tricas visibles en Prometheus + logs JSON + un reporte de drift.</li> <li>Durante el debugging: si te atoras &gt;15 min (scrape, paneles vac\u00edos, labels, parseo de logs, drift CI), registra el caso en Diario de Errores.</li> <li>Al cierre de semana: usa Cierre Semanal para auditar alertas accionables y se\u00f1al \u00fatil (no solo dashboards bonitos).</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] Endpoint <code>/metrics</code> expuesto y scrapeado por Prometheus.</li> <li>[ ] Dashboard (Grafana o equivalente) con latencia, throughput y error rate.</li> <li>[ ] Logs estructurados en JSON con campos de negocio (por ejemplo, <code>model</code>, <code>request_id</code>, <code>prediction</code>).</li> <li>[ ] Drift detection ejecutable (local o CI) con artefacto de salida (HTML/JSON).</li> <li>[ ] Al menos 1 alerta accionable (por ejemplo, error rate o latencia P99).</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Concepto: se\u00f1ales de oro + instrumentaci\u00f3n + ML monitoring</li> <li>Archivo: <code>app/metrics.py</code>, <code>src/logging_config.py</code>, <code>monitoring/check_drift.py</code></li> <li>Prueba: <code>curl http://localhost:8000/metrics</code> y revisi\u00f3n de reportes/artefactos</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#objetivo-del-modulo","title":"\ud83c\udfaf Objetivo del M\u00f3dulo","text":"<p>Implementar monitoreo completo: logs, m\u00e9tricas, y drift detection como en el portafolio.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \"Si no puedo verlo en un dashboard, no s\u00e9 si est\u00e1 funcionando.\"             \u2551\n\u2551                                        \u2014 Mentalidad Senior                   \u2551\n\u2551                                                                              \u2551\n\u2551  OBSERVABILIDAD = LOGS + METRICS + TRACES + ML MONITORING                    \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>16.1 Las 4 Se\u00f1ales de Oro</li> <li>16.2 Prometheus + Grafana</li> <li>16.3 Logging Estructurado</li> <li>16.4 Model Monitoring</li> <li>16.5 \ud83d\udd2c Ingenier\u00eda Inversa: Observabilidad Producci\u00f3n \u2b50 NUEVO</li> <li>Errores habituales</li> <li>[</li> </ul> <p>\u2705 Checkpoint](#checkpoint) - \u2705 Ejercicio</p> <p></p>"},{"location":"docs/16_OBSERVABILIDAD/#mapa-mental-de-conceptos-161-las-4-senales-de-oro","title":"\ud83e\udde0 Mapa Mental de Conceptos: 16.1 Las 4 Se\u00f1ales de Oro","text":"<p>T\u00e9rminos clave que debes dominar para este tema: - Revisa los conceptos principales en la secci\u00f3n siguiente - Practica con los ejercicios del portafolio - Aplica los conocimientos en BankChurn-Predictor</p>"},{"location":"docs/16_OBSERVABILIDAD/#ejercicio-puente-monitoreo","title":"\ud83d\udcbb Ejercicio Puente: Monitoreo","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/16_OBSERVABILIDAD/#practica-del-portafolio-observabilidad-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Observabilidad en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Monitoreo\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/16_OBSERVABILIDAD/#_1","title":"16 \u2014 Observabilidad","text":"<p>\u2705 Checkpoint de Conocimiento</p> <p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Observabilidad?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Monitoreo, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/16_OBSERVABILIDAD/#161-las-4-senales-de-oro","title":"16.1 Las 4 Se\u00f1ales de Oro","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     \ud83d\udcca LAS 4 SE\u00d1ALES DE ORO (+ ML)                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  1. LATENCIA          \u00bfCu\u00e1nto tarda una predicci\u00f3n?                         \u2502\n\u2502     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       Target: P99 &lt; 100ms                                   \u2502\n\u2502                       Alerta: P99 &gt; 200ms                                   \u2502\n\u2502                                                                             \u2502\n\u2502  2. TR\u00c1FICO           \u00bfCu\u00e1ntas requests por segundo?                        \u2502\n\u2502     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          Monitorear: picos, tendencias, anomal\u00edas              \u2502\n\u2502                                                                             \u2502\n\u2502  3. ERRORES           \u00bfQu\u00e9 porcentaje de requests falla?                    \u2502\n\u2502     \u2500\u2500\u2500\u2500\u2500\u2500\u2500           Target: Error rate &lt; 0.1%                             \u2502\n\u2502                       Alerta: Error rate &gt; 1%                               \u2502\n\u2502                                                                             \u2502\n\u2502  4. SATURACI\u00d3N        \u00bfCu\u00e1nto recurso queda?                                \u2502\n\u2502     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500        Alerta: CPU &gt; 80%, Memory &gt; 85%                       \u2502\n\u2502                                                                             \u2502\n\u2502  + ML-ESPEC\u00cdFICO:                                                           \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                           \u2502\n\u2502  5. DATA DRIFT        \u00bfLos datos de entrada cambiaron?                      \u2502\n\u2502  6. PREDICTION DRIFT  \u00bfLas predicciones cambiaron distribuci\u00f3n?             \u2502\n\u2502  7. MODEL DECAY       \u00bfEl accuracy est\u00e1 degradando?                         \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#162-prometheus-grafana","title":"16.2 Prometheus + Grafana","text":""},{"location":"docs/16_OBSERVABILIDAD/#configuracion-del-portafolio","title":"Configuraci\u00f3n del Portafolio","text":"<pre><code># infra/prometheus-config.yaml\n\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'bankchurn-api'\n    static_configs:\n      - targets: ['bankchurn:8000']\n    metrics_path: /metrics\n\n  - job_name: 'carvision-api'\n    static_configs:\n      - targets: ['carvision:8000']\n    metrics_path: /metrics\n\n  - job_name: 'telecom-api'\n    static_configs:\n      - targets: ['telecom:8000']\n    metrics_path: /metrics\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#metricas-en-fastapi","title":"M\u00e9tricas en FastAPI","text":"<pre><code># app/metrics.py\n\nfrom prometheus_client import Counter, Histogram, Gauge, generate_latest  # Tipos de m\u00e9tricas Prometheus.\nfrom fastapi import Response              # Response para retornar texto plano.\n\n# M\u00e9tricas - Se definen a nivel m\u00f3dulo (globales)\nPREDICTIONS_TOTAL = Counter(              # Counter: solo incrementa (total acumulado).\n    'predictions_total',                  # Nombre de la m\u00e9trica (snake_case).\n    'Total de predicciones realizadas',   # Descripci\u00f3n (aparece en /metrics).\n    ['model', 'result']                   # Labels: permiten filtrar por modelo/resultado.\n)\n\nPREDICTION_LATENCY = Histogram(           # Histogram: distribuci\u00f3n de valores (latencias).\n    'prediction_latency_seconds',         # Convenci\u00f3n: unidad en el nombre (_seconds).\n    'Latencia de predicciones',\n    ['model'],                            # Label para filtrar por modelo.\n    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]  # Rangos para calcular percentiles.\n)\n\nMODEL_LOADED = Gauge(                     # Gauge: valor que sube/baja (estado actual).\n    'model_loaded',                       # 1 si cargado, 0 si no.\n    'Indica si el modelo est\u00e1 cargado',\n    ['model']\n)\n\nPREDICTION_PROBABILITY = Histogram(       # Histogram para monitorear distribuci\u00f3n de predicciones.\n    'prediction_probability',             # \u00datil para detectar drift en predicciones.\n    'Distribuci\u00f3n de probabilidades predichas',\n    ['model'],\n    buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]  # Buckets cada 10%.\n)\n\n\n# Endpoint de m\u00e9tricas\n@app.get(\"/metrics\")                      # Prometheus hace scrape a este endpoint.\nasync def metrics():\n    return Response(\n        content=generate_latest(),        # generate_latest(): serializa todas las m\u00e9tricas.\n        media_type=\"text/plain\"           # Prometheus espera text/plain.\n    )\n\n\n# Uso en predicci\u00f3n\nimport time                               # Para medir latencia.\n\n@app.post(\"/predict\")\nasync def predict(request: PredictionRequest):\n    start = time.time()                   # Timestamp antes de predecir.\n\n    # ... predicci\u00f3n ...\n    proba = model.predict_proba(df)[0, 1]\n    prediction = int(proba &gt;= 0.5)\n\n    # Registrar m\u00e9tricas\n    latency = time.time() - start         # Calcula latencia en segundos.\n    PREDICTION_LATENCY.labels(model=\"bankchurn\").observe(latency)  # observe(): registra en histogram.\n    PREDICTIONS_TOTAL.labels(model=\"bankchurn\", result=str(prediction)).inc()  # inc(): incrementa counter.\n    PREDICTION_PROBABILITY.labels(model=\"bankchurn\").observe(proba)  # Registra prob para detectar drift.\n\n    return {\"prediction\": prediction, \"probability\": proba}\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#1621-prometheus-alerting-rules","title":"16.2.1 Prometheus Alerting Rules","text":"<p>Referencia del portafolio: <code>infra/prometheus-rules.yaml</code></p> <pre><code># prometheus-rules.yaml\ngroups:\n  - name: ml-service-alerts\n    rules:\n      # Latencia alta\n      - alert: HighPredictionLatency\n        expr: histogram_quantile(0.99, rate(prediction_latency_seconds_bucket[5m])) &gt; 0.2\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Latencia P99 alta en {{ $labels.model }}\"\n          description: \"P99 latencia es {{ $value }}s (umbral: 200ms)\"\n          runbook_url: \"https://docs.example.com/runbooks/high-latency\"\n\n      # Error rate alto\n      - alert: HighErrorRate\n        expr: rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m]) &gt; 0.01\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Error rate alto en {{ $labels.service }}\"\n          description: \"Error rate es {{ $value | humanizePercentage }}\"\n          runbook_url: \"https://docs.example.com/runbooks/high-error-rate\"\n\n      # Drift detectado\n      - alert: DataDriftDetected\n        expr: ml_drift_score &gt; 0.15\n        for: 15m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Data drift detectado en {{ $labels.model }}\"\n          description: \"Drift score es {{ $value }} (umbral: 0.15)\"\n          runbook_url: \"https://docs.example.com/runbooks/data-drift\"\n\n      # Servicio ca\u00eddo\n      - alert: ServiceDown\n        expr: up{job=~\"bankchurn|carvision|telecomai\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Servicio {{ $labels.job }} est\u00e1 ca\u00eddo\"\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#buenas-practicas-para-alertas","title":"Buenas pr\u00e1cticas para alertas","text":"Pr\u00e1ctica Descripci\u00f3n Accionable Cada alerta debe tener un runbook con pasos concretos Umbral realista Basar umbrales en datos hist\u00f3ricos, no en intuici\u00f3n Severidad apropiada <code>critical</code> solo para lo que requiere acci\u00f3n inmediata Evitar ruido Usar <code>for:</code> para evitar alertas por spikes temporales"},{"location":"docs/16_OBSERVABILIDAD/#163-logging-estructurado","title":"16.3 Logging Estructurado","text":""},{"location":"docs/16_OBSERVABILIDAD/#configuracion-profesional","title":"Configuraci\u00f3n Profesional","text":"<pre><code># src/logging_config.py\n\nimport logging\nimport json\nimport sys\nfrom datetime import datetime\n\n\nclass JSONFormatter(logging.Formatter):\n    \"\"\"Formatter que produce logs en JSON para f\u00e1cil parsing.\"\"\"\n\n    def format(self, record):\n        log_obj = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            \"function\": record.funcName,\n            \"line\": record.lineno,\n        }\n\n        # A\u00f1adir extras si existen\n        if hasattr(record, \"request_id\"):\n            log_obj[\"request_id\"] = record.request_id\n        if hasattr(record, \"user_id\"):\n            log_obj[\"user_id\"] = record.user_id\n        if hasattr(record, \"prediction\"):\n            log_obj[\"prediction\"] = record.prediction\n\n        # A\u00f1adir exception si existe\n        if record.exc_info:\n            log_obj[\"exception\"] = self.formatException(record.exc_info)\n\n        return json.dumps(log_obj)\n\n\ndef setup_logging(level: str = \"INFO\", json_format: bool = True):\n    \"\"\"Configura logging para producci\u00f3n.\"\"\"\n\n    root = logging.getLogger()\n    root.setLevel(getattr(logging, level.upper()))\n\n    handler = logging.StreamHandler(sys.stdout)\n\n    if json_format:\n        handler.setFormatter(JSONFormatter())\n    else:\n        handler.setFormatter(logging.Formatter(\n            \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n        ))\n\n    root.addHandler(handler)\n\n    # Silenciar loggers ruidosos\n    logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n    logging.getLogger(\"uvicorn.access\").setLevel(logging.WARNING)\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#logs-con-contexto","title":"Logs con Contexto","text":"<pre><code>import logging\nimport uuid\n\nlogger = logging.getLogger(__name__)\n\n@app.post(\"/predict\")\nasync def predict(request: PredictionRequest):\n    request_id = str(uuid.uuid4())[:8]\n\n    # Log con contexto\n    logger.info(\n        \"Prediction request received\",\n        extra={\n            \"request_id\": request_id,\n            \"credit_score\": request.CreditScore,\n            \"geography\": request.Geography,\n        }\n    )\n\n    try:\n        prediction = model.predict(...)\n\n        logger.info(\n            \"Prediction completed\",\n            extra={\n                \"request_id\": request_id,\n                \"prediction\": prediction,\n                \"latency_ms\": latency * 1000,\n            }\n        )\n\n        return {\"prediction\": prediction}\n\n    except Exception as e:\n        logger.error(\n            f\"Prediction failed: {str(e)}\",\n            extra={\"request_id\": request_id},\n            exc_info=True\n        )\n        raise\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#164-model-monitoring-drift-detection","title":"16.4 Model Monitoring (Drift Detection)","text":""},{"location":"docs/16_OBSERVABILIDAD/#script-de-drift-detection","title":"Script de Drift Detection","text":"<pre><code># monitoring/check_drift.py - C\u00f3digo REAL del portafolio\n\n\"\"\"\nDetecta drift en datos usando Evidently AI.\n\nCompara datos de referencia (training) con datos actuales (producci\u00f3n).\nGenera reporte HTML y m\u00e9tricas JSON.\n\nUso:\n    python monitoring/check_drift.py --reference data/train.csv --current data/recent.csv\n\"\"\"\n\nimport argparse\nimport json\nfrom pathlib import Path\nfrom datetime import datetime\n\nimport pandas as pd\n\ntry:\n    from evidently import ColumnMapping\n    from evidently.report import Report\n    from evidently.metric_preset import DataDriftPreset, DataQualityPreset\n    EVIDENTLY_AVAILABLE = True\nexcept ImportError:\n    EVIDENTLY_AVAILABLE = False\n\n\ndef check_drift(\n    reference_data: pd.DataFrame,\n    current_data: pd.DataFrame,\n    output_dir: Path,\n    numerical_features: list = None,\n    categorical_features: list = None,\n) -&gt; dict:\n    \"\"\"\n    Ejecuta an\u00e1lisis de drift entre datos de referencia y actuales.\n\n    Returns\n    -------\n    dict\n        M\u00e9tricas de drift incluyendo:\n        - dataset_drift: bool (True si hay drift significativo)\n        - drift_share: float (% de features con drift)\n        - drifted_features: list (features con drift detectado)\n    \"\"\"\n\n    if not EVIDENTLY_AVAILABLE:\n        return {\"error\": \"Evidently no instalado\", \"dataset_drift\": None}\n\n    # Column mapping\n    column_mapping = ColumnMapping()\n    if numerical_features:\n        column_mapping.numerical_features = numerical_features\n    if categorical_features:\n        column_mapping.categorical_features = categorical_features\n\n    # Crear reporte\n    report = Report(metrics=[\n        DataDriftPreset(),\n        DataQualityPreset(),\n    ])\n\n    report.run(\n        reference_data=reference_data,\n        current_data=current_data,\n        column_mapping=column_mapping\n    )\n\n    # Guardar HTML\n    output_dir.mkdir(parents=True, exist_ok=True)\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    html_path = output_dir / f\"drift_report_{timestamp}.html\"\n    report.save_html(str(html_path))\n\n    # Extraer m\u00e9tricas\n    results = report.as_dict()\n\n    drift_metrics = {\n        \"timestamp\": timestamp,\n        \"reference_rows\": len(reference_data),\n        \"current_rows\": len(current_data),\n        \"dataset_drift\": False,\n        \"drift_share\": 0.0,\n        \"drifted_features\": [],\n        \"report_path\": str(html_path),\n    }\n\n    # Parsear resultados de Evidently\n    for metric in results.get(\"metrics\", []):\n        if \"DataDriftTable\" in str(metric.get(\"metric\", \"\")):\n            result = metric.get(\"result\", {})\n            drift_metrics[\"dataset_drift\"] = result.get(\"dataset_drift\", False)\n            drift_metrics[\"drift_share\"] = result.get(\"drift_share\", 0.0)\n\n            # Features con drift\n            drift_by_columns = result.get(\"drift_by_columns\", {})\n            for col, col_data in drift_by_columns.items():\n                if col_data.get(\"drift_detected\", False):\n                    drift_metrics[\"drifted_features\"].append(col)\n\n    # Guardar m\u00e9tricas JSON\n    json_path = output_dir / f\"drift_metrics_{timestamp}.json\"\n    with open(json_path, \"w\") as f:\n        json.dump(drift_metrics, f, indent=2)\n\n    return drift_metrics\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Check data drift\")\n    parser.add_argument(\"--reference\", required=True, help=\"Path to reference data CSV\")\n    parser.add_argument(\"--current\", required=True, help=\"Path to current data CSV\")\n    parser.add_argument(\"--output\", default=\"artifacts\", help=\"Output directory\")\n    args = parser.parse_args()\n\n    reference = pd.read_csv(args.reference)\n    current = pd.read_csv(args.current)\n\n    metrics = check_drift(reference, current, Path(args.output))\n\n    print(json.dumps(metrics, indent=2))\n\n    # Exit code basado en drift\n    if metrics.get(\"dataset_drift\"):\n        print(\"\u26a0\ufe0f DRIFT DETECTADO\")\n        exit(1)\n    else:\n        print(\"\u2705 No hay drift significativo\")\n        exit(0)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#github-action-para-drift-scheduled","title":"GitHub Action para Drift Scheduled","text":"<pre><code># .github/workflows/drift-detection.yml\n\nname: Drift Detection\n\non:\n  schedule:\n    - cron: '0 2 * * *'  # Diario a las 2am UTC\n  workflow_dispatch:\n\njobs:\n  check-drift:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install pandas evidently\n\n      - name: Run drift check\n        run: |\n          python monitoring/check_drift.py \\\n            --reference data/reference/train.csv \\\n            --current data/recent/latest.csv \\\n            --output artifacts/drift\n\n      - name: Upload report\n        uses: actions/upload-artifact@v4\n        with:\n          name: drift-report\n          path: artifacts/drift/\n\n      - name: Create issue if drift detected\n        if: failure()\n        uses: actions/github-script@v7\n        with:\n          script: |\n            github.rest.issues.create({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              title: '\u26a0\ufe0f Data Drift Detected',\n              body: 'Drift detection workflow failed. Check the artifacts.',\n              labels: ['drift', 'monitoring']\n            })\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#165-runbooks-de-alertas-nuevo","title":"16.5 Runbooks de Alertas \u2b50 NUEVO","text":"<p>Un runbook documenta los pasos exactos para responder a una alerta. Sin runbooks, las alertas son ruido; con runbooks, son acci\u00f3n.</p>"},{"location":"docs/16_OBSERVABILIDAD/#1651-estructura-de-un-runbook","title":"16.5.1 Estructura de un Runbook","text":"<pre><code># \ud83d\udea8 Runbook: HighPredictionLatency\n\n## Resumen\n| Campo | Valor |\n|-------|-------|\n| Alerta | `HighPredictionLatency` |\n| Severidad | Warning \u2192 Critical si persiste &gt;15m |\n| Impacto | UX degradada, timeouts en clientes |\n| On-call | @ml-platform-team |\n\n## Diagn\u00f3stico R\u00e1pido (&lt; 2 min)\n\n1. **Verificar si es puntual o sostenido**\n   ```bash\n   # Ver P99 de \u00faltimos 15 min\n   curl -s \"http://prometheus:9090/api/v1/query?query=histogram_quantile(0.99,rate(prediction_latency_seconds_bucket[15m]))\" | jq\n   ```\n\n2. **Verificar recursos del servicio**\n   ```bash\n   docker stats bankchurn-api --no-stream\n   # CPU &gt; 80%? Memory &gt; 85%?\n   ```\n\n3. **Verificar logs recientes**\n   ```bash\n   docker logs bankchurn-api --tail 100 --since 5m | grep -i error\n   ```\n\n## Causas Comunes y Soluciones\n\n### Causa 1: Modelo demasiado grande en memoria\n**S\u00edntomas**: Memory alta, swap activo\n**Soluci\u00f3n**:\n```bash\n# Escalar horizontalmente\nkubectl scale deployment bankchurn --replicas=3\n\n# O reiniciar para liberar memoria\ndocker restart bankchurn-api\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#causa-2-spike-de-trafico","title":"Causa 2: Spike de tr\u00e1fico","text":"<p>S\u00edntomas: Request rate 3x+ del baseline Soluci\u00f3n: <pre><code># Verificar rate actual\ncurl -s \"http://prometheus:9090/api/v1/query?query=rate(http_requests_total[5m])\"\n\n# Escalar si es necesario\nkubectl autoscale deployment bankchurn --min=2 --max=10 --cpu-percent=70\n</code></pre></p>"},{"location":"docs/16_OBSERVABILIDAD/#causa-3-datos-de-entrada-anomalos","title":"Causa 3: Datos de entrada an\u00f3malos","text":"<p>S\u00edntomas: Latencia solo en algunos requests Soluci\u00f3n: <pre><code># Revisar payloads problem\u00e1ticos en logs\ndocker logs bankchurn-api | grep \"latency_ms.*[0-9]{4}\" | tail 20\n\n# A\u00f1adir validaci\u00f3n de input m\u00e1s estricta\n</code></pre></p>"},{"location":"docs/16_OBSERVABILIDAD/#escalacion","title":"Escalaci\u00f3n","text":"<ul> <li>Si no se resuelve en 15 min \u2192 Escalar a @senior-ml-engineer</li> <li>Si impacto en revenue \u2192 Escalar a @on-call-manager</li> <li>Si es recurrente (3+ veces/semana) \u2192 Crear ticket para investigaci\u00f3n root cause</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#post-mortem","title":"Post-mortem","text":"<p>Despu\u00e9s de resolver, documentar: - [ ] Timeline del incidente - [ ] Root cause - [ ] Acciones para prevenir recurrencia <pre><code>### 16.5.2 Runbook: Data Drift Detectado\n\n```markdown\n# \ud83d\udea8 Runbook: DataDriftDetected\n\n## Resumen\n| Campo | Valor |\n|-------|-------|\n| Alerta | `DataDriftDetected` |\n| Severidad | Warning |\n| Impacto | Predicciones potencialmente degradadas |\n| Urgencia | 24-48h para investigar |\n\n## Diagn\u00f3stico\n\n1. **Revisar reporte de drift**\n   ```bash\n   # Ver \u00faltimo reporte\n   ls -la artifacts/drift/\n   # Abrir HTML en browser para an\u00e1lisis visual\n   open artifacts/drift/drift_report_*.html\n   ```\n\n2. **Identificar features con drift**\n   ```bash\n   cat artifacts/drift/drift_metrics_*.json | jq '.drifted_features'\n   ```\n\n3. **Verificar si hay cambio en fuente de datos**\n   - \u00bfCambi\u00f3 el proveedor de datos?\n   - \u00bfHay un nuevo segmento de usuarios?\n   - \u00bfHay un bug en el pipeline de datos?\n\n## \u00c1rbol de Decisi\u00f3n\n</code></pre> \u00bfDrift &gt; 30% de features? \u251c\u2500\u2500 S\u00cd \u2192 Probable cambio en fuente de datos \u2502        \u2192 Investigar pipeline de ingesta \u2502        \u2192 Considerar retrain urgente \u2502 \u2514\u2500\u2500 NO \u2192 Drift localizado          \u251c\u2500\u2500 \u00bfFeatures cr\u00edticas?          \u2502   \u251c\u2500\u2500 S\u00cd \u2192 Retrain en 1-2 d\u00edas          \u2502   \u2514\u2500\u2500 NO \u2192 Monitorear 1 semana          \u2502          \u2514\u2500\u2500 \u00bfDrift estacional esperado?              \u251c\u2500\u2500 S\u00cd \u2192 Documentar, no acci\u00f3n              \u2514\u2500\u2500 NO \u2192 Investigar causa <pre><code>## Acciones seg\u00fan severidad\n\n| Drift Share | Acci\u00f3n |\n|-------------|--------|\n| &lt; 10% | Monitorear, no acci\u00f3n inmediata |\n| 10-30% | Investigar en 48h, considerar retrain |\n| &gt; 30% | Retrain urgente, posible rollback a modelo anterior |\n\n## Comandos de Retrain\n\n```bash\n# 1. Verificar datos disponibles\nls -la data/recent/\n\n# 2. Disparar retrain\npython main.py --mode train --experiment-name \"retrain-$(date +%Y%m%d)\"\n\n# 3. Comparar m\u00e9tricas\npython scripts/compare_models.py --baseline production --candidate new\n\n# 4. Si mejora, promover\npython scripts/promote_model.py --model-name bankchurn --stage Production\n</code></pre> <pre><code>### 16.5.3 Runbook: Service Down\n\n```markdown\n# \ud83d\udea8 Runbook: ServiceDown\n\n## Resumen\n| Campo | Valor |\n|-------|-------|\n| Alerta | `ServiceDown` |\n| Severidad | CRITICAL |\n| Impacto | Servicio completamente inaccesible |\n| SLA | Responder &lt; 5 min |\n\n## Diagn\u00f3stico Inmediato (&lt; 1 min)\n\n```bash\n# 1. Verificar estado de contenedores\ndocker ps -a | grep -E \"(bankchurn|carvision|telecom)\"\n\n# 2. Ver \u00faltimo log\ndocker logs --tail 50 &lt;container_name&gt;\n\n# 3. Health check manual\ncurl -v http://localhost:8001/health\n</code></pre></p>"},{"location":"docs/16_OBSERVABILIDAD/#recuperacion-rapida","title":"Recuperaci\u00f3n R\u00e1pida","text":""},{"location":"docs/16_OBSERVABILIDAD/#opcion-a-reiniciar-servicio","title":"Opci\u00f3n A: Reiniciar servicio","text":"<pre><code>docker restart bankchurn-api\n# Esperar 30s y verificar\ncurl http://localhost:8001/health\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#opcion-b-recrear-contenedor","title":"Opci\u00f3n B: Recrear contenedor","text":"<pre><code>docker compose -f docker-compose.demo.yml up -d bankchurn\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#opcion-c-rollback-a-version-anterior","title":"Opci\u00f3n C: Rollback a versi\u00f3n anterior","text":"<pre><code># Si el problema es por deploy reciente\ndocker pull ghcr.io/duqueom/bankchurn:previous-tag\ndocker compose up -d\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#causas-comunes","title":"Causas Comunes","text":"Causa Diagn\u00f3stico Soluci\u00f3n OOM Kill <code>docker logs</code> muestra <code>Killed</code> Aumentar memory limit Puerto ocupado <code>netstat -tlnp | grep 8001</code> Matar proceso conflictivo Modelo no encontrado Log: <code>FileNotFoundError</code> Verificar volumen montado Crash en startup Exit code 1 Ver logs completos"},{"location":"docs/16_OBSERVABILIDAD/#comunicacion","title":"Comunicaci\u00f3n","text":"<ul> <li>Notificar en #incidents-ml dentro de 5 min</li> <li>Si &gt; 15 min: Actualizar status page</li> <li>Si &gt; 30 min: Escalar a management <pre><code>### 16.5.4 Template de Runbook\n\n```markdown\n# \ud83d\udea8 Runbook: [NOMBRE_ALERTA]\n\n## Resumen\n| Campo | Valor |\n|-------|-------|\n| Alerta | `[nombre]` |\n| Severidad | [Warning/Critical] |\n| Impacto | [Descripci\u00f3n del impacto en usuarios/negocio] |\n| SLA | [Tiempo m\u00e1ximo de respuesta] |\n| Owner | [@team o @persona] |\n\n## Diagn\u00f3stico\n1. [Paso 1 con comando]\n2. [Paso 2 con comando]\n3. [Paso 3]\n\n## Causas Comunes\n| Causa | S\u00edntomas | Soluci\u00f3n |\n|-------|----------|----------|\n| [Causa 1] | [C\u00f3mo identificarla] | [Comandos/pasos] |\n| [Causa 2] | [C\u00f3mo identificarla] | [Comandos/pasos] |\n\n## Escalaci\u00f3n\n- [Cu\u00e1ndo escalar]\n- [A qui\u00e9n escalar]\n\n## Referencias\n- [Links a dashboards relevantes]\n- [Links a documentaci\u00f3n]\n</code></pre></li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#1655-organizacion-de-runbooks-en-el-repo","title":"16.5.5 Organizaci\u00f3n de Runbooks en el Repo","text":"<pre><code>docs/runbooks/\n\u251c\u2500\u2500 README.md                    # \u00cdndice de runbooks\n\u251c\u2500\u2500 high-latency.md             # Latencia alta\n\u251c\u2500\u2500 high-error-rate.md          # Tasa de error\n\u251c\u2500\u2500 service-down.md             # Servicio ca\u00eddo\n\u251c\u2500\u2500 data-drift.md               # Drift detectado\n\u251c\u2500\u2500 model-degradation.md        # Degradaci\u00f3n de m\u00e9tricas\n\u2514\u2500\u2500 disk-full.md                # Disco lleno (artifacts/logs)\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#165-ingenieria-inversa-pedagogica-observabilidad-de-produccion-real","title":"16.5 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Observabilidad de Producci\u00f3n Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s de la configuraci\u00f3n de Prometheus/Alertas del portafolio.</p> <p>Esta secci\u00f3n disecciona la infraestructura de observabilidad real que monitorea los 3 proyectos ML del portafolio.</p>"},{"location":"docs/16_OBSERVABILIDAD/#1651-el-por-que-arquitectonico","title":"16.5.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 el portafolio tiene archivos separados para <code>prometheus-config.yaml</code> y <code>prometheus-rules.yaml</code>?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo descubro autom\u00e1ticamente nuevos pods ML en Kubernetes?       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: A\u00f1adir targets manualmente es error-prone y no escala                  \u2502\n\u2502  DECISI\u00d3N: Kubernetes Service Discovery + annotations                           \u2502\n\u2502  RESULTADO: Prometheus auto-descubre pods con `prometheus.io/scrape: true`      \u2502\n\u2502  REFERENCIA: prometheus-config.yaml l\u00edneas 37-67                                \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo separo reglas de alerta por equipo/dominio?                  \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Un archivo gigante de reglas es imposible de mantener                  \u2502\n\u2502  DECISI\u00d3N: Grupos de reglas: `ml_services_alerts`, `ml_model_alerts`, `infra`   \u2502\n\u2502  RESULTADO: Cada equipo gestiona sus alertas, menor \"alert fatigue\"             \u2502\n\u2502  REFERENCIA: prometheus-rules.yaml l\u00edneas 1-3, 78-80, 124-126                   \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo evito alertas falsas que despiertan al oncall a las 3 AM?    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Alert fatigue \u2192 ignorar todas las alertas \u2192 miss real incidents        \u2502\n\u2502  DECISI\u00d3N: `for: 5m` en reglas (debe persistir 5 min antes de alertar)          \u2502\n\u2502  RESULTADO: Picos transitorios no generan alertas, solo problemas reales        \u2502\n\u2502  REFERENCIA: prometheus-rules.yaml l\u00ednea 13, 28, 39                             \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#1652-anatomia-de-prometheus-configyaml","title":"16.5.2 \ud83d\udd0d Anatom\u00eda de <code>prometheus-config.yaml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/infra/prometheus-config.yaml</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Configuraci\u00f3n Global\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nglobal:\n  scrape_interval: 15s        # Cada 15 segundos, Prometheus \"raspa\" m\u00e9tricas.\n  scrape_timeout: 10s         # Si un target no responde en 10s, marca como down.\n  evaluation_interval: 15s    # Cada 15s eval\u00faa reglas de alerta.\n  external_labels:            # Labels a\u00f1adidos a TODAS las m\u00e9tricas.\n    cluster: ml-portfolio     # Identifica el cluster en Grafana multi-cluster.\n    env: production           # Distingue prod/staging/dev.\n# \u00bfPor qu\u00e9 external_labels?\n# - Cuando federas m\u00faltiples Prometheus, necesitas saber de d\u00f3nde viene cada m\u00e9trica.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Service Discovery para Kubernetes\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nscrape_configs:\n  - job_name: 'bankchurn-predictor'\n    kubernetes_sd_configs:            # Service Discovery de Kubernetes.\n    - role: pod                       # Descubre pods (no servicios ni endpoints).\n      namespaces:\n        names:\n        - ml-portfolio                # Solo busca en este namespace.\n    relabel_configs:                  # Transforma labels antes de guardar.\n    - source_labels: [__meta_kubernetes_pod_label_app]\n      action: keep                    # keep: solo mantiene los que matchean.\n      regex: bankchurn-predictor      # Solo pods con label app=bankchurn-predictor.\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n      action: keep\n      regex: true                     # Solo pods con annotation prometheus.io/scrape=true.\n    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n      action: replace\n      target_label: __metrics_path__  # Usa el path de la annotation (ej: /metrics).\n      regex: (.+)\n    - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n      action: replace\n      regex: ([^:]+)(?::\\d+)?;(\\d+)   # Regex: extrae IP y puerto.\n      replacement: $1:$2               # Combina IP:puerto.\n      target_label: __address__\n# \u00bfPor qu\u00e9 relabel_configs tan complejo?\n# - Flexibilidad: cada pod puede definir su propio path y puerto via annotations.\n# - Filtrado: solo scrapea pods que expl\u00edcitamente lo solicitan.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: Static Config para MLflow\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - job_name: 'mlflow'\n    static_configs:                   # Para servicios que no est\u00e1n en K8s SD.\n    - targets: ['mlflow-service.ml-portfolio.svc.cluster.local:5000']\n      labels:\n        service: mlflow\n        env: production\n# \u00bfPor qu\u00e9 static para MLflow?\n# - MLflow no es un pod que escala din\u00e1micamente, es un servicio \u00fanico.\n# - M\u00e1s simple que configurar annotations en el deployment.\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#1653-anatomia-de-prometheus-rulesyaml","title":"16.5.3 \ud83d\udd0d Anatom\u00eda de <code>prometheus-rules.yaml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/infra/prometheus-rules.yaml</code></p> <p>Este archivo define las alertas accionables que notifican al equipo cuando algo va mal.</p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# GRUPO 1: Alertas de Servicios ML (Latencia, Errores, Disponibilidad)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\ngroups:\n- name: ml_services_alerts\n  interval: 30s                       # Eval\u00faa reglas cada 30s.\n  rules:\n  # Alerta: Error Rate &gt; 5%\n  - alert: HighErrorRate\n    expr: |\n      (\n        sum(rate(http_requests_total{status=~\"5..\"}[5m])) by (service)\n        /                             # Divisi\u00f3n: errores / total.\n        sum(rate(http_requests_total[5m])) by (service)\n      ) &gt; 0.05                        # Umbral: 5% de errores.\n    for: 5m                           # CR\u00cdTICO: debe persistir 5 min.\n    labels:\n      severity: warning               # warning vs critical: define escalaci\u00f3n.\n      team: ml-ops                    # \u00bfQui\u00e9n recibe la alerta?\n    annotations:\n      summary: \"High error rate on {{ $labels.service }}\"\n      description: \"Service {{ $labels.service }} has error rate of {{ $value | humanizePercentage }}\"\n# \u00bfPor qu\u00e9 `for: 5m`?\n# - Evita alertar por picos transitorios (ej: un deployment moment\u00e1neo).\n# - Si el problema persiste 5 min, es real y merece atenci\u00f3n.\n\n  # Alerta: Latencia P95 &gt; 2 segundos\n  - alert: HighLatency\n    expr: |\n      histogram_quantile(0.95,        # Percentil 95: el 95% de requests son m\u00e1s r\u00e1pidos.\n        sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)\n      ) &gt; 2                           # Umbral: 2 segundos es muy lento para ML inference.\n    for: 5m\n    labels:\n      severity: warning\n      team: ml-ops\n    annotations:\n      summary: \"High latency on {{ $labels.service }}\"\n      description: \"95th percentile latency is {{ $value }}s on {{ $labels.service }}\"\n# \u00bfPor qu\u00e9 P95 y no promedio?\n# - El promedio oculta outliers. P95 muestra la experiencia del \"peor 5%\".\n# - Si P95 = 2s, significa que 1 de cada 20 usuarios espera &gt;2s.\n\n  # Alerta: Servicio Ca\u00eddo\n  - alert: ServiceDown\n    expr: up{job=~\".*-intelligence|.*-predictor\"} == 0\n    for: 2m                           # 2 min para servicios cr\u00edticos (m\u00e1s urgente).\n    labels:\n      severity: critical              # critical \u2192 despierta al oncall.\n      team: ml-ops\n    annotations:\n      summary: \"Service {{ $labels.job }} is down\"\n# \u00bfPor qu\u00e9 el regex `.*-intelligence|.*-predictor`?\n# - Matchea: bankchurn-predictor, telecom-intelligence, carvision-intelligence.\n# - Un solo regex cubre los 3 proyectos del portafolio.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# GRUPO 2: Alertas de Modelo ML (Drift, Confianza, Volumen)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n- name: ml_model_alerts\n  interval: 1m                        # Eval\u00faa cada minuto (ML puede cambiar r\u00e1pido).\n  rules:\n  # Alerta: Drift Detectado\n  - alert: ModelDrift\n    expr: model_drift_score &gt; 0.1     # M\u00e9trica custom expuesta por la API.\n    for: 15m                          # Drift necesita tiempo para confirmarse.\n    labels:\n      severity: warning\n      team: ml-ops\n    annotations:\n      summary: \"Model drift detected on {{ $labels.model }}\"\n# \u00bfPor qu\u00e9 15 minutos para drift?\n# - Drift es gradual, no instant\u00e1neo. 15 min evita falsas alarmas.\n\n  # Alerta: Muchas predicciones de baja confianza\n  - alert: LowPredictionConfidence\n    expr: |\n      (\n        sum(model_predictions_total{confidence=\"low\"}) by (model)\n        /\n        sum(model_predictions_total) by (model)\n      ) &gt; 0.3                         # &gt;30% de predicciones con baja confianza.\n    for: 10m\n    labels:\n      severity: warning\n      team: ml-ops\n# \u00bfPor qu\u00e9 alertar por baja confianza?\n# - Indica que el modelo est\u00e1 \"inseguro\" sobre sus predicciones.\n# - Puede se\u00f1alar datos out-of-distribution o necesidad de reentrenamiento.\n\n  # Alerta: Ca\u00edda en volumen de predicciones\n  - alert: PredictionRateDrop\n    expr: |\n      (\n        rate(model_predictions_total[5m])\n        /\n        rate(model_predictions_total[5m] offset 1h)  # Compara con hace 1 hora.\n      ) &lt; 0.5                         # Menos del 50% del volumen normal.\n    for: 10m\n    labels:\n      severity: warning\n      team: ml-ops\n# \u00bfPor qu\u00e9 alertar por ca\u00edda de volumen?\n# - Puede indicar: frontend roto, datos que no llegan, o cambio en comportamiento.\n# - Es una se\u00f1al de que \"algo cambi\u00f3\" aunque el modelo funcione.\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#1654-laboratorio-de-replicacion","title":"16.5.4 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Configurar Prometheus con alertas ML b\u00e1sicas.</p> <ol> <li> <p>A\u00f1ade annotations a tu Deployment de Kubernetes:    <pre><code># k8s/bankchurn-deployment.yaml\nspec:\n  template:\n    metadata:\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8000\"\n        prometheus.io/path: \"/metrics\"\n</code></pre></p> </li> <li> <p>Crea tu primera regla de alerta:    <pre><code># infra/my-alerts.yaml\ngroups:\n- name: mi_primera_alerta\n  rules:\n  - alert: APILatenciaAlta\n    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) &gt; 1\n    for: 2m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Latencia P95 &gt; 1 segundo\"\n</code></pre></p> </li> <li> <p>Verifica en Prometheus UI (http://localhost:9090/alerts) que la regla aparece.</p> </li> </ol>"},{"location":"docs/16_OBSERVABILIDAD/#1655-troubleshooting-preventivo","title":"16.5.5 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n Target \"down\" en Prometheus pero el pod est\u00e1 running Annotations faltantes o incorrectas Verifica <code>prometheus.io/scrape: \"true\"</code> en el pod. Alerta nunca se dispara aunque hay errores El <code>for:</code> es muy largo o la expr est\u00e1 mal Prueba la expr en Prometheus UI primero. Reduce <code>for:</code> temporalmente. Demasiadas alertas (alert fatigue) Umbrales muy bajos o <code>for:</code> muy corto Ajusta umbrales bas\u00e1ndote en baseline real. A\u00f1ade <code>for: 5m</code>. M\u00e9tricas de modelo no aparecen El endpoint <code>/metrics</code> no expone m\u00e9tricas custom Verifica que <code>prometheus_client</code> est\u00e1 instrumentado en tu c\u00f3digo. Grafana no muestra datos Datasource mal configurado o query incorrecta Prueba la query en Prometheus UI. Verifica URL del datasource."},{"location":"docs/16_OBSERVABILIDAD/#errores-habituales-y-como-depurarlos-en-observabilidad-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en Observabilidad ML","text":"<p>En observabilidad ML es habitual tener dashboards bonitos pero poca se\u00f1al \u00fatil, o scripts de drift que fallan en silencio.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/16_OBSERVABILIDAD/#1-metricas-que-no-aparecen-en-prometheusgrafana","title":"1) M\u00e9tricas que no aparecen en Prometheus/Grafana","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En Grafana, los paneles muestran <code>No data</code>.</li> <li>En Prometheus, la m\u00e9trica <code>predictions_total</code> no existe o tiene solo ceros.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica que el endpoint <code>/metrics</code> responde localmente (<code>curl http://localhost:8000/metrics</code>).</li> <li>Revisa <code>prometheus-config.yaml</code>:</li> <li>\u00bfEl <code>job_name</code> y <code>targets</code> apuntan al host/puerto correctos?</li> <li>\u00bf<code>metrics_path</code> es <code>/metrics</code>?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Asegura que el API exponga <code>/metrics</code> y que el contenedor est\u00e9 accesible desde Prometheus (mismo docker network).</li> <li>Usa nombres de servicio (<code>bankchurn:8000</code>) coherentes con <code>docker-compose</code>.</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#2-alertas-demasiado-ruidosas-alert-fatigue","title":"2) Alertas demasiado ruidosas (alert fatigue)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Canal de Slack/Email lleno de alertas constantes que el equipo ignora.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa las reglas de alerta: thresholds demasiado agresivos (por ejemplo, alertar por cualquier spike puntual).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa ventanas de tiempo y reglas de severidad (warning vs critical).</li> <li>Define claramente m\u00e9tricas cr\u00edticas (latencia P99, error rate, dataset_drift) y otras solo informativas.</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#3-logs-json-imposibles-de-parsear","title":"3) Logs JSON imposibles de parsear","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>La herramienta de logs (ELK, Loki, etc.) no reconoce campos como <code>request_id</code> o <code>prediction</code>.</li> <li>Aparecen l\u00edneas mezcladas de formatos distintos.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa <code>setup_logging</code>: \u00bftodos los handlers usan <code>JSONFormatter</code> en producci\u00f3n?</li> <li>Busca logs que usen <code>print</code> en vez de <code>logger.info</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Centraliza la configuraci\u00f3n de logging y evita crear loggers adicionales con otros formatos.</li> <li>Usa siempre <code>extra={...}</code> en los logs de negocio en vez de concatenar strings.</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#4-script-de-drift-que-falla-en-ci-o-nunca-encuentra-drift","title":"4) Script de drift que falla en CI o nunca encuentra drift","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>El workflow <code>drift-detection.yml</code> falla por <code>ImportError: evidently</code> o rutas incorrectas.</li> <li>El script siempre devuelve \"\u2705 No hay drift\" aunque sabes que los datos cambiaron.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa los paths <code>--reference</code> y <code>--current</code> usados en el workflow.</li> <li>Comprueba que <code>EVIDENTLY_AVAILABLE</code> es <code>True</code> y que las columnas de referencia/actual coinciden.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Alinea las rutas de datos de referencia y actuales con la estructura de tu repo.</li> <li>Aseg\u00farate de instalar <code>evidently</code> en el job de CI (<code>pip install evidently</code>).</li> <li>Revisa el JSON de m\u00e9tricas generado para validar que <code>drift_share</code> y <code>drifted_features</code> tienen sentido.</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#5-patron-general-de-debugging-en-observabilidad-ml","title":"5) Patr\u00f3n general de debugging en observabilidad ML","text":"<ol> <li>Empieza por el flujo de datos: API \u2192 <code>/metrics</code> \u2192 Prometheus \u2192 Grafana.</li> <li>Verifica que logs y m\u00e9tricas contengan campos de negocio (no solo t\u00e9cnica b\u00e1sica).</li> <li>Revisa peri\u00f3dicamente los umbrales de alerta seg\u00fan el comportamiento real del sistema.</li> <li>Usa los reports de drift como insumo para decisiones, no como verdad absoluta: comb\u00ednalos con m\u00e9tricas de negocio.</li> </ol> <p>Con esta mentalidad, la observabilidad deja de ser un \"extra\" y se convierte en tu principal herramienta para operar modelos en producci\u00f3n.</p>"},{"location":"docs/16_OBSERVABILIDAD/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/16_OBSERVABILIDAD/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Observability vs Monitoring: Monitoring = m\u00e9tricas predefinidas, Observability = entender comportamiento inesperado.</p> </li> <li> <p>Three Pillars: Logs, Metrics, Traces. Explica cada uno.</p> </li> <li> <p>ML Monitoring: Model drift, data drift, concept drift.</p> </li> </ol>"},{"location":"docs/16_OBSERVABILIDAD/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Alertas Evita alert fatigue: alerta solo lo accionable Dashboards Un dashboard por audiencia (ops, ML, negocio) On-call Documenta runbooks para cada alerta Drift detection Monitorea distribuciones de features y predictions"},{"location":"docs/16_OBSERVABILIDAD/#metricas-clave-para-ml","title":"M\u00e9tricas Clave para ML","text":"<ul> <li>Serving: Latency p50/p95/p99, error rate, throughput</li> <li>Model: Prediction distribution, confidence scores</li> <li>Data: Missing values, schema changes, drift</li> <li>Business: Conversion, revenue impact</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/16_OBSERVABILIDAD/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Prometheus + Grafana Tutorial TechWorld with Nana 50 min YouTube \ud83d\udfe1 ML Model Monitoring with Evidently Evidently AI 30 min YouTube \ud83d\udfe2 Drift Detection Explained NannyML 25 min YouTube"},{"location":"docs/16_OBSERVABILIDAD/#cursos","title":"\ud83d\udcda Cursos","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Duraci\u00f3n Link \ud83d\udfe1 ML Monitoring Made With ML 3h MadeWithML"},{"location":"docs/16_OBSERVABILIDAD/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Evidently Docs Documentaci\u00f3n oficial \ud83d\udfe1 Prometheus Docs Documentaci\u00f3n de Prometheus \ud83d\udfe2 Grafana Dashboards Creaci\u00f3n de dashboards"},{"location":"docs/16_OBSERVABILIDAD/#decision-tecnica-adr-011-prometheus-grafana","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-011 Prometheus + Grafana","text":"<p>Contexto: Necesitamos monitorear modelos en producci\u00f3n y detectar drift.</p> <p>Decisi\u00f3n: Usar Prometheus para m\u00e9tricas y Grafana para dashboards.</p> <p>Alternativas Consideradas: - Datadog: Excelente pero costoso - New Relic: Similar a Datadog - CloudWatch/Stackdriver: Vendor lock-in</p> <p>Consecuencias: - \u2705 Open source, sin costo - \u2705 Est\u00e1ndar de la industria - \u2705 Alertas configurables - \u2705 Integraci\u00f3n con K8s nativa - \u274c M\u00e1s setup que SaaS</p>"},{"location":"docs/16_OBSERVABILIDAD/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/16_OBSERVABILIDAD/#ejercicio-161-logging-estructurado","title":"Ejercicio 16.1: Logging Estructurado","text":"<p>Objetivo: Implementar logging profesional en JSON. Dificultad: \u2b50\u2b50</p> <pre><code># TU TAREA: Configurar logging estructurado\n\nimport logging\nimport json\nfrom datetime import datetime\n\nclass JSONFormatter(logging.Formatter):\n    \"\"\"Formatter que produce logs en JSON.\"\"\"\n\n    def format(self, record):\n        log_data = {\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"level\": record.levelname,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            # TODO: A\u00f1adir m\u00e1s campos \u00fatiles\n        }\n        return json.dumps(log_data)\n\n# TODO: Configurar logger con este formatter\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>import logging\nimport json\nimport sys\nfrom datetime import datetime\nfrom typing import Any\n\nclass JSONFormatter(logging.Formatter):\n    \"\"\"Formatter que produce logs en JSON estructurado.\"\"\"\n\n    def format(self, record: logging.LogRecord) -&gt; str:\n        log_data: dict[str, Any] = {\n            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n            \"level\": record.levelname,\n            \"logger\": record.name,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n            \"function\": record.funcName,\n            \"line\": record.lineno,\n        }\n\n        # A\u00f1adir campos extra si existen\n        if hasattr(record, \"customer_id\"):\n            log_data[\"customer_id\"] = record.customer_id\n        if hasattr(record, \"prediction\"):\n            log_data[\"prediction\"] = record.prediction\n        if hasattr(record, \"latency_ms\"):\n            log_data[\"latency_ms\"] = record.latency_ms\n\n        # A\u00f1adir exception si existe\n        if record.exc_info:\n            log_data[\"exception\"] = self.formatException(record.exc_info)\n\n        return json.dumps(log_data)\n\n\ndef setup_logger(name: str = \"ml_api\") -&gt; logging.Logger:\n    \"\"\"Configura logger con formato JSON.\"\"\"\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # Handler para stdout\n    handler = logging.StreamHandler(sys.stdout)\n    handler.setFormatter(JSONFormatter())\n    logger.addHandler(handler)\n\n    return logger\n\n\n# Uso:\nlogger = setup_logger()\nlogger.info(\"Prediction made\", extra={\"customer_id\": 123, \"prediction\": 1, \"latency_ms\": 45})\n# Output: {\"timestamp\": \"2024-01-15T10:30:00Z\", \"level\": \"INFO\", \"message\": \"Prediction made\", ...}\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Data Drift Cambio en la distribuci\u00f3n de features entre training y producci\u00f3n Concept Drift Cambio en la relaci\u00f3n P(Y|X) entre features y target PSI Population Stability Index - m\u00e9trica para detectar drift Prometheus Sistema open source de monitoreo y alertas basado en m\u00e9tricas Grafana Plataforma de visualizaci\u00f3n para dashboards de m\u00e9tricas"},{"location":"docs/16_OBSERVABILIDAD/#checkpoint-fase-3-mlops-core-completado","title":"\ud83c\udfc1 CHECKPOINT FASE 3: MLOps Core Completado","text":"<p>\ud83c\udfaf \u00a1Has completado los m\u00f3dulos 11-16!</p> <p>Ahora dominas las pr\u00e1cticas que distinguen un proyecto ML profesional: - \u2705 Testing para ML con 80%+ coverage - \u2705 CI/CD con GitHub Actions - \u2705 Docker multi-stage y docker-compose - \u2705 APIs de producci\u00f3n con FastAPI - \u2705 Dashboards interactivos con Streamlit - \u2705 Observabilidad con Prometheus/Grafana y drift detection</p>"},{"location":"docs/16_OBSERVABILIDAD/#examenes-de-hito-testing-y-deployment","title":"\ud83d\udccb Ex\u00e1menes de Hito: Testing y Deployment","text":""},{"location":"docs/16_OBSERVABILIDAD/#examen-3-testing-extracto","title":"Examen 3: Testing (Extracto)","text":"<p>C\u00f3digo a Revisar: <pre><code># tests/test_model.py\n\ndef test_model():\n    model = load_model()\n    data = pd.read_csv(\"data/test.csv\")\n    predictions = model.predict(data)\n    assert len(predictions) == len(data)\n</code></pre></p> <p>Problemas a identificar: \u00bfQu\u00e9 falta en este test?</p> \ud83d\udcdd Ver Soluci\u00f3n  **Errores:** 1. No usa fixtures (hardcoded paths) 2. No verifica tipos de predicciones 3. No valida rangos v\u00e1lidos 4. No es reproducible (depende de archivo externo)  **Test Corregido:** <pre><code>import pytest\nimport numpy as np\n\n@pytest.fixture\ndef sample_data():\n    return pd.DataFrame({\n        \"feature1\": [1.0, 2.0, 3.0],\n        \"feature2\": [0.5, 1.5, 2.5],\n    })\n\n@pytest.fixture\ndef trained_model(sample_data):\n    # Modelo entrenado en fixture\n    return train_model(sample_data, labels=[0, 1, 0])\n\ndef test_predictions_shape(trained_model, sample_data):\n    predictions = trained_model.predict(sample_data)\n    assert len(predictions) == len(sample_data)\n\ndef test_predictions_valid_range(trained_model, sample_data):\n    predictions = trained_model.predict(sample_data)\n    assert all(p in [0, 1] for p in predictions)\n\ndef test_predictions_type(trained_model, sample_data):\n    predictions = trained_model.predict(sample_data)\n    assert isinstance(predictions, np.ndarray)\n</code></pre>"},{"location":"docs/16_OBSERVABILIDAD/#simulacro-de-entrevista-nivel-mid","title":"\ud83c\udfa4 Simulacro de Entrevista: Nivel Mid","text":"<p>60 preguntas para validar MLOps Core (M\u00f3dulos 07-16) Tiempo: 90 minutos Objetivo: Preparaci\u00f3n para posiciones Mid ML Engineer</p>"},{"location":"docs/16_OBSERVABILIDAD/#preguntas-de-muestra","title":"Preguntas de Muestra","text":"<p>Testing ML (10 preguntas) 1. \u00bfQu\u00e9 es la pir\u00e1mide de testing y c\u00f3mo aplica a ML? 2. \u00bfC\u00f3mo testeas que un modelo no tiene data leakage? 3. \u00bfQu\u00e9 fixtures usar\u00edas en <code>conftest.py</code> para tests ML?</p> <p>CI/CD (10 preguntas) 4. \u00bfC\u00f3mo configurar\u00edas matrix testing en GitHub Actions? 5. \u00bfQu\u00e9 es un coverage gate y por qu\u00e9 es importante? 6. \u00bfC\u00f3mo integras security scanning en tu pipeline?</p> <p>Docker (10 preguntas) 7. \u00bfPor qu\u00e9 usar multi-stage builds para ML? 8. \u00bfC\u00f3mo optimizas el tama\u00f1o de imagen Docker para ML? 9. \u00bfQu\u00e9 es un usuario non-root y por qu\u00e9 usarlo?</p> <p>APIs (10 preguntas) 10. \u00bfC\u00f3mo manejas errores en FastAPI para ML? 11. \u00bfQu\u00e9 endpoints de health check implementar\u00edas? 12. \u00bfC\u00f3mo validas inputs con Pydantic en APIs ML?</p> <p>Observabilidad (10 preguntas) 13. \u00bfQu\u00e9 m\u00e9tricas capturar\u00edas para un modelo en producci\u00f3n? 14. \u00bfC\u00f3mo detectas data drift en producci\u00f3n? 15. \u00bfDiferencia entre logging estructurado y tradicional?</p> \ud83d\udca1 Ver Respuestas de Muestra  **1. Pir\u00e1mide de testing en ML:** &gt; Base: unit tests (funciones individuales), Medio: integration tests (pipeline completo), Top: E2E tests (API funcionando). En ML agregamos: tests de datos (schema, rangos), tests de modelo (reproducibilidad, m\u00e9tricas m\u00ednimas).  **7. Multi-stage builds:** &gt; Separamos build (instalar dependencias, compilar) de runtime (solo lo necesario para ejecutar). Reduce imagen de ~2GB a ~500MB. Stage 1: instala todo, Stage 2: copia solo wheels y c\u00f3digo.  **14. Detectar data drift:** &gt; PSI (Population Stability Index) para features categ\u00f3ricas, KS-test para num\u00e9ricas. Umbral t\u00edpico: PSI &gt; 0.2 = drift significativo. Herramientas: Evidently, Alibi Detect, Great Expectations.  <p>Ver simulacro completo \u2192</p>"},{"location":"docs/16_OBSERVABILIDAD/#_2","title":"16 \u2014 Observabilidad","text":"<p>\u2705 Checkpoint del M\u00f3dulo</p> <ul> <li>[ ] Tienes endpoint <code>/metrics</code> en tu API</li> <li>[ ] Logs en formato JSON estructurado</li> <li>[ ] Script de drift detection funcional</li> <li>[ ] Alertas configuradas para m\u00e9tricas cr\u00edticas</li> </ul>"},{"location":"docs/16_OBSERVABILIDAD/#siguiente-fase-produccion","title":"\ud83d\udd1c Siguiente Fase: Producci\u00f3n","text":"<p>Con MLOps Core completado, es hora de aprender estrategias de despliegue e infraestructura.</p> <p>Comenzar Fase 4 \u2192 M\u00f3dulo 17: Despliegue</p>   [\u2190 Streamlit Dashboards](15_STREAMLIT.md) | [Siguiente: Despliegue \u2192](17_DESPLIEGUE.md)"},{"location":"docs/17_DESPLIEGUE/","title":"M\u00d3DULO 17: SERVERLESS VS CONTENEDORES","text":"# \ud83c\udf10 M\u00d3DULO 17: Serverless vs Contenedores  ### La Decisi\u00f3n que Define tu Arquitectura  *\"No hay soluci\u00f3n universal. Hay trade-offs que debes entender.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **4-5 horas**        | 40%                  | 60%                  |"},{"location":"docs/17_DESPLIEGUE/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>17.1 Matriz de Decisi\u00f3n</li> <li>17.2 Opci\u00f3n 1: Serverless (AWS Lambda)</li> <li>17.3 Opci\u00f3n 2: Contenedores Managed</li> <li>17.4 Opci\u00f3n 3: Kubernetes</li> <li>17.5 An\u00e1lisis de Costos (FinOps)</li> <li>17.6 Decisi\u00f3n para BankChurn</li> <li>17.7 \ud83d\udd2c Ingenier\u00eda Inversa: K8s Ingress Real \u2b50 NUEVO</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado el m\u00f3dulo 13 (Docker) para entender im\u00e1genes, redes y puertos.</li> <li>Haber completado el m\u00f3dulo 14 (FastAPI) y contar con un endpoint <code>/health</code>.</li> <li>Conocer los conceptos de latencia, throughput y costo (FinOps b\u00e1sico).</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de elegir: define tu escenario (tr\u00e1fico, latencia, costo y equipo Ops).</li> <li>Durante el estudio: convierte la teor\u00eda en una decisi\u00f3n expl\u00edcita (ADR) y un deploy m\u00ednimo (Cloud Run/ECS o Lambda).</li> <li>Si te atoras &gt;15 min con puertos, healthchecks, cold starts o tama\u00f1o de imagen, registra el caso en el Diario de Errores y aplica el flujo de Protocolo E.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] ADR (decisi\u00f3n y trade-offs) para tu caso (por ejemplo: MVP en Cloud Run).</li> <li>[ ] Deploy funcional (Cloud Run/ECS o Lambda) con <code>/health</code> y un endpoint de predicci\u00f3n.</li> <li>[ ] Healthcheck verificado en plataforma (readiness/liveness o equivalente).</li> <li>[ ] Plan de rollback (documentado y probado al menos una vez).</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Teor\u00eda: serverless vs contenedores vs Kubernetes</li> <li>Pr\u00e1ctica: Dockerfile + deploy en Cloud Run/ECS + runbooks</li> <li>Prueba: <code>curl /health</code> en el endpoint desplegado + revisi\u00f3n de logs/healthchecks</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/17_DESPLIEGUE/#ejercicio-puente-deploy","title":"\ud83d\udcbb Ejercicio Puente: Deploy","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/17_DESPLIEGUE/#practica-del-portafolio-despliegue-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Despliegue en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Deploy\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/17_DESPLIEGUE/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Despliegue?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Deploy, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/17_DESPLIEGUE/#171-matriz-de-decision","title":"17.1 Matriz de Decisi\u00f3n","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    MATRIZ DE DECISI\u00d3N DE DESPLIEGUE                           \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   Factor              \u2502 Lambda/Serverless \u2502 ECS/Cloud Run \u2502 Kubernetes        \u2551\n\u2551   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2551\n\u2551   Tr\u00e1fico             \u2502 &lt; 1M req/mes      \u2502 1M-100M       \u2502 &gt; 100M            \u2551\n\u2551   Latencia            \u2502 Variable (cold)   \u2502 Consistente   \u2502 Consistente       \u2551\n\u2551   Costo bajo tr\u00e1fico  \u2502 \ud83d\udcb0 Muy bajo       \u2502 \ud83d\udcb0\ud83d\udcb0 Medio    \u2502 \ud83d\udcb0\ud83d\udcb0\ud83d\udcb0 Alto      \u2551\n\u2551   Costo alto tr\u00e1fico  \u2502 \ud83d\udcb0\ud83d\udcb0\ud83d\udcb0 Caro       \u2502 \ud83d\udcb0\ud83d\udcb0 Medio    \u2502 \ud83d\udcb0 Barato        \u2551\n\u2551   Complejidad Ops     \u2502 \u2b50 Baja           \u2502 \u2b50\u2b50 Media   \u2502 \u2b50\u2b50\u2b50\u2b50 Alta  \u2551\n\u2551   Equipo necesario    \u2502 1 persona         \u2502 2-3 personas  \u2502 5+ personas       \u2551\n\u2551   GPU Support         \u2502 \u274c                \u2502 \u2705           \u2502 \u2705               \u2551\n\u2551   Max memoria         \u2502 10GB              \u2502 120GB+        \u2502 Ilimitado         \u2551\n\u2551   Max timeout         \u2502 15 min            \u2502 Ilimitado     \u2502 Ilimitado         \u2551\n\u2551   Modelo size l\u00edmite  \u2502 ~250MB pkg        \u2502 Sin l\u00edmite    \u2502 Sin l\u00edmite        \u2551\n\u2551   Auto-scaling        \u2502 Autom\u00e1tico        \u2502 Autom\u00e1tico    \u2502 Configurable      \u2551\n\u2551   Vendor lock-in      \u2502 Alto              \u2502 Medio         \u2502 Bajo              \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#172-opcion-1-serverless-aws-lambda","title":"17.2 Opci\u00f3n 1: Serverless (AWS Lambda)","text":""},{"location":"docs/17_DESPLIEGUE/#cuando-usar","title":"Cu\u00e1ndo Usar","text":"<pre><code>\u2705 USA LAMBDA SI:\n\u2022 Tr\u00e1fico bajo o espor\u00e1dico (&lt; 1M requests/mes)\n\u2022 Modelo peque\u00f1o (&lt; 250MB empaquetado)\n\u2022 Latencia variable es aceptable\n\u2022 No tienes equipo de DevOps\n\u2022 Quieres minimizar costos en bajo tr\u00e1fico\n\n\u274c NO USES LAMBDA SI:\n\u2022 Necesitas GPU\n\u2022 Modelo &gt; 250MB\n\u2022 Cold starts son inaceptables (&lt; 100ms requerido)\n\u2022 Tr\u00e1fico constante y alto\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#estructura-para-lambda","title":"Estructura para Lambda","text":"<pre><code>lambda_function/\n\u251c\u2500\u2500 handler.py          # Entry point\n\u251c\u2500\u2500 model/\n\u2502   \u2514\u2500\u2500 pipeline.pkl    # Modelo (&lt; 250MB)\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 inference.py    # L\u00f3gica\n\u2514\u2500\u2500 requirements.txt\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#handlerpy","title":"handler.py","text":"<pre><code># handler.py - AWS Lambda Handler\nimport json                              # Parse/serialize JSON.\nimport joblib                            # Cargar modelo sklearn.\nimport pandas as pd                      # DataFrame para predicci\u00f3n.\nfrom pathlib import Path                 # Rutas multiplataforma.\n\n# Cargar modelo al inicio (fuera del handler para reutilizar)\nMODEL_PATH = Path(__file__).parent / \"model\" / \"pipeline.pkl\"  # Ruta relativa al handler.\nmodel = joblib.load(MODEL_PATH)          # Se carga UNA vez (warm start reutiliza).\n\ndef lambda_handler(event, context):      # Punto de entrada de Lambda. context: metadata del runtime.\n    \"\"\"AWS Lambda handler.\"\"\"\n    try:\n        # Parse input - Lambda puede recibir body como string o dict\n        if isinstance(event.get(\"body\"), str):  # API Gateway env\u00eda body como string.\n            body = json.loads(event[\"body\"])    # Deserializa JSON.\n        else:\n            body = event.get(\"body\", event)     # Invocaci\u00f3n directa: body es dict.\n\n        # Crear DataFrame\n        df = pd.DataFrame([body])               # Lista con 1 elemento \u2192 1 fila.\n\n        # Predecir\n        proba = model.predict_proba(df)[0, 1]   # [0,1]: fila 0, clase positiva.\n        prediction = \"churn\" if proba &gt;= 0.5 else \"no_churn\"  # Umbral 0.5.\n\n        return {                                # Response format para API Gateway.\n            \"statusCode\": 200,                  # HTTP 200 OK.\n            \"headers\": {\"Content-Type\": \"application/json\"},\n            \"body\": json.dumps({                # body DEBE ser string JSON.\n                \"churn_probability\": round(proba, 4),\n                \"prediction\": prediction,\n            })\n        }\n    except Exception as e:\n        return {\n            \"statusCode\": 500,                  # 500: Internal Server Error.\n            \"body\": json.dumps({\"error\": str(e)})\n        }\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#serverlessyml-serverless-framework","title":"serverless.yml (Serverless Framework)","text":"<pre><code># serverless.yml\nservice: bankchurn-predictor             # Nombre del servicio (prefijo de recursos).\n\nprovider:\n  name: aws                              # Cloud provider.\n  runtime: python3.11                    # Versi\u00f3n de Python.\n  region: us-east-1                      # Regi\u00f3n de AWS.\n  memorySize: 1024                       # MB de RAM (m\u00e1s RAM = m\u00e1s CPU proporcional).\n  timeout: 30                            # Timeout en segundos (m\u00e1x 15 min).\n\nfunctions:\n  predict:                               # Nombre de la funci\u00f3n Lambda.\n    handler: handler.lambda_handler      # m\u00f3dulo.funci\u00f3n a ejecutar.\n    events:                              # Triggers que invocan la funci\u00f3n.\n      - http:                            # API Gateway HTTP trigger.\n          path: predict                  # Ruta: /predict\n          method: post                   # M\u00e9todo HTTP.\n          cors: true                     # Habilita CORS autom\u00e1ticamente.\n\nplugins:\n  - serverless-python-requirements      # Plugin para empaquetar deps de Python.\n\ncustom:\n  pythonRequirements:\n    dockerizePip: true                   # Compila deps en Docker (para binarios nativos).\n    slim: true                           # Elimina archivos innecesarios (reduce tama\u00f1o).\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#173-opcion-2-contenedores-managed-aws-ecs-gcp-cloud-run","title":"17.3 Opci\u00f3n 2: Contenedores Managed (AWS ECS / GCP Cloud Run)","text":""},{"location":"docs/17_DESPLIEGUE/#cuando-usar_1","title":"Cu\u00e1ndo Usar","text":"<pre><code>\u2705 USA ECS/CLOUD RUN SI:\n\u2022 Tr\u00e1fico medio-alto (1M-100M requests/mes)\n\u2022 Necesitas latencia consistente\n\u2022 Modelo de cualquier tama\u00f1o\n\u2022 Quieres balance entre control y simplicidad\n\u2022 Equipo peque\u00f1o de DevOps (2-3 personas)\n\n\u274c NO USES SI:\n\u2022 Necesitas control granular de networking\n\u2022 Multi-cloud es requisito\n\u2022 Tr\u00e1fico extremadamente alto (&gt; 100M)\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#aws-ecs-task-definition","title":"AWS ECS Task Definition","text":"<pre><code>{\n  \"family\": \"bankchurn-api\",\n  \"networkMode\": \"awsvpc\",\n  \"requiresCompatibilities\": [\"FARGATE\"],\n  \"cpu\": \"512\",\n  \"memory\": \"1024\",\n  \"containerDefinitions\": [\n    {\n      \"name\": \"api\",\n      \"image\": \"123456789.dkr.ecr.us-east-1.amazonaws.com/bankchurn:latest\",\n      \"portMappings\": [\n        {\n          \"containerPort\": 8000,\n          \"protocol\": \"tcp\"\n        }\n      ],\n      \"environment\": [\n        {\"name\": \"LOG_LEVEL\", \"value\": \"INFO\"}\n      ],\n      \"healthCheck\": {\n        \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8000/health || exit 1\"],\n        \"interval\": 30,\n        \"timeout\": 5,\n        \"retries\": 3\n      },\n      \"logConfiguration\": {\n        \"logDriver\": \"awslogs\",\n        \"options\": {\n          \"awslogs-group\": \"/ecs/bankchurn\",\n          \"awslogs-region\": \"us-east-1\",\n          \"awslogs-stream-prefix\": \"api\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#gcp-cloud-run-mas-simple","title":"GCP Cloud Run (m\u00e1s simple)","text":"<pre><code># Deploy a Cloud Run\ngcloud run deploy bankchurn-api \\\n  --image gcr.io/my-project/bankchurn:latest \\\n  --platform managed \\\n  --region us-central1 \\\n  --allow-unauthenticated \\\n  --memory 1Gi \\\n  --cpu 1 \\\n  --min-instances 0 \\\n  --max-instances 10 \\\n  --port 8000\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#174-opcion-3-kubernetes","title":"17.4 Opci\u00f3n 3: Kubernetes","text":""},{"location":"docs/17_DESPLIEGUE/#cuando-usar_2","title":"Cu\u00e1ndo Usar","text":"<pre><code>\u2705 USA KUBERNETES SI:\n\u2022 Tr\u00e1fico muy alto (&gt; 100M requests/mes)\n\u2022 M\u00faltiples servicios ML que escalan diferente\n\u2022 Necesitas GPU para inferencia\n\u2022 Multi-cloud o hybrid cloud\n\u2022 Equipo de Ops experimentado (5+ personas)\n\u2022 Ya tienes inversi\u00f3n en K8s\n\n\u274c NO USES SI:\n\u2022 Un solo modelo simple\n\u2022 Equipo peque\u00f1o sin experiencia K8s\n\u2022 Presupuesto limitado para Ops\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#manifiestos-basicos","title":"Manifiestos B\u00e1sicos","text":"<pre><code># k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bankchurn-api\n  labels:\n    app: bankchurn-api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bankchurn-api\n  template:\n    metadata:\n      labels:\n        app: bankchurn-api\n    spec:\n      containers:\n      - name: api\n        image: ghcr.io/username/bankchurn:latest\n        ports:\n        - containerPort: 8000\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 10\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 15\n          periodSeconds: 10\n        env:\n        - name: LOG_LEVEL\n          value: \"INFO\"\n---\n# k8s/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: bankchurn-api\nspec:\n  selector:\n    app: bankchurn-api\n  ports:\n  - port: 80\n    targetPort: 8000\n  type: ClusterIP\n---\n# k8s/hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: bankchurn-api\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: bankchurn-api\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#175-analisis-de-costos-finops","title":"17.5 An\u00e1lisis de Costos (FinOps)","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    AN\u00c1LISIS DE COSTOS MENSUAL                                 \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   ESCENARIO: 1M requests/mes, ~1 req/seg promedio                             \u2551\n\u2551                                                                               \u2551\n\u2551   AWS Lambda:                                                                 \u2551\n\u2551   \u2022 1M requests \u00d7 $0.20/1M = $0.20                                            \u2551\n\u2551   \u2022 1M \u00d7 200ms \u00d7 1GB = 200K GB-s \u00d7 $0.0000166 = $3.32                         \u2551\n\u2551   \u2022 Total: ~$4/mes \u2705 (bajo tr\u00e1fico es barato)                                \u2551\n\u2551                                                                               \u2551\n\u2551   ECS Fargate:                                                                \u2551\n\u2551   \u2022 0.5 vCPU \u00d7 730h \u00d7 $0.04 = $14.60                                          \u2551\n\u2551   \u2022 1GB RAM \u00d7 730h \u00d7 $0.004 = $2.92                                           \u2551\n\u2551   \u2022 Total: ~$18/mes (consistente)                                             \u2551\n\u2551                                                                               \u2551\n\u2551   EKS (3 nodos t3.small):                                                     \u2551\n\u2551   \u2022 3 \u00d7 $15/mes (EC2) = $45                                                   \u2551\n\u2551   \u2022 EKS fee: $72/mes                                                          \u2551\n\u2551   \u2022 Total: ~$120/mes (overkill para este volumen)                             \u2551\n\u2551                                                                               \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   ESCENARIO: 100M requests/mes, ~40 req/seg promedio                          \u2551\n\u2551                                                                               \u2551\n\u2551   AWS Lambda:                                                                 \u2551\n\u2551   \u2022 100M \u00d7 $0.20/1M = $20                                                     \u2551\n\u2551   \u2022 100M \u00d7 200ms \u00d7 1GB = 20M GB-s \u00d7 $0.0000166 = $332                         \u2551\n\u2551   \u2022 Total: ~$350/mes (ya no tan barato)                                       \u2551\n\u2551                                                                               \u2551\n\u2551   ECS Fargate (auto-scaling):                                                 \u2551\n\u2551   \u2022 ~5 tareas promedio                                                        \u2551\n\u2551   \u2022 Total: ~$90/mes \u2705                                                        \u2551\n\u2551                                                                               \u2551\n\u2551   EKS (auto-scaling):                                                         \u2551\n\u2551   \u2022 5 nodos t3.medium promedio                                                \u2551\n\u2551   \u2022 Total: ~$200/mes                                                          \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#176-decision-para-bankchurn","title":"17.6 Decisi\u00f3n para BankChurn","text":""},{"location":"docs/17_DESPLIEGUE/#recomendacion-por-fase","title":"Recomendaci\u00f3n por Fase","text":"Fase Plataforma Raz\u00f3n MVP/Desarrollo Cloud Run o Lambda Simplicidad, bajo costo inicial Producci\u00f3n inicial ECS/Cloud Run Balance costo-control Escala enterprise Kubernetes Control total, multi-service"},{"location":"docs/17_DESPLIEGUE/#adr-para-bankchurn","title":"ADR para BankChurn","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  ADR-009: Despliegue de BankChurn en Cloud Run                                \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551  DECISI\u00d3N: Usar Google Cloud Run para el MVP                                  \u2551\n\u2551                                                                               \u2551\n\u2551  RAZONES:                                                                     \u2551\n\u2551  \u2022 Escala a cero cuando no hay tr\u00e1fico (costo m\u00ednimo)                         \u2551\n\u2551  \u2022 Sin gesti\u00f3n de infraestructura                                             \u2551\n\u2551  \u2022 Latencia consistente (mejor que Lambda para ML)                            \u2551\n\u2551  \u2022 Soporta contenedores Docker est\u00e1ndar                                       \u2551\n\u2551  \u2022 F\u00e1cil migraci\u00f3n a GKE si necesario                                         \u2551\n\u2551                                                                               \u2551\n\u2551  TRADE-OFFS ACEPTADOS:                                                        \u2551\n\u2551  \u2022 Vendor lock-in medio (GCP)                                                 \u2551\n\u2551  \u2022 Menos control que K8s                                                      \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#177-ingenieria-inversa-pedagogica-kubernetes-ingress-real","title":"17.7 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Kubernetes Ingress Real","text":"<p>Objetivo: Entender CADA decisi\u00f3n detr\u00e1s del Ingress del portafolio que expone los 3 proyectos ML.</p>"},{"location":"docs/17_DESPLIEGUE/#1771-el-por-que-arquitectonico","title":"17.7.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<p>\u00bfPor qu\u00e9 el portafolio usa Ingress con subdominios en lugar de un solo LoadBalancer por servicio?</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo expongo 3 APIs ML al internet sin 3 LoadBalancers?           \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: $15-20/mes por LoadBalancer \u00d7 3 = $45-60/mes solo en networking        \u2502\n\u2502  DECISI\u00d3N: Un solo Ingress con routing por host/path                            \u2502\n\u2502  RESULTADO: Un LoadBalancer, 3 servicios accesibles, ~$15/mes                   \u2502\n\u2502  REFERENCIA: ingress.yaml spec.rules (l\u00edneas 24-78)                             \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo protejo las APIs con HTTPS sin gestionar certificados?       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: HTTP en producci\u00f3n = credenciales expuestas, penalizaci\u00f3n SEO          \u2502\n\u2502  DECISI\u00d3N: cert-manager + Let's Encrypt (renovaci\u00f3n autom\u00e1tica)                 \u2502\n\u2502  RESULTADO: TLS gratis, autom\u00e1tico, sin intervenci\u00f3n manual                     \u2502\n\u2502  REFERENCIA: ingress.yaml annotations cert-manager.io (l\u00ednea 8)                 \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo evito que un atacante sature las APIs con requests?          \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: DDoS, costos inflados, degradaci\u00f3n para usuarios leg\u00edtimos             \u2502\n\u2502  DECISI\u00d3N: Rate limiting v\u00eda annotations nginx (100 req/s, 10 rps por IP)       \u2502\n\u2502  RESULTADO: Protecci\u00f3n b\u00e1sica sin WAF externo                                   \u2502\n\u2502  REFERENCIA: ingress.yaml annotations rate-limit (l\u00edneas 10-11)                 \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#1772-anatomia-de-ingressyaml","title":"17.7.2 \ud83d\udd0d Anatom\u00eda de <code>ingress.yaml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/k8s/ingress.yaml</code></p> <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ml-portfolio-ingress\n  namespace: ml-portfolio               # Todos los recursos en un namespace.\n  annotations:\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # BLOQUE 1: Configuraci\u00f3n del Ingress Controller\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    kubernetes.io/ingress.class: nginx  # Usa NGINX Ingress Controller.\n    # \u00bfPor qu\u00e9 nginx? Es el est\u00e1ndar, bien documentado, muchas features.\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # BLOQUE 2: TLS Autom\u00e1tico con Let's Encrypt\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    # \u00bfC\u00f3mo funciona?\n    # 1. cert-manager detecta esta annotation.\n    # 2. Solicita certificado a Let's Encrypt v\u00eda ACME challenge.\n    # 3. Almacena el certificado en el Secret indicado en spec.tls.\n    # 4. Renueva autom\u00e1ticamente antes de expirar (cada 90 d\u00edas).\n\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    # Fuerza HTTPS: cualquier request HTTP \u2192 301 a HTTPS.\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # BLOQUE 3: Rate Limiting (Protecci\u00f3n DDoS b\u00e1sica)\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"       # 100 req/s globales.\n    nginx.ingress.kubernetes.io/limit-rps: \"10\"         # 10 req/s por IP.\n    # \u00bfPor qu\u00e9 10 rps por IP?\n    # - Un usuario leg\u00edtimo no hace 10 predicciones por segundo.\n    # - Un scraper/bot s\u00ed, y esto lo bloquea.\n\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    # BLOQUE 4: Timeouts para ML (inferencia puede ser lenta)\n    # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"  # Max body 10MB (im\u00e1genes).\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"60\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n    # \u00bfPor qu\u00e9 60s?\n    # - Inferencia de modelos grandes (CarVision con im\u00e1genes) puede tardar.\n    # - Default de NGINX es 60s, pero lo hacemos expl\u00edcito.\n\nspec:\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # BLOQUE 5: Certificados TLS\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  tls:\n  - hosts:\n    - ml.duqueom.com                    # Dominio principal.\n    - bankchurn.ml.duqueom.com          # Subdominio por proyecto.\n    - telecom.ml.duqueom.com\n    - carvision.ml.duqueom.com\n    secretName: ml-portfolio-tls        # Donde cert-manager guarda el cert.\n  # \u00bfPor qu\u00e9 un solo Secret para 4 dominios?\n  # - Let's Encrypt soporta certificados multi-dominio (SAN).\n  # - Un cert = menos gesti\u00f3n que 4 certs separados.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # BLOQUE 6: Routing por Subdominio (Patr\u00f3n preferido)\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  rules:\n  - host: bankchurn.ml.duqueom.com      # Subdominio dedicado.\n    http:\n      paths:\n      - path: /                          # Todo el tr\u00e1fico va al servicio.\n        pathType: Prefix\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 80\n  # \u00bfPor qu\u00e9 subdominios vs paths?\n  # - Aislamiento: cada proyecto tiene su propio \"namespace\" de URLs.\n  # - Cookies: no se mezclan entre servicios.\n  # - Escalado: puedes mover un subdominio a otro cluster sin afectar otros.\n\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  # BLOQUE 7: Routing por Path (Alternativa para API Gateway)\n  # \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n  - host: ml.duqueom.com\n    http:\n      paths:\n      - path: /bankchurn                 # /bankchurn/* \u2192 bankchurn-service\n        pathType: Prefix\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 80\n      - path: /telecom                   # /telecom/* \u2192 telecom-service\n        pathType: Prefix\n        backend:\n          service:\n            name: telecom-service\n            port:\n              number: 80\n  # \u00bfCu\u00e1ndo usar paths?\n  # - Cuando necesitas un \"API Gateway\" con un solo dominio.\n  # - Para frontends que consumen m\u00faltiples APIs.\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#1773-laboratorio-de-replicacion","title":"17.7.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Crear un Ingress para tu proyecto BankChurn.</p> <ol> <li> <p>Instala NGINX Ingress Controller (si no lo tienes):    <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml\n</code></pre></p> </li> <li> <p>Instala cert-manager para TLS autom\u00e1tico:    <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.2/cert-manager.yaml\n</code></pre></p> </li> <li> <p>Crea tu ClusterIssuer:    <pre><code># clusterissuer.yaml\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: tu-email@example.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre></p> </li> <li> <p>Crea tu Ingress b\u00e1sico:    <pre><code># mi-ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bankchurn-ingress\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  tls:\n  - hosts:\n    - tu-dominio.com\n    secretName: bankchurn-tls\n  rules:\n  - host: tu-dominio.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 80\n</code></pre></p> </li> <li> <p>Verifica:    <pre><code>kubectl apply -f mi-ingress.yaml\nkubectl get certificate  # Espera a que est\u00e9 \"Ready\"\ncurl https://tu-dominio.com/health\n</code></pre></p> </li> </ol>"},{"location":"docs/17_DESPLIEGUE/#1774-troubleshooting-preventivo","title":"17.7.4 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n 404 en el Ingress Servicio no existe o puerto incorrecto <code>kubectl get svc</code> y verifica nombre/puerto. 502 Bad Gateway Pods no est\u00e1n ready o healthcheck falla <code>kubectl get pods</code> y revisa logs del pod. Certificate no se genera DNS no apunta al Ingress IP o ClusterIssuer mal <code>kubectl describe certificate</code> para ver eventos. HTTP funciona pero HTTPS no Secret TLS no existe o est\u00e1 vac\u00edo <code>kubectl get secret bankchurn-tls -o yaml</code>. Rate limit bloquea usuarios leg\u00edtimos Umbral muy bajo Incrementa <code>limit-rps</code> o usa whitelist por IP."},{"location":"docs/17_DESPLIEGUE/#errores-habituales-y-como-depurarlos-en-despliegue-ml","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en despliegue ML","text":"<p>En despliegue ML es muy f\u00e1cil elegir mal la plataforma o romper detalles como puertos, healthchecks o tama\u00f1os de imagen.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/17_DESPLIEGUE/#1-elegir-la-plataforma-equivocada-costos-o-latencia-inesperados","title":"1) Elegir la plataforma equivocada (costos o latencia inesperados)","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Con Lambda: facturas altas al subir el tr\u00e1fico o latencias variables por cold starts.</li> <li>Con K8s: infraestructura sobredimensionada para un solo modelo simple.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara tu caso con la matriz de decisi\u00f3n del m\u00f3dulo (tr\u00e1fico, latencia, equipo Ops, presupuesto).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Para MVPs y tr\u00e1fico moderado, prefiere Cloud Run/ECS en lugar de K8s.</li> <li>Reserva K8s para escenarios enterprise con m\u00faltiples servicios y tr\u00e1fico muy alto.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#2-lambdas-que-no-despliegan-o-fallan-al-importar-el-modelo","title":"2) Lambdas que no despliegan o fallan al importar el modelo","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Errores como <code>Unable to import module 'handler'</code>.</li> <li>Deployment fallido por paquete demasiado grande (&gt; 250MB).</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa el tama\u00f1o del zip y la estructura de <code>lambda_function/</code>.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Empaqueta solo lo necesario (<code>model/</code>, <code>src/</code>, <code>handler.py</code>, <code>requirements.txt</code>).</li> <li>Usa capas o reduce dependencias pesadas si es posible.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#3-contenedores-que-arrancan-pero-nunca-pasan-el-healthcheck","title":"3) Contenedores que arrancan pero nunca pasan el healthcheck","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>En ECS/Cloud Run/K8s el servicio queda en estado <code>UNHEALTHY</code> o se reinicia en bucle.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara el <code>healthCheck</code>/<code>readinessProbe</code> con los endpoints reales (<code>/health</code>, puerto 8000). </li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Asegura que tu API expone exactamente el endpoint y puerto que la plataforma espera.</li> <li>Ajusta <code>initialDelaySeconds</code>/<code>timeout</code> si el modelo tarda en cargar.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#4-puertos-y-rutas-inconsistentes-entre-docker-y-la-plataforma","title":"4) Puertos y rutas inconsistentes entre Docker y la plataforma","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Funciona en <code>docker run -p 8000:8000</code> pero falla al desplegar en Cloud Run/ECS.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica que el <code>EXPOSE</code> del Dockerfile, el puerto del servidor (uvicorn) y el puerto configurado en la plataforma coincidan.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Usa un puerto est\u00e1ndar (8000) y mant\u00e9n el mismo valor en Dockerfile y manifiestos.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#5-patron-general-de-debugging-en-despliegue-ml","title":"5) Patr\u00f3n general de debugging en despliegue ML","text":"<ol> <li>Verifica primero que la imagen Docker funciona en local (<code>docker run</code> + <code>curl /health</code>).</li> <li>Revisa logs de la plataforma (Lambda logs, Cloud Run logs, ECS/K8s events) para ver errores reales.</li> <li>Comprueba healthchecks, puertos y variables de entorno.</li> <li>Ajusta la plataforma elegida si tus patrones de tr\u00e1fico o equipo no encajan con la decisi\u00f3n inicial.</li> </ol> <p>Con esta disciplina, pasar de local a producci\u00f3n se vuelve un proceso repetible y menos doloroso.</p>"},{"location":"docs/17_DESPLIEGUE/#1761-kubernetes-ingress-con-tls-y-rate-limiting","title":"17.6.1 Kubernetes Ingress con TLS y Rate Limiting","text":"<p>Referencia del portafolio: <code>k8s/ingress.yaml</code></p>"},{"location":"docs/17_DESPLIEGUE/#ingress-con-cert-manager-tls-automatico","title":"Ingress con cert-manager (TLS autom\u00e1tico)","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ml-portfolio-ingress\n  annotations:\n    # TLS con cert-manager\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    # Rate limiting con nginx-ingress\n    nginx.ingress.kubernetes.io/limit-rps: \"10\"\n    nginx.ingress.kubernetes.io/limit-connections: \"5\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - ml-api.example.com\n    secretName: ml-api-tls\n  rules:\n  - host: ml-api.example.com\n    http:\n      paths:\n      - path: /bankchurn\n        pathType: Prefix\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 80\n      - path: /carvision\n        pathType: Prefix\n        backend:\n          service:\n            name: carvision-service\n            port:\n              number: 80\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#clusterissuer-para-lets-encrypt","title":"ClusterIssuer para Let's Encrypt","text":"<pre><code>apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: tu-email@example.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n    - http01:\n        ingress:\n          class: nginx\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#verificacion","title":"Verificaci\u00f3n","text":"<pre><code># Verificar ingress\nkubectl get ingress ml-portfolio-ingress\n\n# Verificar certificado TLS\nkubectl get certificate ml-api-tls\n\n# Test con curl\ncurl -v https://ml-api.example.com/bankchurn/health\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#177-ejercicio-deploy-a-cloud-run","title":"17.7 Ejercicio: Deploy a Cloud Run","text":"<pre><code># 1. Build imagen\ndocker build -t gcr.io/my-project/bankchurn:v1 .\n\n# 2. Push a GCR\ndocker push gcr.io/my-project/bankchurn:v1\n\n# 3. Deploy\ngcloud run deploy bankchurn \\\n  --image gcr.io/my-project/bankchurn:v1 \\\n  --platform managed \\\n  --region us-central1 \\\n  --memory 1Gi \\\n  --allow-unauthenticated\n\n# 4. Test\ncurl -X POST https://bankchurn-xxx.run.app/api/v1/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"credit_score\": 650, \"age\": 35, ...}'\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#ejercicios","title":"\u2705 Ejercicios","text":"<p>Ejercicios del M\u00f3dulo 17: - 17.1: Dockerfile multi-stage - 17.2: Docker Compose para stack ML</p> <p></p>"},{"location":"docs/17_DESPLIEGUE/#checkpoint","title":"\u2705 Checkpoint","text":"<ul> <li>[ ] Puedes explicar (en 60s) por qu\u00e9 tu caso usa Lambda vs Cloud Run/ECS vs Kubernetes.</li> <li>[ ] Tu servicio desplegado responde <code>/health</code> en la plataforma elegida.</li> <li>[ ] El healthcheck/readiness/liveness est\u00e1 configurado y pasa en producci\u00f3n.</li> <li>[ ] Tienes un plan de rollback (y sabes ejecutarlo).</li> <li>[ ] Registraste en runbook qu\u00e9 hacer ante latencia alta y error rate alto.</li> </ul>"},{"location":"docs/17_DESPLIEGUE/#siguiente-paso","title":"\ud83d\udd1c Siguiente Paso","text":"<p>Con la plataforma elegida, es hora de gestionar infraestructura como c\u00f3digo.</p> <p>Ir a M\u00f3dulo 18: Infraestructura como C\u00f3digo \u2192</p>"},{"location":"docs/17_DESPLIEGUE/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/17_DESPLIEGUE/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Cloud Run Tutorial Google Cloud 25 min YouTube \ud83d\udfe1 AWS Lambda for ML AWS 30 min YouTube \ud83d\udfe2 Blue-Green Deployments DevOps Toolkit 20 min YouTube"},{"location":"docs/17_DESPLIEGUE/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Cloud Run Docs Gu\u00eda oficial GCP \ud83d\udfe1 AWS Lambda Serverless AWS"},{"location":"docs/17_DESPLIEGUE/#decision-tecnica-adr-007-plataforma-de-deployment","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-007 Plataforma de Deployment","text":"<p>Contexto: Necesitamos elegir d\u00f3nde desplegar APIs ML.</p> <p>Decisi\u00f3n: Cloud Run para APIs de inferencia (default), K8s para casos complejos.</p> <p>Alternativas Consideradas: - AWS Lambda: Cold starts problem\u00e1ticos para ML - EC2/GCE: M\u00e1s control pero m\u00e1s gesti\u00f3n - Kubernetes: M\u00e1s complejo pero m\u00e1s flexible</p> <p>Consecuencias: - \u2705 Escalado autom\u00e1tico (0 a N) - \u2705 Pay-per-use, sin servidores ociosos - \u2705 CI/CD simple con Cloud Build - \u274c Cold starts (mitigable con min-instances)</p>"},{"location":"docs/17_DESPLIEGUE/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/17_DESPLIEGUE/#ejercicio-171-analisis-de-costos","title":"Ejercicio 17.1: An\u00e1lisis de Costos","text":"<p>Objetivo: Comparar costos entre plataformas. Dificultad: \u2b50\u2b50</p> <pre><code>Escenario:\n- API con 10,000 requests/d\u00eda\n- Latencia promedio 200ms\n- Imagen Docker 500MB\n- 1GB RAM por instancia\n\nTU TAREA: Calcular costo mensual aproximado en:\n- Cloud Run\n- AWS Lambda\n- EC2 t3.small\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>CLOUD RUN (GCP):\n- Requests: 10,000/d\u00eda \u00d7 30 = 300,000/mes\n- CPU: 300,000 \u00d7 0.2s = 60,000 CPU-seconds = 16.7 CPU-hours\n- Memory: 16.7 hours \u00d7 1GB = 16.7 GB-hours\n- Costo: ~$5-10/mes (con free tier)\n\nAWS LAMBDA:\n- Requests: 300,000/mes (1M free)\n- Duration: 300,000 \u00d7 200ms = 60,000 GB-seconds\n- Costo: ~$1-5/mes (pero cold starts!)\n\nEC2 t3.small (always on):\n- $0.0208/hour \u00d7 720h = ~$15/mes\n- + Load Balancer: ~$20/mes\n- Total: ~$35/mes\n\nRECOMENDACI\u00d3N:\n- &lt; 100K req/mes: Cloud Run (escala a 0)\n- 100K-1M req/mes: Cloud Run con min-instances\n- &gt; 1M req/mes: Kubernetes o EC2 dedicado\n</code></pre>"},{"location":"docs/17_DESPLIEGUE/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Blue-Green Estrategia de deployment con dos ambientes id\u00e9nticos Canary Despliegue gradual a un % de tr\u00e1fico Cold Start Tiempo de inicio cuando no hay instancias activas Serverless Modelo donde el proveedor gestiona la infraestructura   **Siguiente m\u00f3dulo** \u2192 [18. Infraestructura](18_INFRAESTRUCTURA.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/18_INFRAESTRUCTURA/","title":"18. Infraestructura como C\u00f3digo","text":"<p>## 0.0 Prerrequisitos</p> <ul> <li>Haber completado el m\u00f3dulo 17 (Despliegue) para entender plataformas y healthchecks.</li> <li>Conocer Docker (im\u00e1genes, puertos, redes) antes de subir el nivel a IaC/K8s.</li> <li>Entender el objetivo de IaC: reproducibilidad, auditor\u00eda y rollback de infraestructura.</li> </ul> <p></p> <p>## 0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</p> <ul> <li>Antes de profundizar: decide si este m\u00f3dulo es \u201cnecesario ahora\u201d o \u201cskill complementario\u201d para tu portafolio.</li> <li>Durante el estudio: traduce cada concepto a un artefacto concreto (un <code>main.tf</code>, un <code>deployment.yaml</code>, un <code>hpa.yaml</code>).</li> <li>Si te atoras &gt;15 min (estado de Terraform, permisos de registry, probes, secrets), reg\u00edstralo en el Diario de Errores y aplica el flujo de Protocolo E.</li> </ul> <p></p> <p>## 0.2 \u2705 Entregables verificables (m\u00ednimo viable)</p> <ul> <li>[ ] Puedes explicar (en 60s) qu\u00e9 problema resuelve IaC vs \u201cclick-ops\u201d.</li> <li>[ ] Puedes leer y modificar un <code>deployment.yaml</code> y un <code>service.yaml</code> b\u00e1sicos.</li> <li>[ ] Entiendes <code>requests/limits</code>, <code>livenessProbe</code> y <code>readinessProbe</code> a nivel conceptual.</li> <li>[ ] Sabes dise\u00f1ar m\u00ednimos de FinOps: presupuestos + alertas + tags/labels.</li> </ul> <p></p> <p>## 0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</p> <ul> <li>Terraform: infraestructura reproducible (clusters, redes, servicios gestionados)</li> <li>Kubernetes: manifests para desplegar y escalar APIs ML</li> <li>Prueba: ser capaz de justificar cu\u00e1ndo usar Docker/CI-CD (portafolio) vs IaC/K8s (contexto profesional)</li> </ul> <p>## \ud83d\udccb Contenido</p> <ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>18.1 Terraform B\u00e1sico</li> <li>18.2 Kubernetes B\u00e1sico</li> <li>18.3 \u00bfCu\u00e1ndo usar qu\u00e9?</li> <li>18.4 Cloud y Control de Costos (FinOps para MLOps)</li> <li>18.5 Horizontal Pod Autoscaler (HPA)</li> <li>18.6 ConfigMaps y Secrets</li> <li>18.7 Ingress para Routing HTTP</li> <li>18.8 C\u00f3mo se us\u00f3 en el Portafolio</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>[</li> </ul> <p>\u2705 Checkpoint](#checkpoint)</p> <p>## \ud83c\udfaf Objetivo</p> <p>Conceptos de IaC (Terraform) y orquestaci\u00f3n (Kubernetes) para despliegue ML.</p> <p>Nota: Este m\u00f3dulo es AVANZADO. Para el portafolio actual, Docker + GitHub Actions es suficiente.</p> <p></p>"},{"location":"docs/18_INFRAESTRUCTURA/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/18_INFRAESTRUCTURA/#ejercicio-puente-cloudk8s","title":"\ud83d\udcbb Ejercicio Puente: Cloud/K8s","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/18_INFRAESTRUCTURA/#practica-del-portafolio-infraestructura-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Infraestructura en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Cloud/K8s\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/18_INFRAESTRUCTURA/#_1","title":"18 \u2014 Infraestructura","text":"<p>\u2705 Checkpoint de Conocimiento</p> <p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Infraestructura?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Cloud/K8s, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/18_INFRAESTRUCTURA/#terraform-basico","title":"Terraform B\u00e1sico","text":""},{"location":"docs/18_INFRAESTRUCTURA/#concepto","title":"Concepto","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  TERRAFORM = Definir infraestructura en c\u00f3digo                            \u2551\n\u2551                                                                           \u2551\n\u2551  En lugar de:                                                             \u2551\n\u2551  \"Crear una instancia EC2 manualmente en la consola AWS\"                  \u2551\n\u2551                                                                           \u2551\n\u2551  Escribes:                                                                \u2551\n\u2551  resource \"aws_instance\" \"ml_server\" {                                    \u2551\n\u2551    ami           = \"ami-12345\"                                            \u2551\n\u2551    instance_type = \"t3.medium\"                                            \u2551\n\u2551  }                                                                        \u2551\n\u2551                                                                           \u2551\n\u2551  Beneficios:                                                              \u2551\n\u2551  \u2022 Reproducible                                                           \u2551\n\u2551  \u2022 Versionado en Git                                                      \u2551\n\u2551  \u2022 Auditado                                                               \u2551\n\u2551  \u2022 Destruir y recrear f\u00e1cilmente                                          \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#estructura-tipica","title":"Estructura T\u00edpica","text":"<pre><code># main.tf\n\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n}\n\n# ECS para ML API\nresource \"aws_ecs_cluster\" \"ml_cluster\" {\n  name = \"ml-portfolio-cluster\"\n}\n\nresource \"aws_ecs_service\" \"bankchurn_api\" {\n  name            = \"bankchurn-api\"\n  cluster         = aws_ecs_cluster.ml_cluster.id\n  task_definition = aws_ecs_task_definition.bankchurn.arn\n  desired_count   = 2\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.bankchurn.arn\n    container_name   = \"bankchurn\"\n    container_port   = 8000\n  }\n}\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#kubernetes-basico","title":"Kubernetes B\u00e1sico","text":""},{"location":"docs/18_INFRAESTRUCTURA/#concepto_1","title":"Concepto","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  KUBERNETES = Orquestar contenedores a escala                             \u2551\n\u2551                                                                           \u2551\n\u2551  Pod: Un contenedor corriendo                                             \u2551\n\u2551  Deployment: N r\u00e9plicas de un Pod                                         \u2551\n\u2551  Service: Exponer Pods a la red                                           \u2551\n\u2551  Ingress: Routing HTTP externo                                            \u2551\n\u2551                                                                           \u2551\n\u2551  Para ML:                                                                 \u2551\n\u2551  \u2022 Deployment para API de inferencia                                      \u2551\n\u2551  \u2022 HPA (Horizontal Pod Autoscaler) para escalar con carga                 \u2551\n\u2551  \u2022 Secrets para API keys y credenciales                                   \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#deployment-yaml","title":"Deployment YAML","text":"<pre><code># k8s/deployment.yaml\n\napiVersion: apps/v1                      # Versi\u00f3n de la API de K8s.\nkind: Deployment                         # Tipo de recurso: gestiona r\u00e9plicas de Pods.\nmetadata:\n  name: bankchurn-api                    # Nombre del Deployment.\n  labels:\n    app: bankchurn                       # Label para seleccionar este recurso.\nspec:\n  replicas: 2                            # N\u00famero de Pods a mantener corriendo.\n  selector:\n    matchLabels:\n      app: bankchurn                     # Selecciona Pods con este label.\n  template:                              # Template del Pod.\n    metadata:\n      labels:\n        app: bankchurn                   # Los Pods creados tendr\u00e1n este label.\n    spec:\n      containers:\n      - name: bankchurn                  # Nombre del contenedor.\n        image: ghcr.io/user/bankchurn:latest  # Imagen Docker a usar.\n        ports:\n        - containerPort: 8000            # Puerto que expone el contenedor.\n        resources:\n          requests:                      # Recursos m\u00ednimos garantizados.\n            memory: \"256Mi\"              # 256 MiB de RAM.\n            cpu: \"250m\"                  # 0.25 CPU cores (milicores).\n          limits:                        # Recursos m\u00e1ximos permitidos.\n            memory: \"512Mi\"              # Si excede, OOMKilled.\n            cpu: \"500m\"                  # Si excede, throttling.\n        livenessProbe:                   # K8s verifica si el Pod est\u00e1 vivo.\n          httpGet:\n            path: /health                # Endpoint a llamar.\n            port: 8000\n          initialDelaySeconds: 30        # Espera antes de primer check.\n          periodSeconds: 10              # Intervalo entre checks.\n        env:                             # Variables de entorno.\n        - name: MLFLOW_TRACKING_URI\n          valueFrom:\n            secretKeyRef:                # Lee valor de un Secret de K8s.\n              name: ml-secrets           # Nombre del Secret.\n              key: mlflow-uri            # Key dentro del Secret.\n---\napiVersion: v1\nkind: Service                            # Service: expone Pods a la red.\nmetadata:\n  name: bankchurn-service\nspec:\n  selector:\n    app: bankchurn                       # Enruta tr\u00e1fico a Pods con este label.\n  ports:\n  - port: 80                             # Puerto externo.\n    targetPort: 8000                     # Puerto del contenedor.\n  type: LoadBalancer                     # Crea un balanceador de carga externo.\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#cuando-usar-que","title":"\u00bfCu\u00e1ndo Usar Qu\u00e9?","text":"Escenario Soluci\u00f3n Recomendada Proyecto personal/demo Docker + docker-compose Startup peque\u00f1a ECS Fargate o Cloud Run Empresa mediana EKS/GKE con Terraform Enterprise Full K8s + GitOps (ArgoCD)"},{"location":"docs/18_INFRAESTRUCTURA/#para-este-portafolio","title":"Para Este Portafolio","text":"<p>Docker + GitHub Actions es suficiente.</p> <p>Terraform y K8s son skills valiosos, pero no necesarios para demostrar competencia MLOps en proyectos de portafolio.</p> <p></p>"},{"location":"docs/18_INFRAESTRUCTURA/#cloud-y-control-de-costos-finops-para-mlops","title":"Cloud y Control de Costos (FinOps para MLOps)","text":"<p>Objetivo: que no te llegue una factura de 500 USD por dejar un cluster o una GPU encendidos sin uso.</p>"},{"location":"docs/18_INFRAESTRUCTURA/#1-modelo-mental-de-costos-en-cloud","title":"1) Modelo mental de costos en cloud","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  REGLA DE ORO: En cloud, TODO lo que corre o almacena datos tiene costo.  \u2551\n\u2551                                                                           \u2551\n\u2551  Principales drivers de costo en MLOps:                                   \u2551\n\u2551  \u2022 C\u00f3mputo: EC2/VMs, nodos de K8s, GPUs, Jobs de entrenamiento            \u2551\n\u2551  \u2022 Almacenamiento: S3/GCS, vol\u00famenes, snapshots, buckets \"olvidados\"      \u2551\n\u2551  \u2022 Networking: tr\u00e1fico de salida (egress), balanceadores de carga         \u2551\n\u2551  \u2022 Servicios gestionados: EKS/GKE fee, bases de datos, colas, etc.        \u2551\n\u2551                                                                           \u2551\n\u2551  Pregunta que siempre debes hacerte:                                      \u2551\n\u2551  \"\u00bfEste recurso est\u00e1 generando valor AHORA MISMO o podr\u00eda estar apagado?\" \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre> <p>Buena parte del FinOps (gesti\u00f3n financiera en cloud) se reduce a:</p> <ul> <li>Apagar lo que no usas (clusters, GPUs, VMs demo).</li> <li>Que los recursos escalen a cero cuando no hay tr\u00e1fico.</li> <li>Poner l\u00edmites y alertas antes de que llegue una sorpresa.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#2-alertas-de-facturacion-minimas-en-aws-y-gcp","title":"2) Alertas de facturaci\u00f3n m\u00ednimas en AWS y GCP","text":""},{"location":"docs/18_INFRAESTRUCTURA/#aws-aws-budgets-cost-explorer","title":"AWS: AWS Budgets + Cost Explorer","text":"<ul> <li>Paso 1: Ir a <code>Billing &gt; Budgets</code> y crear un Budget mensual por cuenta o proyecto.</li> <li>Paso 2: Configurar umbrales t\u00edpicos, por ejemplo:</li> <li>50% del presupuesto \u2192 alerta informativa.</li> <li>80% del presupuesto \u2192 alerta de acci\u00f3n (revisar recursos).</li> <li>100% del presupuesto \u2192 posible freeze de entornos no cr\u00edticos.</li> <li>Paso 3: Enviar alertas a:</li> <li>Email del equipo.</li> <li>(Opcional) SNS \u2192 Slack/Teams.</li> <li>Paso 4: Activar Cost Explorer para revisar qu\u00e9 servicio est\u00e1 creciendo (EKS, EC2, S3, etc.).</li> </ul> <p>\ud83d\udca1 En entrevistas, menciona que siempre configuras AWS Budgets en cuentas nuevas y usas Cost Allocation Tags (<code>Project</code>, <code>Env</code>, <code>Owner</code>) para saber qui\u00e9n gasta qu\u00e9.</p>"},{"location":"docs/18_INFRAESTRUCTURA/#gcp-presupuestos-y-alertas-en-cloud-billing","title":"GCP: Presupuestos y alertas en Cloud Billing","text":"<ul> <li>Paso 1: Entra a <code>Billing &gt; Budgets &amp; alerts</code> y crea un presupuesto por proyecto.</li> <li>Paso 2: Define umbrales 50/80/100% y activa notificaciones por correo.</li> <li>Paso 3: Opcionalmente integra con Cloud Monitoring para disparar alertas a Slack/PagerDuty.</li> <li>Paso 4: Usa el reporte de Cost breakdown para identificar servicios caros (GKE, Cloud Run, BigQuery, etc.).</li> </ul> <p>Checklist r\u00e1pido para cualquier cuenta cloud nueva:</p> <ul> <li>[ ] Hay un owner claro por entorno (quien responde a la factura).</li> <li>[ ] Cada recurso tiene tags/labels de <code>project</code>, <code>env</code>, <code>owner</code>.</li> <li>[ ] Hay un runbook para apagar recursos no cr\u00edticos fuera de horario (scripts/programado).</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#3-errores-frecuentes-de-costo-en-mlops-y-como-evitarlos","title":"3) Errores frecuentes de costo en MLOps y c\u00f3mo evitarlos","text":""},{"location":"docs/18_INFRAESTRUCTURA/#a-dejar-un-cluster-de-kubernetes-encendido-sin-trafico","title":"a) Dejar un cluster de Kubernetes encendido sin tr\u00e1fico","text":"<p>Escenario t\u00edpico: EKS/GKE creado para pruebas, sin pods cr\u00edticos, pero:</p> <ul> <li>Los nodos siguen encendidos.</li> <li>EKS cobra una tarifa fija por cluster.</li> <li>Hay LoadBalancers y vol\u00famenes asociados que nadie recuerda.</li> </ul> <p>Se\u00f1ales de alarma</p> <ul> <li>Factura con l\u00edneas como <code>EKS cluster fee</code>, <code>Compute Engine</code>, <code>Load Balancer</code> sin apenas requests.</li> <li><code>kubectl get pods -A</code> muestra casi todo idle.</li> </ul> <p>Buenas pr\u00e1cticas</p> <ul> <li>Para dev/staging, preferir:</li> <li>Cloud Run/ECS con <code>min-instances = 0</code> o tareas bajo demanda.</li> <li>Clusters ef\u00edmeros destruidos con <code>terraform destroy</code> o scripts programados.</li> <li>Configurar cluster autoscaler con <code>minNodes = 0</code> en nodos no cr\u00edticos.</li> <li>Revisar mensualmente: <code>kubectl get nodes -A</code> + panel de uso de CPU/RAM.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#b-gpus-encendidas-247-para-entrenamiento-puntual","title":"b) GPUs encendidas 24/7 para entrenamiento puntual","text":"<ul> <li>Problema: nodos GPU (p.ej. <code>p3</code>, <code>a2-highgpu</code>) usados una vez al d\u00eda pero pagando 24/7.</li> <li>Soluci\u00f3n:</li> <li>Usar jobs ef\u00edmeros (Spot/Preemptible) y destruirlos al terminar.</li> <li>Automatizar con IaC (<code>terraform apply</code> / <code>destroy</code>) o workflows de CI/CD.</li> <li>Para portafolios, priorizar entrenamiento local y solo usar GPU cloud en casos concretos.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#c-configuracion-comoda-pero-cara-en-serverless","title":"c) Configuraci\u00f3n \"c\u00f3moda\" pero cara en serverless","text":"<ul> <li>En Cloud Run/Lambda es f\u00e1cil poner:</li> <li><code>min-instances</code> &gt; 0 en todos los servicios.</li> <li>Timeouts muy altos con mucha memoria.</li> <li>Reglas sanas:</li> <li>Entornos dev/staging: <code>min-instances = 0</code> y l\u00edmites de memoria modestos.</li> <li>Reservar configuraciones \"grandes\" para prod con justificaci\u00f3n.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#4-checklist-de-costos-por-entorno","title":"4) Checklist de costos por entorno","text":"Entorno Patr\u00f3n recomendado Dev Cloud Run/ECS con <code>min-instances = 0</code>, sin clusters K8s dedicados Staging Igual que dev, pero con presupuestos y alertas separados Prod K8s/cloud gestionado solo si hay tr\u00e1fico real y equipo de Ops suficiente <ul> <li>[ ] Hay un owner claro por entorno (quien responde a la factura).</li> <li>[ ] Cada recurso tiene tags/labels de <code>project</code>, <code>env</code>, <code>owner</code>.</li> <li>[ ] Hay un runbook para apagar recursos no cr\u00edticos fuera de horario (scripts/programado).</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#5-consejos-profesionales-orientados-a-entrevistas","title":"5) Consejos profesionales orientados a entrevistas","text":"<ul> <li>Cuenta una historia realista: \"Nos lleg\u00f3 una factura alta por X; la mitigaci\u00f3n fue: budgets, etiquetado, autoscaling y IaC para destruir entornos ef\u00edmeros\".</li> <li>Menciona expl\u00edcitamente:</li> <li>Presupuestos y alertas de facturaci\u00f3n (AWS Budgets / GCP Budgets).</li> <li>Autoscaling a cero para workloads de baja criticidad.</li> <li>Tags/labels de costo como requisito obligatorio.</li> <li>Conecta esta secci\u00f3n con:</li> <li>La matriz de costo del m\u00f3dulo de despliegue (<code>17_DESPLIEGUE.md</code>).</li> <li>Las m\u00e9tricas y alertas vistas en observabilidad (<code>16_OBSERVABILIDAD.md</code>).</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#errores-habituales-y-como-depurarlos-en-infraestructura-como-codigo","title":"\ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en Infraestructura como C\u00f3digo","text":"<p>Aunque este m\u00f3dulo es avanzado, es com\u00fan cometer errores que dejan tu IaC fr\u00e1gil o inconsistente.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/18_INFRAESTRUCTURA/#1-terraform-aplicado-a-mano-sin-estado-controlado","title":"1) Terraform aplicado \u201ca mano\u201d sin estado controlado","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Se ejecuta <code>terraform apply</code> desde distintas m\u00e1quinas sin control del <code>terraform.tfstate</code>.</li> <li>Recursos que aparecen duplicados o que se destruyen sin querer.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Verifica d\u00f3nde se guarda el estado: local vs backend remoto (S3, GCS, etc.).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Para proyectos serios, usa un backend remoto para el estado y controla qui\u00e9n puede aplicar cambios.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#configuracion-de-backend-remoto-aws-s3-dynamodb","title":"Configuraci\u00f3n de Backend Remoto (AWS S3 + DynamoDB)","text":"<pre><code># backend.tf\nterraform {\n  backend \"s3\" {\n    bucket         = \"ml-portfolio-terraform-state\"\n    key            = \"infra/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-state-lock\"\n  }\n}\n\n# Crear tabla DynamoDB para locking (una sola vez)\nresource \"aws_dynamodb_table\" \"terraform_lock\" {\n  name         = \"terraform-state-lock\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"LockID\"\n\n  attribute {\n    name = \"LockID\"\n    type = \"S\"\n  }\n}\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#backend-remoto-para-gcp-gcs","title":"Backend Remoto para GCP (GCS)","text":"<pre><code>terraform {\n  backend \"gcs\" {\n    bucket  = \"ml-portfolio-terraform-state\"\n    prefix  = \"infra/terraform\"\n  }\n}\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#verificacion","title":"Verificaci\u00f3n","text":"<pre><code># Inicializar con backend remoto\nterraform init -backend-config=\"bucket=ml-portfolio-terraform-state\"\n\n# Verificar estado\nterraform state list\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#2-manifiestos-de-k8s-que-funcionan-en-minikube-pero-no-en-cloud","title":"2) Manifiestos de K8s que funcionan en minikube pero no en cloud","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Deployment correcto en local, pero en EKS/GKE los Pods quedan <code>CrashLoopBackOff</code> o <code>ImagePullBackOff</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa la imagen referenciada (<code>image:</code>) y las credenciales de registry.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Asegura que la imagen est\u00e9 en un registry accesible desde el cluster (ECR/GCR/GHCR) y que el cluster tenga permisos para leerla.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#3-resourceslimits-mal-configurados-en-k8s","title":"3) Resources/limits mal configurados en K8s","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Pods que se matan por OOMKilled o throttling excesivo de CPU.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Observa eventos del Pod y m\u00e9tricas de consumo real.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Ajusta <code>requests</code> y <code>limits</code> seg\u00fan el perfil real de uso de tu API ML, empezando conservador y ajustando con m\u00e9tricas.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#4-cuando-escalar-mas-alla-de-docker","title":"4) \u00bfCu\u00e1ndo escalar m\u00e1s all\u00e1 de Docker?","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Intentar introducir Terraform/K8s en un proyecto de portafolio cuando a\u00fan no dominas Docker + CI/CD.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Si todav\u00eda no tienes un flujo s\u00f3lido con Docker + GitHub Actions, probablemente es pronto para meter K8s.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Sigue la recomendaci\u00f3n del m\u00f3dulo: primero domina Docker + CI/CD. Usa IaC/K8s solo si tu contexto profesional lo exige.</li> </ul>"},{"location":"docs/18_INFRAESTRUCTURA/#5-patron-general-de-debugging-en-iac","title":"5) Patr\u00f3n general de debugging en IaC","text":"<ol> <li>Aplica primero en entornos de prueba peque\u00f1os (playgrounds, sandbox).</li> <li>Revisa siempre el plan (<code>terraform plan</code>, <code>kubectl diff</code>) antes de aplicar.</li> <li>Usa m\u00e9tricas y eventos del cluster para ajustar configuraci\u00f3n en lugar de adivinar.</li> </ol> <p>Con este enfoque, IaC y K8s se vuelven herramientas que suman, no otra fuente de problemas.</p> <p></p>"},{"location":"docs/18_INFRAESTRUCTURA/#horizontal-pod-autoscaler-hpa","title":"Horizontal Pod Autoscaler (HPA)","text":"<p>El HPA escala autom\u00e1ticamente los pods bas\u00e1ndose en m\u00e9tricas como CPU o memoria.</p> <pre><code># k8s/hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: bankchurn-hpa\n  namespace: mlops\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: bankchurn-api\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300  # Esperar 5 min antes de escalar abajo\n    scaleUp:\n      stabilizationWindowSeconds: 0    # Escalar arriba inmediatamente\n</code></pre> <p>\u00bfPor qu\u00e9 70% CPU? Es un balance entre eficiencia (no desperdiciar recursos) y capacidad de respuesta (tener margen para picos).</p> <p></p>"},{"location":"docs/18_INFRAESTRUCTURA/#configmaps-y-secrets","title":"ConfigMaps y Secrets","text":""},{"location":"docs/18_INFRAESTRUCTURA/#configmap-configuracion-no-sensible","title":"ConfigMap (configuraci\u00f3n no sensible)","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: bankchurn-config\n  namespace: mlops\ndata:\n  LOG_LEVEL: \"INFO\"\n  MODEL_PATH: \"/app/artifacts/model.joblib\"\n  MLFLOW_TRACKING_URI: \"http://mlflow-service:5000\"\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#secret-ejemplo-didactico-no-usar-en-produccion","title":"Secret (ejemplo did\u00e1ctico, no usar en producci\u00f3n)","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: ml-secrets\n  namespace: mlops\ntype: Opaque\nstringData:\n  # Valores de ejemplo. En un entorno real se inyectan desde el sistema de secretos.\n  mlflow-uri: \"http://mlflow-service:5000\"\n  database-password: \"REEMPLAZAR_EN_ENTORNO_REAL\"\n  api-key: \"REEMPLAZAR_EN_ENTORNO_REAL\"\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#uso-en-deployment","title":"Uso en Deployment","text":"<pre><code>spec:\n  containers:\n  - name: bankchurn\n    envFrom:\n    - configMapRef:\n        name: bankchurn-config\n    - secretRef:\n        name: ml-secrets\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#ingress-para-routing-http","title":"Ingress para Routing HTTP","text":"<pre><code># k8s/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: mlops-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: api.mlops.example.com\n    http:\n      paths:\n      - path: /bankchurn\n        pathType: Prefix\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 80\n      - path: /carvision\n        pathType: Prefix\n        backend:\n          service:\n            name: carvision-service\n            port:\n              number: 80\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#como-se-uso-en-el-portafolio","title":"\ud83d\udce6 C\u00f3mo se us\u00f3 en el Portafolio","text":"<p>El directorio <code>k8s/</code> del portafolio contiene 8 manifests production-ready:</p> Archivo Prop\u00f3sito <code>namespace.yaml</code> Namespace <code>mlops</code> aislado <code>bankchurn-deployment.yaml</code> Deployment + Service + HPA <code>carvision-deployment.yaml</code> Deployment + Service <code>telecom-deployment.yaml</code> Deployment + Service <code>prometheus-deployment.yaml</code> Monitoreo <code>grafana-deployment.yaml</code> Dashboards <code>ingress.yaml</code> Routing HTTP <code>storage.yaml</code> PersistentVolumeClaims <p>Comandos \u00fatiles:</p> <pre><code># Aplicar todos los manifests\nkubectl apply -f k8s/\n\n# Ver estado de pods\nkubectl get pods -n mlops\n\n# Ver logs de un pod\nkubectl logs -f deployment/bankchurn-api -n mlops\n\n# Escalar manualmente (si no usas HPA)\nkubectl scale deployment bankchurn-api --replicas=3 -n mlops\n\n# Port-forward para testing local\nkubectl port-forward svc/bankchurn-service 8001:80 -n mlops\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#consejos-profesionales","title":"\ud83d\udcbc Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/18_INFRAESTRUCTURA/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>IaC (Infrastructure as Code): Por qu\u00e9 Terraform/Pulumi sobre click-ops.</p> </li> <li> <p>Kubernetes basics: Pods, Deployments, Services, ConfigMaps.</p> </li> <li> <p>Cloud agnostic: Dise\u00f1a para portabilidad cuando sea posible.</p> </li> </ol>"},{"location":"docs/18_INFRAESTRUCTURA/#para-proyectos-reales","title":"Para Proyectos Reales","text":"Situaci\u00f3n Consejo Multi-environment Usa Terraform workspaces o directorios Secrets External Secrets Operator o cloud-native solutions Costos Tagging obligatorio para cost allocation DR (Disaster Recovery) Documenta y prueba regularmente"},{"location":"docs/18_INFRAESTRUCTURA/#stack-recomendado","title":"Stack Recomendado","text":"<pre><code>IaC:        Terraform + Terragrunt\nContainers: Docker + Kubernetes\nCI/CD:      GitHub Actions + ArgoCD\nSecrets:    Vault o AWS Secrets Manager\nMonitoring: Prometheus + Grafana\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#recursos-externos-recomendados","title":"\ud83d\udcfa Recursos Externos Recomendados","text":"<p>Ver RECURSOS_POR_MODULO.md para la lista completa.</p> \ud83c\udff7\ufe0f Recurso Tipo Duraci\u00f3n ## \ud83d\udcfa Recursos Externos del M\u00f3dulo <p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/18_INFRAESTRUCTURA/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Kubernetes Tutorial TechWorld Nana 4h YouTube \ud83d\udd34 Terraform Tutorial freeCodeCamp 2.5h YouTube \ud83d\udfe1 Helm Charts Explained TechWorld Nana 30 min YouTube"},{"location":"docs/18_INFRAESTRUCTURA/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Kubernetes Docs Documentaci\u00f3n oficial \ud83d\udfe1 Terraform Docs HashiCorp docs"},{"location":"docs/18_INFRAESTRUCTURA/#decision-tecnica-adr-009-terraform","title":"\u2696\ufe0f Decisi\u00f3n T\u00e9cnica: ADR-009 Terraform","text":"<p>Contexto: Necesitamos gestionar infraestructura de forma reproducible.</p> <p>Decisi\u00f3n: Usar Terraform para IaC en AWS/GCP.</p> <p>Alternativas Consideradas: - CloudFormation: Solo AWS, menos portable - Pulumi: Code-first pero m\u00e1s complejo - Ansible: Mejor para configuraci\u00f3n que infraestructura</p> <p>Consecuencias: - \u2705 Multi-cloud (AWS, GCP, Azure) - \u2705 Estado declarativo - \u2705 Plan antes de apply - \u274c Curva de aprendizaje inicial</p>"},{"location":"docs/18_INFRAESTRUCTURA/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/18_INFRAESTRUCTURA/#ejercicio-181-leer-kubernetes-manifest","title":"Ejercicio 18.1: Leer Kubernetes Manifest","text":"<p>Objetivo: Entender deployment y service de K8s. Dificultad: \u2b50\u2b50</p> <pre><code># \u00bfQu\u00e9 hace este manifest?\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ml-api\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ml-api\n  template:\n    spec:\n      containers:\n      - name: api\n        image: myregistry/ml-api:v1\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>AN\u00c1LISIS DEL MANIFEST:\n\n1. Deployment \"ml-api\":\n   - Crea 2 r\u00e9plicas del pod\n   - Selector matchLabels para encontrar pods\n\n2. Container \"api\":\n   - Imagen: myregistry/ml-api:v1\n   - Resources requests: m\u00ednimo garantizado\n     - 512Mi RAM, 250m CPU (0.25 cores)\n   - Resources limits: m\u00e1ximo permitido\n     - 1Gi RAM, 500m CPU (0.5 cores)\n\n3. Comportamiento:\n   - K8s programa pods en nodos con recursos disponibles\n   - Si excede limits \u2192 throttling (CPU) o OOMKilled (memory)\n   - HPA puede escalar basado en % de requests\n\n4. Mejoras recomendadas:\n   - A\u00f1adir livenessProbe y readinessProbe\n   - Definir securityContext (non-root)\n   - Usar configMapRef para variables\n</code></pre>"},{"location":"docs/18_INFRAESTRUCTURA/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Kubernetes Orquestador de contenedores para escalar aplicaciones Terraform Herramienta IaC declarativa para provisionar infraestructura HPA Horizontal Pod Autoscaler - escala pods basado en m\u00e9tricas ConfigMap Objeto K8s para configuraci\u00f3n no sensible"},{"location":"docs/18_INFRAESTRUCTURA/#fin-de-fase-4-produccion","title":"\ud83c\udfc1 FIN DE FASE 4: Producci\u00f3n","text":"<p>\ud83c\udfaf \u00a1Has completado los m\u00f3dulos 17-18!</p> <p>Ahora entiendes deployment y infraestructura para producci\u00f3n: - \u2705 Estrategias de despliegue (blue-green, canary) - \u2705 Plataformas cloud (Cloud Run, Lambda, K8s) - \u2705 Infrastructure as Code con Terraform - \u2705 Kubernetes basics</p> <p>Siguiente: Fase 5 - Senior/Staff (Documentaci\u00f3n, Observabilidad Avanzada, FinOps)</p>   **Siguiente m\u00f3dulo** \u2192 [19. Documentaci\u00f3n](19_DOCUMENTACION.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/19_DOCUMENTACION/","title":"M\u00d3DULO 19: DOCUMENTACI\u00d3N Y \u00c9TICA","text":"# \ud83d\udcda M\u00d3DULO 19: Documentaci\u00f3n y \u00c9tica  ### Tu Trabajo No Existe Si No Est\u00e1 Documentado  *\"La documentaci\u00f3n es el regalo que le haces a tu yo del futuro.\"*  | Duraci\u00f3n             | Teor\u00eda               | Pr\u00e1ctica             | | :------------------: | :------------------: | :------------------: | | **4-5 horas**        | 30%                  | 70%                  |"},{"location":"docs/19_DOCUMENTACION/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Haber completado el m\u00f3dulo 18 (Infraestructura) para entender despliegue, entornos y artefactos.</li> <li>Saber escribir Markdown b\u00e1sico (headers, listas, links, code fences).</li> <li>Entender que la documentaci\u00f3n es parte del producto: se versiona, se prueba y se despliega.</li> </ul>"},{"location":"docs/19_DOCUMENTACION/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Antes de empezar: define tu \u201cm\u00ednimo viable\u201d (README + Model Card + un sitio de docs o estructura en <code>docs/</code>).</li> <li>Durante: por cada secci\u00f3n (MkDocs, Model Card, Responsible AI), produce un artefacto real en tu repo.</li> <li>Si te atoras &gt;15 min (MkDocs no compila, links rotos, README desactualizado), reg\u00edstralo en el Diario de Errores y aplica el flujo de Protocolo E.</li> </ul>"},{"location":"docs/19_DOCUMENTACION/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] Tu <code>README</code> tiene un <code>Quick Start</code> que funciona en una m\u00e1quina limpia.</li> <li>[ ] Tienes una Model Card completa (prop\u00f3sito, datos, m\u00e9tricas, limitaciones, mantenimiento).</li> <li>[ ] Puedes ejecutar <code>mkdocs serve</code> (o equivalente) y navegar la documentaci\u00f3n localmente.</li> <li>[ ] Incluyes al menos un checklist de Responsible AI (fairness, privacidad, accountability).</li> </ul>"},{"location":"docs/19_DOCUMENTACION/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>MkDocs: convierte tu repo en un producto navegable (arquitectura, API, runbooks, decisiones).</li> <li>Model Card: convierte tu modelo en un \u201ccontrato\u201d (qu\u00e9 hace, con qu\u00e9 datos, qu\u00e9 no hace, c\u00f3mo mantenerlo).</li> <li>Responsible AI: convierte \u00e9tica en proceso (checklists en PRs, releases, revisiones de cambios).</li> </ul>"},{"location":"docs/19_DOCUMENTACION/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>19.1 MkDocs con Material Theme</li> <li>19.2 Model Card Profesional</li> <li>19.3 Responsible AI Checklist</li> <li>19.4 README Profesional</li> <li>19.5 Ejercicio: Crea Tu Documentaci\u00f3n</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>[</li> </ul> <p>\u2705 Checkpoint](#checkpoint)</p>"},{"location":"docs/19_DOCUMENTACION/#lo-que-lograras","title":"\ud83c\udfaf Lo Que Lograr\u00e1s","text":"<ol> <li>Crear documentaci\u00f3n t\u00e9cnica con MkDocs</li> <li>Escribir Model Cards profesionales</li> <li>Implementar pr\u00e1cticas de Responsible AI</li> <li>Publicar docs en GitHub Pages</li> </ol>"},{"location":"docs/19_DOCUMENTACION/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/19_DOCUMENTACION/#ejercicio-puente-docs","title":"\ud83d\udcbb Ejercicio Puente: Docs","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/19_DOCUMENTACION/#practica-del-portafolio-documentacion-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Documentaci\u00f3n en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Docs\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/19_DOCUMENTACION/#_1","title":"19 \u2014 Documentaci\u00f3n","text":"<p>\u2705 Checkpoint de Conocimiento</p> <p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Documentaci\u00f3n?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Docs, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/19_DOCUMENTACION/#191-mkdocs-con-material-theme","title":"19.1 MkDocs con Material Theme","text":""},{"location":"docs/19_DOCUMENTACION/#estructura-de-docs","title":"Estructura de Docs","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                # Home\n\u251c\u2500\u2500 getting-started/\n\u2502   \u251c\u2500\u2500 installation.md\n\u2502   \u251c\u2500\u2500 quickstart.md\n\u2502   \u2514\u2500\u2500 configuration.md\n\u251c\u2500\u2500 architecture/\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u251c\u2500\u2500 data-flow.md\n\u2502   \u2514\u2500\u2500 decisions.md\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 endpoints.md\n\u2502   \u2514\u2500\u2500 schemas.md\n\u251c\u2500\u2500 development/\n\u2502   \u251c\u2500\u2500 contributing.md\n\u2502   \u2514\u2500\u2500 testing.md\n\u2514\u2500\u2500 model/\n    \u2514\u2500\u2500 model-card.md\n\nmkdocs.yml                  # Configuraci\u00f3n\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#mkdocsyml","title":"mkdocs.yml","text":"<pre><code>site_name: BankChurn Predictor          # Nombre del sitio en el header.\nsite_description: API para predicci\u00f3n de churn bancario  # Meta description para SEO.\nsite_author: Tu Nombre\nsite_url: https://username.github.io/bankchurn  # URL base del sitio publicado.\n\ntheme:\n  name: material                        # Material for MkDocs: tema moderno y responsive.\n  language: es                          # Idioma de la UI.\n  palette:                              # Colores del tema (toggle light/dark).\n    - scheme: default                   # Modo claro.\n      primary: indigo                   # Color primario.\n      accent: indigo                    # Color de acentos (links, botones).\n      toggle:\n        icon: material/brightness-7     # Icono del toggle.\n        name: Cambiar a modo oscuro\n    - scheme: slate                     # Modo oscuro.\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/brightness-4\n        name: Cambiar a modo claro\n  features:                             # Features del tema Material.\n    - navigation.tabs                   # Tabs en el header para secciones.\n    - navigation.sections               # Secciones colapsables en sidebar.\n    - navigation.expand                 # Expande subsecciones autom\u00e1ticamente.\n    - search.suggest                    # Autocompletado en b\u00fasqueda.\n    - content.code.copy                 # Bot\u00f3n para copiar c\u00f3digo.\n    - content.tabs.link                 # Sincroniza tabs entre p\u00e1ginas.\n\nnav:                                    # Estructura de navegaci\u00f3n del sitio.\n  - Home: index.md\n  - Getting Started:                    # Secci\u00f3n con subp\u00e1ginas.\n    - Instalaci\u00f3n: getting-started/installation.md\n    - Quick Start: getting-started/quickstart.md\n    - Configuraci\u00f3n: getting-started/configuration.md\n  - Arquitectura:\n    - Overview: architecture/overview.md\n    - Flujo de Datos: architecture/data-flow.md\n    - Decisiones: architecture/decisions.md\n  - API Reference:\n    - Endpoints: api/endpoints.md\n    - Schemas: api/schemas.md\n  - Desarrollo:\n    - Contribuir: development/contributing.md\n    - Testing: development/testing.md\n  - Model Card: model/model-card.md\n\nmarkdown_extensions:                    # Extensiones de Markdown adicionales.\n  - pymdownx.highlight:                 # Syntax highlighting para c\u00f3digo.\n      anchor_linenums: true             # Links a l\u00edneas espec\u00edficas.\n  - pymdownx.superfences:               # Bloques de c\u00f3digo avanzados.\n      custom_fences:\n        - name: mermaid                 # Soporte para diagramas Mermaid.\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n  - pymdownx.tabbed:                    # Tabs dentro del contenido.\n      alternate_style: true\n  - admonition                          # Boxes de nota/warning/tip.\n  - pymdownx.details                    # Secciones colapsables.\n  - attr_list                           # Atributos HTML en Markdown.\n  - md_in_html                          # Markdown dentro de HTML.\n  - tables                              # Tablas Markdown.\n\nplugins:\n  - search                              # B\u00fasqueda integrada.\n  - mkdocstrings:                       # Auto-documentaci\u00f3n desde docstrings.\n      handlers:\n        python:\n          options:\n            show_source: true           # Muestra c\u00f3digo fuente en docs.\n\nextra:\n  social:                               # Links a redes sociales en footer.\n    - icon: fontawesome/brands/github\n      link: https://github.com/username/bankchurn\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#comandos-mkdocs","title":"Comandos MkDocs","text":"<pre><code># Instalar\npip install mkdocs mkdocs-material mkdocstrings[python]  # mkdocs-material: tema popular. mkdocstrings: autodoc de Python.\n\n# Desarrollo local\nmkdocs serve                          # Inicia servidor en localhost:8000 con hot-reload.\n\n# Build\nmkdocs build                          # Genera HTML est\u00e1tico en carpeta site/.\n\n# Deploy a GitHub Pages\nmkdocs gh-deploy                      # Construye y hace push a branch gh-pages autom\u00e1ticamente.\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#192-model-card-profesional","title":"19.2 Model Card Profesional","text":"<pre><code># Model Card: BankChurn Predictor\n\n## Informaci\u00f3n del Modelo\n\n| Campo | Valor |\n|-------|-------|\n| **Nombre** | BankChurn Predictor |\n| **Versi\u00f3n** | 1.2.3 |\n| **Tipo** | Clasificaci\u00f3n Binaria |\n| **Framework** | Scikit-learn 1.3.0 |\n| **Fecha de Entrenamiento** | 2024-01-15 |\n| **Autor** | Tu Nombre |\n\n## Prop\u00f3sito\n\n### Uso Previsto\n- **Caso de uso principal**: Identificar clientes con alta probabilidad de abandonar el banco\n- **Usuarios objetivo**: Equipo de Retenci\u00f3n de Clientes\n- **Decisiones habilitadas**: Campa\u00f1as de retenci\u00f3n personalizadas\n\n### Uso No Previsto\n- \u274c No usar para decisiones crediticias\n- \u274c No usar como \u00fanico criterio para cancelar servicios\n- \u274c No usar en mercados fuera de Europa (entrenado solo con datos de FR/DE/ES)\n\n## Datos de Entrenamiento\n\n### Dataset\n- **Fuente**: Sistema CRM interno\n- **Per\u00edodo**: 2022-01-01 a 2023-12-31\n- **Tama\u00f1o**: 10,000 registros\n- **Split**: 80% train, 20% test (estratificado)\n\n### Features\n| Feature | Tipo | Descripci\u00f3n |\n|---------|------|-------------|\n| CreditScore | Num\u00e9rica | Score crediticio (300-850) |\n| Age | Num\u00e9rica | Edad del cliente |\n| Geography | Categ\u00f3rica | Pa\u00eds (France, Germany, Spain) |\n| ... | ... | ... |\n\n### Distribuci\u00f3n del Target\n- **Churn (1)**: 20%\n- **No Churn (0)**: 80%\n- **Estrategia**: class_weight='balanced'\n\n## M\u00e9tricas de Performance\n\n### M\u00e9tricas Globales\n| M\u00e9trica | Train | Test | Threshold |\n|---------|-------|------|-----------|\n| AUC-ROC | 0.89 | 0.87 | &gt; 0.85 \u2705 |\n| Precision | 0.72 | 0.68 | &gt; 0.60 \u2705 |\n| Recall | 0.78 | 0.74 | &gt; 0.70 \u2705 |\n| F1 | 0.75 | 0.71 | &gt; 0.65 \u2705 |\n\n### M\u00e9tricas por Subgrupo (Fairness)\n| Subgrupo | AUC-ROC | Precision | Recall |\n|----------|---------|-----------|--------|\n| Gender: Male | 0.86 | 0.67 | 0.73 |\n| Gender: Female | 0.88 | 0.69 | 0.75 |\n| Geography: France | 0.87 | 0.68 | 0.74 |\n| Geography: Germany | 0.85 | 0.66 | 0.72 |\n| Geography: Spain | 0.88 | 0.70 | 0.76 |\n\n**Nota**: La diferencia m\u00e1xima de AUC entre subgrupos es 0.03 (&lt; 0.05 threshold).\n\n## Limitaciones\n\n### Limitaciones Conocidas\n1. **Temporal**: Modelo entrenado con datos hasta 2023. Puede degradarse con cambios econ\u00f3micos.\n2. **Geogr\u00e1fico**: Solo v\u00e1lido para Francia, Alemania y Espa\u00f1a.\n3. **Demogr\u00e1fico**: Menos preciso para clientes &lt; 25 a\u00f1os (pocos datos).\n\n### Cu\u00e1ndo NO Usar\n- Datos con &gt; 30% de valores faltantes\n- Clientes corporativos (solo entrenado con personas f\u00edsicas)\n- Per\u00edodos de crisis econ\u00f3mica (cambio de distribuci\u00f3n)\n\n## Consideraciones \u00c9ticas\n\n### Fairness\n- Se monitorean m\u00e9tricas por g\u00e9nero y geograf\u00eda\n- Diferencias de performance &lt; 5% entre grupos\n- No se usan features protegidas directamente (pero Geography correlaciona con cultura)\n\n### Privacidad\n- Datos pseudonimizados (no PII en features)\n- Cumple con GDPR (Art. 22 - derecho a explicaci\u00f3n)\n- Retenci\u00f3n de datos: 24 meses\n\n### Transparencia\n- SHAP values disponibles para explicabilidad\n- Documentaci\u00f3n de limitaciones p\u00fablica\n- Proceso de feedback habilitado\n\n## Mantenimiento\n\n### Monitoreo\n- Data drift monitoreado diariamente (Evidently)\n- Alerta si drift &gt; 10%\n- Performance evaluada mensualmente con ground truth\n\n### Retraining\n- **Frecuencia**: Trimestral o si drift detectado\n- **Proceso**: Automatizado v\u00eda GitHub Actions\n- **Aprobaci\u00f3n**: Requiere validaci\u00f3n de Data Science Lead\n\n## Historial de Versiones\n\n| Versi\u00f3n | Fecha | Cambios | AUC |\n|---------|-------|---------|-----|\n| 1.0.0 | 2023-06-01 | Versi\u00f3n inicial | 0.82 |\n| 1.1.0 | 2023-09-01 | Feature engineering | 0.85 |\n| 1.2.0 | 2024-01-01 | Retraining con datos 2023 | 0.87 |\n| 1.2.3 | 2024-01-15 | Fix en preprocessing | 0.87 |\n\n## Contacto\n\n- **Responsable**: tu.email@company.com\n- **Equipo**: ML Platform Team\n- **Escalaci\u00f3n**: data-ethics@company.com\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#193-responsible-ai-checklist","title":"19.3 Responsible AI Checklist","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                    CHECKLIST DE RESPONSIBLE AI                                \u2551\n\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\n\u2551                                                                               \u2551\n\u2551   FAIRNESS:                                                                   \u2551\n\u2551   [ ] M\u00e9tricas calculadas por subgrupos demogr\u00e1ficos                          \u2551\n\u2551   [ ] Diferencias de performance &lt; 5% entre grupos                            \u2551\n\u2551   [ ] Features sensibles identificadas y documentadas                         \u2551\n\u2551   [ ] Estrategia de mitigaci\u00f3n si hay sesgo                                   \u2551\n\u2551                                                                               \u2551\n\u2551   TRANSPARENCIA:                                                              \u2551\n\u2551   [ ] Model Card completo y p\u00fablico                                           \u2551\n\u2551   [ ] Explicabilidad disponible (SHAP/LIME)                                   \u2551\n\u2551   [ ] Limitaciones claramente documentadas                                    \u2551\n\u2551   [ ] Usuarios saben que interact\u00faan con ML                                   \u2551\n\u2551                                                                               \u2551\n\u2551   PRIVACIDAD:                                                                 \u2551\n\u2551   [ ] No PII en features                                                      \u2551\n\u2551   [ ] Cumplimiento GDPR/CCPA documentado                                      \u2551\n\u2551   [ ] Pol\u00edtica de retenci\u00f3n de datos                                          \u2551\n\u2551   [ ] Proceso de eliminaci\u00f3n de datos                                         \u2551\n\u2551                                                                               \u2551\n\u2551   ACCOUNTABILITY:                                                             \u2551\n\u2551   [ ] Responsable del modelo identificado                                     \u2551\n\u2551   [ ] Proceso de escalaci\u00f3n definido                                          \u2551\n\u2551   [ ] Auditor\u00eda peri\u00f3dica programada                                          \u2551\n\u2551   [ ] Canal de feedback para usuarios                                         \u2551\n\u2551                                                                               \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#194-readme-profesional","title":"19.4 README Profesional","text":"<pre><code># \ud83c\udfe6 BankChurn Predictor\n\n[![CI](https://github.com/username/bankchurn/actions/workflows/ci.yml/badge.svg)](https://github.com/username/bankchurn/actions)\n[![Coverage](https://codecov.io/gh/username/bankchurn/branch/main/graph/badge.svg)](https://codecov.io/gh/username/bankchurn)\n[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)\n\n&gt; API para predicci\u00f3n de churn bancario con MLOps completo.\n\n## \ud83d\ude80 Quick Start\n\n```bash\n# Clonar\ngit clone https://github.com/username/bankchurn.git\ncd bankchurn\n\n# Instalar\npip install -e \".[dev]\"\n\n# Ejecutar tests\npytest\n\n# Iniciar API\nuvicorn app.main:app --reload\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#documentation","title":"\ud83d\udcd6 Documentation","text":"<ul> <li>Documentaci\u00f3n Completa</li> <li>API Reference</li> <li>Model Card</li> </ul>"},{"location":"docs/19_DOCUMENTACION/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>flowchart LR\n    Client --&gt; API --&gt; Model --&gt; Response</code></pre>"},{"location":"docs/19_DOCUMENTACION/#metrics","title":"\ud83d\udcca Metrics","text":"Metric Value AUC-ROC 0.87 Latency P99 45ms Coverage 85%"},{"location":"docs/19_DOCUMENTACION/#license","title":"\ud83d\udcdc License","text":"<p>MIT \u00a9 Tu Nombre <pre><code>---\n\n## \ud83e\udde8 Errores habituales y c\u00f3mo depurarlos en documentaci\u00f3n ML {#errores-habituales}\n\nLa documentaci\u00f3n suele quedarse para el final, y eso genera READMEs desactualizados y Model Cards incompletas.\n\nSi alguno de estos errores te tom\u00f3 **&gt;15 minutos**, reg\u00edstralo en el **[Diario de Errores](study_tools/DIARIO_ERRORES.md)** y aplica el flujo de **rescate cognitivo** de **[Protocolo E](study_tools/PROTOCOLO_E.md)**.\n\n### 1) README que no refleja el estado real del proyecto\n\n**S\u00edntomas t\u00edpicos**\n\n- Instrucciones de instalaci\u00f3n que no funcionan.\n- Comandos de entrenamiento/serve diferentes a los reales.\n\n**C\u00f3mo identificarlo**\n\n- Intenta seguir tu propio `Quick Start` desde cero en una m\u00e1quina limpia.\n\n**C\u00f3mo corregirlo**\n\n- Actualiza el README cada vez que cambies la CLI, el Makefile o los entornos.\n- Copia los comandos reales desde tu `Makefile` o scripts, no los escribas de memoria.\n\n---\n\n### 2) Model Card incompleta o decorativa\n\n**S\u00edntomas t\u00edpicos**\n\n- Hay secciones de plantilla sin rellenar o con texto gen\u00e9rico.\n- No hay detalles de datos, m\u00e9tricas por subgrupo ni limitaciones claras.\n\n**C\u00f3mo identificarlo**\n\n- Compara tu Model Card con el ejemplo de este m\u00f3dulo: \u00bffaltan tablas clave o secciones enteras?\n\n**C\u00f3mo corregirlo**\n\n- Completa al menos: prop\u00f3sito, datos, m\u00e9tricas principales, m\u00e9tricas por subgrupos, limitaciones y plan de mantenimiento.\n\n---\n\n### 3) MkDocs que compila pero no se integra en el flujo\n\n**S\u00edntomas t\u00edpicos**\n\n- `mkdocs serve` funciona, pero nadie sabe la URL de docs en el README o en el repo.\n\n**C\u00f3mo identificarlo**\n\n- Revisa si tu README enlaza a la documentaci\u00f3n generada.\n\n**C\u00f3mo corregirlo**\n\n- A\u00f1ade enlaces claros en el README (secci\u00f3n Documentation) y en la descripci\u00f3n del repositorio.\n\n---\n\n### 4) Responsible AI checklist ignorada\n\n**S\u00edntomas t\u00edpicos**\n\n- El checklist de Responsible AI est\u00e1 en el repo, pero nunca se usa en revisiones.\n\n**C\u00f3mo identificarlo**\n\n- Pregunta: \u00bfse revisan fairness, privacidad y accountability en los PRs importantes?\n\n**C\u00f3mo corregirlo**\n\n- Integra partes del checklist en tu proceso de revisi\u00f3n (por ejemplo, una secci\u00f3n en la PR template).\n\n---\n\n### 5) Patr\u00f3n general de debugging en documentaci\u00f3n\n\n1. Usa tu propia documentaci\u00f3n como si fueras un usuario nuevo (installation, quick start).\n2. Mant\u00e9n un lugar \u00fanico de verdad para comandos y rutas (Makefile, docs t\u00e9cnicas) y enl\u00e1zalo desde el README.\n3. Considera la Model Card como parte del contrato del modelo, no como adorno.\n\nCon esta mentalidad, tu documentaci\u00f3n pasa de ser un \"nice to have\" a convertirse en una parte cr\u00edtica de la calidad de tu sistema ML.\n\n---\n\n## 19.5 Ejercicio: Crea Tu Documentaci\u00f3n {#195-ejercicio-crea-tu-documentacion}\n\n### Checklist\n</code></pre> MKDOCS: [ ] mkdocs.yml configurado [ ] Home page con overview [ ] Getting started completo [ ] API documentada</p> <p>MODEL CARD: [ ] Informaci\u00f3n del modelo [ ] Datos de entrenamiento [ ] M\u00e9tricas de performance [ ] Limitaciones y \u00e9tica</p> <p>README: [ ] Badges de CI/Coverage [ ] Quick Start [ ] Links a docs [ ] Arquitectura visual <pre><code>---\n\n## \ud83d\udcf9 Material Audiovisual\n\nPara crear demos profesionales (GIFs, screenshots, videos) de tu documentaci\u00f3n y portafolio, consulta:\n\n**[\u2192 Gu\u00eda Audiovisual Completa](apoyo/GUIA_AUDIOVISUAL.md)**\n\nIncluye:\n- C\u00f3mo grabar GIFs demostrativos de APIs y dashboards\n- Screenshots profesionales para README\n- Video de 5 minutos explicando el portafolio\n- Scripts y comandos para levantar el stack demo\n\n---\n\n## \ud83d\udcbc Consejos Profesionales\n\n&gt; **Recomendaciones para destacar en entrevistas y proyectos reales**\n\n### Para Entrevistas\n\n1. **Model Cards**: Explica por qu\u00e9 documentar limitaciones y sesgos es cr\u00edtico.\n\n2. **Documentation as Code**: Docs versionados junto al c\u00f3digo.\n\n3. **Audience-aware**: Diferentes docs para diferentes audiencias.\n\n### Para Proyectos Reales\n\n| Documento | Audiencia | Contenido |\n|-----------|-----------|-----------|\n| README.md | Todos | Quick start, overview |\n| Model Card | ML team, stakeholders | M\u00e9tricas, limitaciones, \u00e9tica |\n| API Docs | Developers | Endpoints, schemas, ejemplos |\n| Runbook | Ops | Troubleshooting, alertas |\n\n### Documentaci\u00f3n que Diferencia\n\n- **ADRs**: Decisiones arquitect\u00f3nicas con contexto\n- **Changelogs**: Generados autom\u00e1ticamente desde commits\n- **Diagramas**: Mermaid/PlantUML versionados\n- **Ejemplos**: Notebooks con casos de uso reales\n\n\n---\n\n## \ud83d\udcfa Recursos Externos Recomendados\n\n&gt; Ver [RECURSOS.md](apoyo/RECURSOS.md) para la lista completa.\n\n## \ud83d\udcfa Recursos Externos del M\u00f3dulo\n\n&gt; \ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario\n\n### \ud83c\udfac Videos\n\n| \ud83c\udff7\ufe0f | T\u00edtulo | Canal | Duraci\u00f3n | Link |\n|:--:|:-------|:------|:--------:|:-----|\n| \ud83d\udd34 | **MkDocs Tutorial** | James Willett | 30 min | [YouTube](https://www.youtube.com/watch?v=Q-YA_dA8C20) |\n| \ud83d\udfe1 | **Model Cards for ML** | Google | 15 min | [Google](https://modelcards.withgoogle.com/about) |\n\n### \ud83d\udcc4 Documentaci\u00f3n\n\n| \ud83c\udff7\ufe0f | Recurso | Descripci\u00f3n |\n|:--:|:--------|:------------|\n| \ud83d\udd34 | [Model Cards](https://modelcards.withgoogle.com/) | Est\u00e1ndar de Google |\n| \ud83d\udfe1 | [MkDocs Material](https://squidfunk.github.io/mkdocs-material/) | Tema MkDocs |\n\n---\n\n## \ud83d\udd27 Ejercicios del M\u00f3dulo\n\n### Ejercicio 19.1: Model Card\n**Objetivo**: Documentar modelo ML con Model Card.\n**Dificultad**: \u2b50\u2b50\n\n```markdown\n# TU TAREA: Completar Model Card para BankChurn\n\n## Model Details\n- Owner: ???\n- Version: ???\n- Type: ???\n\n## Intended Use\n- Primary: ???\n- Out-of-scope: ???\n\n## Training Data\n- Source: ???\n- Size: ???\n\n## Evaluation\n- Metrics: ???\n- Performance: ???\n\n## Limitations\n- ???\n</code></pre></p> \ud83d\udca1 Ver soluci\u00f3n <pre><code># Model Card: BankChurn Predictor\n\n## Model Details\n- **Owner**: ML Team\n- **Version**: 1.2.0 (2024-01)\n- **Type**: Binary Classification (Random Forest)\n- **License**: MIT\n- **Contact**: ml-team@company.com\n\n## Intended Use\n- **Primary**: Predecir probabilidad de churn de clientes bancarios\n- **Users**: Equipo de retenci\u00f3n, marketing\n- **Out-of-scope**: Decisiones automatizadas de cr\u00e9dito, scoring financiero\n\n## Training Data\n- **Source**: CRM interno (2020-2023)\n- **Size**: 10,000 clientes, 50,000 transacciones\n- **Features**: age, tenure, balance, num_products, geography\n- **Target**: churned (binary, 30-day window)\n\n## Evaluation\n| Metric | Train | Test | Threshold |\n|--------|-------|------|-----------|\n| F1 | 0.82 | 0.78 | \u2265 0.75 |\n| Recall | 0.85 | 0.80 | \u2265 0.80 |\n| AUC | 0.91 | 0.87 | \u2265 0.85 |\n\n## Ethical Considerations\n- No usa datos demogr\u00e1ficos sensibles (race, gender)\n- Modelo explicable con SHAP\n- Human-in-the-loop para acciones de retenci\u00f3n\n\n## Limitations\n- Performance menor en clientes nuevos (tenure &lt; 6 meses)\n- No captura eventos macroecon\u00f3micos\n- Requiere actualizaci\u00f3n trimestral\n\n## Maintenance\n- **Retrain**: Trimestral o si AUC &lt; 0.80\n- **Monitoring**: Drift detection semanal\n- **Owner**: ML Team\n</code></pre>"},{"location":"docs/19_DOCUMENTACION/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Model Card Documento estandarizado que describe un modelo ML Dataset Card Documentaci\u00f3n de dataset (fuente, schema, limitaciones) MkDocs Generador de sitios de documentaci\u00f3n desde Markdown Responsible AI Pr\u00e1cticas para desarrollo \u00e9tico de sistemas ML   **Siguiente m\u00f3dulo** \u2192 [20. Observabilidad Avanzada](20_OBSERVABILIDAD_AVANZADA_DRIFT.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/","title":"20. Observabilidad Avanzada y Detecci\u00f3n de Drift","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Dominar detecci\u00f3n de drift, alertas inteligentes y mapeo de m\u00e9tricas ML a KPIs de negocio.</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#contenido","title":"\ud83d\udccb Contenido","text":"<ol> <li>Fundamentos de Drift</li> <li>Detecci\u00f3n Estad\u00edstica</li> <li>EvidentlyAI</li> <li>Alertas</li> <li>M\u00e9tricas \u2192 KPIs 5.5. \ud83d\udd2c Ingenier\u00eda Inversa: Drift en CI/CD \u2b50 NUEVO</li> <li>Ejercicio</li> <li>Entrevista Senior</li> </ol>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#ejercicio-puente-model-monitoring","title":"\ud83d\udcbb Ejercicio Puente: Model Monitoring","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#practica-del-portafolio-drift-detection-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Drift Detection en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Model Monitoring\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Drift Detection?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Model Monitoring, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#1-fundamentos-de-drift","title":"1. Fundamentos de Drift","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#tipos-de-drift","title":"Tipos de Drift","text":"Tipo F\u00f3rmula Ejemplo Data Drift P(X_train) \u2260 P(X_prod) Edad promedio sube 35\u219245 Concept Drift P(Y|X) cambia Relaci\u00f3n features\u2192target cambia Label Drift P(Y) cambia Churn rate 15%\u219230% Prediction Drift Distribuci\u00f3n de \u0177 cambia S\u00edntoma de otros drifts"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#impacto-de-no-detectar","title":"Impacto de No Detectar","text":"<pre><code># drift_impact.py\n\"\"\"Calcula impacto monetario de drift no detectado.\"\"\"\n\ndef calculate_impact(\n    delay_days: int,                    # D\u00edas sin detectar.\n    daily_preds: int = 10_000,          # Predicciones/d\u00eda.\n    extra_errors_pct: float = 0.05,     # 5% m\u00e1s errores.\n    cost_per_error: float = 100.0,      # $100 por error.\n) -&gt; float:\n    \"\"\"Retorna costo total en USD.\"\"\"\n    extra_errors = daily_preds * extra_errors_pct\n    return extra_errors * cost_per_error * delay_days\n\n# Comparaci\u00f3n de escenarios\nprint(f\"Sin monitoreo (90d): ${calculate_impact(90):,.0f}\")   # $4.5M\nprint(f\"Semanal (7d): ${calculate_impact(7):,.0f}\")           # $350K\nprint(f\"Diario (1d): ${calculate_impact(1):,.0f}\")            # $50K\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#2-deteccion-estadistica","title":"2. Detecci\u00f3n Estad\u00edstica","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#21-ks-test","title":"2.1 KS-Test","text":"<pre><code># ks_detector.py\n\"\"\"Detector de drift con Kolmogorov-Smirnov.\"\"\"\n\nimport numpy as np                              # Operaciones num\u00e9ricas y arrays.\nfrom scipy import stats                         # Tests estad\u00edsticos.\nfrom dataclasses import dataclass               # Contenedores de datos inmutables.\n\n\n@dataclass\nclass KSResult:\n    \"\"\"Resultado del test KS para una feature.\"\"\"\n    feature: str                                # Nombre de la feature analizada.\n    statistic: float                            # Estad\u00edstico KS: 0-1, mayor = m\u00e1s diferencia.\n    p_value: float                              # P-value: &lt; 0.05 indica drift significativo.\n    is_drift: bool                              # True si se detect\u00f3 drift.\n\n\ndef ks_test(\n    ref: np.ndarray,                            # Datos de referencia (entrenamiento).\n    cur: np.ndarray,                            # Datos actuales (producci\u00f3n).\n    alpha: float = 0.05,                        # Nivel de significancia (umbral p-value).\n) -&gt; KSResult:\n    \"\"\"\n    Ejecuta KS-test de dos muestras.\n\n    Hip\u00f3tesis:\n    - H0: Ambas muestras provienen de la misma distribuci\u00f3n.\n    - H1: Las distribuciones son diferentes (hay drift).\n    \"\"\"\n    stat, p = stats.ks_2samp(ref, cur)          # Ejecuta test Kolmogorov-Smirnov.\n    is_drift = p &lt; alpha                        # Rechaza H0 si p-value &lt; alpha.\n    return KSResult(\n        feature=\"feature\",                      # Nombre de la feature.\n        statistic=round(stat, 4),               # Redondear para legibilidad.\n        p_value=round(p, 6),                    # P-value redondeado.\n        is_drift=is_drift,                      # Booleano de detecci\u00f3n.\n    )\n\n\n# ========== EJEMPLO DE USO ==========\nref = np.random.normal(35, 10, 1000)            # Referencia: edad media=35, std=10.\ncur = np.random.normal(45, 12, 500)             # Actual: edad media=45 (DRIFT detectado).\nresult = ks_test(ref, cur)                      # Ejecutar test.\nprint(f\"KS={result.statistic}, drift={result.is_drift}\")  # Output: drift=True\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#22-psi-population-stability-index","title":"2.2 PSI (Population Stability Index)","text":"<pre><code># psi_detector.py\n\"\"\"Detector de drift con PSI (Population Stability Index).\"\"\"\n\nimport numpy as np                              # Operaciones num\u00e9ricas.\n\n\ndef calculate_psi(\n    ref: np.ndarray,                            # Datos de referencia (baseline).\n    cur: np.ndarray,                            # Datos actuales a comparar.\n    bins: int = 10,                             # N\u00famero de bins para discretizar.\n) -&gt; float:\n    \"\"\"\n    Calcula PSI = \u03a3 (P_i - Q_i) \u00d7 ln(P_i / Q_i)\n\n    Interpretaci\u00f3n est\u00e1ndar:\n    - PSI &lt; 0.1:  Sin cambio significativo.\n    - PSI 0.1-0.25: Cambio moderado, investigar.\n    - PSI &gt; 0.25: Drift significativo, acci\u00f3n requerida.\n\n    Returns:\n        Valor PSI (float). Mayor valor = mayor drift.\n    \"\"\"\n    # Crear bins uniformes que cubran ambas distribuciones.\n    min_val = min(ref.min(), cur.min())         # M\u00ednimo global.\n    max_val = max(ref.max(), cur.max())         # M\u00e1ximo global.\n    edges = np.linspace(min_val, max_val, bins + 1)  # Bordes de bins.\n\n    # Calcular proporci\u00f3n en cada bin.\n    ref_counts = np.histogram(ref, edges)[0]    # Conteos por bin (referencia).\n    cur_counts = np.histogram(cur, edges)[0]    # Conteos por bin (actual).\n\n    ref_pct = ref_counts / len(ref) + 1e-10     # Proporciones + epsilon (evita log(0)).\n    cur_pct = cur_counts / len(cur) + 1e-10     # Proporciones + epsilon.\n\n    # F\u00f3rmula PSI: suma de (diferencia \u00d7 log del ratio).\n    psi_values = (cur_pct - ref_pct) * np.log(cur_pct / ref_pct)\n    return np.sum(psi_values)                   # PSI total.\n\n\n# ========== EJEMPLO DE USO ==========\npsi = calculate_psi(ref, cur)                   # Calcular PSI.\nprint(f\"PSI={psi:.3f} \u2192 {'\ud83d\udea8 DRIFT' if psi &gt; 0.25 else '\u2705 OK'}\")\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#3-evidentlyai","title":"3. EvidentlyAI","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#instalacion","title":"Instalaci\u00f3n","text":"<pre><code>pip install evidently\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#reporte-de-drift","title":"Reporte de Drift","text":"<pre><code># evidently_report.py\n\"\"\"Genera reportes de drift con Evidently.\"\"\"\n\nimport pandas as pd                             # DataFrames para datos tabulares.\nfrom evidently.report import Report             # Clase principal de reportes.\nfrom evidently.metric_preset import DataDriftPreset  # Preset con m\u00e9tricas de drift.\n\n\ndef generate_drift_report(\n    ref_df: pd.DataFrame,                       # DataFrame de referencia (training).\n    cur_df: pd.DataFrame,                       # DataFrame actual (producci\u00f3n).\n    path: str,                                  # Path donde guardar el HTML.\n) -&gt; None:\n    \"\"\"\n    Genera reporte HTML interactivo de drift.\n\n    El reporte incluye:\n    - Drift por feature (KS-test, PSI).\n    - Visualizaciones de distribuciones.\n    - Score global de drift del dataset.\n    \"\"\"\n    report = Report(metrics=[                   # Crear reporte con preset de drift.\n        DataDriftPreset(),                      # Incluye todas las m\u00e9tricas de drift.\n    ])\n\n    report.run(                                 # Ejecutar an\u00e1lisis.\n        reference_data=ref_df,                  # Datos baseline.\n        current_data=cur_df,                    # Datos a comparar.\n    )\n\n    report.save_html(path)                      # Guardar como HTML interactivo.\n    print(f\"\ud83d\udcca Reporte guardado: {path}\")\n\n\n# ========== EJEMPLO DE USO ==========\n# generate_drift_report(train_df, prod_df, \"drift_report.html\")\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#4-sistema-de-alertas","title":"4. Sistema de Alertas","text":"<pre><code># alerting.py\n\"\"\"Sistema de alertas multi-nivel para drift.\"\"\"\n\nfrom enum import Enum                           # Enumeraciones para severidades.\nfrom dataclasses import dataclass               # Contenedores de datos.\nfrom typing import List                         # Type hints para listas.\nimport logging                                  # Sistema de logging est\u00e1ndar.\n\n\nclass Severity(Enum):\n    \"\"\"Niveles de severidad para alertas.\"\"\"\n    INFO = \"info\"                               # Informativo, no requiere acci\u00f3n.\n    WARNING = \"warning\"                         # Advertencia, investigar.\n    CRITICAL = \"critical\"                       # Cr\u00edtico, acci\u00f3n inmediata.\n\n\n@dataclass\nclass DriftAlert:\n    \"\"\"Representa una alerta de drift.\"\"\"\n    severity: Severity                          # Nivel de severidad.\n    features: List[str]                         # Features afectadas.\n    drift_score: float                          # Score de drift (0-1).\n    message: str                                # Mensaje descriptivo.\n\n\nclass AlertSystem:\n    \"\"\"\n    Sistema de alertas para detecci\u00f3n de drift.\n\n    Clasifica alertas por severidad y las env\u00eda\n    a los canales configurados (logs, Slack, etc.).\n    \"\"\"\n\n    def __init__(self, model_name: str):        # Constructor.\n        self.model = model_name                 # Nombre del modelo monitoreado.\n        self.logger = logging.getLogger(__name__)  # Logger del m\u00f3dulo.\n\n    def trigger(\n        self,\n        features: List[str],                    # Lista de features con drift.\n        score: float,                           # Score de drift promedio.\n    ) -&gt; DriftAlert:\n        \"\"\"Dispara alerta basada en score de drift.\"\"\"\n        # Clasificar severidad seg\u00fan umbrales.\n        if score &gt;= 0.5:                        # Score alto = cr\u00edtico.\n            sev = Severity.CRITICAL\n        elif score &gt;= 0.25:                     # Score medio = warning.\n            sev = Severity.WARNING\n        else:                                   # Score bajo = info.\n            sev = Severity.INFO\n\n        # Crear objeto de alerta.\n        alert = DriftAlert(\n            severity=sev,                       # Severidad calculada.\n            features=features,                  # Features afectadas.\n            drift_score=score,                  # Score num\u00e9rico.\n            message=f\"Drift en {len(features)} features\",  # Mensaje.\n        )\n\n        # Log de la alerta.\n        self.logger.warning(f\"[{sev.value.upper()}] {alert.message}\")\n        return alert                            # Retornar para procesamiento adicional.\n\n\n# ========== EJEMPLO DE USO ==========\nsystem = AlertSystem(\"BankChurn\")               # Crear sistema para modelo BankChurn.\nalert = system.trigger([\"Age\", \"Balance\"], 0.45)  # Disparar alerta con score 0.45.\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#5-metricas-ml-kpis-de-negocio","title":"5. M\u00e9tricas ML \u2192 KPIs de Negocio","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#framework-de-mapeo","title":"Framework de Mapeo","text":"M\u00e9trica ML KPI de Negocio F\u00f3rmula Precision $ desperdiciado en retenci\u00f3n FP \u00d7 costo_retenci\u00f3n Recall $ perdido por churn no detectado FN \u00d7 valor_cliente F1-Score Balance costo/beneficio Combinaci\u00f3n Latency Experiencia de usuario P95 &lt; 200ms <pre><code># kpi_calculator.py\n\"\"\"Mapeo de m\u00e9tricas ML a impacto de negocio.\"\"\"\n\n\ndef precision_to_cost(\n    precision: float,                           # Precision del modelo (0-1).\n    preds: int,                                 # N\u00famero de predicciones positivas.\n    cost_per_fp: float,                         # Costo por falso positivo ($).\n) -&gt; float:\n    \"\"\"\n    Convierte Precision a costo monetario.\n\n    L\u00f3gica: Menor precision = m\u00e1s falsos positivos = m\u00e1s costo.\n    Ejemplo: Gastar en retenci\u00f3n de clientes que no iban a irse.\n    \"\"\"\n    fp = preds * (1 - precision)                # Falsos positivos = preds * (1 - precision).\n    return fp * cost_per_fp                     # Costo total = FP * costo unitario.\n\n\ndef recall_to_revenue(\n    recall: float,                              # Recall del modelo (0-1).\n    actual_pos: int,                            # N\u00famero real de positivos.\n    value_per_fn: float,                        # Valor perdido por falso negativo ($).\n) -&gt; float:\n    \"\"\"\n    Convierte Recall a revenue perdido.\n\n    L\u00f3gica: Menor recall = m\u00e1s falsos negativos = m\u00e1s revenue perdido.\n    Ejemplo: Clientes que se fueron sin ser detectados.\n    \"\"\"\n    fn = actual_pos * (1 - recall)              # Falsos negativos = positivos * (1 - recall).\n    return fn * value_per_fn                    # Revenue perdido = FN * valor unitario.\n\n\n# ========== EJEMPLO: BankChurn ==========\nprecision, recall = 0.85, 0.70                  # M\u00e9tricas actuales del modelo.\nmonthly_preds = 10_000                          # Predicciones positivas al mes.\nactual_churners = 2_000                         # Clientes que realmente se fueron.\n\n# Calcular impacto monetario.\nwasted = precision_to_cost(precision, monthly_preds, cost_per_fp=50)  # $50 por FP.\nlost = recall_to_revenue(recall, actual_churners, value_per_fn=500)   # $500 por FN.\n\nprint(f\"\ud83d\udcb0 Costo FP (retenci\u00f3n desperdiciada): ${wasted:,.0f}/mes\")\nprint(f\"\ud83d\udcb8 Revenue perdido (churn no detectado): ${lost:,.0f}/mes\")\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#55-ingenieria-inversa-pedagogica-drift-detection-en-cicd","title":"5.5 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Drift Detection en CI/CD","text":"<p>Objetivo: Entender c\u00f3mo el portafolio automatiza la detecci\u00f3n de drift en GitHub Actions.</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#551-el-por-que-arquitectonico","title":"5.5.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DECISIONES ARQUITECT\u00d3NICAS DEL PORTAFOLIO                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo detecto drift autom\u00e1ticamente sin intervenci\u00f3n manual?       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Sin automatizaci\u00f3n, el drift pasa desapercibido por semanas            \u2502\n\u2502  DECISI\u00d3N: Workflow de GitHub Actions con schedule diario (cron)                \u2502\n\u2502  RESULTADO: Detecci\u00f3n proactiva 24/7 sin esfuerzo manual                        \u2502\n\u2502  REFERENCIA: drift-detection.yml l\u00edneas 4-6                                     \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo notifico al equipo cuando hay drift significativo?           \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Reportes que nadie lee = drift ignorado                                \u2502\n\u2502  DECISI\u00d3N: Crear GitHub Issue autom\u00e1tico con labels y acci\u00f3n requerida          \u2502\n\u2502  RESULTADO: Issue visible en backlog, asignable, con contexto completo          \u2502\n\u2502  REFERENCIA: drift-detection.yml l\u00edneas 129-161                                 \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo escalo drift detection a m\u00faltiples proyectos?                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                  \u2502\n\u2502  RIESGO: Un workflow por proyecto = mantenimiento duplicado                     \u2502\n\u2502  DECISI\u00d3N: Matrix strategy con lista de proyectos                               \u2502\n\u2502  RESULTADO: Un workflow, N proyectos monitoreados                               \u2502\n\u2502  REFERENCIA: drift-detection.yml l\u00edneas 24-29                                   \u2502\n\u2502                                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#552-anatomia-de-drift-detectionyml","title":"5.5.2 \ud83d\udd0d Anatom\u00eda de <code>drift-detection.yml</code>","text":"<p>Archivo: <code>ML-MLOps-Portfolio/.github/workflows/drift-detection.yml</code></p> <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 1: Triggers - Cu\u00e1ndo ejecutar drift detection\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nname: Data Drift Detection\n\non:\n  schedule:\n    - cron: '0 2 * * *'           # Diario a las 2 AM UTC.\n  workflow_dispatch:               # Permite ejecutar manualmente desde UI.\n  push:\n    branches: [ main ]\n    paths:\n      - '**/monitoring/drift_detection.py'  # Solo si cambia el script.\n# \u00bfPor qu\u00e9 cron a las 2 AM?\n# - Ejecuta cuando hay menos carga en el sistema.\n# - Detecta drift acumulado del d\u00eda anterior.\n# - Resultados disponibles al iniciar el d\u00eda laboral.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 2: Matrix Strategy para M\u00faltiples Proyectos\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\njobs:\n  drift-detection:\n    strategy:\n      matrix:\n        project:\n          - BankChurn-Predictor\n          # - CarVision-Market-Intelligence   # Descomentar para a\u00f1adir.\n          # - TelecomAI-Customer-Intelligence\n# \u00bfPor qu\u00e9 matrix?\n# - Un workflow, m\u00faltiples proyectos.\n# - A\u00f1adir proyecto = una l\u00ednea en la lista.\n# - Cada proyecto corre en paralelo.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 3: Ejecuci\u00f3n del Script de Drift\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n    steps:\n      - name: Run drift detection\n        id: drift\n        working-directory: ${{ matrix.project }}\n        continue-on-error: true           # NO falla el workflow si hay drift.\n        run: |\n          python monitoring/drift_detection.py \\\n            --reference data/raw/Churn.csv \\\n            --current data/raw/Churn.csv \\\n            --output-html reports/drift_report_${{ github.run_number }}.html \\\n            --output-json reports/drift_metrics_${{ github.run_number }}.json \\\n            --threshold 0.5 \\\n            --target Exited\n# \u00bfPor qu\u00e9 continue-on-error: true?\n# - Drift detectado NO debe bloquear el workflow.\n# - Queremos los reportes aunque haya drift.\n# - La acci\u00f3n es crear issue, no fallar CI.\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# BLOQUE 4: Crear GitHub Issue Autom\u00e1tico\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n      - name: Create GitHub Issue on drift alert\n        if: steps.drift.outcome == 'failure'  # Solo si el script detect\u00f3 drift.\n        uses: actions/github-script@v7\n        with:\n          script: |\n            const issue = await github.rest.issues.create({\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              title: `\u26a0\ufe0f Data Drift Alert: ${{ matrix.project }}`,\n              body: `# Data Drift Detected\n\n              **Project:** ${{ matrix.project }}\n              **Date:** ${new Date().toISOString()}\n\n              ## Action Required\n              1. Review the drift report in the workflow artifacts\n              2. Investigate the cause of drift\n              3. Consider retraining the model if needed\n              `,\n              labels: ['drift-alert', 'monitoring', 'mlops']\n            });\n# \u00bfPor qu\u00e9 GitHub Issues y no Slack?\n# - Issues son parte del backlog del equipo (visibilidad garantizada).\n# - Labels permiten filtrar y priorizar.\n# - Historial de incidentes queda documentado en el repo.\n</code></pre>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#553-laboratorio-de-replicacion","title":"5.5.3 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<p>Tu misi\u00f3n: Implementar drift detection automatizado en tu repo.</p> <ol> <li> <p>Crea el script de drift:    <pre><code># monitoring/drift_detection.py\nimport argparse\nimport json\nfrom pathlib import Path\nimport pandas as pd\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset\n\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--reference\", required=True)\n    parser.add_argument(\"--current\", required=True)\n    parser.add_argument(\"--output-json\", required=True)\n    parser.add_argument(\"--threshold\", type=float, default=0.5)\n    args = parser.parse_args()\n\n    ref = pd.read_csv(args.reference)\n    cur = pd.read_csv(args.current)\n\n    report = Report(metrics=[DataDriftPreset()])\n    report.run(reference_data=ref, current_data=cur)\n\n    # Guardar m\u00e9tricas\n    metrics = report.as_dict()\n    Path(args.output_json).write_text(json.dumps(metrics))\n\n    # Exit code indica si hay drift\n    if metrics.get(\"dataset_drift\", False):\n        exit(1)  # Drift detectado\n    exit(0)  # Sin drift\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p> </li> <li> <p>Crea el workflow:    <pre><code># .github/workflows/drift-detection.yml\nname: Drift Detection\non:\n  schedule:\n    - cron: '0 6 * * 1'  # Lunes a las 6 AM\n  workflow_dispatch:\n\njobs:\n  check-drift:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n      - run: pip install evidently pandas\n      - run: python monitoring/drift_detection.py --reference data/train.csv --current data/prod.csv --output-json drift.json\n</code></pre></p> </li> </ol>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#554-troubleshooting-preventivo","title":"5.5.4 \ud83d\udea8 Troubleshooting Preventivo","text":"S\u00edntoma Causa Probable Soluci\u00f3n Workflow falla antes de drift check Dependencias no instaladas A\u00f1ade <code>pip install evidently pandas</code> antes del script. Issue no se crea aunque hay drift Permisos insuficientes A\u00f1ade <code>permissions: issues: write</code> al job. Drift siempre detectado (falso positivo) Threshold muy bajo o datos mal alineados Sube threshold a 0.3-0.5. Verifica que columnas coincidan. Reportes no se suben como artifact Path incorrecto Usa <code>${{ matrix.project }}/reports/</code> no solo <code>reports/</code>."},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#6-ejercicio-integrador","title":"6. Ejercicio Integrador","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#detectar-datos-corruptos-antes-de-retrain","title":"\"Detectar datos corruptos antes de retrain\"","text":"<p>Escenario: Pipeline de datos introduce error \u2192 Age * 10 (35\u2192350).</p> <p>Objetivo: Detectar drift ANTES de que el modelo se reentrene.</p> <pre><code># ejercicio_drift.py\n\"\"\"Ejercicio: Detectar datos corruptos antes de retrain.\"\"\"\n\nimport numpy as np                              # Operaciones num\u00e9ricas.\nfrom scipy import stats                         # Tests estad\u00edsticos.\n\n\n# ========== 1. DATOS DE REFERENCIA ==========\nnp.random.seed(42)                              # Seed para reproducibilidad.\nref_age = np.random.normal(35, 10, 5000)        # Referencia: edad media=35, std=10, n=5000.\n\n# ========== 2. DATOS CORRUPTOS (SIMULAR BUG) ==========\n# Escenario: Pipeline de ETL tiene bug que multiplica Age por 10.\ncorrupt_age = np.random.normal(35, 10, 1000) * 10  # \u26a0\ufe0f BUG: edades 350 en lugar de 35!\n\n# ========== 3. DETECTAR CON KS-TEST ==========\nstat, p = stats.ks_2samp(ref_age, corrupt_age)  # Comparar distribuciones.\nprint(f\"KS-statistic: {stat:.4f}\")              # Estad\u00edstico (0-1).\nprint(f\"P-value: {p:.2e}\")                      # P-value (notaci\u00f3n cient\u00edfica).\n\n# ========== 4. TOMAR DECISI\u00d3N ==========\nalpha = 0.05                                    # Nivel de significancia.\nif p &lt; alpha:                                   # Rechazar H0: distribuciones diferentes.\n    print(\"\ud83d\udea8 ALERTA: Drift detectado - BLOQUEAR RETRAIN\")\n    # Aqu\u00ed ir\u00eda l\u00f3gica para:\n    # - Enviar alerta a Slack/PagerDuty.\n    # - Detener pipeline de reentrenamiento.\n    # - Crear ticket de investigaci\u00f3n.\nelse:                                           # No rechazar H0: distribuciones similares.\n    print(\"\u2705 OK para reentrenar\")\n</code></pre> <p>Entregables: - [ ] Script que detecta el drift. - [ ] Alerta que bloquea pipeline de retrain. - [ ] Reporte Evidently del incidente.</p> <p></p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#7-preguntas-de-entrevista-senior","title":"7. Preguntas de Entrevista Senior","text":""},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#conceptuales","title":"Conceptuales","text":"<ol> <li>\u00bfDiferencia entre data drift y concept drift?</li> <li>\u00bfCu\u00e1ndo usar KS-test vs PSI?</li> <li>\u00bfC\u00f3mo detectar concept drift si no tienes labels en producci\u00f3n?</li> </ol>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#diseno-de-sistema","title":"Dise\u00f1o de Sistema","text":"<ol> <li>Dise\u00f1a un sistema de monitoreo para 100 modelos en producci\u00f3n.</li> <li>\u00bfC\u00f3mo priorizas alertas cuando 10 features muestran drift?</li> <li>Trade-off: alertas frecuentes vs missed drifts.</li> </ol>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#codigo","title":"C\u00f3digo","text":"<ol> <li>Implementa detector de drift con ventana deslizante.</li> <li>\u00bfC\u00f3mo manejas features categ\u00f3ricas en PSI?</li> </ol>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#respuestas-clave","title":"Respuestas Clave","text":"<p>P1: Data drift = distribuci\u00f3n de X cambia. Concept drift = relaci\u00f3n X\u2192Y cambia.</p> <p>P2: KS-test para features continuas, PSI para categ\u00f3ricas o cuando necesitas interpretabilidad por bins.</p> <p>P3: Proxy metrics: prediction drift, feature drift, downstream metrics (latency, error rate).</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 Evidently AI Tutorial Evidently 30 min YouTube \ud83d\udfe1 ML Monitoring in Production MLOps Community 45 min YouTube"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Evidently AI Docs Framework de drift detection \ud83d\udfe1 Alibi Detect Detecci\u00f3n de outliers y drift"},{"location":"docs/20_OBSERVABILIDAD_AVANZADA_DRIFT/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n Data Drift Cambio en la distribuci\u00f3n de features de entrada Concept Drift Cambio en la relaci\u00f3n entre features y target KS-test Test estad\u00edstico para comparar distribuciones PSI Population Stability Index para detectar drift   **Siguiente m\u00f3dulo** \u2192 [21. Cloud FinOps](21_CLOUD_FINOPS.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/21_CLOUD_FINOPS/","title":"21. Cloud FinOps y Estrategia de Costos ML","text":""},{"location":"docs/21_CLOUD_FINOPS/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Dominar la gesti\u00f3n de costos cloud para cargas de trabajo ML, incluyendo estrategias de Spot/On-Demand, auto-scaling inteligente y c\u00e1lculo de TCO.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \"El mejor modelo no es el m\u00e1s preciso, sino el que genera m\u00e1s ROI           \u2551\n\u2551   considerando costos de entrenamiento, inferencia e infraestructura.\"       \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#contenido","title":"\ud83d\udccb Contenido","text":"<ol> <li>Fundamentos de FinOps</li> <li>Costos en ML: Training vs Inference</li> <li>Estrategias Spot vs On-Demand</li> <li>Auto-scaling Inteligente</li> <li>C\u00e1lculo de TCO</li> <li>Ejercicio: Reducir 30% el TCO</li> <li>Preguntas de Entrevista Senior</li> </ol>"},{"location":"docs/21_CLOUD_FINOPS/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/21_CLOUD_FINOPS/#ejercicio-puente-costos","title":"\ud83d\udcbb Ejercicio Puente: Costos","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/21_CLOUD_FINOPS/#practica-del-portafolio-cloud-finops-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Cloud FinOps en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Costos\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/21_CLOUD_FINOPS/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Cloud FinOps?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Costos, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/21_CLOUD_FINOPS/#1-fundamentos-de-finops","title":"1. Fundamentos de FinOps","text":""},{"location":"docs/21_CLOUD_FINOPS/#que-es-finops","title":"\u00bfQu\u00e9 es FinOps?","text":"<p>FinOps = Financial Operations para Cloud. Pr\u00e1ctica de gestionar costos cloud con la misma rigurosidad que el c\u00f3digo.</p>"},{"location":"docs/21_CLOUD_FINOPS/#principios-clave","title":"Principios Clave","text":"Principio Descripci\u00f3n Aplicaci\u00f3n ML Visibility Ver todos los costos Tags por proyecto/modelo Optimization Reducir desperdicio Right-sizing de instancias Governance Pol\u00edticas y l\u00edmites Budgets y alertas"},{"location":"docs/21_CLOUD_FINOPS/#estructura-de-costos-ml","title":"Estructura de Costos ML","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DISTRIBUCI\u00d3N T\u00cdPICA DE COSTOS ML                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  TRAINING (30-50% del costo total)                                          \u2502\n\u2502  \u251c\u2500\u2500 Compute (GPU/CPU)................ 70%                                  \u2502\n\u2502  \u251c\u2500\u2500 Storage (datasets)............... 20%                                  \u2502\n\u2502  \u2514\u2500\u2500 Networking....................... 10%                                  \u2502\n\u2502                                                                             \u2502\n\u2502  INFERENCE (40-60% del costo total)                                         \u2502\n\u2502  \u251c\u2500\u2500 Compute (API servers)............ 60%                                  \u2502\n\u2502  \u251c\u2500\u2500 Load Balancer.................... 15%                                  \u2502\n\u2502  \u251c\u2500\u2500 Storage (model artifacts)........ 15%                                  \u2502\n\u2502  \u2514\u2500\u2500 Networking (egress).............. 10%                                  \u2502\n\u2502                                                                             \u2502\n\u2502  SUPPORTING (10-20% del costo total)                                        \u2502\n\u2502  \u251c\u2500\u2500 MLflow/Experiment Tracking....... 30%                                  \u2502\n\u2502  \u251c\u2500\u2500 Monitoring/Logging............... 40%                                  \u2502\n\u2502  \u2514\u2500\u2500 CI/CD............................ 30%                                  \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#2-costos-training-vs-inference","title":"2. Costos: Training vs Inference","text":""},{"location":"docs/21_CLOUD_FINOPS/#21-calculadora-de-costos","title":"2.1 Calculadora de Costos","text":"<pre><code># cost_calculator.py\n\"\"\"Calculadora de costos ML para AWS/GCP/Azure.\"\"\"\n\nfrom dataclasses import dataclass                   # Contenedores de datos inmutables.\nfrom typing import Dict                             # Type hints para diccionarios.\nfrom enum import Enum                               # Enumeraciones tipadas.\n\n\nclass InstanceType(Enum):\n    \"\"\"\n    Tipos de instancia comunes para ML.\n\n    Valores incluyen specs y precio/hora On-Demand.\n    \"\"\"\n    # CPU - Para inferencia ligera y preprocesamiento.\n    CPU_SMALL = \"t3.medium\"                         # 2 vCPU, 4GB RAM - $0.0416/hr.\n    CPU_LARGE = \"c5.2xlarge\"                        # 8 vCPU, 16GB RAM - $0.34/hr.\n\n    # GPU - Para entrenamiento e inferencia de modelos.\n    GPU_T4 = \"g4dn.xlarge\"                          # 1x NVIDIA T4, 4 vCPU - $0.526/hr.\n    GPU_V100 = \"p3.2xlarge\"                         # 1x NVIDIA V100, 8 vCPU - $3.06/hr.\n    GPU_A100 = \"p4d.24xlarge\"                       # 8x NVIDIA A100, 96 vCPU - $32.77/hr.\n\n\n# ========== PRECIOS DE REFERENCIA ==========\n# Fuente: AWS us-east-1, On-Demand pricing (2024).\n# Nota: Precios cambian frecuentemente, verificar en consola AWS.\nHOURLY_PRICES: Dict[str, float] = {\n    \"t3.medium\": 0.0416,                            # Uso general, burstable.\n    \"c5.2xlarge\": 0.34,                             # Compute-optimized.\n    \"g4dn.xlarge\": 0.526,                           # GPU T4 (inference/training ligero).\n    \"p3.2xlarge\": 3.06,                             # GPU V100 (training intensivo).\n    \"p4d.24xlarge\": 32.77,                          # GPU A100 (LLMs, modelos grandes).\n}\n\n# Descuento t\u00edpico de Spot Instances (60-90% off On-Demand).\nSPOT_DISCOUNT = 0.70                                # 70% descuento = pagar 30% del precio.\n\n\n@dataclass\nclass TrainingJob:\n    \"\"\"\n    Representa un job de entrenamiento.\n\n    Attributes:\n        name: Nombre identificador del job.\n        instance_type: Tipo de instancia EC2.\n        hours: Duraci\u00f3n promedio por ejecuci\u00f3n.\n        runs_per_month: Frecuencia de ejecuci\u00f3n mensual.\n    \"\"\"\n    name: str                                       # Ej: \"BankChurn-Train\".\n    instance_type: str                              # Ej: \"g4dn.xlarge\".\n    hours: float                                    # Horas por ejecuci\u00f3n.\n    runs_per_month: int = 1                         # Ejecuciones mensuales.\n\n\n@dataclass\nclass InferenceEndpoint:\n    \"\"\"\n    Representa un endpoint de inferencia (API).\n\n    Attributes:\n        name: Nombre del endpoint.\n        instance_type: Tipo de instancia.\n        instances: N\u00famero de r\u00e9plicas.\n        hours_per_day: Horas de operaci\u00f3n diaria.\n    \"\"\"\n    name: str                                       # Ej: \"BankChurn-API\".\n    instance_type: str                              # Ej: \"t3.medium\".\n    instances: int                                  # N\u00famero de r\u00e9plicas para HA.\n    hours_per_day: float = 24.0                     # 24 = 24/7, 12 = solo d\u00eda.\n\n\ndef calculate_training_cost(\n    job: TrainingJob,                               # Configuraci\u00f3n del job.\n    use_spot: bool = False,                         # True = usar Spot instances.\n) -&gt; Dict[str, float]:\n    \"\"\"\n    Calcula costo mensual de entrenamiento.\n\n    Returns:\n        Dict con desglose: hourly_rate, monthly_cost_usd, etc.\n    \"\"\"\n    # Obtener precio base (fallback a $0.5/hr si no existe).\n    base_price = HOURLY_PRICES.get(job.instance_type, 0.5)\n\n    # Aplicar descuento Spot si corresponde.\n    if use_spot:\n        effective_price = base_price * (1 - SPOT_DISCOUNT)  # 30% del precio.\n    else:\n        effective_price = base_price                        # Precio completo.\n\n    # Costo mensual = precio/hr \u00d7 horas/run \u00d7 runs/mes.\n    monthly_cost = effective_price * job.hours * job.runs_per_month\n\n    return {\n        \"job_name\": job.name,                       # Identificador.\n        \"instance\": job.instance_type,              # Tipo de instancia.\n        \"hourly_rate\": round(effective_price, 4),   # Precio efectivo/hr.\n        \"hours_per_run\": job.hours,                 # Duraci\u00f3n por ejecuci\u00f3n.\n        \"runs_per_month\": job.runs_per_month,       # Frecuencia mensual.\n        \"monthly_cost_usd\": round(monthly_cost, 2), # Costo total mensual.\n        \"using_spot\": use_spot,                     # Indicador de Spot.\n    }\n\n\ndef calculate_inference_cost(\n    endpoint: InferenceEndpoint,                    # Configuraci\u00f3n del endpoint.\n    days_per_month: int = 30,                       # D\u00edas de operaci\u00f3n.\n) -&gt; Dict[str, float]:\n    \"\"\"\n    Calcula costo mensual de inferencia.\n\n    F\u00f3rmula: precio/hr \u00d7 instancias \u00d7 horas/d\u00eda \u00d7 d\u00edas/mes.\n    \"\"\"\n    base_price = HOURLY_PRICES.get(endpoint.instance_type, 0.5)\n\n    # Calcular horas totales al mes.\n    hours_per_month = endpoint.hours_per_day * days_per_month\n\n    # Costo = precio \u00d7 n\u00famero de instancias \u00d7 horas totales.\n    monthly_cost = base_price * endpoint.instances * hours_per_month\n\n    return {\n        \"endpoint_name\": endpoint.name,             # Identificador.\n        \"instance\": endpoint.instance_type,         # Tipo de instancia.\n        \"instances\": endpoint.instances,            # N\u00famero de r\u00e9plicas.\n        \"hours_per_day\": endpoint.hours_per_day,    # Horas de operaci\u00f3n.\n        \"monthly_cost_usd\": round(monthly_cost, 2), # Costo mensual.\n    }\n\n\n# ========== EJEMPLO: CALCULAR COSTOS DEL PORTFOLIO ==========\nif __name__ == \"__main__\":\n    # Definir jobs de entrenamiento del Portfolio.\n    jobs = [\n        TrainingJob(\"BankChurn-Train\", \"g4dn.xlarge\", hours=2, runs_per_month=4),\n        TrainingJob(\"CarVision-Train\", \"p3.2xlarge\", hours=8, runs_per_month=2),\n        TrainingJob(\"TelecomAI-Train\", \"c5.2xlarge\", hours=1, runs_per_month=8),\n    ]\n\n    # Definir endpoints de inferencia.\n    endpoints = [\n        InferenceEndpoint(\"BankChurn-API\", \"t3.medium\", instances=2),  # 24/7.\n        InferenceEndpoint(\"CarVision-API\", \"g4dn.xlarge\", instances=1, hours_per_day=12),  # Solo d\u00eda.\n    ]\n\n    # ===== REPORTE DE TRAINING =====\n    print(\"=\" * 60)\n    print(\"COSTOS DE TRAINING (mensual)\")\n    print(\"=\" * 60)\n\n    total_training = 0                              # Acumulador.\n    for job in jobs:\n        # Comparar On-Demand vs Spot para cada job.\n        od = calculate_training_cost(job, use_spot=False)   # Precio completo.\n        spot = calculate_training_cost(job, use_spot=True)  # Con descuento.\n        savings = od[\"monthly_cost_usd\"] - spot[\"monthly_cost_usd\"]  # Ahorro.\n\n        print(f\"\\n{job.name}:\")                     # Nombre del job.\n        print(f\"  On-Demand: ${od['monthly_cost_usd']:.2f}/mes\")\n        print(f\"  Spot:      ${spot['monthly_cost_usd']:.2f}/mes\")\n        print(f\"  Ahorro:    ${savings:.2f}/mes ({SPOT_DISCOUNT*100:.0f}%)\")\n\n        total_training += spot[\"monthly_cost_usd\"]  # Sumar costo Spot.\n\n    # ===== REPORTE DE INFERENCE =====\n    print(\"\\n\" + \"=\" * 60)\n    print(\"COSTOS DE INFERENCE (mensual)\")\n    print(\"=\" * 60)\n\n    total_inference = 0                             # Acumulador.\n    for ep in endpoints:\n        cost = calculate_inference_cost(ep)         # Calcular costo.\n        print(f\"\\n{ep.name}:\")\n        print(f\"  Instancias: {cost['instances']}x {cost['instance']}\")\n        print(f\"  Horas/d\u00eda:  {cost['hours_per_day']}\")\n        print(f\"  Costo:      ${cost['monthly_cost_usd']:.2f}/mes\")\n\n        total_inference += cost[\"monthly_cost_usd\"]  # Sumar.\n\n    # ===== RESUMEN TOTAL =====\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"TOTAL TRAINING:  ${total_training:.2f}/mes\")\n    print(f\"TOTAL INFERENCE: ${total_inference:.2f}/mes\")\n    print(f\"TOTAL MENSUAL:   ${total_training + total_inference:.2f}/mes\")\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#3-estrategias-spot-vs-on-demand","title":"3. Estrategias Spot vs On-Demand","text":""},{"location":"docs/21_CLOUD_FINOPS/#matriz-de-decision","title":"Matriz de Decisi\u00f3n","text":"Caso de Uso Recomendaci\u00f3n Raz\u00f3n Training batch \u2705 Spot Tolerante a interrupciones, checkpoints Hyperparameter tuning \u2705 Spot Muchos jobs peque\u00f1os, algunos pueden fallar API de inferencia cr\u00edtica \u274c On-Demand Disponibilidad 99.9% requerida API de inferencia no-cr\u00edtica \u26a0\ufe0f Mixed Base On-Demand + Spot para picos Notebooks/Dev \u2705 Spot Bajo costo, interrupciones aceptables"},{"location":"docs/21_CLOUD_FINOPS/#implementacion-con-checkpoints","title":"Implementaci\u00f3n con Checkpoints","text":"<pre><code># spot_training.py\n\"\"\"Training tolerante a interrupciones con checkpoints.\"\"\"\n\nimport os                                           # Variables de entorno.\nimport json                                         # Serializaci\u00f3n de checkpoints.\nimport signal                                       # Manejo de se\u00f1ales del SO.\nfrom pathlib import Path                            # Manejo de paths.\nfrom datetime import datetime                       # Timestamps.\nfrom typing import Optional, Dict, Any              # Type hints.\nimport logging                                      # Sistema de logging.\n\n# Configurar logging b\u00e1sico.\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass SpotInterruptionHandler:\n    \"\"\"\n    Maneja interrupciones de instancias Spot de forma graceful.\n\n    Funcionamiento:\n    1. AWS env\u00eda SIGTERM 2 minutos antes de terminar Spot.\n    2. Este handler captura la se\u00f1al.\n    3. Guarda checkpoint del estado actual.\n    4. Permite que el proceso termine limpiamente.\n\n    Uso: Permite resumir entrenamiento desde el \u00faltimo checkpoint.\n    \"\"\"\n\n    def __init__(self, checkpoint_dir: str = \"checkpoints\"):\n        \"\"\"Inicializa el handler de interrupciones.\"\"\"\n        self.checkpoint_dir = Path(checkpoint_dir)  # Directorio de checkpoints.\n        self.checkpoint_dir.mkdir(exist_ok=True)    # Crear si no existe.\n        self.interrupted = False                    # Flag de interrupci\u00f3n.\n\n        # Registrar handlers para se\u00f1ales del sistema operativo.\n        signal.signal(signal.SIGTERM, self._handle_sigterm)  # Se\u00f1al de terminaci\u00f3n.\n        signal.signal(signal.SIGINT, self._handle_sigterm)   # Ctrl+C.\n\n    def _handle_sigterm(self, signum, frame):\n        \"\"\"\n        Handler para SIGTERM (se\u00f1al de interrupci\u00f3n Spot).\n\n        Args:\n            signum: N\u00famero de se\u00f1al recibida.\n            frame: Stack frame actual (no usado).\n        \"\"\"\n        logger.warning(\"\u26a0\ufe0f Spot interruption detected! Saving checkpoint...\")\n        self.interrupted = True                     # Marcar como interrumpido.\n\n    def save_checkpoint(\n        self,\n        epoch: int,                                 # \u00c9poca actual del entrenamiento.\n        model_state: Dict[str, Any],                # state_dict del modelo.\n        optimizer_state: Dict[str, Any],            # state_dict del optimizador.\n        metrics: Dict[str, float],                  # M\u00e9tricas actuales (loss, acc).\n    ) -&gt; str:\n        \"\"\"\n        Guarda checkpoint del entrenamiento.\n\n        Returns:\n            Path al archivo de checkpoint guardado.\n        \"\"\"\n        # Construir diccionario de checkpoint.\n        checkpoint = {\n            \"epoch\": epoch,                         # Para resumir desde aqu\u00ed.\n            \"model_state\": model_state,             # Pesos del modelo.\n            \"optimizer_state\": optimizer_state,     # Estado del optimizador (momentum, etc).\n            \"metrics\": metrics,                     # Para comparar al resumir.\n            \"timestamp\": datetime.now().isoformat(),  # Cu\u00e1ndo se guard\u00f3.\n        }\n\n        # Nombre de archivo con n\u00famero de \u00e9poca.\n        path = self.checkpoint_dir / f\"checkpoint_epoch_{epoch}.json\"\n\n        # Guardar (en producci\u00f3n usar\u00edas torch.save() o joblib).\n        with open(path, \"w\") as f:\n            json.dump(checkpoint, f, indent=2, default=str)\n\n        logger.info(f\"\u2705 Checkpoint saved: {path}\")\n        return str(path)\n\n    def load_latest_checkpoint(self) -&gt; Optional[Dict[str, Any]]:\n        \"\"\"\n        Carga el checkpoint m\u00e1s reciente.\n\n        Returns:\n            Dict con el checkpoint o None si no existe.\n        \"\"\"\n        # Buscar todos los checkpoints ordenados.\n        checkpoints = sorted(self.checkpoint_dir.glob(\"checkpoint_*.json\"))\n\n        if not checkpoints:                         # No hay checkpoints previos.\n            logger.info(\"No checkpoints found, starting fresh\")\n            return None\n\n        latest = checkpoints[-1]                    # \u00daltimo (m\u00e1s reciente).\n        logger.info(f\"\ud83d\udcc2 Loading checkpoint: {latest}\")\n\n        with open(latest) as f:\n            return json.load(f)                     # Deserializar y retornar.\n\n    def should_stop(self) -&gt; bool:\n        \"\"\"Retorna True si se detect\u00f3 interrupci\u00f3n Spot.\"\"\"\n        return self.interrupted                     # Verificar flag.\n\n\ndef train_with_spot_support(\n    model,                                          # Modelo a entrenar.\n    train_data,                                     # Datos de entrenamiento.\n    epochs: int = 100,                              # N\u00famero total de \u00e9pocas.\n    checkpoint_every: int = 5,                      # Guardar cada N \u00e9pocas.\n):\n    \"\"\"\n    Entrenamiento con soporte para Spot instances.\n\n    Features:\n    - Resume autom\u00e1tico desde checkpoint.\n    - Guardado peri\u00f3dico.\n    - Graceful shutdown en interrupci\u00f3n.\n    \"\"\"\n    handler = SpotInterruptionHandler()             # Crear handler de interrupciones.\n\n    # ===== INTENTAR RESUMIR DESDE CHECKPOINT =====\n    checkpoint = handler.load_latest_checkpoint()   # Buscar checkpoint previo.\n    start_epoch = checkpoint[\"epoch\"] + 1 if checkpoint else 0  # \u00c9poca inicial.\n\n    if checkpoint:\n        # Restaurar estado del modelo (pseudo-c\u00f3digo).\n        # model.load_state_dict(checkpoint[\"model_state\"])\n        # optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n        logger.info(f\"Resuming from epoch {start_epoch}\")\n\n    # ===== LOOP DE ENTRENAMIENTO =====\n    for epoch in range(start_epoch, epochs):\n        # Verificar interrupci\u00f3n ANTES de cada \u00e9poca.\n        if handler.should_stop():                   # Se detect\u00f3 SIGTERM.\n            logger.warning(\"Stopping due to Spot interruption\")\n            handler.save_checkpoint(                # Guardar estado actual.\n                epoch=epoch,\n                model_state={\"weights\": \"...\"},\n                optimizer_state={\"lr\": 0.001},\n                metrics={\"loss\": 0.5},\n            )\n            break                                   # Salir del loop limpiamente.\n\n        # Training de una \u00e9poca (pseudo-c\u00f3digo).\n        logger.info(f\"Training epoch {epoch}/{epochs}\")\n        # loss = train_one_epoch(model, train_data)\n\n        # Checkpoint peri\u00f3dico cada N \u00e9pocas.\n        if epoch % checkpoint_every == 0:           # Guardar cada 5 \u00e9pocas por defecto.\n            handler.save_checkpoint(\n                epoch=epoch,\n                model_state={\"weights\": \"...\"},\n                optimizer_state={\"lr\": 0.001},\n                metrics={\"loss\": 0.5},\n            )\n\n    logger.info(\"Training completed!\")              # Fin del entrenamiento.\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#4-auto-scaling-inteligente","title":"4. Auto-scaling Inteligente","text":""},{"location":"docs/21_CLOUD_FINOPS/#41-kubernetes-hpa-para-ml","title":"4.1 Kubernetes HPA para ML","text":"<pre><code># k8s/hpa-ml-api.yaml\n# HPA optimizado para APIs de ML\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: bankchurn-api-hpa\n  namespace: ml-production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: bankchurn-api\n\n  # Rango de r\u00e9plicas.\n  minReplicas: 2          # M\u00ednimo para HA.\n  maxReplicas: 10         # M\u00e1ximo para controlar costos.\n\n  # M\u00e9tricas para escalar.\n  metrics:\n    # CPU: escalar si &gt; 70%.\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n\n    # Memoria: escalar si &gt; 80%.\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 80\n\n    # Custom: requests por segundo (requiere Prometheus).\n    - type: Pods\n      pods:\n        metric:\n          name: http_requests_per_second\n        target:\n          type: AverageValue\n          averageValue: \"100\"\n\n  # Comportamiento de escalado.\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300   # 5 min antes de bajar.\n      policies:\n        - type: Percent\n          value: 10                     # Bajar m\u00e1x 10% por vez.\n          periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 0     # Escalar inmediato.\n      policies:\n        - type: Percent\n          value: 100                    # Duplicar si necesario.\n          periodSeconds: 15\n        - type: Pods\n          value: 4                      # O +4 pods m\u00e1ximo.\n          periodSeconds: 15\n      selectPolicy: Max                 # Usar pol\u00edtica m\u00e1s agresiva.\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#42-scaling-basado-en-costolatencia","title":"4.2 Scaling Basado en Costo/Latencia","text":"<pre><code># cost_aware_scaler.py\n\"\"\"Scaler que balancea costo vs latencia.\"\"\"\n\nfrom dataclasses import dataclass                   # Contenedores de datos.\nfrom typing import Tuple                            # Type hints para tuplas.\nimport logging                                      # Sistema de logging.\n\nlogger = logging.getLogger(__name__)                # Logger del m\u00f3dulo.\n\n\n@dataclass\nclass ScalingConfig:\n    \"\"\"\n    Configuraci\u00f3n de scaling.\n\n    Define l\u00edmites y umbrales para el auto-scaler.\n    \"\"\"\n    min_replicas: int = 2                           # M\u00ednimo para HA (High Availability).\n    max_replicas: int = 10                          # M\u00e1ximo para controlar costos.\n    target_latency_p95_ms: float = 200.0            # SLA: P95 &lt; 200ms.\n    max_cost_per_hour: float = 10.0                 # Budget m\u00e1ximo por hora.\n    cost_per_replica_hour: float = 0.50             # Costo de cada r\u00e9plica/hora.\n\n\nclass CostAwareScaler:\n    \"\"\"\n    Auto-scaler que optimiza costo vs latencia.\n\n    Algoritmo de decisi\u00f3n (en orden de prioridad):\n    1. Si latency &gt; target \u2192 SCALE UP (prioridad m\u00e1xima).\n    2. Si cost &gt; budget Y latency OK \u2192 SCALE DOWN.\n    3. Si ambos OK \u2192 HOLD (mantener).\n\n    Esto prioriza la experiencia del usuario sobre el costo.\n    \"\"\"\n\n    def __init__(self, config: ScalingConfig):      # Constructor.\n        self.config = config                        # Guardar configuraci\u00f3n.\n        self.current_replicas = config.min_replicas # Iniciar con m\u00ednimo.\n\n    def calculate_decision(\n        self,\n        current_latency_p95: float,                 # Latencia P95 actual (ms).\n        current_replicas: int,                      # N\u00famero de r\u00e9plicas actuales.\n    ) -&gt; Tuple[str, int]:\n        \"\"\"\n        Decide acci\u00f3n de scaling basada en m\u00e9tricas.\n\n        Returns:\n            Tuple de (nombre_acci\u00f3n, nuevas_r\u00e9plicas).\n        \"\"\"\n        # Calcular costo actual por hora.\n        current_cost = current_replicas * self.config.cost_per_replica_hour\n\n        # ===== CASO 1: LATENCIA MUY ALTA (&gt;150% del target) =====\n        # Prioridad m\u00e1xima: escalar agresivamente.\n        if current_latency_p95 &gt; self.config.target_latency_p95_ms * 1.5:\n            new_replicas = min(                     # Agregar 2 r\u00e9plicas.\n                current_replicas + 2,               # +2 r\u00e9plicas.\n                self.config.max_replicas,           # Sin exceder m\u00e1ximo.\n            )\n            return (\"SCALE_UP_URGENT\", new_replicas)\n\n        # ===== CASO 2: LATENCIA ALTA (&gt;100% del target) =====\n        # Escalar gradualmente (+1 r\u00e9plica).\n        if current_latency_p95 &gt; self.config.target_latency_p95_ms:\n            new_replicas = min(                     # Agregar 1 r\u00e9plica.\n                current_replicas + 1,               # +1 r\u00e9plica.\n                self.config.max_replicas,           # Sin exceder m\u00e1ximo.\n            )\n            return (\"SCALE_UP\", new_replicas)\n\n        # ===== CASO 3: COSTO ALTO PERO LATENCIA OK =====\n        # Solo bajar si latencia est\u00e1 muy por debajo del target (&lt;70%).\n        if (current_cost &gt; self.config.max_cost_per_hour and \n            current_latency_p95 &lt; self.config.target_latency_p95_ms * 0.7):\n            new_replicas = max(                     # Quitar 1 r\u00e9plica.\n                current_replicas - 1,               # -1 r\u00e9plica.\n                self.config.min_replicas,           # Sin bajar del m\u00ednimo.\n            )\n            return (\"SCALE_DOWN_COST\", new_replicas)\n\n        # ===== CASO 4: TODO OK =====\n        # Mantener configuraci\u00f3n actual.\n        return (\"HOLD\", current_replicas)\n\n    def log_decision(\n        self,\n        action: str,                                # Nombre de la acci\u00f3n tomada.\n        old_replicas: int,                          # R\u00e9plicas antes de la decisi\u00f3n.\n        new_replicas: int,                          # R\u00e9plicas despu\u00e9s.\n        latency: float,                             # Latencia que dispar\u00f3 la decisi\u00f3n.\n        cost: float,                                # Costo actual por hora.\n    ):\n        \"\"\"Log la decisi\u00f3n de scaling para auditor\u00eda.\"\"\"\n        logger.info(\n            f\"Scaling: {action} | \"                 # Acci\u00f3n tomada.\n            f\"Replicas: {old_replicas}\u2192{new_replicas} | \"  # Cambio.\n            f\"Latency P95: {latency:.0f}ms | \"      # M\u00e9trica de latencia.\n            f\"Cost: ${cost:.2f}/hr\"                 # Costo horario.\n        )\n\n\n# ========== EJEMPLO DE USO ==========\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)         # Configurar logging.\n\n    # Crear configuraci\u00f3n de scaling.\n    config = ScalingConfig(\n        min_replicas=2,                             # M\u00ednimo 2 para HA.\n        max_replicas=10,                            # M\u00e1ximo 10 por costos.\n        target_latency_p95_ms=200,                  # SLA: P95 &lt; 200ms.\n        max_cost_per_hour=5.0,                      # Budget: $5/hr.\n        cost_per_replica_hour=0.50,                 # $0.50 por r\u00e9plica/hr.\n    )\n\n    scaler = CostAwareScaler(config)                # Crear scaler.\n\n    # Simular diferentes escenarios de carga.\n    scenarios = [\n        (150, 2),                                   # Latencia OK, pocas r\u00e9plicas \u2192 HOLD.\n        (250, 2),                                   # Latencia alta, pocas r\u00e9plicas \u2192 SCALE_UP.\n        (350, 3),                                   # Latencia muy alta \u2192 SCALE_UP_URGENT.\n        (120, 8),                                   # Latencia baja, muchas r\u00e9plicas \u2192 SCALE_DOWN.\n    ]\n\n    # Evaluar cada escenario.\n    for latency, replicas in scenarios:\n        action, new_replicas = scaler.calculate_decision(latency, replicas)\n        cost = replicas * config.cost_per_replica_hour  # Costo actual.\n        scaler.log_decision(action, replicas, new_replicas, latency, cost)\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#5-calculo-de-tco-total-cost-of-ownership","title":"5. C\u00e1lculo de TCO (Total Cost of Ownership)","text":""},{"location":"docs/21_CLOUD_FINOPS/#51-framework-de-tco","title":"5.1 Framework de TCO","text":"<pre><code># tco_calculator.py\n\"\"\"Calculadora de TCO (Total Cost of Ownership) para arquitecturas MLOps.\"\"\"\n\nfrom dataclasses import dataclass, field            # Contenedores de datos.\nfrom typing import List, Dict                       # Type hints.\nfrom enum import Enum                               # Enumeraciones.\n\n\nclass CostCategory(Enum):\n    \"\"\"\n    Categor\u00edas de costos cloud.\n\n    Permite agrupar y analizar costos por tipo.\n    \"\"\"\n    COMPUTE = \"compute\"                             # EC2, Lambda, EKS, etc.\n    STORAGE = \"storage\"                             # S3, EBS, EFS.\n    NETWORK = \"network\"                             # Data transfer, ALB, NAT.\n    SERVICES = \"managed_services\"                   # CloudWatch, Secrets Manager.\n    LABOR = \"labor\"                                 # Costo de personal (opcional).\n\n\n@dataclass\nclass CostItem:\n    \"\"\"\n    Item de costo individual.\n\n    Representa un recurso o servicio con su costo mensual.\n    \"\"\"\n    name: str                                       # Nombre descriptivo.\n    category: CostCategory                          # Categor\u00eda para agrupaci\u00f3n.\n    monthly_cost: float                             # Costo mensual en USD.\n    notes: str = \"\"                                 # Notas adicionales (specs, etc).\n\n\n@dataclass\nclass TCOAnalysis:\n    \"\"\"\n    An\u00e1lisis completo de TCO.\n\n    Agrega m\u00faltiples CostItems y genera reportes.\n    \"\"\"\n    project_name: str                               # Nombre del proyecto.\n    items: List[CostItem] = field(default_factory=list)  # Lista de items.\n\n    def add_item(self, item: CostItem):             # A\u00f1adir item a la lista.\n        \"\"\"A\u00f1ade un item de costo al an\u00e1lisis.\"\"\"\n        self.items.append(item)\n\n    def total_monthly(self) -&gt; float:               # Sumar todos los costos mensuales.\n        \"\"\"Retorna costo mensual total.\"\"\"\n        return sum(i.monthly_cost for i in self.items)\n\n    def total_annual(self) -&gt; float:                # Costo anual = mensual * 12.\n        \"\"\"Retorna costo anual total.\"\"\"\n        return self.total_monthly() * 12\n\n    def by_category(self) -&gt; Dict[str, float]:      # Agrupar por categor\u00eda.\n        \"\"\"Retorna costos agrupados por categor\u00eda.\"\"\"\n        result = {}                                 # Diccionario de resultados.\n        for item in self.items:                     # Iterar items.\n            cat = item.category.value               # Obtener nombre de categor\u00eda.\n            result[cat] = result.get(cat, 0) + item.monthly_cost  # Sumar.\n        return result\n\n    def generate_report(self) -&gt; str:\n        \"\"\"\n        Genera reporte de TCO formateado.\n\n        Returns:\n            String con el reporte completo.\n        \"\"\"\n        # Encabezado del reporte.\n        lines = [\n            \"=\" * 60,\n            f\"TCO ANALYSIS: {self.project_name}\",\n            \"=\" * 60,\n            \"\",\n            \"DESGLOSE POR CATEGOR\u00cdA:\",\n            \"-\" * 40,\n        ]\n\n        # Desglose por categor\u00eda (ordenado por costo descendente).\n        by_cat = self.by_category()\n        for cat, cost in sorted(by_cat.items(), key=lambda x: -x[1]):\n            pct = (cost / self.total_monthly()) * 100  # Porcentaje del total.\n            lines.append(f\"  {cat:20} ${cost:&gt;10,.2f} ({pct:&gt;5.1f}%)\")\n\n        # Totales.\n        lines.extend([\n            \"\",\n            \"-\" * 40,\n            f\"  TOTAL MENSUAL:      ${self.total_monthly():&gt;10,.2f}\",\n            f\"  TOTAL ANUAL:        ${self.total_annual():&gt;10,.2f}\",\n            \"=\" * 60,\n        ])\n\n        return \"\\n\".join(lines)                     # Unir l\u00edneas con saltos.\n\n\ndef calculate_portfolio_tco() -&gt; TCOAnalysis:\n    \"\"\"\n    Calcula TCO del Portfolio MLOps.\n\n    Returns:\n        TCOAnalysis con todos los costos del portfolio.\n    \"\"\"\n    tco = TCOAnalysis(\"ML-MLOps-Portfolio\")         # Crear an\u00e1lisis.\n\n    # ========== COMPUTE ==========\n    # Training jobs (usando Spot para ahorro).\n    tco.add_item(CostItem(\n        name=\"BankChurn Training (Spot)\",           # Modelo de churn.\n        category=CostCategory.COMPUTE,\n        monthly_cost=15.80,                         # $15.80/mes.\n        notes=\"g4dn.xlarge, 2hr/run, 4 runs/month, 70% Spot discount\"\n    ))\n    tco.add_item(CostItem(\n        name=\"CarVision Training (Spot)\",           # Modelo de visi\u00f3n.\n        category=CostCategory.COMPUTE,\n        monthly_cost=14.69,                         # $14.69/mes.\n        notes=\"p3.2xlarge, 8hr/run, 2 runs/month, 70% Spot discount\"\n    ))\n\n    # APIs de inferencia (On-Demand para disponibilidad).\n    tco.add_item(CostItem(\n        name=\"BankChurn API (On-Demand)\",           # API de predicci\u00f3n.\n        category=CostCategory.COMPUTE,\n        monthly_cost=59.90,                         # $59.90/mes.\n        notes=\"2x t3.medium, 24/7\"                  # 2 r\u00e9plicas 24/7.\n    ))\n    tco.add_item(CostItem(\n        name=\"CarVision API (On-Demand)\",           # API de im\u00e1genes.\n        category=CostCategory.COMPUTE,\n        monthly_cost=189.36,                        # $189.36/mes.\n        notes=\"1x g4dn.xlarge, 12hr/day\"            # Solo horario laboral.\n    ))\n\n    # ========== STORAGE ==========\n    tco.add_item(CostItem(\n        name=\"S3 - Datasets\",                       # Datos de entrenamiento.\n        category=CostCategory.STORAGE,\n        monthly_cost=23.00,                         # $23/mes.\n        notes=\"~1TB, S3 Standard\"                   # Tier Standard para acceso frecuente.\n    ))\n    tco.add_item(CostItem(\n        name=\"S3 - Model Artifacts\",                # Modelos guardados.\n        category=CostCategory.STORAGE,\n        monthly_cost=5.00,                          # $5/mes.\n        notes=\"~200GB, S3 Standard-IA\"              # Infrequent Access para artefactos.\n    ))\n    tco.add_item(CostItem(\n        name=\"ECR - Docker Images\",                 # Im\u00e1genes Docker.\n        category=CostCategory.STORAGE,\n        monthly_cost=10.00,                         # $10/mes.\n        notes=\"~100GB images\"                       # Im\u00e1genes de contenedores.\n    ))\n\n    # ========== NETWORK ==========\n    tco.add_item(CostItem(\n        name=\"Data Transfer (Egress)\",              # Tr\u00e1fico de salida.\n        category=CostCategory.NETWORK,\n        monthly_cost=45.00,                         # $45/mes.\n        notes=\"~500GB egress/month\"                 # Tr\u00e1fico hacia internet.\n    ))\n    tco.add_item(CostItem(\n        name=\"Load Balancer\",                       # Balanceador de carga.\n        category=CostCategory.NETWORK,\n        monthly_cost=18.00,                         # $18/mes.\n        notes=\"ALB + LCU\"                           # Application Load Balancer.\n    ))\n\n    # ========== MANAGED SERVICES ==========\n    tco.add_item(CostItem(\n        name=\"CloudWatch Logs\",                     # Logging centralizado.\n        category=CostCategory.SERVICES,\n        monthly_cost=15.00,                         # $15/mes.\n        notes=\"Ingestion + Storage\"                 # Ingesta y almacenamiento.\n    ))\n    tco.add_item(CostItem(\n        name=\"Secrets Manager\",                     # Gesti\u00f3n de secretos.\n        category=CostCategory.SERVICES,\n        monthly_cost=2.00,                          # $2/mes.\n        notes=\"~5 secrets\"                          # API keys, credenciales.\n    ))\n\n    return tco                                      # Retornar an\u00e1lisis completo.\n\n\n# ========== EJEMPLO DE USO ==========\nif __name__ == \"__main__\":\n    tco = calculate_portfolio_tco()                 # Calcular TCO.\n    print(tco.generate_report())                    # Imprimir reporte.\n</code></pre> <p>Output esperado: <pre><code>============================================================\nTCO ANALYSIS: ML-MLOps-Portfolio\n============================================================\n\nDESGLOSE POR CATEGOR\u00cdA:\n----------------------------------------\n  compute              $   279.75 (70.5%)\n  network              $    63.00 (15.9%)\n  storage              $    38.00 ( 9.6%)\n  managed_services     $    17.00 ( 4.3%)\n\n----------------------------------------\n  TOTAL MENSUAL:      $   397.75\n  TOTAL ANUAL:        $ 4,773.00\n============================================================\n</code></pre></p> <p></p>"},{"location":"docs/21_CLOUD_FINOPS/#6-ejercicio-reducir-tco-en-30","title":"6. Ejercicio: Reducir TCO en 30%","text":""},{"location":"docs/21_CLOUD_FINOPS/#escenario","title":"Escenario","text":"<p>El Portfolio actual tiene TCO de ~$400/mes. Tu objetivo: reducir a $280/mes (-30%).</p>"},{"location":"docs/21_CLOUD_FINOPS/#estrategias-a-evaluar","title":"Estrategias a Evaluar","text":"<ol> <li>Spot para Training (ya implementado) - \u2705</li> <li>Reserved Instances para APIs 24/7</li> <li>Right-sizing de instancias</li> <li>Apagar APIs en horarios de bajo tr\u00e1fico</li> <li>Migrar storage a tiers m\u00e1s baratos</li> </ol>"},{"location":"docs/21_CLOUD_FINOPS/#template-de-solucion","title":"Template de Soluci\u00f3n","text":"<pre><code># ejercicio_tco_reduction.py\n\"\"\"Ejercicio: Reducir TCO del Portfolio en 30%.\"\"\"\n\nfrom dataclasses import dataclass                   # Contenedores de datos.\nfrom typing import List, Tuple                      # Type hints.\n\n\n@dataclass\nclass OptimizationStrategy:\n    \"\"\"\n    Estrategia de optimizaci\u00f3n de costos.\n\n    Representa una oportunidad de reducci\u00f3n con su\n    impacto esperado y nivel de riesgo.\n    \"\"\"\n    name: str                                       # Nombre descriptivo.\n    current_cost: float                             # Costo actual mensual.\n    optimized_cost: float                           # Costo despu\u00e9s de optimizar.\n    implementation: str                             # C\u00f3mo implementar.\n    risk: str                                       # \"low\", \"medium\", \"high\".\n\n    @property\n    def savings(self) -&gt; float:                     # Propiedad calculada.\n        \"\"\"Ahorro mensual en USD.\"\"\"\n        return self.current_cost - self.optimized_cost\n\n    @property\n    def savings_pct(self) -&gt; float:                 # Propiedad calculada.\n        \"\"\"Porcentaje de ahorro.\"\"\"\n        return (self.savings / self.current_cost) * 100\n\n\ndef propose_optimizations() -&gt; List[OptimizationStrategy]:\n    \"\"\"\n    Propone estrategias de optimizaci\u00f3n.\n\n    Returns:\n        Lista de estrategias ordenadas por impacto.\n    \"\"\"\n    return [\n        # Estrategia 1: Reserved Instances para APIs 24/7.\n        OptimizationStrategy(\n            name=\"Reserved Instances para BankChurn API\",\n            current_cost=59.90,                     # On-Demand actual.\n            optimized_cost=35.94,                   # 40% descuento con RI 1yr.\n            implementation=\"Comprar RI 1-year para 2x t3.medium\",\n            risk=\"low\"                              # Bajo riesgo: compromiso conocido.\n        ),\n        # Estrategia 2: Reducir horas de operaci\u00f3n.\n        OptimizationStrategy(\n            name=\"Apagar CarVision API en noches\",\n            current_cost=189.36,                    # 12hr/d\u00eda actual.\n            optimized_cost=94.68,                   # Reducir a 6hr/d\u00eda.\n            implementation=\"Schedule: 8am-8pm \u00fanicamente\",\n            risk=\"medium\"                           # Medio: requiere validar uso nocturno.\n        ),\n        # Estrategia 3: Storage tiering.\n        OptimizationStrategy(\n            name=\"Migrar datasets antiguos a S3 Glacier\",\n            current_cost=23.00,                     # S3 Standard actual.\n            optimized_cost=8.00,                    # Glacier para datos antiguos.\n            implementation=\"Lifecycle policy: 30 d\u00edas \u2192 Glacier\",\n            risk=\"low\"                              # Bajo: pol\u00edticas autom\u00e1ticas.\n        ),\n        # Estrategia 4: Right-sizing.\n        OptimizationStrategy(\n            name=\"Right-size BankChurn API\",\n            current_cost=59.90,                     # t3.medium actual.\n            optimized_cost=29.95,                   # t3.small (50% ahorro).\n            implementation=\"Reducir a t3.small (validar latencia)\",\n            risk=\"medium\"                           # Medio: requiere pruebas de carga.\n        ),\n    ]\n\n\ndef calculate_optimized_tco(\n    strategies: List[OptimizationStrategy],         # Lista de estrategias.\n) -&gt; Tuple[float, float]:\n    \"\"\"\n    Calcula TCO optimizado aplicando todas las estrategias.\n\n    Returns:\n        Tuple de (ahorro_total, nuevo_tco).\n    \"\"\"\n    current_tco = 397.75                            # TCO actual del portfolio.\n    total_savings = sum(s.savings for s in strategies)  # Sumar ahorros.\n    new_tco = current_tco - total_savings           # Nuevo TCO.\n\n    return total_savings, new_tco\n\n\n# ========== EJEMPLO DE USO ==========\nif __name__ == \"__main__\":\n    strategies = propose_optimizations()            # Obtener estrategias.\n\n    # Imprimir encabezado.\n    print(\"=\" * 60)\n    print(\"PLAN DE OPTIMIZACI\u00d3N DE TCO\")\n    print(\"=\" * 60)\n\n    # Mostrar cada estrategia.\n    for s in strategies:\n        print(f\"\\n\ud83d\udccc {s.name}\")                      # Nombre.\n        print(f\"   Actual:     ${s.current_cost:.2f}/mes\")  # Costo actual.\n        print(f\"   Optimizado: ${s.optimized_cost:.2f}/mes\")  # Costo optimizado.\n        print(f\"   Ahorro:     ${s.savings:.2f}/mes ({s.savings_pct:.0f}%)\")  # Ahorro.\n        print(f\"   Riesgo:     {s.risk}\")           # Nivel de riesgo.\n        print(f\"   C\u00f3mo:       {s.implementation}\")  # Implementaci\u00f3n.\n\n    # Calcular totales.\n    savings, new_tco = calculate_optimized_tco(strategies)\n    reduction_pct = (savings / 397.75) * 100        # Porcentaje de reducci\u00f3n.\n\n    # Imprimir resumen.\n    print(\"\\n\" + \"=\" * 60)\n    print(\"RESUMEN\")\n    print(\"=\" * 60)\n    print(f\"TCO Actual:     ${397.75:.2f}/mes\")\n    print(f\"TCO Optimizado: ${new_tco:.2f}/mes\")\n    print(f\"Ahorro Total:   ${savings:.2f}/mes ({reduction_pct:.0f}%)\")\n    print(f\"Meta (30%):     {'\u2705 CUMPLIDA' if reduction_pct &gt;= 30 else '\u274c NO CUMPLIDA'}\")\n</code></pre>"},{"location":"docs/21_CLOUD_FINOPS/#entregables","title":"Entregables","text":"<ul> <li>[ ] Script con estrategias de optimizaci\u00f3n.</li> <li>[ ] C\u00e1lculo de nuevo TCO.</li> <li>[ ] Plan de implementaci\u00f3n con timeline.</li> <li>[ ] An\u00e1lisis de riesgos por estrategia.</li> </ul>"},{"location":"docs/21_CLOUD_FINOPS/#7-preguntas-de-entrevista-senior","title":"7. Preguntas de Entrevista Senior","text":""},{"location":"docs/21_CLOUD_FINOPS/#conceptuales","title":"Conceptuales","text":"<ol> <li>\u00bfQu\u00e9 es FinOps y c\u00f3mo se aplica a ML?</li> <li>\u00bfCu\u00e1ndo usar Spot vs On-Demand vs Reserved?</li> <li>\u00bfC\u00f3mo calculas el ROI de un modelo ML?</li> </ol>"},{"location":"docs/21_CLOUD_FINOPS/#diseno","title":"Dise\u00f1o","text":"<ol> <li>Dise\u00f1a un sistema de auto-scaling que balancee costo y latencia.</li> <li>\u00bfC\u00f3mo implementar\u00edas checkpointing para training en Spot?</li> <li>\u00bfC\u00f3mo reducir\u00edas costos de inference sin afectar latencia?</li> </ol>"},{"location":"docs/21_CLOUD_FINOPS/#caso-practico","title":"Caso Pr\u00e1ctico","text":"<ol> <li>Tu modelo de churn cuesta $10K/mes en inference. El CFO pide reducir 40%. \u00bfQu\u00e9 opciones propones?</li> </ol>"},{"location":"docs/21_CLOUD_FINOPS/#respuestas-clave","title":"Respuestas Clave","text":"<p>P1: FinOps es la pr\u00e1ctica de gestionar costos cloud como c\u00f3digo: visibilidad, optimizaci\u00f3n y governance. En ML: tagging por experimento, right-sizing GPU, Spot para training.</p> <p>P2:  - Spot: Training batch, hyperparameter tuning, dev/test. - On-Demand: APIs cr\u00edticas, cargas impredecibles. - Reserved: APIs 24/7 con carga estable (40-70% descuento).</p> <p>P7: Opciones: 1. Reserved Instances (-40%). 2. Auto-scaling agresivo en horarios de bajo tr\u00e1fico. 3. Model distillation (modelo m\u00e1s peque\u00f1o). 4. Batch predictions en lugar de real-time donde sea posible. 5. Edge inference para reducir llamadas al cloud.</p>"},{"location":"docs/21_CLOUD_FINOPS/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/21_CLOUD_FINOPS/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 AWS Cost Optimization Well-Architected \ud83d\udfe1 FinOps Foundation Comunidad y certificaciones \ud83d\udfe2 Spot Instance Advisor Herramienta AWS"},{"location":"docs/21_CLOUD_FINOPS/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n FinOps Pr\u00e1ctica de gestionar costos cloud como c\u00f3digo TCO Total Cost of Ownership - costo total de propiedad Spot Instance Capacidad excedente de cloud a ~70% descuento Reserved Instance Compromiso 1-3 a\u00f1os con 40-70% descuento   **Siguiente m\u00f3dulo** \u2192 [22. IaC Empresarial](22_IAC_EMPRESARIAL.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/22_IAC_EMPRESARIAL/","title":"22. Infrastructure as Code (IaC) Empresarial","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Dominar IaC para entornos ML multi-ambiente (Dev/Staging/Prod), gesti\u00f3n de estado Terraform y patrones de arquitectura enterprise.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  \"Infrastructure as Code no es solo automatizaci\u00f3n:                          \u2551\n\u2551   es documentaci\u00f3n viva, auditor\u00eda y reproducibilidad de tu plataforma.\"     \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#contenido","title":"\ud83d\udccb Contenido","text":"<ol> <li>Fundamentos de IaC Enterprise</li> <li>Gesti\u00f3n de Estado Terraform</li> <li>2.1 State Locking con S3 + DynamoDB</li> <li>2.2 Creaci\u00f3n del Backend (Bootstrap)</li> <li>2.3 State Management Best Practices</li> <li>2.4 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: State Locking \u2b50 NUEVO</li> <li>Arquitectura Multi-Ambiente</li> <li>M\u00f3dulos Terraform Reutilizables</li> <li>CI/CD para Infraestructura</li> <li>Ejercicio: Refactorizar para Staging</li> <li>Preguntas de Entrevista Senior</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#ejercicio-puente-terraform","title":"\ud83d\udcbb Ejercicio Puente: Terraform","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#practica-del-portafolio-iac-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: IaC en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Terraform\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de IaC?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Terraform, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#1-fundamentos-de-iac-enterprise","title":"1. Fundamentos de IaC Enterprise","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#principios","title":"Principios","text":"Principio Descripci\u00f3n Implementaci\u00f3n Immutable No modificar, reemplazar Blue/Green deployments Declarative Definir estado deseado Terraform, CloudFormation Versioned Todo en Git PR reviews para infra Modular Componentes reutilizables Terraform modules Testable Validar antes de aplicar <code>terraform plan</code>, Terratest"},{"location":"docs/22_IAC_EMPRESARIAL/#estructura-de-proyecto-enterprise","title":"Estructura de Proyecto Enterprise","text":"<pre><code>infra/\n\u251c\u2500\u2500 modules/                    # M\u00f3dulos reutilizables.\n\u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u251c\u2500\u2500 eks/\n\u2502   \u251c\u2500\u2500 rds/\n\u2502   \u2514\u2500\u2500 ml-serving/\n\u251c\u2500\u2500 environments/               # Configuraci\u00f3n por ambiente.\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u251c\u2500\u2500 terraform.tfvars\n\u2502   \u2502   \u2514\u2500\u2500 backend.tf\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2502   \u251c\u2500\u2500 terraform.tfvars\n\u2502   \u2502   \u2514\u2500\u2500 backend.tf\n\u2502   \u2514\u2500\u2500 prod/\n\u2502       \u251c\u2500\u2500 main.tf\n\u2502       \u251c\u2500\u2500 variables.tf\n\u2502       \u251c\u2500\u2500 terraform.tfvars\n\u2502       \u2514\u2500\u2500 backend.tf\n\u251c\u2500\u2500 shared/                     # Recursos compartidos.\n\u2502   \u251c\u2500\u2500 ecr/\n\u2502   \u251c\u2500\u2500 iam/\n\u2502   \u2514\u2500\u2500 networking/\n\u2514\u2500\u2500 scripts/\n    \u251c\u2500\u2500 apply.sh\n    \u251c\u2500\u2500 plan.sh\n    \u2514\u2500\u2500 destroy.sh\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#2-gestion-de-estado-terraform","title":"2. Gesti\u00f3n de Estado Terraform","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#21-state-locking-con-s3-dynamodb","title":"2.1 State Locking con S3 + DynamoDB","text":"<pre><code># environments/prod/backend.tf\n# Backend remoto con locking para evitar conflictos.\n\nterraform {\n  backend \"s3\" {\n    # Bucket para almacenar el estado.\n    bucket = \"mlops-portfolio-tfstate\"\n    key    = \"prod/terraform.tfstate\"     # Path \u00fanico por ambiente.\n    region = \"us-east-1\"\n\n    # Tabla DynamoDB para locking.\n    # Previene que dos personas apliquen cambios simult\u00e1neos.\n    dynamodb_table = \"mlops-portfolio-tflock\"\n\n    # Encriptaci\u00f3n del estado (contiene secrets).\n    encrypt = true\n\n    # Versionado para rollback.\n    versioning = true\n  }\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#22-creacion-del-backend-bootstrap","title":"2.2 Creaci\u00f3n del Backend (Bootstrap)","text":"<pre><code># shared/backend-bootstrap/main.tf\n# Este m\u00f3dulo se aplica UNA vez para crear el backend.\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\n# S3 Bucket para estado.\nresource \"aws_s3_bucket\" \"tfstate\" {\n  bucket = \"mlops-portfolio-tfstate\"\n\n  # Prevenir eliminaci\u00f3n accidental.\n  lifecycle {\n    prevent_destroy = true\n  }\n\n  tags = {\n    Name        = \"Terraform State\"\n    Environment = \"shared\"\n    ManagedBy   = \"terraform\"\n  }\n}\n\n# Habilitar versionado.\nresource \"aws_s3_bucket_versioning\" \"tfstate\" {\n  bucket = aws_s3_bucket.tfstate.id\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\n# Encriptaci\u00f3n server-side.\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"tfstate\" {\n  bucket = aws_s3_bucket.tfstate.id\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm = \"aws:kms\"\n    }\n  }\n}\n\n# Bloquear acceso p\u00fablico.\nresource \"aws_s3_bucket_public_access_block\" \"tfstate\" {\n  bucket = aws_s3_bucket.tfstate.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\n# DynamoDB para locking.\nresource \"aws_dynamodb_table\" \"tflock\" {\n  name         = \"mlops-portfolio-tflock\"\n  billing_mode = \"PAY_PER_REQUEST\"  # Sin provisioning.\n  hash_key     = \"LockID\"           # Requerido por Terraform.\n\n  attribute {\n    name = \"LockID\"\n    type = \"S\"\n  }\n\n  tags = {\n    Name        = \"Terraform Lock Table\"\n    Environment = \"shared\"\n    ManagedBy   = \"terraform\"\n  }\n}\n\noutput \"state_bucket\" {\n  value = aws_s3_bucket.tfstate.id\n}\n\noutput \"lock_table\" {\n  value = aws_dynamodb_table.tflock.name\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#23-state-management-best-practices","title":"2.3 State Management Best Practices","text":"<pre><code># scripts/state_management.py\n\"\"\"Utilidades para gesti\u00f3n de estado Terraform.\"\"\"\n\nimport subprocess                                   # Ejecutar comandos del sistema.\nimport json                                         # Parsear output JSON de Terraform.\nfrom pathlib import Path                            # Manejo de paths.\nfrom typing import Dict, List                       # Type hints.\nimport logging                                      # Sistema de logging.\n\n# Configurar logging b\u00e1sico.\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass TerraformStateManager:\n    \"\"\"\n    Gestor de estado Terraform.\n\n    Best practices implementadas:\n    - Backup antes de operaciones destructivas.\n    - Validaci\u00f3n de drift (diferencias entre estado y realidad).\n    - Importaci\u00f3n de recursos existentes al estado.\n    - Wrapper seguro para comandos Terraform.\n    \"\"\"\n\n    def __init__(self, env_path: str):\n        \"\"\"\n        Inicializa el gestor de estado.\n\n        Args:\n            env_path: Path al directorio del ambiente (ej: environments/prod).\n        \"\"\"\n        self.env_path = Path(env_path)              # Convertir a Path object.\n        self.state_file = self.env_path / \"terraform.tfstate\"  # Path al state file.\n\n    def run_terraform(self, *args) -&gt; subprocess.CompletedProcess:\n        \"\"\"\n        Ejecuta comando Terraform de forma segura.\n\n        Args:\n            *args: Argumentos para el comando terraform.\n\n        Returns:\n            CompletedProcess con stdout, stderr y returncode.\n        \"\"\"\n        cmd = [\"terraform\"] + list(args)            # Construir comando completo.\n        logger.info(f\"Running: {' '.join(cmd)}\")    # Log del comando.\n        return subprocess.run(\n            cmd,                                    # Comando a ejecutar.\n            cwd=self.env_path,                      # Directorio de trabajo.\n            capture_output=True,                    # Capturar stdout/stderr.\n            text=True,                              # Retornar como string.\n        )\n\n    def init(self, reconfigure: bool = False) -&gt; bool:\n        \"\"\"\n        Inicializa Terraform (descarga providers, configura backend).\n\n        Args:\n            reconfigure: Si True, reconfigura backend ignorando estado previo.\n\n        Returns:\n            True si la inicializaci\u00f3n fue exitosa.\n        \"\"\"\n        args = [\"init\"]                             # Comando base.\n        if reconfigure:                             # Opci\u00f3n para reconfigurar.\n            args.append(\"-reconfigure\")             # Ignorar configuraci\u00f3n previa.\n\n        result = self.run_terraform(*args)          # Ejecutar.\n        if result.returncode != 0:                  # Verificar \u00e9xito.\n            logger.error(f\"Init failed: {result.stderr}\")\n            return False\n        return True\n\n    def plan(self, out_file: str = \"plan.out\") -&gt; Dict:\n        \"\"\"\n        Genera plan de cambios sin aplicarlos.\n\n        Args:\n            out_file: Archivo donde guardar el plan.\n\n        Returns:\n            Dict con conteo de cambios: {\"add\": N, \"change\": N, \"destroy\": N}.\n        \"\"\"\n        # Ejecutar plan con output JSON.\n        result = self.run_terraform(\"plan\", f\"-out={out_file}\", \"-json\")\n\n        # Inicializar contadores.\n        changes = {\"add\": 0, \"change\": 0, \"destroy\": 0}\n\n        # Parsear cada l\u00ednea del output JSON.\n        for line in result.stdout.split(\"\\n\"):     # Terraform emite JSON line by line.\n            if line.strip():                        # Ignorar l\u00edneas vac\u00edas.\n                try:\n                    data = json.loads(line)         # Parsear JSON.\n                    if data.get(\"type\") == \"planned_change\":  # Es un cambio.\n                        action = data.get(\"change\", {}).get(\"action\")\n                        if action == \"create\":      # Recurso nuevo.\n                            changes[\"add\"] += 1\n                        elif action == \"update\":    # Recurso modificado.\n                            changes[\"change\"] += 1\n                        elif action == \"delete\":    # Recurso a eliminar.\n                            changes[\"destroy\"] += 1\n                except json.JSONDecodeError:        # L\u00ednea no es JSON v\u00e1lido.\n                    pass                            # Ignorar (logs, etc).\n\n        return changes                              # Retornar resumen.\n\n    def detect_drift(self) -&gt; List[str]:\n        \"\"\"\n        Detecta drift entre estado guardado y realidad en el cloud.\n\n        Drift ocurre cuando alguien modifica recursos fuera de Terraform.\n\n        Returns:\n            Lista de descripciones de recursos con drift.\n        \"\"\"\n        # -detailed-exitcode: 0=sin cambios, 1=error, 2=hay cambios.\n        result = self.run_terraform(\"plan\", \"-detailed-exitcode\")\n\n        # Exit code 2 = hay cambios (drift detectado).\n        if result.returncode == 2:\n            logger.warning(\"\u26a0\ufe0f Drift detected!\")   # Advertir sobre drift.\n\n            # Parsear output para identificar recursos afectados.\n            drifted = []                            # Lista de recursos con drift.\n            for line in result.stdout.split(\"\\n\"):\n                # Buscar l\u00edneas que indican cambios.\n                if \"will be\" in line or \"must be\" in line:\n                    drifted.append(line.strip())    # Agregar a lista.\n            return drifted\n\n        logger.info(\"\u2705 No drift detected\")         # Todo OK.\n        return []                                   # Lista vac\u00eda = sin drift.\n\n    def import_resource(\n        self,\n        address: str,                               # Direcci\u00f3n Terraform del recurso.\n        resource_id: str,                           # ID del recurso en el cloud.\n    ) -&gt; bool:\n        \"\"\"\n        Importa recurso existente al estado de Terraform.\n\n        \u00datil cuando:\n        - Recursos fueron creados manualmente.\n        - Se migra infraestructura existente a IaC.\n\n        Args:\n            address: Direcci\u00f3n Terraform (ej: aws_instance.web).\n            resource_id: ID del recurso en el cloud (ej: i-1234567890abcdef0).\n\n        Returns:\n            True si la importaci\u00f3n fue exitosa.\n        \"\"\"\n        result = self.run_terraform(\"import\", address, resource_id)\n        if result.returncode != 0:                  # Verificar \u00e9xito.\n            logger.error(f\"Import failed: {result.stderr}\")\n            return False\n        logger.info(f\"\u2705 Imported {address}\")        # Confirmar \u00e9xito.\n        return True\n\n    def backup_state(self) -&gt; str:\n        \"\"\"\n        Crea backup del estado actual antes de operaciones riesgosas.\n\n        Returns:\n            Path al archivo de backup, o string vac\u00edo si fall\u00f3.\n        \"\"\"\n        from datetime import datetime               # Import local para timestamp.\n\n        # Generar nombre \u00fanico con timestamp.\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        backup_name = f\"terraform.tfstate.backup.{timestamp}\"\n\n        # Extraer estado actual del backend remoto.\n        result = self.run_terraform(\"state\", \"pull\")  # Pull state from backend.\n        if result.returncode == 0:                  # Si tuvo \u00e9xito.\n            backup_path = self.env_path / backup_name  # Path completo.\n            backup_path.write_text(result.stdout)   # Escribir contenido.\n            logger.info(f\"\u2705 State backed up to {backup_path}\")\n            return str(backup_path)\n\n        logger.error(\"Failed to backup state\")      # Error al hacer backup.\n        return \"\"                                   # Retornar vac\u00edo.\n\n\n# ========== EJEMPLO DE USO ==========\nif __name__ == \"__main__\":\n    # Crear manager para el ambiente de producci\u00f3n.\n    manager = TerraformStateManager(\"environments/prod\")\n\n    # Paso 1: Inicializar Terraform.\n    manager.init()\n\n    # Paso 2: Detectar drift (cambios fuera de Terraform).\n    drift = manager.detect_drift()\n    if drift:                                       # Si hay drift.\n        print(\"Recursos con drift:\")               # Mostrar afectados.\n        for r in drift:\n            print(f\"  - {r}\")\n\n    # Paso 3: Generar plan de cambios.\n    changes = manager.plan()                        # Plan sin aplicar.\n    print(f\"\\nPlan: +{changes['add']} ~{changes['change']} -{changes['destroy']}\")\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#24-ingenieria-inversa-pedagogica-state-locking-real","title":"2.4 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: State Locking Real","text":"<p>Objetivo: Entender por qu\u00e9 usamos DynamoDB y S3 para el estado de Terraform en lugar de un archivo local.</p> <p>Archivo: <code>environments/prod/backend.tf</code></p>"},{"location":"docs/22_IAC_EMPRESARIAL/#el-por-que-arquitectonico","title":"El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       PROBLEMA DE CONCURRENCIA EN IAC                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502  Escenario: Dev A y Dev B ejecutan 'terraform apply' al mismo tiempo.       \u2502\n\u2502                                                                             \u2502\n\u2502  SIN LOCKING (Local state):                                                 \u2502\n\u2502  \u2022 Ambos leen el estado local (o git pull).                                 \u2502\n\u2502  \u2022 A aplica cambios. B aplica cambios sobre versi\u00f3n vieja.                  \u2502\n\u2502  \u2022 RESULTADO: Estado corrupto, recursos eliminados por error.               \u2502\n\u2502                                                                             \u2502\n\u2502  CON LOCKING (S3 + DynamoDB):                                               \u2502\n\u2502  \u2022 A inicia apply \u2192 Terraform escribe un \"lock\" en DynamoDB.                \u2502\n\u2502  \u2022 B inicia apply \u2192 Ve el lock y ESPERA (o falla).                          \u2502\n\u2502  \u2022 A termina \u2192 Libera el lock.                                              \u2502\n\u2502  \u2022 RESULTADO: Integridad garantizada.                                       \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#anatomia-del-codigo","title":"Anatom\u00eda del C\u00f3digo","text":"<pre><code>terraform {\n  backend \"s3\" {\n    bucket         = \"mlops-portfolio-tfstate\"  # D\u00f3nde se guarda el JSON del estado\n    key            = \"prod/terraform.tfstate\"   # Ruta \u00fanica dentro del bucket\n    region         = \"us-east-1\"\n\n    # EL SECRETO DEL LOCKING\n    dynamodb_table = \"mlops-portfolio-tflock\"   # Tabla para coordinar locks\n    encrypt        = true                       # Encriptar datos sensibles en reposo\n  }\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#laboratorio-de-replicacion","title":"Laboratorio de Replicaci\u00f3n","text":"<ol> <li>Crea la tabla DynamoDB manualmente (o con script bootstrap) con clave primaria <code>LockID</code>.</li> <li>Configura el backend en tu <code>main.tf</code>.</li> <li>Ejecuta <code>terraform init</code>.</li> <li>Prueba de Fuego: Abre dos terminales. En una ejecuta <code>terraform apply</code> y d\u00e9jalo esperando confirmaci\u00f3n (\"Enter a value:\"). En la otra intenta <code>terraform apply</code>. La segunda debe fallar con \"Error acquiring the state lock\".</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#3-arquitectura-multi-ambiente","title":"3. Arquitectura Multi-Ambiente","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#31-variables-por-ambiente","title":"3.1 Variables por Ambiente","text":"<pre><code># environments/dev/variables.tf\n# Variables espec\u00edficas de desarrollo.\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n  default     = \"dev\"\n}\n\nvariable \"instance_type\" {\n  description = \"EC2 instance type for ML serving\"\n  type        = string\n  default     = \"t3.small\"  # Peque\u00f1o para dev.\n}\n\nvariable \"min_capacity\" {\n  description = \"Minimum instances for auto-scaling\"\n  type        = number\n  default     = 1  # M\u00ednimo para dev.\n}\n\nvariable \"max_capacity\" {\n  description = \"Maximum instances for auto-scaling\"\n  type        = number\n  default     = 2  # Limitado para dev.\n}\n\nvariable \"enable_monitoring\" {\n  description = \"Enable detailed monitoring\"\n  type        = bool\n  default     = false  # Ahorro en dev.\n}\n</code></pre> <pre><code># environments/staging/variables.tf\n# Variables para staging (similar a prod pero m\u00e1s peque\u00f1o).\n\nvariable \"environment\" {\n  type    = string\n  default = \"staging\"\n}\n\nvariable \"instance_type\" {\n  type    = string\n  default = \"t3.medium\"  # Intermedio.\n}\n\nvariable \"min_capacity\" {\n  type    = number\n  default = 2  # HA b\u00e1sica.\n}\n\nvariable \"max_capacity\" {\n  type    = number\n  default = 4\n}\n\nvariable \"enable_monitoring\" {\n  type    = bool\n  default = true  # Testear monitoring.\n}\n</code></pre> <pre><code># environments/prod/variables.tf\n# Variables para producci\u00f3n.\n\nvariable \"environment\" {\n  type    = string\n  default = \"prod\"\n}\n\nvariable \"instance_type\" {\n  type    = string\n  default = \"t3.large\"  # M\u00e1s capacidad.\n}\n\nvariable \"min_capacity\" {\n  type    = number\n  default = 3  # HA completa.\n}\n\nvariable \"max_capacity\" {\n  type    = number\n  default = 10\n}\n\nvariable \"enable_monitoring\" {\n  type    = bool\n  default = true\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#32-maintf-comun-con-modulos","title":"3.2 Main.tf Com\u00fan con M\u00f3dulos","text":"<pre><code># environments/staging/main.tf\n# Configuraci\u00f3n de staging usando m\u00f3dulos compartidos.\n\nterraform {\n  required_version = \"&gt;= 1.5.0\"\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n\n  default_tags {\n    tags = {\n      Environment = var.environment\n      Project     = \"MLOps-Portfolio\"\n      ManagedBy   = \"Terraform\"\n    }\n  }\n}\n\n# VPC compartida.\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  environment = var.environment\n  cidr_block  = \"10.1.0.0/16\"  # Diferente CIDR por ambiente.\n}\n\n# EKS Cluster para ML workloads.\nmodule \"eks\" {\n  source = \"../../modules/eks\"\n\n  environment    = var.environment\n  vpc_id         = module.vpc.vpc_id\n  subnet_ids     = module.vpc.private_subnet_ids\n  instance_types = [var.instance_type]\n\n  # Staging: cluster m\u00e1s peque\u00f1o.\n  desired_capacity = var.min_capacity\n  min_capacity     = var.min_capacity\n  max_capacity     = var.max_capacity\n}\n\n# ML Serving infrastructure.\nmodule \"ml_serving\" {\n  source = \"../../modules/ml-serving\"\n\n  environment       = var.environment\n  cluster_id        = module.eks.cluster_id\n  instance_type     = var.instance_type\n  enable_monitoring = var.enable_monitoring\n\n  # Endpoints de modelos.\n  models = {\n    bankchurn = {\n      image     = \"123456789.dkr.ecr.us-east-1.amazonaws.com/bankchurn:staging\"\n      replicas  = var.min_capacity\n      cpu       = \"500m\"\n      memory    = \"1Gi\"\n    }\n    carvision = {\n      image     = \"123456789.dkr.ecr.us-east-1.amazonaws.com/carvision:staging\"\n      replicas  = 1  # GPU-based, menos r\u00e9plicas.\n      cpu       = \"1000m\"\n      memory    = \"4Gi\"\n      gpu       = 1\n    }\n  }\n}\n\n# Outputs.\noutput \"cluster_endpoint\" {\n  value = module.eks.cluster_endpoint\n}\n\noutput \"model_endpoints\" {\n  value = module.ml_serving.endpoints\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#33-terraform-workspaces-alternativa","title":"3.3 Terraform Workspaces (Alternativa)","text":"<pre><code># Alternativa a directorios: Terraform Workspaces.\n# \u00datil para proyectos m\u00e1s simples.\n\n# Crear workspaces.\nterraform workspace new dev\nterraform workspace new staging\nterraform workspace new prod\n\n# Cambiar de workspace.\nterraform workspace select staging\n\n# Listar workspaces.\nterraform workspace list\n\n# En c\u00f3digo, usar: terraform.workspace\n# Ejemplo:\n# instance_type = terraform.workspace == \"prod\" ? \"t3.large\" : \"t3.small\"\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#4-modulos-terraform-reutilizables","title":"4. M\u00f3dulos Terraform Reutilizables","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#41-modulo-de-ml-serving","title":"4.1 M\u00f3dulo de ML Serving","text":"<pre><code># modules/ml-serving/main.tf\n# M\u00f3dulo reutilizable para desplegar modelos ML.\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"cluster_id\" {\n  type = string\n}\n\nvariable \"instance_type\" {\n  type = string\n}\n\nvariable \"enable_monitoring\" {\n  type    = bool\n  default = true\n}\n\nvariable \"models\" {\n  description = \"Map of models to deploy\"\n  type = map(object({\n    image    = string\n    replicas = number\n    cpu      = string\n    memory   = string\n    gpu      = optional(number, 0)\n  }))\n}\n\n# Namespace para ML workloads.\nresource \"kubernetes_namespace\" \"ml\" {\n  metadata {\n    name = \"ml-${var.environment}\"\n    labels = {\n      environment = var.environment\n      purpose     = \"ml-serving\"\n    }\n  }\n}\n\n# Deployment para cada modelo.\nresource \"kubernetes_deployment\" \"model\" {\n  for_each = var.models\n\n  metadata {\n    name      = each.key\n    namespace = kubernetes_namespace.ml.metadata[0].name\n    labels = {\n      app         = each.key\n      environment = var.environment\n    }\n  }\n\n  spec {\n    replicas = each.value.replicas\n\n    selector {\n      match_labels = {\n        app = each.key\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app         = each.key\n          environment = var.environment\n        }\n        annotations = {\n          \"prometheus.io/scrape\" = var.enable_monitoring ? \"true\" : \"false\"\n          \"prometheus.io/port\"   = \"8000\"\n        }\n      }\n\n      spec {\n        container {\n          name  = each.key\n          image = each.value.image\n\n          resources {\n            requests = {\n              cpu    = each.value.cpu\n              memory = each.value.memory\n            }\n            limits = {\n              cpu    = each.value.cpu\n              memory = each.value.memory\n            }\n          }\n\n          port {\n            container_port = 8000\n          }\n\n          liveness_probe {\n            http_get {\n              path = \"/health\"\n              port = 8000\n            }\n            initial_delay_seconds = 30\n            period_seconds        = 10\n          }\n\n          readiness_probe {\n            http_get {\n              path = \"/health\"\n              port = 8000\n            }\n            initial_delay_seconds = 5\n            period_seconds        = 5\n          }\n        }\n      }\n    }\n  }\n}\n\n# Service para cada modelo.\nresource \"kubernetes_service\" \"model\" {\n  for_each = var.models\n\n  metadata {\n    name      = each.key\n    namespace = kubernetes_namespace.ml.metadata[0].name\n  }\n\n  spec {\n    selector = {\n      app = each.key\n    }\n\n    port {\n      port        = 80\n      target_port = 8000\n    }\n\n    type = \"ClusterIP\"\n  }\n}\n\n# HPA para auto-scaling.\nresource \"kubernetes_horizontal_pod_autoscaler_v2\" \"model\" {\n  for_each = var.models\n\n  metadata {\n    name      = each.key\n    namespace = kubernetes_namespace.ml.metadata[0].name\n  }\n\n  spec {\n    scale_target_ref {\n      api_version = \"apps/v1\"\n      kind        = \"Deployment\"\n      name        = each.key\n    }\n\n    min_replicas = each.value.replicas\n    max_replicas = each.value.replicas * 3\n\n    metric {\n      type = \"Resource\"\n      resource {\n        name = \"cpu\"\n        target {\n          type                = \"Utilization\"\n          average_utilization = 70\n        }\n      }\n    }\n  }\n}\n\n# Outputs.\noutput \"endpoints\" {\n  value = {\n    for k, v in kubernetes_service.model : k =&gt; {\n      name      = v.metadata[0].name\n      namespace = v.metadata[0].namespace\n      port      = v.spec[0].port[0].port\n    }\n  }\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#5-cicd-para-infraestructura","title":"5. CI/CD para Infraestructura","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#51-github-actions-para-terraform","title":"5.1 GitHub Actions para Terraform","text":"<pre><code># .github/workflows/terraform.yml\nname: Terraform CI/CD\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'infra/**'\n  pull_request:\n    branches: [main]\n    paths:\n      - 'infra/**'\n\nenv:\n  TF_VERSION: '1.5.0'\n  AWS_REGION: 'us-east-1'\n\njobs:\n  # Job 1: Validaci\u00f3n y Plan.\n  plan:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        environment: [dev, staging, prod]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Terraform Init\n        run: terraform init\n        working-directory: infra/environments/${{ matrix.environment }}\n\n      - name: Terraform Validate\n        run: terraform validate\n        working-directory: infra/environments/${{ matrix.environment }}\n\n      - name: Terraform Plan\n        run: terraform plan -out=plan.tfplan\n        working-directory: infra/environments/${{ matrix.environment }}\n\n      # Guardar plan para apply posterior.\n      - name: Upload Plan\n        uses: actions/upload-artifact@v4\n        with:\n          name: plan-${{ matrix.environment }}\n          path: infra/environments/${{ matrix.environment }}/plan.tfplan\n\n  # Job 2: Apply (solo en main, con aprobaci\u00f3n manual para prod).\n  apply:\n    needs: plan\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        environment: [dev, staging]  # Prod requiere aprobaci\u00f3n manual.\n\n    environment: ${{ matrix.environment }}  # GitHub Environment para protecci\u00f3n.\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Download Plan\n        uses: actions/download-artifact@v4\n        with:\n          name: plan-${{ matrix.environment }}\n          path: infra/environments/${{ matrix.environment }}\n\n      - name: Terraform Init\n        run: terraform init\n        working-directory: infra/environments/${{ matrix.environment }}\n\n      - name: Terraform Apply\n        run: terraform apply -auto-approve plan.tfplan\n        working-directory: infra/environments/${{ matrix.environment }}\n\n  # Job 3: Apply Prod (requiere aprobaci\u00f3n manual).\n  apply-prod:\n    needs: [plan, apply]\n    if: github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    environment: prod  # Requiere aprobaci\u00f3n manual en GitHub.\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: ${{ env.TF_VERSION }}\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}\n          aws-region: ${{ env.AWS_REGION }}\n\n      - name: Download Plan\n        uses: actions/download-artifact@v4\n        with:\n          name: plan-prod\n          path: infra/environments/prod\n\n      - name: Terraform Init\n        run: terraform init\n        working-directory: infra/environments/prod\n\n      - name: Terraform Apply\n        run: terraform apply -auto-approve plan.tfplan\n        working-directory: infra/environments/prod\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#6-ejercicio-refactorizar-para-staging","title":"6. Ejercicio: Refactorizar para Staging","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#escenario","title":"Escenario","text":"<p>El directorio <code>infra/</code> actual solo tiene <code>dev/</code> y <code>prod/</code>. Tu objetivo: crear ambiente <code>staging</code> que:</p> <ol> <li>Replica producci\u00f3n con instancias m\u00e1s peque\u00f1as.</li> <li>Usa el mismo m\u00f3dulo de ML-serving.</li> <li>Tiene su propio state file.</li> <li>Se integra al CI/CD.</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#template-de-solucion","title":"Template de Soluci\u00f3n","text":"<pre><code># Paso 1: Crear estructura.\nmkdir -p infra/environments/staging\n\n# Paso 2: Copiar y modificar configuraci\u00f3n.\ncp infra/environments/prod/*.tf infra/environments/staging/\n\n# Paso 3: Modificar variables para staging.\n</code></pre> <pre><code># infra/environments/staging/terraform.tfvars\n# Valores espec\u00edficos para staging.\n\nenvironment = \"staging\"\n\n# Instancias m\u00e1s peque\u00f1as que prod.\ninstance_type = \"t3.medium\"  # prod usa t3.large\n\n# Menos r\u00e9plicas.\nmin_capacity = 2  # prod usa 3\nmax_capacity = 4  # prod usa 10\n\n# Monitoring habilitado para testing.\nenable_monitoring = true\n\n# Tags adicionales.\nextra_tags = {\n  CostCenter = \"staging-testing\"\n  Owner      = \"ml-team\"\n}\n</code></pre> <pre><code># infra/environments/staging/backend.tf\n# Backend separado para staging.\n\nterraform {\n  backend \"s3\" {\n    bucket         = \"mlops-portfolio-tfstate\"\n    key            = \"staging/terraform.tfstate\"  # Path \u00fanico.\n    region         = \"us-east-1\"\n    dynamodb_table = \"mlops-portfolio-tflock\"\n    encrypt        = true\n  }\n}\n</code></pre>"},{"location":"docs/22_IAC_EMPRESARIAL/#entregables","title":"Entregables","text":"<ul> <li>[ ] Directorio <code>staging/</code> completo con todos los archivos.</li> <li>[ ] Backend configurado con state separado.</li> <li>[ ] Variables ajustadas (instancias m\u00e1s peque\u00f1as).</li> <li>[ ] CI/CD actualizado para incluir staging.</li> <li>[ ] Documentaci\u00f3n de diferencias vs prod.</li> </ul>"},{"location":"docs/22_IAC_EMPRESARIAL/#7-preguntas-de-entrevista-senior","title":"7. Preguntas de Entrevista Senior","text":""},{"location":"docs/22_IAC_EMPRESARIAL/#conceptuales","title":"Conceptuales","text":"<ol> <li>\u00bfPor qu\u00e9 es importante el state locking en Terraform?</li> <li>\u00bfCu\u00e1ndo usar Workspaces vs directorios separados?</li> <li>\u00bfC\u00f3mo manejas secrets en IaC?</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#diseno","title":"Dise\u00f1o","text":"<ol> <li>Dise\u00f1a una estrategia de promoci\u00f3n Dev \u2192 Staging \u2192 Prod.</li> <li>\u00bfC\u00f3mo implementar\u00edas drift detection automatizado?</li> <li>\u00bfC\u00f3mo har\u00edas rollback de infraestructura?</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#caso-practico","title":"Caso Pr\u00e1ctico","text":"<ol> <li>Tu terraform apply falla a mitad de camino. \u00bfQu\u00e9 haces?</li> </ol>"},{"location":"docs/22_IAC_EMPRESARIAL/#respuestas-clave","title":"Respuestas Clave","text":"<p>P1: State locking previene que dos personas apliquen cambios simult\u00e1neos, lo cual podr\u00eda corromper el estado o crear recursos duplicados. DynamoDB proporciona locking at\u00f3mico.</p> <p>P2:  - Workspaces: Proyectos simples, misma configuraci\u00f3n con variables diferentes. - Directorios: Proyectos complejos, configuraciones significativamente diferentes, mejor auditor\u00eda y separation of concerns.</p> <p>P3:  1. AWS Secrets Manager / HashiCorp Vault para secrets. 2. Variables de ambiente en CI/CD (nunca en c\u00f3digo). 3. <code>terraform-docs</code> para documentar sin exponer. 4. <code>.gitignore</code> para <code>*.tfvars</code> con secrets.</p> <p>P7:  1. NO ejecutar <code>terraform apply</code> de nuevo inmediatamente. 2. Revisar estado con <code>terraform state list</code>. 3. Identificar recursos parcialmente creados. 4. Opci\u00f3n A: <code>terraform taint</code> recursos problem\u00e1ticos y re-apply. 5. Opci\u00f3n B: Importar recursos existentes al estado. 6. Opci\u00f3n C: Rollback manual + <code>terraform destroy</code> selectivo.</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/22_IAC_EMPRESARIAL/#documentacion","title":"\ud83d\udcc4 Documentaci\u00f3n","text":"\ud83c\udff7\ufe0f Recurso Descripci\u00f3n \ud83d\udd34 Terraform Best Practices Gu\u00eda de patrones \ud83d\udfe1 HashiCorp Learn Tutoriales oficiales \ud83d\udfe2 Terragrunt DRY Terraform"},{"location":"docs/22_IAC_EMPRESARIAL/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n State Archivo que mapea recursos reales a configuraci\u00f3n Terraform Backend D\u00f3nde se almacena el state (S3, GCS, etc.) Module Conjunto reutilizable de recursos Terraform Workspace Instancia separada del mismo c\u00f3digo con state diferente   **Siguiente m\u00f3dulo** \u2192 [23. Proyecto Integrador](23_PROYECTO_INTEGRADOR.md)  ---  [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/23_PROYECTO_INTEGRADOR/","title":"20. Proyecto Integrador","text":"<p>## 0.0 Prerrequisitos</p> <ul> <li>Haber completado los m\u00f3dulos 01\u201319 (en particular: Testing, CI/CD, APIs, Observabilidad y Documentaci\u00f3n).</li> <li>Tener listo un repositorio \u201cvac\u00edo pero bien estructurado\u201d (o estar dispuesto a crearlo primero) antes de entrenar cualquier modelo.</li> <li>Aceptar el enfoque de este m\u00f3dulo: integraci\u00f3n por capas (estructura \u2192 pipeline \u2192 tests \u2192 API \u2192 Docker \u2192 CI/CD \u2192 docs).</li> </ul> <p></p> <p>## 0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</p> <ul> <li>Antes de empezar: define un \u201calcance senior\u201d realista (qu\u00e9 vas a construir y qu\u00e9 NO).</li> <li>Durante: trabaja con commits peque\u00f1os, y valida cada capa (instalaci\u00f3n, tests, API) antes de pasar a la siguiente.</li> <li>Si te atoras &gt;15 min (tests rotos, CI fallando, configs duplicadas), reg\u00edstralo en el Diario de Errores y aplica el flujo de Protocolo E.</li> </ul> <p></p> <p>## 0.2 \u2705 Entregables verificables (m\u00ednimo viable)</p> <ul> <li>[ ] El repo instala con <code>pip install -e .</code> (sin pasos manuales ocultos).</li> <li>[ ] <code>make test</code> pasa en local con coverage objetivo.</li> <li>[ ] <code>make train</code> produce artefactos reproducibles (y el pipeline se puede re-ejecutar).</li> <li>[ ] La API expone <code>/health</code> y <code>/predict</code> y tiene tests m\u00ednimos.</li> <li>[ ] Hay documentaci\u00f3n m\u00ednima (README + Model/Data card).</li> </ul> <p></p> <p>## 0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</p> <ul> <li>Este m\u00f3dulo es tu \u201cproducto final\u201d: demostrar que puedes ensamblar un sistema ML completo, no solo un modelo.</li> <li>Reutiliza patrones del portafolio (estructura <code>src/</code>, config, tests, CI) pero justificando adaptaciones.</li> <li>Tu objetivo es que un revisor pueda clonar tu repo, ejecutar 2\u20133 comandos y ver el sistema funcionando.</li> </ul> <p>## \ud83d\udccb Contenido</p> <ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>20.1 Objetivo</li> <li>20.2 El Proyecto: Sistema de Recomendaci\u00f3n de Planes</li> <li>20.3 Checklist de Entrega (100 puntos)</li> <li>20.4 Plantilla de README</li> <li>20.5 R\u00fabrica de Evaluaci\u00f3n</li> <li>Errores habituales</li> <li>20.6 Tips para \u00c9xito</li> <li>20.7 Consejos Profesionales</li> <li>20.8 Recursos Externos Recomendados</li> <li>20.9 Referencias del Glosario</li> <li>\u2705 Ejercicio</li> <li>20.10 Entrega</li> <li>23.11 \ud83d\udd2c Ingenier\u00eda Inversa: Arquitectura Monorepo \u2b50 NUEVO</li> <li>\u2705 Checkpoint</li> </ul> <p></p> <p>## \ud83c\udfaf Objetivo</p> <p>Construir un proyecto ML completo desde cero, aplicando TODO lo aprendido.</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551  \ud83c\udfc6 EL RETO FINAL                                                            \u2551\n\u2551                                                                              \u2551\n\u2551  Has aprendido los conceptos. Has estudiado el c\u00f3digo del portafolio.        \u2551\n\u2551  Ahora es momento de DEMOSTRAR que puedes construirlo desde cero.            \u2551\n\u2551                                                                              \u2551\n\u2551  TIEMPO: 1-2 semanas                                                         \u2551\n\u2551  RESULTADO: Un 4to proyecto digno del portafolio                             \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#el-proyecto-sistema-de-recomendacion-de-planes","title":"\ud83d\udccb  El Proyecto: Sistema de Recomendaci\u00f3n de Planes","text":"<p>Contexto: Una empresa de telecomunicaciones quiere recomendar planes m\u00f3viles bas\u00e1ndose en el comportamiento del usuario.</p> <p>Dataset sugerido: Telecom Users Dataset o similar.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#mapa-mental-de-conceptos","title":"\ud83e\udde0 Mapa Mental de Conceptos","text":"<p>T\u00e9rminos clave para este m\u00f3dulo: - Revisa los conceptos principales en las secciones siguientes - Practica con los ejercicios del portafolio BankChurn - Aplica los checkpoints para verificar tu comprensi\u00f3n</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#ejercicio-puente-capstone","title":"\ud83d\udcbb Ejercicio Puente: Capstone","text":"<p>Meta: Practica el concepto antes de aplicarlo al portafolio.</p> <p>Ejercicio b\u00e1sico: 1. Lee la secci\u00f3n te\u00f3rica siguiente 2. Identifica los patrones clave del c\u00f3digo de ejemplo 3. Replica el patr\u00f3n en un proyecto de prueba</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#practica-del-portafolio-proyecto-integrador-en-bankchurn","title":"\ud83d\udee0\ufe0f Pr\u00e1ctica del Portafolio: Proyecto Integrador en BankChurn","text":"<p>Tarea: Aplicar este m\u00f3dulo en BankChurn-Predictor.</p> <pre><code>cd BankChurn-Predictor\n# Explora el c\u00f3digo relacionado con Capstone\n</code></pre> <p>Checklist: - [ ] Localic\u00e9 el c\u00f3digo relevante - [ ] Entend\u00ed la implementaci\u00f3n actual - [ ] Identifiqu\u00e9 posibles mejoras</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#checkpoint-de-conocimiento","title":"\u2705 Checkpoint de Conocimiento","text":"<p>Pregunta 1: \u00bfCu\u00e1l es el objetivo principal de Proyecto Integrador?</p> <p>Pregunta 2: \u00bfC\u00f3mo se implementa en el portafolio?</p> <p>\ud83d\udd27 Escenario Debugging: Si algo falla en Capstone, \u00bfcu\u00e1l ser\u00eda tu primer paso de diagn\u00f3stico?</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#checklist-de-entrega-100-puntos","title":"\u2705  Checklist de Entrega (100 puntos)","text":""},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-1-estructura-y-configuracion-20-puntos","title":"Fase 1: Estructura y Configuraci\u00f3n (20 puntos)","text":"Requisito Puntos Archivo Estructura src/ layout 3 <code>src/planrec/</code> pyproject.toml completo 3 <code>pyproject.toml</code> Makefile con comandos b\u00e1sicos 2 <code>Makefile</code> Config Pydantic con validaci\u00f3n 4 <code>src/planrec/config.py</code> Config YAML externo 2 <code>configs/config.yaml</code> .gitignore apropiado 2 <code>.gitignore</code> README profesional 4 <code>README.md</code>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-2-pipeline-ml-25-puntos","title":"Fase 2: Pipeline ML (25 puntos)","text":"Requisito Puntos Archivo Carga y validaci\u00f3n de datos 3 <code>src/planrec/data.py</code> Feature Engineering como Transformer 5 <code>src/planrec/features.py</code> sklearn Pipeline unificado 5 <code>src/planrec/training.py</code> Cross-validation estratificada 3 <code>src/planrec/training.py</code> M\u00e9tricas apropiadas (F1, AUC) 3 <code>src/planrec/evaluation.py</code> Guardado de artefactos 3 <code>artifacts/</code> Prevenci\u00f3n de data leakage 3 <code>drop_columns</code> en config"},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-3-testing-20-puntos","title":"Fase 3: Testing (20 puntos)","text":"Requisito Puntos Archivo conftest.py con fixtures 4 <code>tests/conftest.py</code> Tests unitarios (features) 4 <code>tests/test_features.py</code> Tests de datos 3 <code>tests/test_data.py</code> Tests de modelo 3 <code>tests/test_model.py</code> Tests de integraci\u00f3n 3 <code>tests/test_training.py</code> Coverage \u2265 80% 3 <code>pytest --cov</code>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-4-api-y-serving-15-puntos","title":"Fase 4: API y Serving (15 puntos)","text":"Requisito Puntos Archivo FastAPI con Pydantic schemas 4 <code>app/fastapi_app.py</code> Endpoint /health 2 Endpoint /predict 4 Dockerfile multi-stage 3 <code>Dockerfile</code> Non-root user 2"},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-5-cicd-y-calidad-15-puntos","title":"Fase 5: CI/CD y Calidad (15 puntos)","text":"Requisito Puntos Archivo GitHub Actions workflow 5 <code>.github/workflows/ci.yml</code> Tests autom\u00e1ticos 3 Coverage enforcement 3 Linting (ruff/black) 2 Pre-commit hooks 2 <code>.pre-commit-config.yaml</code>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#fase-6-documentacion-5-puntos","title":"Fase 6: Documentaci\u00f3n (5 puntos)","text":"Requisito Puntos Archivo Model Card 3 <code>docs/model_card.md</code> Data Card 2 <code>docs/data_card.md</code>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#plantilla-de-readme","title":"\ud83d\udcdd  Plantilla de README","text":"<pre><code># \ud83d\udcf1 PlanRec: Mobile Plan Recommender\n\n[![CI](https://github.com/USER/planrec/actions/workflows/ci.yml/badge.svg)](...)\n[![Coverage](https://img.shields.io/badge/Coverage-85%25-brightgreen)](...)\n[![Python](https://img.shields.io/badge/Python-3.11-blue)](...)\n\n&gt; Sistema de recomendaci\u00f3n de planes m\u00f3viles basado en comportamiento de usuarios.\n\n## \ud83c\udfaf Resumen del Proyecto\n\n| M\u00e9trica | Valor |\n|---------|-------|\n| **Accuracy** | 85% |\n| **F1-Score** | 0.82 |\n| **Coverage** | 85% |\n\n## \ud83d\ude80 Quick Start\n\n\\`\\`\\`bash\n# Instalar\npip install -e \".[dev]\"\n\n# Entrenar\nmake train\n\n# Servir API\nmake serve\n\n# Tests\nmake test\n\\`\\`\\`\n\n## \ud83d\udcc1 Estructura\n\n\\`\\`\\`\nplanrec/\n\u251c\u2500\u2500 src/planrec/       # C\u00f3digo fuente\n\u251c\u2500\u2500 app/               # FastAPI\n\u251c\u2500\u2500 tests/             # Tests\n\u251c\u2500\u2500 configs/           # Configuraci\u00f3n\n\u2514\u2500\u2500 artifacts/         # Modelos (gitignored)\n\\`\\`\\`\n\n## \ud83d\udcca Arquitectura\n\n[Diagrama de arquitectura]\n\n## \ud83d\udee0\ufe0f Stack Tecnol\u00f3gico\n\n- **ML**: scikit-learn, pandas, numpy\n- **API**: FastAPI, uvicorn\n- **Config**: Pydantic, PyYAML\n- **Testing**: pytest, pytest-cov\n- **CI/CD**: GitHub Actions\n- **Container**: Docker\n\n## \ud83d\udcd6 Documentaci\u00f3n\n\n- [Model Card](docs/model_card.md)\n- [Data Card](docs/data_card.md)\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#rubrica-de-evaluacion","title":"\ud83c\udfaf  R\u00fabrica de Evaluaci\u00f3n","text":""},{"location":"docs/23_PROYECTO_INTEGRADOR/#nivel-junior-50-69-puntos","title":"Nivel Junior (50-69 puntos)","text":"<ul> <li>Funciona pero con estructura b\u00e1sica</li> <li>Tests m\u00ednimos</li> <li>Sin CI/CD</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#nivel-mid-70-84-puntos","title":"Nivel Mid (70-84 puntos)","text":"<ul> <li>Estructura correcta</li> <li>Tests con coverage &gt; 70%</li> <li>CI b\u00e1sico</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#nivel-senior-85-94-puntos","title":"Nivel Senior (85-94 puntos)","text":"<ul> <li>Custom Transformer funcionando</li> <li>Coverage &gt; 80%</li> <li>CI/CD completo</li> <li>Documentaci\u00f3n profesional</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#nivel-staff-95-100-puntos","title":"Nivel Staff (95-100 puntos)","text":"<ul> <li>Todo lo anterior</li> <li>Drift detection</li> <li>MLflow integration</li> <li>Model Card completo</li> <li>Code review pasable en FAANG</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#errores-habituales-y-como-depurarlos-en-el-proyecto-integrador","title":"\ud83e\udde8  Errores habituales y c\u00f3mo depurarlos en el Proyecto Integrador","text":"<p>En el proyecto integrador el mayor reto no es una tecnolog\u00eda concreta, sino coordinar todas las piezas sin romper nada en el camino.</p> <p>Si alguno de estos errores te tom\u00f3 &gt;15 minutos, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#1-empezar-por-el-modelo-y-olvidar-la-estructura","title":"1) Empezar por el modelo y olvidar la estructura","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Tienes notebooks y scripts sueltos, pero no un paquete <code>src/planrec</code> ni <code>pyproject.toml</code> claros.</li> <li>Es dif\u00edcil correr el proyecto en otra m\u00e1quina o en CI.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Preg\u00fantate: \u00bfpuedo ejecutar <code>pip install -e .</code> y luego <code>python -m planrec.cli</code> o similar?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Copia la estructura de BankChurn/CarVision: <code>src/</code>, <code>configs/</code>, <code>app/</code>, <code>tests/</code>, <code>artifacts/</code>.</li> <li>Define desde el inicio <code>pyproject.toml</code>, <code>Makefile</code> y <code>.gitignore</code>.</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#2-config-dispersa-o-duplicada","title":"2) Config dispersa o duplicada","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Rutas de datos, thresholds o hiperpar\u00e1metros hardcodeados en varios archivos.</li> <li>Cambias algo en un sitio y se rompe otra parte.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Busca valores repetidos (por ejemplo, paths o columnas) en m\u00faltiples m\u00f3dulos.</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Centraliza configuraci\u00f3n en <code>configs/config.yaml</code> y una clase Pydantic (<code>Config</code>) que valide todo.</li> <li>Haz que training, API y scripts lean SIEMPRE desde esa fuente de verdad.</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#3-tests-que-no-cubren-el-flujo-completo","title":"3) Tests que no cubren el flujo completo","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Coverage aceptable, pero sin tests de integraci\u00f3n ni de API.</li> <li>El pipeline entero falla cuando intentas ejecutar <code>make train</code> o el endpoint <code>/predict</code>.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Revisa si tienes al menos:</li> <li>Tests de features (<code>test_features.py</code>).</li> <li>Tests de datos (<code>test_data.py</code>).</li> <li>Tests de entrenamiento/integraci\u00f3n (<code>test_training.py</code>).</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>A\u00f1ade al menos un test que recorra el flujo E2E con datos peque\u00f1os, similar a los de CarVision.</li> <li>Usa fixtures y <code>tmp_path</code> para no depender de rutas reales.</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#4-cicd-que-solo-corre-en-local","title":"4) CI/CD que solo corre en local","text":"<p>S\u00edntomas t\u00edpicos</p> <ul> <li>Tienes un archivo <code>.github/workflows/ci.yml</code> pero los jobs fallan siempre en GitHub.</li> </ul> <p>C\u00f3mo identificarlo</p> <ul> <li>Compara el workflow con el del portafolio: \u00bfcoinciden <code>working-directory</code>, versiones de Python y comandos?</li> </ul> <p>C\u00f3mo corregirlo</p> <ul> <li>Simplifica primero: un job que haga <code>pip install -e .</code> y <code>pytest</code>.</li> <li>A\u00f1ade coverage y linting cuando el flujo b\u00e1sico sea estable.</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#5-patron-general-de-debugging-del-proyecto-integrador","title":"5) Patr\u00f3n general de debugging del proyecto integrador","text":"<ol> <li>Valida la base: estructura, instalaci\u00f3n (<code>pip install -e .</code>), <code>make test</code>.</li> <li>Aseg\u00farate de que el pipeline de training funciona de principio a fin con datos peque\u00f1os.</li> <li>Solo entonces a\u00f1ade API, Docker y CI/CD, verificando cada capa con su propio conjunto de tests.</li> </ol> <p>Con este enfoque, reduces la frustraci\u00f3n y aumentas la probabilidad de tener un 4\u00ba proyecto s\u00f3lido de portafolio.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#tips-para-exito","title":"\ud83d\udca1  Tips para \u00c9xito","text":"<ol> <li>Empieza por la estructura - No escribas c\u00f3digo sin tener pyproject.toml y Makefile</li> <li>Tests primero - TDD te ahorra tiempo a largo plazo</li> <li>Commits peque\u00f1os - Un commit por feature, mensajes claros</li> <li>README actualizado - Actual\u00edzalo mientras avanzas, no al final</li> <li>Copia patrones - Usa el c\u00f3digo de BankChurn/CarVision como referencia</li> </ol>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#consejos-profesionales","title":"\ud83d\udcbc  Consejos Profesionales","text":"<p>Recomendaciones para destacar en entrevistas y proyectos reales</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#para-entrevistas","title":"Para Entrevistas","text":"<ol> <li> <p>Cuenta una historia: Tu portafolio debe mostrar progresi\u00f3n y aprendizaje.</p> </li> <li> <p>Explica decisiones: \"\u00bfPor qu\u00e9 elegiste X?\" es la pregunta m\u00e1s com\u00fan.</p> </li> <li> <p>Muestra m\u00e9tricas: Impacto cuantificable impresiona m\u00e1s que features.</p> </li> </ol>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#para-tu-portafolio","title":"Para tu Portafolio","text":"Elemento Por qu\u00e9 Importa README profesional Primera impresi\u00f3n, 30 segundos para captar atenci\u00f3n Demo en vivo Muestra que funciona, no solo que existe C\u00f3digo limpio Los revisores leen tu c\u00f3digo Documentaci\u00f3n Demuestra comunicaci\u00f3n t\u00e9cnica"},{"location":"docs/23_PROYECTO_INTEGRADOR/#checklist-final-del-portafolio","title":"Checklist Final del Portafolio","text":"<ul> <li>[ ] Cada proyecto tiene problema claro y soluci\u00f3n</li> <li>[ ] M\u00e9tricas de performance documentadas</li> <li>[ ] CI/CD funcionando con badges</li> <li>[ ] Docker para reproducibilidad</li> <li>[ ] README con GIFs o screenshots</li> <li>[ ] Deployed y accesible (demo link)</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#recursos-externos-del-modulo","title":"\ud83d\udcfa Recursos Externos del M\u00f3dulo","text":"<p>\ud83c\udff7\ufe0f Sistema: \ud83d\udd34 Obligatorio | \ud83d\udfe1 Recomendado | \ud83d\udfe2 Complementario</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#videos","title":"\ud83c\udfac Videos","text":"\ud83c\udff7\ufe0f T\u00edtulo Canal Duraci\u00f3n Link \ud83d\udd34 End-to-End ML Project Krish Naik 2h YouTube \ud83d\udfe1 MLOps Best Practices Google Cloud 45 min YouTube"},{"location":"docs/23_PROYECTO_INTEGRADOR/#cursos-integrales","title":"\ud83d\udcda Cursos Integrales","text":"\ud83c\udff7\ufe0f T\u00edtulo Plataforma Cubre Link \ud83d\udd34 MLOps Zoomcamp DataTalksClub Todo el stack GitHub \ud83d\udd34 Made With ML MadeWithML ML + MLOps MadeWithML \ud83d\udfe1 Full Stack Deep Learning FSDL Producci\u00f3n ML FSDL"},{"location":"docs/23_PROYECTO_INTEGRADOR/#ejercicios-del-modulo","title":"\ud83d\udd27 Ejercicios del M\u00f3dulo","text":""},{"location":"docs/23_PROYECTO_INTEGRADOR/#ejercicio-231-script-e2e-completo","title":"Ejercicio 23.1: Script E2E Completo","text":"<p>Objetivo: Crear script que ejecute pipeline completo. Dificultad: \u2b50\u2b50\u2b50</p> <pre><code># scripts/run_e2e.py\n# TU TAREA: Script que ejecute todo el pipeline\n\ndef run_e2e_pipeline():\n    \"\"\"Ejecuta pipeline completo de ML.\"\"\"\n    # 1. Verificar datos existen\n    # 2. Entrenar modelo\n    # 3. Verificar artefactos\n    # 4. Levantar API\n    # 5. Test de integraci\u00f3n\n    # 6. Cleanup\n    pass\n</code></pre> \ud83d\udca1 Ver soluci\u00f3n <pre><code>#!/usr/bin/env python3\n\"\"\"Script E2E para validar pipeline completo.\"\"\"\n\nimport subprocess\nimport sys\nimport time\nfrom pathlib import Path\n\nimport requests\n\n\ndef run_e2e_pipeline() -&gt; bool:\n    \"\"\"Ejecuta pipeline completo de ML.\"\"\"\n    print(\"\ud83d\ude80 Iniciando pipeline E2E...\")\n\n    # 1. Verificar datos\n    data_path = Path(\"data/raw/dataset.csv\")\n    if not data_path.exists():\n        print(f\"\u274c Dataset no encontrado: {data_path}\")\n        return False\n    print(\"\u2705 Dataset encontrado\")\n\n    # 2. Entrenar modelo\n    print(\"\ud83d\udd04 Entrenando modelo...\")\n    result = subprocess.run(\n        [\"python\", \"-m\", \"bankchurn.training\"],\n        capture_output=True,\n        text=True\n    )\n    if result.returncode != 0:\n        print(f\"\u274c Error en training: {result.stderr}\")\n        return False\n    print(\"\u2705 Modelo entrenado\")\n\n    # 3. Verificar artefactos\n    model_path = Path(\"artifacts/model.joblib\")\n    if not model_path.exists():\n        print(f\"\u274c Modelo no encontrado: {model_path}\")\n        return False\n    print(\"\u2705 Artefactos generados\")\n\n    # 4. Levantar API\n    print(\"\ud83d\udd04 Iniciando API...\")\n    api_process = subprocess.Popen(\n        [\"uvicorn\", \"app.fastapi_app:app\", \"--port\", \"8000\"],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE\n    )\n    time.sleep(5)  # Esperar startup\n\n    try:\n        # 5. Test de integraci\u00f3n\n        print(\"\ud83d\udd04 Ejecutando tests de integraci\u00f3n...\")\n\n        # Health check\n        response = requests.get(\"http://localhost:8000/health\")\n        assert response.status_code == 200\n        print(\"\u2705 Health check OK\")\n\n        # Prediction\n        test_data = {\"feature1\": 1.0, \"feature2\": 0.5}\n        response = requests.post(\n            \"http://localhost:8000/predict\",\n            json=test_data\n        )\n        assert response.status_code == 200\n        assert \"prediction\" in response.json()\n        print(\"\u2705 Prediction endpoint OK\")\n\n        print(\"\ud83c\udf89 Pipeline E2E completado exitosamente!\")\n        return True\n\n    finally:\n        # 6. Cleanup\n        api_process.terminate()\n        api_process.wait()\n        print(\"\u2705 Cleanup completado\")\n\n\nif __name__ == \"__main__\":\n    success = run_e2e_pipeline()\n    sys.exit(0 if success else 1)\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#glosario-del-modulo","title":"\ud83d\udd17 Glosario del M\u00f3dulo","text":"T\u00e9rmino Definici\u00f3n E2E Pipeline Flujo completo desde datos raw hasta predicci\u00f3n en producci\u00f3n Integration Test Tests que verifican m\u00faltiples componentes trabajando juntos Smoke Test Test r\u00e1pido que verifica funcionalidad b\u00e1sica est\u00e1 operativa Self-assessment Autoevaluaci\u00f3n usando r\u00fabrica de criterios"},{"location":"docs/23_PROYECTO_INTEGRADOR/#entrega-final","title":"\ud83c\udfc1 Entrega Final","text":"<ol> <li>Repositorio p\u00fablico en GitHub</li> <li>CI pasando (verde)</li> <li>README con badges actualizados</li> <li>Self-assessment del checklist completado</li> </ol>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#2311-ingenieria-inversa-pedagogica-arquitectura-monorepo","title":"23.11 \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: Arquitectura Monorepo","text":"<p>Objetivo: Entender c\u00f3mo escalar de 1 proyecto a 3 proyectos compartiendo c\u00f3digo.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23111-el-por-que-arquitectonico","title":"23.11.1 \ud83c\udfaf El \"Por Qu\u00e9\" Arquitect\u00f3nico","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    EVOLUCI\u00d3N DEL PORTAFOLIO: 1 \u2192 3 PROYECTOS                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  PROBLEMA 1: \u00bfC\u00f3mo comparto c\u00f3digo entre BankChurn, CarVision y TelecomAI?      \u2502\n\u2502  DECISI\u00d3N: common_utils/ como librer\u00eda interna instalable                       \u2502\n\u2502  RESULTADO: DRY a nivel de portafolio, logger y seeds consistentes              \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 2: \u00bfC\u00f3mo mantengo CI/CD para 3 proyectos sin duplicar workflows?      \u2502\n\u2502  DECISI\u00d3N: Matriz de GitHub Actions con strategy.matrix.project                 \u2502\n\u2502  RESULTADO: Un workflow, 3 proyectos testeados en paralelo                      \u2502\n\u2502                                                                                 \u2502\n\u2502  PROBLEMA 3: \u00bfC\u00f3mo evito que cambios en un proyecto rompan otros?               \u2502\n\u2502  DECISI\u00d3N: Cada proyecto tiene su propio pyproject.toml y tests aislados        \u2502\n\u2502  RESULTADO: Independencia con c\u00f3digo compartido opcional                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23112-anatomia-del-monorepo","title":"23.11.2 \ud83d\udd0d Anatom\u00eda del Monorepo","text":"<p>Estructura: <code>ML-MLOps-Portfolio/</code></p> <pre><code>ML-MLOps-Portfolio/\n\u2502\n\u251c\u2500\u2500 common_utils/                    # \u2190 LIBRER\u00cdA COMPARTIDA\n\u2502   \u251c\u2500\u2500 __init__.py                  # Exports: setup_logging, set_seed\n\u2502   \u251c\u2500\u2500 logger.py                    # Logging consistente para todos\n\u2502   \u2514\u2500\u2500 seed.py                      # Reproducibilidad centralizada\n\u2502\n\u251c\u2500\u2500 BankChurn-Predictor/             # \u2190 PROYECTO 1 (independiente)\n\u2502   \u251c\u2500\u2500 src/bankchurn/\n\u2502   \u2502   \u2514\u2500\u2500 training.py              # from common_utils import setup_logging\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 pyproject.toml               # Dependencias propias\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502\n\u251c\u2500\u2500 CarVision-Market-Intelligence/   # \u2190 PROYECTO 2 (independiente)\n\u2502   \u251c\u2500\u2500 src/carvision/\n\u2502   \u2502   \u2514\u2500\u2500 training.py              # from common_utils import set_seed\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 pyproject.toml\n\u2502\n\u251c\u2500\u2500 TelecomAI-Customer-Intelligence/ # \u2190 PROYECTO 3 (independiente)\n\u2502   \u251c\u2500\u2500 src/telecom/\n\u2502   \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 .github/workflows/\n\u2502   \u2514\u2500\u2500 ci-mlops.yml                 # \u2190 UN workflow para los 3 proyectos\n\u2502\n\u251c\u2500\u2500 infra/                           # Docker Compose, Prometheus, etc.\n\u2514\u2500\u2500 Makefile                         # Comandos ra\u00edz delegando a sub-proyectos\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23113-common_utils-codigo-compartido","title":"23.11.3 \ud83d\udce6 common_utils: C\u00f3digo Compartido","text":"<pre><code># common_utils/__init__.py\n\"\"\"\nAPI p\u00fablica de utilidades compartidas.\n\nTodas las funciones aqu\u00ed son usadas por BankChurn, CarVision y TelecomAI\npara garantizar consistencia en logging y reproducibilidad.\n\"\"\"\n\nfrom common_utils.logger import setup_logging    # Logging consistente.\nfrom common_utils.seed import set_seed           # Seeds para reproducibilidad.\n\n__version__ = \"1.0.0\"                            # Versi\u00f3n de la librer\u00eda.\n__all__ = [\"setup_logging\", \"set_seed\"]          # Exports expl\u00edcitos.\n</code></pre> <pre><code># common_utils/seed.py\n\"\"\"Reproducibilidad centralizada para todos los proyectos.\"\"\"\n\nimport os                                        # Variables de entorno.\nimport random                                    # Random de Python.\nimport numpy as np                               # NumPy random.\n\nDEFAULT_SEED = 42                                # Valor por defecto.\n\n\ndef set_seed(seed: int = DEFAULT_SEED) -&gt; int:\n    \"\"\"\n    Configura seeds globales para reproducibilidad.\n\n    Esta funci\u00f3n setea el seed para Python, NumPy, y opcionalmente\n    PyTorch/TensorFlow si est\u00e1n instalados.\n    \"\"\"\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)     # Hash determin\u00edstico.\n    random.seed(seed)                            # Random de Python.\n    np.random.seed(seed)                         # NumPy.\n\n    # PyTorch (opcional, si est\u00e1 instalado).\n    try:\n        import torch\n        torch.manual_seed(seed)                  # CPU.\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)     # GPU.\n    except ImportError:\n        pass  # PyTorch no instalado.\n\n    return seed\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23114-cicd-con-matriz-de-proyectos","title":"23.11.4 \ud83d\udd04 CI/CD con Matriz de Proyectos","text":"<pre><code># .github/workflows/ci-mlops.yml\nname: CI/CD MLOps Portfolio\n\non:\n  push:\n    branches: [main, develop]\n\njobs:\n  tests:\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: false                           # No cancelar otros si uno falla.\n      matrix:\n        python-version: ['3.11', '3.12']         # Probar m\u00faltiples versiones.\n        project:                                 # \u2190 LOS 3 PROYECTOS\n          - BankChurn-Predictor\n          - CarVision-Market-Intelligence\n          - TelecomAI-Customer-Intelligence\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        working-directory: ${{ matrix.project }} # \u2190 Cambia a cada proyecto.\n        run: pip install -e \".[dev]\"\n\n      - name: Run tests\n        working-directory: ${{ matrix.project }}\n        run: pytest --cov --cov-fail-under=80\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23115-laboratorio-de-replicacion","title":"23.11.5 \ud83e\uddea Laboratorio de Replicaci\u00f3n","text":"<pre><code># Paso 1: Crear estructura monorepo desde cero\nmkdir mi-portfolio-ml &amp;&amp; cd mi-portfolio-ml\n\n# Paso 2: Crear common_utils\nmkdir -p common_utils\ncat &gt; common_utils/__init__.py &lt;&lt; 'EOF'\nfrom common_utils.logger import setup_logging\nfrom common_utils.seed import set_seed\n__all__ = [\"setup_logging\", \"set_seed\"]\nEOF\n\n# Paso 3: Crear primer proyecto usando common_utils\nmkdir -p proyecto1/src/proyecto1\ncat &gt; proyecto1/src/proyecto1/training.py &lt;&lt; 'EOF'\nimport sys\nsys.path.insert(0, \"../..\")  # Para desarrollo local.\nfrom common_utils import setup_logging, set_seed\n\nlogger = setup_logging(__name__)\nset_seed(42)\n\ndef train():\n    logger.info(\"Training con seed reproducible\")\nEOF\n\n# Paso 4: Verificar que funciona\ncd proyecto1 &amp;&amp; python -c \"from src.proyecto1.training import train; train()\"\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#23116-troubleshooting-monorepo","title":"23.11.6 \ud83d\udea8 Troubleshooting Monorepo","text":"S\u00edntoma Causa Soluci\u00f3n \"ModuleNotFoundError: common_utils\" PYTHONPATH no incluye ra\u00edz <code>pip install -e ../common_utils</code> o <code>sys.path.insert</code> CI falla solo en un proyecto Dependencias diferentes Verificar <code>pyproject.toml</code> de ese proyecto Cambio en common_utils rompe proyecto Sin tests de integraci\u00f3n A\u00f1adir tests que importen desde common_utils"},{"location":"docs/23_PROYECTO_INTEGRADOR/#checkpoint-final-guia-completa","title":"\ud83c\udfc6 CHECKPOINT FINAL: Gu\u00eda Completa","text":"<p>\ud83c\udfaf \u00a1Felicidades! Has completado los m\u00f3dulos 01-23</p> <p>Ahora tienes el conocimiento de un Senior/Staff MLOps Engineer: - \u2705 Python profesional con type hints y Pydantic - \u2705 Pipelines ML reproducibles con sklearn y DVC - \u2705 Testing completo con 80%+ coverage - \u2705 CI/CD profesional con GitHub Actions - \u2705 Docker, APIs y dashboards de producci\u00f3n - \u2705 Observabilidad con drift detection - \u2705 Infraestructura como c\u00f3digo - \u2705 3 proyectos production-ready en tu portafolio</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#examen-final-de-integracion","title":"\ud83d\udccb Examen Final de Integraci\u00f3n","text":"<p>Formato: Self-Correction System Design Duraci\u00f3n: 90-120 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#ejercicio-disena-un-sistema-ml","title":"Ejercicio: Dise\u00f1a un Sistema ML","text":"<p>Escenario: Una empresa de e-commerce quiere predecir qu\u00e9 productos comprar\u00e1n los usuarios. Tienes: - 10M usuarios activos - 1M productos - 100M interacciones/mes - Latencia requerida: &lt;100ms - Budget: Moderado (no FAANG)</p> <p>Tu tarea: Dise\u00f1a la arquitectura completa.</p> \ud83d\udcdd Ver Soluci\u00f3n  **Arquitectura Propuesta:**  <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     DATA LAYER                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  S3 (raw) \u2192 Spark (ETL) \u2192 Feature Store (Redis) \u2192 DVC       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    TRAINING LAYER                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  MLflow Tracking \u2192 Kubernetes Jobs \u2192 Model Registry         \u2502\n\u2502  - Batch training diario                                    \u2502\n\u2502  - A/B testing de modelos                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SERVING LAYER                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Load Balancer \u2192 FastAPI (K8s HPA) \u2192 Redis Cache            \u2502\n\u2502  - 3 replicas m\u00ednimo                                        \u2502\n\u2502  - Auto-scale hasta 10                                      \u2502\n\u2502  - Cache de predicciones frecuentes                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  MONITORING LAYER                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Prometheus \u2192 Grafana \u2192 Alerting \u2192 Evidently (drift)        \u2502\n\u2502  - Latency p99 &lt; 100ms                                      \u2502\n\u2502  - Error rate &lt; 0.1%                                        \u2502\n\u2502  - Drift check diario                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>  **Decisiones clave:** - **Feature Store (Redis)**: Pre-computa features para latencia &lt;100ms - **K8s HPA**: Auto-scaling para 10M usuarios - **Cache**: Productos populares tienen predicciones cacheadas - **Batch + Real-time**: Training batch, serving real-time"},{"location":"docs/23_PROYECTO_INTEGRADOR/#simulacro-de-entrevista-nivel-seniorstaff","title":"\ud83c\udfa4 Simulacro de Entrevista: Nivel Senior/Staff","text":"<p>115+ preguntas divididas en 2 partes Tiempo: 90 min cada parte Objetivo: Preparaci\u00f3n para posiciones Senior/Staff ML Engineer</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#parte-1-tecnico-avanzado-50-preguntas","title":"Parte 1: T\u00e9cnico Avanzado (50+ preguntas)","text":"<p>System Design (15 preguntas) 1. \u00bfC\u00f3mo dise\u00f1ar\u00edas un sistema de recomendaciones para 100M usuarios? 2. \u00bfTrade-offs entre batch y real-time serving? 3. \u00bfC\u00f3mo manejar\u00edas cold start en recomendaciones?</p> <p>Arquitectura ML (15 preguntas) 4. \u00bfCu\u00e1ndo usar\u00edas feature store vs computar on-the-fly? 5. \u00bfC\u00f3mo implementar\u00edas A/B testing para modelos? 6. \u00bfEstrategia de rollback si un modelo degrada?</p> <p>Infraestructura (10 preguntas) 7. \u00bfC\u00f3mo optimizar\u00edas costos en un pipeline ML en AWS? 8. \u00bfCu\u00e1ndo usar Spot vs On-Demand para training? 9. \u00bfC\u00f3mo escalar\u00edas a m\u00faltiples regiones?</p> \ud83d\udca1 Ver Respuestas de Muestra  **1. Sistema de recomendaciones 100M usuarios:** &gt; Arquitectura en capas: (1) Candidate generation con ANN (approximate nearest neighbors), (2) Ranking con modelo m\u00e1s complejo, (3) Re-ranking con reglas de negocio. Feature store para latencia. Sharding por user_id. Cache para usuarios frecuentes.  **5. A/B testing de modelos:** &gt; Traffic splitting a nivel de load balancer. M\u00e9tricas: latency, prediction distribution, business metrics (CTR, conversi\u00f3n). Duraci\u00f3n m\u00ednima para significance estad\u00edstica. Rollback autom\u00e1tico si degradaci\u00f3n &gt;X%.  **7. Optimizar costos AWS:** &gt; (1) Spot instances para training (70% ahorro), (2) Right-sizing de instancias, (3) S3 lifecycle policies, (4) Reserved capacity para serving baseline, (5) Auto-scaling agresivo en off-peak."},{"location":"docs/23_PROYECTO_INTEGRADOR/#parte-2-liderazgo-y-trade-offs-65-preguntas","title":"Parte 2: Liderazgo y Trade-offs (65 preguntas)","text":"<p>Liderazgo T\u00e9cnico (20 preguntas) 1. \u00bfC\u00f3mo priorizas deuda t\u00e9cnica vs nuevas features? 2. \u00bfC\u00f3mo convences a stakeholders de invertir en MLOps? 3. \u00bfC\u00f3mo mentorizas a juniors en ML?</p> <p>Trade-offs (20 preguntas) 4. \u00bfCu\u00e1ndo sacrificar\u00edas accuracy por latency? 5. \u00bfBuild vs buy para herramientas MLOps? 6. \u00bfMonolito vs microservicios para ML?</p> <p>Casos Pr\u00e1cticos (25 preguntas) 7. Tu modelo tiene bias racial. \u00bfQu\u00e9 haces? 8. El CEO quiere ML en todo. \u00bfC\u00f3mo priorizas? 9. Producci\u00f3n falla a las 3am. \u00bfTu proceso?</p> \ud83d\udca1 Ver Respuestas de Muestra  **2. Convencer stakeholders de MLOps:** &gt; Mostrar m\u00e9tricas de impacto: \"Sin CI/CD, bugs llegan a producci\u00f3n 3x m\u00e1s. Con testing, reducimos incidentes 60%.\" Hablar en t\u00e9rminos de negocio: tiempo de desarrollo, confiabilidad, velocidad de iteraci\u00f3n.  **5. Build vs buy:** &gt; Build si: core competency, requirements muy espec\u00edficos, control total necesario. Buy si: commodity, time-to-market cr\u00edtico, equipo peque\u00f1o. MLflow: open source gratuito. Datadog: costoso pero ahorra tiempo.  **7. Bias en modelo:** &gt; (1) No silenciar, escalar inmediatamente. (2) Cuantificar: \u00bfqu\u00e9 grupos afectados? (3) Rollback si impacto significativo. (4) Root cause: datos hist\u00f3ricos, features proxy. (5) Mitigaci\u00f3n: resampling, fairness constraints, auditor\u00eda continua.  <p>Ver simulacro completo Parte 1 \u2192 Ver simulacro completo Parte 2 \u2192</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#preparacion-de-entrevistas","title":"\ud83c\udfaf Preparaci\u00f3n de Entrevistas","text":""},{"location":"docs/23_PROYECTO_INTEGRADOR/#speech-de-portafolio-5-7-minutos","title":"Speech de Portafolio (5-7 minutos)","text":"<p>Estructura recomendada:</p> <pre><code>1. INTRO (30 seg)\n   \"He construido un portafolio de 3 proyectos ML production-ready...\"\n\n2. PROYECTO DESTACADO (2-3 min)\n   - Problema de negocio\n   - Decisiones t\u00e9cnicas clave\n   - M\u00e9tricas de impacto\n\n3. STACK T\u00c9CNICO (1-2 min)\n   - Por qu\u00e9 sklearn pipelines\n   - Por qu\u00e9 FastAPI + Docker\n   - Observabilidad con Prometheus\n\n4. DIFERENCIADORES (1 min)\n   - 80%+ coverage en todos los proyectos\n   - CI/CD completo\n   - Documentaci\u00f3n profesional\n\n5. CIERRE (30 seg)\n   \"Estoy buscando oportunidades donde pueda...\"\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#talking-points-clave","title":"Talking Points Clave","text":"Pregunta Com\u00fan Respuesta Concisa \"\u00bfPor qu\u00e9 sklearn?\" \"Pipelines serializables, reproducibilidad, integraci\u00f3n con MLflow\" \"\u00bfPor qu\u00e9 FastAPI?\" \"Async, validaci\u00f3n Pydantic, docs autom\u00e1ticas, rendimiento\" \"\u00bfC\u00f3mo garantizas calidad?\" \"80%+ coverage, pre-commit hooks, CI gates\" \"\u00bfTu mayor desaf\u00edo?\" \"Prevenir data leakage en pipelines complejos\""},{"location":"docs/23_PROYECTO_INTEGRADOR/#checklist-final-del-portafolio_1","title":"\u2705 Checklist Final del Portafolio","text":"<ul> <li>[ ] <code>pip install -e .</code> funciona en un entorno limpio</li> <li>[ ] <code>make test</code> pasa con coverage objetivo</li> <li>[ ] <code>make train</code> produce artefactos reproducibles</li> <li>[ ] API expone <code>/health</code> y <code>/predict</code></li> <li>[ ] CI est\u00e1 en verde con badges en README</li> <li>[ ] 3 proyectos con diferentes problemas ML</li> <li>[ ] Model Cards y documentaci\u00f3n completa</li> <li>[ ] Demo accesible (local o deployed)</li> </ul>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#defensa-del-portafolio-guia-completa-de-entrevista","title":"\ud83c\udfa4 Defensa del Portafolio \u2014 Gu\u00eda Completa de Entrevista","text":"<p>Objetivo: Prepararte para defender cada decisi\u00f3n arquitect\u00f3nica del portafolio en una entrevista t\u00e9cnica real.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#speech-de-elevador-5-7-minutos","title":"\ud83c\udf99\ufe0f Speech de Elevador (5-7 minutos)","text":"<p>Estructura Recomendada:</p> <pre><code>MINUTO 1: CONTEXTO + PROBLEMA\n\"Constru\u00ed un portafolio de 3 proyectos ML production-ready que demuestran\nel ciclo completo MLOps: desde entrenamiento hasta monitoreo en prod...\"\n\nMINUTO 2-3: LOS 3 PROYECTOS (30s cada uno)\n- BankChurn: Clasificaci\u00f3n binaria \u2192 FastAPI \u2192 Docker\n- CarVision: Regresi\u00f3n precios \u2192 Streamlit \u2192 Feature Engineering\n- TelecomAI: Multiclase \u2192 MLflow tracking \u2192 CI/CD completo\n\nMINUTO 4-5: DECISIONES T\u00c9CNICAS CLAVE\n\"Eleg\u00ed DVC sobre Git LFS porque...\" (1 min)\n\"Us\u00e9 sklearn Pipelines para evitar data leakage...\" (1 min)\n\nMINUTO 6: RESULTADOS CUANTIFICABLES\n\"97% coverage en CarVision, CI/CD con matrix testing 3.10-3.12...\"\n\nMINUTO 7: CIERRE + APRENDIZAJES\n\"El mayor desaf\u00edo fue... Lo resolver\u00eda diferente haciendo...\"\n</code></pre>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#preguntas-de-entrevista-por-categoria","title":"\u2753 Preguntas de Entrevista por Categor\u00eda","text":""},{"location":"docs/23_PROYECTO_INTEGRADOR/#arquitectura-general","title":"\ud83c\udfd7\ufe0f Arquitectura General","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 dividiste el portafolio en 3 proyectos separados?</p> <p>Cada proyecto aborda un tipo diferente de problema ML (clasificaci\u00f3n binaria, regresi\u00f3n, multiclase). Esto demuestra versatilidad y permite ciclos de vida independientes.</p> <p>\ud83d\udfe1 Mid: \u00bfC\u00f3mo manejas la configuraci\u00f3n entre desarrollo y producci\u00f3n?</p> <p>Uso Pydantic Settings que lee de variables de entorno con fallback a valores por defecto. Docker pasa <code>--env-file</code> o variables directas.</p> <p>\ud83d\udd34 Senior: Si tuvieras 100 modelos en producci\u00f3n, \u00bfc\u00f3mo organizar\u00edas el c\u00f3digo?</p> <p>Evolucionar\u00eda a monorepo con Model Server (Seldon/TF Serving), Model Registry centralizado (MLflow), Feature Store para features compartidos, y canary deployments por modelo.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#python-y-codigo","title":"\ud83d\udc0d Python y C\u00f3digo","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 usas type hints en todo el c\u00f3digo?</p> <p>Documentaci\u00f3n ejecutable, errores en tiempo de desarrollo con mypy, mejor autocompletado del IDE.</p> <p>\ud83d\udfe1 Mid: \u00bfPor qu\u00e9 creaste clases como <code>ChurnTrainer</code> en lugar de funciones sueltas?</p> <p>Estado encapsulado (el trainer mantiene el pipeline), extensibilidad (otros trainers heredan de BaseTrainer), testeabilidad (puedo mockear el trainer completo).</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#pipelines-ml","title":"\ud83d\udcca Pipelines ML","text":"<p>\ud83d\udfe2 Junior: \u00bfQu\u00e9 es data leakage y c\u00f3mo lo evitas?</p> <p>Informaci\u00f3n del test set contamina training. Lo evito con sklearn Pipeline que encapsula fit/transform.</p> <p>\ud83d\udfe1 Mid: \u00bfPor qu\u00e9 usas ColumnTransformer?</p> <p>Procesamiento diferenciado (num\u00e9ricas escalar, categ\u00f3ricas one-hot), serializaci\u00f3n unificada (un solo .pkl), sin riesgo de desalineaci\u00f3n.</p> <p>\ud83d\udd34 Senior: \u00bfC\u00f3mo implementar\u00edas Target Encoding sin leakage?</p> <p>K-Fold dentro del fit: calcular encoding SOLO con train de cada fold, usar smoothing para categor\u00edas raras.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#versionado-dvcmlflow","title":"\ud83d\udd04 Versionado (DVC/MLflow)","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 usas DVC en lugar de Git LFS?</p> <p>DVC: storage propio (S3, gratis), pipelines (<code>dvc.yaml</code>), experimentos (<code>dvc exp run</code>), cache. Git LFS: cobra por ancho de banda, sin pipelines.</p> <p>\ud83d\udfe1 Mid: \u00bfC\u00f3mo decides cu\u00e1ndo promover un modelo de Staging a Production?</p> <p>3 gates: (1) T\u00e9cnico: m\u00e9tricas &gt; baseline, tests pasan, signature match. (2) Drift: PSI &lt; 0.2. (3) Negocio: review de stakeholders.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#testing","title":"\ud83e\uddea Testing","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 tienes 80%+ de coverage como requirement?</p> <p>Balance pragm\u00e1tico: &lt;60% faltan tests cr\u00edticos, 80-90% est\u00e1ndar de industria, &gt;95% costo marginal alto. Lo importante: paths cr\u00edticos cubiertos.</p> <p>\ud83d\udfe1 Mid: \u00bfC\u00f3mo testeas el pipeline ML sin datos reales?</p> <p>Pir\u00e1mide de fixtures: <code>minimal_data</code> (4 filas) para unitarios, <code>realistic_data</code> (1000 filas) para integraci\u00f3n, <code>edge_case_data</code> (NaN, outliers) para l\u00edmites.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#docker-y-deployment","title":"\ud83d\udc33 Docker y Deployment","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 usas multi-stage builds?</p> <p>Separa construcci\u00f3n de ejecuci\u00f3n: builder tiene compiladores (~900MB), runtime solo lo necesario (~150MB). Resultado: de 2GB a 300MB.</p> <p>\ud83d\udfe1 Mid: \u00bfC\u00f3mo manejas el caching de dependencias?</p> <p>Orden de capas importa. Primero COPY requirements.txt, luego RUN pip install (se cachea si no cambi\u00f3), finalmente COPY c\u00f3digo.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#cicd","title":"\ud83d\udd12 CI/CD","text":"<p>\ud83d\udfe2 Junior: \u00bfPor qu\u00e9 usas matrix testing (Python 3.10, 3.11, 3.12)?</p> <p>Garantiza compatibilidad: usuarios pueden tener diferentes versiones, producci\u00f3n podr\u00eda estar en versi\u00f3n diferente. Costo m\u00ednimo: 3 jobs paralelos.</p> <p>\ud83d\udfe1 Mid: \u00bfC\u00f3mo evitas que secretos se filtren en el repositorio?</p> <p>Defensa en profundidad: pre-commit hook (gitleaks), CI scan, .gitignore robusto, GitHub Secret Scanning, documentaci\u00f3n de qu\u00e9 variables necesitan.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#preguntas-trampa-y-como-responder","title":"\u26a0\ufe0f Preguntas Trampa y C\u00f3mo Responder","text":"<p>Trampa 1: \"\u00bfPor qu\u00e9 no usaste PyTorch/TensorFlow?\"</p> <p>\"Para problemas tabulares, sklearn es la herramienta correcta: m\u00e1s r\u00e1pido de entrenar, interpretabilidad con feature_importances_, deployment m\u00e1s simple. Si fuera im\u00e1genes/NLP, usar\u00eda PyTorch.\"</p> <p>Trampa 2: \"Tu coverage es 97%. \u00bfNo es demasiado?\"</p> <p>\"97% puede ser excesivo SI testeas getters triviales. En mi caso cubre paths cr\u00edticos. El valor real no es el n\u00famero, sino tener confianza para refactors.\"</p> <p>Trampa 3: \"\u00bfPor qu\u00e9 no usaste Kubernetes desde el inicio?\"</p> <p>\"K8s resuelve problemas de escala que no tengo en desarrollo. Mi approach: desarrollo con docker-compose, producci\u00f3n con K8s cuando hay m\u00e1s de 3 servicios o necesito autoscaling.\"</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#rubrica-de-autoevaluacion","title":"\ud83d\udcca R\u00fabrica de Autoevaluaci\u00f3n","text":"Criterio 1 (Novato) 2 (Competente) 3 (Profesional) 4 (Experto) Claridad Divago Correcto pero largo Conciso y correcto Conciso + analog\u00edas memorables Profundidad Solo superficie Explico el \"qu\u00e9\" Explico el \"por qu\u00e9\" Trade-offs y alternativas Conexi\u00f3n al c\u00f3digo No menciono portafolio Menciono archivos Cito c\u00f3digo espec\u00edfico Puedo abrir y mostrar en vivo Manejo de presi\u00f3n Me bloqueo Respondo nervioso Tranquilo, pido clarificaci\u00f3n Gu\u00edo la conversaci\u00f3n <p>Meta para entrevista: Promedio \u2265 3 en todos los criterios.</p>"},{"location":"docs/23_PROYECTO_INTEGRADOR/#escenarios-de-system-design-staff-level","title":"\ud83c\udfaf Escenarios de System Design (Staff Level)","text":"<p>Escenario 1: Escala 10x</p> <p>\"Tu API recibe 100 rps. El cliente quiere 1000 rps.\"</p> <p>Respuesta estructurada: 1. Medir primero con locust 2. Optimizaciones por capa: API (m\u00e1s r\u00e9plicas + HPA), Modelo (batch predictions), Red (gRPC), Storage (Redis cache) 3. Arquitectura: Ingress \u2192 HPA pods \u2192 Redis cache 4. Trade-off: M\u00e1s r\u00e9plicas = m\u00e1s costo, cache = posible stale data</p> <p>Escenario 2: Multi-modelo</p> <p>\"Tienes 20 modelos en producci\u00f3n. \u00bfC\u00f3mo organizas el serving?\"</p> <p>Recomendaci\u00f3n: Model Server (Seldon) + Gateway para routing + MLflow Registry para governance.</p>   ## \ud83c\udf89 \u00a1Felicidades!  Has completado la **Gu\u00eda MLOps \u2014 Portfolio Edition**  Ahora tienes las habilidades de un **Senior/Staff MLOps Engineer**  ---  **[\u2190 IaC Empresarial](22_IAC_EMPRESARIAL.md)** | **[Volver al \u00cdndice \u2192](00_INDICE.md)**   <p>\u00a1\u00c9xito en tu proyecto! \ud83d\ude80</p>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/","title":"\ud83d\uddfa\ufe0f Mapa 1:1 \u2014 ML-MLOps-Portfolio \u2192 Gu\u00eda MLOps","text":"<p>Objetivo: mapear cada componente clave del repo <code>ML-MLOps-Portfolio</code> a los m\u00f3dulos, ejercicios y entregables de esta gu\u00eda.</p> <p>Uso recomendado: - Lee el portafolio y ubica el artefacto. - Ve al m\u00f3dulo indicado. - Ejecuta la tarea (ejercicio/lab/exam/portfolio task) y deja evidencia.</p>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#0-convencion-rapida","title":"0) Convenci\u00f3n r\u00e1pida","text":"<ul> <li>Gu\u00eda (m\u00f3dulos): <code>docs/NN_TITULO.md</code></li> <li>Evidencia: archivo/PR/commit, captura, logs, reporte, dashboard, o workflow run.</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#1-root-del-portafolio-tooling-docs","title":"1) Root del Portafolio (tooling + docs)","text":"Artefacto (Portfolio) Qu\u00e9 demuestra Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima (Gu\u00eda \u2192 Portafolio) Evidencia <code>README.md</code> Storytelling t\u00e9cnico + arquitectura <code>19_DOCUMENTACION</code>, <code>02_DISENO_SISTEMAS</code>, <code>22_CHECKLIST</code> Redactar README \u201crecruiter-ready\u201d (demo, m\u00e9tricas, arquitectura, quick start) README actualizado <code>QUICK_START.md</code> Onboarding 1 comando <code>04_ENTORNOS</code>, <code>13_DOCKER</code>, <code>17_DESPLIEGUE</code> Implementar \u201cone-command demo\u201d (Makefile + docker-compose) <code>make docker-demo</code> funciona <code>RUNBOOK.md</code> Operaci\u00f3n (SRE-style) <code>19_DOCUMENTACION</code>, <code>16_OBSERVABILIDAD</code>, <code>17_DESPLIEGUE</code> Crear runbook: start/stop, health-check, troubleshooting, rollback Runbook + comandos probados <code>CHECKLIST_RELEASE.md</code> Release readiness <code>22_CHECKLIST</code>, <code>12_CI_CD</code>, <code>19_DOCUMENTACION</code> Checklist de release (CI, seguridad, artefactos, versi\u00f3n, GHCR) Checklist rellenada <code>Makefile</code> (root) Automatizaci\u00f3n profesional <code>04_ENTORNOS</code>, <code>12_CI_CD</code> Unificar comandos (install/test/lint/docker-demo/health-check) Targets funcionando <code>.pre-commit-config.yaml</code> Calidad (format/lint/type/security) <code>05_GIT_PROFESIONAL</code>, <code>11_TESTING_ML</code>, <code>12_CI_CD</code> Instalar y usar pre-commit; arreglar issues <code>pre-commit run --all-files</code> <code>.gitleaks.toml</code> Seguridad (secrets) <code>12_CI_CD</code>, <code>19_DOCUMENTACION</code> Ejecutar gitleaks + pol\u00edtica de secretos Reporte/CI passing <code>docker-compose.demo.yml</code> Stack demo multi-servicio <code>13_DOCKER</code>, <code>10_EXPERIMENT_TRACKING</code>, <code>17_DESPLIEGUE</code> Levantar 3 APIs + MLflow + (opc) Prom/Grafana Servicios healthy <code>docker-compose.mlflow.yml</code> MLflow con Postgres+MinIO <code>10_EXPERIMENT_TRACKING</code>, <code>13_DOCKER</code> Separar tracking server (backend + artifact store) UI + artefactos"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#2-cicd-y-automatizacion-github-actions","title":"2) CI/CD y Automatizaci\u00f3n (GitHub Actions)","text":"Artefacto (Portfolio) Qu\u00e9 demuestra Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>.github/workflows/ci-mlops.yml</code> CI unificado (tests/quality/security/docker) <code>12_CI_CD</code>, <code>11_TESTING_ML</code>, <code>13_DOCKER</code> Replicar workflow por proyecto + matriz + artefactos Workflow verde <code>.github/workflows/docs.yml</code> Docs pipeline <code>19_DOCUMENTACION</code>, <code>12_CI_CD</code> Build/deploy docs (MkDocs) Deployment ok <code>.github/workflows/drift-detection.yml</code> Drift automation <code>16_OBSERVABILIDAD</code>, <code>12_CI_CD</code> Correr drift job + artifacts + issue/comment Artifact + summary <code>.github/workflows/drift-bankchurn.yml</code> Drift gate (manual) <code>16_OBSERVABILIDAD</code> Ejecutar drift check, exportar JSON/HTML Reportes generados <code>.github/workflows/retrain-bankchurn.yml</code> Retrain + registry <code>10_EXPERIMENT_TRACKING</code>, <code>12_CI_CD</code> Retrain manual + promoci\u00f3n condicional Modelo registrado"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#3-scripts-operacion-auditoria-demo","title":"3) Scripts (operaci\u00f3n, auditor\u00eda, demo)","text":"Script (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>scripts/demo.sh</code> Demo end-to-end local <code>13_DOCKER</code>, <code>17_DESPLIEGUE</code> Automatizar start + smoke requests Salida OK <code>scripts/setup_demo_models.sh</code> Bootstrap de modelos <code>09_TRAINING_PROFESIONAL</code>, <code>13_DOCKER</code> Generar artefactos reproducibles para demo/CI Modelos creados <code>scripts/run_demo_tests.sh</code> Smoke tests bash <code>11_TESTING_ML</code>, <code>12_CI_CD</code> Convertir smoke tests a pytest (o validar ambos) Tests pasan <code>scripts/run_audit.sh</code> Auditor\u00eda (lint/type/sec/tests) <code>12_CI_CD</code> Ejecutar auditor\u00eda y guardar reportes <code>reports/audit/*</code> <code>scripts/fetch_data.py</code> Data fetch + checksum <code>06_VERSIONADO_DATOS</code> Registry de datasets + validaci\u00f3n integridad <code>checksums.json</code> <code>scripts/promote_model.py</code> Model registry promotion <code>10_EXPERIMENT_TRACKING</code>, <code>16_OBSERVABILIDAD</code> Promover modelo por umbral (m\u00e9tricas) Registro/etapa <code>scripts/health_check.py</code> Verificaci\u00f3n local de modelos <code>11_TESTING_ML</code>, <code>04_ENTORNOS</code> Health check reproducible post-clone Script OK"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#4-observabilidad-prometheusgrafana-alertas","title":"4) Observabilidad (Prometheus/Grafana) + Alertas","text":"Artefacto (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>infra/prometheus-config.yaml</code> Scraping (K8s + servicios) <code>16_OBSERVABILIDAD</code>, <code>18_INFRAESTRUCTURA</code> A\u00f1adir targets/labels + validar m\u00e9tricas Prometheus targets <code>infra/prometheus-rules.yaml</code> Alerting rules <code>16_OBSERVABILIDAD</code> Definir alertas (latency, error rate, drift) Alert rules cargadas <code>k8s/*deployment.yaml</code> (annotations) <code>prometheus.io/scrape</code> <code>16_OBSERVABILIDAD</code>, <code>17_DESPLIEGUE</code> Exponer <code>/metrics</code> en FastAPI y scrapear M\u00e9tricas visibles"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#5-infraestructura-terraform-kubernetes","title":"5) Infraestructura (Terraform + Kubernetes)","text":"Artefacto (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>infra/terraform/README.md</code> IaC overview <code>18_INFRAESTRUCTURA</code> Documentar despliegue IaC (AWS/GCP) README claro <code>infra/terraform/aws/main.tf</code> EKS/VPC/S3/RDS/ECR <code>18_INFRAESTRUCTURA</code>, <code>17_DESPLIEGUE</code> Plan/apply en entorno sandbox + outputs <code>terraform plan</code> <code>k8s/namespace.yaml</code> Namespaces <code>17_DESPLIEGUE</code> Namespace dedicado + RBAC m\u00ednimo <code>kubectl get ns</code> <code>k8s/ingress.yaml</code> TLS/rate-limit <code>17_DESPLIEGUE</code>, <code>18_INFRAESTRUCTURA</code> Ingress con dominios, TLS y l\u00edmites Ingress funcionando <code>k8s/*-deployment.yaml</code> + HPA Rollout + autoscaling <code>17_DESPLIEGUE</code> Probes + requests/limits + HPA <code>kubectl describe hpa</code>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#6-testing-integracion-carga","title":"6) Testing (integraci\u00f3n + carga)","text":"Artefacto (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>tests/integration/test_demo.py</code> Cross-service tests <code>11_TESTING_ML</code>, <code>12_CI_CD</code> Pytest de health + predict (schemas) <code>pytest -q</code> <code>tests/load/locustfile.py</code> Load testing <code>02_DISENO_SISTEMAS</code>, <code>16_OBSERVABILIDAD</code> Prueba de carga + SLOs (p95, error rate) Reporte Locust"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#7-utilidades-comunes-reproducibilidad-logging","title":"7) Utilidades comunes (reproducibilidad + logging)","text":"Artefacto (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>common_utils/seed.py</code> Reproducibilidad <code>01_PYTHON_MODERNO</code>, <code>04_ENTORNOS</code> Seed centralizado (Py/NumPy/TF/PT) Tests deterministas <code>common_utils/logger.py</code> Logging consistente <code>16_OBSERVABILIDAD</code> Logging estructurado + correlaci\u00f3n request-id Logs uniformes"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#8-proyectos-top-3-bankchurn-carvision-telecomai","title":"8) Proyectos Top-3 (BankChurn / CarVision / TelecomAI)","text":"<p>Regla general (aplica a los 3): - <code>src/&lt;pkg&gt;/</code> \u2192 <code>03_ESTRUCTURA_PROYECTO</code>, <code>07_SKLEARN_PIPELINES</code>, <code>08_INGENIERIA_FEATURES</code>, <code>09_TRAINING_PROFESIONAL</code> - <code>app/fastapi_app.py</code> \u2192 <code>14_FASTAPI</code> - <code>Dockerfile</code>/<code>docker-compose.yml</code> \u2192 <code>13_DOCKER</code>, <code>17_DESPLIEGUE</code> - <code>tests/</code> \u2192 <code>11_TESTING_ML</code> - <code>model_card.md</code> + <code>data_card.md</code> \u2192 <code>19_DOCUMENTACION</code></p> <p>CarVision adicional: - <code>app/streamlit_app.py</code> \u2192 <code>15_STREAMLIT</code></p>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#9-brechas-detectadas-para-expandir-modulos-sin-borrar-contenido","title":"9) Brechas detectadas (para expandir m\u00f3dulos sin borrar contenido)","text":"<ul> <li>MLflow Model Registry + promoci\u00f3n real (<code>scripts/promote_model.py</code>, workflows de retrain): reforzar en <code>10_EXPERIMENT_TRACKING</code>.</li> <li>Alerting serio + runbooks por alerta (<code>infra/prometheus-rules.yaml</code>): reforzar en <code>16_OBSERVABILIDAD</code>.</li> <li>K8s Ingress (TLS, rate limiting, cert-manager) (<code>k8s/ingress.yaml</code>): reforzar en <code>17_DESPLIEGUE</code>.</li> <li>Terraform backend remoto + locking (S3+Dynamo / GCS): reforzar en <code>18_INFRAESTRUCTURA</code>.</li> <li>Load testing con Locust + SLOs (<code>tests/load/*</code>): crear pr\u00e1ctica dedicada.</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#10-documentacion-del-portafolio-docs","title":"10) Documentaci\u00f3n del Portafolio (docs/)","text":"Artefacto (Portfolio) Rol Gu\u00eda (m\u00f3dulos) Tarea m\u00ednima Evidencia <code>docs/ARCHITECTURE_PORTFOLIO.md</code> Arquitectura sistema <code>02_DISENO_SISTEMAS</code>, <code>19_DOCUMENTACION</code> Crear diagrama Mermaid + explicar flujo request Diagrama + doc <code>docs/OPERATIONS_PORTFOLIO.md</code> Gu\u00edas operacionales <code>16_OBSERVABILIDAD</code>, <code>17_DESPLIEGUE</code> Documentar setup, workflows, troubleshooting Runbook operativo <code>docs/RELEASE.md</code> Release process <code>12_CI_CD</code>, <code>19_DOCUMENTACION</code> Proceso de release + checklist Proceso documentado <code>docs/API/</code> API reference (OpenAPI) <code>14_FASTAPI</code>, <code>19_DOCUMENTACION</code> Documentar endpoints, schemas, ejemplos OpenAPI spec <code>mkdocs.yml</code> (portfolio) Docs site config <code>19_DOCUMENTACION</code> Configurar MkDocs Material + nav <code>mkdocs serve</code> funciona"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#11-definition-of-done-portafolio-100-replicado","title":"11) Definition of Done: \"Portafolio 100% Replicado\"","text":""},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#nivel-1-minimo-viable-junior","title":"Nivel 1: M\u00ednimo Viable (Junior)","text":"<ul> <li>[ ] Estructura de proyecto siguiendo el template</li> <li>[ ] Al menos 1 proyecto con API funcionando</li> <li>[ ] Tests unitarios con &gt;70% coverage</li> <li>[ ] Dockerfile funcional</li> <li>[ ] README con Quick Start</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#nivel-2-competente-mid","title":"Nivel 2: Competente (Mid)","text":"<ul> <li>[ ] Los 3 proyectos con APIs funcionando</li> <li>[ ] <code>make docker-demo</code> levanta stack completo</li> <li>[ ] CI/CD b\u00e1sico (tests + lint)</li> <li>[ ] MLflow tracking configurado</li> <li>[ ] Tests de integraci\u00f3n pasando</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#nivel-3-profesional-senior","title":"Nivel 3: Profesional (Senior)","text":"<ul> <li>[ ] CI/CD con matriz, coverage gates, security</li> <li>[ ] <code>/metrics</code> expone m\u00e9tricas, Prometheus scrapea</li> <li>[ ] Drift detection configurado</li> <li>[ ] Documentaci\u00f3n completa (MkDocs + Model Cards)</li> <li>[ ] Runbook con troubleshooting</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#nivel-4-experto-staff","title":"Nivel 4: Experto (Staff)","text":"<ul> <li>[ ] IaC con Terraform (al menos plan funcional)</li> <li>[ ] Kubernetes manifests production-ready</li> <li>[ ] Alerting rules configuradas</li> <li>[ ] Load testing con SLOs definidos</li> <li>[ ] Proceso de release documentado</li> </ul>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#12-comandos-de-verificacion","title":"12) Comandos de Verificaci\u00f3n","text":"<pre><code># Verificar stack demo\nmake docker-demo\ncurl http://localhost:8001/health\ncurl http://localhost:8002/health\ncurl http://localhost:8003/health\n\n# Verificar tests\npytest tests/ -v --cov\n\n# Verificar CI local\npre-commit run --all-files\n\n# Verificar MLflow\ncurl http://localhost:5000/health\n\n# Verificar m\u00e9tricas\ncurl http://localhost:8001/metrics\n\n# Verificar drift\npython scripts/drift_detection.py --output reports/\n\n# Verificar docs\ncd docs &amp;&amp; mkdocs serve\n</code></pre>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#13-recursos-de-referencia-cruzada","title":"13) Recursos de Referencia Cruzada","text":"Necesitas... Ve a... Entender la arquitectura 02_DISENO_SISTEMAS Configurar entorno 04_ENTORNOS Crear pipelines ML 07_SKLEARN_PIPELINES Configurar MLflow 10_EXPERIMENT_TRACKING Escribir tests 11_TESTING_ML Configurar CI/CD 12_CI_CD Dockerizar 13_DOCKER Crear API 14_FASTAPI Monitorear 16_OBSERVABILIDAD Desplegar 17_DESPLIEGUE Documentar 19_DOCUMENTACION"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#14-recursos-pedagogicos-integrados-en-modulos","title":"14) Recursos Pedag\u00f3gicos (Integrados en M\u00f3dulos)","text":"Recurso Qu\u00e9 ofrece Ubicaci\u00f3n Quizzes 3 preguntas + 1 ejercicio por m\u00f3dulo Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" al final de cada m\u00f3dulo La Trampa 50+ errores t\u00edpicos con soluciones Secci\u00f3n \"\ud83e\udea4 La Trampa\" al final de cada m\u00f3dulo Defensa del Portafolio Preguntas de entrevista t\u00e9cnica M\u00f3dulo 23 - Secci\u00f3n Defensa"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#flujo-de-aprendizaje-por-semana","title":"Flujo de Aprendizaje por Semana","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  1. Leer m\u00f3dulo (teor\u00eda)                                                \u2502\n\u2502  2. Replicar c\u00f3digo en el portafolio (pr\u00e1ctica)                         \u2502\n\u2502  3. Revisar secci\u00f3n \"\ud83e\udea4 La Trampa\" del m\u00f3dulo (debugging)                \u2502\n\u2502  4. Completar secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" (evaluaci\u00f3n)                \u2502\n\u2502  5. Preparar entrevista con M\u00f3dulo 23 - Defensa del Portafolio          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/MAPA_PORTAFOLIO_1TO1/#navegacion","title":"\ud83d\udd17 Navegaci\u00f3n","text":"<ul> <li>\u2190 Volver al \u00cdndice</li> <li>\u2192 Plan de Estudios</li> <li>\u2192 Syllabus</li> <li>\u2192 Defensa del Portafolio (M\u00f3dulo 23)</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/","title":"\ud83d\udcc5 Plan de Estudios \u2014 Ruta Acelerada (8 Semanas)","text":"<p>Roadmap detallado para completar el portafolio MLOps</p> <p>\ud83d\udccc Ruta principal (recomendada): 24 semanas (6 meses) \u2014 ver <code>README.md</code> del repo y el \u00cdndice Principal.</p> <p>\ud83d\uddfa\ufe0f Mapa 1:1 Portafolio \u2192 Gu\u00eda: MAPA_PORTAFOLIO_1TO1.md</p>"},{"location":"docs/PLAN_ESTUDIOS/#vista-general","title":"\ud83d\udcca Vista General","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PLAN DE 8 SEMANAS                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                      \u2502\n\u2502  Semana 1-2:  FUNDAMENTOS                                            \u2502\n\u2502               Python moderno, estructura, Git, entornos              \u2502\n\u2502                                                                      \u2502\n\u2502  Semana 3-4:  ML ENGINEERING                                         \u2502\n\u2502               Pipelines sklearn, feature engineering, MLflow         \u2502\n\u2502                                                                      \u2502\n\u2502  Semana 5-6:  MLOps CORE                                             \u2502\n\u2502               Testing, CI/CD, Docker, APIs                           \u2502\n\u2502                                                                      \u2502\n\u2502  Semana 7:    PRODUCCI\u00d3N                                             \u2502\n\u2502               Deploy, observabilidad, infraestructura                \u2502\n\u2502                                                                      \u2502\n\u2502  Semana 8:    PROYECTO FINAL                                         \u2502\n\u2502               Documentaci\u00f3n, demo, preparaci\u00f3n entrevistas           \u2502\n\u2502                                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Consejo did\u00e1ctico: En cada m\u00f3dulo, antes de marcar el checkpoint como completado, revisa tambi\u00e9n la secci\u00f3n de \"Errores habituales y c\u00f3mo depurarlos\" para consolidar patrones de debugging.</p> <p>Ruta 0 \u2192 Senior/Staff: Usa la secci\u00f3n \"Ruta 0 \u2192 Senior/Staff (macro-m\u00f3dulos)\" del SYLLABUS como mapa de alto nivel, y este plan de 8 semanas como cronograma concreto.</p> <p>Sistema recomendado: aplica Protocolo E, registra bloqueos en el Diario de Errores y cierra cada semana con Cierre Semanal.</p> <p>Material de Apoyo: Glosario | Recursos</p>"},{"location":"docs/PLAN_ESTUDIOS/#semana-1-python-moderno-estructura","title":"\ud83d\udcda Semana 1: Python Moderno + Estructura","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos","title":"Objetivos","text":"<ul> <li>[ ] Dominar type hints y Pydantic</li> <li>[ ] Crear estructura src/ layout</li> <li>[ ] Configurar pyproject.toml</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1 Leer 01_PYTHON_MODERNO 2h Notas 2 Ejercicios type hints 3h C\u00f3digo tipado 3 Leer 02_DISENO_SISTEMAS 2h ML Canvas 4 Leer 03_ESTRUCTURA_PROYECTO 2h Estructura base 5 Crear proyecto BankChurn base 3h Repo inicial"},{"location":"docs/PLAN_ESTUDIOS/#recursos","title":"Recursos","text":"<ul> <li>Pydantic Docs</li> <li>Python Type Hints Cheat Sheet</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#semana-2-git-entornos-dvc","title":"\ud83d\udcda Semana 2: Git + Entornos + DVC","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_1","title":"Objetivos","text":"<ul> <li>[ ] Configurar pre-commit hooks</li> <li>[ ] Dominar Conventional Commits</li> <li>[ ] Inicializar DVC</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_1","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1 Leer 04_ENTORNOS 2h requirements.txt 2 Leer 05_GIT_PROFESIONAL 2h pre-commit.yaml 3 Configurar pre-commit en proyecto 2h Hooks funcionando 4 Leer 06_VERSIONADO_DATOS 2h DVC init 5 Versionar datos de BankChurn 3h .dvc files"},{"location":"docs/PLAN_ESTUDIOS/#semana-3-pipelines-sklearn","title":"\ud83d\udcda Semana 3: Pipelines sklearn","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_2","title":"Objetivos","text":"<ul> <li>[ ] Crear Pipeline unificado</li> <li>[ ] Implementar ColumnTransformer</li> <li>[ ] Crear Custom Transformer</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_2","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1-2 Leer 07_SKLEARN_PIPELINES 4h Pipeline b\u00e1sico 3 Implementar ColumnTransformer 3h Preprocessing 4-5 Leer 08_INGENIERIA_FEATURES 4h FeatureEngineer class"},{"location":"docs/PLAN_ESTUDIOS/#proyecto","title":"Proyecto","text":"<p>Crear <code>src/bankchurn/training.py</code> con pipeline completo.</p>"},{"location":"docs/PLAN_ESTUDIOS/#semana-4-training-mlflow","title":"\ud83d\udcda Semana 4: Training + MLflow","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_3","title":"Objetivos","text":"<ul> <li>[ ] Crear clase Trainer profesional</li> <li>[ ] Implementar cross-validation</li> <li>[ ] Integrar MLflow tracking</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_3","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1-2 Leer 09_TRAINING_PROFESIONAL 4h ChurnTrainer class 3-5 Leer 10_EXPERIMENT_TRACKING 6h MLflow integrado"},{"location":"docs/PLAN_ESTUDIOS/#proyecto_1","title":"Proyecto","text":"<p>Entrenar modelo con m\u00e9tricas en MLflow UI.</p>"},{"location":"docs/PLAN_ESTUDIOS/#semana-5-testing","title":"\ud83d\udcda Semana 5: Testing","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_4","title":"Objetivos","text":"<ul> <li>[ ] Escribir tests unitarios</li> <li>[ ] Alcanzar 80% coverage</li> <li>[ ] Crear fixtures reutilizables</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_4","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1-2 Leer 11_TESTING_ML 4h conftest.py 3-5 Escribir tests para BankChurn 6h 80% coverage"},{"location":"docs/PLAN_ESTUDIOS/#semana-6-cicd-docker-apis","title":"\ud83d\udcda Semana 6: CI/CD + Docker + APIs","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_5","title":"Objetivos","text":"<ul> <li>[ ] Crear GitHub Actions workflow</li> <li>[ ] Dockerfile multi-stage</li> <li>[ ] API FastAPI funcional</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_5","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1 Leer 12_CI_CD 2h ci.yml 2 Leer 13_DOCKER 2h Dockerfile 3-4 Leer 14_FASTAPI 4h /predict endpoint 5 Leer 15_STREAMLIT 2h Dashboard b\u00e1sico"},{"location":"docs/PLAN_ESTUDIOS/#semana-7-produccion","title":"\ud83d\udcda Semana 7: Producci\u00f3n","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_6","title":"Objetivos","text":"<ul> <li>[ ] Implementar logging estructurado</li> <li>[ ] Entender estrategias de deploy</li> <li>[ ] Conocer Terraform/K8s b\u00e1sico</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_6","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1-2 Leer 16_OBSERVABILIDAD 4h Logging JSON 3-4 Leer 17_DESPLIEGUE 4h Estrategia elegida 5 Leer 18_INFRAESTRUCTURA 2h Conceptos IaC"},{"location":"docs/PLAN_ESTUDIOS/#semana-8-proyecto-final","title":"\ud83d\udcda Semana 8: Proyecto Final","text":""},{"location":"docs/PLAN_ESTUDIOS/#objetivos_7","title":"Objetivos","text":"<ul> <li>[ ] Completar documentaci\u00f3n</li> <li>[ ] Pasar r\u00fabrica de evaluaci\u00f3n</li> <li>[ ] Preparar para entrevistas</li> </ul>"},{"location":"docs/PLAN_ESTUDIOS/#actividades-diarias_7","title":"Actividades Diarias","text":"D\u00eda Actividad Tiempo Entregable 1 Leer 19_DOCUMENTACION 2h Model Card 2-3 23_PROYECTO_INTEGRADOR 6h Self-assessment 4 Revisar Glosario 2h T\u00e9rminos dominados 5 Simulacro Senior 3h Preparaci\u00f3n lista"},{"location":"docs/PLAN_ESTUDIOS/#tiempo-total-estimado","title":"\u23f1\ufe0f Tiempo Total Estimado","text":"Componente Horas Lectura de m\u00f3dulos 40h Ejercicios pr\u00e1cticos 30h Proyecto BankChurn 20h Proyectos adicionales 20h TOTAL 110h <p>Dedicaci\u00f3n sugerida: 15-20 horas/semana</p>"},{"location":"docs/PLAN_ESTUDIOS/#checklist-de-finalizacion","title":"\u2705 Checklist de Finalizaci\u00f3n","text":"<ul> <li>[ ] 3 proyectos funcionando (BankChurn, CarVision, TelecomAI)</li> <li>[ ] CI/CD pasando en los 3</li> <li>[ ] Coverage \u226580% en todos</li> <li>[ ] APIs dockerizadas</li> <li>[ ] READMEs profesionales</li> <li>[ ] Model Cards completos</li> </ul>   [\u2190 Volver al \u00cdndice](00_INDICE.md)"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/","title":"\ud83c\udfaf Simulacro de Entrevista Junior ML Engineer","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#portafolio-mlops-50-preguntas-fundamentales","title":"Portafolio MLOps \u2014 50 Preguntas Fundamentales","text":"<p>Autor del Portafolio: Daniel Duque (DuqueOM) Versi\u00f3n: 1.0 Fecha: Diciembre 2025 Nivel: Junior (0-2 a\u00f1os de experiencia)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ol> <li>Python B\u00e1sico</li> <li>Machine Learning Fundamentos</li> <li>Datos y Preprocesamiento</li> <li>Git y Herramientas</li> <li>Pr\u00e1ctica con el Portafolio</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#antes-de-empezar","title":"\ud83c\udfaf Antes de Empezar","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#que-se-espera-de-un-junior","title":"\u00bfQu\u00e9 se espera de un Junior?","text":"Lo que S\u00cd se espera Lo que NO se espera Fundamentos s\u00f3lidos de Python Dise\u00f1o de arquitecturas complejas Entender train/test split Optimizaci\u00f3n de hiperpar\u00e1metros avanzada Saber qu\u00e9 es overfitting Implementar MLOps completo Usar Git b\u00e1sico CI/CD avanzado Leer y modificar c\u00f3digo existente Escribir c\u00f3digo de producci\u00f3n desde cero Hacer preguntas inteligentes Tener todas las respuestas"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#consejos-para-la-entrevista","title":"Consejos para la Entrevista","text":"<ol> <li>S\u00e9 honesto: \"No lo s\u00e9, pero lo investigar\u00eda as\u00ed...\" es mejor que inventar</li> <li>Muestra curiosidad: Haz preguntas sobre el c\u00f3digo que ves</li> <li>Relaciona con el portafolio: \"En BankChurn aprend\u00ed que...\"</li> <li>Piensa en voz alta: El proceso importa m\u00e1s que la respuesta perfecta</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#1-python-b\u00e1sico-preguntas-1-10","title":"1. Python B\u00e1sico (Preguntas 1-10)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-1-tipos-de-datos","title":"Pregunta 1: Tipos de Datos","text":"<p>\u00bfCu\u00e1l es la diferencia entre lista, tupla y diccionario?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta","title":"Respuesta:","text":"<pre><code># Lista: mutable, ordenada\nfeatures = [\"age\", \"salary\", \"tenure\"]  # Crea lista con 3 strings.\nfeatures.append(\"score\")                 # append(): a\u00f1ade elemento al final. Listas son mutables.\n\n# Tupla: inmutable, ordenada\ncoordinates = (40.7, -74.0)              # Tupla de coordenadas. Par\u00e9ntesis indican tupla.\n# coordinates[0] = 41.0  # ERROR         # TypeError: las tuplas NO se pueden modificar.\n\n# Diccionario: mutable, key-value\ncustomer = {\"id\": 123, \"name\": \"John\", \"churn\": False}  # Dict: pares clave:valor.\ncustomer[\"score\"] = 0.85                 # A\u00f1ade nueva clave. Dicts son mutables.\n</code></pre> <p>Cu\u00e1ndo usar cada uno: - Lista: Colecci\u00f3n que cambiar\u00e1 (features a seleccionar) - Tupla: Datos que no deben cambiar (coordenadas, constantes) - Diccionario: Acceso por clave (configuraci\u00f3n, datos de cliente)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-2-list-comprehension","title":"Pregunta 2: List Comprehension","text":"<p>Reescribe este c\u00f3digo con list comprehension: <pre><code>result = []                              # Lista vac\u00eda para acumular resultados.\nfor x in range(10):                      # range(10): genera 0,1,2,...,9.\n    if x % 2 == 0:                       # %: m\u00f3dulo. x%2==0 significa \"x es par\".\n        result.append(x**2)              # **: exponente. A\u00f1ade el cuadrado de x.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_1","title":"Respuesta:","text":"<pre><code>result = [x**2 for x in range(10) if x % 2 == 0]  # List comprehension: [expresi\u00f3n for item in iterable if condici\u00f3n]\n# [0, 4, 16, 36, 64]                              # Resultado: cuadrados de n\u00fameros pares del 0 al 9.\n</code></pre> <p>Ventajas: - M\u00e1s conciso - M\u00e1s r\u00e1pido (optimizado internamente) - M\u00e1s \"pyth\u00f3nico\"</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-3-funciones-y-argumentos","title":"Pregunta 3: Funciones y Argumentos","text":"<p>\u00bfQu\u00e9 hace <code>*args</code> y <code>**kwargs</code>?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_2","title":"Respuesta:","text":"<pre><code>def log_experiment(*args, **kwargs):    # *args: captura argumentos posicionales como tupla.\n    # args: tupla de argumentos posicionales   # **kwargs: captura argumentos con nombre como dict.\n    # kwargs: diccionario de argumentos con nombre\n    print(f\"Metrics: {args}\")            # f-string: permite insertar variables con {}.\n    print(f\"Config: {kwargs}\")           # Imprime el diccionario de kwargs.\n\nlog_experiment(0.85, 0.82, model=\"rf\", n_estimators=100)  # 2 posicionales + 2 con nombre.\n# Metrics: (0.85, 0.82)                  # args captura los valores sin nombre.\n# Config: {'model': 'rf', 'n_estimators': 100}  # kwargs captura los pares key=value.\n</code></pre> <p>En el portafolio (<code>BankChurn/trainer.py</code>): <pre><code>def __init__(self, config: BankChurnConfig, **kwargs):\n    self.config = config\n    self.extra_params = kwargs  # Flexibilidad para params adicionales\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-4-manejo-de-errores","title":"Pregunta 4: Manejo de Errores","text":"<p>\u00bfPor qu\u00e9 usamos try/except?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_3","title":"Respuesta:","text":"<pre><code>def load_data(path: str) -&gt; pd.DataFrame:  # Type hints: espera str, retorna DataFrame.\n    try:                                    # try: intenta ejecutar c\u00f3digo que puede fallar.\n        df = pd.read_csv(path)              # Operaci\u00f3n que puede lanzar excepciones.\n        return df\n    except FileNotFoundError:               # Captura error espec\u00edfico: archivo no existe.\n        print(f\"Error: {path} no existe\")\n        raise                               # raise: re-lanza la excepci\u00f3n para que el caller la maneje.\n    except pd.errors.EmptyDataError:        # Captura otro error espec\u00edfico.\n        print(\"Error: archivo vac\u00edo\")\n        raise                               # Siempre re-lanzar si no puedes recuperarte.\n</code></pre> <p>Buenas pr\u00e1cticas: - Capturar excepciones espec\u00edficas, no gen\u00e9ricas - Hacer logging del error - Re-lanzar si no puedes manejarlo</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-5-import-y-modulos","title":"Pregunta 5: Import y M\u00f3dulos","text":"<p>\u00bfCu\u00e1l es la diferencia entre estas formas de import?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_4","title":"Respuesta:","text":"<pre><code># Importar m\u00f3dulo completo\nimport pandas as pd                      # Importa todo el m\u00f3dulo con alias \"pd\".\ndf = pd.read_csv(\"data.csv\")             # Acceso via pd.funci\u00f3n().\n\n# Importar funci\u00f3n espec\u00edfica\nfrom sklearn.model_selection import train_test_split  # Solo importa esta funci\u00f3n.\nX_train, X_test = train_test_split(X)    # Uso directo sin prefijo.\n\n# Importar todo (\u26a0\ufe0f evitar en producci\u00f3n)\nfrom math import *                       # * importa TODO: contamina namespace, dif\u00edcil saber origen.\n</code></pre> <p>Best practice: Importar lo que necesitas, usar alias est\u00e1ndar (<code>pd</code>, <code>np</code>, <code>plt</code>).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-6-type-hints","title":"Pregunta 6: Type Hints","text":"<p>\u00bfQu\u00e9 significan los type hints y por qu\u00e9 usarlos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_5","title":"Respuesta:","text":"<pre><code>def predict_churn(\n    credit_score: int,                    # : int indica que espera un entero.\n    age: int,\n    is_active: bool                       # : bool indica booleano (True/False).\n) -&gt; float:                               # -&gt; float indica que RETORNA un decimal.\n    \"\"\"Retorna probabilidad de churn.\"\"\"\n    ...                                   # ... es placeholder (Ellipsis), indica \"implementar\".\n</code></pre> <p>Beneficios: 1. Documentaci\u00f3n: Claro qu\u00e9 espera y retorna 2. IDE support: Autocompletado, detecci\u00f3n de errores 3. Tooling: <code>mypy</code> puede verificar tipos</p> <p>En el portafolio: Todos los archivos usan type hints (<code>config.py</code>, <code>training.py</code>).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-7-clases-basicas","title":"Pregunta 7: Clases B\u00e1sicas","text":"<p>\u00bfQu\u00e9 es <code>__init__</code> y <code>self</code>?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_6","title":"Respuesta:","text":"<pre><code>class BankChurnTrainer:                   # class: define un nuevo tipo de objeto.\n    def __init__(self, config):           # __init__: constructor, se ejecuta al crear instancia.\n        # Constructor: se ejecuta al crear instancia\n        self.config = config              # self: referencia a ESTA instancia. Guarda config.\n        self.model_ = None                # Atributo inicializado en None (convenci\u00f3n: _ para fitted).\n\n    def train(self, X, y):                # M\u00e9todo: funci\u00f3n que pertenece a la clase.\n        # self permite acceder a atributos de la instancia\n        if self.config.model_type == \"rf\":  # Accede a config guardada en __init__.\n            self.model_ = RandomForestClassifier()\n        self.model_.fit(X, y)             # Entrena y guarda modelo en self.\n\n# Uso\ntrainer = BankChurnTrainer(config)        # Crea instancia: __init__ se ejecuta autom\u00e1ticamente.\ntrainer.train(X, y)                       # Llama m\u00e9todo train en esta instancia.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-8-lectura-de-archivos","title":"Pregunta 8: Lectura de Archivos","text":"<p>\u00bfC\u00f3mo lees un archivo CSV con pandas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_7","title":"Respuesta:","text":"<pre><code>import pandas as pd\n\n# B\u00e1sico\ndf = pd.read_csv(\"data/raw/Churn.csv\")    # Lee CSV y crea DataFrame.\n\n# Con opciones\ndf = pd.read_csv(\n    \"data/raw/Churn.csv\",\n    sep=\",\",                              # Separador de columnas (coma por defecto).\n    encoding=\"utf-8\",                     # Codificaci\u00f3n del archivo.\n    na_values=[\"\", \"NA\", \"null\"],         # Valores que pandas tratar\u00e1 como NaN.\n    dtype={\"customer_id\": str}            # Fuerza tipo de columna espec\u00edfica.\n)\n\n# Verificar\nprint(df.shape)                           # (filas, columnas): (10000, 14).\nprint(df.info())                          # Muestra tipos de datos y valores nulos por columna.\nprint(df.head())                          # Primeras 5 filas del DataFrame.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-9-entornos-virtuales","title":"Pregunta 9: Entornos Virtuales","text":"<p>\u00bfPor qu\u00e9 usamos entornos virtuales?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_8","title":"Respuesta:","text":"<pre><code># Crear entorno\npython -m venv .venv          # -m venv: ejecuta m\u00f3dulo venv. .venv: nombre de la carpeta.\n\n# Activar\nsource .venv/bin/activate     # Linux/Mac: source ejecuta el script de activaci\u00f3n.\n.venv\\Scripts\\activate        # Windows: script diferente por el sistema.\n\n# Instalar dependencias\npip install -r requirements.txt  # -r: lee archivo y instala todas las dependencias listadas.\n</code></pre> <p>Razones: 1. Aislamiento: Cada proyecto tiene sus propias versiones 2. Reproducibilidad: Mismo entorno en cualquier m\u00e1quina 3. Evita conflictos: sklearn 1.3 en proyecto A, sklearn 1.2 en proyecto B</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-10-debugging-basico","title":"Pregunta 10: Debugging B\u00e1sico","text":"<p>\u00bfC\u00f3mo depuras c\u00f3digo en Python?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_9","title":"Respuesta:","text":"<pre><code># 1. Print statements (b\u00e1sico pero \u00fatil)\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")  # f-string para inspeccionar variables.\n\n# 2. Usar assert\nassert X.shape[0] == y.shape[0], \"Mismatch en filas\"  # assert: falla si condici\u00f3n es False.\n\n# 3. Breakpoints en IDE (recomendado)\n# Poner breakpoint y usar F5 para debugear   # Pausa ejecuci\u00f3n y permite inspeccionar.\n\n# 4. pdb (en terminal)\nimport pdb; pdb.set_trace()                   # pdb: debugger interactivo de Python.\n\n# 5. Logging (producci\u00f3n)\nimport logging\nlogging.debug(f\"Loaded {len(df)} rows\")       # Mejor que print: niveles, archivos, formato.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#2-machine-learning-fundamentos-preguntas-11-20","title":"2. Machine Learning Fundamentos (Preguntas 11-20)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-11-traintest-split","title":"Pregunta 11: Train/Test Split","text":"<p>\u00bfPor qu\u00e9 separamos datos en train y test?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_10","title":"Respuesta:","text":"<pre><code>from sklearn.model_selection import train_test_split  # Funci\u00f3n para dividir datos.\n\nX_train, X_test, y_train, y_test = train_test_split(  # Retorna 4 arrays.\n    X, y, \n    test_size=0.2,      # 80/20 split: 20% para test.\n    random_state=42,    # Semilla: mismos datos cada ejecuci\u00f3n.\n    stratify=y          # Mantiene proporci\u00f3n de clases en ambos sets.\n)\n</code></pre> <p>Raz\u00f3n: Evaluar c\u00f3mo el modelo generaliza a datos nunca vistos. - Train: Aprende patrones - Test: Simula producci\u00f3n, mide rendimiento real</p> <p>Error com\u00fan: Usar test para ajustar modelo \u2192 overfitting al test.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-12-overfitting-vs-underfitting","title":"Pregunta 12: Overfitting vs Underfitting","text":"<p>Explica overfitting y underfitting.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_11","title":"Respuesta:","text":"Concepto S\u00edntomas Causa Soluci\u00f3n Overfitting Train acc: 99%, Test acc: 70% Modelo muy complejo Regularizaci\u00f3n, m\u00e1s datos, simplificar Underfitting Train acc: 60%, Test acc: 58% Modelo muy simple M\u00e1s features, modelo m\u00e1s complejo <pre><code># Detectar en el portafolio\nprint(f\"Train accuracy: {model.score(X_train, y_train):.2%}\")  # .score(): accuracy del modelo.\nprint(f\"Test accuracy: {model.score(X_test, y_test):.2%}\")    # :.2%: formatea como porcentaje.\n\n# Si diferencia &gt; 10%, posible overfitting  # Train &gt;&gt; Test = modelo memoriza, no generaliza.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-13-clasificacion-vs-regresion","title":"Pregunta 13: Clasificaci\u00f3n vs Regresi\u00f3n","text":"<p>\u00bfCu\u00e1ndo usar clasificaci\u00f3n y cu\u00e1ndo regresi\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_12","title":"Respuesta:","text":"Problema Tipo Target M\u00e9trica \u00bfCliente har\u00e1 churn? Clasificaci\u00f3n S\u00ed/No (0/1) Accuracy, F1, AUC \u00bfCu\u00e1nto cuesta el auto? Regresi\u00f3n Precio ($) RMSE, MAE, R\u00b2 \u00bfQu\u00e9 plan elegir\u00e1? Clasificaci\u00f3n multiclase A/B/C Accuracy, F1 macro <p>En el portafolio: - BankChurn: Clasificaci\u00f3n binaria (churn: 0/1) - CarVision: Regresi\u00f3n (precio continuo) - TelecomAI: Clasificaci\u00f3n multiclase (tipo de plan)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-14-cross-validation","title":"Pregunta 14: Cross-Validation","text":"<p>\u00bfQu\u00e9 es cross-validation y por qu\u00e9 usarla?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_13","title":"Respuesta:","text":"<pre><code>from sklearn.model_selection import cross_val_score  # CV autom\u00e1tico con scoring.\n\nscores = cross_val_score(model, X, y, cv=5)          # cv=5: 5-fold cross-validation.\nprint(f\"Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})\")  # Media \u00b1 2*std (95% confianza).\n</code></pre> <p>Proceso K-Fold (K=5): 1. Divide datos en 5 partes iguales 2. Entrena en 4, valida en 1 3. Repite 5 veces (cada parte es validaci\u00f3n una vez) 4. Promedia resultados</p> <p>Ventajas: - Usa todos los datos para entrenar y validar - Estimaci\u00f3n m\u00e1s robusta del rendimiento - Detecta variabilidad del modelo</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-15-feature-scaling","title":"Pregunta 15: Feature Scaling","text":"<p>\u00bfPor qu\u00e9 normalizamos features?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_14","title":"Respuesta:","text":"<pre><code>from sklearn.preprocessing import StandardScaler   # Estandariza: (x - media) / std.\n\nscaler = StandardScaler()                          # Crea instancia del transformador.\nX_scaled = scaler.fit_transform(X_train)           # fit: calcula media/std. transform: aplica.\n\n# Antes: age=[18-92], salary=[20000-200000]        # Escalas muy diferentes.\n# Despu\u00e9s: ambas con media=0, std=1               # Escalas comparables.\n</code></pre> <p>Razones: 1. Algoritmos sensibles a escala: SVM, KNN, redes neuronales 2. Gradiente descent: Converge m\u00e1s r\u00e1pido 3. Interpretaci\u00f3n: Coeficientes comparables</p> <p>Algoritmos que NO necesitan scaling: Random Forest, Decision Tree, XGBoost.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-16-one-hot-encoding","title":"Pregunta 16: One-Hot Encoding","text":"<p>\u00bfC\u00f3mo manejas variables categ\u00f3ricas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_15","title":"Respuesta:","text":"<pre><code>from sklearn.preprocessing import OneHotEncoder    # Convierte categor\u00edas a columnas binarias.\n\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # ignore: no falla con categor\u00edas nuevas.\nX_encoded = encoder.fit_transform(df[['Geography', 'Gender']])  # fit: aprende categor\u00edas. transform: aplica.\n\n# Geography: France, Germany, Spain\n# \u2192 Geography_France, Geography_Germany, Geography_Spain  # 1 columna por categor\u00eda, valores 0/1.\n</code></pre> <p>Alternativas: - Label Encoding: Para ordinales (Bajo &lt; Medio &lt; Alto) - Target Encoding: Codifica con la media del target (\u26a0\ufe0f riesgo de leakage)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-17-missing-values","title":"Pregunta 17: Missing Values","text":"<p>\u00bfC\u00f3mo manejas valores faltantes?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_16","title":"Respuesta:","text":"<pre><code>from sklearn.impute import SimpleImputer            # Rellena valores faltantes (NaN).\n\n# Num\u00e9ricos: media o mediana\nimputer_num = SimpleImputer(strategy='median')     # median: robusto a outliers.\n\n# Categ\u00f3ricos: moda o valor constante\nimputer_cat = SimpleImputer(strategy='constant', fill_value='Unknown')  # Rellena con 'Unknown'.\n</code></pre> <p>Estrategias: | Caso | Estrategia | |------|------------| | Pocos missing (&lt;5%) | Imputar con media/moda | | Muchos missing | Considerar eliminar columna | | Missing tiene significado | Crear feature <code>is_missing</code> |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-18-random-forest","title":"Pregunta 18: Random Forest","text":"<p>Explica c\u00f3mo funciona Random Forest.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_17","title":"Respuesta:","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier  # Ensemble de \u00e1rboles de decisi\u00f3n.\n\nrf = RandomForestClassifier(\n    n_estimators=100,  # 100 \u00e1rboles: m\u00e1s \u00e1rboles = m\u00e1s robusto pero m\u00e1s lento.\n    max_depth=10,      # Profundidad m\u00e1xima: limita complejidad, evita overfitting.\n    random_state=42    # Semilla para reproducibilidad.\n)\n</code></pre> <p>Concepto simple: 1. Crea N \u00e1rboles de decisi\u00f3n 2. Cada \u00e1rbol usa subset aleatorio de datos y features 3. Predicci\u00f3n final = voto mayoritario (clasificaci\u00f3n) o promedio (regresi\u00f3n)</p> <p>Ventajas: Robusto, pocas configuraciones, maneja bien missing values.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-19-metricas-de-clasificacion","title":"Pregunta 19: M\u00e9tricas de Clasificaci\u00f3n","text":"<p>\u00bfQu\u00e9 es accuracy, precision, recall y F1?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_18","title":"Respuesta:","text":"<pre><code>from sklearn.metrics import classification_report  # Reporte completo de m\u00e9tricas.\n\nprint(classification_report(y_test, y_pred))       # Muestra precision, recall, f1 por clase.\n</code></pre> M\u00e9trica F\u00f3rmula Cu\u00e1ndo priorizar Accuracy Correctos / Total Clases balanceadas Precision TP / (TP + FP) Costo alto de falsos positivos Recall TP / (TP + FN) Costo alto de falsos negativos F1 2 \u00d7 (P \u00d7 R) / (P + R) Balance entre P y R <p>En BankChurn: Priorizo Recall (no queremos perder clientes que har\u00e1n churn).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-20-curva-roc-y-auc","title":"Pregunta 20: Curva ROC y AUC","text":"<p>\u00bfQu\u00e9 es AUC-ROC?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_19","title":"Respuesta:","text":"<pre><code>from sklearn.metrics import roc_auc_score, roc_curve  # M\u00e9tricas para clasificaci\u00f3n binaria.\n\n# AUC: \u00c1rea bajo la curva ROC\nauc = roc_auc_score(y_test, y_pred_proba[:, 1])       # [:, 1]: probabilidad de clase positiva.\nprint(f\"AUC: {auc:.3f}\")                              # :.3f: 3 decimales.\n</code></pre> <p>Interpretaci\u00f3n: - AUC = 1.0: Clasificador perfecto - AUC = 0.5: Clasificador aleatorio - AUC &gt; 0.8: Generalmente bueno</p> <p>Ventaja: Funciona bien con clases desbalanceadas.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#3-datos-y-preprocesamiento-preguntas-21-30","title":"3. Datos y Preprocesamiento (Preguntas 21-30)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-21-exploracion-de-datos","title":"Pregunta 21: Exploraci\u00f3n de Datos","text":"<p>\u00bfQu\u00e9 haces primero cuando recibes un dataset?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_20","title":"Respuesta:","text":"<pre><code>import pandas as pd\n\ndf = pd.read_csv(\"data.csv\")                          # Carga el dataset.\n\n# 1. Dimensiones\nprint(f\"Shape: {df.shape}\")                           # (filas, columnas): tama\u00f1o del dataset.\n\n# 2. Tipos de datos\nprint(df.dtypes)                                      # Tipo de cada columna (int, float, object).\n\n# 3. Missing values\nprint(df.isnull().sum())                              # Cuenta NaN por columna.\n\n# 4. Estad\u00edsticas b\u00e1sicas\nprint(df.describe())                                  # Media, std, min, max, cuartiles.\n\n# 5. Primeras filas\nprint(df.head())                                      # Visualiza primeras 5 filas.\n\n# 6. Target distribution\nprint(df['target'].value_counts(normalize=True))      # normalize=True: proporciones en vez de conteos.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-22-deteccion-de-outliers","title":"Pregunta 22: Detecci\u00f3n de Outliers","text":"<p>\u00bfC\u00f3mo detectas outliers?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_21","title":"Respuesta:","text":"<pre><code>import numpy as np\n\n# M\u00e9todo IQR (Interquartile Range)\nQ1 = df['Balance'].quantile(0.25)                     # Percentil 25.\nQ3 = df['Balance'].quantile(0.75)                     # Percentil 75.\nIQR = Q3 - Q1                                         # Rango intercuart\u00edlico.\n\nlower = Q1 - 1.5 * IQR                                # L\u00edmite inferior.\nupper = Q3 + 1.5 * IQR                                # L\u00edmite superior.\n\noutliers = df[(df['Balance'] &lt; lower) | (df['Balance'] &gt; upper)]  # Filtra outliers.\nprint(f\"Outliers: {len(outliers)}\")                   # Cuenta cu\u00e1ntos hay.\n</code></pre> <p>Qu\u00e9 hacer con outliers: 1. Verificar si son errores de datos \u2192 corregir 2. Si son leg\u00edtimos \u2192 considerar winsorization o mantener 3. Para modelos sensibles \u2192 eliminar o transformar</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-23-correlacion","title":"Pregunta 23: Correlaci\u00f3n","text":"<p>\u00bfC\u00f3mo identificas features correlacionadas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_22","title":"Respuesta:","text":"<pre><code>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Matriz de correlaci\u00f3n\ncorr = df.corr()                                      # Calcula correlaci\u00f3n entre todas las columnas num\u00e9ricas.\n\n# Heatmap\nplt.figure(figsize=(10, 8))                           # Tama\u00f1o del gr\u00e1fico.\nsns.heatmap(corr, annot=True, cmap='coolwarm')        # annot: muestra valores. cmap: colores.\nplt.show()\n\n# Features altamente correlacionadas (&gt;0.9)\nhigh_corr = (corr.abs() &gt; 0.9) &amp; (corr != 1.0)        # abs(): valor absoluto. Excluye diagonal.\n</code></pre> <p>\u00bfPor qu\u00e9 importa? Features muy correlacionadas son redundantes \u2192 considerar eliminar una.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-24-desbalance-de-clases","title":"Pregunta 24: Desbalance de Clases","text":"<p>\u00bfQu\u00e9 haces cuando tienes 95% clase A y 5% clase B?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_23","title":"Respuesta:","text":"<pre><code># 1. Cambiar m\u00e9trica (no usar accuracy)\nfrom sklearn.metrics import f1_score, recall_score  # M\u00e9tricas que consideran desbalance.\n\n# 2. Class weights\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(class_weight='balanced')  # Penaliza m\u00e1s errores en clase minoritaria.\n\n# 3. Oversampling (SMOTE)\nfrom imblearn.over_sampling import SMOTE             # Genera ejemplos sint\u00e9ticos de clase minoritaria.\nX_res, y_res = SMOTE().fit_resample(X, y)            # Balancea el dataset.\n\n# 4. Undersampling\nfrom imblearn.under_sampling import RandomUnderSampler  # Reduce clase mayoritaria.\n</code></pre> <p>En BankChurn: 80/20 balance \u2192 usamos <code>class_weight='balanced'</code> y F1.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-25-feature-selection","title":"Pregunta 25: Feature Selection","text":"<p>\u00bfC\u00f3mo seleccionas features importantes?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_24","title":"Respuesta:","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier\n\n# 1. Feature importance de RF\nrf = RandomForestClassifier().fit(X, y)              # Entrena RF.\nimportances = pd.DataFrame({\n    'feature': X.columns,\n    'importance': rf.feature_importances_            # Importancia calculada por RF.\n}).sort_values('importance', ascending=False)        # Ordena de mayor a menor.\n\n# 2. Correlaci\u00f3n con target\ncorrelations = df.corr()['target'].abs().sort_values(ascending=False)  # Correlaci\u00f3n absoluta.\n\n# 3. SelectKBest\nfrom sklearn.feature_selection import SelectKBest, f_classif  # Selecci\u00f3n estad\u00edstica.\nselector = SelectKBest(f_classif, k=10)              # k=10: selecciona las 10 mejores.\nX_selected = selector.fit_transform(X, y)            # Retorna solo las k features.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-26-data-leakage","title":"Pregunta 26: Data Leakage","text":"<p>\u00bfQu\u00e9 es data leakage y c\u00f3mo evitarlo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_25","title":"Respuesta:","text":"<p>Data leakage = cuando informaci\u00f3n del futuro o del target filtra al entrenamiento.</p> <pre><code># \u274c MAL: fit scaler en TODO antes de split\nscaler.fit(X)                                        # Ve datos de test \u2192 LEAKAGE.\nX_train, X_test = train_test_split(X)\n\n# \u2705 BIEN: fit solo en train\nX_train, X_test = train_test_split(X)                # Primero split.\nscaler.fit(X_train)                                  # fit SOLO en train.\nX_train = scaler.transform(X_train)                  # transform train.\nX_test = scaler.transform(X_test)                    # transform test (sin fit).\n</code></pre> <p>En el portafolio: Usamos Pipeline de sklearn que maneja esto autom\u00e1ticamente.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-27-pipelines-de-sklearn","title":"Pregunta 27: Pipelines de sklearn","text":"<p>\u00bfPor qu\u00e9 usar Pipeline?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_26","title":"Respuesta:","text":"<pre><code>from sklearn.pipeline import Pipeline               # Encadena pasos de ML.\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\n\npipe = Pipeline([                                   # Lista de tuplas (nombre, transformador).\n    ('scaler', StandardScaler()),                   # Paso 1: escalar.\n    ('model', RandomForestClassifier())             # Paso 2: modelo.\n])\n\n# Un solo fit/predict\npipe.fit(X_train, y_train)                          # fit propaga por todos los pasos.\ny_pred = pipe.predict(X_test)                       # predict: transforma y predice.\n</code></pre> <p>Beneficios: 1. Evita leakage: fit solo en train autom\u00e1ticamente 2. C\u00f3digo limpio: Todo en un objeto 3. F\u00e1cil deploy: <code>joblib.dump(pipe, 'model.joblib')</code> 4. Reproducibilidad: Mismo proceso siempre</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-28-guardado-de-modelos","title":"Pregunta 28: Guardado de Modelos","text":"<p>\u00bfC\u00f3mo guardas y cargas un modelo entrenado?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_27","title":"Respuesta:","text":"<pre><code>import joblib                                       # Serializaci\u00f3n eficiente para objetos Python.\n\n# Guardar\njoblib.dump(model, 'artifacts/model.joblib')        # Serializa modelo a archivo.\n\n# Cargar\nmodel = joblib.load('artifacts/model.joblib')       # Deserializa de archivo.\n\n# Usar\nprediction = model.predict(new_data)                # Modelo listo para predecir.\n</code></pre> <p>En producci\u00f3n (FastAPI): <pre><code>@lru_cache()                                        # Cache: carga modelo UNA vez, reutiliza.\ndef load_model():\n    return joblib.load(\"artifacts/pipeline.joblib\") # Evita cargar en cada request.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-29-validacion-de-datos","title":"Pregunta 29: Validaci\u00f3n de Datos","text":"<p>\u00bfC\u00f3mo validas que los datos de entrada son correctos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_28","title":"Respuesta:","text":"<pre><code>from pydantic import BaseModel, Field, validator  # Pydantic: validaci\u00f3n de datos.\n\nclass CustomerInput(BaseModel):                   # Hereda de BaseModel para validaci\u00f3n autom\u00e1tica.\n    credit_score: int = Field(ge=300, le=850)     # ge: &gt;=300, le: &lt;=850. Validaci\u00f3n de rango.\n    age: int = Field(ge=18, le=100)               # Edad entre 18 y 100.\n    geography: str\n\n    @validator('geography')                       # Validador custom para geography.\n    def geography_valid(cls, v):                  # cls: clase, v: valor a validar.\n        valid = ['France', 'Germany', 'Spain']\n        if v not in valid:\n            raise ValueError(f'Must be one of {valid}')  # Error descriptivo.\n        return v                                  # Retorna valor validado.\n</code></pre> <p>Beneficios: Errores claros antes de llegar al modelo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-30-reproducibilidad","title":"Pregunta 30: Reproducibilidad","text":"<p>\u00bfC\u00f3mo garantizas que tu experimento sea reproducible?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_29","title":"Respuesta:","text":"<pre><code>import random\nimport numpy as np\n\n# 1. Fijar seeds\nSEED = 42                                         # Constante para todas las semillas.\nrandom.seed(SEED)                                 # Seed para m\u00f3dulo random de Python.\nnp.random.seed(SEED)                              # Seed para numpy.\n\n# 2. En modelos\nmodel = RandomForestClassifier(random_state=SEED) # random_state: semilla interna del modelo.\n\n# 3. En split\ntrain_test_split(X, y, random_state=SEED)         # Misma semilla = mismo split siempre.\n\n# 4. Documentar versiones\n# requirements.txt o pyproject.toml con versiones fijas  # sklearn==1.3.0, no sklearn.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#4-git-y-herramientas-preguntas-31-40","title":"4. Git y Herramientas (Preguntas 31-40)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-31-git-basico","title":"Pregunta 31: Git B\u00e1sico","text":"<p>\u00bfCu\u00e1l es el flujo b\u00e1sico de Git?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_30","title":"Respuesta:","text":"<pre><code># 1. Ver estado\ngit status                    # Muestra archivos modificados/nuevos/staged.\n\n# 2. A\u00f1adir cambios\ngit add .                     # A\u00f1ade TODO al staging area.\ngit add archivo.py            # A\u00f1ade archivo espec\u00edfico.\n\n# 3. Commit\ngit commit -m \"feat: add preprocessing step\"  # Guarda cambios con mensaje descriptivo.\n\n# 4. Push\ngit push origin main          # Sube commits locales al remoto (origin/main).\n\n# 5. Pull (obtener cambios)\ngit pull origin main          # Descarga y fusiona cambios del remoto.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-32-branches","title":"Pregunta 32: Branches","text":"<p>\u00bfPor qu\u00e9 usar branches?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_31","title":"Respuesta:","text":"<pre><code># Crear branch\ngit checkout -b feature/add-validation  # -b: crea branch y cambia a ella.\n\n# Trabajar...\ngit add .\ngit commit -m \"feat: add pydantic validation\"  # Conventional commit: tipo(scope): mensaje.\n\n# Push branch\ngit push origin feature/add-validation  # Sube branch al remoto.\n\n# Crear Pull Request en GitHub\n# Despu\u00e9s de aprobar, merge a main       # PR permite code review antes de merge.\n</code></pre> <p>Razones: - Aislar cambios - Revisar c\u00f3digo antes de merge - Mantener main siempre funcional</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-33-gitignore","title":"Pregunta 33: .gitignore","text":"<p>\u00bfQu\u00e9 debe ir en .gitignore?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_32","title":"Respuesta:","text":"<pre><code># Datos (grandes, sensibles)\ndata/\n*.csv\n*.parquet\n\n# Artefactos\nartifacts/\n*.joblib\n*.pkl\n\n# Entornos\n.venv/\n__pycache__/\n\n# IDEs\n.vscode/\n.idea/\n\n# Logs\n*.log\nmlruns/\n</code></pre> <p>Regla: No subir datos grandes, artefactos binarios, ni secretos.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-34-requirements","title":"Pregunta 34: Requirements","text":"<p>\u00bfC\u00f3mo manejas dependencias?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_33","title":"Respuesta:","text":"<pre><code># Crear requirements.txt\npip freeze &gt; requirements.txt           # Exporta TODAS las dependencias instaladas.\n\n# Mejor: usar pip-tools\npip-compile requirements.in &gt; requirements.txt  # Genera lockfile desde requirements.in.\n\n# Instalar\npip install -r requirements.txt         # Instala exactamente las versiones especificadas.\n\n# Moderno: pyproject.toml\npip install -e \".[dev]\"                 # -e: editable. [dev]: grupo de deps opcionales.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-35-makefile","title":"Pregunta 35: Makefile","text":"<p>\u00bfPara qu\u00e9 sirve un Makefile?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_34","title":"Respuesta:","text":"<pre><code>.PHONY: install test train              # Declara targets que no son archivos.\n\ninstall:                                # Target: make install\n    pip install -e \".[dev]\"             # Comando a ejecutar (TAB obligatorio).\n\ntest:                                   # Target: make test\n    pytest tests/ -v --cov=src          # Ejecuta tests con coverage.\n\ntrain:                                  # Target: make train\n    python main.py --config configs/config.yaml\n\nlint:                                   # Target: make lint\n    ruff check src/                     # Verifica calidad de c\u00f3digo.\n</code></pre> <p>Uso: <pre><code>make install\nmake test\nmake train\n</code></pre></p> <p>Beneficio: Comandos est\u00e1ndar, documentados, f\u00e1ciles de recordar.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-36-pytest-basico","title":"Pregunta 36: pytest B\u00e1sico","text":"<p>\u00bfC\u00f3mo escribes un test b\u00e1sico?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_35","title":"Respuesta:","text":"<pre><code># tests/test_data.py\nimport pytest                            # Framework de testing.\nimport pandas as pd\n\ndef test_load_data():                    # Funci\u00f3n test: debe empezar con test_.\n    df = pd.read_csv(\"data/raw/sample.csv\")\n    assert len(df) &gt; 0                   # assert: falla si condici\u00f3n es False.\n    assert \"target\" in df.columns        # Verifica que columna existe.\n\ndef test_no_nulls_in_target():           # Otro test independiente.\n    df = pd.read_csv(\"data/raw/sample.csv\")\n    assert df[\"target\"].isnull().sum() == 0  # No debe haber NaN en target.\n\n# Ejecutar\n# pytest tests/test_data.py -v           # -v: verbose, muestra detalles.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-37-estructura-de-proyecto","title":"Pregunta 37: Estructura de Proyecto","text":"<p>\u00bfC\u00f3mo organizas un proyecto ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_36","title":"Respuesta:","text":"<pre><code>mi-proyecto/\n\u251c\u2500\u2500 src/miproyecto/     # C\u00f3digo fuente\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py       # Configuraci\u00f3n\n\u2502   \u251c\u2500\u2500 data.py         # Carga de datos\n\u2502   \u251c\u2500\u2500 features.py     # Feature engineering\n\u2502   \u2514\u2500\u2500 training.py     # Entrenamiento\n\u251c\u2500\u2500 app/                # APIs\n\u251c\u2500\u2500 tests/              # Tests\n\u251c\u2500\u2500 configs/            # YAML configs\n\u251c\u2500\u2500 data/raw/           # Datos\n\u251c\u2500\u2500 artifacts/          # Modelos guardados\n\u251c\u2500\u2500 pyproject.toml      # Dependencias\n\u251c\u2500\u2500 Makefile           \n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-38-readme","title":"Pregunta 38: README","text":"<p>\u00bfQu\u00e9 debe tener un buen README?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_37","title":"Respuesta:","text":"<pre><code># Nombre del Proyecto\n\n## Descripci\u00f3n\nQu\u00e9 hace el proyecto, problema que resuelve.\n\n## Instalaci\u00f3n\n```bash\npip install -e .\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#uso-rapido","title":"Uso R\u00e1pido","text":"<pre><code>from miproyecto import predict\nresult = predict(data)\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#estructura","title":"Estructura","text":"<p>\u00c1rbol de directorios.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#tests","title":"Tests","text":"<pre><code>make test\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#autor","title":"Autor","text":"<p>Nombre, contacto. <pre><code>---\n\n## Pregunta 39: Docker B\u00e1sico\n**\u00bfQu\u00e9 es Docker y por qu\u00e9 usarlo?**\n\n### Respuesta:\nDocker empaqueta tu aplicaci\u00f3n con todas sus dependencias.\n\n```dockerfile\nFROM python:3.11-slim                    # Imagen base: Python 3.11 ligera.\n\nWORKDIR /app                             # Directorio de trabajo dentro del contenedor.\nCOPY requirements.txt .                  # Copia solo requirements primero (cache de capas).\nRUN pip install -r requirements.txt      # Instala dependencias.\n\nCOPY . .                                 # Copia el resto del c\u00f3digo.\nCMD [\"python\", \"main.py\"]               # Comando por defecto al ejecutar contenedor.\n</code></pre></p> <pre><code># Construir\ndocker build -t mi-app .                 # -t: tag/nombre. .: contexto actual.\n\n# Ejecutar\ndocker run mi-app                        # Ejecuta contenedor con la imagen.\n</code></pre> <p>Beneficio: \"Funciona en mi m\u00e1quina\" \u2192 Funciona en cualquier m\u00e1quina.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-40-apis-basicas","title":"Pregunta 40: APIs B\u00e1sicas","text":"<p>\u00bfQu\u00e9 es una API REST?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_38","title":"Respuesta:","text":"<p>API = Interfaz para que otros programas usen tu c\u00f3digo.</p> <pre><code>from fastapi import FastAPI               # Framework web moderno para APIs.\n\napp = FastAPI()                           # Crea instancia de la aplicaci\u00f3n.\n\n@app.get(\"/health\")                       # Decorador: ruta GET /health.\ndef health():\n    return {\"status\": \"ok\"}               # Retorna JSON autom\u00e1ticamente.\n\n@app.post(\"/predict\")                     # Decorador: ruta POST /predict.\ndef predict(data: dict):                 # data: body del request como dict.\n    # Usar modelo\n    return {\"prediction\": result}         # Respuesta JSON.\n</code></pre> <pre><code># Ejecutar\nuvicorn app:app --reload                 # uvicorn: servidor ASGI. --reload: hot reload.\n\n# Probar\ncurl http://localhost:8000/health        # curl: hace request HTTP desde terminal.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#5-pr\u00e1ctica-con-el-portafolio-preguntas-41-50","title":"5. Pr\u00e1ctica con el Portafolio (Preguntas 41-50)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-41-describir-el-portafolio","title":"Pregunta 41: Describir el Portafolio","text":"<p>Cu\u00e9ntame sobre el portafolio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_39","title":"Respuesta:","text":"<p>\"Es un portafolio de MLOps con 3 proyectos production-ready:</p> <ol> <li> <p>BankChurn-Predictor: Clasificaci\u00f3n binaria para predecir churn de clientes bancarios. Pipeline sklearn unificado, FastAPI, 79% coverage.</p> </li> <li> <p>CarVision-Market-Intelligence: Regresi\u00f3n para predecir precios de autos usados. FeatureEngineer centralizado, Streamlit dashboard.</p> </li> <li> <p>TelecomAI: Clasificaci\u00f3n multiclase para segmentaci\u00f3n de clientes de telecom.</p> </li> </ol> <p>Todos siguen las mismas pr\u00e1cticas: estructura src/, Pydantic para configs, pytest, GitHub Actions CI.\"</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-42-ejecutar-el-proyecto","title":"Pregunta 42: Ejecutar el Proyecto","text":"<p>\u00bfC\u00f3mo ejecuto BankChurn?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_40","title":"Respuesta:","text":"<pre><code># 1. Clonar\ngit clone https://github.com/duqueom/ML-MLOps-Portfolio.git  # Descarga repositorio.\ncd ML-MLOps-Portfolio/BankChurn-Predictor  # Entra al proyecto.\n\n# 2. Crear entorno\npython -m venv .venv                     # Crea entorno virtual.\nsource .venv/bin/activate                # Activa entorno (Linux/Mac).\n\n# 3. Instalar\npip install -e \".[dev]\"                  # Instala proyecto + deps de desarrollo.\n\n# 4. Entrenar\npython main.py --config configs/config.yaml  # Ejecuta entrenamiento con config.\n\n# 5. API\nuvicorn app.fastapi_app:app --reload     # Inicia servidor de desarrollo.\n\n# 6. Tests\npytest tests/ -v                         # Ejecuta todos los tests.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-43-entender-el-pipeline","title":"Pregunta 43: Entender el Pipeline","text":"<p>\u00bfC\u00f3mo funciona el pipeline de BankChurn?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_41","title":"Respuesta:","text":"<pre><code># 1. Cargar config\nconfig = BankChurnConfig.from_yaml(\"configs/config.yaml\")  # Pydantic valida config.\n\n# 2. Cargar datos\ndf = pd.read_csv(config.data.raw_path)   # Ruta viene de config.\n\n# 3. Crear trainer\ntrainer = Trainer(config)                 # Trainer encapsula l\u00f3gica de entrenamiento.\n\n# 4. Entrenar (dentro crea Pipeline sklearn)\ntrainer.fit(X, y)                         # fit: entrena preprocesador + modelo.\n# Pipeline = [preprocessor, model]        # Todo en un objeto.\n# preprocessor = ColumnTransformer(numeric_pipe, categorical_pipe)\n\n# 5. Evaluar\nmetrics = trainer.evaluate(X_test, y_test)  # Retorna dict de m\u00e9tricas.\n\n# 6. Guardar\ntrainer.save(\"artifacts/\")                # Serializa pipeline completo.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-44-modificar-el-codigo","title":"Pregunta 44: Modificar el C\u00f3digo","text":"<p>\u00bfC\u00f3mo a\u00f1adir\u00edas una nueva feature?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_42","title":"Respuesta:","text":"<pre><code># 1. En config.yaml, a\u00f1adir columna\nfeatures:\n  numerical:\n    - CreditScore\n    - Age\n    - NewFeature  # Nueva                # Solo agregar aqu\u00ed si ya existe en datos.\n\n# 2. Si requiere transformaci\u00f3n, editar FeatureEngineer\nclass FeatureEngineer:                    # Transformer custom.\n    def transform(self, X):\n        X['NewFeature'] = X['Col1'] / X['Col2']  # Crea feature derivada.\n        return X\n\n# 3. Agregar test\ndef test_new_feature():                   # Test para la nueva feature.\n    fe = FeatureEngineer()\n    result = fe.transform(sample_df)\n    assert 'NewFeature' in result.columns # Verifica que se cre\u00f3.\n\n# 4. Ejecutar tests\npytest tests/test_features.py -v          # Verifica que todo sigue funcionando.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-45-leer-un-error","title":"Pregunta 45: Leer un Error","text":"<p>Este c\u00f3digo falla. \u00bfPor qu\u00e9? <pre><code>X_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_43","title":"Respuesta:","text":"<p>Problema: <code>fit_transform</code> en test causa data leakage.</p> <pre><code># \u2705 Correcto\nX_train = scaler.fit_transform(X_train)  # fit + transform: aprende de train.\nX_test = scaler.transform(X_test)        # solo transform: usa params de train.\n</code></pre> <p>El scaler debe aprender (fit) solo de training data.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-46-interpretar-metricas","title":"Pregunta 46: Interpretar M\u00e9tricas","text":"<p>El modelo tiene accuracy 95% pero el negocio no est\u00e1 contento. \u00bfPor qu\u00e9?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_44","title":"Respuesta:","text":"<p>Posibles razones:</p> <ol> <li> <p>Clases desbalanceadas: Si 95% son clase 0, predecir siempre 0 da 95% accuracy pero es in\u00fatil.</p> </li> <li> <p>M\u00e9trica incorrecta: El negocio necesita recall (no perder churners) pero optimizaste accuracy.</p> </li> <li> <p>Falsos negativos costosos: Cada cliente que hace churn y no detectamos cuesta $X.</p> </li> </ol> <p>Soluci\u00f3n: Usar F1, recall, o una m\u00e9trica de negocio (costo).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-47-configuracion-yaml","title":"Pregunta 47: Configuraci\u00f3n YAML","text":"<p>\u00bfPor qu\u00e9 usar archivos YAML para configuraci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_45","title":"Respuesta:","text":"<pre><code># configs/config.yaml\nmodel:\n  type: \"random_forest\"          # Tipo de modelo a usar.\n  n_estimators: 100               # Hiperpar\u00e1metros del modelo.\n  max_depth: 10\n\ndata:\n  raw_path: \"data/raw/Churn.csv\"  # Rutas configurables.\n  test_size: 0.2                  # Proporci\u00f3n de test.\n\ntraining:\n  random_state: 42                # Semilla para reproducibilidad.\n</code></pre> <p>Ventajas: 1. Separaci\u00f3n: Cambiar par\u00e1metros sin tocar c\u00f3digo 2. Versionable: Git puede trackear cambios 3. Legible: F\u00e1cil de entender 4. Reproducibilidad: Guardar config de cada experimento</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-48-cicd-basico","title":"Pregunta 48: CI/CD B\u00e1sico","text":"<p>\u00bfQu\u00e9 hace el workflow de GitHub Actions?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_46","title":"Respuesta:","text":"<pre><code># .github/workflows/ci.yml\nname: CI                          # Nombre del workflow.\non: [push, pull_request]          # Triggers: se activa en push o PR.\n\njobs:\n  test:\n    runs-on: ubuntu-latest        # Ejecuta en Ubuntu.\n    steps:\n      - uses: actions/checkout@v4  # Clona el repo.\n      - uses: actions/setup-python@v5  # Instala Python.\n      - run: pip install -e \".[dev]\"  # Instala dependencias.\n      - run: pytest tests/ -v     # Ejecuta tests.\n</code></pre> <p>Flujo: 1. Push c\u00f3digo \u2192 GitHub Actions se activa 2. Crea m\u00e1quina virtual limpia 3. Instala dependencias 4. Ejecuta tests 5. Reporta pass/fail</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-49-debugging-en-produccion","title":"Pregunta 49: Debugging en Producci\u00f3n","text":"<p>El API retorna error 500. \u00bfC\u00f3mo lo depuras?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_47","title":"Respuesta:","text":"<pre><code># 1. Ver logs\nuvicorn app:app --log-level debug # --log-level debug: muestra todos los logs.\n\n# 2. A\u00f1adir logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)  # Configura nivel de logging.\n\n@app.post(\"/predict\")\ndef predict(data: Input):\n    logging.debug(f\"Input: {data}\")        # Log de entrada para debugging.\n    try:\n        result = model.predict(...)        # Operaci\u00f3n que puede fallar.\n        logging.debug(f\"Result: {result}\") # Log de resultado.\n        return result\n    except Exception as e:\n        logging.error(f\"Error: {e}\")       # Log de error con detalles.\n        raise                              # Re-lanza para que FastAPI maneje.\n\n# 3. Probar localmente\ncurl -X POST http://localhost:8000/predict \\  # curl: cliente HTTP desde terminal.\n  -H \"Content-Type: application/json\" \\       # Header: indica formato JSON.\n  -d '{\"credit_score\": 650, ...}'             # -d: data/body del request.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#pregunta-50-proximos-pasos","title":"Pregunta 50: Pr\u00f3ximos Pasos","text":"<p>\u00bfQu\u00e9 aprender\u00edas despu\u00e9s de este portafolio?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#respuesta_48","title":"Respuesta:","text":"<p>\"Con las bases del portafolio, me gustar\u00eda profundizar en:</p> <ol> <li> <p>MLflow/Experiment Tracking: Ya est\u00e1 configurado, pero quiero usarlo m\u00e1s para comparar experimentos sistem\u00e1ticamente.</p> </li> <li> <p>Docker avanzado: Optimizar im\u00e1genes, multi-stage builds.</p> </li> <li> <p>Testing m\u00e1s robusto: A\u00f1adir tests de integraci\u00f3n, property-based testing.</p> </li> <li> <p>Kubernetes b\u00e1sico: Entender c\u00f3mo escalar los servicios.</p> </li> <li> <p>Monitoreo en producci\u00f3n: Detectar drift, alertas.</p> </li> </ol> <p>El portafolio me dio la base; ahora quiero profundizar en cada \u00e1rea.\"</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#recursos-para-preparacion","title":"\ud83d\udcda Recursos para Preparaci\u00f3n","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#modulos-de-la-guia-relacionados","title":"M\u00f3dulos de la Gu\u00eda Relacionados","text":"Pregunta M\u00f3dulo Python b\u00e1sico 01_PYTHON_MODERNO.md ML fundamentos 07_SKLEARN_PIPELINES.md, 08_INGENIERIA_FEATURES.md Git 05_GIT_PROFESIONAL.md Testing 11_TESTING_ML.md APIs 14_FASTAPI.md"},{"location":"docs/SIMULACRO_ENTREVISTA_JUNIOR/#checklist-pre-entrevista","title":"Checklist Pre-Entrevista","text":"<ul> <li>[ ] Puedo ejecutar <code>make install &amp;&amp; make test</code> en BankChurn</li> <li>[ ] Entiendo qu\u00e9 hace cada archivo en <code>src/bankchurn/</code></li> <li>[ ] S\u00e9 explicar train/test split y por qu\u00e9 importa</li> <li>[ ] Puedo leer y modificar el <code>config.yaml</code></li> <li>[ ] Entiendo el flujo Git b\u00e1sico</li> </ul>   **\u00a1\u00c9xito en tu entrevista! \ud83d\ude80**  *Recuerda: ser Junior significa estar aprendiendo. Muestra curiosidad y ganas de aprender.*  [\u2190 \u00cdndice](00_INDICE.md) | [Simulacro Mid \u2192](SIMULACRO_ENTREVISTA_MID.md) | [Simulacro Senior \u2192](SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md)"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/","title":"\ud83c\udfaf Simulacro de Entrevista Mid-Level ML Engineer","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#portafolio-mlops-60-preguntas-tecnicas","title":"Portafolio MLOps \u2014 60 Preguntas T\u00e9cnicas","text":"<p>Nivel: Mid (2-4 a\u00f1os de experiencia) Versi\u00f3n: 1.0 | Diciembre 2025</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ol> <li>Pipelines y Arquitectura</li> <li>MLOps Pr\u00e1ctico</li> <li>Testing y Calidad</li> <li>Deployment y APIs</li> <li>Escenarios Pr\u00e1cticos</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#que-se-espera-de-un-mid-level","title":"\ud83c\udfaf \u00bfQu\u00e9 se espera de un Mid-Level?","text":"S\u00ed se espera No se espera (a\u00fan) Dise\u00f1ar pipelines end-to-end Arquitecturas distribuidas complejas Implementar CI/CD funcional Optimizaci\u00f3n de infraestructura a escala Debugging aut\u00f3nomo Mentoring de equipos Code reviews Decisiones de arquitectura cr\u00edticas Escribir tests comprehensivos Dise\u00f1o de sistemas desde cero"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#1-pipelines-y-arquitectura-preguntas-1-15","title":"1. Pipelines y Arquitectura (Preguntas 1-15)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-1-pipeline-unificado","title":"Pregunta 1: Pipeline Unificado","text":"<p>\u00bfPor qu\u00e9 usar un Pipeline unificado en lugar de artefactos separados?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta","title":"Respuesta:","text":"<pre><code># \u274c Antes: artefactos separados\npreprocessor = joblib.load(\"preprocessor.pkl\")  # Cargar preprocesador.\nmodel = joblib.load(\"model.pkl\")                # Cargar modelo por separado.\nX = preprocessor.transform(X)                   # Transformar manualmente.\npred = model.predict(X)                         # Predecir.\n\n# \u2705 Despu\u00e9s: pipeline unificado\npipe = joblib.load(\"pipeline.joblib\")           # TODO en un archivo.\npred = pipe.predict(X)                          # Una llamada hace todo.\n</code></pre> <p>Beneficios: 1. Elimina training-serving skew 2. Single source of truth 3. Versionado simple 4. Deploy m\u00e1s limpio</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-2-columntransformer","title":"Pregunta 2: ColumnTransformer","text":"<p>Explica el ColumnTransformer del portafolio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_1","title":"Respuesta:","text":"<pre><code>preprocessor = ColumnTransformer([               # Aplica transformaciones por tipo de columna.\n    ('num', Pipeline([                           # Pipeline para num\u00e9ricas.\n        ('imputer', SimpleImputer(strategy='median')),  # Imputa con mediana.\n        ('scaler', StandardScaler())             # Estandariza.\n    ]), numerical_cols),\n    ('cat', Pipeline([                           # Pipeline para categ\u00f3ricas.\n        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n        ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding.\n    ]), categorical_cols),\n], remainder='drop')                             # Elimina columnas no especificadas.\n</code></pre> <p>Procesa columnas en paralelo: num\u00e9ricas y categ\u00f3ricas tienen transformaciones distintas.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-3-custom-transformer","title":"Pregunta 3: Custom Transformer","text":"<p>\u00bfCu\u00e1ndo crear un transformer personalizado?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_2","title":"Respuesta:","text":"<pre><code>class FeatureEngineer(BaseEstimator, TransformerMixin):  # Hereda para compatibilidad con Pipeline.\n    def fit(self, X, y=None):                    # fit: aprende de datos (aqu\u00ed no hace nada).\n        return self                              # Retorna self para encadenar.\n\n    def transform(self, X):                      # transform: aplica transformaci\u00f3n.\n        X = X.copy()                             # Copia para no modificar original.\n        X['vehicle_age'] = 2024 - X['model_year']  # Crea feature derivada.\n        return X\n</code></pre> <p>Cu\u00e1ndo usar: - L\u00f3gica de negocio espec\u00edfica - Features derivadas - Transformaciones no est\u00e1ndar</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-4-estratified-split","title":"Pregunta 4: Estratified Split","text":"<p>\u00bfPor qu\u00e9 stratify=y en train_test_split?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_3","title":"Respuesta:","text":"<pre><code>X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42  # stratify: mantiene proporci\u00f3n de clases.\n)\n</code></pre> <p>Con clases desbalanceadas (80/20 churn), <code>stratify=y</code> garantiza que train y test mantengan la misma proporci\u00f3n. Sin esto, un split aleatorio podr\u00eda dar 85/15 en train y 70/30 en test.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-5-hyperparameter-tuning","title":"Pregunta 5: Hyperparameter Tuning","text":"<p>\u00bfC\u00f3mo optimizas hiperpar\u00e1metros?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_4","title":"Respuesta:","text":"<pre><code>from sklearn.model_selection import RandomizedSearchCV  # B\u00fasqueda aleatoria de hiperpar\u00e1metros.\n\nparam_dist = {\n    'model__n_estimators': [50, 100, 200],       # model__: accede a params del paso 'model'.\n    'model__max_depth': [5, 10, 20, None]\n}\n\nsearch = RandomizedSearchCV(\n    pipe, param_dist, n_iter=20, cv=5, scoring='f1'  # n_iter: 20 combinaciones aleatorias.\n)\nsearch.fit(X_train, y_train)                     # Prueba combinaciones con CV.\nprint(search.best_params_)                       # Mejores hiperpar\u00e1metros encontrados.\n</code></pre> <p>GridSearch vs RandomizedSearch: Random es m\u00e1s eficiente con muchos par\u00e1metros.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-6-metricas-de-negocio","title":"Pregunta 6: M\u00e9tricas de Negocio","text":"<p>\u00bfC\u00f3mo traduces m\u00e9tricas ML a valor de negocio?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_5","title":"Respuesta:","text":"<pre><code># Costo de falsos negativos (cliente que churns sin detectar)\ncost_fn = 500                                    # Costo de adquirir cliente nuevo.\n\n# Costo de falsos positivos (retenci\u00f3n innecesaria)\ncost_fp = 50                                     # Costo de campa\u00f1a de retenci\u00f3n.\n\n# Costo total\ntotal_cost = (FN * cost_fn) + (FP * cost_fp)     # M\u00e9trica de negocio: minimizar esto.\n</code></pre> <p>Optimizar para minimizar costo total, no solo accuracy.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-7-ensemble-methods","title":"Pregunta 7: Ensemble Methods","text":"<p>Explica VotingClassifier con soft voting.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_6","title":"Respuesta:","text":"<pre><code>ensemble = VotingClassifier([                    # Combina m\u00faltiples modelos.\n    ('lr', LogisticRegression()),                # Modelo lineal.\n    ('rf', RandomForestClassifier())             # Modelo no-lineal.\n], voting='soft', weights=[0.4, 0.6])            # soft: promedia probabilidades. weights: RF pesa m\u00e1s.\n</code></pre> <ul> <li>Soft voting: Promedia probabilidades (mejor que votos binarios)</li> <li>Weights: RF tiene m\u00e1s peso porque tiene mejor AUC individual</li> <li>Complementariedad: LR lineal + RF no-lineal = menor varianza</li> </ul>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-8-cross-validation-avanzado","title":"Pregunta 8: Cross-Validation Avanzado","text":"<p>\u00bfCu\u00e1ndo usar TimeSeriesSplit vs StratifiedKFold?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_7","title":"Respuesta:","text":"Tipo Usar cuando StratifiedKFold Clasificaci\u00f3n con clases desbalanceadas TimeSeriesSplit Datos temporales (evitar data leakage temporal) GroupKFold Datos con grupos (ej: m\u00faltiples muestras por paciente) <pre><code>from sklearn.model_selection import TimeSeriesSplit  # CV para datos temporales.\ntscv = TimeSeriesSplit(n_splits=5)               # 5 splits temporales.\n# Train: [1,2,3], Test: [4]                      # Nunca usa datos futuros para entrenar.\n# Train: [1,2,3,4], Test: [5]                    # El train crece, test siempre es \"futuro\".\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-9-feature-importance","title":"Pregunta 9: Feature Importance","text":"<p>\u00bfC\u00f3mo explicas qu\u00e9 features son importantes?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_8","title":"Respuesta:","text":"<pre><code># 1. Importancia de RF\nimportances = model.feature_importances_         # Importancia basada en reducci\u00f3n de impureza.\n\n# 2. Permutation importance (m\u00e1s robusto)\nfrom sklearn.inspection import permutation_importance\nperm = permutation_importance(model, X_test, y_test)  # Permuta features y mide impacto.\n\n# 3. SHAP (m\u00e1s interpretable)\nimport shap\nexplainer = shap.TreeExplainer(model)            # Explainer para modelos de \u00e1rboles.\nshap_values = explainer.shap_values(X_test)      # Contribuci\u00f3n de cada feature por predicci\u00f3n.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-10-handling-categorical-high-cardinality","title":"Pregunta 10: Handling Categorical High Cardinality","text":"<p>\u00bfC\u00f3mo manejas categor\u00edas con muchos valores \u00fanicos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_9","title":"Respuesta:","text":"<pre><code># 1. Target encoding (con cuidado de leakage)\nfrom category_encoders import TargetEncoder      # Codifica con media del target.\nencoder = TargetEncoder()                        # \u26a0\ufe0f Usar solo en train para evitar leakage.\n\n# 2. Frequency encoding\nX['brand_freq'] = X['brand'].map(X['brand'].value_counts(normalize=True))  # Frecuencia relativa.\n\n# 3. Grouping rare categories\nX['brand'] = X['brand'].apply(lambda x: x if freq[x] &gt; 0.01 else 'Other')  # Agrupa raras en 'Other'.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-11-reproducibilidad","title":"Pregunta 11: Reproducibilidad","text":"<p>\u00bfC\u00f3mo garantizas experimentos reproducibles?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_10","title":"Respuesta:","text":"<pre><code># 1. Seeds\nSEED = 42\nnp.random.seed(SEED)                             # Seed numpy.\nrandom.seed(SEED)                                # Seed random.\n\n# 2. Config versionada\nconfig = BankChurnConfig.from_yaml(\"configs/config.yaml\")  # Pydantic valida.\n\n# 3. MLflow tracking\nmlflow.log_params(config.model.dict())           # Guarda hiperpar\u00e1metros.\nmlflow.log_artifact(\"configs/config.yaml\")       # Guarda archivo de config.\n\n# 4. Dependencias fijas\n# pyproject.toml con versiones espec\u00edficas       # sklearn==1.3.0, no sklearn.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-12-data-validation","title":"Pregunta 12: Data Validation","text":"<p>\u00bfC\u00f3mo validas datos de entrada en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_11","title":"Respuesta:","text":"<pre><code>from pydantic import BaseModel, Field, validator  # Pydantic para validaci\u00f3n.\n\nclass PredictionInput(BaseModel):                # Schema de entrada.\n    credit_score: int = Field(ge=300, le=850)    # ge/le: rangos v\u00e1lidos.\n    age: int = Field(ge=18, le=100)\n    geography: str\n\n    @validator('geography')                      # Validador custom.\n    def validate_geography(cls, v):              # v: valor a validar.\n        valid = ['France', 'Germany', 'Spain']\n        if v not in valid:\n            raise ValueError(f'Must be one of {valid}')  # Error descriptivo.\n        return v                                 # Retorna valor validado.\n</code></pre> <p>Pydantic valida antes de que llegue al modelo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-13-config-management","title":"Pregunta 13: Config Management","text":"<p>\u00bfPor qu\u00e9 Pydantic para configuraci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_12","title":"Respuesta:","text":"<pre><code>class ModelConfig(BaseModel):\n    model_type: Literal[\"rf\", \"lr\", \"xgb\"]        # Solo estos valores permitidos.\n    n_estimators: int = Field(ge=10, le=1000)     # Rango v\u00e1lido.\n\n    @validator('n_estimators')                    # Validaci\u00f3n cross-field.\n    def validate_estimators(cls, v, values):     # values: otros campos ya validados.\n        if values.get('model_type') == 'lr' and v != 1:\n            raise ValueError('LR no usa n_estimators')  # L\u00f3gica de negocio.\n        return v\n</code></pre> <p>Beneficios: Validaci\u00f3n autom\u00e1tica, tipos claros, errores descriptivos, documentaci\u00f3n impl\u00edcita.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-14-artifact-management","title":"Pregunta 14: Artifact Management","text":"<p>\u00bfC\u00f3mo organizas artefactos del modelo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_13","title":"Respuesta:","text":"<pre><code>artifacts/\n\u251c\u2500\u2500 pipeline.joblib       # Modelo + preprocessor\n\u251c\u2500\u2500 training_results.json # M\u00e9tricas\n\u251c\u2500\u2500 config.yaml          # Config usada\n\u2514\u2500\u2500 feature_names.json   # Features esperadas\n</code></pre> <pre><code># Guardar\njoblib.dump(pipe, 'artifacts/pipeline.joblib')   # Serializa pipeline completo.\nwith open('artifacts/training_results.json', 'w') as f:\n    json.dump(metrics, f)                        # Guarda m\u00e9tricas como JSON.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-15-model-versioning","title":"Pregunta 15: Model Versioning","text":"<p>\u00bfC\u00f3mo versionas modelos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_14","title":"Respuesta:","text":"<pre><code># 1. MLflow Model Registry\nmlflow.sklearn.log_model(pipe, \"model\")          # Guarda modelo en MLflow.\n# Registrar como v1, v2, etc.                    # UI permite promover a staging/production.\n\n# 2. Naming convention\nmodel_name = f\"bankchurn_v{version}_{timestamp}.joblib\"  # Nombre descriptivo.\n\n# 3. Git tags\ngit tag -a v1.0.0 -m \"Model v1.0.0: AUC 0.85\"   # Asocia versi\u00f3n de c\u00f3digo con modelo.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#2-mlops-pr\u00e1ctico-preguntas-16-30","title":"2. MLOps Pr\u00e1ctico (Preguntas 16-30)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-16-mlflow-tracking","title":"Pregunta 16: MLflow Tracking","text":"<p>\u00bfC\u00f3mo usas MLflow para tracking?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_15","title":"Respuesta:","text":"<pre><code>import mlflow\n\nwith mlflow.start_run():                         # Context manager: crea y cierra run.\n    mlflow.log_params({\"n_estimators\": 100, \"max_depth\": 10})  # Hiperpar\u00e1metros.\n    mlflow.log_metrics({\"auc\": 0.85, \"f1\": 0.78})  # M\u00e9tricas de evaluaci\u00f3n.\n    mlflow.sklearn.log_model(pipe, \"model\")      # Guarda modelo serializado.\n    mlflow.log_artifact(\"configs/config.yaml\")   # Guarda archivos adicionales.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-17-dvc","title":"Pregunta 17: DVC","text":"<p>\u00bfPara qu\u00e9 usas DVC?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_16","title":"Respuesta:","text":"<pre><code># Trackear datos\ndvc add data/raw/Churn.csv                       # Crea .dvc file, a\u00f1ade datos a .gitignore.\n\n# Push a remote\ndvc push                                         # Sube datos a remote (S3, GCS, etc.).\n\n# Pull datos\ndvc pull                                         # Descarga datos del remote.\n</code></pre> <p>Beneficio: Versionar datos grandes sin subirlos a Git.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-18-github-actions-ci","title":"Pregunta 18: GitHub Actions CI","text":"<p>Explica el workflow CI del portafolio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_17","title":"Respuesta:","text":"<pre><code>name: CI\non: [push, pull_request]                         # Triggers del workflow.\n\njobs:\n  test:\n    runs-on: ubuntu-latest                       # Runner de GitHub.\n    steps:\n      - uses: actions/checkout@v4                # Clona el repo.\n      - run: pip install -e \".[dev]\"             # Instala dependencias.\n      - run: pytest tests/ --cov=src             # Ejecuta tests con coverage.\n      - run: ruff check src/                     # Linting.\n</code></pre> <p>Flujo: Push \u2192 Install \u2192 Test \u2192 Lint \u2192 Pass/Fail badge.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-19-pre-commit-hooks","title":"Pregunta 19: Pre-commit Hooks","text":"<p>\u00bfQu\u00e9 hooks usas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_18","title":"Respuesta:","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit  # Linter r\u00e1pido.\n    hooks:\n      - id: ruff                                 # Verifica estilo.\n      - id: ruff-format                          # Auto-formatea.\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    hooks:\n      - id: mypy                                 # Verificaci\u00f3n de tipos.\n</code></pre> <p>Ejecutan autom\u00e1ticamente antes de cada commit.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-20-docker-multi-stage","title":"Pregunta 20: Docker Multi-stage","text":"<p>Explica el Dockerfile del portafolio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_19","title":"Respuesta:","text":"<pre><code># Build stage\nFROM python:3.11-slim AS builder                # Stage de compilaci\u00f3n.\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir -w /wheels -r requirements.txt  # Genera wheels.\n\n# Runtime stage\nFROM python:3.11-slim                           # Imagen limpia, sin herramientas de build.\nCOPY --from=builder /wheels /wheels             # Copia solo wheels del builder.\nRUN pip install --no-cache /wheels/*            # Instala sin compilar.\nCOPY . /app\nUSER nonroot                                    # Seguridad: no root.\nCMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\"] # Comando de inicio.\n</code></pre> <p>Multi-stage: Build pesado en stage 1, runtime ligero en stage 2.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-21-training-serving-skew","title":"Pregunta 21: Training-Serving Skew","text":"<p>\u00bfQu\u00e9 es training-serving skew y c\u00f3mo lo evitas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_20","title":"Respuesta:","text":"<p>Training-serving skew ocurre cuando el modelo ve datos diferentes en producci\u00f3n vs entrenamiento.</p> <p>Causas comunes: <pre><code># \u274c MAL: Preprocesamiento diferente\n# Training\nX_train['age_normalized'] = (X_train['age'] - X_train['age'].mean()) / X_train['age'].std()  # Stats de train.\n\n# Serving (usa stats de producci\u00f3n, no de training!)\nX_prod['age_normalized'] = (X_prod['age'] - X_prod['age'].mean()) / X_prod['age'].std()  # Stats de prod \u2192 SKEW.\n</code></pre></p> <p>Soluci\u00f3n: Pipeline unificado: <pre><code># \u2705 BIEN: Todo en un pipeline\npipe = Pipeline([\n    ('scaler', StandardScaler()),                # Guarda mean/std de training internamente.\n    ('model', RandomForestClassifier())\n])\npipe.fit(X_train, y_train)                       # fit: aprende stats de train.\njoblib.dump(pipe, 'model.joblib')                # Serializa TODO junto.\n\n# En producci\u00f3n: mismo pipeline\npipe = joblib.load('model.joblib')               # Carga con stats de train.\npred = pipe.predict(X_new)                       # transform usa stats originales.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-22-data-drift-detection","title":"Pregunta 22: Data Drift Detection","text":"<p>\u00bfC\u00f3mo detectas data drift en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_21","title":"Respuesta:","text":"<pre><code>from evidently.metrics import DataDriftTable     # Evidently: librer\u00eda de monitoreo ML.\nfrom evidently.report import Report\n\n# Comparar distribuciones\nreport = Report(metrics=[DataDriftTable()])      # M\u00e9trica de drift.\nreport.run(reference_data=X_train, current_data=X_prod)  # Compara train vs producci\u00f3n.\nreport.save_html(\"drift_report.html\")            # Genera reporte visual.\n</code></pre> <p>M\u00e9todos estad\u00edsticos: | M\u00e9todo | Uso | Umbral t\u00edpico | |--------|-----|---------------| | PSI (Population Stability Index) | Categ\u00f3ricas | &gt;0.2 = drift significativo | | KS-test (Kolmogorov-Smirnov) | Num\u00e9ricas | p-value &lt; 0.05 | | JS Divergence | Distribuciones | &gt;0.1 = drift |</p> <p>En el portafolio: Configurable en <code>16_OBSERVABILIDAD.md</code>.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-23-metricas-de-produccion","title":"Pregunta 23: M\u00e9tricas de Producci\u00f3n","text":"<p>\u00bfQu\u00e9 m\u00e9tricas monitoreas en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_22","title":"Respuesta:","text":"<pre><code># Prometheus metrics en FastAPI\nfrom prometheus_client import Counter, Histogram  # Cliente Prometheus para Python.\n\nPREDICTIONS = Counter('predictions_total', 'Total predictions', ['model_version'])  # Contador.\nLATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')  # Histograma.\n\n@app.post(\"/predict\")\nasync def predict(data: Input):\n    with LATENCY.time():                         # Mide tiempo autom\u00e1ticamente.\n        result = model.predict(data)\n    PREDICTIONS.labels(model_version=\"v1.2\").inc()  # Incrementa contador con label.\n    return result\n</code></pre> <p>M\u00e9tricas clave: | Categor\u00eda | M\u00e9tricas | |-----------|----------| | Rendimiento | Latencia p50/p95/p99, throughput | | Disponibilidad | Error rate, uptime | | ML espec\u00edficas | Prediction distribution, feature distributions | | Negocio | Conversiones, costos evitados |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-24-rollback-de-modelos","title":"Pregunta 24: Rollback de Modelos","text":"<p>\u00bfC\u00f3mo haces rollback si un modelo falla?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_23","title":"Respuesta:","text":"<pre><code># 1. Versionado de modelos\nmodels/\n\u251c\u2500\u2500 v1.0.0/pipeline.joblib  # \u2190 Rollback aqu\u00ed\n\u251c\u2500\u2500 v1.1.0/pipeline.joblib\n\u2514\u2500\u2500 v1.2.0/pipeline.joblib  # Actual (fallando)\n\n# 2. Blue-Green deployment\n# deployment.yaml\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      version: v1.1.0  # Cambiar a versi\u00f3n anterior\n\n# 3. Con MLflow\nclient = MlflowClient()\nclient.transition_model_version_stage(\n    name=\"bankchurn\",\n    version=3,\n    stage=\"Production\"  # Promover versi\u00f3n anterior\n)\n</code></pre> <p>Proceso de rollback: 1. Detectar degradaci\u00f3n (alertas de m\u00e9tricas) 2. Cambiar variable de entorno o config 3. Reiniciar pods / recargar modelo 4. Verificar m\u00e9tricas post-rollback</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-25-ab-testing-en-ml","title":"Pregunta 25: A/B Testing en ML","text":"<p>\u00bfC\u00f3mo implementas A/B testing para modelos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_24","title":"Respuesta:","text":"<pre><code>import random\n\n@app.post(\"/predict\")\nasync def predict(data: Input, user_id: str):\n    # Asignar bucket consistente por usuario\n    bucket = hash(user_id) % 100                 # Hash determinista: mismo user = mismo bucket.\n\n    if bucket &lt; 10:                              # 10% tr\u00e1fico al challenger.\n        model = model_v2                         # Challenger: modelo nuevo.\n        version = \"v2\"\n    else:\n        model = model_v1                         # Champion: modelo actual.\n        version = \"v1\"\n\n    result = model.predict(data)\n\n    # Logging para an\u00e1lisis\n    log_prediction(user_id, version, result)     # Guarda para comparar m\u00e9tricas.\n\n    return {\"prediction\": result, \"model_version\": version}\n</code></pre> <p>M\u00e9tricas a comparar: - Accuracy/F1 en cohortes - M\u00e9tricas de negocio (conversi\u00f3n, revenue) - Latencia y error rate</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-26-manejo-de-secrets","title":"Pregunta 26: Manejo de Secrets","text":"<p>\u00bfC\u00f3mo manejas secrets y credenciales?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_25","title":"Respuesta:","text":"<pre><code># \u274c MAL: Hardcoded\nAPI_KEY = \"TU_API_KEY_AQUI\"                      # NUNCA hacer esto: queda en Git.\n\n# \u2705 BIEN: Variables de entorno\nimport os\nAPI_KEY = os.getenv(\"API_KEY\")                   # Lee de variable de entorno.\n\n# \u2705 MEJOR: python-dotenv\nfrom dotenv import load_dotenv\nload_dotenv()                                    # Carga variables de .env al entorno.\nAPI_KEY = os.getenv(\"API_KEY\")                   # Ahora disponible.\n</code></pre> <p>.env (nunca en Git): <pre><code># .env (valores de ejemplo)\nAPI_KEY=REEMPLAZAR_EN_ENTORNO_REAL\nDB_PASSWORD=REEMPLAZAR_EN_ENTORNO_REAL\n</code></pre></p> <p>.gitignore: <pre><code>.env\n.env.*\n!.env.example\n</code></pre></p> <p>En CI/CD: GitHub Secrets \u2192 <code>${{ secrets.API_KEY }}</code></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-27-feature-store","title":"Pregunta 27: Feature Store","text":"<p>\u00bfQu\u00e9 es un feature store y cu\u00e1ndo usarlo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_26","title":"Respuesta:","text":"<p>Feature store = repositorio centralizado de features reutilizables.</p> <pre><code># Sin feature store (problema)\n# Equipo A: calcula age_bucket de una forma\n# Equipo B: calcula age_bucket de otra forma\n# \u2192 Inconsistencia                              # Cada equipo tiene su versi\u00f3n.\n\n# Con feature store (soluci\u00f3n)\nfrom feast import FeatureStore                   # Feast: feature store open source.\n\nstore = FeatureStore(repo_path=\".\")              # Conecta al store.\nfeatures = store.get_online_features(            # Obtiene features en tiempo real.\n    features=[\"customer:age_bucket\", \"customer:tenure_months\"],  # Formato: tabla:feature.\n    entity_rows=[{\"customer_id\": \"C123\"}]        # Entidad a buscar.\n)\n</code></pre> <p>Cu\u00e1ndo usar: | Situaci\u00f3n | Feature Store | |-----------|---------------| | 1-2 modelos, equipo peque\u00f1o | No necesario | | M\u00faltiples modelos, features compartidas | Recomendado | | Features en tiempo real | Muy recomendado |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-28-escalado-de-inferencia","title":"Pregunta 28: Escalado de Inferencia","text":"<p>\u00bfC\u00f3mo escalas inferencia para alto tr\u00e1fico?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_27","title":"Respuesta:","text":"<pre><code># Kubernetes HPA (Horizontal Pod Autoscaler)\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler               # Escala pods autom\u00e1ticamente.\nmetadata:\n  name: bankchurn-api\nspec:\n  scaleTargetRef:                           # Deployment a escalar.\n    apiVersion: apps/v1\n    kind: Deployment\n    name: bankchurn-api\n  minReplicas: 2                            # M\u00ednimo 2 pods siempre.\n  maxReplicas: 10                           # M\u00e1ximo 10 pods.\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70              # Escala cuando CPU &gt; 70%.\n</code></pre> <p>Estrategias: | Estrategia | Cu\u00e1ndo | |------------|--------| | HPA | Tr\u00e1fico variable, latencia cr\u00edtica | | Batch processing | Alto volumen, latencia flexible | | Caching | Inputs repetidos frecuentes | | Model optimization | Latencia muy baja requerida |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-29-logging-en-ml","title":"Pregunta 29: Logging en ML","text":"<p>\u00bfQu\u00e9 informaci\u00f3n loggeas en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_28","title":"Respuesta:","text":"<pre><code>import logging\nimport json\n\nlogger = logging.getLogger(__name__)             # Logger por m\u00f3dulo.\n\n@app.post(\"/predict\")\nasync def predict(data: Input):\n    request_id = str(uuid.uuid4())               # ID \u00fanico para trazar request.\n\n    # Log de entrada\n    logger.info(json.dumps({                     # JSON estructurado para an\u00e1lisis.\n        \"event\": \"prediction_request\",\n        \"request_id\": request_id,\n        \"features\": data.dict(),                 # Features de entrada.\n        \"timestamp\": datetime.utcnow().isoformat()\n    }))\n\n    start = time.time()                          # Medir latencia.\n    result = model.predict(data)\n    latency = time.time() - start\n\n    # Log de salida\n    logger.info(json.dumps({\n        \"event\": \"prediction_response\",\n        \"request_id\": request_id,                # Mismo ID para correlacionar.\n        \"prediction\": result,\n        \"probability\": float(proba),\n        \"latency_ms\": latency * 1000,            # Latencia en ms.\n        \"model_version\": \"v1.2.0\"                # Versi\u00f3n para debugging.\n    }))\n\n    return result\n</code></pre> <p>Logs esenciales: request_id, inputs, outputs, latencia, versi\u00f3n, errores.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-30-retraining-automatico","title":"Pregunta 30: Retraining Autom\u00e1tico","text":"<p>\u00bfC\u00f3mo automatizas el retraining?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_29","title":"Respuesta:","text":"<pre><code># GitHub Actions scheduled workflow\nname: Weekly Retrain\non:\n  schedule:\n    - cron: '0 2 * * 0'                         # Domingos 2am UTC.\n  workflow_dispatch:                            # Permite trigger manual.\n\njobs:\n  retrain:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - run: pip install -e \".[dev]\"\n      - run: python main.py --config configs/config.yaml  # Entrena modelo.\n      - run: python scripts/evaluate.py --threshold 0.80  # Valida m\u00e9tricas.\n      - run: |                                  # Deploy condicional.\n          if [ $? -eq 0 ]; then                 # Si evaluaci\u00f3n pas\u00f3.\n            echo \"Model passed threshold, deploying...\"\n            # Deploy logic\n          fi\n</code></pre> <p>Triggers de retraining: | Trigger | Implementaci\u00f3n | |---------|----------------| | Scheduled | Cron jobs, Airflow | | Data drift | Alerta \u2192 trigger workflow | | Performance degradation | M\u00e9tricas bajo umbral | | New data volume | X nuevos registros |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#3-testing-y-calidad-preguntas-31-40","title":"3. Testing y Calidad (Preguntas 31-40)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-31-tipos-de-tests","title":"Pregunta 31: Tipos de Tests","text":"<p>\u00bfQu\u00e9 tipos de tests tiene el portafolio?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_30","title":"Respuesta:","text":"<pre><code># Unit test - prueba una funci\u00f3n aislada\ndef test_feature_engineer():\n    fe = FeatureEngineer()\n    result = fe.transform(sample_df)             # Prueba transform.\n    assert 'vehicle_age' in result.columns       # Verifica output esperado.\n\n# Integration test - prueba m\u00faltiples componentes juntos\ndef test_training_pipeline():\n    trainer = Trainer(config)\n    trainer.fit(X, y)                            # Prueba flujo completo.\n    assert trainer.model_ is not None            # Verifica que modelo existe.\n\n# API test - prueba endpoint HTTP\ndef test_predict_endpoint():\n    response = client.post(\"/predict\", json=sample_input)  # Request HTTP.\n    assert response.status_code == 200           # Verifica respuesta exitosa.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-32-fixtures","title":"Pregunta 32: Fixtures","text":"<p>\u00bfC\u00f3mo usas fixtures en pytest?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_31","title":"Respuesta:","text":"<pre><code>@pytest.fixture                                  # Fixture: setup reutilizable.\ndef sample_data():\n    return pd.DataFrame({                        # Datos de prueba.\n        'CreditScore': [650, 700],\n        'Age': [35, 45],\n        'Exited': [0, 1]\n    })\n\n@pytest.fixture\ndef trained_model(sample_data):                  # Fixture puede usar otra fixture.\n    trainer = Trainer(config)\n    trainer.fit(sample_data)                     # Entrena con datos de prueba.\n    return trainer\n\ndef test_predict(trained_model, sample_data):    # Test recibe fixtures como args.\n    preds = trained_model.predict(sample_data)\n    assert len(preds) == len(sample_data)        # Verifica cantidad de predicciones.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-33-coverage","title":"Pregunta 33: Coverage","text":"<p>\u00bfCu\u00e1nto coverage es suficiente?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_32","title":"Respuesta:","text":"<pre><code>pytest tests/ --cov=src --cov-report=html       # --cov: mide coverage de src/. --cov-report: genera HTML.\n</code></pre> Nivel Coverage Comentario M\u00ednimo 70% Lo b\u00e1sico Bueno 80% Est\u00e1ndar industria Excelente 90%+ C\u00f3digo cr\u00edtico <p>El portafolio tiene 79% en BankChurn.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-34-property-based-testing","title":"Pregunta 34: Property-Based Testing","text":"<p>\u00bfQu\u00e9 es property-based testing?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_33","title":"Respuesta:","text":"<p>En lugar de casos espec\u00edficos, defines propiedades que siempre deben cumplirse.</p> <pre><code>from hypothesis import given, strategies as st   # Hypothesis: property-based testing.\n\n@given(                                          # @given genera casos de prueba autom\u00e1ticos.\n    credit_score=st.integers(min_value=300, max_value=850),  # Estrategia: enteros en rango.\n    age=st.integers(min_value=18, max_value=100)\n)\ndef test_prediction_is_valid(credit_score, age):\n    \"\"\"Propiedad: la predicci\u00f3n siempre es 0 o 1.\"\"\"  # Define invariante.\n    input_data = {\"credit_score\": credit_score, \"age\": age}\n    pred = model.predict(pd.DataFrame([input_data]))\n    assert pred[0] in [0, 1]                     # Debe cumplirse para TODOS los inputs.\n\n@given(df=st.data())                             # st.data(): permite draw din\u00e1mico.\ndef test_feature_engineer_preserves_rows(df):\n    \"\"\"Propiedad: FeatureEngineer no cambia n\u00famero de filas.\"\"\"\n    sample = df.draw(st.dataframes(columns=[     # Genera DataFrame aleatorio.\n        st.column(\"age\", dtype=int),\n        st.column(\"salary\", dtype=float)\n    ]))\n    result = fe.transform(sample)\n    assert len(result) == len(sample)            # Filas deben preservarse.\n</code></pre> <p>Ventaja: Encuentra edge cases que no pensaste.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-35-testing-de-modelos-ml","title":"Pregunta 35: Testing de Modelos ML","text":"<p>\u00bfC\u00f3mo testeas que un modelo funciona correctamente?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_34","title":"Respuesta:","text":"<pre><code># 1. Test de smoke: modelo carga y predice\ndef test_model_loads_and_predicts():\n    model = joblib.load(\"artifacts/pipeline.joblib\")  # Carga modelo.\n    sample = pd.DataFrame([{\"CreditScore\": 650, \"Age\": 35}])\n    pred = model.predict(sample)                 # Debe poder predecir.\n    assert len(pred) == 1                        # Una predicci\u00f3n por fila.\n\n# 2. Test de formato de salida\ndef test_prediction_format():\n    pred = model.predict(X_test)\n    assert pred.shape == (len(X_test),)          # Shape correcto.\n    assert set(pred).issubset({0, 1})            # Solo valores v\u00e1lidos.\n\n# 3. Test de rendimiento m\u00ednimo\ndef test_model_performance():\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    assert accuracy &gt;= 0.75, f\"Accuracy {accuracy} below threshold\"  # Umbral m\u00ednimo.\n\n# 4. Test de invarianza\ndef test_prediction_deterministic():\n    pred1 = model.predict(X_test)\n    pred2 = model.predict(X_test)\n    assert np.array_equal(pred1, pred2)          # Misma entrada = misma salida.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-36-mocking","title":"Pregunta 36: Mocking","text":"<p>\u00bfQu\u00e9 es mocking y cu\u00e1ndo usarlo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_35","title":"Respuesta:","text":"<p>Mocking = reemplazar dependencias reales con objetos simulados.</p> <pre><code>from unittest.mock import Mock, patch           # Mock: simula objetos. patch: reemplaza.\n\n# Mockear llamada a API externa\n@patch('myapp.external_api.get_customer_data')  # Reemplaza esta funci\u00f3n.\ndef test_predict_with_external_data(mock_api):  # mock_api: objeto mock.\n    # Configurar mock\n    mock_api.return_value = {\"credit_score\": 700, \"age\": 45}  # Respuesta simulada.\n\n    # Test usa el mock en lugar de API real\n    result = predict_for_customer(\"C123\")       # No llama API real.\n\n    # Verificar que se llam\u00f3\n    mock_api.assert_called_once_with(\"C123\")    # Verifica argumentos.\n    assert result is not None\n\n# Mockear modelo para test de API\n@patch('app.fastapi_app.model')                 # Reemplaza el modelo.\ndef test_predict_endpoint(mock_model):\n    mock_model.predict.return_value = np.array([1])  # Simula predicci\u00f3n.\n    mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])\n\n    response = client.post(\"/predict\", json=sample_input)\n    assert response.json()[\"prediction\"] == 1   # Usa valor del mock.\n</code></pre> <p>Cu\u00e1ndo usar: APIs externas, base de datos, servicios lentos.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-37-testing-de-apis","title":"Pregunta 37: Testing de APIs","text":"<p>\u00bfC\u00f3mo testeas endpoints de FastAPI?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_36","title":"Respuesta:","text":"<pre><code>from fastapi.testclient import TestClient       # Cliente para tests sin servidor.\nfrom app.fastapi_app import app\n\nclient = TestClient(app)                        # Crea cliente de prueba.\n\ndef test_health_endpoint():\n    response = client.get(\"/health\")            # GET request.\n    assert response.status_code == 200          # 200 OK.\n    assert response.json()[\"status\"] == \"healthy\"  # Verifica contenido.\n\ndef test_predict_valid_input():\n    response = client.post(\"/predict\", json={   # POST con JSON body.\n        \"credit_score\": 650,\n        \"age\": 35,\n        \"geography\": \"France\"\n    })\n    assert response.status_code == 200\n    assert \"prediction\" in response.json()      # Verifica campos de respuesta.\n    assert \"probability\" in response.json()\n\ndef test_predict_invalid_input():\n    response = client.post(\"/predict\", json={\n        \"credit_score\": 9999,                   # Fuera de rango: Pydantic rechaza.\n        \"age\": 35\n    })\n    assert response.status_code == 422          # 422: Validation error.\n\ndef test_predict_missing_field():\n    response = client.post(\"/predict\", json={\n        \"credit_score\": 650                     # Falta age: campo requerido.\n    })\n    assert response.status_code == 422\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-38-parametrized-tests","title":"Pregunta 38: Parametrized Tests","text":"<p>\u00bfC\u00f3mo evitas duplicaci\u00f3n en tests?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_37","title":"Respuesta:","text":"<pre><code>import pytest\n\n@pytest.mark.parametrize(\"credit_score,age,expected\", [  # Lista de casos.\n    (300, 18, 0),                               # M\u00ednimos v\u00e1lidos.\n    (850, 100, 1),                              # M\u00e1ximos v\u00e1lidos.\n    (650, 45, 0),                               # Caso t\u00edpico.\n])\ndef test_prediction_cases(credit_score, age, expected):  # Se ejecuta 3 veces.\n    input_data = {\"credit_score\": credit_score, \"age\": age}\n    pred = model.predict(pd.DataFrame([input_data]))\n    assert pred[0] in [0, 1]                    # Verificamos formato, no valor exacto.\n\n@pytest.mark.parametrize(\"invalid_input,expected_error\", [  # Casos de error.\n    ({\"credit_score\": -1}, \"greater than or equal to 300\"),\n    ({\"credit_score\": 1000}, \"less than or equal to 850\"),\n    ({\"age\": 5}, \"greater than or equal to 18\"),\n])\ndef test_validation_errors(invalid_input, expected_error):\n    response = client.post(\"/predict\", json=invalid_input)\n    assert response.status_code == 422          # Todos deben dar 422.\n    assert expected_error in str(response.json())  # Mensaje de error esperado.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-39-testing-de-edge-cases","title":"Pregunta 39: Testing de Edge Cases","text":"<p>\u00bfC\u00f3mo testeas edge cases en ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_38","title":"Respuesta:","text":"<pre><code># 1. Inputs vac\u00edos\ndef test_empty_dataframe():\n    df = pd.DataFrame()                          # DataFrame sin filas.\n    with pytest.raises(ValueError):              # Debe lanzar error.\n        model.predict(df)\n\n# 2. Nulls\ndef test_missing_values():\n    df = pd.DataFrame([{\"CreditScore\": None, \"Age\": 35}])  # NaN en feature.\n    # Pipeline debe manejar o fallar graciosamente\n    result = model.predict(df)                   # SimpleImputer deber\u00eda manejar.\n\n# 3. Outliers extremos\ndef test_extreme_values():\n    df = pd.DataFrame([{\n        \"CreditScore\": 850,\n        \"Age\": 100,\n        \"Balance\": 1_000_000_000                 # Outlier extremo.\n    }])\n    pred = model.predict(df)\n    assert pred[0] in [0, 1]                     # Debe predecir sin fallar.\n\n# 4. Tipos incorrectos\ndef test_wrong_types():\n    with pytest.raises(Exception):               # Debe fallar con tipo incorrecto.\n        model.predict(\"not a dataframe\")         # String en vez de DataFrame.\n\n# 5. Columnas faltantes\ndef test_missing_columns():\n    df = pd.DataFrame([{\"CreditScore\": 650}])   # Falta Age.\n    with pytest.raises(KeyError):                # Pipeline necesita todas las columnas.\n        model.predict(df)\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-40-test-driven-development-tdd","title":"Pregunta 40: Test-Driven Development (TDD)","text":"<p>\u00bfC\u00f3mo aplicas TDD en ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_39","title":"Respuesta:","text":"<p>TDD: Escribir test \u2192 Ver que falla \u2192 Implementar \u2192 Ver que pasa \u2192 Refactorizar.</p> <pre><code># 1. Escribir test primero\ndef test_feature_engineer_creates_age_bucket():\n    df = pd.DataFrame({\"age\": [25, 45, 65]})     # Datos de prueba.\n    fe = FeatureEngineer()\n    result = fe.transform(df)\n\n    assert \"age_bucket\" in result.columns        # Verifica que crea columna.\n    assert list(result[\"age_bucket\"]) == [\"young\", \"middle\", \"senior\"]  # Valores esperados.\n\n# 2. Test falla (FeatureEngineer no existe a\u00fan)  # Red: test falla.\n# 3. Implementar m\u00ednimo para pasar               # Green: c\u00f3digo m\u00ednimo.\nclass FeatureEngineer(BaseEstimator, TransformerMixin):\n    def transform(self, X):\n        X = X.copy()\n        X[\"age_bucket\"] = pd.cut(                # pd.cut: binning.\n            X[\"age\"], \n            bins=[0, 30, 50, 100],               # Rangos de edad.\n            labels=[\"young\", \"middle\", \"senior\"] # Etiquetas.\n        )\n        return X\n\n# 4. Test pasa \u2713                                 # Verificar que pasa.\n# 5. Refactorizar si es necesario               # Mejorar sin romper tests.\n</code></pre> <p>En ML, TDD es \u00fatil para: - Feature engineering (definir comportamiento esperado) - Validaci\u00f3n de datos - APIs</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#4-deployment-y-apis-preguntas-41-50","title":"4. Deployment y APIs (Preguntas 41-50)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-41-fastapi-basics","title":"Pregunta 41: FastAPI Basics","text":"<p>Muestra un endpoint de predicci\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_40","title":"Respuesta:","text":"<pre><code>from fastapi import FastAPI                      # Framework web.\nfrom pydantic import BaseModel                   # Validaci\u00f3n de datos.\n\napp = FastAPI()                                  # Crea aplicaci\u00f3n.\n\nclass Input(BaseModel):                          # Schema de entrada.\n    credit_score: int\n    age: int\n\n@app.post(\"/predict\")                            # Endpoint POST.\ndef predict(data: Input):                        # FastAPI valida autom\u00e1ticamente.\n    X = pd.DataFrame([data.dict()])              # Convierte a DataFrame.\n    pred = model.predict(X)                      # Predice.\n    return {\"prediction\": int(pred[0])}          # Retorna JSON.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-42-health-checks","title":"Pregunta 42: Health Checks","text":"<p>\u00bfPor qu\u00e9 tener /health endpoint?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_41","title":"Respuesta:","text":"<pre><code>@app.get(\"/health\")                              # GET endpoint para health checks.\ndef health():\n    return {\n        \"status\": \"healthy\",                     # Estado general.\n        \"model_loaded\": model is not None,       # Verifica que modelo carg\u00f3.\n        \"version\": \"1.0.0\"                       # Versi\u00f3n para debugging.\n    }\n</code></pre> <p>Kubernetes usa esto para saber si el pod est\u00e1 listo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-43-uvicorn-y-asgi","title":"Pregunta 43: Uvicorn y ASGI","text":"<p>\u00bfQu\u00e9 es uvicorn y por qu\u00e9 usarlo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_42","title":"Respuesta:","text":"<p>Uvicorn = servidor ASGI (Asynchronous Server Gateway Interface) de alto rendimiento.</p> <pre><code># Desarrollo\nuvicorn app.fastapi_app:app --reload --port 8000  # --reload: hot reload con cambios.\n\n# Producci\u00f3n\nuvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000 --workers 4  # --workers: procesos paralelos.\n</code></pre> <p>Configuraci\u00f3n para producci\u00f3n: <pre><code># Con gunicorn + uvicorn workers\ngunicorn app.fastapi_app:app \\                   # gunicorn: gestor de procesos.\n    --workers 4 \\                                # 4 procesos worker.\n    --worker-class uvicorn.workers.UvicornWorker \\  # Workers ASGI.\n    --bind 0.0.0.0:8000                          # Puerto y host.\n</code></pre></p> <p>ASGI vs WSGI: | WSGI | ASGI | |------|------| | Sync only | Async + Sync | | Flask, Django | FastAPI, Starlette | | Una request a la vez por worker | M\u00faltiples requests concurrentes |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-44-cors-configuration","title":"Pregunta 44: CORS Configuration","text":"<p>\u00bfC\u00f3mo manejas CORS en FastAPI?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_43","title":"Respuesta:","text":"<p>CORS = Cross-Origin Resource Sharing. Necesario cuando frontend y backend est\u00e1n en dominios distintos.</p> <pre><code>from fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware  # Middleware para CORS.\n\napp = FastAPI()\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[                              # Or\u00edgenes permitidos.\n        \"http://localhost:3000\",                 # React dev.\n        \"https://myapp.example.com\",             # Producci\u00f3n.\n    ],\n    allow_credentials=True,                      # Permite cookies.\n    allow_methods=[\"GET\", \"POST\"],               # M\u00e9todos HTTP permitidos.\n    allow_headers=[\"*\"],                         # Headers permitidos.\n)\n</code></pre> <p>En producci\u00f3n: Especificar or\u00edgenes exactos, no usar <code>\"*\"</code>.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-45-async-en-fastapi","title":"Pregunta 45: Async en FastAPI","text":"<p>\u00bfCu\u00e1ndo usar async def vs def?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_44","title":"Respuesta:","text":"<pre><code># Sync: operaciones CPU-bound o librer\u00edas sync\n@app.post(\"/predict\")\ndef predict(data: Input):                       # def: s\u00edncrono.\n    result = model.predict(data)                 # sklearn es sync, no usar async.\n    return {\"prediction\": result}\n\n# Async: operaciones I/O-bound\n@app.get(\"/external-data\")\nasync def get_external():                        # async def: as\u00edncrono.\n    async with httpx.AsyncClient() as client:   # Cliente HTTP as\u00edncrono.\n        response = await client.get(\"https://api.example.com/data\")  # await: espera sin bloquear.\n    return response.json()\n</code></pre> <p>Regla general: | Operaci\u00f3n | Usar | |-----------|------| | sklearn, pandas, joblib | <code>def</code> (sync) | | HTTP requests, DB async | <code>async def</code> | | File I/O masivo | <code>async def</code> con aiofiles |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-46-model-caching","title":"Pregunta 46: Model Caching","text":"<p>\u00bfC\u00f3mo evitas cargar el modelo en cada request?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_45","title":"Respuesta:","text":"<pre><code># FastAPI: lru_cache\nfrom functools import lru_cache                  # Cache de funciones.\n\n@lru_cache()                                     # Cachea resultado de la funci\u00f3n.\ndef get_model():\n    return joblib.load(\"artifacts/pipeline.joblib\")  # Solo carga una vez.\n\n@app.post(\"/predict\")\ndef predict(data: Input):\n    model = get_model()                          # Primera vez: carga. Resto: cache.\n    return model.predict(data)\n\n# Alternativa: cargar al inicio\nmodel = None\n\n@app.on_event(\"startup\")                         # Se ejecuta al iniciar app.\nasync def load_model():\n    global model                                 # Modifica variable global.\n    model = joblib.load(\"artifacts/pipeline.joblib\")\n</code></pre> <p>Streamlit: <pre><code>@st.cache_resource                               # Cache persistente entre reruns.\ndef load_model():\n    return joblib.load(\"artifacts/pipeline.joblib\")  # Solo carga una vez.\n\nmodel = load_model()                             # Cacheado entre interacciones.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-47-streamlit-dashboard","title":"Pregunta 47: Streamlit Dashboard","text":"<p>\u00bfC\u00f3mo creas un dashboard de predicci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_46","title":"Respuesta:","text":"<pre><code>import streamlit as st\nimport pandas as pd\n\nst.title(\"\ud83c\udfe6 BankChurn Predictor\")                # T\u00edtulo de la app.\n\n# Sidebar para inputs\nst.sidebar.header(\"Customer Data\")               # Header en sidebar.\ncredit_score = st.sidebar.slider(\"Credit Score\", 300, 850, 650)  # Slider con rango.\nage = st.sidebar.slider(\"Age\", 18, 100, 35)      # Valor default: 35.\ngeography = st.sidebar.selectbox(\"Geography\", [\"France\", \"Germany\", \"Spain\"])  # Dropdown.\n\n# Cargar modelo (cacheado)\n@st.cache_resource                               # Cache para recursos pesados.\ndef load_model():\n    return joblib.load(\"artifacts/pipeline.joblib\")\n\nmodel = load_model()                             # Carga una sola vez.\n\n# Predicci\u00f3n\nif st.sidebar.button(\"Predict\"):                 # Bot\u00f3n que dispara predicci\u00f3n.\n    input_df = pd.DataFrame([{                   # Crea DataFrame de entrada.\n        \"CreditScore\": credit_score,\n        \"Age\": age,\n        \"Geography\": geography\n    }])\n\n    prediction = model.predict(input_df)[0]      # Predicci\u00f3n binaria.\n    proba = model.predict_proba(input_df)[0, 1]  # Probabilidad de clase 1.\n\n    col1, col2 = st.columns(2)                   # Layout en 2 columnas.\n    col1.metric(\"Prediction\", \"Churn\" if prediction else \"Stay\")  # Muestra resultado.\n    col2.metric(\"Probability\", f\"{proba:.1%}\")   # Probabilidad formateada.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-48-docker-compose-para-ml","title":"Pregunta 48: Docker Compose para ML","text":"<p>\u00bfC\u00f3mo orquestas m\u00faltiples servicios?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_47","title":"Respuesta:","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  api:\n    build: .                                     # Construye desde Dockerfile local.\n    ports:\n      - \"8000:8000\"                              # host:container.\n    environment:\n      - MODEL_PATH=/app/artifacts/pipeline.joblib  # Variable de entorno.\n    volumes:\n      - ./artifacts:/app/artifacts:ro            # ro: read-only.\n    depends_on:\n      - mlflow                                   # Espera a que mlflow inicie.\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]  # Health check.\n      interval: 30s                              # Cada 30 segundos.\n      timeout: 10s\n      retries: 3\n\n  mlflow:\n    image: python:3.11-slim                      # Imagen base.\n    command: mlflow server --host 0.0.0.0        # Comando de inicio.\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - ./mlruns:/mlflow/mlruns                  # Persistencia de experimentos.\n\n  prometheus:\n    image: prom/prometheus                       # Imagen oficial.\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml  # Config.\n</code></pre> <pre><code>docker-compose up -d                            # -d: detached (background).\ndocker-compose logs -f api                      # -f: follow logs en tiempo real.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-49-kubernetes-deployment","title":"Pregunta 49: Kubernetes Deployment","text":"<p>\u00bfC\u00f3mo despliegas en Kubernetes?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_48","title":"Respuesta:","text":"<pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment                                # Tipo de recurso K8s.\nmetadata:\n  name: bankchurn-api\nspec:\n  replicas: 3                                   # 3 instancias del pod.\n  selector:\n    matchLabels:\n      app: bankchurn-api                        # Selector para pods.\n  template:\n    metadata:\n      labels:\n        app: bankchurn-api\n    spec:\n      containers:\n      - name: api\n        image: bankchurn-api:v1.0.0             # Imagen Docker.\n        ports:\n        - containerPort: 8000                   # Puerto interno.\n        resources:\n          requests:                             # M\u00ednimo garantizado.\n            memory: \"256Mi\"\n            cpu: \"250m\"                         # 0.25 CPU.\n          limits:                               # M\u00e1ximo permitido.\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:                          # Verifica si pod est\u00e1 vivo.\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30               # Espera antes de primer check.\n          periodSeconds: 10                     # Cada 10 segundos.\n        readinessProbe:                         # Verifica si puede recibir tr\u00e1fico.\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service                                   # Expone pods como servicio.\nmetadata:\n  name: bankchurn-api\nspec:\n  selector:\n    app: bankchurn-api                          # Conecta con pods del Deployment.\n  ports:\n  - port: 80                                    # Puerto externo.\n    targetPort: 8000                            # Puerto del contenedor.\n  type: LoadBalancer                            # Expone externamente con LB.\n</code></pre> <pre><code>kubectl apply -f deployment.yaml                # Aplica configuraci\u00f3n.\nkubectl get pods                                # Lista pods.\nkubectl logs -f deployment/bankchurn-api        # Ver logs en tiempo real.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-50-horizontal-pod-autoscaler","title":"Pregunta 50: Horizontal Pod Autoscaler","text":"<p>\u00bfC\u00f3mo escalas autom\u00e1ticamente?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_49","title":"Respuesta:","text":"<pre><code># hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler                   # Autoescalador horizontal.\nmetadata:\n  name: bankchurn-api-hpa\nspec:\n  scaleTargetRef:                               # Deployment a escalar.\n    apiVersion: apps/v1\n    kind: Deployment\n    name: bankchurn-api\n  minReplicas: 2                                # M\u00ednimo 2 pods.\n  maxReplicas: 10                               # M\u00e1ximo 10 pods.\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70                  # Escala si CPU &gt; 70%.\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80                  # Escala si memoria &gt; 80%.\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300           # Espera 5 min antes de reducir.\n    scaleUp:\n      stabilizationWindowSeconds: 60            # Escala up m\u00e1s r\u00e1pido (1 min).\n</code></pre> <pre><code>kubectl apply -f hpa.yaml                       # Aplica HPA.\nkubectl get hpa                                 # Ver estado del autoescalador.\n# NAME                  REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS\n# bankchurn-api-hpa     Deployment/bankchurn   45%/70%   2         10        3  # 45% actual, 70% target.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#5-escenarios-pr\u00e1cticos-preguntas-51-60","title":"5. Escenarios Pr\u00e1cticos (Preguntas 51-60)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-51-debug-de-produccion","title":"Pregunta 51: Debug de Producci\u00f3n","text":"<p>El modelo tiene accuracy 85% en dev pero 60% en prod. \u00bfPor qu\u00e9?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_50","title":"Respuesta:","text":"<ol> <li>Data drift: Distribuci\u00f3n de datos cambi\u00f3</li> <li>Feature mismatch: Features procesadas diferente</li> <li>Training-serving skew: Preprocesamiento distinto</li> <li>Datos de prod con m\u00e1s ruido: Edge cases no vistos</li> </ol> <p>Acciones: Comparar distribuciones, revisar pipeline, logging de inputs.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-52-code-review","title":"Pregunta 52: Code Review","text":"<p>\u00bfQu\u00e9 buscas en un code review de ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_51","title":"Respuesta:","text":"<ul> <li>[ ] Data leakage en split/preprocessing</li> <li>[ ] Tests para features y modelo</li> <li>[ ] Config externalizada (no hardcoded)</li> <li>[ ] Type hints y docstrings</li> <li>[ ] Reproducibilidad (seeds, versiones)</li> <li>[ ] Logging apropiado</li> </ul>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-53-explicabilidad-del-modelo","title":"Pregunta 53: Explicabilidad del Modelo","text":"<p>El cliente dice: \"No puedo usar tu modelo si no me explicas por qu\u00e9 toma las decisiones\".</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_52","title":"Respuesta:","text":"<pre><code>import shap\n\n# 1. SHAP para explicaciones individuales\nexplainer = shap.TreeExplainer(model)         # Explainer para modelos de \u00e1rboles.\nshap_values = explainer.shap_values(X_sample) # Calcula contribuci\u00f3n de cada feature.\n\n# Waterfall plot para una predicci\u00f3n\nshap.waterfall_plot(shap.Explanation(         # Visualiza contribuciones.\n    values=shap_values[0],                    # Valores SHAP de una predicci\u00f3n.\n    base_values=explainer.expected_value,     # Valor base (promedio).\n    data=X_sample.iloc[0]                     # Valores reales de features.\n))\n\n# 2. Feature importance global\nshap.summary_plot(shap_values, X_sample)      # Resumen de todas las predicciones.\n\n# 3. En producci\u00f3n: incluir en respuesta\n@app.post(\"/predict\")\ndef predict(data: Input):\n    pred = model.predict(X)[0]\n\n    # Top 3 razones\n    shap_vals = explainer.shap_values(X)\n    top_features = sorted(                    # Ordena por impacto.\n        zip(feature_names, shap_vals[0]),\n        key=lambda x: abs(x[1]),              # Valor absoluto del impacto.\n        reverse=True\n    )[:3]                                     # Solo top 3.\n\n    return {\n        \"prediction\": pred,\n        \"explanation\": [                      # Explicaci\u00f3n en respuesta.\n            {\"feature\": f, \"impact\": v} \n            for f, v in top_features\n        ]\n    }\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-54-optimizacion-de-latencia","title":"Pregunta 54: Optimizaci\u00f3n de Latencia","text":"<p>El modelo tarda 500ms por predicci\u00f3n. El negocio necesita &lt;100ms.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_53","title":"Respuesta:","text":"<pre><code># 1. Profiling: \u00bfd\u00f3nde est\u00e1 el cuello de botella?\nimport cProfile\ncProfile.run('model.predict(X_sample)')       # Identifica funciones lentas.\n\n# 2. Opciones de optimizaci\u00f3n:\n\n# a) Modelo m\u00e1s ligero\nfrom sklearn.linear_model import LogisticRegression  # LR es 10x m\u00e1s r\u00e1pido que RF.\n\n# b) Reducir features\nfrom sklearn.feature_selection import SelectKBest\nselector = SelectKBest(k=10)                  # Solo top 10 features = menos c\u00e1lculo.\n\n# c) Batch predictions\n@app.post(\"/predict/batch\")\ndef predict_batch(items: List[Input]):\n    X = pd.DataFrame([item.dict() for item in items])\n    preds = model.predict(X)                  # Una llamada = menos overhead.\n    return {\"predictions\": preds.tolist()}\n\n# d) Caching de predicciones frecuentes\nfrom functools import lru_cache\n\n@lru_cache(maxsize=1000)                      # Cache \u00faltimas 1000 predicciones.\ndef predict_cached(credit_score: int, age: int):\n    return model.predict([[credit_score, age]])[0]  # Cache hit = instant\u00e1neo.\n\n# e) ONNX para inferencia r\u00e1pida\nfrom skl2onnx import convert_sklearn          # Convierte a formato optimizado.\nonnx_model = convert_sklearn(model, initial_types=[...])  # Runtime m\u00e1s r\u00e1pido.\n</code></pre> <p>M\u00e9tricas de latencia: | Optimizaci\u00f3n | Latencia t\u00edpica | |--------------|-----------------| | RF sklearn | 50-200ms | | LR sklearn | 1-5ms | | ONNX | 1-10ms | | Caching (hit) | &lt;1ms |</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-55-manejo-de-pii","title":"Pregunta 55: Manejo de PII","text":"<p>El dataset contiene nombres, emails y tel\u00e9fonos. \u00bfC\u00f3mo lo manejas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_54","title":"Respuesta:","text":"<pre><code># 1. Identificar columnas PII\npii_columns = [\"name\", \"email\", \"phone\", \"ssn\", \"address\"]  # Datos sensibles.\n\n# 2. Anonimizaci\u00f3n\nimport hashlib\n\ndef anonymize_pii(df: pd.DataFrame) -&gt; pd.DataFrame:\n    df = df.copy()\n    for col in pii_columns:\n        if col in df.columns:\n            df[col] = df[col].apply(          # Hash irreversible.\n                lambda x: hashlib.sha256(str(x).encode()).hexdigest()[:16]\n            )                                 # No se puede revertir.\n    return df\n\n# 3. Drop antes de training (mejor opci\u00f3n)\nX = df.drop(columns=pii_columns, errors='ignore')  # Elimina PII del modelo.\n\n# 4. En logs: nunca loggear PII\nlogger.info(f\"Prediction for customer {customer_id[:4]}***\")  # Mascara ID.\n\n# 5. En respuestas de API: mascarar\ndef mask_email(email: str) -&gt; str:\n    parts = email.split(\"@\")\n    return f\"{parts[0][:2]}***@{parts[1]}\"   # jo***@gmail.com.\n</code></pre> <p>Compliance checklist: - [ ] PII no est\u00e1 en features del modelo - [ ] PII no aparece en logs - [ ] PII no se almacena en MLflow/tracking - [ ] Acceso a datos restringido</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-56-fairness-y-bias","title":"Pregunta 56: Fairness y Bias","text":"<p>Producto detect\u00f3 que el modelo rechaza m\u00e1s a clientes de cierta regi\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_55","title":"Respuesta:","text":"<pre><code>from fairlearn.metrics import MetricFrame      # Fairlearn: librer\u00eda de fairness.\nfrom sklearn.metrics import accuracy_score, recall_score\n\n# 1. Calcular m\u00e9tricas por grupo\nmetrics = MetricFrame(\n    metrics={\n        \"accuracy\": accuracy_score,\n        \"recall\": recall_score\n    },\n    y_true=y_test,\n    y_pred=y_pred,\n    sensitive_features=df_test[\"geography\"]   # Variable sensible.\n)\n\nprint(metrics.by_group)                        # M\u00e9tricas por grupo.\n#              accuracy  recall\n# geography\n# France         0.85     0.80\n# Germany        0.83     0.78\n# Spain          0.70     0.55                 # \u2190 Problema: peor para Spain.\n\n# 2. Mitigaci\u00f3n\nfrom fairlearn.reductions import ExponentiatedGradient  # Algoritmo de mitigaci\u00f3n.\nfrom fairlearn.constraints import DemographicParity     # Restricci\u00f3n de fairness.\n\nmitigator = ExponentiatedGradient(\n    estimator=base_model,\n    constraints=DemographicParity()            # Igualar tasas entre grupos.\n)\nmitigator.fit(X_train, y_train, sensitive_features=train_geography)\n\n# 3. Monitoreo continuo\n# Alertar si la diferencia entre grupos &gt; 10%  # Dashboard de fairness.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-57-tests-flaky-en-ci","title":"Pregunta 57: Tests Flaky en CI","text":"<p>El CI pasa 80% de las veces y falla 20% sin cambios en c\u00f3digo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_56","title":"Respuesta:","text":"<pre><code># 1. Problema com\u00fan: Random sin seed\n# \u274c Mal\nmodel = RandomForestClassifier()              # Sin seed: resultados diferentes cada vez.\n\n# \u2705 Bien\nmodel = RandomForestClassifier(random_state=42)  # Seed fija: resultados reproducibles.\n\n# 2. Problema: Orden de ejecuci\u00f3n\n# \u274c Mal: test depende de otro\ndef test_predict():\n    assert model.predict(X) == [1]            # model de test anterior: dependencia oculta.\n\n# \u2705 Bien: tests aislados\n@pytest.fixture\ndef trained_model():                          # Fixture crea modelo fresco.\n    m = Model()\n    m.fit(X, y)\n    return m\n\ndef test_predict(trained_model):              # Test recibe su propio modelo.\n    assert trained_model.predict(X)\n\n# 3. Problema: Timeouts en CI\n# \u274c Mal\nrequests.get(\"https://external-api.com\", timeout=5)  # API externa puede fallar.\n\n# \u2705 Bien\n@pytest.fixture\ndef mock_api():                               # Mock evita llamadas externas.\n    with patch(\"myapp.api.get\") as mock:\n        mock.return_value = {\"data\": \"test\"}\n        yield mock\n\n# 4. Debug: Correr m\u00faltiples veces\npytest tests/ --count=10                      # pytest-repeat: detecta tests flaky.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-58-modelo-grande-para-deploy","title":"Pregunta 58: Modelo Grande para Deploy","text":"<p>El modelo pesa 2GB y tarda 30s en cargar. \u00bfC\u00f3mo optimizas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_57","title":"Respuesta:","text":"<pre><code># 1. Quantization (reducir precisi\u00f3n)\nimport onnxruntime as ort\nfrom onnxruntime.quantization import quantize_dynamic\n\nquantize_dynamic(\n    \"model.onnx\",\n    \"model_quantized.onnx\",\n    weight_type=ort.QuantType.QInt8             # 8-bit en vez de 32-bit.\n)\n# 2GB \u2192 ~500MB                                  # 4x reducci\u00f3n de tama\u00f1o.\n\n# 2. Model distillation (modelo m\u00e1s peque\u00f1o que imita al grande)\nteacher = load_large_model()                    # Modelo grande y lento.\nstudent = SmallModel()                          # Modelo peque\u00f1o y r\u00e1pido.\n\n# Entrenar student con outputs del teacher\nstudent_preds = student(X)\nteacher_preds = teacher(X)                      # Student aprende a imitar teacher.\nloss = mse_loss(student_preds, teacher_preds)   # Minimiza diferencia.\n\n# 3. Feature selection (menos features = modelo m\u00e1s peque\u00f1o)\nfrom sklearn.feature_selection import SelectFromModel\nselector = SelectFromModel(model, threshold=\"median\")  # Selecciona features importantes.\nX_reduced = selector.transform(X)               # Menos columnas = modelo m\u00e1s ligero.\n\n# 4. Lazy loading en API\nmodel = None\n\n@app.on_event(\"startup\")                        # Carga al iniciar, no en cada request.\nasync def load():\n    global model\n    model = joblib.load(\"model.joblib\")         # Solo una vez, cacheado.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-59-muchos-falsos-positivos","title":"Pregunta 59: Muchos Falsos Positivos","text":"<p>El modelo predice churn para clientes que claramente no van a irse.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_58","title":"Respuesta:","text":"<pre><code># 1. Ajustar threshold (default=0.5)\ny_proba = model.predict_proba(X_test)[:, 1]     # Probabilidades de clase 1.\n\n# Encontrar threshold \u00f3ptimo\nfrom sklearn.metrics import precision_recall_curve\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n\n# Threshold que maximiza F1\nf1_scores = 2 * (precision * recall) / (precision + recall)  # F\u00f3rmula F1.\noptimal_threshold = thresholds[np.argmax(f1_scores)]  # Mejor threshold.\nprint(f\"Optimal threshold: {optimal_threshold}\")  # Ej: 0.65 en vez de 0.5.\n\n# Usar nuevo threshold\ny_pred = (y_proba &gt;= optimal_threshold).astype(int)  # Threshold m\u00e1s alto = menos FP.\n\n# 2. Revisar balance de datos\nprint(y_train.value_counts(normalize=True))     # Ver proporciones de clases.\n# Si muy desbalanceado: SMOTE, class_weight     # T\u00e9cnicas de balanceo.\n\n# 3. Verificar data leakage\n# \u00bfHay features que \"predicen perfectamente\"?\nfor col in X.columns:\n    corr = X[col].corr(y)\n    if abs(corr) &gt; 0.9:                         # Correlaci\u00f3n sospechosa.\n        print(f\"\u26a0\ufe0f {col} tiene correlaci\u00f3n {corr}\")  # Posible leakage.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#pregunta-60-comunicar-a-stakeholders-no-tecnicos","title":"Pregunta 60: Comunicar a Stakeholders No T\u00e9cnicos","text":"<p>El VP de producto pregunta: \"\u00bfFunciona o no funciona tu modelo?\"</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#respuesta_59","title":"Respuesta:","text":"<pre><code># 1. Traducir m\u00e9tricas t\u00e9cnicas a impacto de negocio\n\"\"\"\n\u274c Mal: \"El modelo tiene AUC 0.85 y F1 0.78\"  # T\u00e9rminos que no entienden.\n\n\u2705 Bien:                                        # Lenguaje de negocio.\n\"Por cada 100 clientes que van a hacer churn:\n- Detectamos 78 antes de que se vayan          # Recall en lenguaje simple.\n- De los que marcamos como riesgo, 82% efectivamente se iban  # Precision.\n\nImpacto: Si cada cliente perdido cuesta $500,\nel modelo puede prevenir $31,200 en p\u00e9rdidas mensuales  # $$$\n(78 clientes \u00d7 $500 \u00d7 80% tasa de retenci\u00f3n con intervenci\u00f3n)\"\n\"\"\"\n\n# 2. Visualizaciones claras\nimport plotly.express as px                     # Plotly: gr\u00e1ficos interactivos.\n\n# Confusion matrix visual\nfig = px.imshow(\n    [[TN, FP], [FN, TP]],                       # Matriz de confusi\u00f3n.\n    labels=dict(x=\"Predicted\", y=\"Actual\"),\n    x=[\"Stay\", \"Churn\"],\n    y=[\"Stay\", \"Churn\"],\n    text_auto=True                              # Muestra n\u00fameros en celdas.\n)\nfig.show()\n\n# 3. Dashboard ejecutivo en Streamlit\nst.metric(\"Clientes en Riesgo\", \"234\", delta=\"-12 vs mes pasado\")  # KPI con delta.\nst.metric(\"Precision Retenci\u00f3n\", \"82%\", delta=\"+5%\")  # M\u00e9trica clave.\nst.metric(\"Ahorro Estimado\", \"$45,000/mes\")     # Impacto en dinero.\n</code></pre> <p>Regla de oro: Siempre conectar con dinero o KPIs que el stakeholder ya conoce.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_MID/#recursos","title":"\ud83d\udcda Recursos","text":"Tema M\u00f3dulo Pipelines 07_SKLEARN_PIPELINES.md Testing 11_TESTING_ML.md CI/CD 12_CI_CD.md Docker 13_DOCKER.md FastAPI 14_FASTAPI.md MLflow 10_EXPERIMENT_TRACKING.md   **\u00a1\u00c9xito en tu entrevista! \ud83d\ude80**  [\u2190 Simulacro Junior](SIMULACRO_ENTREVISTA_JUNIOR.md) | [Simulacro Senior \u2192](SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md)"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/","title":"\ud83c\udfaf Simulacro de Entrevista Lead/Senior ML Engineer","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#portafolio-mlops-100-preguntas-tecnicas-y-conceptuales","title":"Portafolio MLOps \u2014 100+ Preguntas T\u00e9cnicas y Conceptuales","text":"<p>Autor del Portafolio: Daniel Duque (DuqueOM) Versi\u00f3n: 1.0 Fecha: Noviembre 2025  </p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ol> <li>Fundamentos de ML</li> <li>MLOps y Ciclo de Vida</li> <li>BankChurn-Predictor</li> <li>CarVision-Market-Intelligence</li> <li>TelecomAI-Customer-Intelligence</li> <li>Arquitectura y Dise\u00f1o</li> <li>CI/CD y DevOps</li> <li>Infraestructura K8s/Docker</li> <li>\u00c9tica y Fairness</li> <li>Liderazgo y Escenarios</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#1-fundamentos-de-machine-learning-preguntas-1-15","title":"1. Fundamentos de Machine Learning (Preguntas 1-15)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-1-data-leakage","title":"Pregunta 1: Data Leakage","text":"<p>\u00bfQu\u00e9 es el data leakage y c\u00f3mo lo preveniste?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta","title":"Respuesta:","text":"<p>El data leakage ocurre cuando informaci\u00f3n del test set o target filtra al training.</p> <p>Prevenci\u00f3n en BankChurn (<code>training.py:278-293</code>): <pre><code># CRITICAL: Split BEFORE fitting preprocessor\nX_train, X_test, y_train, y_test = train_test_split(X, y, ...)  # Split primero.\nself.preprocessor_ = self.build_preprocessor(X_train)  # Construye con train.\nX_train = self.preprocessor_.fit_transform(X_train)   # fit_transform: aprende de train.\nX_test = self.preprocessor_.transform(X_test)         # transform: aplica sin aprender.\n</code></pre></p> <p>En CarVision (<code>config.yaml</code>): <pre><code>drop_columns: [\"price_per_mile\", \"price_category\"]  # Dependen del target\n</code></pre></p> <p>Justificaci\u00f3n: El preprocesador (StandardScaler, OneHotEncoder) debe ajustarse exclusivamente con datos de training.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-2-class-imbalance","title":"Pregunta 2: Class Imbalance","text":"<p>\u00bfC\u00f3mo manejaste el desbalance 80/20 en churn?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_1","title":"Respuesta:","text":"<p>Implement\u00e9 m\u00faltiples estrategias en <code>ResampleClassifier</code> (<code>models.py</code>):</p> <pre><code>class ResampleClassifier(BaseEstimator, ClassifierMixin):  # Wrapper para resampling.\n    # strategy: {\"none\", \"oversample\", \"undersample\", \"class_weight\"}\n    def _apply_resampling(self, X, y):\n        if self.strategy == \"oversample\":             # Aumenta clase minoritaria.\n            return SMOTE(random_state=self.random_state).fit_resample(X, y)  # Sint\u00e9ticos.\n        elif self.strategy == \"undersample\":          # Reduce clase mayoritaria.\n            return RandomUnderSampler().fit_resample(X, y)\n</code></pre> <p>Estrategias adicionales: - <code>LogisticRegression(class_weight=\"balanced\")</code> - <code>RandomForestClassifier(class_weight=\"balanced_subsample\")</code> - F1-Score como m\u00e9trica primaria (equilibra precision-recall)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-3-ensemble-votingclassifier","title":"Pregunta 3: Ensemble VotingClassifier","text":"<p>Explica el VotingClassifier con pesos [0.4, 0.6].</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_2","title":"Respuesta:","text":"<pre><code>ensemble = VotingClassifier(\n    estimators=[(\"lr\", lr), (\"rf\", rf)],  # Lista de modelos.\n    voting=\"soft\",                         # soft: promedia probabilidades (mejor que hard).\n    weights=[0.4, 0.6]                     # RF pesa m\u00e1s por mejor AUC individual.\n)\n</code></pre> <p>Razones: 1. Soft voting: Aprovecha confianza del modelo (probabilidades) 2. RF (0.6): Mejor AUC individual, captura no-linealidades 3. LR (0.4): Regularizaci\u00f3n, interpretabilidad, buen baseline</p> <p>Complementariedad: LR asume linealidad, RF captura interacciones \u2192 combinaci\u00f3n reduce varianza.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-4-featureengineer-centralizado","title":"Pregunta 4: FeatureEngineer Centralizado","text":"<p>\u00bfC\u00f3mo garantizas consistencia entre training e inference?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_3","title":"Respuesta:","text":"<p>Clase <code>FeatureEngineer</code> como sklearn transformer (<code>features.py</code>):</p> <pre><code>class FeatureEngineer(BaseEstimator, TransformerMixin):  # Transformer custom.\n    def transform(self, X):\n        X = X.copy()                       # No modifica original.\n        if \"model_year\" in X.columns:      # Feature engineering condicional.\n            X[\"vehicle_age\"] = self.current_year - X[\"model_year\"]  # A\u00f1o actual - modelo.\n        if \"model\" in X.columns:\n            X[\"brand\"] = X[\"model\"].str.split().str[0]  # Extrae marca del nombre.\n        return X\n</code></pre> <p>Pipeline integrado: <pre><code>pipe = Pipeline([(\"features\", fe), (\"pre\", pre), (\"model\", model)])  # Pipeline completo.\njoblib.dump(pipe, \"model.joblib\")  # Serializa TODO junto: features + preproceso + modelo.\n</code></pre></p> <p>Beneficio: Single Source of Truth para training, API, dashboard.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-5-stratifiedkfold","title":"Pregunta 5: StratifiedKFold","text":"<p>\u00bfPor qu\u00e9 usaste StratifiedKFold?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_4","title":"Respuesta:","text":"<pre><code>cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Mantiene proporci\u00f3n de clases en cada fold.\n</code></pre> <p>Razones: 1. Preserva proporci\u00f3n: Con 80/20, KFold simple podr\u00eda generar folds 90/10 2. Representatividad: Cada fold simula distribuci\u00f3n de producci\u00f3n 3. Estabilidad: Reduce varianza entre folds</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-6-metricas-de-regresion","title":"Pregunta 6: M\u00e9tricas de Regresi\u00f3n","text":"<p>\u00bfCu\u00e1ndo priorizas RMSE vs MAE vs MAPE?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_5","title":"Respuesta:","text":"M\u00e9trica Priorizar cuando RMSE Errores grandes son costosos (penaliza outliers) MAE Robustez a outliers, interpretaci\u00f3n directa MAPE Comparaci\u00f3n entre escalas diferentes R\u00b2 Benchmarking vs baseline <p>En CarVision priorizo RMSE: Un error de $10K en auto de $5K es cr\u00edtico.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-7-imputation-strategies","title":"Pregunta 7: Imputation Strategies","text":"<p>\u00bfPor qu\u00e9 median para num\u00e9ricos y \"constant\" para categ\u00f3ricos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_6","title":"Respuesta:","text":"<pre><code># Num\u00e9ricos: robusta a outliers\n(\"imputer\", SimpleImputer(strategy=\"median\"))        # Mediana no se afecta por extremos.\n# Categ\u00f3ricos: categor\u00eda expl\u00edcita permite aprender patr\u00f3n de missing\n(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\"))  # \"missing\" es informativo.\n</code></pre> <p>Justificaci\u00f3n: <code>most_frequent</code> sesga hacia categor\u00eda dominante; \"missing\" es m\u00e1s informativo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-8-regularizacion-l2","title":"Pregunta 8: Regularizaci\u00f3n L2","text":"<p>\u00bfQu\u00e9 significa C=0.1 en LogisticRegression?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_7","title":"Respuesta:","text":"<pre><code>LogisticRegression(C=0.1, solver=\"liblinear\")        # C=0.1: regularizaci\u00f3n fuerte (C=1/\u03bb).\n</code></pre> <p>C = 1/\u03bb (inverso de regularizaci\u00f3n L2): - C bajo (0.1) = regularizaci\u00f3n fuerte \u2192 modelo simple, menos overfitting - C alto (10) = regularizaci\u00f3n d\u00e9bil \u2192 m\u00e1s flexibilidad</p> <p>Selecci\u00f3n: Incluido en espacio de b\u00fasqueda Optuna <code>[0.01, 10.0]</code> log scale.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-9-random-forest-hyperparameters","title":"Pregunta 9: Random Forest Hyperparameters","text":"<p>\u00bfPor qu\u00e9 max_depth=10 y min_samples_leaf=5?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_8","title":"Respuesta:","text":"Par\u00e1metro Valor Efecto <code>max_depth=10</code> L\u00edmite profundidad Previene memorizaci\u00f3n <code>min_samples_leaf=5</code> M\u00ednimo en hojas Evita hojas con 1-2 samples <code>n_estimators=100</code> \u00c1rboles Balance varianza/costo <p>Validaci\u00f3n: ~0.85 AUC con gap train-test &lt; 3%.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-10-gradientboosting-vs-randomforest","title":"Pregunta 10: GradientBoosting vs RandomForest","text":"<p>\u00bfPor qu\u00e9 GB en TelecomAI y RF en BankChurn?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_9","title":"Respuesta:","text":"Aspecto Random Forest Gradient Boosting Enfoque Bagging (paralelo) Boosting (secuencial) Dataset Grande (10K+) Peque\u00f1o (~2K) Features Mix cat/num Num\u00e9ricas simples <p>TelecomAI usa GB con <code>max_depth=2, lr=0.05</code>: muchos \u00e1rboles simples \u2192 regularizaci\u00f3n fuerte.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-11-cross-validation-con-logging","title":"Pregunta 11: Cross-Validation con Logging","text":"<p>\u00bfC\u00f3mo reportas resultados de CV?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_10","title":"Respuesta:","text":"<pre><code>for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), 1):  # Itera folds.\n    fold_f1 = f1_score(y_fold_val, y_pred, average=\"weighted\")  # M\u00e9trica por fold.\n    cv_scores.append(fold_f1)\n    logger.info(f\"Fold {fold}/{n_folds}: F1 = {fold_f1:.4f}\")   # Log cada fold.\n\nlogger.info(f\"CV Mean F1: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")  # Resumen.\n</code></pre> <p>M\u00e9tricas reportadas: Media \u00b1 desviaci\u00f3n est\u00e1ndar para evaluar estabilidad.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-12-threshold-selection","title":"Pregunta 12: Threshold Selection","text":"<p>\u00bfC\u00f3mo elegiste el threshold de clasificaci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_11","title":"Respuesta:","text":"<pre><code># prediction.py\ndef predict(self, X, threshold=0.5):            # Threshold configurable.\n    results[\"prediction\"] = (results[\"probability\"] &gt;= threshold).astype(int)  # Binario.\n    results[\"risk_level\"] = pd.cut(results[\"probability\"],  # Categor\u00edas de riesgo.\n        bins=[0, 0.3, 0.7, 1.0], labels=[\"low\", \"medium\", \"high\"])\n</code></pre> <p>Default 0.5, pero configurable v\u00eda API. En producci\u00f3n: - Si costo de FN alto \u2192 bajar threshold (m\u00e1s recall) - Si costo de FP alto \u2192 subir threshold (m\u00e1s precision)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-13-feature-importance","title":"Pregunta 13: Feature Importance","text":"<p>\u00bfC\u00f3mo calculas y usas feature importance?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_12","title":"Respuesta:","text":"<pre><code># evaluation.py - error_analysis\nfeature_importance: true  # En config\n\n# RandomForest tiene .feature_importances_\n# Para ensemble, extraemos de sub-modelos\n</code></pre> <p>Uso: Identificar features dominantes, detectar posibles data leakage, explicabilidad al negocio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-14-calibration","title":"Pregunta 14: Calibration","text":"<p>\u00bfQu\u00e9 es la calibraci\u00f3n de probabilidades?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_13","title":"Respuesta:","text":"<p>Del Model Card: <pre><code>## Calibration\n- Platt (sigmoid) sobre el modelo final (cv=\"prefit\")\n</code></pre></p> <p>Problema: <code>predict_proba()</code> puede dar probabilidades que no reflejan frecuencia real. Soluci\u00f3n: <code>CalibratedClassifierCV</code> ajusta probabilidades para que 0.7 signifique ~70% de positivos reales.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-15-baseline-comparison","title":"Pregunta 15: Baseline Comparison","text":"<p>\u00bfC\u00f3mo comparas tu modelo contra un baseline?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_14","title":"Respuesta:","text":"<pre><code># evaluation.py (CarVision)\ndummy = DummyRegressor(strategy=\"median\")\ndummy.fit(X_train, y_train)\nbaseline_metrics = {\"rmse\": rmse(y_test, dummy.predict(X_test))}\n</code></pre> <p>Bootstrap para significancia estad\u00edstica: <pre><code>delta_rmse_mean = modelo - baseline\np_value_two_sided  # Si &lt; 0.05, diferencia significativa\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#2-mlops-y-ciclo-de-vida-preguntas-16-30","title":"2. MLOps y Ciclo de Vida (Preguntas 16-30)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-16-mlflow-integration","title":"Pregunta 16: MLflow Integration","text":"<p>\u00bfC\u00f3mo integraste MLflow?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_15","title":"Respuesta:","text":"<pre><code># training.py\nif self.config.mlflow.enabled:                   # Condicional por config.\n    mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)  # D\u00f3nde guardar.\n    mlflow.set_experiment(self.config.mlflow.experiment_name)  # Nombre experimento.\n\nwith mlflow.start_run():                         # Context manager para run.\n    mlflow.log_params(self.config.model.dict())  # Hiperpar\u00e1metros.\n    mlflow.log_metrics(metrics)                  # M\u00e9tricas de evaluaci\u00f3n.\n</code></pre> <p>Config (<code>config.yaml</code>): <pre><code>mlflow:\n  tracking_uri: \"file:./mlruns\"  # Local\n  experiment_name: \"bankchurn-experiment\"\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-17-reproducibilidad-con-seeds","title":"Pregunta 17: Reproducibilidad con Seeds","text":"<p>\u00bfC\u00f3mo garantizas reproducibilidad?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_16","title":"Respuesta:","text":"<pre><code># common_utils/seed.py\ndef set_seed(seed=None):\n    seed = seed or os.getenv(\"SEED\") or 42       # Prioridad: arg &gt; env &gt; default.\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)     # Hash de Python.\n    random.seed(seed)                            # M\u00f3dulo random.\n    np.random.seed(seed)                         # NumPy.\n    # PyTorch/TensorFlow si instalados\n    return seed                                  # Retorna seed usada.\n</code></pre> <p>Uso en todos los proyectos: <pre><code>seed_used = set_seed(args.seed)\nlogger.info(f\"Using seed: {seed_used}\")\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-18-configuration-con-pydantic","title":"Pregunta 18: Configuration con Pydantic","text":"<p>Explica tu sistema de configuraci\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_17","title":"Respuesta:","text":"<pre><code># config.py\nclass ModelConfig(BaseModel):                    # Config anidada.\n    test_size: float = Field(0.2, ge=0.0, le=1.0)  # Validaci\u00f3n de rango.\n    cv_folds: int = Field(5, ge=2)               # M\u00ednimo 2 folds.\n\nclass BankChurnConfig(BaseModel):                # Config ra\u00edz.\n    model: ModelConfig                           # Configs anidadas.\n    data: DataConfig\n    mlflow: MLflowConfig\n\n    @classmethod\n    def from_yaml(cls, path):                    # Factory method.\n        with open(path) as f:\n            return cls(**yaml.safe_load(f))      # YAML \u2192 Pydantic.\n</code></pre> <p>Beneficios: Validaci\u00f3n autom\u00e1tica, valores por defecto, type hints, serializaci\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-19-model-versioning","title":"Pregunta 19: Model Versioning","text":"<p>\u00bfC\u00f3mo versionas modelos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_18","title":"Respuesta:","text":"<ol> <li>Naming: <code>models/model_v1.0.0.pkl</code></li> <li>Metadata JSON: commit_sha, m\u00e9tricas, timestamp</li> <li>K8s ConfigMap: <code>MODEL_VERSION: \"v2.0.0\"</code></li> <li>Docker tags: <code>bankchurn:v1.0.0</code></li> <li>MLflow Registry: Staging \u2192 Production</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-20-dvc-data-versioning","title":"Pregunta 20: DVC Data Versioning","text":"<p>\u00bfPor qu\u00e9 DVC?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_19","title":"Respuesta:","text":"<pre><code>dvc add data/raw/Churn.csv\ngit add data/raw/Churn.csv.dvc .gitignore\ndvc push  # A storage remoto\n</code></pre> <p>Beneficios: Cada commit Git tiene snapshot exacto de datos, sin almacenarlos en Git.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-21-pipeline-como-artefacto-unico","title":"Pregunta 21: Pipeline como Artefacto \u00danico","text":"<p>\u00bfPor qu\u00e9 empaquetar preprocessor + model?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_20","title":"Respuesta:","text":"<pre><code>pipeline = Pipeline([(\"preprocess\", pre), (\"clf\", clf)])  # Pipeline completo.\njoblib.dump(pipeline, \"model.joblib\")            # Un solo archivo.\n</code></pre> <p>Deployment simplificado: <pre><code>pipe = joblib.load(\"model.joblib\")               # Carga todo.\npred = pipe.predict(raw_df)                      # predict() hace preproceso + predicci\u00f3n.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-22-health-checks","title":"Pregunta 22: Health Checks","text":"<p>\u00bfC\u00f3mo implementaste health checks?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_21","title":"Respuesta:","text":"<pre><code>@app.get(\"/health\")                              # Endpoint para health checks.\nasync def health_check():\n    return {\"status\": \"healthy\" if predictor else \"degraded\",  # Estado basado en modelo.\n            \"model_loaded\": predictor is not None}  # Info adicional.\n</code></pre> <p>K8s probes: <pre><code>livenessProbe:\n  httpGet: {path: /health, port: 8000}\n  initialDelaySeconds: 30\nreadinessProbe:\n  httpGet: {path: /health, port: 8000}\n  initialDelaySeconds: 10\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-23-model-loading-strategy","title":"Pregunta 23: Model Loading Strategy","text":"<p>\u00bfC\u00f3mo cargas el modelo en FastAPI?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_22","title":"Respuesta:","text":"<pre><code>@contextlib.asynccontextmanager                  # Context manager as\u00edncrono.\nasync def lifespan(app: FastAPI):\n    global predictor\n    predictor = load_model_logic()               # Carga al iniciar app.\n    yield                                        # App corre aqu\u00ed.\n    # Cleanup al cerrar (si necesario).\n\napp = FastAPI(lifespan=lifespan)                 # Usa lifespan en app.\n</code></pre> <p>Beneficio: Carga \u00fanica, no por request. Fail-fast friendly.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-24-batch-prediction","title":"Pregunta 24: Batch Prediction","text":"<p>\u00bfC\u00f3mo manejas predicciones batch?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_23","title":"Respuesta:","text":"<pre><code>@app.post(\"/predict_batch\")                      # Endpoint para batch.\nasync def predict_batch(batch_data: BatchCustomerData):\n    if len(batch_data.customers) &gt; 1000:         # L\u00edmite para evitar timeout.\n        raise HTTPException(400, \"Max 1000 per batch\")\n\n    df = pd.DataFrame([c.dict() for c in batch_data.customers])  # Lista \u2192 DataFrame.\n    results = predictor.predict(df)              # Una llamada para todo el batch.\n    return {\"predictions\": results, \"processing_time\": time}\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-25-metrics-collection","title":"Pregunta 25: Metrics Collection","text":"<p>\u00bfQu\u00e9 m\u00e9tricas operacionales colectas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_24","title":"Respuesta:","text":"<pre><code>@app.get(\"/metrics\")                             # Endpoint de m\u00e9tricas operacionales.\nasync def get_metrics():\n    return {\n        \"total_predictions\": request_count,      # Contador de requests.\n        \"average_prediction_time_ms\": avg_time,  # Latencia promedio.\n        \"model_accuracy\": model_metadata.get(\"test_accuracy\")  # M\u00e9trica ML.\n    }\n</code></pre> <p>Prometheus-ready: Annotations en K8s para scraping autom\u00e1tico.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-26-error-handling-en-api","title":"Pregunta 26: Error Handling en API","text":"<p>\u00bfC\u00f3mo manejas errores?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_25","title":"Respuesta:","text":"<pre><code>@app.post(\"/predict\")\nasync def predict(customer: CustomerData):\n    if predictor is None:                        # Modelo no cargado.\n        raise HTTPException(503, \"Model not available\")  # 503: Service Unavailable.\n    try:\n        return predictor.predict(df)\n    except Exception as e:\n        logger.error(f\"Prediction error: {e}\")   # Log para debugging.\n        raise HTTPException(500, str(e))         # 500: Internal Server Error.\n</code></pre> <p>C\u00f3digos apropiados: 503 servicio no disponible, 500 error interno.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-27-logging-strategy","title":"Pregunta 27: Logging Strategy","text":"<p>\u00bfC\u00f3mo estructuraste el logging?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_26","title":"Respuesta:","text":"<pre><code>logging.basicConfig(\n    level=logging.INFO,                          # Nivel m\u00ednimo a loggear.\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",  # Formato.\n    handlers=[FileHandler(\"app.log\"), StreamHandler()]  # Archivo + consola.\n)\nlogger = logging.getLogger(__name__)             # Logger por m\u00f3dulo.\n</code></pre> <p>Niveles usados: INFO para operaciones normales, WARNING para fallbacks, ERROR para fallos.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-28-api-validation-con-pydantic","title":"Pregunta 28: API Validation con Pydantic","text":"<p>\u00bfC\u00f3mo validas inputs en la API?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_27","title":"Respuesta:","text":"<pre><code>class CustomerData(BaseModel):                   # Schema de entrada.\n    CreditScore: int = Field(..., ge=300, le=850)  # Rango v\u00e1lido.\n    Age: int = Field(..., ge=18, le=100)         # Validaci\u00f3n autom\u00e1tica.\n    Geography: str\n\n    @validator(\"Geography\")                      # Validador custom.\n    def validate_geo(cls, v):\n        if v not in [\"France\", \"Spain\", \"Germany\"]:\n            raise ValueError(\"Invalid geography\")  # Error descriptivo.\n        return v\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-29-response-enrichment","title":"Pregunta 29: Response Enrichment","text":"<p>\u00bfQu\u00e9 incluyes en la respuesta de predicci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_28","title":"Respuesta:","text":"<pre><code>class PredictionResponse(BaseModel):             # Schema de respuesta.\n    churn_probability: float                     # Probabilidad [0,1].\n    churn_prediction: int                        # 0 o 1.\n    risk_level: str                              # LOW/MEDIUM/HIGH para negocio.\n    confidence: float                            # abs(prob - 0.5) * 2: qu\u00e9 tan seguro.\n    model_version: str                           # Para trazabilidad.\n    prediction_timestamp: str                    # Cu\u00e1ndo se hizo.\n</code></pre> <p>Risk level: Categorizaci\u00f3n para decisiones de negocio.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-30-graceful-degradation","title":"Pregunta 30: Graceful Degradation","text":"<p>\u00bfQu\u00e9 pasa si el modelo no carga?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_29","title":"Respuesta:","text":"<pre><code>async def lifespan(app):\n    success = load_model_logic()                 # Intenta cargar.\n    if not success:\n        logger.warning(\"Started without model\")  # No falla, solo avisa.\n    yield                                        # App corre en modo degradado.\n\n# Health check reporta estado degradado\n{\"status\": \"degraded\", \"model_loaded\": false}    # Ops pueden ver el problema.\n</code></pre> <p>Beneficio: Health checks funcionan, ops pueden diagnosticar.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#3-bankchurn-predictor-preguntas-31-45","title":"3. BankChurn-Predictor (Preguntas 31-45)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-31-arquitectura-modular","title":"Pregunta 31: Arquitectura Modular","text":"<p>Describe la estructura del proyecto.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_30","title":"Respuesta:","text":"<pre><code>src/bankchurn/\n\u251c\u2500\u2500 cli.py        # Entry point CLI\n\u251c\u2500\u2500 config.py     # Pydantic validation\n\u251c\u2500\u2500 models.py     # ResampleClassifier\n\u251c\u2500\u2500 training.py   # ChurnTrainer class\n\u251c\u2500\u2500 evaluation.py # ModelEvaluator class\n\u2514\u2500\u2500 prediction.py # ChurnPredictor class\n</code></pre> <p>Principio: Single Responsibility - cada m\u00f3dulo una funci\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-32-cli-design","title":"Pregunta 32: CLI Design","text":"<p>\u00bfC\u00f3mo dise\u00f1aste la CLI?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_31","title":"Respuesta:","text":"<pre><code># cli.py\nparser.add_subparsers(dest=\"command\")\ntrain_parser = subparsers.add_parser(\"train\")\ntrain_parser.add_argument(\"--config\", required=True)\n\ndef cli_main(argv=None):\n    args = parser.parse_args(argv)\n    if args.command == \"train\":\n        return train_command(args)\n</code></pre> <p>Uso: <code>python -m bankchurn train --config configs/config.yaml</code></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-33-resampleclassifier","title":"Pregunta 33: ResampleClassifier","text":"<p>Explica tu clasificador custom.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_32","title":"Respuesta:","text":"<pre><code>class ResampleClassifier(BaseEstimator, ClassifierMixin):  # Compatible con sklearn.\n    def __init__(self, estimator=None, strategy=\"none\"):\n        self.estimator = estimator               # Modelo base.\n        self.strategy = strategy                 # Estrategia de resampling.\n\n    def fit(self, X, y):\n        X_res, y_res = self._apply_resampling(X, y)  # Aplica estrategia.\n        self.estimator_.fit(X_res, y_res)        # Entrena en datos resampled.\n        return self                              # Retorna self para encadenar.\n</code></pre> <p>Implementa interfaz sklearn: <code>fit</code>, <code>predict</code>, <code>predict_proba</code> \u2192 compatible con Pipeline.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-34-fairness-evaluation","title":"Pregunta 34: Fairness Evaluation","text":"<p>\u00bfC\u00f3mo eval\u00faas sesgo por grupos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_33","title":"Respuesta:","text":"<pre><code>def compute_fairness_metrics(self, X, y, sensitive_features):\n    for feature in sensitive_features:           # [\"Geography\", \"Gender\"]\n        for group in X[feature].unique():        # Cada grupo demogr\u00e1fico.\n            mask = X[feature] == group           # Filtra por grupo.\n            group_f1 = f1_score(y[mask], y_pred[mask])  # M\u00e9trica por grupo.\n\n    # Disparate Impact\n    disparate_impact = min(positive_rates) / max(positive_rates)  # &lt;0.8 = problema.\n</code></pre> <p>Threshold: Disparate Impact &lt; 0.8 indica discriminaci\u00f3n potencial.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-35-model-card","title":"Pregunta 35: Model Card","text":"<p>\u00bfQu\u00e9 incluyes en tu Model Card?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_34","title":"Respuesta:","text":"<pre><code># Model Card - BankChurn\n- Model: VotingClassifier (LR + RF)\n- Target: Exited (1=churn)\n## Intended Use: Priorizar retenci\u00f3n, no decisi\u00f3n autom\u00e1tica\n## Limitations: Desbalance 80/20, posible drift temporal\n## Fairness: Tests por geograf\u00eda/g\u00e9nero, gap recall &lt; 0.3\n## SLO: Disponibilidad 99.5%, Latencia P95 &lt; 50ms\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-36-testing-strategy","title":"Pregunta 36: Testing Strategy","text":"<p>\u00bfC\u00f3mo organizaste los tests?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_35","title":"Respuesta:","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py       # Fixtures compartidos\n\u251c\u2500\u2500 test_training.py  # ChurnTrainer\n\u251c\u2500\u2500 test_evaluation.py# ModelEvaluator\n\u251c\u2500\u2500 test_prediction.py# ChurnPredictor\n\u251c\u2500\u2500 test_config.py    # Pydantic validation\n\u2514\u2500\u2500 test_integration.py# E2E workflow\n</code></pre> <p>Coverage: 77% con pytest-cov.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-37-fixture-pattern","title":"Pregunta 37: Fixture Pattern","text":"<p>\u00bfC\u00f3mo usas fixtures en pytest?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_36","title":"Respuesta:","text":"<pre><code>@pytest.fixture                                  # Fixture: setup reutilizable.\ndef config():\n    return BankChurnConfig.from_yaml(\"configs/config.yaml\")  # Config de test.\n\n@pytest.fixture\ndef sample_data():\n    return pd.DataFrame({                        # Datos sint\u00e9ticos.\n        \"CreditScore\": np.random.randint(300, 850, 200),\n        \"Exited\": np.random.choice([0, 1], 200, p=[0.8, 0.2])  # 80/20 desbalance.\n    })\n\ndef test_training(config, sample_data, tmp_path):  # Recibe fixtures como args.\n    trainer = ChurnTrainer(config)\n    # ...\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-38-integration-test","title":"Pregunta 38: Integration Test","text":"<p>\u00bfQu\u00e9 cubre tu test de integraci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_37","title":"Respuesta:","text":"<pre><code>def test_full_training_workflow(config, sample_data, tmp_path):  # E2E test.\n    trainer = ChurnTrainer(config)\n    data = trainer.load_data(data_path)          # Paso 1: cargar.\n    X, y = trainer.prepare_features(data)        # Paso 2: preparar.\n    model, metrics = trainer.train(X, y)         # Paso 3: entrenar.\n    trainer.save_model(model_path)               # Paso 4: guardar.\n\n    # Verify artifacts\n    assert model_path.exists()                   # Modelo guardado.\n    assert metrics[\"test_f1\"] &gt; 0.5              # M\u00e9trica m\u00ednima.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-39-dockerfile-multi-stage","title":"Pregunta 39: Dockerfile Multi-Stage","text":"<p>Explica tu Dockerfile.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_38","title":"Respuesta:","text":"<pre><code># Stage 1: Builder\nFROM python:3.13-slim AS builder              # Stage de compilaci\u00f3n.\nRUN pip install -r requirements.txt           # Instala deps.\n# Stage 2: Runtime\nFROM python:3.13-slim AS runtime              # Imagen final limpia.\nCOPY --from=builder /opt/venv /opt/venv       # Copia solo venv.\nUSER appuser                                  # Seguridad: no root.\nHEALTHCHECK CMD curl -f http://localhost:8000/health  # K8s/Docker puede verificar.\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\"]  # Comando de inicio.\n</code></pre> <p>Beneficios: Imagen final sin build tools, usuario non-root, healthcheck.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-40-cors-configuration","title":"Pregunta 40: CORS Configuration","text":"<p>\u00bfC\u00f3mo configuraste CORS?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_39","title":"Respuesta:","text":"<pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],                         # \"*\": cualquier origen (solo dev!).\n    allow_methods=[\"GET\", \"POST\"],               # M\u00e9todos permitidos.\n    allow_headers=[\"*\"],                         # Headers permitidos.\n)\n</code></pre> <p>Nota: <code>allow_origins=[\"*\"]</code> solo para desarrollo. Producci\u00f3n especifica dominios.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-41-45-ver-archivo-parte-2","title":"Pregunta 41-45: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#4-carvision-market-intelligence-preguntas-46-60","title":"4. CarVision-Market-Intelligence (Preguntas 46-60)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-46-pipeline-features-pre-model","title":"Pregunta 46: Pipeline [features, pre, model]","text":"<p>Explica el pipeline de CarVision.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_40","title":"Respuesta:","text":"<pre><code>pipe = Pipeline([                                # Pipeline de 3 pasos.\n    (\"features\", FeatureEngineer(current_year=2024)),  # Feature engineering.\n    (\"pre\", ColumnTransformer([                  # Preprocesamiento paralelo.\n        (\"num\", numeric_pipeline, num_cols),     # Pipeline num\u00e9rico.\n        (\"cat\", categorical_pipeline, cat_cols)  # Pipeline categ\u00f3rico.\n    ])),\n    (\"model\", RandomForestRegressor())           # Modelo final.\n])\n</code></pre> <p>Flujo: Raw DF \u2192 Feature Engineering \u2192 Preprocessing \u2192 Model.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-47-data-filtering","title":"Pregunta 47: Data Filtering","text":"<p>\u00bfPor qu\u00e9 filtras precios entre $1K-$500K?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_41","title":"Respuesta:","text":"<pre><code>def clean_data(df, filters):\n    df = df[(df[\"price\"] &gt; 1000) &amp; (df[\"price\"] &lt; 500000)]  # Rango razonable.\n    df = df[df[\"model_year\"] &gt;= 1990]              # Autos modernos.\n    df = df[df[\"odometer\"] &lt; 500000]               # Kilometraje realista.\n</code></pre> <p>Raz\u00f3n: &lt; $1K son errores/donaciones, &gt; $500K son coleccionables (mercado diferente).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-48-bootstrap-confidence-intervals","title":"Pregunta 48: Bootstrap Confidence Intervals","text":"<p>\u00bfC\u00f3mo calculas intervalos de confianza?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_42","title":"Respuesta:","text":"<pre><code>for _ in range(200):                               # 200 iteraciones bootstrap.\n    idx = rng.choice(n, size=n, replace=True)      # Muestreo con reemplazo.\n    deltas.append(rmse(y[idx], y_model[idx]) - rmse(y[idx], y_base[idx]))  # Diferencia.\n\nci_low, ci_high = np.percentile(deltas, [2.5, 97.5])  # Percentiles 2.5% y 97.5%.\n</code></pre> <p>Interpretaci\u00f3n: CI95 no incluye 0 \u2192 diferencia significativa.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-49-temporal-backtesting","title":"Pregunta 49: Temporal Backtesting","text":"<p>\u00bfC\u00f3mo validas con datos temporales?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_43","title":"Respuesta:","text":"<pre><code>df_sorted = df.sort_values(\"model_year\")           # Ordena por tiempo.\ndf_test = df_sorted.tail(int(len(df) * 0.2))       # 20% m\u00e1s recientes como test.\nmetrics_temporal = evaluate(model, df_test)        # Eval\u00faa en \"futuro\".\n</code></pre> <p>Simula producci\u00f3n: Siempre predecimos el \"futuro\".</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-50-streamlit-caching","title":"Pregunta 50: Streamlit Caching","text":"<p>\u00bfC\u00f3mo optimizas el dashboard?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_44","title":"Respuesta:","text":"<pre><code>@st.cache_data                                     # Cache para datos serializables.\ndef load_data():\n    return FeatureEngineer().transform(load_raw_data())  # Solo ejecuta una vez.\n\n@st.cache_resource                                 # Cache para recursos (modelos).\ndef load_model():\n    return joblib.load(\"model.joblib\")             # Persiste entre reruns.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#preguntas-51-60-ver-archivo-parte-2","title":"Preguntas 51-60: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#5-telecomai-preguntas-61-70","title":"5. TelecomAI (Preguntas 61-70)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-61-simple-feature-set","title":"Pregunta 61: Simple Feature Set","text":"<p>\u00bfPor qu\u00e9 solo 4 features?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_45","title":"Respuesta:","text":"<pre><code>features: [calls, minutes, messages, mb_used]\n</code></pre> <p>Raz\u00f3n: ~2K muestras, m\u00e1s features = overfitting. AUC 0.84 indica se\u00f1al suficiente.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-62-gradientboosting-shallow","title":"Pregunta 62: GradientBoosting Shallow","text":"<p>\u00bfPor qu\u00e9 max_depth=2?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_46","title":"Respuesta:","text":"<pre><code>model:\n  name: gradient_boosting\n  params: {n_estimators: 200, max_depth: 2, learning_rate: 0.05}\n</code></pre> <p>Muchos \u00e1rboles simples: Regularizaci\u00f3n fuerte, reduce overfitting en dataset peque\u00f1o.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-63-70-ver-archivo-parte-2","title":"Pregunta 63-70: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#6-arquitectura-y-dise\u00f1o-preguntas-71-80","title":"6. Arquitectura y Dise\u00f1o (Preguntas 71-80)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-71-design-patterns","title":"Pregunta 71: Design Patterns","text":"<p>\u00bfQu\u00e9 patrones aplicaste?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_47","title":"Respuesta:","text":"<ol> <li>Strategy: <code>ResampleClassifier(strategy=\"oversample\")</code></li> <li>Factory: <code>build_model(cfg)</code> crea diferentes clasificadores</li> <li>Template Method: <code>ChurnTrainer.train()</code> con pasos customizables</li> <li>Dependency Injection: <code>ChurnTrainer(config)</code></li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-72-solid-principles","title":"Pregunta 72: SOLID Principles","text":"<p>\u00bfC\u00f3mo aplicaste SOLID?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_48","title":"Respuesta:","text":"<ul> <li>S: Un m\u00f3dulo, una responsabilidad (training.py solo entrena)</li> <li>O: ResampleClassifier abierto a nuevas estrategias</li> <li>L: Hereda de sklearn, sustituible donde se espere classifier</li> <li>I: Interfaces peque\u00f1as (Predictor, Evaluator, Trainer)</li> <li>D: Depende de config, no de valores hardcodeados</li> </ul>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#preguntas-73-80-ver-archivo-parte-2","title":"Preguntas 73-80: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#7-cicd-y-devops-preguntas-81-90","title":"7. CI/CD y DevOps (Preguntas 81-90)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-81-unified-ci-pipeline","title":"Pregunta 81: Unified CI Pipeline","text":"<p>Explica tu workflow unificado.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_49","title":"Respuesta:","text":"<pre><code># ci-mlops.yml\njobs:\n  tests:           # pytest + coverage por proyecto.      Job 1: Tests unitarios.\n  quality-gates:   # black, flake8, mypy.                 Job 2: Calidad de c\u00f3digo.\n  security:        # bandit, gitleaks, pip-audit.         Job 3: Seguridad.\n  docker:          # build + trivy scan.                  Job 4: Contenedores.\n  integration-test: # docker-compose E2E.                 Job 5: Tests E2E.\n</code></pre> <p>Matrix: Python 3.11/3.12 \u00d7 3 proyectos.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-82-security-scanning","title":"Pregunta 82: Security Scanning","text":"<p>\u00bfQu\u00e9 herramientas de seguridad usas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_50","title":"Respuesta:","text":"<ul> <li>Gitleaks: Detecta secrets en c\u00f3digo</li> <li>Bandit: An\u00e1lisis est\u00e1tico Python</li> <li>Trivy: Vulnerabilidades en containers</li> <li>pip-audit: Dependencias con CVEs</li> </ul>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#preguntas-83-90-ver-archivo-parte-2","title":"Preguntas 83-90: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#8-infraestructura-preguntas-91-100","title":"8. Infraestructura (Preguntas 91-100)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-91-kubernetes-deployment","title":"Pregunta 91: Kubernetes Deployment","text":"<p>Explica tu deployment de K8s.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_51","title":"Respuesta:","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment                                  # Recurso K8s para despliegue.\nspec:\n  replicas: 3                                     # 3 instancias para HA.\n  strategy: {type: RollingUpdate}                 # Actualizaci\u00f3n sin downtime.\n  template:\n    spec:\n      containers:\n      - name: bankchurn-api\n        resources:\n          requests: {memory: \"512Mi\", cpu: \"250m\"}  # M\u00ednimo garantizado.\n          limits: {memory: \"1Gi\", cpu: \"1000m\"}    # M\u00e1ximo permitido.\n        livenessProbe: ...                        # Verifica si est\u00e1 vivo.\n        readinessProbe: ...                       # Verifica si puede recibir tr\u00e1fico.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-92-horizontalpodautoscaler","title":"Pregunta 92: HorizontalPodAutoscaler","text":"<p>\u00bfC\u00f3mo configuras autoscaling?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_52","title":"Respuesta:","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler                     # Autoescalador.\nspec:\n  minReplicas: 2                                  # M\u00ednimo 2 para HA.\n  maxReplicas: 10                                 # M\u00e1ximo 10 para carga alta.\n  metrics:\n  - type: Resource\n    resource: {name: cpu, target: {averageUtilization: 70}}  # Escala si CPU &gt; 70%.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#preguntas-93-100-ver-archivo-parte-2","title":"Preguntas 93-100: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#9-\u00e9tica-y-fairness-preguntas-101-105","title":"9. \u00c9tica y Fairness (Preguntas 101-105)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-101-responsible-ai","title":"Pregunta 101: Responsible AI","text":"<p>\u00bfC\u00f3mo abordas responsabilidad en ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_53","title":"Respuesta:","text":"<ol> <li>Model Cards: Documentan limitaciones y riesgos</li> <li>Fairness metrics: Disparate Impact por grupo</li> <li>Transparencia: Logs de predicciones, versiones</li> <li>Human-in-loop: Modelo como apoyo, no decisi\u00f3n final</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-102-105-ver-archivo-parte-2","title":"Pregunta 102-105: [Ver archivo parte 2]","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#10-liderazgo-preguntas-106-115","title":"10. Liderazgo (Preguntas 106-115)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#pregunta-106-technical-decision-making","title":"Pregunta 106: Technical Decision Making","text":"<p>\u00bfC\u00f3mo decides entre RF y GB?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#respuesta_54","title":"Respuesta:","text":"<p>Factores: Tama\u00f1o dataset, tipo de features, requerimientos de latencia, interpretabilidad. Proceso: Experimento con baseline \u2192 comparar m\u00e9tricas \u2192 considerar trade-offs.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE1/#preguntas-107-115-ver-archivo-parte-2","title":"Preguntas 107-115: [Ver archivo Parte 2]","text":"<p>[Contin\u00faa en SIMULACRO_ENTREVISTA_PARTE2.md]</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/","title":"\ud83c\udfaf Simulacro Entrevista Lead/Senior ML Engineer - Parte 2","text":"<p>Continuaci\u00f3n de preguntas 41-115</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-41-45-bankchurn-continuacion","title":"Preguntas 41-45: BankChurn (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-41-risk-level-classification","title":"Pregunta 41: Risk Level Classification","text":"<p>\u00bfC\u00f3mo categorizas el riesgo de churn?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta","title":"Respuesta:","text":"<pre><code># prediction.py\ndef _assign_risk_level(self, probability: float) -&gt; str:  # Categoriza probabilidad.\n    if probability &lt; 0.3:              # Baja probabilidad de churn.\n        return \"low\"\n    elif probability &lt; 0.7:            # Probabilidad intermedia.\n        return \"medium\"\n    else:                              # Alta probabilidad.\n        return \"high\"\n</code></pre> <p>Uso en negocio: - High: Contacto proactivo inmediato - Medium: Ofertas de retenci\u00f3n - Low: Monitoreo est\u00e1ndar</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-42-feature-contribution-explanation","title":"Pregunta 42: Feature Contribution Explanation","text":"<p>\u00bfC\u00f3mo explicas las predicciones?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_1","title":"Respuesta:","text":"<pre><code># prediction.py\ndef _generate_explanation(self, X_row) -&gt; Dict[str, float]:  # Explicaci\u00f3n simple.\n    # Enfoque simplificado: distancia a media por feature\n    contributions = {}\n    for col in self.feature_names:\n        mean_val = self.feature_means.get(col, 0)  # Media de training.\n        diff = (X_row[col] - mean_val) / (self.feature_stds.get(col, 1) + 1e-8)  # Z-score.\n        contributions[col] = float(diff)           # Qu\u00e9 tan lejos del promedio.\n    return contributions\n</code></pre> <p>Limitaci\u00f3n reconocida: No es SHAP values real, pero da intuici\u00f3n inicial sin dependencia adicional.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-43-model-metadata","title":"Pregunta 43: Model Metadata","text":"<p>\u00bfQu\u00e9 metadata guardas con el modelo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_2","title":"Respuesta:","text":"<pre><code>{\n  \"version\": \"1.0.0\",\n  \"trained_at\": \"2024-11-20T10:30:00Z\",\n  \"config_hash\": \"abc123def456\",\n  \"test_metrics\": {\n    \"f1_score\": 0.82,\n    \"auc_roc\": 0.853\n  },\n  \"feature_names\": [\"CreditScore\", \"Age\", ...],\n  \"training_samples\": 8000,\n  \"git_commit\": \"abc123\"\n}\n</code></pre> <p>Uso: Trazabilidad, comparaci\u00f3n entre versiones, debugging.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-44-lifespan-vs-on-event-loading","title":"Pregunta 44: Lifespan vs On-Event Loading","text":"<p>\u00bfPor qu\u00e9 usas lifespan en lugar de startup event?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_3","title":"Respuesta:","text":"<pre><code># FastAPI &gt;= 0.95 depreca @app.on_event\n@asynccontextmanager                              # Context manager as\u00edncrono.\nasync def lifespan(app: FastAPI):\n    # Startup\n    load_model()                                  # Carga al iniciar.\n    yield                                         # App corre aqu\u00ed.\n    # Shutdown (cleanup)                          # Cleanup al cerrar.\n\napp = FastAPI(lifespan=lifespan)                  # Patr\u00f3n moderno.\n</code></pre> <p>Beneficios: - Patr\u00f3n moderno recomendado - Context manager claro para setup/teardown - Mejor manejo de recursos async</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-45-test-coverage-strategy","title":"Pregunta 45: Test Coverage Strategy","text":"<p>\u00bfC\u00f3mo alcanzaste 77% coverage?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_4","title":"Respuesta:","text":"<pre><code># pytest.ini\n[pytest]\naddopts = --cov=src/bankchurn --cov-report=term-missing\n\n# Estrategia:\n# 1. Unit tests por m\u00f3dulo\n# 2. Integration tests para workflows completos\n# 3. Edge cases: datos vac\u00edos, missing columns, tipos inv\u00e1lidos\n# 4. Error paths: excepciones esperadas\n</code></pre> <p>Cobertura por m\u00f3dulo: - training.py: 85% - evaluation.py: 80% - config.py: 90% - cli.py: 60% (I/O dif\u00edcil de testear)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-51-60-carvision-continuacion","title":"Preguntas 51-60: CarVision (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-51-feature-type-inference","title":"Pregunta 51: Feature Type Inference","text":"<p>\u00bfC\u00f3mo detectas tipos de features autom\u00e1ticamente?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_5","title":"Respuesta:","text":"<pre><code># data.py\ndef infer_feature_types(df, cfg):\n    num_cfg = cfg.get(\"numeric_features\", [])     # Del config o vac\u00edo.\n    cat_cfg = cfg.get(\"categorical_features\", [])\n\n    if not num_cfg:                               # Si no especificado, infiere.\n        num_cfg = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n    if not cat_cfg:\n        cat_cfg = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\n    return num_cfg, cat_cfg                       # Retorna listas de columnas.\n</code></pre> <p>Beneficio: Config minimalista (<code>[]</code>) usa inferencia autom\u00e1tica.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-52-segment-error-analysis","title":"Pregunta 52: Segment Error Analysis","text":"<p>\u00bfC\u00f3mo analizas errores por segmento?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_6","title":"Respuesta:","text":"<pre><code>def _analyse_errors_by_segment(df, y_true, y_pred, segment_cols):\n    results = []\n    for col in segment_cols:                      # [\"condition\", \"type\", \"model_year\"]\n        for val, group in df.groupby(col):        # Agrupa por valor.\n            if len(group) &lt; 30:                   # Ignora grupos peque\u00f1os.\n                continue\n            results.append({\n                \"segment\": f\"{col}={val}\",\n                \"rmse\": rmse(group[target], y_pred[group.index]),  # Error por segmento.\n                \"n_samples\": len(group)\n            })\n    return pd.DataFrame(results)                  # DataFrame de resultados.\n</code></pre> <p>Hallazgo t\u00edpico: Mayor error en autos muy nuevos (pocos datos) o muy viejos (alta variabilidad).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-53-dual-application-api-dashboard","title":"Pregunta 53: Dual Application (API + Dashboard)","text":"<p>\u00bfC\u00f3mo manejas API y Streamlit juntos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_7","title":"Respuesta:","text":"<pre><code>app/\n\u251c\u2500\u2500 fastapi_app.py     # REST API (port 8002)\n\u2514\u2500\u2500 streamlit_app.py   # Dashboard (port 8501)\n</code></pre> <p>Ambos usan: <pre><code>from src.carvision.features import FeatureEngineer\nfrom src.carvision.data import clean_data\n\n# Mismo pipeline, diferentes interfaces\nmodel = joblib.load(MODEL_PATH)\n</code></pre></p> <p>Docker Compose: <pre><code>services:\n  carvision-api:\n    command: uvicorn app.fastapi_app:app --port 8002  # API REST.\n  carvision-dashboard:\n    command: streamlit run app/streamlit_app.py --server.port 8501  # Dashboard interactivo.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-54-price-category-leakage","title":"Pregunta 54: Price Category Leakage","text":"<p>\u00bfPor qu\u00e9 price_category causa leakage?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_8","title":"Respuesta:","text":"<pre><code># features.py - ANTES (bug)\nX[\"price_category\"] = pd.cut(X[\"price\"], bins=[0, 5000, 15000, 50000, np.inf])  # price ES el target!\n</code></pre> <p>Problema: <code>price_category</code> depende de <code>price</code> (el target). - En training: tiene el valor correcto - En inference: <code>price</code> no existe \u2192 error o leakage si se imputa</p> <p>Soluci\u00f3n: <code>drop_columns: [\"price_per_mile\", \"price_category\"]</code> en config.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-55-split-indices-persistence","title":"Pregunta 55: Split Indices Persistence","text":"<p>\u00bfPor qu\u00e9 guardas los \u00edndices del split?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_9","title":"Respuesta:","text":"<pre><code>def save_split_indices(indices, path):\n    with open(path, \"w\") as f:\n        json.dump({k: v.tolist() for k, v in indices.items()}, f)  # Guarda \u00edndices como JSON.\n</code></pre> <p>Uso: <pre><code># Reproducir exactamente el mismo split\nindices = load_split_indices(\"split_indices.json\")  # Carga \u00edndices guardados.\nX_train = X.iloc[indices[\"train\"]]                  # Reconstruye train.\nX_test = X.iloc[indices[\"test\"]]                    # Reconstruye test.\n</code></pre></p> <p>Beneficio: Comparar modelos con EXACTAMENTE los mismos datos de test.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-56-dummy-baseline","title":"Pregunta 56: Dummy Baseline","text":"<p>\u00bfPor qu\u00e9 comparas con DummyRegressor?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_10","title":"Respuesta:","text":"<pre><code>dummy = DummyRegressor(strategy=\"median\")            # Predice siempre la mediana.\nbaseline_rmse = rmse(y_test, dummy.fit(X_train, y_train).predict(X_test))  # Baseline a superar.\n</code></pre> <p>Estrategias disponibles: - <code>mean</code>: Predice promedio - <code>median</code>: Predice mediana (robusta a outliers) - <code>constant</code>: Valor fijo</p> <p>Interpretaci\u00f3n: Si tu modelo no supera dummy, no agrega valor.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-57-random-forest-para-regresion","title":"Pregunta 57: Random Forest para Regresi\u00f3n","text":"<p>\u00bfPor qu\u00e9 RF y no XGBoost para CarVision?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_11","title":"Respuesta:","text":"Criterio RandomForest XGBoost Simplicidad Menos hiperpar\u00e1metros Muchos HP cr\u00edticos Robustez Menos sensible a HP Requiere tuning fino Interpretabilidad Feature importance directa M\u00e1s complejo Performance Competitivo en tabular Marginalmente mejor <p>Decisi\u00f3n: RF es \"good enough\" con menor riesgo de overfitting y configuraci\u00f3n m\u00e1s simple.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-58-mape-calculation","title":"Pregunta 58: MAPE Calculation","text":"<p>\u00bfPor qu\u00e9 sumas epsilon en MAPE?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_12","title":"Respuesta:","text":"<pre><code>mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  # 1e-8 evita /0.\n</code></pre> <p>Problema: Si <code>y_true = 0</code>, divisi\u00f3n por cero. Soluci\u00f3n: <code>+ 1e-8</code> evita divisi\u00f3n por cero.</p> <p>Alternativa mejor para precios: <pre><code># Symmetric MAPE\nsmape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))  # Sim\u00e9trico.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-59-streamlit-sections","title":"Pregunta 59: Streamlit Sections","text":"<p>\u00bfC\u00f3mo organizas el dashboard?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_13","title":"Respuesta:","text":"<pre><code># streamlit_app.py\ntab1, tab2, tab3, tab4 = st.tabs([                   # Tabs para organizaci\u00f3n.\n    \"\ud83d\udcca Overview\",\n    \"\ud83d\udcc8 Market Analysis\", \n    \"\ud83c\udfaf Model Metrics\",\n    \"\ud83d\udcb0 Price Predictor\"\n])\n\nwith tab1:                                           # Contenido del tab.\n    display_overview_kpis()\nwith tab4:\n    # Formulario de predicci\u00f3n\n    brand = st.selectbox(\"Brand\", brands)            # Dropdown.\n    year = st.slider(\"Year\", 1990, 2024)             # Slider.\n    if st.button(\"Predict\"):                         # Bot\u00f3n.\n        pred = model.predict(features)\n        st.success(f\"Estimated Price: ${pred:,.0f}\")  # Resultado formateado.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-60-api-vs-dashboard-trade-offs","title":"Pregunta 60: API vs Dashboard Trade-offs","text":"<p>\u00bfCu\u00e1ndo recomiendas API vs Dashboard?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_14","title":"Respuesta:","text":"Caso de Uso Recomendaci\u00f3n Integraci\u00f3n con otros sistemas API Usuarios no t\u00e9cnicos Dashboard Alto volumen API Exploraci\u00f3n ad-hoc Dashboard Automatizaci\u00f3n API Demos/POC Dashboard <p>CarVision ofrece ambos: API para integraci\u00f3n con sistemas de dealers, Dashboard para analistas de mercado.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-63-70-telecomai-continuacion","title":"Preguntas 63-70: TelecomAI (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-63-unified-pipeline-benefit","title":"Pregunta 63: Unified Pipeline Benefit","text":"<p>\u00bfPor qu\u00e9 un solo artefacto pipeline?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_15","title":"Respuesta:","text":"<pre><code># ANTES (2 archivos)\npreprocessor = joblib.load(\"preprocessor.pkl\")       # Riesgo: versiones desincronizadas.\nmodel = joblib.load(\"model.pkl\")\nX_proc = preprocessor.transform(X)\npred = model.predict(X_proc)\n\n# AHORA (1 archivo)\npipeline = joblib.load(\"model.joblib\")               # Un solo artefacto.\npred = pipeline.predict(X)                           # Una llamada hace todo.\n</code></pre> <p>Beneficios: 1. Deployment m\u00e1s simple 2. Imposible desincronizar preprocessor/model 3. Una sola versi\u00f3n para auditar</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-64-config-yaml-structure","title":"Pregunta 64: Config YAML Structure","text":"<p>\u00bfC\u00f3mo estructuras el config de TelecomAI?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_16","title":"Respuesta:","text":"<pre><code>project_name: TelecomAI-Customer-Intelligence\nrandom_seed: 42\n\npaths:\n  data_csv: users_behavior.csv\n  model_path: artifacts/model.joblib\n\nfeatures: [calls, minutes, messages, mb_used]\ntarget: is_ultra\n\nsplit:\n  test_size: 0.2\n  stratify: true\n\nmodel:\n  name: gradient_boosting\n  params:\n    n_estimators: 200\n    max_depth: 2\n</code></pre> <p>Principio: Toda configuraci\u00f3n externalizada, ning\u00fan valor hardcodeado.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-65-stratify-con-clasificacion-binaria","title":"Pregunta 65: Stratify con Clasificaci\u00f3n Binaria","text":"<p>\u00bfCu\u00e1ndo es cr\u00edtica la estratificaci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_17","title":"Respuesta:","text":"<p>Cr\u00edtica cuando: - Clases desbalanceadas (&lt; 70/30) - Dataset peque\u00f1o (&lt; 5K samples) - M\u00e9trica sensible a distribuci\u00f3n (precision, recall)</p> <pre><code># Sin estratificaci\u00f3n en 2K samples con 30% positivos:\n# Test set podr\u00eda tener 20% o 40% positivos \u2192 m\u00e9tricas no comparables\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-66-simple-model-debugging","title":"Pregunta 66: Simple Model Debugging","text":"<p>\u00bfC\u00f3mo debuggeas un modelo simple?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_18","title":"Respuesta:","text":"<pre><code># 1. Check feature distributions\nprint(X_train.describe())                            # Estad\u00edsticas de train.\nprint(X_test.describe())                             # Deber\u00eda ser similar a train.\n\n# 2. Check target distribution\nprint(y_train.value_counts(normalize=True))          # Proporciones en train.\nprint(y_test.value_counts(normalize=True))           # Deber\u00eda ser similar.\n\n# 3. Learning curve\nfrom sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, val_scores = learning_curve(  # Detecta over/underfitting.\n    model, X, y, cv=5, scoring=\"roc_auc\"\n)\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-67-gradient-boosting-learning-rate","title":"Pregunta 67: Gradient Boosting Learning Rate","text":"<p>\u00bfQu\u00e9 pasa si lr es muy alto o muy bajo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_19","title":"Respuesta:","text":"lr Efecto 0.5+ (alto) Convergencia r\u00e1pida, riesgo de overfitting 0.01-0.1 (medio) Balance t\u00edpico &lt; 0.01 (bajo) Necesita muchos estimators, m\u00e1s robusto <pre><code># TelecomAI usa lr=0.05, n_estimators=200\n# Conservador pero estable\n</code></pre> <p>Regla pr\u00e1ctica: <code>lr * n_estimators \u2248 10-20</code> para convergencia.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-68-evaluation-metrics-save","title":"Pregunta 68: Evaluation Metrics Save","text":"<p>\u00bfC\u00f3mo persistes m\u00e9tricas?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_20","title":"Respuesta:","text":"<pre><code># evaluation.py\ndef evaluate_model(pipeline, X_test, y_test, cfg):\n    metrics = compute_classification_metrics(y_test, y_pred, y_proba)  # Calcula m\u00e9tricas.\n\n    # Save to YAML\n    with open(cfg.paths[\"metrics_path\"], \"w\") as f:\n        yaml.safe_dump(metrics, f)                   # Guarda en formato legible.\n\n    return metrics\n</code></pre> <p>Formato YAML para legibilidad humana: <pre><code>accuracy: 0.812\nprecision: 0.785\nrecall: 0.743\nf1: 0.763\nroc_auc: 0.840\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-69-fastapi-app-telecomai","title":"Pregunta 69: FastAPI App TelecomAI","text":"<p>\u00bfC\u00f3mo estructuras la API?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_21","title":"Respuesta:","text":"<pre><code># app/fastapi_app.py\nclass UserBehavior(BaseModel):                       # Schema de entrada.\n    calls: int\n    minutes: float\n    messages: int\n    mb_used: float\n\n@app.post(\"/predict\")\nasync def predict_plan(user: UserBehavior):          # Recibe datos validados.\n    features = pd.DataFrame([user.dict()])           # Convierte a DataFrame.\n    pred = pipeline.predict(features)[0]             # Predicci\u00f3n.\n    proba = pipeline.predict_proba(features)[0][1]   # Probabilidad clase 1.\n    return {\n        \"recommended_plan\": \"Ultra\" if pred == 1 else \"Basic\",  # Respuesta de negocio.\n        \"confidence\": float(proba)                   # Confianza.\n    }\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-70-telecomai-business-context","title":"Pregunta 70: TelecomAI Business Context","text":"<p>\u00bfC\u00f3mo se usa el modelo en el negocio?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_22","title":"Respuesta:","text":"<p>Contexto: Recomendar plan de datos (Basic vs Ultra) basado en patrones de uso.</p> <p>Flujo: 1. Cliente usa servicio por periodo de prueba 2. Sistema recolecta m\u00e9tricas: calls, minutes, messages, mb_used 3. Modelo predice plan \u00f3ptimo 4. Ventas contacta con oferta personalizada</p> <p>Valor: - Reduce churn por plan inadecuado - Aumenta ARPU en usuarios infraservidos - Mejora satisfacci\u00f3n del cliente</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-73-80-arquitectura-continuacion","title":"Preguntas 73-80: Arquitectura (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-73-error-handling-philosophy","title":"Pregunta 73: Error Handling Philosophy","text":"<p>\u00bfCu\u00e1l es tu filosof\u00eda de manejo de errores?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_23","title":"Respuesta:","text":"<ol> <li>Fail fast: Validar inputs al inicio</li> <li>Errores espec\u00edficos: <code>ValueError</code> vs <code>FileNotFoundError</code> vs gen\u00e9rico</li> <li>Logs contextuales: Incluir datos relevantes en el error</li> <li>Graceful degradation: Servicio funciona con capacidad reducida</li> </ol> <pre><code># Malo\ntry:\n    do_something()\nexcept Exception:                                # Captura todo: oculta bugs.\n    pass                                         # Silencia errores: peligroso.\n\n# Bueno\ntry:\n    do_something(input_data)\nexcept ValueError as e:                          # Captura espec\u00edfica.\n    logger.error(f\"Invalid input {input_data}: {e}\")  # Log con contexto.\n    raise HTTPException(400, f\"Invalid input: {e}\")   # HTTP apropiado.\nexcept FileNotFoundError as e:\n    logger.error(f\"Model file missing: {e}\")\n    raise HTTPException(503, \"Model not available\")   # 503: servicio no disponible.\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-74-dependency-management","title":"Pregunta 74: Dependency Management","text":"<p>\u00bfC\u00f3mo manejas dependencias entre proyectos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_24","title":"Respuesta:","text":"<pre><code>Projects Tripe Ten/\n\u251c\u2500\u2500 common_utils/         # Shared code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 logger.py\n\u2502   \u2514\u2500\u2500 seed.py\n\u251c\u2500\u2500 BankChurn-Predictor/\n\u2502   \u2514\u2500\u2500 requirements.txt  # Project-specific deps\n\u251c\u2500\u2500 CarVision-Market-Intelligence/\n\u2502   \u2514\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 TelecomAI-Customer-Intelligence/\n    \u2514\u2500\u2500 requirements.txt\n</code></pre> <p>common_utils en cada project: <pre><code>import sys\nsys.path.insert(0, str(Path(__file__).parent.parent.parent))  # A\u00f1ade ra\u00edz al path.\nfrom common_utils.seed import set_seed                        # Import de c\u00f3digo compartido.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-75-api-versioning","title":"Pregunta 75: API Versioning","text":"<p>\u00bfC\u00f3mo versionar\u00edas la API?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_25","title":"Respuesta:","text":"<pre><code># Opci\u00f3n 1: Path versioning                       # M\u00e1s expl\u00edcito y cacheable.\n@app.post(\"/v1/predict\")\n@app.post(\"/v2/predict\")\n\n# Opci\u00f3n 2: Header versioning                    # M\u00e1s limpio, menos visible.\n@app.post(\"/predict\")\nasync def predict(request: Request):\n    version = request.headers.get(\"API-Version\", \"1\")  # Default v1.\n\n# Opci\u00f3n 3: Query param                          # Simple pero contamina URL.\n@app.post(\"/predict\")\nasync def predict(version: str = Query(\"1\")):\n</code></pre> <p>Recomendaci\u00f3n: Path versioning es m\u00e1s expl\u00edcito y cacheable.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-76-configuration-hierarchy","title":"Pregunta 76: Configuration Hierarchy","text":"<p>\u00bfC\u00f3mo manejas diferentes environments?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_26","title":"Respuesta:","text":"<pre><code># configs/config.yaml (base)\nmlflow:\n  tracking_uri: \"file:./mlruns\"  # Default: local\n\n# Override via environment variables\n# MLFLOW_TRACKING_URI=http://mlflow.prod:5000\n\n# O archivos separados\n# configs/config.dev.yaml\n# configs/config.prod.yaml\n</code></pre> <p>Carga con override: <pre><code>config = BankChurnConfig.from_yaml(\"configs/config.yaml\")  # Config base.\nconfig.mlflow.tracking_uri = os.getenv(\"MLFLOW_URI\", config.mlflow.tracking_uri)  # Override por env.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-77-async-vs-sync-en-fastapi","title":"Pregunta 77: Async vs Sync en FastAPI","text":"<p>\u00bfCu\u00e1ndo usas async?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_27","title":"Respuesta:","text":"<pre><code># Sync - operaciones CPU-bound (ML inference)\n@app.post(\"/predict\")\ndef predict_sync(data: CustomerData):            # def: s\u00edncrono.\n    return model.predict(data)                   # CPU bound: no usar async.\n\n# Async - operaciones I/O bound\n@app.get(\"/health\")\nasync def health_async():                        # async def: as\u00edncrono.\n    await check_external_service()               # Network call: s\u00ed usar async.\n</code></pre> <p>ML inference es CPU-bound: <code>def</code> es preferible para evitar bloquear event loop.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-78-testing-pyramid","title":"Pregunta 78: Testing Pyramid","text":"<p>\u00bfC\u00f3mo estructuras tus tests?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_28","title":"Respuesta:","text":"<pre><code>Tests/\n\u251c\u2500\u2500 Unit (70%)\n\u2502   \u251c\u2500\u2500 test_config.py\n\u2502   \u251c\u2500\u2500 test_models.py\n\u2502   \u2514\u2500\u2500 test_evaluation.py\n\u251c\u2500\u2500 Integration (20%)\n\u2502   \u2514\u2500\u2500 test_training.py (E2E workflow)\n\u2514\u2500\u2500 E2E (10%)\n    \u2514\u2500\u2500 test_api.py (requests reales)\n</code></pre> <p>Pir\u00e1mide: Muchos unit tests (r\u00e1pidos), pocos E2E (lentos pero valiosos).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-79-code-review-checklist","title":"Pregunta 79: Code Review Checklist","text":"<p>\u00bfQu\u00e9 revisas en un PR de ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_29","title":"Respuesta:","text":"<ol> <li>Data leakage: \u00bfSplit antes de fit?</li> <li>Reproducibilidad: \u00bfSeeds configurados?</li> <li>Tests: \u00bfCubren happy path y edge cases?</li> <li>Config: \u00bfValores hardcodeados?</li> <li>M\u00e9tricas: \u00bfApropiadas para el problema?</li> <li>Logging: \u00bfSuficiente para debugging?</li> <li>Documentation: \u00bfModel card actualizado?</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-80-technical-debt-management","title":"Pregunta 80: Technical Debt Management","text":"<p>\u00bfC\u00f3mo manejas deuda t\u00e9cnica?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_30","title":"Respuesta:","text":"<p>Categorizaci\u00f3n: - Critical: Bugs de seguridad, data leakage \u2192 Sprint actual - High: Tests faltantes, logging pobre \u2192 Pr\u00f3ximo sprint - Medium: Refactoring, documentaci\u00f3n \u2192 Backlog priorizado - Low: Nice-to-have \u2192 Tech debt day mensual</p> <p>Tracking: Issues en GitHub con label <code>tech-debt</code> y estimaci\u00f3n de impacto.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-83-90-cicd-continuacion","title":"Preguntas 83-90: CI/CD (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-83-matrix-testing-strategy","title":"Pregunta 83: Matrix Testing Strategy","text":"<p>\u00bfPor qu\u00e9 matrix Python 3.11/3.12?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_31","title":"Respuesta:","text":"<pre><code>strategy:\n  matrix:\n    python-version: ['3.11', '3.12']             # 2 versiones de Python.\n    project: [BankChurn, CarVision, TelecomAI]   # 3 proyectos.\n</code></pre> <p>Razones: - 3.11: Versi\u00f3n estable ampliamente usada - 3.12: Versi\u00f3n m\u00e1s reciente, validar compatibilidad - 3 proyectos: Detectar regresiones cross-project</p> <p>Total jobs: 2 \u00d7 3 = 6 combinaciones paralelas.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-84-fail-fast-strategy","title":"Pregunta 84: Fail-Fast Strategy","text":"<p>\u00bfCu\u00e1ndo usar fail-fast: false?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_32","title":"Respuesta:","text":"<pre><code>strategy:\n  fail-fast: false                               # Ejecuta todos los jobs aunque uno falle.\n</code></pre> <p>Usar <code>false</code> cuando: - Quieres ver TODOS los errores, no solo el primero - Jobs son independientes (matriz de versiones) - Debugging de problemas de compatibilidad</p> <p>Usar <code>true</code> cuando: - Jobs dependientes - Quieres feedback r\u00e1pido - Recursos de CI limitados</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-85-docker-build-caching","title":"Pregunta 85: Docker Build Caching","text":"<p>\u00bfC\u00f3mo optimizas builds de Docker?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_33","title":"Respuesta:","text":"<pre><code># Orden \u00f3ptimo de COPY\nCOPY requirements.txt .                          # Primero deps (cambia poco).\nRUN pip install -r requirements.txt              # Cached si requirements no cambia.\nCOPY src/ ./src/                                 # Despu\u00e9s c\u00f3digo (cambia m\u00e1s).\n</code></pre> <p>CI caching: <pre><code>- uses: docker/build-push-action@v5\n  with:\n    cache-from: type=gha                         # Usa cache de GitHub Actions.\n    cache-to: type=gha,mode=max                  # Guarda m\u00e1ximo cache.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-86-security-scanning-results","title":"Pregunta 86: Security Scanning Results","text":"<p>\u00bfQu\u00e9 haces con findings de seguridad?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_34","title":"Respuesta:","text":"<p>Proceso: 1. Critical/High: Bloquea PR, fix inmediato 2. Medium: Documenta, fix en siguiente sprint 3. Low: Backlog, evaluar riesgo/esfuerzo 4. False positives: A\u00f1adir a <code>.gitleaksignore</code> con justificaci\u00f3n</p> <pre><code># .gitleaksignore\n# False positive: example API key in documentation\ndocs/examples/api_usage.md:15\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-87-coverage-thresholds","title":"Pregunta 87: Coverage Thresholds","text":"<p>\u00bfPor qu\u00e9 70% coverage m\u00ednimo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_35","title":"Respuesta:","text":"<pre><code>- name: Check coverage threshold\n  run: |\n    coverage report --fail-under=70              # Falla CI si coverage &lt; 70%.\n</code></pre> <p>Raz\u00f3n del 70%: - &lt; 60%: Riesgo de bugs no detectados - 70-80%: Balance costo/beneficio t\u00edpico - &gt; 90%: Diminishing returns, tests fr\u00e1giles</p> <p>No todo necesita tests: I/O, logging, error messages triviales.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-88-integration-test-strategy","title":"Pregunta 88: Integration Test Strategy","text":"<p>\u00bfQu\u00e9 cubren tus integration tests?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_36","title":"Respuesta:","text":"<pre><code>integration-test:\n  steps:\n    - run: docker-compose -f docker-compose.demo.yml up -d\n    - run: |\n        # Wait for services\n        sleep 30\n        # Test each API\n        curl http://localhost:8001/health\n        curl http://localhost:8002/health\n        curl -X POST http://localhost:8001/predict -d '...'\n</code></pre> <p>Cobertura: Health checks, predicciones b\u00e1sicas, formato de respuesta.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-89-documentation-validation","title":"Pregunta 89: Documentation Validation","text":"<p>\u00bfC\u00f3mo validas documentaci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_37","title":"Respuesta:","text":"<pre><code>doc-validation:\n  steps:\n    - name: Check markdown links\n      run: |\n        npm install -g markdown-link-check      # Instala herramienta.\n        find . -name \"*.md\" -exec markdown-link-check {} \\;  # Valida todos los .md.\n\n    - name: Build mkdocs\n      run: |\n        pip install mkdocs\n        mkdocs build --strict                   # --strict: falla con warnings.\n</code></pre> <p>Valida: Links rotos, sintaxis markdown, build de docs.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-90-deployment-strategy","title":"Pregunta 90: Deployment Strategy","text":"<p>\u00bfC\u00f3mo desplegar\u00edas a producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_38","title":"Respuesta:","text":"<pre><code>deploy-prod:\n  needs: [tests, security, docker-build]        # Solo despu\u00e9s de pasar gates.\n  if: github.ref == 'refs/heads/main'           # Solo en main.\n  steps:\n    - name: Push to registry\n      run: docker push ghcr.io/${{ github.repository }}:${{ github.sha }}  # Imagen con SHA.\n\n    - name: Update K8s deployment\n      run: |\n        kubectl set image deployment/bankchurn \\  # Rolling update.\n          bankchurn=ghcr.io/${{ github.repository }}:${{ github.sha }}\n</code></pre> <p>Estrategia: Rolling update con readiness probes.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-93-100-infraestructura-continuacion","title":"Preguntas 93-100: Infraestructura (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-93-resource-requests-vs-limits","title":"Pregunta 93: Resource Requests vs Limits","text":"<p>Explica requests vs limits en K8s.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_39","title":"Respuesta:","text":"<pre><code>resources:\n  requests:                                     # M\u00ednimo garantizado.\n    memory: \"512Mi\"                             # Scheduler reserva esto.\n    cpu: \"250m\"                                 # 0.25 CPU.\n  limits:                                       # M\u00e1ximo permitido.\n    memory: \"1Gi\"                               # OOMKill si excede.\n    cpu: \"1000m\"                                # Throttling si excede.\n</code></pre> <p>Best practice: - <code>requests</code>: Uso t\u00edpico (P50) - <code>limits</code>: Uso pico aceptable (P99)</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-94-prometheus-scraping","title":"Pregunta 94: Prometheus Scraping","text":"<p>\u00bfC\u00f3mo configuras Prometheus para scraping?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_40","title":"Respuesta:","text":"<pre><code># prometheus-config.yaml\nscrape_configs:\n  - job_name: 'bankchurn-predictor'             # Nombre del job.\n    kubernetes_sd_configs:                      # Descubrimiento en K8s.\n    - role: pod\n      namespaces:\n        names: [ml-portfolio]                   # Solo este namespace.\n    relabel_configs:\n    - source_labels: [__meta_kubernetes_pod_label_app]\n      action: keep                              # Solo pods con este label.\n      regex: bankchurn-predictor\n</code></pre> <p>Annotations en Deployment: <pre><code>annotations:\n  prometheus.io/scrape: \"true\"                  # Habilita scraping.\n  prometheus.io/port: \"8000\"                    # Puerto de m\u00e9tricas.\n  prometheus.io/path: \"/metrics\"                # Path del endpoint.\n</code></pre></p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-95-configmap-usage","title":"Pregunta 95: ConfigMap Usage","text":"<p>\u00bfCu\u00e1ndo usas ConfigMap vs Secret?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_41","title":"Respuesta:","text":"Dato Usar MODEL_VERSION ConfigMap LOG_LEVEL ConfigMap API_KEY Secret DB_PASSWORD Secret <pre><code># ConfigMap\napiVersion: v1\nkind: ConfigMap\ndata:\n  MODEL_VERSION: \"v2.0.0\"\n  LOG_LEVEL: \"INFO\"\n---\n# Montaje en pod\nenvFrom:\n  - configMapRef:\n      name: bankchurn-config\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-96-rolling-update-strategy","title":"Pregunta 96: Rolling Update Strategy","text":"<p>Explica tu estrategia de actualizaci\u00f3n.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_42","title":"Respuesta:","text":"<pre><code>spec:\n  replicas: 3                                   # 3 pods para HA.\n  strategy:\n    type: RollingUpdate                         # Actualizaci\u00f3n gradual.\n    rollingUpdate:\n      maxUnavailable: 1                         # M\u00e1ximo 1 pod down durante update.\n      maxSurge: 1                               # M\u00e1ximo 1 pod extra temporal.\n</code></pre> <p>Flujo con 3 replicas: 1. Crear 1 nuevo pod (4 total) 2. Cuando nuevo est\u00e1 Ready, terminar 1 viejo (3 total) 3. Repetir hasta todos actualizados</p> <p>Zero downtime con readiness probes correctos.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-97-volume-mounts-para-modelos","title":"Pregunta 97: Volume Mounts para Modelos","text":"<p>\u00bfC\u00f3mo montas modelos en K8s?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_43","title":"Respuesta:","text":"<pre><code>spec:\n  containers:\n  - name: bankchurn-api\n    volumeMounts:\n    - name: models\n      mountPath: /app/models                    # D\u00f3nde montar en container.\n      readOnly: true                            # Solo lectura.\n  volumes:\n  - name: models\n    persistentVolumeClaim:\n      claimName: ml-models-pvc                  # PVC con modelos.\n</code></pre> <p>Alternativas: - PVC: Modelos compartidos entre pods - S3/GCS: Descarga al inicio - ConfigMap: Solo para configs peque\u00f1os</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-98-ingress-configuration","title":"Pregunta 98: Ingress Configuration","text":"<p>\u00bfC\u00f3mo expones servicios externamente?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_44","title":"Respuesta:","text":"<pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ml-portfolio-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - host: bankchurn.example.com\n    http:\n      paths:\n      - path: /\n        backend:\n          service:\n            name: bankchurn-service\n            port:\n              number: 8000\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-99-terraform-overview","title":"Pregunta 99: Terraform Overview","text":"<p>\u00bfQu\u00e9 infraestructura defines con Terraform?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_45","title":"Respuesta:","text":"<pre><code>infra/terraform/\n\u251c\u2500\u2500 aws/\n\u2502   \u251c\u2500\u2500 main.tf      # EKS cluster, S3, RDS\n\u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u2514\u2500\u2500 outputs.tf\n\u2514\u2500\u2500 gcp/\n    \u251c\u2500\u2500 main.tf      # GKE, GCS, CloudSQL\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Recursos t\u00edpicos: - Container registry (ECR/GCR) - Kubernetes cluster (EKS/GKE) - Object storage (S3/GCS) para modelos - Database (RDS/CloudSQL) para MLflow</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-100-disaster-recovery","title":"Pregunta 100: Disaster Recovery","text":"<p>\u00bfC\u00f3mo manejas DR para ML systems?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_46","title":"Respuesta:","text":"<p>1. Model artifacts: - S3 versioning + cross-region replication - Git LFS / DVC como backup secundario</p> <p>2. MLflow database: - RDS multi-AZ + daily snapshots - Point-in-time recovery</p> <p>3. Kubernetes: - Declarative configs en Git (GitOps) - Multi-region deployment para HA</p> <p>RTO/RPO objetivos: - RTO (Recovery Time): &lt; 1 hora - RPO (Recovery Point): &lt; 1 d\u00eda de experimentos</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-102-105-etica-continuacion","title":"Preguntas 102-105: \u00c9tica (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-102-bias-detection","title":"Pregunta 102: Bias Detection","text":"<p>\u00bfC\u00f3mo detectas bias en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_47","title":"Respuesta:","text":"<pre><code># Monitoreo continuo\nfor segment in [\"Geography\", \"Gender\", \"Age_bucket\"]:  # Variables sensibles.\n    pred_rate = predictions.groupby(segment)[\"churn_pred\"].mean()  # Tasa por grupo.\n    log_metric(f\"pred_rate_{segment}\", pred_rate.to_dict())  # M\u00e9trica para dashboard.\n\n    # Alerta si disparate impact &lt; 0.8\n    di = pred_rate.min() / pred_rate.max()      # Ratio m\u00edn/m\u00e1x.\n    if di &lt; 0.8:                                # Threshold de fairness.\n        alert(f\"Potential bias in {segment}: DI={di}\")\n</code></pre>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-103-model-card-maintenance","title":"Pregunta 103: Model Card Maintenance","text":"<p>\u00bfCon qu\u00e9 frecuencia actualizas Model Cards?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_48","title":"Respuesta:","text":"<p>Actualizar cuando: - Nueva versi\u00f3n del modelo - Cambio en datos de entrenamiento - Descubrimiento de limitaci\u00f3n/bias - Cambio en uso previsto</p> <p>Versionado: Model Card versi\u00f3n = Model versi\u00f3n (<code>v1.0.0</code>).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-104-human-in-the-loop","title":"Pregunta 104: Human-in-the-Loop","text":"<p>\u00bfC\u00f3mo integras supervisi\u00f3n humana?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_49","title":"Respuesta:","text":"<p>BankChurn: - Modelo sugiere clientes en riesgo - Equipo de retenci\u00f3n revisa lista - Decisi\u00f3n final es humana (llamar o no)</p> <p>No automatizar: Ofertas, descuentos, cierre de cuentas.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-105-gdpr-compliance","title":"Pregunta 105: GDPR Compliance","text":"<p>\u00bfC\u00f3mo manejas datos personales?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_50","title":"Respuesta:","text":"<ol> <li>Minimizaci\u00f3n: Solo features necesarias (no nombre, email)</li> <li>Pseudonimizaci\u00f3n: CustomerID sin mapeo a identidad real</li> <li>Right to erasure: Pipeline para eliminar datos de un cliente</li> <li>Audit trail: Logs de predicciones (sin PII) para auditor\u00eda</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preguntas-107-115-liderazgo-continuacion","title":"Preguntas 107-115: Liderazgo (continuaci\u00f3n)","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-107-team-communication","title":"Pregunta 107: Team Communication","text":"<p>\u00bfC\u00f3mo comunicas decisiones t\u00e9cnicas al equipo?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_51","title":"Respuesta:","text":"<ol> <li>ADRs (Architecture Decision Records): Documentar why, not just what</li> <li>Tech talks: Sesiones de 30 min sobre decisiones importantes</li> <li>PR descriptions: Contexto suficiente para reviewers</li> <li>Diagrams: Mermaid/Lucidchart para arquitectura</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-108-mentoring-junior-engineers","title":"Pregunta 108: Mentoring Junior Engineers","text":"<p>\u00bfC\u00f3mo mentoras a juniors en ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_52","title":"Respuesta:","text":"<ol> <li>Pair programming: En primeros PRs de ML</li> <li>Code review detallado: Explicar el \"por qu\u00e9\"</li> <li>Recursos curados: Pointing to best practices</li> <li>Proyectos graduales: Simple \u2192 Complejo</li> </ol> <p>Errores comunes a prevenir: - Data leakage (el m\u00e1s cr\u00edtico) - Overfitting sin validaci\u00f3n - M\u00e9tricas incorrectas para el problema</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-109-stakeholder-management","title":"Pregunta 109: Stakeholder Management","text":"<p>\u00bfC\u00f3mo manejas expectativas de stakeholders?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_53","title":"Respuesta:","text":"<ol> <li>Baseline comparison: \"El modelo mejora X% sobre regla actual\"</li> <li>Confidence intervals: \"Precisi\u00f3n entre 75-85%\"</li> <li>Limitations expl\u00edcitas: \"No funciona bien para casos X\"</li> <li>Iterative delivery: MVP \u2192 Mejoras incrementales</li> </ol> <p>Evitar: Prometer 99% accuracy, plazos imposibles, omitir limitaciones.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-110-technical-debt-negotiation","title":"Pregunta 110: Technical Debt Negotiation","text":"<p>\u00bfC\u00f3mo negocias tiempo para tech debt?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_54","title":"Respuesta:","text":"<p>Argumentos efectivos: 1. Riesgo cuantificado: \"Sin tests, bugs llegan a prod\" 2. Velocity impact: \"Refactor ahora ahorra X horas/semana\" 3. Costo de delay: \"Cada mes aumenta esfuerzo 20%\"</p> <p>Estrategia: 20% del sprint para tech debt (negociado upfront).</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-111-production-incident-response","title":"Pregunta 111: Production Incident Response","text":"<p>\u00bfC\u00f3mo manejas un incidente en producci\u00f3n?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_55","title":"Respuesta:","text":"<p>Playbook: 1. Detect: Alertas de Prometheus/PagerDuty 2. Triage: Severity assessment (P1-P4) 3. Communicate: Status page update 4. Mitigate: Rollback if needed 5. Fix: Root cause resolution 6. Postmortem: Blameless an\u00e1lisis</p> <p>Para ML espec\u00edfico: Rollback = deploy versi\u00f3n anterior del modelo.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-112-cross-functional-collaboration","title":"Pregunta 112: Cross-functional Collaboration","text":"<p>\u00bfC\u00f3mo trabajas con Data Scientists vs ML Engineers?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_56","title":"Respuesta:","text":"Rol Responsabilidad Data Scientist Exploraci\u00f3n, feature engineering, model selection ML Engineer Productionization, CI/CD, monitoring Overlap Evaluaci\u00f3n, experiments <p>Handoff: DS entrega notebook + requirements, MLE convierte a pipeline.</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-113-prioritization-framework","title":"Pregunta 113: Prioritization Framework","text":"<p>\u00bfC\u00f3mo priorizas features de ML?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_57","title":"Respuesta:","text":"<p>RICE Score: - Reach: \u00bfCu\u00e1ntos usuarios afecta? - Impact: \u00bfCu\u00e1nto mejora m\u00e9tricas? - Confidence: \u00bfQu\u00e9 tan seguros estamos? - Effort: \u00bfCu\u00e1nto trabajo requiere?</p> <p>Score = (R \u00d7 I \u00d7 C) / E</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-114-remote-team-leadership","title":"Pregunta 114: Remote Team Leadership","text":"<p>\u00bfC\u00f3mo lideras equipos remotos?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_58","title":"Respuesta:","text":"<ol> <li>Async by default: Documentaci\u00f3n &gt; meetings</li> <li>Overlap hours: 2-3 horas para sync</li> <li>Clear ownership: Cada task tiene responsable</li> <li>Over-communication: Status updates frecuentes</li> <li>Trust + accountability: Medir outcomes, no horas</li> </ol>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#pregunta-115-career-growth-path","title":"Pregunta 115: Career Growth Path","text":"<p>\u00bfC\u00f3mo defines el growth path para ML Engineers?</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#respuesta_59","title":"Respuesta:","text":"<pre><code>Junior ML Engineer\n  \u2193 (1-2 a\u00f1os)\nML Engineer\n  \u2193 (2-3 a\u00f1os)\nSenior ML Engineer\n  \u2193 (2-4 a\u00f1os)\n  \u251c\u2500\u2192 Staff ML Engineer (IC track)\n  \u2514\u2500\u2192 ML Engineering Manager (Management track)\n</code></pre> <p>Skills por nivel: - Junior: Implementar pipelines existentes - Mid: Dise\u00f1ar nuevos pipelines - Senior: Arquitectura end-to-end, mentoring - Staff: Cross-team influence, technical vision</p>"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#resumen-y-recursos","title":"\ud83d\udcda Resumen y Recursos","text":""},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#skills-demostrados-en-este-portafolio","title":"Skills Demostrados en Este Portafolio","text":"\u00c1rea Evidencia ML Fundamentals 3 proyectos: clasificaci\u00f3n, regresi\u00f3n, ensemble MLOps MLflow, DVC, CI/CD, monitoring Software Engineering Pydantic, tests, modular design DevOps Docker, K8s, Terraform Leadership Documentation, decisions, trade-offs"},{"location":"docs/SIMULACRO_ENTREVISTA_SENIOR_PARTE2/#preparacion-adicional-recomendada","title":"Preparaci\u00f3n Adicional Recomendada","text":"<ol> <li>System Design: Dise\u00f1ar ML system de principio a fin</li> <li>Coding Interview: LeetCode medium (estructuras de datos)</li> <li>Behavioral: STAR method para experiencias pasadas</li> <li>Deep Dive: Estar listo para explicar CUALQUIER l\u00ednea de c\u00f3digo</li> </ol> <p>Fin del Simulacro de Entrevista</p> <p>Generado basado en an\u00e1lisis exhaustivo del portafolio ML-MLOps</p>"},{"location":"docs/SYLLABUS/","title":"\ud83d\udcc5 SYLLABUS \u2014 Gu\u00eda MLOps (Portfolio Edition)","text":"<p>Ruta principal (recomendada): 24 semanas (6 meses).</p> <p>Ruta acelerada: 8 semanas.</p> <p>\ud83d\uddfa\ufe0f Mapa 1:1 Portafolio \u2192 Gu\u00eda: MAPA_PORTAFOLIO_1TO1.md</p> <p>\ud83d\udccc Navegaci\u00f3n: Este documento complementa el \u00cdndice Principal (00_INDICE.md) con detalles de macro-m\u00f3dulos y progresi\u00f3n 0 \u2192 Senior/Staff. Para la estructura m\u00f3dulo por m\u00f3dulo, consulta el \u00edndice.</p>"},{"location":"docs/SYLLABUS/#objetivo-del-programa","title":"\ud83c\udfaf Objetivo del Programa","text":"<p>Al completar este programa ser\u00e1s capaz de:</p> <ul> <li>\u2705 Reproducir 100% de los artefactos clave del portafolio (modelos, APIs, dashboards)</li> <li>\u2705 Implementar CI/CD profesional con 80%+ coverage</li> <li>\u2705 Dise\u00f1ar arquitecturas ML production-ready</li> <li>\u2705 Pasar entrevistas t\u00e9cnicas nivel Senior/Staff</li> <li>\u2705 Crear Model Cards y Dataset Cards completos</li> <li>\u2705 Implementar observabilidad y monitoreo b\u00e1sico</li> </ul> <p>## \ud83d\udcca Estructura del Programa (12 M\u00f3dulos) \u2014 Ruta acelerada (8 semanas)</p> M\u00f3dulo Nombre Duraci\u00f3n Mini-Proyecto 00 Introducci\u00f3n 0.5 d\u00edas Setup inicial 01 Python Moderno 2 d\u00edas Librer\u00eda <code>utils/</code> 02 Ingenier\u00eda de Datos 4 d\u00edas ETL reproducible 03 Feature Engineering 3 d\u00edas Transformadores <code>.pkl</code> 04 Modelado 6 d\u00edas Scripts de entrenamiento 05 MLflow &amp; DVC 3 d\u00edas Tracking local 06 Despliegue API 3 d\u00edas FastAPI <code>/predict</code> 07 Dashboard 2 d\u00edas Streamlit app 08 CI/CD &amp; Testing 3 d\u00edas GitHub Actions 09 Model &amp; Dataset Cards 1.5 d\u00edas Documentaci\u00f3n ML 10 Observabilidad 2 d\u00edas Logging + alertas 11 Mantenimiento &amp; Auditor\u00eda 2 d\u00edas Runbooks <p>Tiempo total estimado (ruta acelerada): 32 d\u00edas (~6-8 semanas a ritmo moderado)</p> <p>Si sigues la ruta principal (24 semanas), usa este mismo mapa pero con m\u00e1s pr\u00e1ctica, debugging y entregables (ver <code>README.md</code> del repo y el <code>00_INDICE.md</code>).</p> <p>## \ud83e\udded Ruta 0 \u2192 Senior/Staff (macro-m\u00f3dulos)</p> <p>Esta ruta agrupa los 23 m\u00f3dulos de la gu\u00eda en 11 macro-m\u00f3dulos que siguen el plan \"0 \u2192 Senior/Staff MLOps\" que definiste. No reemplaza la numeraci\u00f3n actual (01\u201323), sino que ofrece una vista de alto nivel basada en madurez.</p> Macro-M\u00f3dulo Nombre Objetivo principal M\u00f3dulos relacionados 00 Entorno, Herramientas y Flujo de Trabajo Poder ejecutar los 3 proyectos del portafolio en tu m\u00e1quina 00_INDICE, 03_ESTRUCTURA_PROYECTO, 04_ENTORNOS, 05_GIT_PROFESIONAL, 17_DESPLIEGUE, PLAN_ESTUDIOS, QUICK_START del repo 01 Python Fundamentos para Producci\u00f3n Pasar de Python junior a escribir c\u00f3digo pythonico y mantenible 01_PYTHON_MODERNO, 03_ESTRUCTURA_PROYECTO, common_utils/* 02 Fundamentos de Data Science y ML Tener bases s\u00f3lidas de DS/ML antes de entrar a MLOps 07_SKLEARN_PIPELINES, 08_INGENIERIA_FEATURES, 09_TRAINING_PROFESIONAL, notebooks de los proyectos 03 Ingenier\u00eda de Datos Aplicada a ML Preparar datos como en una empresa, pensando en ML downstream 06_VERSIONADO_DATOS, 08_INGENIERIA_FEATURES, partes de TelecomAI-Customer-Intelligence 04 Fundamentos de MLOps Entender reproducibilidad, versionado y artefactos 06_VERSIONADO_DATOS, 10_EXPERIMENT_TRACKING, DECISIONES_TECH, 22_CHECKLIST 05 Pipelines + CI/CD Construir pipelines reales con tests y gates de calidad 07_SKLEARN_PIPELINES, 11_TESTING_ML, 12_CI_CD, workflows de .github/workflows/ 06 Model Deployment Desplegar modelos con nivel Senior (APIs, Docker, serverless) 13_DOCKER, 14_FASTAPI, 17_DESPLIEGUE, docker-compose.demo.yml 07 Monitoring, Observabilidad y Alertas Diferenciarte como Senior mediante observabilidad real 16_OBSERVABILIDAD, 22_CHECKLIST, dashboards de Grafana 08 Infraestructura y Nube Operar como engineer: IaC, redes y cloud basics 17_DESPLIEGUE, 18_INFRAESTRUCTURA, infra/terraform/, k8s/ 09 Escalado y Sistemas Distribuidos Pensar en batch/streaming y K8s para ML a gran escala 18_INFRAESTRUCTURA, partes avanzadas de 17_DESPLIEGUE, tests/load/* 10 Seguridad, Gobernanza y Cumplimiento Tratar el portafolio como un sistema empresarial 19_DOCUMENTACION, 12_CI_CD (gitleaks, security), .gitleaks.toml, RUNBOOK.md 11 Arquitectura MLOps Senior/Staff Ver el sistema completo: multi-model, observabilidad y gobierno 23_PROYECTO_INTEGRADOR, apoyo/GLOSARIO, apoyo/RECURSOS, DECISIONES_TECH, RUNBOOK.md <p>Guion resumido por macro-m\u00f3dulo</p> <p>M\u00d3DULO 00 \u2014 Entorno, Herramientas y Flujo de Trabajo  Objetivo: garantizar que puedas ejecutar los 3 proyectos (BankChurn, CarVision, TelecomAI).  Incluye: Conda/pipx/uv, Docker + Docker Compose, Git + branching, VS Code + DevContainers, Makefiles, estructura est\u00e1ndar ML/MLOps.  Pr\u00e1ctica en este repo: seguir <code>00_INDICE.md</code>, <code>PLAN_ESTUDIOS.md</code> y el QUICK_START de la ra\u00edz hasta ejecutar BankChurn end-to-end.</p> <p>M\u00d3DULO 01 \u2014 Python Fundamentos para Producci\u00f3n  Objetivo: llevar de Python junior a c\u00f3digo pythonico y mantenible.  Incluye: POO aplicada a ML, tipado est\u00e1tico (mypy), logging profesional, manejo de errores, estructura de paquetes.  Pr\u00e1ctica en este repo: trabajar <code>01_PYTHON_MODERNO.md</code> y refactorizar utilidades en <code>common_utils/</code> y el c\u00f3digo de BankChurn.</p> <p>M\u00d3DULO 02 \u2014 Fundamentos de Data Science y ML  Objetivo: construir bases s\u00f3lidas de DS/ML antes de MLOps.  Incluye: exploraci\u00f3n, limpieza, feature engineering, validaci\u00f3n cruzada, overfitting/underfitting.  Pr\u00e1ctica en este repo: rehacer el pipeline de features y validaci\u00f3n de BankChurn apoy\u00e1ndote en <code>07_SKLEARN_PIPELINES.md</code>, <code>08_INGENIERIA_FEATURES.md</code> y <code>09_TRAINING_PROFESIONAL.md</code>.</p> <p>M\u00d3DULO 03 \u2014 Ingenier\u00eda de Datos Aplicada a ML  Objetivo: preparar datos como en una empresa, pensando en su uso en modelos.  Incluye: ETL/ELT, orquestaci\u00f3n ligera, data quality, feature stores.  Pr\u00e1ctica en este repo: usar <code>06_VERSIONADO_DATOS.md</code> y <code>08_INGENIERIA_FEATURES.md</code> para montar un mini feature store inspirado en TelecomAI.</p> <p>M\u00d3DULO 04 \u2014 Fundamentos de MLOps  Objetivo: introducir el mindset MLOps (reproducibilidad, versionado, artefactos).  Incluye: versionado de datos y modelos, ML metadata, experiment tracking, artefactos.  Pr\u00e1ctica en este repo: integrar MLflow y DVC a BankChurn siguiendo <code>06_VERSIONADO_DATOS.md</code>, <code>10_EXPERIMENT_TRACKING.md</code> y <code>DECISIONES_TECH.md</code>.</p> <p>M\u00d3DULO 05 \u2014 Pipelines + CI/CD  Objetivo: crear pipelines reales con CI/CD enterprise-like.  Incluye: GitHub Actions, testing, coverage, code-quality gates.  Pr\u00e1ctica en este repo: combinar <code>07_SKLEARN_PIPELINES.md</code>, <code>11_TESTING_ML.md</code> y <code>12_CI_CD.md</code> para obtener un pipeline completo para los 3 proyectos usando los workflows reales del repositorio.</p> <p>M\u00d3DULO 06 \u2014 Model Deployment  Objetivo: desplegar con nivel Senior.  Incluye: APIs con FastAPI, dockerizaci\u00f3n, serverless, patrones de model serving.  Pr\u00e1ctica en este repo: usar <code>13_DOCKER.md</code>, <code>14_FASTAPI.md</code> y <code>17_DESPLIEGUE.md</code> para desplegar CarVision en contenedor + endpoint (local y/o cloud).</p> <p>M\u00d3DULO 07 \u2014 Monitoring, Observabilidad y Alertas  Objetivo: incorporar observabilidad que diferencie un junior de un senior.  Incluye: concept vs data drift, monitoreo de features/predicciones, logging estructurado, Prometheus + Grafana.  Pr\u00e1ctica en este repo: seguir <code>16_OBSERVABILIDAD.md</code> para instrumentar BankChurn con m\u00e9tricas y paneles, apoy\u00e1ndote en los manifiestos de <code>k8s/</code> y las reglas de <code>infra/</code>.</p> <p>M\u00d3DULO 08 \u2014 Infraestructura y Nube  Objetivo: operar como un engineer en cloud.  Incluye: IaC (Terraform), fundamentos AWS/GCP, redes, seguridad b\u00e1sica y control de costos (FinOps) para evitar sorpresas en la factura.  Pr\u00e1ctica en este repo: partir de <code>17_DESPLIEGUE.md</code> y <code>18_INFRAESTRUCTURA.md</code> (especialmente la secci\u00f3n Cloud y Control de Costos) para desplegar un stack MLOps b\u00e1sico en cloud (o simularlo localmente con los manifests y Terraform). </p> <p>M\u00d3DULO 09 \u2014 Escalado y Sistemas Distribuidos  Objetivo: pensar en batch/streaming y K8s para producci\u00f3n masiva.  Incluye: batch vs streaming, Kubernetes, automatizaci\u00f3n avanzada.  Pr\u00e1ctica en este repo: usar las secciones avanzadas de <code>18_INFRAESTRUCTURA.md</code>, los manifests en <code>k8s/</code> y los tests de carga en <code>tests/load/</code> como base para dise\u00f1ar un despliegue escalable de CarVision.</p> <p>M\u00d3DULO 10 \u2014 Seguridad, Gobernanza y Cumplimiento  Objetivo: llevar la senioridad al plano empresarial.  Incluye: pol\u00edticas, roles, seguridad de repos (secrets, escaneo), Model Cards y \u00e9tica.  Pr\u00e1ctica en este repo: combinar <code>19_DOCUMENTACION.md</code>, la configuraci\u00f3n de <code>12_CI_CD.md</code> (gitleaks, security scanning) y <code>.gitleaks.toml</code> para definir pol\u00edticas m\u00ednimas y completar Model Cards para los 3 proyectos.</p> <p>M\u00d3DULO 11 \u2014 Arquitectura MLOps Senior/Staff  Objetivo: tener visi\u00f3n completa de sistemas reales (multi-model, gobierno, observabilidad a gran escala).  Incluye: arquitecturas event-driven, multi-model governance, patrones de observabilidad.  Pr\u00e1ctica en este repo: usar <code>23_PROYECTO_INTEGRADOR.md</code>, <code>DECISIONES_TECH.md</code> y <code>RUNBOOK.md</code> para dise\u00f1ar y documentar una arquitectura MLOps completa que integre los 3 proyectos.</p> <p>Puedes usar:</p> <ul> <li>Esta secci\u00f3n para entender el mapa mental 0 \u2192 Senior/Staff.</li> <li>El \u00edndice de 23 m\u00f3dulos (<code>00_INDICE.md</code>) y el plan por semanas para avanzar paso a paso.</li> </ul> <p>## \ud83d\udcda Detalle por M\u00f3dulo</p>"},{"location":"docs/SYLLABUS/#modulo-00-introduccion-05-dias","title":"M\u00f3dulo 00 \u2014 Introducci\u00f3n (0.5 d\u00edas)","text":"Contenido Entregable Objetivos del curso \u2705 Entender el roadmap C\u00f3mo leer la gu\u00eda \u2705 Setup de herramientas Requerimientos m\u00ednimos \u2705 Entorno listo Mapa gu\u00eda \u2192 repo \u2705 Comprensi\u00f3n de estructura <p>Output: Entorno de desarrollo listo, comprensi\u00f3n clara del objetivo final.</p>"},{"location":"docs/SYLLABUS/#modulo-01-python-moderno-2-dias","title":"M\u00f3dulo 01 \u2014 Python Moderno (2 d\u00edas)","text":"Contenido Entregable Type hints y tipado est\u00e1tico C\u00f3digo tipado Dataclasses y Pydantic Config validado OOP y SOLID b\u00e1sico Clases bien dise\u00f1adas Estructura de paquete <code>utils/</code> funcional <p>Mini-Proyecto: Crear librer\u00eda <code>utils/</code> con <code>config.py</code> (Pydantic) y <code>mathops.py</code> (funciones tipadas).</p> <p>Validar: <code>make check-01</code></p>"},{"location":"docs/SYLLABUS/#modulo-02-ingenieria-de-datos-4-dias","title":"M\u00f3dulo 02 \u2014 Ingenier\u00eda de Datos (4 d\u00edas)","text":"Contenido Entregable Lectura/escritura de datos Loaders reutilizables Validaci\u00f3n con schemas Contratos de datos Transformaciones b\u00e1sicas ETL reproducible Tests de integridad Datos validados <p>Mini-Proyecto: ETL que produce CSV/Parquet reproducible + tests de integridad.</p> <p>Validar: <code>make check-02</code></p>"},{"location":"docs/SYLLABUS/#modulo-03-feature-engineering-3-dias","title":"M\u00f3dulo 03 \u2014 Feature Engineering (3 d\u00edas)","text":"Contenido Entregable Pipelines serializables Pipeline persistido Custom encoders Transformadores <code>.pkl</code> Prevenci\u00f3n de data leakage C\u00f3digo seguro Persistencia de artefactos Artefactos reutilizables <p>Mini-Proyecto: <code>FeatureEngineer</code> class con transformadores serializados.</p> <p>Validar: <code>make check-03</code></p>"},{"location":"docs/SYLLABUS/#modulo-04-modelado-6-dias","title":"M\u00f3dulo 04 \u2014 Modelado (6 d\u00edas)","text":"Contenido Entregable Pipelines sklearn completos Pipeline unificado Validaci\u00f3n temporal/cruzada CV implementado Hyperparameter tuning B\u00fasqueda de hiperpar\u00e1metros Experimentaci\u00f3n reproducible Scripts de entrenamiento <p>Mini-Proyecto: Scripts que generan modelos y reportes en <code>outputs/</code>.</p> <p>Validar: <code>make check-04</code></p>"},{"location":"docs/SYLLABUS/#modulo-05-mlflow-dvc-3-dias","title":"M\u00f3dulo 05 \u2014 MLflow &amp; DVC (3 d\u00edas)","text":"Contenido Entregable MLflow server local <code>mlflow ui</code> funcionando Tracking de experimentos M\u00e9tricas registradas DVC init y pipelines <code>dvc.yaml</code> configurado Versionado de artefactos Datos versionados <p>Mini-Proyecto: <code>mlruns/</code> y <code>dvc/</code> que emulan el flujo del repo.</p> <p>Validar: <code>make check-05</code></p>"},{"location":"docs/SYLLABUS/#modulo-06-despliegue-api-3-dias","title":"M\u00f3dulo 06 \u2014 Despliegue API (3 d\u00edas)","text":"Contenido Entregable FastAPI b\u00e1sico API funcional Schemas Pydantic Request/Response tipados Tests de integraci\u00f3n Tests pasando Dockerfile Contenedor listo <p>Mini-Proyecto: API local con endpoint <code>/predict</code> funcional.</p> <p>Validar: <code>make check-06</code></p>"},{"location":"docs/SYLLABUS/#modulo-07-dashboard-2-dias","title":"M\u00f3dulo 07 \u2014 Dashboard (2 d\u00edas)","text":"Contenido Entregable Streamlit b\u00e1sico App funcionando Consumo de API Integraci\u00f3n con backend Caching y optimizaci\u00f3n Performance aceptable Ejemplo desplegable Ready to deploy <p>Mini-Proyecto: Dashboard Streamlit que consume la API local.</p> <p>Validar: <code>make check-07</code></p>"},{"location":"docs/SYLLABUS/#modulo-08-cicd-testing-3-dias","title":"M\u00f3dulo 08 \u2014 CI/CD &amp; Testing (3 d\u00edas)","text":"Contenido Entregable GitHub Actions Workflow configurado Matrix testing Tests multi-versi\u00f3n Coverage reports 80%+ coverage Security scanning gitleaks local <p>Mini-Proyecto: <code>ci_template.yml</code> funcional, simulaci\u00f3n local con <code>act</code>.</p> <p>Validar: <code>make check-08</code></p>"},{"location":"docs/SYLLABUS/#modulo-09-model-dataset-cards-15-dias","title":"M\u00f3dulo 09 \u2014 Model &amp; Dataset Cards (1.5 d\u00edas)","text":"Contenido Entregable Plantilla Model Card Template relleno Plantilla Dataset Card Template relleno Buenas pr\u00e1cticas de documentaci\u00f3n Docs completos Ejemplos del portafolio Cards reales <p>Mini-Proyecto: Model Card y Dataset Card completados para un mini-proyecto.</p> <p>Validar: <code>make check-09</code></p>"},{"location":"docs/SYLLABUS/#modulo-10-observabilidad-monitoring-2-dias","title":"M\u00f3dulo 10 \u2014 Observabilidad &amp; Monitoring (2 d\u00edas)","text":"Contenido Entregable Logging estructurado Logs configurados M\u00e9tricas b\u00e1sicas Latencia, error rate Simulaci\u00f3n de alertas Scripts de alerta Drift detection b\u00e1sico Checks implementados <p>Mini-Proyecto: Sistema con logging estructurado y scripts de alerta.</p> <p>Validar: <code>make check-10</code></p>"},{"location":"docs/SYLLABUS/#modulo-11-mantenimiento-auditoria-2-dias","title":"M\u00f3dulo 11 \u2014 Mantenimiento &amp; Auditor\u00eda (2 d\u00edas)","text":"Contenido Entregable Playbooks de mantenimiento Runbooks documentados Tests de regresi\u00f3n Regression tests Actualizaci\u00f3n de dependencias Proceso documentado Calendario de revisiones Plan de mantenimiento <p>Mini-Proyecto: MAINTENANCE_GUIDE.md y scripts de validaci\u00f3n.</p> <p>Validar: <code>make check-11</code></p>"},{"location":"docs/SYLLABUS/#modulos-avanzados-seniorstaff","title":"\ud83d\ude80 M\u00f3dulos Avanzados (Senior/Staff)","text":"<p>Estos m\u00f3dulos cubren temas avanzados para nivel Senior/Staff:</p>"},{"location":"docs/SYLLABUS/#modulo-20-observabilidad-avanzada-y-drift-3-dias","title":"M\u00f3dulo 20 \u2014 Observabilidad Avanzada y Drift (3 d\u00edas)","text":"Contenido Entregable Detecci\u00f3n estad\u00edstica de drift (KS-test, PSI) Detector funcionando EvidentlyAI / Alibi Detect Reportes automatizados Alertas multi-nivel Sistema de alertas M\u00e9tricas ML \u2192 KPIs de negocio Dashboard de impacto <p>Mini-Proyecto: Sistema que detecta datos corruptos antes de retrain.</p> <p>Documento: 20_OBSERVABILIDAD_AVANZADA_DRIFT.md</p> <p>Examen relacionado: EXAM_05_PRODUCTION</p>"},{"location":"docs/SYLLABUS/#modulo-21-cloud-finops-y-estrategia-2-dias","title":"M\u00f3dulo 21 \u2014 Cloud FinOps y Estrategia (2 d\u00edas)","text":"Contenido Entregable Costos ML: Training vs Inference Calculadora de costos Spot vs On-Demand vs Reserved Estrategia documentada Auto-scaling inteligente HPA configurado C\u00e1lculo de TCO An\u00e1lisis completo <p>Mini-Proyecto: Reducir TCO del Portfolio en 30%.</p> <p>Documento: 21_CLOUD_FINOPS.md</p> <p>Recursos: Material de Apoyo</p>"},{"location":"docs/SYLLABUS/#modulo-22-infrastructure-as-code-empresarial-3-dias","title":"M\u00f3dulo 22 \u2014 Infrastructure as Code Empresarial (3 d\u00edas)","text":"Contenido Entregable Gesti\u00f3n de estado Terraform State locking configurado Arquitectura multi-ambiente Dev/Staging/Prod M\u00f3dulos reutilizables Terraform modules CI/CD para infraestructura Pipeline de infra <p>Mini-Proyecto: Refactorizar infra/ para soportar Staging.</p> <p>Documento: 22_IAC_EMPRESARIAL.md</p> <p>Examen Final: EXAM_06_INTEGRATION</p>"},{"location":"docs/SYLLABUS/#rubrica-de-evaluacion-100-puntos-por-modulo","title":"\ud83d\udcca R\u00fabrica de Evaluaci\u00f3n (100 puntos por m\u00f3dulo)","text":"Criterio Puntos Descripci\u00f3n Funcionalidad 40 Pasa tests m\u00ednimos, produce outputs esperados Calidad del c\u00f3digo 20 Linters, type hints, modularidad Documentaci\u00f3n 15 README, Model/Dataset Cards Reproducibilidad 15 Instrucciones make, lockfile, ejecuci\u00f3n local Tests y cobertura 10 Pruebas unitarias/integraci\u00f3n m\u00ednimas <p>Nota m\u00ednima aprobatoria: 70/100 por m\u00f3dulo</p>"},{"location":"docs/SYLLABUS/#progreso-sugerido","title":"\ud83d\udcc8 Progreso Sugerido","text":""},{"location":"docs/SYLLABUS/#ruta-acelerada-8-semanas","title":"Ruta Acelerada (8 semanas)","text":"<pre><code>Semana 1:   M\u00f3dulos 00-01 (Fundamentos Python)\nSemana 2:   M\u00f3dulos 02-03 + 03B/03C (Datos, Features, Refactoring)\nSemana 3:   M\u00f3dulo 04 (Modelado completo)\nSemana 4:   M\u00f3dulos 05-06 (Tracking + API)\nSemana 5:   M\u00f3dulos 07-08 (Dashboard + CI/CD)\nSemana 6:   M\u00f3dulos 09-11 (Docs + Mantenimiento)\nSemana 7:   M\u00f3dulos 20-21 (Observabilidad + FinOps)\nSemana 8:   M\u00f3dulo 22 + Proyecto Integrador (IaC + Consolidaci\u00f3n)\n</code></pre>"},{"location":"docs/SYLLABUS/#ruta-principal-24-semanas","title":"Ruta Principal (24 semanas)","text":"<pre><code>Mes 1:      M\u00f3dulos 00-03 + Ejercicios Puente\nMes 2:      M\u00f3dulos 04-06 (Modelado + Tracking + API)\nMes 3:      M\u00f3dulos 07-11 (Dashboard + CI/CD + Docs)\nMes 4:      M\u00f3dulos 20-22 (Avanzados)\nMes 5:      Proyecto Integrador + Pr\u00e1ctica\nMes 6:      Preparaci\u00f3n Entrevistas + Pulido Portfolio\n</code></pre>"},{"location":"docs/SYLLABUS/#preparacion-para-entrevistas","title":"\ud83c\udfa4 Preparaci\u00f3n para Entrevistas","text":"<p>La gu\u00eda incluye simulacros de entrevista adaptados a cada nivel de experiencia:</p> Nivel Simulacro Preguntas Cu\u00e1ndo Usar \ud83d\udfe2 Junior Simulacro Junior 50 Semanas 1-4 \ud83d\udfe1 Mid Simulacro Mid 60 Semanas 5-6 \ud83d\udd34 Senior Simulacro Senior P1 + P2 115 Semanas 7-8"},{"location":"docs/SYLLABUS/#defensa-del-portafolio","title":"\ud83c\udd95 Defensa del Portafolio","text":"Recurso Descripci\u00f3n DEFENSA_PORTAFOLIO.md Preguntas t\u00e9cnicas sobre decisiones de arquitectura del portafolio <p>Incluye: - Speech de 5-7 minutos: Gui\u00f3n estructurado para presentar tu trabajo - 50+ preguntas por categor\u00eda: Arquitectura, Python, Pipelines, DVC/MLflow, Testing, Docker, CI/CD, Observabilidad, Infraestructura - Escenarios de System Design: Escalado 10x, multi-modelo - Preguntas trampa: C\u00f3mo responder sin caer en errores comunes - R\u00fabrica de autoevaluaci\u00f3n: Mide tu preparaci\u00f3n</p> <p>Progresi\u00f3n recomendada: 1. Junior: Python b\u00e1sico, ML fundamentos, Git, estructura de proyecto 2. Mid: Pipelines, testing, CI/CD, Docker, APIs 3. Senior: System design, arquitectura, liderazgo, trade-offs</p>"},{"location":"docs/SYLLABUS/#los-4-pilares-pedagogicos","title":"\ud83c\udfdb\ufe0f Los 4 Pilares Pedag\u00f3gicos","text":"<p>Cada semana est\u00e1 estructurada en 4 pilares, ahora integrados directamente en cada m\u00f3dulo:</p> Pilar Ubicaci\u00f3n Contenido 1. Teor\u00eda M\u00f3dulos (<code>01_</code> a <code>23_</code>) Conceptos con analog\u00edas del mundo real 2. Pr\u00e1ctica README.md + m\u00f3dulos C\u00f3digo paso a paso, puentes al portafolio 3. La Trampa Secci\u00f3n \"\ud83e\udea4 La Trampa\" al final de cada m\u00f3dulo 50+ errores t\u00edpicos integrados por tema 4. Evaluaci\u00f3n Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" al final de cada m\u00f3dulo Quizzes integrados (3 preguntas + 1 ejercicio)"},{"location":"docs/SYLLABUS/#la-trampa-errores-comunes-integrados","title":"\ud83e\udea4 La Trampa \u2014 Errores Comunes (Integrados)","text":"<p>Al final de cada m\u00f3dulo encontrar\u00e1s errores que todos cometen: - S\u00edntoma: Qu\u00e9 ves cuando caes en la trampa - Causa ra\u00edz: Por qu\u00e9 sucede - Soluci\u00f3n: C\u00f3mo arreglarlo paso a paso - Prevenci\u00f3n: C\u00f3mo evitarlo en el futuro</p>"},{"location":"docs/SYLLABUS/#quizzes-integrados-en-modulos","title":"\ud83d\udcdd Quizzes (Integrados en M\u00f3dulos)","text":"<p>Al final de cada m\u00f3dulo: - 3 preguntas conceptuales (25 pts c/u) - 1 ejercicio pr\u00e1ctico de c\u00f3digo (25 pts) - Total: 100 pts/m\u00f3dulo, m\u00ednimo aprobatorio: 70 pts</p>"},{"location":"docs/SYLLABUS/#prerrequisitos","title":"\u2705 Prerrequisitos","text":"<ul> <li>Python 3.10+ instalado</li> <li>Git b\u00e1sico (clone, commit, push)</li> <li>L\u00ednea de comandos b\u00e1sica (bash/zsh)</li> <li>Cuenta GitHub activa</li> <li>Editor/IDE (VS Code recomendado)</li> <li>8GB RAM m\u00ednimo, 16GB recomendado</li> </ul>"},{"location":"docs/SYLLABUS/#como-usar-la-guia","title":"\ud83d\udee0\ufe0f C\u00f3mo usar la gu\u00eda","text":"<ol> <li>Clonar el repositorio gu\u00eda</li> <li>Ejecutar <code>make setup</code> para preparar el entorno</li> <li>Seguir cada m\u00f3dulo en orden</li> <li>Completar el mini-proyecto de cada m\u00f3dulo</li> <li>Validar con <code>make check-XX</code> correspondiente</li> <li>Revisar soluciones en <code>solutions/</code> si necesitas ayuda</li> </ol>"},{"location":"docs/SYLLABUS/#entregables-finales","title":"\ud83d\udce6 Entregables Finales","text":"<p>Al completar la gu\u00eda tendr\u00e1s:</p> <ul> <li>[ ] Portafolio ML reproducido localmente</li> <li>[ ] 3 proyectos con CI/CD funcionando</li> <li>[ ] Model Cards y Dataset Cards completos</li> <li>[ ] APIs y dashboards desplegables</li> <li>[ ] Sistema de observabilidad b\u00e1sico</li> <li>[ ] Runbooks de mantenimiento</li> </ul>   **\u00a1Empieza ahora!** \u2192 [00_INDICE.md](00_INDICE.md)"},{"location":"docs/apoyo/","title":"\ud83d\udcda Material de Apoyo","text":"<p>Recursos complementarios para el estudio de la gu\u00eda MLOps.</p>"},{"location":"docs/apoyo/#contenido","title":"\ud83d\udccb Contenido","text":"Recurso Descripci\u00f3n Uso Recomendado Glosario 100+ t\u00e9rminos esenciales de MLOps Consulta permanente Checklist Profesional Verificaci\u00f3n pre-deploy y auditor\u00eda Al finalizar proyectos Recursos Externos Libros, cursos, papers, comunidades Profundizaci\u00f3n R\u00fabrica de Evaluaci\u00f3n Criterios de 100 puntos Autoevaluaci\u00f3n Gu\u00eda Audiovisual C\u00f3mo crear demos y videos Preparaci\u00f3n de portafolio Scripts Operacionales Scripts de demo, testing y auditor\u00eda Operaciones diarias Gu\u00eda de Mantenimiento Operaciones y runbooks Post-deployment Plantillas Templates reutilizables Inicio de proyectos <p>Nota: Los recursos por m\u00f3dulo, ejercicios, ex\u00e1menes, simulacros y decisiones t\u00e9cnicas ahora est\u00e1n integrados directamente en cada m\u00f3dulo.</p>"},{"location":"docs/apoyo/#cuando-usar-cada-recurso","title":"\ud83c\udfaf Cu\u00e1ndo Usar Cada Recurso","text":""},{"location":"docs/apoyo/#durante-el-estudio","title":"Durante el Estudio","text":"<ul> <li>Glosario: Cuando encuentres un t\u00e9rmino desconocido</li> <li>Cada M\u00f3dulo: Incluye sus propios recursos, ejercicios y ADRs</li> </ul>"},{"location":"docs/apoyo/#al-finalizar-proyectos","title":"Al Finalizar Proyectos","text":"<ul> <li>Checklist: Verificar que todo est\u00e9 production-ready</li> <li>R\u00fabrica: Autoevaluar calidad del trabajo</li> </ul>"},{"location":"docs/apoyo/#preparacion-de-entrevistas","title":"Preparaci\u00f3n de Entrevistas","text":"<ul> <li>Gu\u00eda Audiovisual: Crear demos profesionales</li> <li>M\u00f3dulo 23: Incluye preparaci\u00f3n de entrevistas y Defensa del Portafolio integrada</li> </ul>"},{"location":"docs/apoyo/#recursos-pedagogicos-integrados-en-modulos","title":"\ud83c\udd95 Recursos Pedag\u00f3gicos (Integrados en M\u00f3dulos)","text":"Recurso Descripci\u00f3n Ubicaci\u00f3n Quizzes 3 preguntas + 1 ejercicio por m\u00f3dulo Secci\u00f3n \"\ud83d\udcdd Quiz del M\u00f3dulo\" al final de cada m\u00f3dulo La Trampa 50+ errores t\u00edpicos con soluciones Secci\u00f3n \"\ud83e\udea4 La Trampa\" al final de cada m\u00f3dulo Defensa del Portafolio Preguntas de entrevista t\u00e9cnica M\u00f3dulo 23 <p>\u2190 Volver al \u00cdndice Principal</p>"},{"location":"docs/apoyo/CHECKLIST/","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":""},{"location":"docs/apoyo/CHECKLIST/#modulo-22-checklist-final","title":"M\u00d3DULO 22: CHECKLIST FINAL","text":""},{"location":"docs/apoyo/CHECKLIST/#verificacion-del-portafolio","title":"Verificaci\u00f3n del Portafolio","text":""},{"location":"docs/apoyo/CHECKLIST/#guia-mlops-v20-duqueom-noviembre-2025","title":"Gu\u00eda MLOps v2.0 | DuqueOM | Noviembre 2025","text":""},{"location":"docs/apoyo/CHECKLIST/#_2","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":"# \u2705 M\u00d3DULO 22: Checklist Final  **Verificaci\u00f3n del Portafolio**  *\"La calidad se verifica, no se asume.\"*  | Nivel        | Duraci\u00f3n   | |:------------:|:----------:| | \ud83d\udcda Referencia | 1 hora     |"},{"location":"docs/apoyo/CHECKLIST/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Lista de verificaci\u00f3n completa para asegurar que tu portafolio MLOps est\u00e1 listo para presentar.</p>"},{"location":"docs/apoyo/CHECKLIST/#checklist-pre-release","title":"\u2705 Checklist Pre-Release","text":""},{"location":"docs/apoyo/CHECKLIST/#1-repositorio-y-estructura","title":"1. Repositorio y Estructura","text":"<pre><code>## Estructura del Repo\n- [ ] README.md completo con badges\n- [ ] LICENSE presente (MIT recomendado)\n- [ ] .gitignore apropiado para Python/ML\n- [ ] Estructura de carpetas profesional\n- [ ] Cada proyecto tiene su propio README\n\n## Versionado\n- [ ] Commits con formato convencional\n- [ ] Branches organizados (main, develop)\n- [ ] Tags para releases\n- [ ] CHANGELOG.md actualizado\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#2-codigo-y-calidad","title":"2. C\u00f3digo y Calidad","text":"<pre><code>## C\u00f3digo\n- [ ] C\u00f3digo modular (src/proyecto/)\n- [ ] Configuraci\u00f3n con Pydantic (config.py)\n- [ ] Logging implementado\n- [ ] Type hints en funciones principales\n- [ ] Docstrings en clases y funciones p\u00fablicas\n\n## Estilo\n- [ ] Formateado con Black\n- [ ] Imports ordenados con isort\n- [ ] Sin errores cr\u00edticos de flake8\n- [ ] Sin warnings de mypy (o justificados)\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#3-datos","title":"3. Datos","text":"<pre><code>## Versionado de Datos\n- [ ] DVC inicializado\n- [ ] Datasets versionados\n- [ ] Remote configurado (local o cloud)\n- [ ] .dvc files commiteados\n- [ ] dvc.yaml con pipeline definido\n\n## Documentaci\u00f3n de Datos\n- [ ] Data Card presente\n- [ ] Descripci\u00f3n de features\n- [ ] Distribuci\u00f3n de target documentada\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#4-modelo-y-pipeline","title":"4. Modelo y Pipeline","text":"<pre><code>## Pipeline ML\n- [ ] Pipeline sklearn unificado\n- [ ] Preprocessor incluido en pipeline\n- [ ] Modelo serializable con joblib\n- [ ] Reproducibilidad verificada (seeds)\n\n## Tracking\n- [ ] MLflow configurado\n- [ ] Par\u00e1metros logueados\n- [ ] M\u00e9tricas logueadas\n- [ ] Modelos registrados como artefactos\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#5-testing","title":"5. Testing","text":"<pre><code>## Tests\n- [ ] tests/conftest.py con fixtures\n- [ ] Tests unitarios (test_*.py)\n- [ ] Tests de integraci\u00f3n\n- [ ] Tests de API\n- [ ] Coverage \u2265 70%\n\n## Ejecuci\u00f3n\n- [ ] pytest ejecuta sin errores\n- [ ] pytest --cov reporta coverage\n- [ ] Tests son independientes (no orden)\n- [ ] Tests r\u00e1pidos (&lt;30s total)\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#6-cicd","title":"6. CI/CD","text":"<pre><code>## GitHub Actions\n- [ ] .github/workflows/ci.yml presente\n- [ ] Jobs: lint, test, build\n- [ ] Matrix testing (Python 3.11, 3.12)\n- [ ] Badge de CI en README\n- [ ] Pipeline pasa en verde\n\n## Seguridad\n- [ ] Bandit scan sin HIGH severity\n- [ ] Gitleaks configurado\n- [ ] No secrets en c\u00f3digo\n- [ ] .env.example presente (no .env)\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#7-docker","title":"7. Docker","text":"<pre><code>## Dockerfile\n- [ ] Multi-stage build\n- [ ] Usuario no-root\n- [ ] .dockerignore presente\n- [ ] Imagen &lt; 1GB (idealmente &lt; 500MB)\n- [ ] HEALTHCHECK configurado\n\n## Compose\n- [ ] docker-compose.yml funcional\n- [ ] Servicios se levantan correctamente\n- [ ] Health checks pasan\n- [ ] Puertos documentados\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#8-api","title":"8. API","text":"<pre><code>## FastAPI\n- [ ] /health endpoint\n- [ ] /predict endpoint\n- [ ] Validaci\u00f3n con Pydantic\n- [ ] Documentaci\u00f3n en /docs\n- [ ] CORS configurado\n\n## Funcionamiento\n- [ ] API responde correctamente\n- [ ] Predicciones son v\u00e1lidas\n- [ ] Errores tienen mensajes claros\n- [ ] Latencia &lt; 100ms\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#9-documentacion","title":"9. Documentaci\u00f3n","text":"<pre><code>## README Principal\n- [ ] Descripci\u00f3n clara del proyecto\n- [ ] Quick Start funcional\n- [ ] Instrucciones de instalaci\u00f3n\n- [ ] Ejemplos de uso\n- [ ] Badges de CI, coverage, etc.\n\n## Model Card\n- [ ] Model Details completos\n- [ ] Intended Use documentado\n- [ ] M\u00e9tricas de performance\n- [ ] Limitaciones expl\u00edcitas\n- [ ] Consideraciones \u00e9ticas\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#10-demo","title":"10. Demo","text":"<pre><code>## Video Demo\n- [ ] Duraci\u00f3n 3-5 minutos\n- [ ] Introducci\u00f3n del problema\n- [ ] Muestra estructura del c\u00f3digo\n- [ ] Demo en vivo funcionando\n- [ ] CI/CD pipeline visible\n- [ ] Cierre con call-to-action\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#verificacion-final","title":"\ud83d\udd0d Verificaci\u00f3n Final","text":""},{"location":"docs/apoyo/CHECKLIST/#comandos-de-validacion","title":"Comandos de Validaci\u00f3n","text":"<pre><code># 1. Clone limpio\ncd /tmp\ngit clone https://github.com/USUARIO/REPO.git\ncd REPO\n\n# 2. Instalar y testear\npip install -e \".[dev]\"\npytest tests/ -v --cov=src\n\n# 3. Lint\nblack --check src/\nflake8 src/ --select=E9,F63,F7,F82\n\n# 4. Docker\ndocker build -t test-image .\ndocker run --rm -d -p 8000:8000 test-image\nsleep 10\ncurl http://localhost:8000/health\n\n# 5. DVC\ndvc status\ndvc repro --dry\n\n# 6. MLflow\nmlflow ui --port 5000 &amp;\n# Verificar UI en http://localhost:5000\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#criterios-de-aprobacion","title":"Criterios de Aprobaci\u00f3n","text":"Criterio M\u00ednimo Ideal Coverage 70% 85%+ Latencia API &lt;200ms &lt;50ms Tama\u00f1o Docker &lt;1GB &lt;500MB Tests 10+ 30+ CI tiempo &lt;10min &lt;5min"},{"location":"docs/apoyo/CHECKLIST/#checklist-por-proyecto","title":"\ud83d\udccb Checklist por Proyecto","text":""},{"location":"docs/apoyo/CHECKLIST/#bankchurn-predictor","title":"BankChurn-Predictor","text":"<pre><code>- [ ] src/bankchurn/ modular\n- [ ] VotingClassifier implementado\n- [ ] Calibraci\u00f3n de probabilidades\n- [ ] Tests de fairness\n- [ ] API /predict funcional\n- [ ] Model Card con m\u00e9tricas\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#carvision-market-intelligence","title":"CarVision-Market-Intelligence","text":"<pre><code>- [ ] FeatureEngineer centralizado\n- [ ] Pipeline [features, pre, model]\n- [ ] Streamlit dashboard\n- [ ] FastAPI backend\n- [ ] Data leakage prevenido\n- [ ] Bootstrap confidence intervals\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#telecomai-customer-intelligence","title":"TelecomAI-Customer-Intelligence","text":"<pre><code>- [ ] Clasificaci\u00f3n multi-estrategia\n- [ ] VotingClassifier configurado\n- [ ] Pipeline end-to-end\n- [ ] Tests de integraci\u00f3n\n- [ ] API documentada\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#pre-push-checklist","title":"\ud83d\ude80 Pre-Push Checklist","text":"<p>Antes de cada push importante:</p> <pre><code>## Quick Check\n- [ ] `pytest` pasa\n- [ ] `black --check .` pasa\n- [ ] `flake8 src/` sin errores cr\u00edticos\n- [ ] `docker build` funciona\n- [ ] Commit message es descriptivo\n- [ ] No hay archivos sensibles staged\n</code></pre>"},{"location":"docs/apoyo/CHECKLIST/#scorecard-de-portafolio","title":"\ud83d\udcca Scorecard de Portafolio","text":""},{"location":"docs/apoyo/CHECKLIST/#auto-evaluacion-0-10-por-item","title":"Auto-evaluaci\u00f3n (0-10 por \u00edtem)","text":"Categor\u00eda Puntuaci\u00f3n Notas C\u00f3digo /10 Modularidad, estilo, documentaci\u00f3n Testing /10 Coverage, variedad de tests CI/CD /10 Automatizaci\u00f3n, velocidad Docker /10 Optimizaci\u00f3n, seguridad API /10 Funcionalidad, documentaci\u00f3n Datos /10 Versionado, documentaci\u00f3n ML /10 Pipeline, m\u00e9tricas, tracking Docs /10 README, Model Cards Demo /10 Video, presentaci\u00f3n Profesionalismo /10 Consistencia, atenci\u00f3n al detalle <p>Total: /100</p>"},{"location":"docs/apoyo/CHECKLIST/#niveles","title":"Niveles","text":"Puntuaci\u00f3n Nivel 90-100 \ud83c\udfc6 Excepcional - Listo para entrevistas senior 80-89 \u2b50 Excelente - Muy competitivo 70-79 \u2705 Bueno - S\u00f3lido para aplicar 60-69 \ud83d\udcc8 Aceptable - Necesita mejoras menores &lt;60 \ud83d\udd04 En progreso - Continuar trabajando"},{"location":"docs/apoyo/CHECKLIST/#acciones-post-checklist","title":"\ud83c\udfaf Acciones Post-Checklist","text":""},{"location":"docs/apoyo/CHECKLIST/#si-pasas-todo","title":"Si pasas todo:","text":"<ol> <li>\u2705 Publicar en GitHub</li> <li>\u2705 A\u00f1adir a LinkedIn</li> <li>\u2705 Incluir en CV</li> <li>\u2705 Compartir en comunidades</li> </ol>"},{"location":"docs/apoyo/CHECKLIST/#si-faltan-items","title":"Si faltan items:","text":"<ol> <li>Priorizar items cr\u00edticos (tests, CI, docs)</li> <li>Crear issues para items faltantes</li> <li>Planificar sprints de mejora</li> <li>Re-evaluar en 1 semana</li> </ol>   ### Navegaci\u00f3n  | \u25c0\ufe0f Anterior                      | \ud83d\udcd1 \u00cdndice             | \u25b6\ufe0f Siguiente                    | |:---------------------------------|:----------------------:|:---------------------------------| | [GLOSARIO.md](GLOSARIO.md) | [\u00cdndice](../00_INDICE.md) | [RECURSOS.md](RECURSOS.md) |  ---  *\u00a9 2025 DuqueOM - Gu\u00eda MLOps v3.0*  **M\u00f3dulo 22 Completado** \u2705"},{"location":"docs/apoyo/GLOSARIO/","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":""},{"location":"docs/apoyo/GLOSARIO/#modulo-21-glosario-completo-mlops","title":"M\u00d3DULO 21: GLOSARIO COMPLETO MLOps","text":""},{"location":"docs/apoyo/GLOSARIO/#diccionario-exhaustivo-de-a-z-con-explicaciones-profundas-analogias-y-ejemplos","title":"Diccionario Exhaustivo de A-Z con Explicaciones Profundas, Analog\u00edas y Ejemplos","text":""},{"location":"docs/apoyo/GLOSARIO/#guia-mlops-v50-senior-edition-duqueom-diciembre-2025","title":"Gu\u00eda MLOps v5.0: Senior Edition | DuqueOM | Diciembre 2025","text":""},{"location":"docs/apoyo/GLOSARIO/#_2","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":"# \ud83d\udcd6 M\u00d3DULO 21: Glosario Completo MLOps  **Diccionario Exhaustivo con Explicaciones Profundas, Analog\u00edas y Ejemplos del Portafolio**  *\"Dominar el vocabulario t\u00e9cnico es el primer paso para comunicarte como Senior.\"*  | Nivel        | Duraci\u00f3n   | |:------------:|:----------:| | \ud83d\udcda Referencia | Consulta continua |"},{"location":"docs/apoyo/GLOSARIO/#00-prerrequisitos","title":"0.0 Prerrequisitos","text":"<ul> <li>Este m\u00f3dulo es de consulta: \u00fasalo cuando un t\u00e9rmino te frene en m\u00f3dulos 01\u201320.</li> <li>Ten a mano el repositorio del portafolio para buscar ejemplos reales (config, pipeline, CI, serving, observabilidad).</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#01-protocolo-e-como-estudiar-este-modulo","title":"0.1 \ud83e\udde0 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo","text":"<ul> <li>Cuando un t\u00e9rmino te bloquee, evita \u201cseguir por intuici\u00f3n\u201d: detente, define, busca un ejemplo y valida.</li> <li>Si te tom\u00f3 &gt;15 min, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate cognitivo de Protocolo E.</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#02-entregables-verificables-minimo-viable","title":"0.2 \u2705 Entregables verificables (m\u00ednimo viable)","text":"<ul> <li>[ ] Puedes explicar en 2\u20133 frases al menos 10 t\u00e9rminos cr\u00edticos (por ejemplo: pipeline, data leakage, drift, CI/CD, serving, observabilidad).</li> <li>[ ] Puedes mapear cada t\u00e9rmino a un lugar concreto del repo (por ejemplo: <code>pyproject.toml</code>, <code>tests/</code>, <code>.github/workflows/</code>, <code>configs/</code>, <code>artifacts/</code>).</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#03-puente-teoria-codigo-portafolio","title":"0.3 \ud83e\udde9 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)","text":"<ul> <li>Cada vez que leas un t\u00e9rmino, conecta: \u00bfd\u00f3nde vive esto en tu repo?</li> <li>Ejemplos t\u00edpicos:</li> <li>API \u2192 <code>app/</code> (FastAPI)</li> <li>CI/CD \u2192 <code>.github/workflows/</code></li> <li>Artefactos \u2192 <code>artifacts/</code></li> <li>Config \u2192 <code>configs/</code> + Pydantic</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#contenido","title":"\ud83d\udccb Contenido","text":"<ul> <li>0.0 Prerrequisitos</li> <li>0.1 Protocolo E: C\u00f3mo estudiar este m\u00f3dulo</li> <li>0.2 Entregables verificables (m\u00ednimo viable)</li> <li>0.3 Puente teor\u00eda \u2194 c\u00f3digo (Portafolio)</li> <li>21.1 Introducci\u00f3n</li> <li>21.2\u201321.27 Glosario A\u2013Z</li> <li>21.28 S\u00edmbolos y Abreviaciones</li> <li>21.29 Tablas de Referencia R\u00e1pida</li> <li>Errores habituales</li> <li>\u2705 Ejercicio</li> <li>\u2705 Checkpoint</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#introduccion","title":"\ud83d\udcda Introducci\u00f3n","text":"<p>Este glosario define todos los t\u00e9rminos t\u00e9cnicos utilizados en la Gu\u00eda MLOps v5.0 y en los proyectos del portafolio (BankChurn, CarVision, TelecomAI). Cada t\u00e9rmino incluye:</p> <ul> <li>Definici\u00f3n t\u00e9cnica precisa y completa</li> <li>Explicaci\u00f3n conceptual para entender el \"por qu\u00e9\"</li> <li>Analog\u00eda desarrollada para facilitar comprensi\u00f3n intuitiva</li> <li>Ejemplo del portafolio cuando aplica</li> <li>T\u00e9rminos relacionados para profundizar</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#como-usar-este-glosario","title":"C\u00f3mo usar este glosario","text":"<ol> <li>Primera lectura: Lee las analog\u00edas para captar la intuici\u00f3n</li> <li>Profundizaci\u00f3n: Lee la explicaci\u00f3n conceptual completa</li> <li>Aplicaci\u00f3n: Revisa los ejemplos del portafolio</li> <li>Conexi\u00f3n: Explora los t\u00e9rminos relacionados</li> </ol>"},{"location":"docs/apoyo/GLOSARIO/#a","title":"A","text":""},{"location":"docs/apoyo/GLOSARIO/#accuracy-exactitud","title":"Accuracy (Exactitud)","text":"<p>Definici\u00f3n t\u00e9cnica: M\u00e9trica de clasificaci\u00f3n que mide el porcentaje de predicciones correctas sobre el total. Se calcula como <code>(TP + TN) / (TP + TN + FP + FN)</code> donde TP=True Positives, TN=True Negatives, FP=False Positives, FN=False Negatives.</p> <p>Explicaci\u00f3n conceptual: Accuracy responde a la pregunta \"\u00bfqu\u00e9 porcentaje de mis predicciones fueron correctas?\". Es intuitiva pero peligrosamente enga\u00f1osa con clases desbalanceadas. Si el 95% de tus clientes NO abandonan (no-churn), un modelo que siempre predice \"no-churn\" tiene 95% accuracy pero es completamente in\u00fatil para detectar churners.</p> <p>Analog\u00eda desarrollada: Imagina un arquero que dispara 100 flechas a un blanco. Si 85 dan en el blanco, su accuracy es 85%. Pero si el blanco ocupa el 95% del muro, incluso disparando con los ojos cerrados acertar\u00edas 95%. Por eso en ML usamos m\u00e9tricas adicionales (Precision, Recall) que nos dicen qu\u00e9 tan bien acertamos a cada zona espec\u00edfica.</p> <p>En el portafolio: BankChurn tiene ~20% de churners. Un modelo \"dummy\" que siempre predice \"no-churn\" tendr\u00eda 80% accuracy. Por eso usamos ROC-AUC (86%) y Recall como m\u00e9tricas principales.</p> <p>Relacionados: Precision, Recall, F1 Score, ROC-AUC, Class Imbalance</p>"},{"location":"docs/apoyo/GLOSARIO/#adr-architecture-decision-record","title":"ADR (Architecture Decision Record)","text":"<p>Definici\u00f3n t\u00e9cnica: Documento estructurado que registra una decisi\u00f3n de arquitectura significativa junto con su contexto, las alternativas consideradas, la decisi\u00f3n tomada y sus consecuencias (positivas y negativas).</p> <p>Explicaci\u00f3n conceptual: En proyectos de software, tomamos cientos de decisiones t\u00e9cnicas. Meses despu\u00e9s, nadie recuerda por qu\u00e9 se eligi\u00f3 PostgreSQL en vez de MongoDB, o por qu\u00e9 el modelo usa RandomForest y no XGBoost. Los ADRs resuelven esto: son la \"memoria institucional\" del proyecto. Siguen un formato est\u00e1ndar (Estado, Contexto, Decisi\u00f3n, Consecuencias) que facilita la lectura y b\u00fasqueda.</p> <p>Analog\u00eda desarrollada: Piensa en un ADR como el acta de una reuni\u00f3n de arquitectos. A\u00f1os despu\u00e9s de construir un edificio, si alguien pregunta \"\u00bfpor qu\u00e9 las vigas son de acero y no de madera?\", el acta explica: \"En 2020, consideramos madera (m\u00e1s barata) y acero (m\u00e1s resistente). Elegimos acero porque el edificio est\u00e1 en zona s\u00edsmica. Consecuencia: costo 20% mayor pero certificaci\u00f3n antis\u00edsmica garantizada.\"</p> <p>Ejemplo del portafolio: <pre><code># ADR-001: Uso de RandomForest sobre XGBoost\n\n## Estado: Aceptado\n\n## Contexto\nNecesitamos un modelo de clasificaci\u00f3n para churn que sea interpretable \npara el equipo de negocio y robusto sin tuning extensivo.\n\n## Decisi\u00f3n\nUsamos RandomForestClassifier con class_weight='balanced'.\n\n## Consecuencias\n+ Feature importances nativas (explicabilidad)\n+ Robusto sin hiperpar\u00e1metro tuning complejo\n- Puede perder 1-2% AUC vs XGBoost optimizado\n</code></pre></p> <p>Relacionados: ML Canvas, C4 Model, Documentaci\u00f3n, DECISIONES_TECH.md</p>"},{"location":"docs/apoyo/GLOSARIO/#api-application-programming-interface","title":"API (Application Programming Interface)","text":"<p>Definici\u00f3n t\u00e9cnica: Contrato que define c\u00f3mo dos sistemas de software se comunican. Especifica los endpoints disponibles, los formatos de entrada/salida, los m\u00e9todos HTTP soportados y los c\u00f3digos de respuesta. En MLOps, las APIs REST son el mecanismo principal para exponer modelos ML como servicios consumibles.</p> <p>Explicaci\u00f3n conceptual: Un modelo ML entrenado es solo un archivo (.pkl, .joblib). Para que sea \u00fatil, otros sistemas deben poder enviarle datos y recibir predicciones. Una API act\u00faa como la \"ventana al mundo\" del modelo: recibe requests HTTP con datos del cliente, los valida, los pasa al modelo, y devuelve la predicci\u00f3n en formato estructurado (JSON). Esto desacopla el modelo de los consumidores: la app m\u00f3vil, el dashboard, el sistema de CRM pueden todos usar la misma API sin conocer los detalles internos del modelo.</p> <p>Analog\u00eda desarrollada: Una API es como el mesero de un restaurante. T\u00fa (el cliente) no entras a la cocina a preparar tu comida (no cargas el modelo en tu c\u00f3digo). En su lugar, le dices al mesero qu\u00e9 quieres (env\u00edas un request), \u00e9l lleva el pedido a la cocina (la API invoca al modelo), y te trae el plato preparado (la API devuelve la predicci\u00f3n). El men\u00fa es la documentaci\u00f3n de la API: te dice qu\u00e9 puedes pedir y c\u00f3mo.</p> <p>Ejemplo del portafolio (BankChurn FastAPI): <pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\n\nclass PredictionRequest(BaseModel):\n    CreditScore: int = Field(..., ge=300, le=850)\n    Age: int = Field(..., ge=18, le=100)\n    Balance: float = Field(..., ge=0)\n    # ... m\u00e1s features\n\nclass PredictionResponse(BaseModel):\n    prediction: int\n    probability: float\n    risk_level: str\n\n@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    df = pd.DataFrame([request.model_dump()])\n    proba = model.predict_proba(df)[0, 1]\n    return PredictionResponse(\n        prediction=int(proba &gt; 0.5),\n        probability=proba,\n        risk_level=\"high\" if proba &gt; 0.7 else \"medium\" if proba &gt; 0.3 else \"low\"\n    )\n</code></pre></p> <p>Relacionados: REST, FastAPI, Endpoint, HTTP, Pydantic, OpenAPI/Swagger</p>"},{"location":"docs/apoyo/GLOSARIO/#artefacto-artifact","title":"Artefacto (Artifact)","text":"<p>Definici\u00f3n t\u00e9cnica: Cualquier archivo generado durante el ciclo de vida de ML que necesita ser versionado, almacenado y potencialmente reproducido. Incluye: modelos serializados (.pkl, .joblib, .onnx), datasets procesados, gr\u00e1ficos de evaluaci\u00f3n, reportes de m\u00e9tricas, logs de entrenamiento, y configuraciones.</p> <p>Explicaci\u00f3n conceptual: Un proyecto ML no es solo c\u00f3digo\u2014genera \"productos intermedios\" en cada etapa. El dataset limpio es un artefacto. El modelo entrenado es un artefacto. El reporte de m\u00e9tricas es un artefacto. La gesti\u00f3n profesional de artefactos permite: (1) reproducibilidad\u2014volver a cualquier versi\u00f3n anterior, (2) trazabilidad\u2014saber qu\u00e9 datos y c\u00f3digo produjeron qu\u00e9 modelo, (3) colaboraci\u00f3n\u2014compartir resultados entre equipos.</p> <p>Analog\u00eda desarrollada: Piensa en una f\u00e1brica de autos. Los planos son artefactos (c\u00f3digo). Las piezas moldeadas son artefactos (datasets procesados). El motor ensamblado es un artefacto (modelo entrenado). El auto terminado es un artefacto (pipeline completo). Cada pieza tiene un n\u00famero de serie y registro de qu\u00e9 m\u00e1quina la produjo, cu\u00e1ndo, con qu\u00e9 materiales. Si un auto tiene un defecto, puedes rastrear hacia atr\u00e1s hasta encontrar la pieza defectuosa y qu\u00e9 lote de materiales caus\u00f3 el problema.</p> <p>Ejemplo del portafolio: <pre><code>artifacts/\n\u251c\u2500\u2500 model.joblib          # Modelo serializado (pipeline completo)\n\u251c\u2500\u2500 metrics.json          # {\"roc_auc\": 0.86, \"recall\": 0.75}\n\u251c\u2500\u2500 feature_importance.png # Gr\u00e1fico de importancia\n\u2514\u2500\u2500 training_config.yaml  # Configuraci\u00f3n usada\n</code></pre></p> <p>Relacionados: MLflow, Model Registry, DVC, Reproducibilidad</p>"},{"location":"docs/apoyo/GLOSARIO/#asgi-asynchronous-server-gateway-interface","title":"ASGI (Asynchronous Server Gateway Interface)","text":"<p>Definici\u00f3n: Especificaci\u00f3n para servidores web async en Python. Maneja m\u00faltiples requests concurrentemente.</p> <p>Analog\u00eda: Mesero que anota pedido mesa 1, mientras espera va a mesa 2, etc. Maneja conversaciones \"en paralelo\".</p> <p>Relacionados: Uvicorn, FastAPI, Async/Await</p>"},{"location":"docs/apoyo/GLOSARIO/#auc-roc","title":"AUC-ROC","text":"<p>Definici\u00f3n: \u00c1rea bajo curva ROC. Mide capacidad de distinguir clases. 1.0 = perfecto, 0.5 = aleatorio.</p> <p>Analog\u00eda: Separando manzanas buenas de malas. AUC 0.9 = 90% de las veces asigna mayor score a la manzana buena.</p> <p>Relacionados: ROC Curve, Precision, Recall, Threshold</p>"},{"location":"docs/apoyo/GLOSARIO/#auto-scaling","title":"Auto-scaling","text":"<p>Definici\u00f3n: Sistema que aumenta/disminuye recursos autom\u00e1ticamente seg\u00fan demanda.</p> <p>Analog\u00eda: Restaurante contratando meseros temporales cuando hay mucha gente.</p> <p>Relacionados: HPA, Kubernetes, Load Balancer</p>"},{"location":"docs/apoyo/GLOSARIO/#b","title":"B","text":""},{"location":"docs/apoyo/GLOSARIO/#backpropagation","title":"Backpropagation","text":"<p>Definici\u00f3n: Algoritmo de entrenamiento de redes neuronales que propaga el error hacia atr\u00e1s calculando gradientes.</p> <p>Analog\u00eda: Equipo de relevos donde analizas hacia atr\u00e1s qui\u00e9n contribuy\u00f3 al fallo.</p> <p>Relacionados: Gradient Descent, Learning Rate, Neural Network</p>"},{"location":"docs/apoyo/GLOSARIO/#baseline","title":"Baseline","text":"<p>Definici\u00f3n: Modelo simple como referencia. Si tu modelo complejo no lo supera, algo est\u00e1 mal.</p> <p>Analog\u00eda: Antes de comprar auto deportivo, verifica que sea m\u00e1s r\u00e1pido que tu bicicleta.</p> <p>Relacionados: Benchmark, Model Evaluation</p>"},{"location":"docs/apoyo/GLOSARIO/#baseestimator","title":"BaseEstimator","text":"<p>Definici\u00f3n: Clase base sklearn con <code>get_params()</code> y <code>set_params()</code>. Todos los estimadores heredan de ella.</p> <p>Analog\u00eda: Contrato est\u00e1ndar que todos los constructores deben seguir para que el sistema funcione.</p> <p>Relacionados: TransformerMixin, Custom Transformer, Pipeline</p>"},{"location":"docs/apoyo/GLOSARIO/#batch-prediction","title":"Batch Prediction","text":"<p>Definici\u00f3n: Procesar m\u00faltiples muestras a la vez, programadamente. Contrasta con online/real-time.</p> <p>Analog\u00eda: Catering (cocinas todo de antemano) vs restaurante a la carta (cocinas cada plato al pedirlo).</p> <p>Relacionados: Online Prediction, Latencia</p>"},{"location":"docs/apoyo/GLOSARIO/#black","title":"Black","text":"<p>Definici\u00f3n: Formateador Python opinionado. Aplica estilo consistente autom\u00e1ticamente.</p> <p>Analog\u00eda: Corrector que arregla gram\u00e1tica y estilo sin preguntarte.</p> <pre><code>black src/\n</code></pre> <p>Relacionados: Linting, Flake8, isort</p>"},{"location":"docs/apoyo/GLOSARIO/#branch-rama","title":"Branch (Rama)","text":"<p>Definici\u00f3n: L\u00ednea de desarrollo paralela en Git.</p> <p>Analog\u00eda: Fotocopia del manuscrito para probar final alternativo sin afectar original.</p> <pre><code>git checkout -b feature/add-mlflow\n</code></pre> <p>Relacionados: Git, Merge, Pull Request</p>"},{"location":"docs/apoyo/GLOSARIO/#c","title":"C","text":""},{"location":"docs/apoyo/GLOSARIO/#c4-model","title":"C4 Model","text":"<p>Definici\u00f3n: Visualizaci\u00f3n de arquitectura en 4 niveles: Context, Container, Component, Code.</p> <p>Analog\u00eda: Google Maps con zoom. Mundo \u2192 Pa\u00eds \u2192 Ciudad \u2192 Calle.</p> <p>Relacionados: ADR, Arquitectura</p>"},{"location":"docs/apoyo/GLOSARIO/#cicd","title":"CI/CD","text":"<p>Definici\u00f3n: Continuous Integration (tests autom\u00e1ticos) + Continuous Deployment (deploy autom\u00e1tico).</p> <p>Analog\u00eda: F\u00e1brica con control de calidad automatizado que env\u00eda autos aprobados al concesionario.</p> <p>Relacionados: GitHub Actions, Pipeline, DevOps</p>"},{"location":"docs/apoyo/GLOSARIO/#classification","title":"Classification","text":"<p>Definici\u00f3n: Problema ML supervisado para predecir categor\u00edas discretas.</p> <p>Analog\u00eda: Doctor diagnosticando enfermedades (multiclase) o decidiendo operar/no operar (binaria).</p> <p>Relacionados: Regression, Supervised Learning</p>"},{"location":"docs/apoyo/GLOSARIO/#class-imbalance-desbalance-de-clases","title":"Class Imbalance (Desbalance de Clases)","text":"<p>Definici\u00f3n t\u00e9cnica: Situaci\u00f3n donde una o m\u00e1s clases est\u00e1n significativamente subrepresentadas en el dataset de entrenamiento. Ratios como 95:5, 99:1 o peores son comunes en problemas reales (fraude, churn, enfermedades raras).</p> <p>Explicaci\u00f3n conceptual: Los algoritmos de ML optimizan m\u00e9tricas globales. Si el 95% de tus datos son \"no-fraude\", el modelo aprende que la estrategia m\u00e1s \"segura\" es predecir siempre \"no-fraude\"\u2014obtiene 95% accuracy haciendo nada \u00fatil. El desbalance es quiz\u00e1s el problema m\u00e1s com\u00fan y subestimado en ML aplicado. Afecta tanto al entrenamiento (el modelo no ve suficientes ejemplos de la clase minoritaria) como a la evaluaci\u00f3n (accuracy es enga\u00f1osa).</p> <p>Analog\u00eda desarrollada: Imagina entrenar un perro buscador de trufas d\u00e1ndole 1000 piedras y solo 10 trufas. El perro aprende r\u00e1pidamente que decir \"piedra\" le da premio el 99% de las veces. Nunca aprende realmente a oler trufas. Para entrenarlo bien, necesitas: (1) darle m\u00e1s trufas (oversampling), (2) penalizarlo m\u00e1s cuando falla una trufa (class weights), o (3) medir su \u00e9xito por trufas encontradas, no por piedras correctamente ignoradas (m\u00e9tricas apropiadas).</p> <p>Soluciones t\u00e9cnicas: <pre><code># 1. Class weights (penaliza m\u00e1s errores en clase minoritaria)\nRandomForestClassifier(class_weight='balanced')\n\n# 2. SMOTE (genera ejemplos sint\u00e9ticos de clase minoritaria)\nfrom imblearn.over_sampling import SMOTE\nX_resampled, y_resampled = SMOTE().fit_resample(X, y)\n\n# 3. Threshold adjustment (bajar umbral de decisi\u00f3n)\nproba = model.predict_proba(X)[:, 1]\npredictions = (proba &gt; 0.3).astype(int)  # En vez de 0.5\n\n# 4. M\u00e9tricas apropiadas\nfrom sklearn.metrics import recall_score, roc_auc_score\n# NO usar accuracy como m\u00e9trica principal\n</code></pre></p> <p>En el portafolio: BankChurn tiene ~20% churners. Usamos <code>class_weight='balanced'</code> y priorizamos Recall sobre Accuracy.</p> <p>Relacionados: class_weight, SMOTE, Recall, Precision, ROC-AUC, Threshold</p>"},{"location":"docs/apoyo/GLOSARIO/#class_weight","title":"class_weight","text":"<p>Definici\u00f3n t\u00e9cnica: Par\u00e1metro de sklearn que asigna pesos diferentes a las clases durante el entrenamiento. Con <code>class_weight='balanced'</code>, los pesos se calculan autom\u00e1ticamente como inversamente proporcionales a la frecuencia de cada clase.</p> <p>Explicaci\u00f3n conceptual: Es la forma m\u00e1s simple de manejar desbalance. En lugar de modificar los datos (oversampling/undersampling), modificamos c\u00f3mo el modelo \"valora\" los errores. Un error en la clase minoritaria \"cuenta m\u00e1s\" que un error en la clase mayoritaria. Matem\u00e1ticamente, es como si tuvi\u00e9ramos m\u00e1s ejemplos de la clase minoritaria sin realmente duplicarlos.</p> <p>F\u00f3rmula: <code>weight[i] = n_samples / (n_classes * n_samples_i)</code></p> <p>Ejemplo del portafolio: <pre><code># BankChurn: 80% no-churn, 20% churn\n# Sin class_weight: modelo ignora churners\n# Con class_weight='balanced': churners valen 4x m\u00e1s\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(\n    n_estimators=100,\n    class_weight='balanced',  # Cr\u00edtico para churn\n    random_state=42\n)\n</code></pre></p> <p>Relacionados: Class Imbalance, SMOTE, RandomForest</p>"},{"location":"docs/apoyo/GLOSARIO/#cold-start","title":"Cold Start","text":"<p>Definici\u00f3n: Tiempo para que servicio est\u00e9 listo tras iniciarse. Incluye cargar modelo en memoria.</p> <p>Analog\u00eda: Encender auto en invierno. Debes esperar que el motor se caliente.</p> <p>Relacionados: Serverless, Lambda, Latencia</p>"},{"location":"docs/apoyo/GLOSARIO/#columntransformer","title":"ColumnTransformer","text":"<p>Definici\u00f3n: Sklearn: aplica diferentes transformaciones a diferentes columnas.</p> <p>Analog\u00eda: Lavander\u00eda con m\u00e1quinas diferentes: color\u2192encoder, blanca\u2192scaler, delicados\u2192passthrough.</p> <pre><code>preprocessor = ColumnTransformer([\n    ('num', StandardScaler(), num_cols),\n    ('cat', OneHotEncoder(), cat_cols),\n])\n</code></pre> <p>Relacionados: Pipeline, Transformer</p>"},{"location":"docs/apoyo/GLOSARIO/#commit","title":"Commit","text":"<p>Definici\u00f3n: Snapshot de cambios en Git con hash \u00fanico y mensaje.</p> <p>Analog\u00eda: Foto de tu escritorio. Puedes volver a cualquier foto anterior.</p> <pre><code>git commit -m \"feat: add probability calibration\"\n</code></pre> <p>Relacionados: Git, Branch, Push, Conventional Commits</p>"},{"location":"docs/apoyo/GLOSARIO/#conftestpy","title":"conftest.py","text":"<p>Definici\u00f3n t\u00e9cnica: Archivo especial de pytest que contiene fixtures (funciones que proveen datos/recursos) compartidas entre todos los tests del directorio y subdirectorios. pytest lo descubre autom\u00e1ticamente sin necesidad de imports.</p> <p>Explicaci\u00f3n conceptual: Los tests necesitan datos de prueba, conexiones a bases de datos mock, modelos pre-entrenados, etc. Sin conftest.py, cada archivo de tests tendr\u00eda que definir o importar estos recursos. conftest.py centraliza esta l\u00f3gica: defines las fixtures una vez, y est\u00e1n disponibles autom\u00e1ticamente en todos los tests. Es el \"almac\u00e9n central de recursos de testing\".</p> <p>Analog\u00eda desarrollada: Imagina un set de filmaci\u00f3n. Antes de cada escena, alguien prepara el escenario: pone las luces, coloca los props, prepara el vestuario. conftest.py es ese equipo de preparaci\u00f3n. Los actores (tests) llegan y todo est\u00e1 listo. No tienen que traer sus propios props\u2014solo los piden por nombre y aparecen.</p> <p>Ejemplo del portafolio (CarVision): <pre><code># tests/conftest.py\nimport pytest\nimport pandas as pd\nimport numpy as np\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Datos sint\u00e9ticos para tests.\"\"\"\n    np.random.seed(42)\n    return pd.DataFrame({\n        'year': np.random.randint(2010, 2023, 100),\n        'mileage': np.random.randint(10000, 150000, 100),\n        'price': np.random.uniform(5000, 50000, 100),\n    })\n\n@pytest.fixture\ndef trained_pipeline(sample_data):\n    \"\"\"Pipeline entrenado para tests de inferencia.\"\"\"\n    from carvision.pipeline import build_pipeline\n    pipe = build_pipeline()\n    X = sample_data.drop('price', axis=1)\n    y = sample_data['price']\n    return pipe.fit(X, y)\n\n@pytest.fixture\ndef config():\n    \"\"\"Configuraci\u00f3n de test.\"\"\"\n    return {'model': {'n_estimators': 10}, 'random_state': 42}\n</code></pre></p> <p>Relacionados: pytest, Fixture, Unit Test, Integration Test</p>"},{"location":"docs/apoyo/GLOSARIO/#conventional-commits","title":"Conventional Commits","text":"<p>Definici\u00f3n t\u00e9cnica: Especificaci\u00f3n para escribir mensajes de commit estandarizados. Formato: <code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;</code>. Types incluyen: feat, fix, docs, style, refactor, test, chore.</p> <p>Explicaci\u00f3n conceptual: Los mensajes de commit son la historia del proyecto. \"fixed bug\" o \"updates\" no dicen nada \u00fatil. Conventional Commits impone estructura: el tipo indica qu\u00e9 cambi\u00f3 (feature nueva, bug fix, documentaci\u00f3n), el scope indica d\u00f3nde (api, pipeline, tests), la descripci\u00f3n explica qu\u00e9. Esto permite: (1) generar CHANGELOGs autom\u00e1ticamente, (2) determinar versiones sem\u00e1nticas, (3) entender la historia del proyecto r\u00e1pidamente.</p> <p>Analog\u00eda desarrollada: Imagina un libro de bit\u00e1cora de un barco. \"Navegamos\" no ayuda. \"2024-01-15 14:00 - Cambio de rumbo: de Norte a Noroeste para evitar tormenta detectada a 50km\" es \u00fatil. Conventional Commits son esa bit\u00e1cora estructurada para c\u00f3digo.</p> <p>Ejemplos del portafolio: <pre><code># Formato: &lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n\nfeat(api): add batch prediction endpoint\nfix(pipeline): handle NaN values in categorical columns\ndocs(readme): add quick start guide and badges\ntest(training): add integration tests for cross-validation\nrefactor(features): extract FeatureEngineer to separate module\nchore(deps): update scikit-learn to 1.3.0\n</code></pre></p> <p>Relacionados: Git, pre-commit, Semantic Versioning</p>"},{"location":"docs/apoyo/GLOSARIO/#concept-drift","title":"Concept Drift","text":"<p>Definici\u00f3n: Cambio en relaci\u00f3n features-target. Patrones aprendidos ya no son v\u00e1lidos.</p> <p>Analog\u00eda: Modelo entrenado pre-pandemia predice gustos de pel\u00edculas post-pandemia incorrectamente.</p> <p>vs Data Drift: Data Drift = cambia X. Concept Drift = cambia P(Y|X).</p>"},{"location":"docs/apoyo/GLOSARIO/#configmap","title":"ConfigMap","text":"<p>Definici\u00f3n: Kubernetes: almacena configuraci\u00f3n no sensible como pares clave-valor.</p> <p>Analog\u00eda: Tabl\u00f3n de anuncios de oficina. Informaci\u00f3n p\u00fablica que todos necesitan.</p>"},{"location":"docs/apoyo/GLOSARIO/#container-contenedor","title":"Container (Contenedor)","text":"<p>Definici\u00f3n: Software empaquetado con c\u00f3digo y dependencias. Ejecuta igual en cualquier ambiente.</p> <p>Analog\u00eda: Contenedor de barco. Funciona igual en cualquier puerto.</p> <p>Relacionados: Docker, Image, Kubernetes</p>"},{"location":"docs/apoyo/GLOSARIO/#coverage","title":"Coverage","text":"<p>Definici\u00f3n: Porcentaje de c\u00f3digo ejecutado por tests. No garantiza correcci\u00f3n.</p> <p>Analog\u00eda: Inspector que revis\u00f3 80% de habitaciones. No significa que encontr\u00f3 todos los problemas.</p> <pre><code>pytest --cov=src\n</code></pre> <p>Target: &gt;80% para c\u00f3digo cr\u00edtico</p>"},{"location":"docs/apoyo/GLOSARIO/#cross-validation","title":"Cross-Validation","text":"<p>Definici\u00f3n: Evaluar modelo dividiendo datos en K folds. Entrena K veces con diferentes splits.</p> <p>Analog\u00eda: 5 estudiantes, 5 rondas. En cada ronda, diferente estudiante es evaluado.</p> <pre><code>scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n</code></pre> <p>Relacionados: K-Fold, Overfitting</p>"},{"location":"docs/apoyo/GLOSARIO/#custom-transformer","title":"Custom Transformer","text":"<p>Definici\u00f3n: Clase sklearn personalizada que hereda BaseEstimator + TransformerMixin.</p> <p>Analog\u00eda: Pieza LEGO personalizada con conexiones est\u00e1ndar (fit/transform).</p> <pre><code>class RatioFeatures(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None): return self\n    def transform(self, X):\n        X['ratio'] = X['Balance'] / (X['Products'] + 1)\n        return X\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#d","title":"D","text":""},{"location":"docs/apoyo/GLOSARIO/#dag-directed-acyclic-graph","title":"DAG (Directed Acyclic Graph)","text":"<p>Definici\u00f3n: Grafo dirigido sin ciclos. Representa dependencias entre tareas.</p> <p>Analog\u00eda: Instrucciones de receta. No puedes hornear antes de mezclar.</p> <p>Relacionados: DVC, Pipeline, Airflow</p>"},{"location":"docs/apoyo/GLOSARIO/#data-drift","title":"Data Drift","text":"<p>Definici\u00f3n t\u00e9cnica: Cambio en la distribuci\u00f3n estad\u00edstica de las features (P(X)) entre el momento del entrenamiento y la inferencia en producci\u00f3n. No implica necesariamente que la relaci\u00f3n feature-target haya cambiado, solo que los datos de entrada son diferentes.</p> <p>Explicaci\u00f3n conceptual: Tu modelo fue entrenado con datos de 2023. Llega 2025 y los patrones de los clientes han cambiado: son m\u00e1s j\u00f3venes, usan m\u00e1s canales digitales, tienen balances diferentes. Aunque la \"l\u00f3gica\" de qu\u00e9 causa churn no haya cambiado, tu modelo recibe inputs que nunca vio y puede fallar. Data drift es como un m\u00e9dico entrenado solo con pacientes adultos intentando diagnosticar ni\u00f1os\u2014la anatom\u00eda es diferente aunque las enfermedades sean las mismas.</p> <p>Analog\u00eda desarrollada: Imagina un modelo que predice si llover\u00e1 bas\u00e1ndose en la presi\u00f3n atmosf\u00e9rica. Fue entrenado en Madrid. Lo despliegas en Ciudad de M\u00e9xico (altitud muy diferente). La presi\u00f3n \"normal\" en CDMX es mucho menor que en Madrid. El modelo ve presiones que interpreta como \"muy baja\" y siempre predice lluvia. No es que el modelo est\u00e9 roto\u2014es que los datos de entrada son muy diferentes a los de entrenamiento.</p> <p>Tipos de drift: - Covariate shift: Cambia P(X), pero P(Y|X) permanece igual - Prior probability shift: Cambia P(Y), la proporci\u00f3n de clases - Concept drift: Cambia P(Y|X), la relaci\u00f3n misma</p> <p>Detecci\u00f3n t\u00e9cnica: <pre><code># Kolmogorov-Smirnov test para cada feature\nfrom scipy.stats import ks_2samp\n\nfor col in features:\n    stat, pvalue = ks_2samp(train_data[col], prod_data[col])\n    if pvalue &lt; 0.05:\n        print(f\"Drift detectado en {col}: KS={stat:.3f}, p={pvalue:.4f}\")\n\n# Population Stability Index (PSI)\n# PSI &lt; 0.1: No drift\n# PSI 0.1-0.2: Drift moderado\n# PSI &gt; 0.2: Drift significativo\n</code></pre></p> <p>Herramientas: Evidently, NannyML, Great Expectations</p> <p>Relacionados: Concept Drift, Model Monitoring, Evidently, Retraining</p>"},{"location":"docs/apoyo/GLOSARIO/#data-leakage","title":"Data Leakage","text":"<p>Definici\u00f3n: Informaci\u00f3n del futuro o test filtra al entrenamiento. M\u00e9tricas infladas.</p> <p>Analog\u00eda: Estudiar con las respuestas del mismo examen. 100% en pr\u00e1ctica, 0% en real.</p> <p>Ejemplos: <code>price_per_mile = price / miles</code>, normalizar antes de split.</p>"},{"location":"docs/apoyo/GLOSARIO/#dependency-injection","title":"Dependency Injection","text":"<p>Definici\u00f3n: Dependencias se pasan desde afuera en lugar de crearse internamente.</p> <p>Analog\u00eda: Cafeter\u00eda recibe leche de proveedor en vez de tener vacas propias.</p> <pre><code># Con DI: f\u00e1cil de testear\nclass Predictor:\n    def __init__(self, model: BaseEstimator):\n        self.model = model  # Inyectado\n</code></pre> <p>Relacionados: SOLID, Testing</p>"},{"location":"docs/apoyo/GLOSARIO/#deployment","title":"Deployment","text":"<p>Definici\u00f3n: Poner modelo/aplicaci\u00f3n en ambiente donde usuarios reales lo usan.</p> <p>Analog\u00eda: Abrir restaurante al p\u00fablico despu\u00e9s de cocinar en casa y probar con amigos.</p> <p>Tipos: Batch, REST API, Edge, Streaming</p>"},{"location":"docs/apoyo/GLOSARIO/#docker","title":"Docker","text":"<p>Definici\u00f3n: Plataforma para aplicaciones en contenedores. C\u00f3digo + dependencias portables.</p> <p>Analog\u00eda: M\u00e1quina del tiempo para c\u00f3digo. Congelas ambiente exacto.</p> <pre><code>FROM python:3.11-slim\nCOPY . /app\nRUN pip install -r requirements.txt\nCMD [\"uvicorn\", \"app:app\"]\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#docstring","title":"Docstring","text":"<p>Definici\u00f3n: String de documentaci\u00f3n al inicio de funciones/clases.</p> <p>Analog\u00eda: Instrucciones en la caja de un producto.</p> <pre><code>def predict(data: pd.DataFrame) -&gt; np.ndarray:\n    \"\"\"\n    Genera predicciones de churn.\n\n    Args:\n        data: DataFrame con features.\n    Returns:\n        Array de probabilidades 0-1.\n    \"\"\"\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#dvc-data-version-control","title":"DVC (Data Version Control)","text":"<p>Definici\u00f3n: Versiona datasets y pipelines ML. Datos grandes en storage remoto, metadatos en Git.</p> <p>Analog\u00eda: Git = \u00e1lbum con miniaturas. DVC = almac\u00e9n con fotos originales grandes.</p> <pre><code>dvc add data/dataset.csv\ndvc push\ngit add data/dataset.csv.dvc\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#e","title":"E","text":""},{"location":"docs/apoyo/GLOSARIO/#e2e-test","title":"E2E Test","text":"<p>Definici\u00f3n: Test del sistema completo, desde entrada hasta salida final.</p> <p>Analog\u00eda: Test drive de auto completo, no motor aislado.</p>"},{"location":"docs/apoyo/GLOSARIO/#early-stopping","title":"Early Stopping","text":"<p>Definici\u00f3n: Detiene entrenamiento cuando validaci\u00f3n deja de mejorar. Evita overfitting.</p> <p>Analog\u00eda: Sacar galletas del horno cuando est\u00e1n doradas, antes de que se quemen.</p> <pre><code>EarlyStopping(monitor='val_loss', patience=5)\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#embedding","title":"Embedding","text":"<p>Definici\u00f3n: Representaci\u00f3n vectorial densa de datos de alta dimensionalidad.</p> <p>Analog\u00eda: Mapear ciudades del mundo en papel 2D. Similares quedan cerca.</p> <p>Uso: Word2Vec, Entity embeddings</p>"},{"location":"docs/apoyo/GLOSARIO/#endpoint","title":"Endpoint","text":"<p>Definici\u00f3n: URL espec\u00edfica de API que realiza operaci\u00f3n particular.</p> <p>Analog\u00eda: Ventanillas de banco. Cada una hace algo diferente.</p> <pre><code>@app.get(\"/health\")\n@app.post(\"/predict\")\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#ensemble","title":"Ensemble","text":"<p>Definici\u00f3n: Combina m\u00faltiples modelos para mejores predicciones.</p> <p>Analog\u00eda: 100 doctores opinando en vez de 1. Opini\u00f3n agregada suele ser mejor.</p> <p>Tipos: Bagging (Random Forest), Boosting (XGBoost), Stacking</p>"},{"location":"docs/apoyo/GLOSARIO/#environment","title":"Environment","text":"<p>Definici\u00f3n: Conjunto aislado de dependencias donde ejecuta c\u00f3digo.</p> <p>Analog\u00eda: Diferentes cocinas para diferentes tipos de comida.</p> <p>Tipos: Desarrollo, Staging, Producci\u00f3n</p>"},{"location":"docs/apoyo/GLOSARIO/#evidently","title":"Evidently","text":"<p>Definici\u00f3n t\u00e9cnica: Librer\u00eda open-source de Python para monitoreo de modelos ML en producci\u00f3n. Genera reportes interactivos de data drift, target drift, data quality, y performance del modelo comparando datasets de referencia con datasets actuales.</p> <p>Explicaci\u00f3n conceptual: Cuando despliegas un modelo, necesitas saber si sigue funcionando bien. Evidently automatiza esta vigilancia: compara los datos que ve el modelo en producci\u00f3n con los datos de entrenamiento, detecta cambios estad\u00edsticos (drift), genera alertas, y produce reportes visuales. Es como tener un \"chequeo m\u00e9dico\" continuo para tu modelo.</p> <p>Analog\u00eda desarrollada: Imagina que tienes un carro. Evidently es el tablero de instrumentos que te dice si la presi\u00f3n de las llantas baj\u00f3, si el aceite necesita cambio, si el motor est\u00e1 sobrecalentando. No esperas a que el carro se descomponga\u2014el tablero te avisa antes de que el problema sea grave.</p> <p>Ejemplo pr\u00e1ctico: <pre><code>from evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset, DataQualityPreset\n\n# Comparar datos de training vs producci\u00f3n\nreport = Report(metrics=[\n    DataDriftPreset(),\n    DataQualityPreset(),\n])\n\nreport.run(\n    reference_data=train_df,\n    current_data=production_df\n)\n\n# Generar reporte HTML interactivo\nreport.save_html(\"drift_report.html\")\n\n# O extraer m\u00e9tricas program\u00e1ticamente\ndrift_results = report.as_dict()\nif drift_results['metrics'][0]['result']['dataset_drift']:\n    print(\"\u26a0\ufe0f Drift significativo detectado!\")\n</code></pre></p> <p>Capacidades: - Data Drift: Detecta cambios en distribuciones de features - Target Drift: Detecta cambios en distribuci\u00f3n del target - Data Quality: Valores faltantes, outliers, correlaciones - Model Performance: Accuracy, precision, recall en producci\u00f3n - Regression Performance: MAE, RMSE, error distribution</p> <p>Relacionados: Data Drift, Model Monitoring, Observabilidad, NannyML</p>"},{"location":"docs/apoyo/GLOSARIO/#experiment-tracking","title":"Experiment Tracking","text":"<p>Definici\u00f3n: Registrar par\u00e1metros, m\u00e9tricas, artefactos de cada experimento ML.</p> <p>Analog\u00eda: Cuaderno de laboratorio de cient\u00edfico.</p> <p>Herramientas: MLflow, W&amp;B, Neptune</p>"},{"location":"docs/apoyo/GLOSARIO/#f","title":"F","text":""},{"location":"docs/apoyo/GLOSARIO/#f1-score","title":"F1 Score","text":"<p>Definici\u00f3n: Media arm\u00f3nica de Precision y Recall. Balance entre ambas.</p> <p>F\u00f3rmula: <code>F1 = 2 \u00d7 (Precision \u00d7 Recall) / (Precision + Recall)</code></p> <p>Analog\u00eda: Buscador de trufas. No sirve encontrar pocas muy precisamente ni todas con muchas falsas.</p>"},{"location":"docs/apoyo/GLOSARIO/#fastapi","title":"FastAPI","text":"<p>Definici\u00f3n: Framework Python para APIs de alto rendimiento con validaci\u00f3n autom\u00e1tica.</p> <p>Analog\u00eda: Mesero eficiente que valida pedidos, da men\u00fa descriptivo, atiende muchas mesas.</p> <pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\napp = FastAPI()\n\n@app.post(\"/predict\")\nasync def predict(data: PredictionInput):\n    return {\"probability\": model.predict_proba([data])[0, 1]}\n</code></pre> <p>Relacionados: Pydantic, Uvicorn, REST</p>"},{"location":"docs/apoyo/GLOSARIO/#feature","title":"Feature","text":"<p>Definici\u00f3n: Variable de entrada para predicciones.</p> <p>Analog\u00eda: Ingredientes de receta. Para predecir si pastel sale bien: harina, az\u00facar, temperatura.</p> <p>Tipos: Num\u00e9ricas, Categ\u00f3ricas, Binarias, Derivadas</p>"},{"location":"docs/apoyo/GLOSARIO/#feature-engineering","title":"Feature Engineering","text":"<p>Definici\u00f3n: Crear/transformar/seleccionar features para mejorar modelo.</p> <p>Analog\u00eda: Chef preparando ingredientes. Ingredientes crudos se transforman en algo digerible.</p> <pre><code>df['balance_per_product'] = df['Balance'] / (df['NumOfProducts'] + 1)\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#feature-store","title":"Feature Store","text":"<p>Definici\u00f3n: Sistema centralizado para almacenar y servir features consistentemente.</p> <p>Analog\u00eda: Almac\u00e9n central de ingredientes preparados para cadena de restaurantes.</p> <p>Herramientas: Feast, Tecton</p>"},{"location":"docs/apoyo/GLOSARIO/#fixture-pytest","title":"Fixture (pytest)","text":"<p>Definici\u00f3n: Funci\u00f3n que provee datos/recursos reutilizables para tests.</p> <p>Analog\u00eda: Setup de set de filmaci\u00f3n antes de cada escena.</p> <pre><code>@pytest.fixture\ndef sample_customer():\n    return {\"Age\": 35, \"Balance\": 50000}\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#flake8","title":"Flake8","text":"<p>Definici\u00f3n: Linting para Python: errores l\u00f3gicos, estilo PEP8, complejidad.</p> <p>Analog\u00eda: Corrector de estilo de peri\u00f3dico.</p> <pre><code>flake8 src/\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#g","title":"G","text":""},{"location":"docs/apoyo/GLOSARIO/#git","title":"Git","text":"<p>Definici\u00f3n: Control de versiones distribuido.</p> <p>Analog\u00eda: \"Deshacer\" infinito. Volver a cualquier momento, ver qu\u00e9 cambi\u00f3 y por qu\u00e9.</p> <pre><code>git add . &amp;&amp; git commit -m \"mensaje\" &amp;&amp; git push\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#github-actions","title":"GitHub Actions","text":"<p>Definici\u00f3n: CI/CD integrado en GitHub.</p> <p>Analog\u00eda: Mayordomo robot que ejecuta instrucciones autom\u00e1ticamente.</p> <pre><code>on: [push]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - run: pytest tests/\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#gitleaks","title":"Gitleaks","text":"<p>Definici\u00f3n: Detecta secrets accidentalmente commiteados.</p> <p>Analog\u00eda: Detector de metales en aeropuerto para c\u00f3digo.</p>"},{"location":"docs/apoyo/GLOSARIO/#gradient-descent","title":"Gradient Descent","text":"<p>Definici\u00f3n: Algoritmo que encuentra par\u00e1metros que minimizan p\u00e9rdida.</p> <p>Analog\u00eda: En monta\u00f1a con niebla, das pasos peque\u00f1os siempre cuesta abajo.</p> <p>Relacionados: Learning Rate, Loss Function</p>"},{"location":"docs/apoyo/GLOSARIO/#grafana","title":"Grafana","text":"<p>Definici\u00f3n: Visualizaci\u00f3n y dashboards para m\u00e9tricas.</p> <p>Analog\u00eda: Tablero de instrumentos de avi\u00f3n.</p> <p>Relacionados: Prometheus, Observabilidad</p>"},{"location":"docs/apoyo/GLOSARIO/#h","title":"H","text":""},{"location":"docs/apoyo/GLOSARIO/#health-check","title":"Health Check","text":"<p>Definici\u00f3n: Endpoint que verifica si servicio funciona.</p> <p>Analog\u00eda: M\u00e9dico preguntando \"\u00bfc\u00f3mo te sientes?\".</p> <pre><code>@app.get(\"/health\")\ndef health():\n    return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#hpa-horizontal-pod-autoscaler","title":"HPA (Horizontal Pod Autoscaler)","text":"<p>Definici\u00f3n: Kubernetes: escala pods autom\u00e1ticamente seg\u00fan m\u00e9tricas.</p> <p>Analog\u00eda: Gerente de restaurante que llama m\u00e1s meseros si hay muchas mesas ocupadas.</p>"},{"location":"docs/apoyo/GLOSARIO/#hyperparameter","title":"Hyperparameter","text":"<p>Definici\u00f3n: Par\u00e1metro configurado ANTES del entrenamiento.</p> <p>Analog\u00eda: Decisiones antes de hornear: temperatura, tiempo, tama\u00f1o de molde.</p> <p>Ejemplos: n_estimators, learning_rate, max_depth</p>"},{"location":"docs/apoyo/GLOSARIO/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<p>Definici\u00f3n: Encontrar combinaci\u00f3n \u00f3ptima de hiperpar\u00e1metros.</p> <p>Analog\u00eda: Afinar guitarra. Probar perillas hasta mejor sonido.</p> <p>T\u00e9cnicas: Grid Search, Random Search, Bayesian Optimization</p>"},{"location":"docs/apoyo/GLOSARIO/#i","title":"I","text":""},{"location":"docs/apoyo/GLOSARIO/#image-docker","title":"Image (Docker)","text":"<p>Definici\u00f3n: Template inmutable para crear contenedores.</p> <p>Analog\u00eda: Receta + ingredientes pre-empaquetados. Imagen es el kit, contenedor es el pastel horneado.</p>"},{"location":"docs/apoyo/GLOSARIO/#imputer","title":"Imputer","text":"<p>Definici\u00f3n: Rellena valores faltantes (NaN).</p> <p>Analog\u00eda: Restaurador de pinturas rellenando huecos.</p> <pre><code>SimpleImputer(strategy='median')\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#inference","title":"Inference","text":"<p>Definici\u00f3n: Usar modelo entrenado para predicciones sobre datos nuevos.</p> <p>Analog\u00eda: Entrenamiento = estudiar. Inferencia = tomar el examen.</p>"},{"location":"docs/apoyo/GLOSARIO/#ingress","title":"Ingress","text":"<p>Definici\u00f3n: Kubernetes: gestiona acceso HTTP externo al cluster.</p> <p>Analog\u00eda: Recepci\u00f3n de edificio que dirige tr\u00e1fico.</p>"},{"location":"docs/apoyo/GLOSARIO/#integration-test","title":"Integration Test","text":"<p>Definici\u00f3n: Verifica que m\u00faltiples componentes funcionan juntos.</p> <p>Analog\u00eda: Probar que motor, transmisi\u00f3n y ruedas funcionan juntos.</p>"},{"location":"docs/apoyo/GLOSARIO/#isort","title":"isort","text":"<p>Definici\u00f3n: Ordena imports de Python autom\u00e1ticamente.</p> <p>Analog\u00eda: Organizador de armario que siempre pone ropa en mismo orden.</p>"},{"location":"docs/apoyo/GLOSARIO/#j","title":"J","text":""},{"location":"docs/apoyo/GLOSARIO/#job-github-actions","title":"Job (GitHub Actions)","text":"<p>Definici\u00f3n: Conjunto de steps en mismo runner.</p> <p>Relacionados: Workflow, Step, Runner</p>"},{"location":"docs/apoyo/GLOSARIO/#joblib","title":"Joblib","text":"<p>Definici\u00f3n: Serializa objetos Python, especialmente modelos sklearn.</p> <pre><code>joblib.dump(model, \"model.pkl\")\nmodel = joblib.load(\"model.pkl\")\n</code></pre> <p>##  K</p> <p>### Kubernetes (K8s)  Definici\u00f3n: Orquestador de contenedores para automatizar despliegue y escalado.</p> <p>Analog\u00eda: Director de orquesta coordinando muchos m\u00fasicos (contenedores).</p> <p>Recursos: Pod, Deployment, Service, Ingress</p>"},{"location":"docs/apoyo/GLOSARIO/#k-fold","title":"K-Fold","text":"<p>Definici\u00f3n: Dividir datos en K partes para cross-validation.</p> <p>Relacionados: Cross-Validation, Stratified</p> <p>##  L</p> <p>### Latency (Latencia)  Definici\u00f3n: Tiempo de respuesta del sistema. En APIs ML: milisegundos.</p> <p>Analog\u00eda: Tiempo entre pedir comida y que llegue.</p> <p>P95: El 95% de requests responden en menos de X ms.</p>"},{"location":"docs/apoyo/GLOSARIO/#learning-rate","title":"Learning Rate","text":"<p>Definici\u00f3n: Tama\u00f1o de paso en gradient descent.</p> <p>Analog\u00eda: Paso grande = llegas r\u00e1pido pero puedes pasar el m\u00ednimo. Paso peque\u00f1o = lento pero preciso.</p>"},{"location":"docs/apoyo/GLOSARIO/#linting","title":"Linting","text":"<p>Definici\u00f3n: An\u00e1lisis est\u00e1tico para detectar errores y violaciones de estilo.</p> <p>Herramientas: Flake8, pylint, mypy</p>"},{"location":"docs/apoyo/GLOSARIO/#load-balancer","title":"Load Balancer","text":"<p>Definici\u00f3n: Distribuye tr\u00e1fico entre m\u00faltiples servidores.</p> <p>Analog\u00eda: Hostess de restaurante que asigna mesas equitativamente.</p>"},{"location":"docs/apoyo/GLOSARIO/#loss-function-funcion-de-perdida","title":"Loss Function (Funci\u00f3n de P\u00e9rdida)","text":"<p>Definici\u00f3n: Mide qu\u00e9 tan mal son las predicciones. El entrenamiento la minimiza.</p> <p>Ejemplos: MSE (regresi\u00f3n), Cross-Entropy (clasificaci\u00f3n)</p>"},{"location":"docs/apoyo/GLOSARIO/#m","title":"M","text":"<p>### Makefile  Definici\u00f3n: Archivo con comandos abreviados para tareas comunes.</p> <pre><code>test:\n    pytest tests/ -v\nlint:\n    black src/ &amp;&amp; flake8 src/\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#matrix-github-actions","title":"Matrix (GitHub Actions)","text":"<p>Definici\u00f3n: Ejecutar job con m\u00faltiples combinaciones de par\u00e1metros.</p> <pre><code>strategy:\n  matrix:\n    python-version: [3.10, 3.11]\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#metric-metrica","title":"Metric (M\u00e9trica)","text":"<p>Definici\u00f3n: Valor num\u00e9rico que mide rendimiento del modelo.</p> <p>Clasificaci\u00f3n: Accuracy, Precision, Recall, F1, AUC Regresi\u00f3n: MSE, RMSE, MAE, R\u00b2</p>"},{"location":"docs/apoyo/GLOSARIO/#middleware","title":"Middleware","text":"<p>Definici\u00f3n: C\u00f3digo que intercepta requests/responses entre cliente y aplicaci\u00f3n.</p> <p>Analog\u00eda: Portero que revisa credenciales antes de dejarte pasar.</p>"},{"location":"docs/apoyo/GLOSARIO/#mlflow","title":"MLflow","text":"<p>Definici\u00f3n: Plataforma open-source para gestionar ciclo de vida ML.</p> <p>Componentes: Tracking, Projects, Models, Registry</p> <pre><code>with mlflow.start_run():\n    mlflow.log_params(params)\n    mlflow.log_metrics(metrics)\n    mlflow.sklearn.log_model(model, \"model\")\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#mlops","title":"MLOps","text":"<p>Definici\u00f3n t\u00e9cnica: Conjunto de pr\u00e1cticas que unifican Machine Learning, DevOps y Data Engineering para automatizar y estandarizar el ciclo de vida completo de modelos ML: desde experimentaci\u00f3n hasta producci\u00f3n, incluyendo monitoreo, reentrenamiento y gobernanza.</p> <p>Explicaci\u00f3n conceptual: Data Scientists saben entrenar modelos. DevOps sabe desplegar aplicaciones. Data Engineers saben mover datos. MLOps es el puente que conecta estos tres mundos. Sin MLOps, tienes \"modelos en notebooks\" que nunca llegan a producci\u00f3n, o modelos desplegados que nadie monitorea y se degradan silenciosamente. MLOps trae madurez industrial al ML.</p> <p>Analog\u00eda desarrollada: Imagina que los Data Scientists son chefs que crean recetas incre\u00edbles en su cocina experimental. DevOps es el equipo que opera restaurantes a escala. MLOps es el proceso que convierte esa receta experimental en un men\u00fa estandarizado, con control de calidad, ingredientes versionados, y alertas si la calidad baja. Sin MLOps, tienes un chef genial cuyas recetas nadie puede reproducir consistentemente.</p> <p>Pilares de MLOps: 1. Versionado: C\u00f3digo (Git), Datos (DVC), Modelos (MLflow) 2. Automatizaci\u00f3n: CI/CD, pipelines de entrenamiento 3. Testing: Datos, modelos, APIs, integraci\u00f3n 4. Monitoreo: Drift, performance, latencia 5. Reproducibilidad: Ambientes, seeds, configuraciones</p> <p>Relacionados: DevOps, CI/CD, MLflow, DVC, Model Monitoring</p>"},{"location":"docs/apoyo/GLOSARIO/#multi-stage-build-docker","title":"Multi-stage Build (Docker)","text":"<p>Definici\u00f3n t\u00e9cnica: T\u00e9cnica de construcci\u00f3n de im\u00e1genes Docker que usa m\u00faltiples <code>FROM</code> statements, permitiendo separar el ambiente de compilaci\u00f3n/build del ambiente de ejecuci\u00f3n. El resultado es una imagen final m\u00e1s peque\u00f1a y segura que solo contiene lo necesario para ejecutar la aplicaci\u00f3n.</p> <p>Explicaci\u00f3n conceptual: Cuando construyes una aplicaci\u00f3n, necesitas herramientas de compilaci\u00f3n, tests, dependencias de desarrollo. Pero en producci\u00f3n, solo necesitas el binario final y las dependencias runtime. Multi-stage te permite \"cocinar\" en una cocina completa y luego servir solo el plato terminado, sin llevar todos los utensilios al comedor.</p> <p>Analog\u00eda desarrollada: Imagina construir un mueble IKEA. Necesitas martillo, destornillador, nivel, instrucciones, embalaje. Pero una vez terminado, solo quieres el mueble en tu sala\u2014no el taller completo. Multi-stage es exactamente eso: usas un container \"taller\" con todas las herramientas, construyes, y luego copias solo el resultado final a un container \"sala\" limpio y minimalista.</p> <p>Ejemplo del portafolio: <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 1: Builder - Tiene todas las herramientas\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim AS builder\n\nWORKDIR /app\n\n# Instalar dependencias de compilaci\u00f3n (solo en builder)\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Instalar dependencias Python en directorio aislado\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --target=/app/deps -r requirements.txt\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# STAGE 2: Runtime - Solo lo necesario para ejecutar\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim\n\n# Usuario no-root (seguridad)\nRUN useradd --create-home appuser\n\nWORKDIR /app\n\n# Copiar SOLO las dependencias instaladas (no el toolchain)\nCOPY --from=builder /app/deps /usr/local/lib/python3.11/site-packages/\n\n# Copiar c\u00f3digo de aplicaci\u00f3n\nCOPY --chown=appuser:appuser src/ ./src/\nCOPY --chown=appuser:appuser app/ ./app/\nCOPY --chown=appuser:appuser artifacts/ ./artifacts/\n\nUSER appuser\n\nEXPOSE 8000\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre></p> <p>Beneficios: - Imagen m\u00e1s peque\u00f1a: De ~1.5GB a ~500MB - M\u00e1s segura: Sin compiladores ni herramientas de ataque - M\u00e1s r\u00e1pida de desplegar: Menos bytes que transferir</p> <p>Relacionados: Docker, Container, Dockerfile, Non-root User</p>"},{"location":"docs/apoyo/GLOSARIO/#model-card","title":"Model Card","text":"<p>Definici\u00f3n: Documento describiendo modelo: prop\u00f3sito, datos, m\u00e9tricas, limitaciones, \u00e9tica.</p> <p>Analog\u00eda: Prospecto de medicamento. Informaci\u00f3n completa sobre qu\u00e9 hace y sus efectos.</p>"},{"location":"docs/apoyo/GLOSARIO/#model-registry","title":"Model Registry","text":"<p>Definici\u00f3n: Sistema para versionar y gestionar modelos ML.</p> <p>Estados: Staging \u2192 Production \u2192 Archived</p>"},{"location":"docs/apoyo/GLOSARIO/#mypy","title":"mypy","text":"<p>Definici\u00f3n: Type checking est\u00e1tico para Python.</p> <pre><code>mypy src/\n</code></pre> <p>Relacionados: Type Hints, Pydantic</p>"},{"location":"docs/apoyo/GLOSARIO/#n","title":"N","text":"<p>### NaN (Not a Number)  Definici\u00f3n: Valor especial para datos faltantes o indefinidos.</p> <pre><code>import numpy as np\nnp.nan\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#namespace","title":"Namespace","text":"<p>Definici\u00f3n: Kubernetes: divisi\u00f3n l\u00f3gica del cluster para aislamiento.</p> <p>Analog\u00eda: Departamentos en una empresa. Cada uno tiene sus recursos.</p>"},{"location":"docs/apoyo/GLOSARIO/#o","title":"O","text":"<p>### Observability (Observabilidad)  Definici\u00f3n: Capacidad de entender estado interno de sistema desde outputs externos.</p> <p>3 Pilares: Logs, Metrics, Traces</p> <p>Analog\u00eda: Instrumentos de avi\u00f3n. Si no puedes ver, no puedes arreglar.</p>"},{"location":"docs/apoyo/GLOSARIO/#one-hot-encoding","title":"One-Hot Encoding","text":"<p>Definici\u00f3n: Convierte variables categ\u00f3ricas en vectores binarios.</p> <pre><code>Country: [France, Spain, Germany]\nFrance \u2192 [1, 0, 0]\nSpain  \u2192 [0, 1, 0]\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#overfitting-sobreajuste","title":"Overfitting (Sobreajuste)","text":"<p>Definici\u00f3n: Modelo memoriza datos de entrenamiento, no generaliza.</p> <p>Analog\u00eda: Estudiante que memoriza respuestas exactas pero no entiende conceptos.</p> <p>Se\u00f1ales: Train accuracy muy alta, validation accuracy baja.</p> <p>Soluciones: M\u00e1s datos, regularizaci\u00f3n, early stopping, dropout</p>"},{"location":"docs/apoyo/GLOSARIO/#p","title":"P","text":"<p>### Pipeline (sklearn)  Definici\u00f3n: Secuencia de transformaciones y estimador final encadenados.</p> <p>Analog\u00eda: L\u00ednea de ensamblaje. Cada estaci\u00f3n hace una transformaci\u00f3n.</p> <pre><code>pipeline = Pipeline([\n    ('scaler', StandardScaler()),\n    ('model', RandomForestClassifier())\n])\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#pod","title":"Pod","text":"<p>Definici\u00f3n: Kubernetes: unidad de deployment m\u00e1s peque\u00f1a. Uno o m\u00e1s contenedores.</p> <p>Analog\u00eda: Apartamento en edificio. Contenedores son habitaciones del apartamento.</p>"},{"location":"docs/apoyo/GLOSARIO/#precision-precision","title":"Precision (Precisi\u00f3n)","text":"<p>Definici\u00f3n: De predicciones positivas, \u00bfcu\u00e1ntas son correctas? TP / (TP + FP)</p> <p>Analog\u00eda: De las personas que detuviste como sospechosas, \u00bfcu\u00e1ntas eran realmente criminales?</p>"},{"location":"docs/apoyo/GLOSARIO/#pre-commit-hook","title":"Pre-commit Hook","text":"<p>Definici\u00f3n: Script que se ejecuta autom\u00e1ticamente antes de cada commit.</p> <p>Analog\u00eda: Control de calidad que revisa tu trabajo antes de entregarlo.</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    hooks:\n      - id: black\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#prometheus","title":"Prometheus","text":"<p>Definici\u00f3n: Sistema de monitoreo y alertas. Recolecta m\u00e9tricas de servicios.</p> <p>Relacionados: Grafana, Metrics, Observabilidad</p>"},{"location":"docs/apoyo/GLOSARIO/#pull-request-pr","title":"Pull Request (PR)","text":"<p>Definici\u00f3n: Solicitud para integrar cambios con revisi\u00f3n de c\u00f3digo.</p> <p>Analog\u00eda: Propuesta formal que requiere aprobaci\u00f3n antes de aceptarse.</p>"},{"location":"docs/apoyo/GLOSARIO/#pydantic","title":"Pydantic","text":"<p>Definici\u00f3n: Validaci\u00f3n de datos en Python usando type hints.</p> <pre><code>class Customer(BaseModel):\n    age: int = Field(ge=18, le=100)\n    name: str\n</code></pre> <p>Relacionados: Type Hints, FastAPI, Validation</p>"},{"location":"docs/apoyo/GLOSARIO/#pytest","title":"pytest","text":"<p>Definici\u00f3n: Framework de testing para Python.</p> <pre><code>def test_prediction():\n    result = model.predict([[35, 50000]])\n    assert result[0] in [0, 1]\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#r","title":"R","text":"<p>### Random Forest</p> <p>Definici\u00f3n t\u00e9cnica: Algoritmo de ensemble learning que construye m\u00faltiples \u00e1rboles de decisi\u00f3n durante el entrenamiento y combina sus predicciones (votaci\u00f3n mayoritaria para clasificaci\u00f3n, promedio para regresi\u00f3n). Cada \u00e1rbol se entrena con un subconjunto aleatorio de datos (bagging) y features (random subspace).</p> <p>Explicaci\u00f3n conceptual: Un solo \u00e1rbol de decisi\u00f3n puede sobreajustarse f\u00e1cilmente y es muy sensible a peque\u00f1os cambios en los datos. Random Forest resuelve esto con la \"sabidur\u00eda de las multitudes\": entrena cientos de \u00e1rboles \"diversos\" (cada uno ve datos diferentes) y promedia sus opiniones. Los errores individuales se cancelan, produciendo un modelo robusto y estable.</p> <p>Analog\u00eda desarrollada: Imagina 100 doctores, cada uno especializado en diferentes aspectos (algunos ven m\u00e1s casos de ciertas enfermedades, otros atienden diferentes demograf\u00edas). Si cada doctor da su diagn\u00f3stico individualmente, algunos acertar\u00e1n y otros fallar\u00e1n. Pero si los 100 votan y tomas la opini\u00f3n mayoritaria, casi siempre aciertas. Eso es Random Forest: democracia de \u00e1rboles donde los errores individuales se cancelan.</p> <p>Por qu\u00e9 es popular en MLOps: - Interpretabilidad: Feature importances nativas - Robustez: Funciona bien \"out of the box\" sin tuning extensivo - Versatilidad: Clasificaci\u00f3n y regresi\u00f3n - Sin normalizaci\u00f3n: No requiere escalar features</p> <p>Ejemplo del portafolio (BankChurn): <pre><code>from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\n\n# Par\u00e1metros clave:\n# - n_estimators: N\u00famero de \u00e1rboles (m\u00e1s = m\u00e1s estable, m\u00e1s lento)\n# - max_depth: Profundidad m\u00e1xima (controla overfitting)\n# - class_weight: Manejo de desbalance\n\npipeline = Pipeline([\n    ('preprocessor', ColumnTransformer([\n        ('num', SimpleImputer(strategy='median'), num_cols),\n        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n    ])),\n    ('classifier', RandomForestClassifier(\n        n_estimators=100,\n        max_depth=10,\n        class_weight='balanced',  # Cr\u00edtico para churn\n        random_state=42,\n        n_jobs=-1  # Paralelizar\n    ))\n])\n\n# Feature importance despu\u00e9s de entrenar\nimportances = pipeline.named_steps['classifier'].feature_importances_\n</code></pre></p> <p>Hiperpar\u00e1metros importantes: | Par\u00e1metro | Default | Efecto | |-----------|---------|--------| | n_estimators | 100 | M\u00e1s \u00e1rboles = m\u00e1s estable pero m\u00e1s lento | | max_depth | None | Limitar previene overfitting | | min_samples_split | 2 | Mayor valor = \u00e1rboles m\u00e1s peque\u00f1os | | class_weight | None | 'balanced' para clases desbalanceadas |</p> <p>Relacionados: Ensemble, Bagging, Decision Tree, class_weight, Feature Importance</p>"},{"location":"docs/apoyo/GLOSARIO/#recall-sensibilidad","title":"Recall (Sensibilidad)","text":"<p>Definici\u00f3n t\u00e9cnica: M\u00e9trica que mide qu\u00e9 proporci\u00f3n de los casos positivos reales fueron correctamente identificados. F\u00f3rmula: <code>TP / (TP + FN)</code>. Tambi\u00e9n llamada Sensibilidad o True Positive Rate.</p> <p>Explicaci\u00f3n conceptual: Recall responde: \"De todos los casos positivos reales, \u00bfcu\u00e1ntos logr\u00e9 detectar?\". Es cr\u00edtica cuando el costo de no detectar un positivo es alto: diagn\u00f3stico de c\u00e1ncer (no detectar = paciente sin tratamiento), detecci\u00f3n de fraude (no detectar = p\u00e9rdida financiera), predicci\u00f3n de churn (no detectar = cliente perdido).</p> <p>Analog\u00eda desarrollada: Imagina un detector de metales en un aeropuerto. Recall es: \"De todas las armas reales que pasaron, \u00bfcu\u00e1ntas detect\u00f3?\". Un Recall del 100% significa que detect\u00f3 todas las armas (aunque haya generado muchas falsas alarmas con llaves y monedas). En seguridad, preferimos alta sensibilidad aunque suene m\u00e1s veces innecesariamente.</p> <p>En el portafolio: BankChurn prioriza Recall porque el costo de no detectar un churner (perderlo) es mayor que el costo de ofrecerle retenci\u00f3n a alguien que no iba a irse.</p> <p>Trade-off Precision vs Recall: <pre><code>                    Predicci\u00f3n\n                    Positivo    Negativo\nRealidad Positivo   TP          FN (Recall falla aqu\u00ed)\n         Negativo   FP          TN\n\nRecall = TP / (TP + FN) \u2192 Maximizar TP, minimizar FN\n</code></pre></p> <p>Relacionados: Precision, F1 Score, Threshold, ROC-AUC</p>"},{"location":"docs/apoyo/GLOSARIO/#regression-regresion","title":"Regression (Regresi\u00f3n)","text":"<p>Definici\u00f3n: Problema ML para predecir valor num\u00e9rico continuo.</p> <p>Ejemplos: Precio de casa, temperatura, ventas</p>"},{"location":"docs/apoyo/GLOSARIO/#regularization-regularizacion","title":"Regularization (Regularizaci\u00f3n)","text":"<p>Definici\u00f3n: T\u00e9cnicas para prevenir overfitting penalizando complejidad.</p> <p>Tipos: L1 (Lasso), L2 (Ridge), Dropout, Early Stopping</p>"},{"location":"docs/apoyo/GLOSARIO/#replica","title":"Replica","text":"<p>Definici\u00f3n: Copia de un pod/servicio para alta disponibilidad.</p> <p>Relacionados: Deployment, ReplicaSet</p>"},{"location":"docs/apoyo/GLOSARIO/#reproducibility-reproducibilidad","title":"Reproducibility (Reproducibilidad)","text":"<p>Definici\u00f3n: Obtener mismos resultados con mismo c\u00f3digo y datos.</p> <p>Clave: Seeds, versionado de datos/c\u00f3digo/ambiente</p>"},{"location":"docs/apoyo/GLOSARIO/#rest-api","title":"REST API","text":"<p>Definici\u00f3n: Estilo arquitect\u00f3nico con HTTP methods: GET, POST, PUT, DELETE.</p> <p>Relacionados: API, HTTP, Endpoint</p>"},{"location":"docs/apoyo/GLOSARIO/#runbook","title":"Runbook","text":"<p>Definici\u00f3n t\u00e9cnica: Documento operacional que contiene procedimientos paso a paso para manejar incidentes, alertas o tareas de mantenimiento de un sistema en producci\u00f3n. Incluye informaci\u00f3n del servicio, alertas comunes, y procedimientos de emergencia.</p> <p>Contenido t\u00edpico: - Informaci\u00f3n del servicio (owner, criticidad, endpoints) - Procedimientos para alertas comunes - Comandos de diagn\u00f3stico y recuperaci\u00f3n - Escalamiento y contactos</p> <p>En el portafolio: Ver 17_DESPLIEGUE.md.</p> <p>Relacionados: SLO, SLA, Incident Response, On-call</p>"},{"location":"docs/apoyo/GLOSARIO/#ruff","title":"Ruff","text":"<p>Definici\u00f3n t\u00e9cnica: Linter y formateador de c\u00f3digo Python extremadamente r\u00e1pido, escrito en Rust. Reemplaza m\u00faltiples herramientas (Flake8, Black, isort, pyupgrade, etc.) con una sola herramienta 10-100x m\u00e1s r\u00e1pida.</p> <p>Explicaci\u00f3n conceptual: Tradicionalmente, un proyecto Python necesitaba m\u00faltiples herramientas para mantener la calidad del c\u00f3digo: Black para formatear, Flake8 para detectar errores, isort para ordenar imports, pyupgrade para sintaxis moderna. Cada herramienta ten\u00eda su configuraci\u00f3n, versi\u00f3n, y tiempo de ejecuci\u00f3n. Ruff unifica todo esto: un solo binario que hace todo, instant\u00e1neamente. Es la herramienta moderna que est\u00e1 reemplazando al stack tradicional.</p> <p>Analog\u00eda desarrollada: Imagina tener una navaja suiza en vez de cargar tijeras, destornillador, cuchillo y abridor por separado. Ruff es esa navaja suiza: todas las herramientas de calidad de c\u00f3digo en una, y adem\u00e1s es m\u00e1s ligera y r\u00e1pida que cualquiera de las individuales.</p> <p>Por qu\u00e9 importa: - Velocidad: 10-100x m\u00e1s r\u00e1pido que Flake8+Black+isort - Unificaci\u00f3n: Una herramienta, una configuraci\u00f3n - Compatibilidad: Entiende las reglas de Flake8, Black, isort - Moderno: Soporta Python 3.12+, type hints, f-strings</p> <p>Ejemplo de configuraci\u00f3n (pyproject.toml): <pre><code>[tool.ruff]\nline-length = 88\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\nselect = [\n    \"E\",    # pycodestyle errors\n    \"W\",    # pycodestyle warnings\n    \"F\",    # Pyflakes\n    \"I\",    # isort\n    \"B\",    # flake8-bugbear\n    \"C4\",   # flake8-comprehensions\n    \"UP\",   # pyupgrade\n]\nignore = [\"E501\"]  # Line too long (handled by formatter)\n\n[tool.ruff.lint.isort]\nknown-first-party = [\"bankchurn\", \"carvision\", \"telecomai\"]\n</code></pre></p> <p>Uso: <pre><code># Lint (detectar errores)\nruff check src/\n\n# Lint con auto-fix\nruff check --fix src/\n\n# Format (como Black)\nruff format src/\n\n# Pre-commit hook\n# .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.4.4\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n</code></pre></p> <p>Relacionados: Linting, Black, Flake8, isort, pre-commit, Code Quality</p>"},{"location":"docs/apoyo/GLOSARIO/#s","title":"S","text":""},{"location":"docs/apoyo/GLOSARIO/#scaling-escalado-de-features","title":"Scaling (Escalado de Features)","text":"<p>Definici\u00f3n: Normalizar features a rango similar.</p> <p>T\u00e9cnicas: StandardScaler (z-score), MinMaxScaler (0-1)</p>"},{"location":"docs/apoyo/GLOSARIO/#scikit-learn-sklearn","title":"Scikit-learn (sklearn)","text":"<p>Definici\u00f3n: Librer\u00eda Python para ML cl\u00e1sico.</p> <p>M\u00f3dulos: preprocessing, model_selection, ensemble, metrics</p>"},{"location":"docs/apoyo/GLOSARIO/#secret","title":"Secret","text":"<p>Definici\u00f3n: Valor sensible (contrase\u00f1a, API key) que no debe estar en c\u00f3digo.</p> <p>Kubernetes: Objeto Secret para almacenar datos sensibles encriptados.</p>"},{"location":"docs/apoyo/GLOSARIO/#seed-random-state","title":"Seed (Random State)","text":"<p>Definici\u00f3n: Valor para inicializar generadores aleatorios. Garantiza reproducibilidad.</p> <pre><code>np.random.seed(42)\nRandomForestClassifier(random_state=42)\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#service-kubernetes","title":"Service (Kubernetes)","text":"<p>Definici\u00f3n: Abstracci\u00f3n que expone pods como servicio de red.</p> <p>Tipos: ClusterIP, NodePort, LoadBalancer</p>"},{"location":"docs/apoyo/GLOSARIO/#shap","title":"SHAP","text":"<p>Definici\u00f3n t\u00e9cnica: SHapley Additive exPlanations. Framework de interpretabilidad basado en teor\u00eda de juegos que asigna a cada feature su contribuci\u00f3n marginal a una predicci\u00f3n espec\u00edfica. Funciona con cualquier modelo (model-agnostic).</p> <p>Explicaci\u00f3n conceptual: Cuando un modelo predice que un cliente va a abandonar, quieres saber por qu\u00e9. SHAP descompone la predicci\u00f3n en contribuciones de cada feature: \"El balance alto contribuy\u00f3 +0.15 a la probabilidad de churn, la edad joven contribuy\u00f3 -0.08, el n\u00famero de productos contribuy\u00f3 +0.12...\". Esto permite explicar cada predicci\u00f3n individual, no solo el modelo en general.</p> <p>Analog\u00eda desarrollada: Imagina un jurado de 10 personas que decide un veredicto. SHAP es como analizar cu\u00e1nto influy\u00f3 cada jurado en la decisi\u00f3n final. \"Mar\u00eda estaba muy convencida (+0.3), Juan estaba indeciso (+0.05), Pedro iba en contra (-0.2)...\". Sumando todas las contribuciones, obtienes el veredicto final.</p> <p>Relacionados: Interpretabilidad, Feature Importance, Explainability</p>"},{"location":"docs/apoyo/GLOSARIO/#smote-synthetic-minority-over-sampling-technique","title":"SMOTE (Synthetic Minority Over-sampling Technique)","text":"<p>Definici\u00f3n t\u00e9cnica: T\u00e9cnica de oversampling que genera ejemplos sint\u00e9ticos de la clase minoritaria interpolando entre ejemplos existentes y sus k vecinos m\u00e1s cercanos. No duplica ejemplos\u2014crea nuevos puntos en el espacio de features.</p> <p>Explicaci\u00f3n conceptual: Cuando tienes 95% de una clase y 5% de otra, el modelo aprende a ignorar la minoritaria. SMOTE resuelve esto generando ejemplos sint\u00e9ticos \"plausibles\" de la clase minoritaria. Toma un ejemplo real, encuentra sus vecinos m\u00e1s cercanos (tambi\u00e9n de la clase minoritaria), y crea nuevos puntos en la l\u00ednea que los conecta. As\u00ed el modelo ve m\u00e1s variedad de la clase minoritaria sin simplemente copiar los mismos ejemplos.</p> <p>Analog\u00eda desarrollada: Imagina que tienes 10 fotos de gatos negros y 1000 de perros. Duplicar la foto del gato 100 veces no ayuda\u2014el modelo memoriza esa \u00fanica foto. SMOTE es como un artista que mira tus 10 fotos de gatos negros y pinta 90 fotos nuevas de gatos negros \"plausibles\" interpolando caracter\u00edsticas: \"este tiene los ojos del gato 1, las orejas del gato 3, el tama\u00f1o del gato 7...\".</p> <p>Ejemplo: <pre><code>from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\n\n# Siempre aplicar DESPU\u00c9S del split (evitar data leakage)\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n\n# SMOTE solo en training\nsmote = SMOTE(random_state=42, k_neighbors=5)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Ahora las clases est\u00e1n balanceadas en training\nprint(f\"Original: {y_train.value_counts().to_dict()}\")\nprint(f\"Resampled: {pd.Series(y_train_resampled).value_counts().to_dict()}\")\n</code></pre></p> <p>Cu\u00e1ndo usar SMOTE vs class_weight: - SMOTE: Cuando quieres m\u00e1s variedad en ejemplos minoritarios - class_weight: M\u00e1s simple, no modifica datos, funciona bien en la mayor\u00eda de casos</p> <p>Relacionados: Class Imbalance, Oversampling, class_weight, imblearn</p>"},{"location":"docs/apoyo/GLOSARIO/#solid","title":"SOLID","text":"<p>Definici\u00f3n t\u00e9cnica: Cinco principios de dise\u00f1o de software orientado a objetos que promueven c\u00f3digo mantenible, extensible y testeable.</p> <p>Los 5 principios:</p> <ol> <li> <p>S - Single Responsibility: Una clase debe tener una sola raz\u00f3n para cambiar    <pre><code># \u274c Mal: Clase hace demasiado\nclass ChurnPredictor:\n    def load_data(self): ...\n    def clean_data(self): ...\n    def train(self): ...\n    def save_to_s3(self): ...\n\n# \u2705 Bien: Responsabilidades separadas\nclass DataLoader: ...\nclass FeatureEngineer: ...\nclass ChurnTrainer: ...\nclass S3Uploader: ...\n</code></pre></p> </li> <li> <p>O - Open/Closed: Abierto para extensi\u00f3n, cerrado para modificaci\u00f3n    <pre><code># Puedes a\u00f1adir nuevos modelos sin modificar c\u00f3digo existente\nclass BaseTrainer(ABC):\n    @abstractmethod\n    def train(self, X, y): ...\n\nclass RandomForestTrainer(BaseTrainer): ...\nclass XGBoostTrainer(BaseTrainer): ...  # Extensi\u00f3n, no modificaci\u00f3n\n</code></pre></p> </li> <li> <p>L - Liskov Substitution: Subclases deben ser substituibles por sus padres</p> </li> <li> <p>I - Interface Segregation: Interfaces peque\u00f1as y espec\u00edficas</p> </li> <li> <p>D - Dependency Inversion: Depender de abstracciones, no de implementaciones</p> </li> </ol> <p>En el portafolio: <code>FeatureEngineer</code>, <code>ChurnTrainer</code> siguen Single Responsibility. El uso de sklearn Pipeline permite Open/Closed (cambiar modelo sin modificar pipeline).</p> <p>Relacionados: Clean Code, Design Patterns, Testing</p>"},{"location":"docs/apoyo/GLOSARIO/#src-layout","title":"src/ Layout","text":"<p>Definici\u00f3n t\u00e9cnica: Estructura de proyecto Python donde el c\u00f3digo fuente reside en un subdirectorio <code>src/</code> en lugar de la ra\u00edz. El paquete se instala con <code>pip install -e .</code> para desarrollo.</p> <p>Explicaci\u00f3n conceptual: La estructura \"flat\" (c\u00f3digo en ra\u00edz) causa problemas: Python puede importar archivos locales en vez del paquete instalado, tests pueden pasar localmente pero fallar en CI, y es dif\u00edcil distinguir c\u00f3digo de proyecto de configuraci\u00f3n. <code>src/</code> layout resuelve esto forzando que el c\u00f3digo solo sea accesible como paquete instalado.</p> <p>Analog\u00eda desarrollada: Imagina una tienda donde los productos est\u00e1n tanto en el almac\u00e9n como en el piso de venta. Confusi\u00f3n garantizada: \u00bfel cliente est\u00e1 comprando del almac\u00e9n o del piso? src/ layout es como tener una puerta clara entre almac\u00e9n (desarrollo) y piso de venta (paquete instalado).</p> <p>Estructura del portafolio: <pre><code>BankChurn-Predictor/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 bankchurn/           # Paquete principal\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 config.py        # Configuraci\u00f3n Pydantic\n\u2502       \u251c\u2500\u2500 pipeline.py      # Pipeline sklearn\n\u2502       \u2514\u2500\u2500 trainer.py       # Clase de entrenamiento\n\u251c\u2500\u2500 tests/                   # Tests (fuera de src/)\n\u251c\u2500\u2500 app/                     # APIs (fuera de src/)\n\u251c\u2500\u2500 configs/                 # Configuraciones YAML\n\u251c\u2500\u2500 artifacts/               # Modelos entrenados\n\u2514\u2500\u2500 pyproject.toml          # Configuraci\u00f3n de paquete\n</code></pre></p> <p>Configuraci\u00f3n en pyproject.toml: <pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"bankchurn\"\nversion = \"0.1.0\"\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n</code></pre></p> <p>Relacionados: pyproject.toml, Package, Import, Project Structure</p>"},{"location":"docs/apoyo/GLOSARIO/#staging","title":"Staging","text":"<p>Definici\u00f3n: Ambiente que replica producci\u00f3n para testing final.</p> <p>Analog\u00eda: Ensayo general antes del estreno.</p>"},{"location":"docs/apoyo/GLOSARIO/#stratified-split","title":"Stratified Split","text":"<p>Definici\u00f3n: Divisi\u00f3n que mantiene proporci\u00f3n de clases en train y test.</p> <pre><code>train_test_split(X, y, stratify=y)\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#streamlit","title":"Streamlit","text":"<p>Definici\u00f3n t\u00e9cnica: Framework Python para crear aplicaciones web interactivas con c\u00f3digo puro Python. Convierte scripts de an\u00e1lisis de datos en dashboards web sin necesidad de conocimientos de HTML, CSS o JavaScript.</p> <p>Explicaci\u00f3n conceptual: Data Scientists crean an\u00e1lisis incre\u00edbles en notebooks, pero compartirlos requiere que el receptor tenga Python instalado y sepa ejecutar notebooks. Streamlit permite convertir ese an\u00e1lisis en una aplicaci\u00f3n web que cualquiera puede usar: a\u00f1ades decoradores como <code>st.title()</code>, <code>st.button()</code>, <code>st.dataframe()</code> y Streamlit genera una UI web autom\u00e1ticamente. Es la forma m\u00e1s r\u00e1pida de pasar de \"script de an\u00e1lisis\" a \"aplicaci\u00f3n interactiva\".</p> <p>Analog\u00eda desarrollada: Imagina que eres un chef que crea recetas incre\u00edbles. Jupyter notebooks es como escribir la receta en un cuaderno t\u00e9cnico\u2014otros chefs pueden seguirla, pero no el p\u00fablico general. Streamlit es como montar un food truck donde la gente puede probar tus platos sin saber cocinar. Tu c\u00f3digo Python sigue siendo la \"cocina\", pero ahora tiene una ventana de servicio bonita.</p> <p>Ejemplo del portafolio (CarVision Dashboard): <pre><code>import streamlit as st\nimport pandas as pd\nimport joblib\n\nst.set_page_config(page_title=\"CarVision Predictor\", page_icon=\"\ud83d\ude97\")\nst.title(\"\ud83d\ude97 CarVision Price Predictor\")\n\n# Sidebar para inputs\nwith st.sidebar:\n    st.header(\"Vehicle Features\")\n    year = st.slider(\"Year\", 2000, 2024, 2018)\n    mileage = st.number_input(\"Mileage\", 0, 300000, 50000)\n    brand = st.selectbox(\"Brand\", [\"Toyota\", \"Honda\", \"Ford\"])\n\n# Cargar modelo (con cache para no recargar)\n@st.cache_resource\ndef load_model():\n    return joblib.load(\"artifacts/model.joblib\")\n\nmodel = load_model()\n\n# Bot\u00f3n de predicci\u00f3n\nif st.button(\"\ud83d\udd2e Predict Price\"):\n    input_df = pd.DataFrame([{\"year\": year, \"mileage\": mileage, \"brand\": brand}])\n    prediction = model.predict(input_df)[0]\n\n    st.success(f\"Estimated Price: ${prediction:,.0f}\")\n\n    # M\u00e9tricas visuales\n    col1, col2 = st.columns(2)\n    col1.metric(\"Predicted Price\", f\"${prediction:,.0f}\")\n    col2.metric(\"Confidence\", \"High\" if prediction &gt; 10000 else \"Medium\")\n</code></pre></p> <p>Componentes clave: - <code>st.title()</code>, <code>st.header()</code>: T\u00edtulos - <code>st.slider()</code>, <code>st.number_input()</code>, <code>st.selectbox()</code>: Inputs - <code>st.button()</code>: Acciones - <code>st.dataframe()</code>, <code>st.plotly_chart()</code>: Visualizaci\u00f3n - <code>@st.cache_resource</code>: Cache de modelos/datos pesados</p> <p>Relacionados: Dashboard, FastAPI, Gradio, Panel</p>"},{"location":"docs/apoyo/GLOSARIO/#t","title":"T","text":""},{"location":"docs/apoyo/GLOSARIO/#target","title":"Target","text":"<p>Definici\u00f3n: Variable que queremos predecir. Tambi\u00e9n llamada \"label\" o \"y\".</p>"},{"location":"docs/apoyo/GLOSARIO/#terraform","title":"Terraform","text":"<p>Definici\u00f3n: Infrastructure as Code. Provisiona recursos en cloud con c\u00f3digo.</p> <pre><code>resource \"aws_instance\" \"ml_server\" {\n  instance_type = \"t3.medium\"\n}\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#test-coverage","title":"Test Coverage","text":"<p>Definici\u00f3n: Porcentaje de c\u00f3digo ejecutado durante tests.</p> <p>Relacionados: Coverage, pytest</p>"},{"location":"docs/apoyo/GLOSARIO/#threshold-umbral","title":"Threshold (Umbral)","text":"<p>Definici\u00f3n: Punto de corte para convertir probabilidades en clases.</p> <p>Default: 0.5, pero ajustable seg\u00fan necesidades de negocio.</p>"},{"location":"docs/apoyo/GLOSARIO/#throughput","title":"Throughput","text":"<p>Definici\u00f3n: Cantidad de predicciones/requests por unidad de tiempo.</p> <p>Analog\u00eda: Cu\u00e1ntos platos puede servir el restaurante por hora.</p>"},{"location":"docs/apoyo/GLOSARIO/#traces","title":"Traces","text":"<p>Definici\u00f3n: Seguimiento de requests a trav\u00e9s de sistema distribuido.</p> <p>Herramientas: Jaeger, OpenTelemetry</p> <p>Relacionados: Observabilidad, Logs, Metrics</p>"},{"location":"docs/apoyo/GLOSARIO/#transformermixin","title":"TransformerMixin","text":"<p>Definici\u00f3n: Mixin sklearn que a\u00f1ade <code>fit_transform()</code> autom\u00e1ticamente.</p> <p>Relacionados: BaseEstimator, Custom Transformer</p>"},{"location":"docs/apoyo/GLOSARIO/#trivy","title":"Trivy","text":"<p>Definici\u00f3n: Esc\u00e1ner de vulnerabilidades para contenedores.</p> <pre><code>trivy image my-app:latest\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#type-hints","title":"Type Hints","text":"<p>Definici\u00f3n: Anotaciones en Python que indican tipos esperados.</p> <pre><code>def predict(data: pd.DataFrame) -&gt; np.ndarray:\n    pass\n</code></pre> <p>Relacionados: mypy, Pydantic</p>"},{"location":"docs/apoyo/GLOSARIO/#u","title":"U","text":""},{"location":"docs/apoyo/GLOSARIO/#underfitting-subajuste","title":"Underfitting (Subajuste)","text":"<p>Definici\u00f3n: Modelo demasiado simple. No captura patrones.</p> <p>Se\u00f1ales: Train y validation accuracy bajas.</p>"},{"location":"docs/apoyo/GLOSARIO/#unit-test","title":"Unit Test","text":"<p>Definici\u00f3n: Test de funci\u00f3n/m\u00e9todo individual en aislamiento.</p> <pre><code>def test_feature_ratio():\n    result = compute_ratio(100, 2)\n    assert result == 50\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#uvicorn","title":"Uvicorn","text":"<p>Definici\u00f3n: Servidor ASGI de alto rendimiento para FastAPI.</p> <pre><code>uvicorn app:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#v","title":"V","text":""},{"location":"docs/apoyo/GLOSARIO/#validation-set","title":"Validation Set","text":"<p>Definici\u00f3n: Datos para ajustar hiperpar\u00e1metros, separado de train y test.</p> <p>Split t\u00edpico: 60% train, 20% validation, 20% test</p>"},{"location":"docs/apoyo/GLOSARIO/#vendor-lock-in","title":"Vendor Lock-in","text":"<p>Definici\u00f3n: Dependencia de proveedor espec\u00edfico que dificulta migraci\u00f3n.</p> <p>Analog\u00eda: Comprar auto donde repuestos solo existen en una tienda.</p>"},{"location":"docs/apoyo/GLOSARIO/#version-control","title":"Version Control","text":"<p>Definici\u00f3n: Sistema para rastrear cambios en archivos.</p> <p>Herramientas: Git (c\u00f3digo), DVC (datos), MLflow (modelos)</p>"},{"location":"docs/apoyo/GLOSARIO/#voting-classifier","title":"Voting Classifier","text":"<p>Definici\u00f3n: Ensemble que combina predicciones por votaci\u00f3n.</p> <pre><code>VotingClassifier([\n    ('rf', RandomForestClassifier()),\n    ('xgb', XGBClassifier())\n], voting='soft')\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#w","title":"W","text":""},{"location":"docs/apoyo/GLOSARIO/#weights-biases-wb","title":"Weights &amp; Biases (W&amp;B)","text":"<p>Definici\u00f3n: Plataforma SaaS para experiment tracking con visualizaciones avanzadas.</p> <p>Relacionados: MLflow, Experiment Tracking</p>"},{"location":"docs/apoyo/GLOSARIO/#workflow-github-actions","title":"Workflow (GitHub Actions)","text":"<p>Definici\u00f3n: Proceso automatizado definido en archivo YAML.</p> <p>Relacionados: Job, Step, CI/CD</p>"},{"location":"docs/apoyo/GLOSARIO/#x","title":"X","text":""},{"location":"docs/apoyo/GLOSARIO/#xgboost","title":"XGBoost","text":"<p>Definici\u00f3n: Implementaci\u00f3n optimizada de gradient boosting. Muy popular en competencias.</p> <pre><code>from xgboost import XGBClassifier\nmodel = XGBClassifier(n_estimators=100, learning_rate=0.1)\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#y","title":"Y","text":""},{"location":"docs/apoyo/GLOSARIO/#yaml","title":"YAML","text":"<p>Definici\u00f3n: Formato de serializaci\u00f3n legible para configuraci\u00f3n.</p> <pre><code>model:\n  type: ensemble\n  n_estimators: 100\n</code></pre>"},{"location":"docs/apoyo/GLOSARIO/#z","title":"Z","text":""},{"location":"docs/apoyo/GLOSARIO/#zero-downtime-deployment","title":"Zero-Downtime Deployment","text":"<p>Definici\u00f3n: Actualizar aplicaci\u00f3n sin interrumpir servicio.</p> <p>T\u00e9cnicas: Rolling update, Blue-green deployment</p>"},{"location":"docs/apoyo/GLOSARIO/#simbolos-y-abreviaciones","title":"S\u00edmbolos y Abreviaciones","text":"S\u00edmbolo Significado TP True Positive TN True Negative FP False Positive FN False Negative P95 Percentil 95 GHCR GitHub Container Registry IaC Infrastructure as Code DAG Directed Acyclic Graph OOM Out of Memory CRUD Create, Read, Update, Delete SLA Service Level Agreement SLO Service Level Objective TTL Time To Live"},{"location":"docs/apoyo/GLOSARIO/#tablas-de-referencia-rapida","title":"\ud83d\udcca Tablas de Referencia R\u00e1pida","text":""},{"location":"docs/apoyo/GLOSARIO/#metricas-de-clasificacion","title":"M\u00e9tricas de Clasificaci\u00f3n","text":"M\u00e9trica F\u00f3rmula Uso Accuracy (TP+TN)/(Total) Balance general (clases balanceadas) Precision TP/(TP+FP) Minimizar falsos positivos Recall TP/(TP+FN) Minimizar falsos negativos F1 2\u00d7P\u00d7R/(P+R) Balance P y R AUC-ROC \u00c1rea bajo curva Capacidad discriminatoria"},{"location":"docs/apoyo/GLOSARIO/#tipos-de-testing","title":"Tipos de Testing","text":"Tipo Alcance Ejemplo Unit Funci\u00f3n individual <code>test_compute_ratio()</code> Integration M\u00faltiples componentes <code>test_pipeline_fit()</code> E2E Sistema completo <code>test_api_predict_flow()</code>"},{"location":"docs/apoyo/GLOSARIO/#ambientes","title":"Ambientes","text":"Ambiente Prop\u00f3sito Datos Development Desarrollo Sint\u00e9ticos/muestra Staging Testing final R\u00e9plica producci\u00f3n Production Usuarios reales Reales"},{"location":"docs/apoyo/GLOSARIO/#errores-habituales","title":"\ud83e\uddef  Errores habituales","text":"<ul> <li>Confundir t\u00e9rminos cercanos (por ejemplo: latency vs throughput, drift vs data leakage) y \u201cseguir\u201d sin aclararlo.</li> <li>No aterrizar el t\u00e9rmino a un ejemplo del repo (config, pipeline, CI, serving, observabilidad).</li> <li>Memorizar definiciones sin poder dar un ejemplo y un anti-ejemplo.</li> <li>Si un t\u00e9rmino te tom\u00f3 &gt;15 min, reg\u00edstralo en el Diario de Errores y aplica el flujo de rescate de Protocolo E.</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#ejercicio","title":"\u2705  Ejercicio","text":"<ul> <li>Elige 12 t\u00e9rminos (4 de datos, 4 de entrenamiento, 4 de serving/infra).</li> <li>Para cada uno:</li> <li>Escribe una definici\u00f3n de 1\u20132 frases.</li> <li>A\u00f1ade un ejemplo del repo (ruta/archivo o comando).</li> <li>A\u00f1ade un \u201cc\u00f3mo se rompe\u201d (error t\u00edpico) y c\u00f3mo lo detectar\u00edas.</li> </ul>"},{"location":"docs/apoyo/GLOSARIO/#checkpoint","title":"\ud83c\udfa4  Checkpoint","text":"<ul> <li>[ ] Puedo explicar (sin leer) 10 t\u00e9rminos cr\u00edticos del glosario en 2\u20133 frases.</li> <li>[ ] Para 5 t\u00e9rminos, puedo apuntar a \u201cd\u00f3nde vive\u201d en el repo (archivo/carpeta concreta).</li> <li>[ ] Tengo al menos 3 entradas nuevas en el Diario de Errores asociadas a t\u00e9rminos que me frenaron.</li> <li>[ ] Puedo distinguir con un ejemplo: data leakage vs drift vs overfitting.</li> </ul>   ### Navegaci\u00f3n  | \u25c0\ufe0f Anterior | \ud83d\udcd1 \u00cdndice | \u25b6\ufe0f Siguiente | |:-----------|:---------:|:------------| | [20_OBSERVABILIDAD_AVANZADA_DRIFT.md](../20_OBSERVABILIDAD_AVANZADA_DRIFT.md) | [\u00cdndice](../00_INDICE.md) | [22_IAC_EMPRESARIAL.md](../22_IAC_EMPRESARIAL.md) |  ---  *\u00a9 2025 DuqueOM - Gu\u00eda MLOps v5.0: Senior Edition*  **M\u00f3dulo 21 Completado** \u2705"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/","title":"\ud83c\udfac Gu\u00eda de Material Audiovisual \u2014 ML-MLOps Portfolio","text":"<p>Gu\u00eda completa para crear demos profesionales de tu portafolio</p> <p>\u00daltima actualizaci\u00f3n: Diciembre 2025 Versi\u00f3n: 5.1 \u2014 Portfolio Edition Repositorio: github.com/DuqueOM/ML-MLOps-Portfolio</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ol> <li>Estado Actual del Portafolio</li> <li>Servicios del Stack Demo</li> <li>Material Audiovisual Requerido</li> <li>Herramientas Recomendadas</li> <li>Gu\u00eda de GIFs Demostrativos</li> <li>Gu\u00eda de Screenshots</li> <li>Gu\u00eda de Video Principal</li> <li>Comandos y Scripts \u00datiles</li> <li>Checklist Final</li> </ol>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#estado-actual-del-portafolio","title":"\ud83c\udfaf Estado Actual del Portafolio","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#proyectos-del-portafolio","title":"Proyectos del Portafolio","text":"Proyecto Descripci\u00f3n Tecnolog\u00edas Clave BankChurn-Predictor Predicci\u00f3n de abandono bancario sklearn Pipeline, ResampleClassifier, MLflow CarVision-Market-Intelligence Predicci\u00f3n de precios de veh\u00edculos FeatureEngineer transformer, Streamlit dashboard TelecomAI-Customer-Intelligence Clasificaci\u00f3n de planes m\u00f3viles Pipeline ML unificado"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#metricas-actuales","title":"M\u00e9tricas Actuales","text":"Proyecto Coverage M\u00e9trica Principal CI Status BankChurn 79% 86% AUC \u2705 Passing CarVision 80% 0.87 R\u00b2 \u2705 Passing TelecomAI 80% 82% Accuracy \u2705 Passing"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#servicios-del-stack-demo","title":"\ud83d\udda5 Servicios del Stack Demo","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#comando-para-levantar","title":"Comando para Levantar","text":"<pre><code>docker-compose -f docker-compose.demo.yml up -d\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#5-servicios-principales","title":"5 Servicios Principales","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SERVICIOS DEL STACK DEMO                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd39 MLFLOW TRACKING SERVER                                              \u2502\n\u2502     URL: http://localhost:5000                                          \u2502\n\u2502     Funci\u00f3n: Tracking de experimentos, Model Registry                   \u2502\n\u2502     Mostrar: Lista de experimentos, m\u00e9tricas, modelos registrados       \u2502\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd39 BANKCHURN API (FastAPI)                                             \u2502\n\u2502     URL: http://localhost:8001/docs                                     \u2502\n\u2502     Funci\u00f3n: Predicci\u00f3n de abandono de clientes                         \u2502\n\u2502     Mostrar: Swagger UI, endpoint /predict, respuesta JSON              \u2502\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd39 CARVISION API (FastAPI)                                             \u2502\n\u2502     URL: http://localhost:8002/docs                                     \u2502\n\u2502     Funci\u00f3n: Predicci\u00f3n de precios de veh\u00edculos                         \u2502\n\u2502     Mostrar: Swagger UI, endpoint /predict                              \u2502\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd39 CARVISION STREAMLIT DASHBOARD                                       \u2502\n\u2502     URL: http://localhost:8501                                          \u2502\n\u2502     Funci\u00f3n: Dashboard interactivo para an\u00e1lisis y predicci\u00f3n           \u2502\n\u2502     Mostrar: Gr\u00e1ficos, formulario de predicci\u00f3n, resultados             \u2502\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd39 TELECOMAI API (FastAPI)                                             \u2502\n\u2502     URL: http://localhost:8003/docs                                     \u2502\n\u2502     Funci\u00f3n: Clasificaci\u00f3n de planes m\u00f3viles                            \u2502\n\u2502     Mostrar: Swagger UI, endpoint /predict                              \u2502\n\u2502                                                                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  SERVICIOS OPCIONALES (con --profile monitoring)                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  \ud83d\udd38 PROMETHEUS: http://localhost:9090                                   \u2502\n\u2502  \ud83d\udd38 GRAFANA:    http://localhost:3000 (admin/admin)                     \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#resumen-de-urls","title":"Resumen de URLs","text":"Servicio Puerto URL Completa Tipo MLflow UI 5000 http://localhost:5000 Dashboard BankChurn API 8001 http://localhost:8001/docs Swagger CarVision API 8002 http://localhost:8002/docs Swagger CarVision Dashboard 8501 http://localhost:8501 Streamlit TelecomAI API 8003 http://localhost:8003/docs Swagger Prometheus 9090 http://localhost:9090 Monitoring Grafana 3000 http://localhost:3000 Dashboards"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#material-audiovisual-requerido","title":"\ud83d\udcca Material Audiovisual Requerido","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#resumen-de-elementos","title":"Resumen de Elementos","text":"Categor\u00eda Cantidad Prioridad Descripci\u00f3n GIFs Demostrativos 5 \ud83d\udd34 Alta Portfolio, 3 APIs, Streamlit Screenshots 8 \ud83d\udfe1 Media UIs, dashboards, CI Video Demo Principal 1 \ud83d\udd34 Alta 3-5 min completo Thumbnails 4 \ud83d\udfe2 Baja Para YouTube/docs"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#mapa-de-archivos-referencias","title":"Mapa de Archivos \u2192 Referencias","text":"Archivo Ubicaci\u00f3n Se usa en <code>portfolio-demo.gif</code> <code>media/gifs/</code> README.md principal <code>bankchurn-preview.gif</code> <code>media/gifs/</code> README.md, BankChurn/README.md <code>carvision-preview.gif</code> <code>media/gifs/</code> README.md, CarVision/README.md <code>streamlit-carvision.gif</code> <code>media/gifs/</code> CarVision/README.md <code>telecom-preview.gif</code> <code>media/gifs/</code> README.md, TelecomAI/README.md <code>mlflow-experiments.png</code> <code>media/screenshots/</code> docs/, READMEs <code>mlflow-model-registry.png</code> <code>media/screenshots/</code> docs/ <code>swagger-bankchurn.png</code> <code>media/screenshots/</code> BankChurn/README.md <code>swagger-carvision.png</code> <code>media/screenshots/</code> CarVision/README.md <code>swagger-telecom.png</code> <code>media/screenshots/</code> TelecomAI/README.md <code>streamlit-dashboard.png</code> <code>media/screenshots/</code> CarVision/README.md <code>github-actions-ci.png</code> <code>media/screenshots/</code> README.md principal"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#herramientas-recomendadas","title":"\ud83d\udee0 Herramientas Recomendadas","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#para-windows","title":"Para Windows","text":"Herramienta Uso Instalaci\u00f3n OBS Studio Grabar pantalla <code>winget install OBSProject.OBSStudio</code> Greenshot Screenshots <code>winget install Greenshot.Greenshot</code> ffmpeg Convertir video\u2192GIF <code>winget install ffmpeg</code> ShareX GIFs directos <code>winget install ShareX.ShareX</code>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#para-linux","title":"Para Linux","text":"Herramienta Uso Instalaci\u00f3n OBS Studio Grabar pantalla <code>sudo apt install obs-studio</code> Flameshot Screenshots <code>sudo apt install flameshot</code> ffmpeg Convertir video\u2192GIF <code>sudo apt install ffmpeg</code> Peek GIFs directos <code>sudo apt install peek</code>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#para-macos","title":"Para macOS","text":"Herramienta Uso Instalaci\u00f3n OBS Studio Grabar pantalla <code>brew install obs</code> Screenshot nativo Screenshots Cmd+Shift+4 ffmpeg Convertir video\u2192GIF <code>brew install ffmpeg</code> Gifski GIFs de alta calidad <code>brew install gifski</code>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guia-de-gifs-demostrativos","title":"\ud83c\udf9e Gu\u00eda de GIFs Demostrativos","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-1-portfolio-demo-principal-todos-los-servicios","title":"GIF 1: Portfolio Demo Principal (TODOS los servicios)","text":"<p>Archivo: <code>media/gifs/portfolio-demo.gif</code> Duraci\u00f3n: 20-25 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion-detallado","title":"Guion Detallado","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              PORTFOLIO DEMO PRINCIPAL (20-25 segundos)                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:03  ESCENA 1: Levantar servicios                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Terminal con comando:                                                \u2502\n\u2502    docker-compose -f docker-compose.demo.yml up -d                      \u2502\n\u2502  \u2022 Mostrar output: \"Creating mlflow-server...\",                         \u2502\n\u2502    \"Creating bankchurn-api...\", \"Creating carvision-api...\",            \u2502\n\u2502    \"Creating carvision-dashboard...\", \"Creating telecom-api...\"         \u2502\n\u2502                                                                         \u2502\n\u2502  0:03-0:08  ESCENA 2: Los 5 servicios funcionando                       \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Abrir 5 pesta\u00f1as del navegador (split screen o en secuencia):        \u2502\n\u2502    1. http://localhost:5000 (MLflow)                                    \u2502\n\u2502    2. http://localhost:8001/docs (BankChurn Swagger)                    \u2502\n\u2502    3. http://localhost:8002/docs (CarVision Swagger)                    \u2502\n\u2502    4. http://localhost:8501 (CarVision Streamlit) \u2190 IMPORTANTE          \u2502\n\u2502    5. http://localhost:8003/docs (TelecomAI Swagger)                    \u2502\n\u2502  \u2022 Pausar 2 segundos en cada una                                        \u2502\n\u2502                                                                         \u2502\n\u2502  0:08-0:13  ESCENA 3: Demo Streamlit Dashboard                          \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Enfocar en localhost:8501                                            \u2502\n\u2502  \u2022 Mostrar gr\u00e1ficos de an\u00e1lisis de datos                                \u2502\n\u2502  \u2022 Llenar formulario de predicci\u00f3n r\u00e1pido                               \u2502\n\u2502  \u2022 Mostrar resultado de precio estimado                                 \u2502\n\u2502                                                                         \u2502\n\u2502  0:13-0:18  ESCENA 4: Predicci\u00f3n en API                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Cambiar a BankChurn Swagger (localhost:8001/docs)                    \u2502\n\u2502  \u2022 Click en POST /predict \u2192 \"Try it out\"                                \u2502\n\u2502  \u2022 Ejecutar y mostrar respuesta JSON                                    \u2502\n\u2502                                                                         \u2502\n\u2502  0:18-0:22  ESCENA 5: MLflow Experiments                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Cambiar a MLflow (localhost:5000)                                    \u2502\n\u2502  \u2022 Mostrar lista de experimentos                                        \u2502\n\u2502  \u2022 Click en un experimento para ver m\u00e9tricas                            \u2502\n\u2502                                                                         \u2502\n\u2502  0:22-0:25  ESCENA 6: Cierre                                            \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Volver a vista general con las 5 pesta\u00f1as                            \u2502\n\u2502  \u2022 O mostrar terminal con \"docker-compose ps\" (5 running)               \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#preparacion-completa","title":"Preparaci\u00f3n Completa","text":"<pre><code># 1. Levantar todos los servicios\ncd /path/to/ML-MLOps-Portfolio\ndocker-compose -f docker-compose.demo.yml up -d\n\n# 2. Esperar a que est\u00e9n listos (importante!)\necho \"Esperando 45 segundos para que todos los servicios inicien...\"\nsleep 45\n\n# 3. Verificar TODOS los servicios\necho \"=== Verificando 5 servicios ===\"\necho \"MLflow:\" &amp;&amp; curl -s http://localhost:5000/health 2&gt;/dev/null || echo \"OK\"\necho \"BankChurn:\" &amp;&amp; curl -s http://localhost:8001/health\necho \"CarVision API:\" &amp;&amp; curl -s http://localhost:8002/health\necho \"CarVision Streamlit:\" &amp;&amp; curl -s http://localhost:8501 &gt;/dev/null &amp;&amp; echo '{\"status\":\"healthy\"}'\necho \"TelecomAI:\" &amp;&amp; curl -s http://localhost:8003/health\n\n# 4. Ver estado de contenedores\ndocker-compose -f docker-compose.demo.yml ps\n\n# 5. Abrir TODAS las pesta\u00f1as\n# Linux:\nxdg-open http://localhost:5000      # MLflow\nxdg-open http://localhost:8001/docs # BankChurn\nxdg-open http://localhost:8002/docs # CarVision API\nxdg-open http://localhost:8501      # CarVision Streamlit \u2190 NO OLVIDAR\nxdg-open http://localhost:8003/docs # TelecomAI\n\n# Windows (PowerShell):\n# Start-Process http://localhost:5000\n# Start-Process http://localhost:8001/docs\n# Start-Process http://localhost:8002/docs\n# Start-Process http://localhost:8501\n# Start-Process http://localhost:8003/docs\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-2-bankchurn-api-demo","title":"GIF 2: BankChurn API Demo","text":"<p>Archivo: <code>media/gifs/bankchurn-preview.gif</code> Duraci\u00f3n: 8-10 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion","title":"Guion","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    BANKCHURN DEMO (8-10 segundos)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:02  Swagger UI de BankChurn                                     \u2502\n\u2502  \u2022 Mostrar http://localhost:8001/docs                                   \u2502\n\u2502  \u2022 T\u00edtulo visible: \"BankChurn Predictor API\"                            \u2502\n\u2502                                                                         \u2502\n\u2502  0:02-0:05  Expandir /predict                                           \u2502\n\u2502  \u2022 Click en POST /predict                                               \u2502\n\u2502  \u2022 Click \"Try it out\"                                                   \u2502\n\u2502  \u2022 Llenar con datos de ejemplo (ver abajo)                              \u2502\n\u2502                                                                         \u2502\n\u2502  0:05-0:08  Ejecutar y ver resultado                                    \u2502\n\u2502  \u2022 Click \"Execute\"                                                      \u2502\n\u2502  \u2022 Scroll para ver respuesta:                                           \u2502\n\u2502    {                                                                    \u2502\n\u2502      \"prediction\": 0,                                                   \u2502\n\u2502      \"probability\": 0.23,                                               \u2502\n\u2502      \"label\": \"No Churn\"                                                \u2502\n\u2502    }                                                                    \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#datos-de-ejemplo-para-bankchurn","title":"Datos de Ejemplo para BankChurn","text":"<pre><code>{\n  \"credit_score\": 650,\n  \"age\": 45,\n  \"tenure\": 5,\n  \"balance\": 50000,\n  \"num_of_products\": 2,\n  \"has_cr_card\": 1,\n  \"is_active_member\": 1,\n  \"estimated_salary\": 75000,\n  \"geography\": \"France\",\n  \"gender\": \"Male\"\n}\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-3-carvision-api-demo","title":"GIF 3: CarVision API Demo","text":"<p>Archivo: <code>media/gifs/carvision-preview.gif</code> Duraci\u00f3n: 8-10 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion_1","title":"Guion","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CARVISION API DEMO (8-10 segundos)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:02  Swagger UI de CarVision                                     \u2502\n\u2502  \u2022 Mostrar http://localhost:8002/docs                                   \u2502\n\u2502  \u2022 T\u00edtulo: \"CarVision Market Intelligence API\"                          \u2502\n\u2502                                                                         \u2502\n\u2502  0:02-0:05  Expandir /predict                                           \u2502\n\u2502  \u2022 Click en POST /predict                                               \u2502\n\u2502  \u2022 \"Try it out\"                                                         \u2502\n\u2502  \u2022 Llenar datos de veh\u00edculo                                             \u2502\n\u2502                                                                         \u2502\n\u2502  0:05-0:08  Resultado                                                   \u2502\n\u2502  \u2022 Ejecutar predicci\u00f3n                                                  \u2502\n\u2502  \u2022 Mostrar precio estimado: {\"predicted_price\": 25430.50}               \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#datos-de-ejemplo-para-carvision","title":"Datos de Ejemplo para CarVision","text":"<pre><code>{\n  \"model_year\": 2020,\n  \"model\": \"toyota camry\",\n  \"condition\": \"good\",\n  \"odometer\": 35000,\n  \"fuel\": \"gas\",\n  \"transmission\": \"automatic\",\n  \"type\": \"sedan\",\n  \"paint_color\": \"white\"\n}\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-4-carvision-streamlit-dashboard-nuevo-importante","title":"GIF 4: CarVision Streamlit Dashboard (NUEVO - IMPORTANTE)","text":"<p>Archivo: <code>media/gifs/streamlit-carvision.gif</code> Duraci\u00f3n: 12-15 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion-detallado_1","title":"Guion Detallado","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CARVISION STREAMLIT DEMO (12-15 segundos)                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:03  Dashboard Principal                                         \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar http://localhost:8501                                        \u2502\n\u2502  \u2022 Vista inicial del dashboard con t\u00edtulo                               \u2502\n\u2502  \u2022 Sidebar visible con opciones                                         \u2502\n\u2502                                                                         \u2502\n\u2502  0:03-0:06  Secci\u00f3n de An\u00e1lisis de Datos                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar gr\u00e1ficos de distribuci\u00f3n de precios                          \u2502\n\u2502  \u2022 Gr\u00e1fico de precios por marca/a\u00f1o                                     \u2502\n\u2502  \u2022 Estad\u00edsticas descriptivas                                            \u2502\n\u2502                                                                         \u2502\n\u2502  0:06-0:10  Formulario de Predicci\u00f3n                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Navegar a secci\u00f3n de predicci\u00f3n                                      \u2502\n\u2502  \u2022 Seleccionar marca: Toyota                                            \u2502\n\u2502  \u2022 Seleccionar modelo: Camry                                            \u2502\n\u2502  \u2022 A\u00f1o: 2020                                                            \u2502\n\u2502  \u2022 Kilometraje: 35,000                                                  \u2502\n\u2502  \u2022 Condici\u00f3n: Good                                                      \u2502\n\u2502                                                                         \u2502\n\u2502  0:10-0:13  Resultado de Predicci\u00f3n                                     \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Click en bot\u00f3n \"Predecir Precio\"                                     \u2502\n\u2502  \u2022 Mostrar resultado: \"$25,430\" (grande, visible)                       \u2502\n\u2502  \u2022 Mostrar intervalo de confianza si existe                             \u2502\n\u2502                                                                         \u2502\n\u2502  0:13-0:15  Vista Final                                                 \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Scroll up para mostrar todo el dashboard                             \u2502\n\u2502  \u2022 O cambiar a otra secci\u00f3n brevemente                                  \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-5-telecomai-api-demo","title":"GIF 5: TelecomAI API Demo","text":"<p>Archivo: <code>media/gifs/telecom-preview.gif</code> Duraci\u00f3n: 8 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion_2","title":"Guion","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    TELECOMAI DEMO (8 segundos)                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:02  Swagger UI de TelecomAI                                     \u2502\n\u2502  \u2022 Mostrar http://localhost:8003/docs                                   \u2502\n\u2502  \u2022 T\u00edtulo: \"TelecomAI Customer Intelligence API\"                        \u2502\n\u2502                                                                         \u2502\n\u2502  0:02-0:05  Expandir /predict                                           \u2502\n\u2502  \u2022 Llenar datos de uso del cliente                                      \u2502\n\u2502                                                                         \u2502\n\u2502  0:05-0:08  Resultado                                                   \u2502\n\u2502  \u2022 Ejecutar predicci\u00f3n                                                  \u2502\n\u2502  \u2022 Mostrar plan recomendado                                             \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#gif-6-mlflow-dashboard-nuevo-recomendado","title":"GIF 6: MLflow Dashboard (NUEVO - Recomendado)","text":"<p>Archivo: <code>media/gifs/mlflow-demo.gif</code> Duraci\u00f3n: 10-12 segundos Resoluci\u00f3n: 800x600</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guion_3","title":"Guion","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    MLFLOW DEMO (10-12 segundos)                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:03  MLflow UI Principal                                         \u2502\n\u2502  \u2022 Mostrar http://localhost:5000                                        \u2502\n\u2502  \u2022 Lista de experimentos visible                                        \u2502\n\u2502                                                                         \u2502\n\u2502  0:03-0:06  Seleccionar Experimento                                     \u2502\n\u2502  \u2022 Click en experimento \"bankchurn\" o \"carvision\"                       \u2502\n\u2502  \u2022 Mostrar lista de runs                                                \u2502\n\u2502                                                                         \u2502\n\u2502  0:06-0:09  Ver M\u00e9tricas                                                \u2502\n\u2502  \u2022 Click en un run espec\u00edfico                                           \u2502\n\u2502  \u2022 Mostrar m\u00e9tricas: AUC, F1, Accuracy                                  \u2502\n\u2502  \u2022 Mostrar par\u00e1metros logueados                                         \u2502\n\u2502                                                                         \u2502\n\u2502  0:09-0:12  Model Artifacts                                             \u2502\n\u2502  \u2022 Mostrar secci\u00f3n de artifacts                                         \u2502\n\u2502  \u2022 Modelo guardado visible                                              \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guia-de-screenshots","title":"\ud83d\udcf8 Gu\u00eda de Screenshots","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#screenshots-requeridos-8-total","title":"Screenshots Requeridos (8 total)","text":"# Nombre Qu\u00e9 capturar URL 1 <code>mlflow-experiments.png</code> Lista de experimentos en MLflow localhost:5000 2 <code>mlflow-metrics.png</code> Gr\u00e1ficos de m\u00e9tricas de un run localhost:5000 3 <code>swagger-bankchurn.png</code> Swagger UI de BankChurn localhost:8001/docs 4 <code>swagger-carvision.png</code> Swagger UI de CarVision localhost:8002/docs 5 <code>swagger-telecom.png</code> Swagger UI de TelecomAI localhost:8003/docs 6 <code>streamlit-dashboard.png</code> Dashboard Streamlit completo localhost:8501 7 <code>streamlit-prediction.png</code> Resultado de predicci\u00f3n en Streamlit localhost:8501 8 <code>github-actions-ci.png</code> CI pipeline pasando GitHub"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#como-tomar-buenos-screenshots","title":"C\u00f3mo Tomar Buenos Screenshots","text":"<ol> <li>Usa zoom al 100% en el navegador</li> <li>Limpia la URL bar (quita extensiones visibles)</li> <li>Usa modo claro para mejor legibilidad en docs</li> <li>Resoluci\u00f3n m\u00ednima: 1200x800</li> <li>Comprime despu\u00e9s con <code>pngquant</code></li> </ol> <pre><code># Comprimir todos los screenshots\nfor f in media/screenshots/*.png; do\n  pngquant --quality=65-80 \"$f\" --output \"${f%.png}-opt.png\"\ndone\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#guia-de-video-principal","title":"\ud83c\udfa5 Gu\u00eda de Video Principal","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#especificaciones","title":"Especificaciones","text":"Campo Valor Duraci\u00f3n 4-6 minutos Resoluci\u00f3n 1080p (1920x1080) Formato MP4 Audio Narraci\u00f3n clara Plataforma YouTube (unlisted) o Google Drive"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#estructura-del-video-actualizada","title":"Estructura del Video (Actualizada)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  VIDEO DEMO PRINCIPAL (4-6 min)                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                         \u2502\n\u2502  0:00-0:30  INTRODUCCI\u00d3N                                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 \"Hola, soy [nombre] y este es mi portafolio MLOps\"                   \u2502\n\u2502  \u2022 Mostrar GitHub repo                                                  \u2502\n\u2502  \u2022 \"3 proyectos ML end-to-end con CI/CD y 5 servicios dockerizados\"     \u2502\n\u2502                                                                         \u2502\n\u2502  0:30-1:00  LEVANTAR EL STACK                                           \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar terminal: docker-compose up                                  \u2502\n\u2502  \u2022 Explicar: \"Con un solo comando levanto 5 servicios\"                  \u2502\n\u2502  \u2022 Mostrar docker ps con los 5 contenedores                             \u2502\n\u2502                                                                         \u2502\n\u2502  1:00-2:00  TOUR POR LOS 5 SERVICIOS                                    \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 MLflow (5000): \"Aqu\u00ed trackeo todos los experimentos\"                 \u2502\n\u2502  \u2022 BankChurn API (8001): \"API de predicci\u00f3n de churn\"                   \u2502\n\u2502  \u2022 CarVision API (8002): \"API de precios de veh\u00edculos\"                  \u2502\n\u2502  \u2022 Streamlit (8501): \"Dashboard interactivo para CarVision\"             \u2502\n\u2502  \u2022 TelecomAI API (8003): \"Clasificaci\u00f3n de planes m\u00f3viles\"              \u2502\n\u2502                                                                         \u2502\n\u2502  2:00-3:00  DEMO BANKCHURN                                              \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar c\u00f3digo del pipeline sklearn                                  \u2502\n\u2502  \u2022 Ejecutar predicci\u00f3n en Swagger UI                                    \u2502\n\u2502  \u2022 Mostrar m\u00e9tricas en MLflow                                           \u2502\n\u2502                                                                         \u2502\n\u2502  3:00-4:00  DEMO CARVISION + STREAMLIT                                  \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar FeatureEngineer custom transformer                           \u2502\n\u2502  \u2022 Demo en Streamlit Dashboard (gr\u00e1ficos + predicci\u00f3n)                  \u2502\n\u2502  \u2022 Mostrar API tambi\u00e9n funcionando                                      \u2502\n\u2502                                                                         \u2502\n\u2502  4:00-4:30  CI/CD Y TESTING                                             \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar GitHub Actions                                               \u2502\n\u2502  \u2022 Tests con 80%+ coverage                                              \u2502\n\u2502  \u2022 Badge de CI passing                                                  \u2502\n\u2502                                                                         \u2502\n\u2502  4:30-5:00  ARQUITECTURA                                                \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Mostrar diagrama de arquitectura                                     \u2502\n\u2502  \u2022 Stack: sklearn, MLflow, FastAPI, Streamlit, Docker                   \u2502\n\u2502  \u2022 Configuraci\u00f3n con Pydantic                                           \u2502\n\u2502                                                                         \u2502\n\u2502  5:00-5:30  CIERRE                                                      \u2502\n\u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n\u2502  \u2022 Resumen: \"3 proyectos, 5 servicios, 80%+ coverage\"                   \u2502\n\u2502  \u2022 \"Todo el c\u00f3digo est\u00e1 en GitHub\"                                      \u2502\n\u2502  \u2022 Mostrar URL del repositorio                                          \u2502\n\u2502                                                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#script-de-narracion","title":"Script de Narraci\u00f3n","text":"<p>INTRO: \"Hola, soy [nombre]. Este es mi portafolio de Machine Learning y MLOps. Incluye tres proyectos completos que se ejecutan como cinco servicios dockerizados: tres APIs con FastAPI, un dashboard con Streamlit, y tracking centralizado con MLflow.\"</p> <p>STACK: \"Con docker-compose levanto todo el stack. Mira, aqu\u00ed puedes ver los cinco contenedores corriendo: el servidor de MLflow, las tres APIs de predicci\u00f3n, y el dashboard de Streamlit para CarVision.\"</p> <p>TOUR: \"D\u00e9jame mostrarte cada servicio. En el puerto 5000 tenemos MLflow donde trackeo todos los experimentos. En 8001 est\u00e1 BankChurn para predicci\u00f3n de abandono de clientes. En 8002 CarVision para precios de veh\u00edculos. En 8501, que es muy importante, tenemos el dashboard de Streamlit con visualizaciones interactivas. Y en 8003 TelecomAI para clasificaci\u00f3n de planes.\"</p> <p>BANKCHURN: \"Veamos BankChurn. El modelo usa un pipeline unificado de sklearn con ColumnTransformer para preprocesamiento. Aqu\u00ed hago una predicci\u00f3n en la API... y mira, el cliente tiene 23% de probabilidad de abandonar.\"</p> <p>CARVISION: \"CarVision tiene algo especial: un custom transformer llamado FeatureEngineer que calcula features como la edad del veh\u00edculo. Pero lo mejor es el dashboard de Streamlit... aqu\u00ed puedo ver an\u00e1lisis de datos y hacer predicciones de forma interactiva. Mira, este Toyota Camry 2020 tiene un precio estimado de $25,000.\"</p> <p>CIERRE: \"Todo pasa por CI con GitHub Actions y tiene m\u00e1s de 80% de coverage. El c\u00f3digo completo est\u00e1 en GitHub. Gracias por ver.\"</p>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#comandos-y-scripts-utiles","title":"\ud83d\udcbb Comandos y Scripts \u00datiles","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#levantar-el-stack-completo","title":"Levantar el Stack Completo","text":"<pre><code># Clonar repositorio\ngit clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git\ncd ML-MLOps-Portfolio\n\n# Levantar los 5 servicios principales\ndocker-compose -f docker-compose.demo.yml up -d\n\n# Esperar a que est\u00e9n listos\nsleep 45\n\n# Verificar TODOS los servicios (5)\necho \"=== Estado de los 5 servicios ===\"\necho \"1. MLflow (5000):\"\ncurl -s http://localhost:5000 &gt;/dev/null &amp;&amp; echo \"   \u2705 Running\" || echo \"   \u274c Down\"\n\necho \"2. BankChurn API (8001):\"\ncurl -s http://localhost:8001/health &amp;&amp; echo \"\"\n\necho \"3. CarVision API (8002):\"\ncurl -s http://localhost:8002/health &amp;&amp; echo \"\"\n\necho \"4. CarVision Streamlit (8501):\"\ncurl -s http://localhost:8501 &gt;/dev/null &amp;&amp; echo '   \u2705 {\"status\":\"healthy\"}' || echo \"   \u274c Down\"\n\necho \"5. TelecomAI API (8003):\"\ncurl -s http://localhost:8003/health &amp;&amp; echo \"\"\n\n# Ver contenedores\ndocker-compose -f docker-compose.demo.yml ps\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#abrir-todas-las-urls","title":"Abrir Todas las URLs","text":"<pre><code># Linux\nxdg-open http://localhost:5000 &amp;      # MLflow\nxdg-open http://localhost:8001/docs &amp; # BankChurn\nxdg-open http://localhost:8002/docs &amp; # CarVision API\nxdg-open http://localhost:8501 &amp;      # CarVision Streamlit\nxdg-open http://localhost:8003/docs &amp; # TelecomAI\n\n# macOS\nopen http://localhost:5000\nopen http://localhost:8001/docs\nopen http://localhost:8002/docs\nopen http://localhost:8501\nopen http://localhost:8003/docs\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#powershell-windows","title":"PowerShell (Windows)","text":"<pre><code># Abrir todas las URLs\nStart-Process \"http://localhost:5000\"      # MLflow\nStart-Process \"http://localhost:8001/docs\" # BankChurn\nStart-Process \"http://localhost:8002/docs\" # CarVision API\nStart-Process \"http://localhost:8501\"      # CarVision Streamlit\nStart-Process \"http://localhost:8003/docs\" # TelecomAI\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#convertir-video-a-gif","title":"Convertir Video a GIF","text":"<pre><code># M\u00e9todo con paleta (mejor calidad)\nffmpeg -i video.mp4 -vf \"fps=12,scale=800:-1:flags=lanczos,palettegen\" palette.png\nffmpeg -i video.mp4 -i palette.png -filter_complex \"fps=12,scale=800:-1:flags=lanczos[x];[x][1:v]paletteuse\" output.gif\nrm palette.png\n\n# Optimizar tama\u00f1o\ngifsicle -O3 --colors 128 output.gif -o output-optimized.gif\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#ejemplos-de-prediccion-para-demo","title":"Ejemplos de Predicci\u00f3n para Demo","text":"<pre><code># BankChurn - Cliente que NO abandonar\u00e1\ncurl -X POST http://localhost:8001/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"credit_score\": 750,\n    \"age\": 35,\n    \"tenure\": 8,\n    \"balance\": 125000,\n    \"num_of_products\": 2,\n    \"has_cr_card\": 1,\n    \"is_active_member\": 1,\n    \"estimated_salary\": 95000,\n    \"geography\": \"France\",\n    \"gender\": \"Female\"\n  }' | jq\n\n# CarVision - Predecir precio\ncurl -X POST http://localhost:8002/predict \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model_year\": 2020,\n    \"model\": \"toyota camry\",\n    \"condition\": \"good\",\n    \"odometer\": 35000,\n    \"fuel\": \"gas\",\n    \"transmission\": \"automatic\",\n    \"type\": \"sedan\"\n  }' | jq\n</code></pre>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#checklist-final","title":"\u2705 Checklist Final","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#material-de-alta-prioridad-5-gifs","title":"Material de Alta Prioridad (5 GIFs)","text":"<ul> <li>[ ] <code>media/gifs/portfolio-demo.gif</code> \u2014 Demo completo (5 servicios)</li> <li>[ ] <code>media/gifs/bankchurn-preview.gif</code> \u2014 Demo API BankChurn</li> <li>[ ] <code>media/gifs/carvision-preview.gif</code> \u2014 Demo API CarVision</li> <li>[ ] <code>media/gifs/streamlit-carvision.gif</code> \u2014 Demo Streamlit Dashboard \u2190 NUEVO</li> <li>[ ] <code>media/gifs/telecom-preview.gif</code> \u2014 Demo API TelecomAI</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#material-de-alta-prioridad-video","title":"Material de Alta Prioridad (Video)","text":"<ul> <li>[ ] Video principal grabado (4-6 min)</li> <li>[ ] Video subido a YouTube/Drive</li> <li>[ ] Link actualizado en README.md</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#material-de-media-prioridad-screenshots","title":"Material de Media Prioridad (Screenshots)","text":"<ul> <li>[ ] <code>mlflow-experiments.png</code> \u2014 Lista de experimentos</li> <li>[ ] <code>mlflow-metrics.png</code> \u2014 M\u00e9tricas de un run</li> <li>[ ] <code>swagger-bankchurn.png</code> \u2014 Swagger BankChurn</li> <li>[ ] <code>swagger-carvision.png</code> \u2014 Swagger CarVision</li> <li>[ ] <code>swagger-telecom.png</code> \u2014 Swagger TelecomAI</li> <li>[ ] <code>streamlit-dashboard.png</code> \u2014 Dashboard completo</li> <li>[ ] <code>streamlit-prediction.png</code> \u2014 Resultado de predicci\u00f3n</li> <li>[ ] <code>github-actions-ci.png</code> \u2014 CI pasando</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#verificacion-final","title":"Verificaci\u00f3n Final","text":"<ul> <li>[ ] Todos los GIFs pesan &lt; 5MB</li> <li>[ ] Screenshots optimizados</li> <li>[ ] Video tiene audio claro</li> <li>[ ] READMEs actualizados con GIFs</li> <li>[ ] Links funcionan correctamente</li> <li>[ ] Git push realizado</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#recursos-adicionales","title":"\ud83d\udcda Recursos Adicionales","text":""},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#tutoriales-recomendados","title":"Tutoriales Recomendados","text":"<ul> <li>OBS Studio Quickstart</li> <li>ffmpeg GIF Guide</li> <li>Streamlit Deployment</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#ejemplos-de-portafolios-con-buenos-demos","title":"Ejemplos de Portafolios con Buenos Demos","text":"<ul> <li>made-with-ml</li> <li>mlops-zoomcamp</li> </ul>"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#links-del-portafolio","title":"\ud83d\udd17 Links del Portafolio","text":"Recurso URL Repositorio https://github.com/DuqueOM/ML-MLOps-Portfolio BankChurn /BankChurn-Predictor CarVision /CarVision-Market-Intelligence TelecomAI /TelecomAI-Customer-Intelligence"},{"location":"docs/apoyo/GUIA_AUDIOVISUAL/#urls-locales-con-docker","title":"URLs Locales (con Docker)","text":"Servicio URL MLflow http://localhost:5000 BankChurn API http://localhost:8001/docs CarVision API http://localhost:8002/docs CarVision Streamlit http://localhost:8501 TelecomAI API http://localhost:8003/docs   **\u00a1Tu portafolio tiene 5 servicios listos para demostrar!** \ud83d\ude80  [\u2190 Volver al \u00cdndice](../00_INDICE.md)"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/","title":"\ud83d\udd27 Gu\u00eda de Scripts Operacionales del Portafolio","text":"<p>Referencia completa de los scripts de operaci\u00f3n, demo, auditor\u00eda y automatizaci\u00f3n del portafolio ML-MLOps-Portfolio.</p> <p>Esta gu\u00eda te ense\u00f1a a entender, usar y crear scripts operacionales profesionales como los del portafolio.</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#indice","title":"\ud83d\udccb \u00cdndice","text":"<ul> <li>Visi\u00f3n General</li> <li>Scripts del Portafolio</li> <li>1. Scripts de Demo</li> <li>2. Scripts de Testing</li> <li>3. Scripts de Datos</li> <li>4. Scripts de Modelos</li> <li>5. Scripts de Auditor\u00eda</li> <li>6. Makefile: Orquestador Principal</li> <li>7. \ud83d\udd2c Ingenier\u00eda Inversa: Automatizaci\u00f3n \u2b50 NUEVO</li> <li>Patrones y Buenas Pr\u00e1cticas</li> <li>Ejercicios</li> </ul>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#vision-general","title":"Visi\u00f3n General","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#por-que-scripts-operacionales","title":"\u00bfPor Qu\u00e9 Scripts Operacionales?","text":"<pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551  SCRIPTS OPERACIONALES = Automatizaci\u00f3n profesional de tareas repetitivas     \u2551\n\u2551                                                                               \u2551\n\u2551  SIN SCRIPTS:                          CON SCRIPTS:                           \u2551\n\u2551  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                           \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                            \u2551\n\u2551  \u2022 \"\u00bfC\u00f3mo levanto el demo?\"            \u2022 `make docker-demo`                   \u2551\n\u2551  \u2022 \"\u00bfQu\u00e9 comandos corro para tests?\"   \u2022 `make test`                          \u2551\n\u2551  \u2022 \"\u00bfC\u00f3mo verifico que todo est\u00e1 OK?\"  \u2022 `bash scripts/health_check.py`       \u2551\n\u2551  \u2022 \"\u00bfC\u00f3mo preparo datos para CI?\"      \u2022 `bash scripts/setup_demo_models.sh`  \u2551\n\u2551                                                                               \u2551\n\u2551  BENEFICIOS:                                                                  \u2551\n\u2551  \u2022 Onboarding r\u00e1pido (nuevos devs corren `make install &amp;&amp; make test`)        \u2551\n\u2551  \u2022 Reproducibilidad (mismos comandos en local y CI)                          \u2551\n\u2551  \u2022 Documentaci\u00f3n ejecutable (el script ES la documentaci\u00f3n)                  \u2551\n\u2551  \u2022 Menos errores humanos (no hay que recordar flags y paths)                 \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#estructura-de-scripts-en-el-portafolio","title":"Estructura de Scripts en el Portafolio","text":"<pre><code>ML-MLOps-Portfolio/\n\u251c\u2500\u2500 scripts/                          # Scripts globales (root)\n\u2502   \u251c\u2500\u2500 demo.sh                       # Levanta stack completo\n\u2502   \u251c\u2500\u2500 setup_demo_models.sh          # Genera modelos para demo/CI\n\u2502   \u251c\u2500\u2500 run_demo_tests.sh             # Smoke tests de APIs\n\u2502   \u251c\u2500\u2500 run_e2e.sh                    # Tests end-to-end\n\u2502   \u251c\u2500\u2500 run_audit.sh                  # Auditor\u00eda completa (lint/type/sec)\n\u2502   \u251c\u2500\u2500 run_tests_top3.sh             # Tests de los 3 proyectos principales\n\u2502   \u251c\u2500\u2500 fetch_data.py                 # Descarga y valida datos\n\u2502   \u251c\u2500\u2500 health_check.py               # Verificaci\u00f3n de servicios\n\u2502   \u251c\u2500\u2500 promote_model.py              # Promoci\u00f3n de modelos en registry\n\u2502   \u2514\u2500\u2500 run_experiments.py            # Ejecuta experimentos MLflow\n\u2502\n\u251c\u2500\u2500 Makefile                          # Orquestador principal\n\u2502\n\u251c\u2500\u2500 BankChurn-Predictor/\n\u2502   \u251c\u2500\u2500 Makefile                      # Makefile del proyecto\n\u2502   \u2514\u2500\u2500 scripts/                      # Scripts espec\u00edficos del proyecto\n\u2502       \u2514\u2500\u2500 run_mlflow.py\n\u2502\n\u251c\u2500\u2500 CarVision-Market-Intelligence/\n\u2502   \u2514\u2500\u2500 Makefile\n\u2502\n\u2514\u2500\u2500 TelecomAI-Customer-Intelligence/\n    \u2514\u2500\u2500 Makefile\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#scripts-del-portafolio","title":"Scripts del Portafolio","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#mapa-de-scripts-modulos-de-la-guia","title":"Mapa de Scripts \u2192 M\u00f3dulos de la Gu\u00eda","text":"Script Prop\u00f3sito M\u00f3dulo(s) Relacionado(s) <code>demo.sh</code> Levanta stack demo 13_DOCKER, 17_DESPLIEGUE <code>setup_demo_models.sh</code> Genera modelos 09_TRAINING, 13_DOCKER <code>run_demo_tests.sh</code> Smoke tests 11_TESTING, 12_CI_CD <code>run_audit.sh</code> Auditor\u00eda 05_GIT, 11_TESTING, 12_CI_CD <code>fetch_data.py</code> Datos 06_VERSIONADO_DATOS <code>health_check.py</code> Verificaci\u00f3n 14_FASTAPI, 16_OBSERVABILIDAD <code>promote_model.py</code> Registry 10_EXPERIMENT_TRACKING <code>run_experiments.py</code> MLflow 10_EXPERIMENT_TRACKING"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#1-scripts-de-demo","title":"1. Scripts de Demo","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#demosh-levanta-el-stack-completo","title":"demo.sh \u2014 Levanta el Stack Completo","text":"<pre><code>#!/bin/bash\n# scripts/demo.sh \u2014 Demo end-to-end del portafolio\n# Uso: bash scripts/demo.sh\n\nset -e  # Salir si hay error\n\n# Colores para output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\necho -e \"${GREEN}\ud83d\ude80 Starting ML-MLOps Portfolio Demo...${NC}\"\n\n# 1. Verificar requisitos\necho -e \"${YELLOW}[1/5] Checking requirements...${NC}\"\ncommand -v docker &gt;/dev/null 2&gt;&amp;1 || { echo -e \"${RED}Docker is required but not installed.${NC}\"; exit 1; }\ncommand -v docker-compose &gt;/dev/null 2&gt;&amp;1 || command -v \"docker compose\" &gt;/dev/null 2&gt;&amp;1 || { echo -e \"${RED}Docker Compose is required.${NC}\"; exit 1; }\n\n# 2. Generar modelos si no existen\necho -e \"${YELLOW}[2/5] Ensuring demo models exist...${NC}\"\nif [ ! -f \"BankChurn-Predictor/models/pipeline.joblib\" ]; then\n    echo \"Generating demo models...\"\n    bash scripts/setup_demo_models.sh\nfi\n\n# 3. Build de im\u00e1genes\necho -e \"${YELLOW}[3/5] Building Docker images...${NC}\"\ndocker compose -f docker-compose.demo.yml build --quiet\n\n# 4. Levantar servicios\necho -e \"${YELLOW}[4/5] Starting services...${NC}\"\ndocker compose -f docker-compose.demo.yml up -d\n\n# 5. Esperar y verificar\necho -e \"${YELLOW}[5/5] Waiting for services to be healthy...${NC}\"\nsleep 30\n\n# Health checks\nSERVICES=(\"localhost:5000\" \"localhost:8001\" \"localhost:8002\" \"localhost:8003\")\nNAMES=(\"MLflow\" \"BankChurn\" \"CarVision\" \"TelecomAI\")\n\nALL_HEALTHY=true\nfor i in \"${!SERVICES[@]}\"; do\n    if curl -sf \"http://${SERVICES[$i]}/health\" &gt;/dev/null 2&gt;&amp;1; then\n        echo -e \"${GREEN}\u2713 ${NAMES[$i]} is healthy${NC}\"\n    else\n        echo -e \"${RED}\u2717 ${NAMES[$i]} is NOT healthy${NC}\"\n        ALL_HEALTHY=false\n    fi\ndone\n\nif [ \"$ALL_HEALTHY\" = true ]; then\n    echo -e \"\\n${GREEN}\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550${NC}\"\n    echo -e \"${GREEN}\u2705 Demo is ready!${NC}\"\n    echo -e \"${GREEN}\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550${NC}\"\n    echo -e \"\n    \ud83c\udfe6 BankChurn API:    http://localhost:8001/docs\n    \ud83d\ude97 CarVision API:    http://localhost:8002/docs\n    \ud83d\ude97 CarVision UI:     http://localhost:8501\n    \ud83d\udcf1 TelecomAI API:    http://localhost:8003/docs\n    \ud83d\udcca MLflow:           http://localhost:5000\n    \"\nelse\n    echo -e \"\\n${RED}\u26a0\ufe0f Some services are not healthy. Check logs:${NC}\"\n    echo \"docker compose -f docker-compose.demo.yml logs\"\n    exit 1\nfi\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#setup_demo_modelssh-genera-modelos-para-democi","title":"setup_demo_models.sh \u2014 Genera Modelos para Demo/CI","text":"<pre><code>#!/bin/bash\n# scripts/setup_demo_models.sh \u2014 Genera modelos m\u00ednimos para demo y CI\n# Estos modelos son r\u00e1pidos de crear y suficientes para probar las APIs\n\nset -e\n\necho \"\ud83d\udd27 Setting up demo models...\"\n\n# BankChurn\necho \"[1/3] BankChurn model...\"\ncd BankChurn-Predictor\npython -c \"\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nimport joblib\nimport os\n\n# Crear modelo simple\nX, y = make_classification(n_samples=1000, n_features=10, random_state=42)\nmodel = RandomForestClassifier(n_estimators=10, random_state=42)\nmodel.fit(X, y)\n\n# Guardar\nos.makedirs('models', exist_ok=True)\njoblib.dump(model, 'models/pipeline.joblib')\nprint('  \u2713 BankChurn model saved')\n\"\ncd ..\n\n# CarVision\necho \"[2/3] CarVision model...\"\ncd CarVision-Market-Intelligence\npython -c \"\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\nimport joblib\nimport os\n\nX, y = make_regression(n_samples=1000, n_features=10, random_state=42)\nmodel = RandomForestRegressor(n_estimators=10, random_state=42)\nmodel.fit(X, y)\n\nos.makedirs('artifacts', exist_ok=True)\njoblib.dump(model, 'artifacts/model.joblib')\nprint('  \u2713 CarVision model saved')\n\"\ncd ..\n\n# TelecomAI\necho \"[3/3] TelecomAI model...\"\ncd TelecomAI-Customer-Intelligence\npython -c \"\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.datasets import make_classification\nimport joblib\nimport os\n\nX, y = make_classification(n_samples=1000, n_features=4, n_classes=3, n_informative=3, random_state=42)\nmodel = GradientBoostingClassifier(n_estimators=10, random_state=42)\nmodel.fit(X, y)\n\nos.makedirs('artifacts', exist_ok=True)\njoblib.dump(model, 'artifacts/model.joblib')\nprint('  \u2713 TelecomAI model saved')\n\"\ncd ..\n\necho \"\u2705 All demo models created successfully!\"\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#2-scripts-de-testing","title":"2. Scripts de Testing","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#run_demo_testssh-smoke-tests-de-apis","title":"run_demo_tests.sh \u2014 Smoke Tests de APIs","text":"<pre><code>#!/bin/bash\n# scripts/run_demo_tests.sh \u2014 Verifica que las APIs respondan correctamente\n\nset -e\n\necho \"\ud83e\uddea Running demo tests...\"\n\n# Funci\u00f3n para test de API\ntest_api() {\n    local name=$1\n    local url=$2\n    local payload=$3\n\n    echo -n \"Testing $name... \"\n\n    response=$(curl -sf -X POST \"$url\" \\\n        -H \"Content-Type: application/json\" \\\n        -d \"$payload\" 2&gt;/dev/null)\n\n    if [ $? -eq 0 ]; then\n        echo \"\u2713 OK\"\n        return 0\n    else\n        echo \"\u2717 FAILED\"\n        return 1\n    fi\n}\n\n# Test BankChurn\ntest_api \"BankChurn /predict\" \\\n    \"http://localhost:8001/predict\" \\\n    '{\"CreditScore\":650,\"Geography\":\"France\",\"Gender\":\"Female\",\"Age\":40,\"Tenure\":3,\"Balance\":60000,\"NumOfProducts\":2,\"HasCrCard\":1,\"IsActiveMember\":1,\"EstimatedSalary\":50000}'\n\n# Test CarVision\ntest_api \"CarVision /predict\" \\\n    \"http://localhost:8002/predict\" \\\n    '{\"model_year\":2018,\"model\":\"ford f-150\",\"condition\":\"good\",\"cylinders\":6,\"fuel\":\"gas\",\"odometer\":50000,\"transmission\":\"automatic\",\"drive\":\"4wd\",\"type\":\"truck\",\"paint_color\":\"white\"}'\n\n# Test TelecomAI\ntest_api \"TelecomAI /predict\" \\\n    \"http://localhost:8003/predict\" \\\n    '{\"calls\":40,\"minutes\":311.9,\"messages\":83,\"mb_used\":19915.42}'\n\n# Health checks\necho \"\"\necho \"Health endpoints:\"\nfor port in 8001 8002 8003; do\n    status=$(curl -sf \"http://localhost:$port/health\" | jq -r '.status' 2&gt;/dev/null || echo \"error\")\n    echo \"  localhost:$port/health -&gt; $status\"\ndone\n\necho \"\"\necho \"\u2705 All demo tests passed!\"\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#run_e2esh-tests-end-to-end","title":"run_e2e.sh \u2014 Tests End-to-End","text":"<pre><code>#!/bin/bash\n# scripts/run_e2e.sh \u2014 Pipeline end-to-end completo\n\nset -e\n\nPROJECT=${1:-BankChurn-Predictor}\necho \"\ud83d\udd04 Running E2E pipeline for $PROJECT...\"\n\ncd \"$PROJECT\"\n\n# 1. Verificar datos\necho \"[1/5] Checking data...\"\nif [ ! -f \"data/raw/Churn_Modelling.csv\" ] &amp;&amp; [ ! -f \"data/Churn_Modelling.csv\" ]; then\n    echo \"\u26a0\ufe0f Data not found, attempting to fetch...\"\n    python scripts/fetch_data.py 2&gt;/dev/null || echo \"Skipping data fetch\"\nfi\n\n# 2. Train\necho \"[2/5] Training model...\"\npython main.py --mode train 2&gt;/dev/null || python -m bankchurn.training\n\n# 3. Test\necho \"[3/5] Running tests...\"\npytest tests/ -q --tb=short\n\n# 4. Coverage\necho \"[4/5] Checking coverage...\"\npytest tests/ --cov=src/ --cov-fail-under=70 -q\n\n# 5. API test\necho \"[5/5] Testing API (if running)...\"\nif curl -sf http://localhost:8001/health &gt;/dev/null 2&gt;&amp;1; then\n    curl -sf http://localhost:8001/predict \\\n        -H \"Content-Type: application/json\" \\\n        -d '{\"CreditScore\":650,\"Age\":40}' || true\nfi\n\necho \"\"\necho \"\u2705 E2E pipeline completed for $PROJECT!\"\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#3-scripts-de-datos","title":"3. Scripts de Datos","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#fetch_datapy-descarga-y-valida-datos","title":"fetch_data.py \u2014 Descarga y Valida Datos","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"scripts/fetch_data.py \u2014 Descarga datasets con validaci\u00f3n de integridad.\n\nUso:\n    python scripts/fetch_data.py\n    python scripts/fetch_data.py --project BankChurn-Predictor\n    python scripts/fetch_data.py --verify-only\n\"\"\"\n\nimport argparse\nimport hashlib\nimport json\nimport urllib.request\nfrom pathlib import Path\n\n\n# Registro de datasets con checksums para validaci\u00f3n\nDATASETS = {\n    \"BankChurn-Predictor\": {\n        \"url\": \"https://raw.githubusercontent.com/example/data/churn.csv\",\n        \"path\": \"data/raw/Churn_Modelling.csv\",\n        \"checksum\": \"abc123...\",  # SHA256\n        \"description\": \"Bank customer churn data\"\n    },\n    \"CarVision-Market-Intelligence\": {\n        \"url\": \"https://example.com/vehicles.csv\",\n        \"path\": \"data/vehicles_cleaned.csv\",\n        \"checksum\": \"def456...\",\n        \"description\": \"Vehicle listings for price prediction\"\n    }\n}\n\n\ndef calculate_checksum(filepath: Path) -&gt; str:\n    \"\"\"Calcula SHA256 de un archivo.\"\"\"\n    sha256 = hashlib.sha256()\n    with open(filepath, \"rb\") as f:\n        for block in iter(lambda: f.read(65536), b\"\"):\n            sha256.update(block)\n    return sha256.hexdigest()\n\n\ndef download_dataset(project: str, force: bool = False) -&gt; bool:\n    \"\"\"Descarga dataset para un proyecto.\"\"\"\n    if project not in DATASETS:\n        print(f\"\u274c Unknown project: {project}\")\n        return False\n\n    config = DATASETS[project]\n    filepath = Path(project) / config[\"path\"]\n\n    # Verificar si ya existe y es v\u00e1lido\n    if filepath.exists() and not force:\n        actual_checksum = calculate_checksum(filepath)\n        if actual_checksum == config[\"checksum\"]:\n            print(f\"\u2713 {project}: Data already exists and is valid\")\n            return True\n        else:\n            print(f\"\u26a0\ufe0f {project}: Checksum mismatch, re-downloading...\")\n\n    # Crear directorio\n    filepath.parent.mkdir(parents=True, exist_ok=True)\n\n    # Descargar\n    print(f\"\ud83d\udce5 Downloading {config['description']}...\")\n    try:\n        urllib.request.urlretrieve(config[\"url\"], filepath)\n\n        # Verificar checksum\n        actual_checksum = calculate_checksum(filepath)\n        if actual_checksum != config[\"checksum\"]:\n            print(f\"\u274c Checksum verification failed for {project}\")\n            return False\n\n        print(f\"\u2713 {project}: Downloaded and verified\")\n        return True\n    except Exception as e:\n        print(f\"\u274c Failed to download {project}: {e}\")\n        return False\n\n\ndef verify_all() -&gt; dict:\n    \"\"\"Verifica integridad de todos los datasets.\"\"\"\n    results = {}\n    for project, config in DATASETS.items():\n        filepath = Path(project) / config[\"path\"]\n        if filepath.exists():\n            actual = calculate_checksum(filepath)\n            results[project] = {\n                \"exists\": True,\n                \"valid\": actual == config[\"checksum\"],\n                \"path\": str(filepath)\n            }\n        else:\n            results[project] = {\n                \"exists\": False,\n                \"valid\": False,\n                \"path\": str(filepath)\n            }\n    return results\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Fetch and validate datasets\")\n    parser.add_argument(\"--project\", help=\"Specific project to fetch\")\n    parser.add_argument(\"--verify-only\", action=\"store_true\", help=\"Only verify, don't download\")\n    parser.add_argument(\"--force\", action=\"store_true\", help=\"Force re-download\")\n    args = parser.parse_args()\n\n    if args.verify_only:\n        results = verify_all()\n        print(json.dumps(results, indent=2))\n        return\n\n    if args.project:\n        download_dataset(args.project, args.force)\n    else:\n        for project in DATASETS:\n            download_dataset(project, args.force)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#4-scripts-de-modelos","title":"4. Scripts de Modelos","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#promote_modelpy-promocion-de-modelos-en-registry","title":"promote_model.py \u2014 Promoci\u00f3n de Modelos en Registry","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"scripts/promote_model.py \u2014 Promueve modelos en MLflow Model Registry.\n\nUso:\n    python scripts/promote_model.py --model-name bankchurn --stage Production\n    python scripts/promote_model.py --run-id abc123 --stage Staging\n    python scripts/promote_model.py --model-name bankchurn --stage Production --min-f1 0.6\n\"\"\"\n\nimport argparse\nimport sys\nfrom typing import Optional\n\nimport mlflow\nfrom mlflow.tracking import MlflowClient\n\n\ndef get_best_run(experiment_name: str, metric: str = \"f1_score\") -&gt; Optional[dict]:\n    \"\"\"Obtiene el mejor run de un experimento por m\u00e9trica.\"\"\"\n    client = MlflowClient()\n    experiment = client.get_experiment_by_name(experiment_name)\n\n    if not experiment:\n        print(f\"\u274c Experiment '{experiment_name}' not found\")\n        return None\n\n    runs = client.search_runs(\n        experiment_ids=[experiment.experiment_id],\n        order_by=[f\"metrics.{metric} DESC\"],\n        max_results=1\n    )\n\n    if not runs:\n        print(f\"\u274c No runs found in experiment '{experiment_name}'\")\n        return None\n\n    return runs[0]\n\n\ndef promote_model(\n    model_name: str,\n    stage: str,\n    run_id: Optional[str] = None,\n    min_metric: Optional[float] = None,\n    metric_name: str = \"f1_score\"\n) -&gt; bool:\n    \"\"\"Promueve un modelo a un stage espec\u00edfico.\"\"\"\n    client = MlflowClient()\n\n    # Si no se especifica run_id, buscar el mejor\n    if not run_id:\n        best_run = get_best_run(model_name, metric_name)\n        if not best_run:\n            return False\n        run_id = best_run.info.run_id\n        metric_value = best_run.data.metrics.get(metric_name, 0)\n\n        print(f\"\ud83d\udcca Best run: {run_id}\")\n        print(f\"   {metric_name}: {metric_value:.4f}\")\n\n        # Verificar umbral m\u00ednimo\n        if min_metric and metric_value &lt; min_metric:\n            print(f\"\u274c Metric {metric_value:.4f} is below threshold {min_metric}\")\n            return False\n\n    # Registrar modelo si no existe\n    try:\n        model_uri = f\"runs:/{run_id}/model\"\n        mv = mlflow.register_model(model_uri, model_name)\n        version = mv.version\n        print(f\"\u2713 Registered model version {version}\")\n    except Exception as e:\n        # Modelo ya registrado, obtener \u00faltima versi\u00f3n\n        versions = client.get_latest_versions(model_name)\n        if versions:\n            version = versions[0].version\n        else:\n            print(f\"\u274c Failed to register model: {e}\")\n            return False\n\n    # Transicionar a nuevo stage\n    client.transition_model_version_stage(\n        name=model_name,\n        version=version,\n        stage=stage,\n        archive_existing_versions=True  # Archiva versiones anteriores en ese stage\n    )\n\n    print(f\"\u2705 Model '{model_name}' v{version} promoted to {stage}\")\n    return True\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Promote models in MLflow Registry\")\n    parser.add_argument(\"--model-name\", required=True, help=\"Name of the model\")\n    parser.add_argument(\"--stage\", required=True, choices=[\"Staging\", \"Production\", \"Archived\"])\n    parser.add_argument(\"--run-id\", help=\"Specific run ID to promote\")\n    parser.add_argument(\"--min-f1\", type=float, help=\"Minimum F1 score required\")\n    parser.add_argument(\"--tracking-uri\", default=\"http://localhost:5000\")\n    args = parser.parse_args()\n\n    mlflow.set_tracking_uri(args.tracking_uri)\n\n    success = promote_model(\n        model_name=args.model_name,\n        stage=args.stage,\n        run_id=args.run_id,\n        min_metric=args.min_f1,\n        metric_name=\"f1_score\"\n    )\n\n    sys.exit(0 if success else 1)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#health_checkpy-verificacion-de-servicios","title":"health_check.py \u2014 Verificaci\u00f3n de Servicios","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"scripts/health_check.py \u2014 Verifica estado de servicios ML.\n\nUso:\n    python scripts/health_check.py\n    python scripts/health_check.py --services bankchurn,carvision\n    python scripts/health_check.py --json\n\"\"\"\n\nimport argparse\nimport json\nimport sys\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport urllib.request\nimport urllib.error\n\n\n@dataclass\nclass ServiceStatus:\n    name: str\n    url: str\n    healthy: bool\n    latency_ms: Optional[float] = None\n    error: Optional[str] = None\n\n\n# Servicios del portafolio\nSERVICES = {\n    \"mlflow\": \"http://localhost:5000/health\",\n    \"bankchurn\": \"http://localhost:8001/health\",\n    \"carvision\": \"http://localhost:8002/health\",\n    \"telecomai\": \"http://localhost:8003/health\",\n    \"streamlit\": \"http://localhost:8501/_stcore/health\",\n    \"prometheus\": \"http://localhost:9090/-/healthy\",\n    \"grafana\": \"http://localhost:3000/api/health\",\n}\n\n\ndef check_service(name: str, url: str, timeout: float = 5.0) -&gt; ServiceStatus:\n    \"\"\"Verifica un servicio individual.\"\"\"\n    import time\n\n    start = time.time()\n    try:\n        req = urllib.request.Request(url, method=\"GET\")\n        with urllib.request.urlopen(req, timeout=timeout) as response:\n            latency = (time.time() - start) * 1000\n            return ServiceStatus(\n                name=name,\n                url=url,\n                healthy=response.status == 200,\n                latency_ms=round(latency, 2)\n            )\n    except urllib.error.URLError as e:\n        return ServiceStatus(\n            name=name,\n            url=url,\n            healthy=False,\n            error=str(e.reason)\n        )\n    except Exception as e:\n        return ServiceStatus(\n            name=name,\n            url=url,\n            healthy=False,\n            error=str(e)\n        )\n\n\ndef check_all_services(services: dict, parallel: bool = True) -&gt; list[ServiceStatus]:\n    \"\"\"Verifica todos los servicios.\"\"\"\n    results = []\n\n    if parallel:\n        with ThreadPoolExecutor(max_workers=len(services)) as executor:\n            futures = {\n                executor.submit(check_service, name, url): name\n                for name, url in services.items()\n            }\n            for future in as_completed(futures):\n                results.append(future.result())\n    else:\n        for name, url in services.items():\n            results.append(check_service(name, url))\n\n    return sorted(results, key=lambda x: x.name)\n\n\ndef print_status(results: list[ServiceStatus], as_json: bool = False):\n    \"\"\"Imprime resultados.\"\"\"\n    if as_json:\n        data = [\n            {\n                \"name\": r.name,\n                \"url\": r.url,\n                \"healthy\": r.healthy,\n                \"latency_ms\": r.latency_ms,\n                \"error\": r.error\n            }\n            for r in results\n        ]\n        print(json.dumps(data, indent=2))\n        return\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"SERVICE HEALTH CHECK\")\n    print(\"=\" * 60)\n\n    for r in results:\n        status = \"\u2705\" if r.healthy else \"\u274c\"\n        latency = f\"({r.latency_ms}ms)\" if r.latency_ms else \"\"\n        error = f\" - {r.error}\" if r.error else \"\"\n        print(f\"{status} {r.name:15} {latency:12} {error}\")\n\n    healthy_count = sum(1 for r in results if r.healthy)\n    print(\"=\" * 60)\n    print(f\"Total: {healthy_count}/{len(results)} services healthy\")\n    print(\"=\" * 60 + \"\\n\")\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Check ML services health\")\n    parser.add_argument(\"--services\", help=\"Comma-separated list of services to check\")\n    parser.add_argument(\"--json\", action=\"store_true\", help=\"Output as JSON\")\n    parser.add_argument(\"--timeout\", type=float, default=5.0, help=\"Timeout in seconds\")\n    args = parser.parse_args()\n\n    # Filtrar servicios si se especifica\n    services = SERVICES\n    if args.services:\n        requested = set(args.services.lower().split(\",\"))\n        services = {k: v for k, v in SERVICES.items() if k in requested}\n\n    results = check_all_services(services)\n    print_status(results, as_json=args.json)\n\n    # Exit code basado en salud\n    all_healthy = all(r.healthy for r in results)\n    sys.exit(0 if all_healthy else 1)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#5-scripts-de-auditoria","title":"5. Scripts de Auditor\u00eda","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#run_auditsh-auditoria-completa","title":"run_audit.sh \u2014 Auditor\u00eda Completa","text":"<pre><code>#!/bin/bash\n# scripts/run_audit.sh \u2014 Auditor\u00eda completa de c\u00f3digo, tipos y seguridad\n\nset -e\n\nREPORT_DIR=\"reports/audit\"\nmkdir -p \"$REPORT_DIR\"\n\necho \"\ud83d\udd0d Starting full audit...\"\necho \"Reports will be saved to: $REPORT_DIR\"\necho \"\"\n\n# 1. Linting con ruff/flake8\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"[1/5] Code Style (flake8/ruff)\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\nfor project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n    echo \"Checking $project...\"\n    flake8 \"$project/src\" --output-file=\"$REPORT_DIR/flake8-$project.txt\" \\\n        --count --statistics 2&gt;/dev/null || true\n\n    # Mostrar resumen\n    if [ -f \"$REPORT_DIR/flake8-$project.txt\" ]; then\n        errors=$(wc -l &lt; \"$REPORT_DIR/flake8-$project.txt\")\n        echo \"  \u2192 $errors issues found\"\n    fi\ndone\necho \"\"\n\n# 2. Formateo con black\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"[2/5] Formatting (black)\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\nfor project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n    echo \"Checking $project...\"\n    black --check \"$project/src\" \"$project/app\" 2&gt;/dev/null || echo \"  \u2192 Formatting issues found\"\ndone\necho \"\"\n\n# 3. Type checking con mypy\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"[3/5] Type Checking (mypy)\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\nfor project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n    echo \"Checking $project...\"\n    mypy \"$project/src\" --ignore-missing-imports \\\n        --html-report \"$REPORT_DIR/mypy-$project\" 2&gt;/dev/null || echo \"  \u2192 Type issues found\"\ndone\necho \"\"\n\n# 4. Security con bandit\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"[4/5] Security (bandit)\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\nfor project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do\n    echo \"Scanning $project...\"\n    bandit -r \"$project/src\" -f json -o \"$REPORT_DIR/bandit-$project.json\" 2&gt;/dev/null || true\n\n    # Mostrar resumen\n    if [ -f \"$REPORT_DIR/bandit-$project.json\" ]; then\n        high=$(jq '.metrics._totals.\"SEVERITY.HIGH\"' \"$REPORT_DIR/bandit-$project.json\" 2&gt;/dev/null || echo 0)\n        medium=$(jq '.metrics._totals.\"SEVERITY.MEDIUM\"' \"$REPORT_DIR/bandit-$project.json\" 2&gt;/dev/null || echo 0)\n        echo \"  \u2192 High: $high, Medium: $medium\"\n    fi\ndone\necho \"\"\n\n# 5. Secrets con gitleaks\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"[5/5] Secret Detection (gitleaks)\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\n\nif command -v gitleaks &amp;&gt; /dev/null; then\n    gitleaks detect --source . --report-path \"$REPORT_DIR/gitleaks.json\" --report-format json 2&gt;/dev/null || true\n    echo \"  \u2192 Report saved to $REPORT_DIR/gitleaks.json\"\nelse\n    echo \"  \u2192 gitleaks not installed, skipping\"\nfi\necho \"\"\n\n# Resumen final\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"AUDIT COMPLETE\"\necho \"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\"\necho \"Reports saved to: $REPORT_DIR/\"\nls -la \"$REPORT_DIR/\"\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#6-makefile-orquestador-principal","title":"6. Makefile: Orquestador Principal","text":"<p>El Makefile es el punto de entrada principal para todas las operaciones:</p> <pre><code># Makefile \u2014 ML-MLOps Portfolio\n# Comandos unificados para desarrollo, testing y operaciones\n\n.PHONY: help install test lint format docker-build docker-demo clean\n\n# Variables\nPROJECTS := BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence\nPYTHON := python3\n\n# Colores\nGREEN := \\033[0;32m\nYELLOW := \\033[1;33m\nNC := \\033[0m\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# HELP\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nhelp: ## Muestra esta ayuda\n    @echo \"$(GREEN)ML-MLOps Portfolio - Comandos disponibles:$(NC)\"\n    @grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | \\\n        awk 'BEGIN {FS = \":.*?## \"}; {printf \"  $(YELLOW)%-20s$(NC) %s\\n\", $$1, $$2}'\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# DESARROLLO\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ninstall: ## Instala dependencias de todos los proyectos\n    @for project in $(PROJECTS); do \\\n        echo \"$(GREEN)Installing $$project...$(NC)\"; \\\n        cd $$project &amp;&amp; pip install -e \".[dev]\" &amp;&amp; cd ..; \\\n    done\n\ninstall-dev: ## Instala herramientas de desarrollo\n    pip install pre-commit black flake8 mypy pytest pytest-cov bandit\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# TESTING\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ntest: ## Ejecuta tests de todos los proyectos\n    @for project in $(PROJECTS); do \\\n        echo \"$(GREEN)Testing $$project...$(NC)\"; \\\n        cd $$project &amp;&amp; pytest tests/ -q &amp;&amp; cd ..; \\\n    done\n\ntest-coverage: ## Tests con reporte de coverage\n    @for project in $(PROJECTS); do \\\n        echo \"$(GREEN)Coverage for $$project...$(NC)\"; \\\n        cd $$project &amp;&amp; pytest --cov=src/ --cov-report=term-missing &amp;&amp; cd ..; \\\n    done\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# CALIDAD DE C\u00d3DIGO\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nlint: ## Ejecuta linting\n    @pre-commit run --all-files || true\n\nformat: ## Formatea c\u00f3digo con black\n    @black . --exclude '/(\\.venv|data|artifacts|mlruns)/'\n    @isort . --skip-gitignore\n\ntypecheck: ## Type checking con mypy\n    @for project in $(PROJECTS); do \\\n        mypy $$project/src/ --ignore-missing-imports || true; \\\n    done\n\naudit: ## Auditor\u00eda completa (lint + types + security)\n    bash scripts/run_audit.sh\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# DOCKER\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\ndocker-build: ## Construye im\u00e1genes Docker\n    @for project in $(PROJECTS); do \\\n        echo \"$(GREEN)Building $$project...$(NC)\"; \\\n        docker build -t $$(echo $$project | tr '[:upper:]' '[:lower:]'):latest $$project; \\\n    done\n\ndocker-demo: ## Inicia stack demo completo\n    bash scripts/demo.sh\n\ndocker-demo-up: ## Inicia servicios (sin build)\n    docker compose -f docker-compose.demo.yml up -d\n\ndocker-demo-down: ## Detiene servicios\n    docker compose -f docker-compose.demo.yml down\n\ndocker-logs: ## Ver logs de servicios\n    docker compose -f docker-compose.demo.yml logs -f\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# MLFLOW Y EXPERIMENTOS\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nmlflow-ui: ## Inicia MLflow UI local\n    mlflow ui --port 5000 --backend-store-uri ./mlruns\n\nexperiments: ## Ejecuta experimentos de todos los proyectos\n    $(PYTHON) scripts/run_experiments.py\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# HEALTH Y VERIFICACI\u00d3N\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nhealth-check: ## Verifica salud de servicios\n    $(PYTHON) scripts/health_check.py\n\nsmoke-test: ## Smoke tests de APIs\n    bash scripts/run_demo_tests.sh\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# LIMPIEZA\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclean: ## Limpia archivos temporales\n    find . -type d -name __pycache__ -exec rm -rf {} + 2&gt;/dev/null || true\n    find . -type d -name .pytest_cache -exec rm -rf {} + 2&gt;/dev/null || true\n    find . -type d -name htmlcov -exec rm -rf {} + 2&gt;/dev/null || true\n    find . -name \"*.pyc\" -delete\n    find . -name \".coverage\" -delete\n\nclean-docker: ## Limpia contenedores e im\u00e1genes\n    docker compose -f docker-compose.demo.yml down -v --remove-orphans\n    @for project in $(PROJECTS); do \\\n        docker rmi $$(echo $$project | tr '[:upper:]' '[:lower:]'):latest 2&gt;/dev/null || true; \\\n    done\n\n# Default\n.DEFAULT_GOAL := help\n</code></pre> <p></p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#7-ingenieria-inversa-pedagogica-la-automatizacion-invisible","title":"7. \ud83d\udd2c Ingenier\u00eda Inversa Pedag\u00f3gica: La Automatizaci\u00f3n Invisible","text":"<p>Objetivo: Entender c\u00f3mo se orquestan 3 proyectos y m\u00faltiples servicios con un solo comando.</p> <p>Esta secci\u00f3n analiza el \"pegamento\" que mantiene unido el portafolio: el <code>Makefile</code> ra\u00edz y el script <code>demo.sh</code>.</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#71-el-patron-recursive-make-makefile","title":"7.1 El Patr\u00f3n \"Recursive Make\" (Makefile)","text":"<p>En un monorepo, no queremos duplicar comandos. El <code>Makefile</code> ra\u00edz act\u00faa como un director de orquesta que delega en los <code>Makefiles</code> de cada m\u00fasico (proyecto).</p> <p>Archivo: <code>Makefile</code> (ra\u00edz)</p> <pre><code># BLOQUE: Iteraci\u00f3n sobre proyectos\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nPROJECTS := BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence\n\ninstall:\n    @for project in $(PROJECTS); do \\              # 1. Itera por cada carpeta\n        echo \"Installing $$project...\"; \\\n        cd $$project &amp;&amp; $(MAKE) install &amp;&amp; cd ..; \\ # 2. Entra, ejecuta make local, y sale\n    done\n</code></pre> <p>\u00bfPor qu\u00e9 hacerlo as\u00ed? - Encapsulamiento: Cada proyecto sabe c\u00f3mo instalarse a s\u00ed mismo. El ra\u00edz no necesita saber qu\u00e9 librer\u00edas usa <code>BankChurn</code>. - Escalabilidad: Si a\u00f1ades un 4\u00ba proyecto, solo lo agregas a la lista <code>PROJECTS</code>.</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#72-anatomia-de-scriptsdemosh","title":"7.2 Anatom\u00eda de <code>scripts/demo.sh</code>","text":"<p>Este script no es solo una lista de comandos; es un flujo de orquestaci\u00f3n robusto.</p> <p>Archivo: <code>scripts/demo.sh</code></p> <pre><code># BLOQUE: Espera Activa (Polling)\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n# Problema: docker-compose up retorna inmediatamente, pero los servicios tardan en arrancar.\n# Soluci\u00f3n: No usar sleep fijos (flaky), usar polling de health endpoints.\n\necho \"Waiting for services...\"\nSERVICES=(\"localhost:5000\" \"localhost:8001\" ...)\n\nfor i in \"${!SERVICES[@]}\"; do\n    # curl -f: Falla si el c\u00f3digo HTTP no es 200 (ej. 500, 404)\n    # Reintenta impl\u00edcitamente o el usuario debe implementar el loop\n    if curl -sf \"http://${SERVICES[$i]}/health\" &gt;/dev/null; then\n        echo \"\u2713 Healthy\"\n    fi\ndone\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#73-troubleshooting-de-automatizacion","title":"7.3 Troubleshooting de Automatizaci\u00f3n","text":"Error Com\u00fan Causa Soluci\u00f3n <code>make: *** [BankChurn-Predictor] Error 2</code> Fall\u00f3 el make del subproyecto Ve al directorio del proyecto y corre <code>make</code> all\u00ed para ver el error real. <code>curl: (7) Failed to connect</code> en demo El servicio no ha arrancado a\u00fan Aumenta el tiempo de espera o revisa <code>docker logs</code> para ver si crashe\u00f3 al inicio. <code>Permission denied</code> en scripts Falta bit de ejecuci\u00f3n <code>chmod +x scripts/*.sh</code>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#patrones-y-buenas-practicas","title":"Patrones y Buenas Pr\u00e1cticas","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#1-siempre-usa-set-e-en-bash","title":"1. Siempre Usa <code>set -e</code> en Bash","text":"<pre><code>#!/bin/bash\nset -e  # Salir inmediatamente si hay error\nset -u  # Error si se usa variable no definida\nset -o pipefail  # Propagar errores en pipes\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#2-proporciona-colores-y-feedback","title":"2. Proporciona Colores y Feedback","text":"<pre><code>RED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\necho -e \"${GREEN}\u2713 Success${NC}\"\necho -e \"${RED}\u2717 Error${NC}\"\necho -e \"${YELLOW}\u26a0 Warning${NC}\"\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#3-verifica-requisitos-al-inicio","title":"3. Verifica Requisitos al Inicio","text":"<pre><code># Verificar que Docker est\u00e9 instalado\ncommand -v docker &gt;/dev/null 2&gt;&amp;1 || { echo \"Docker required\"; exit 1; }\n\n# Verificar que un archivo exista\n[ -f \"config.yaml\" ] || { echo \"config.yaml not found\"; exit 1; }\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#4-usa-funciones-para-reutilizacion","title":"4. Usa Funciones para Reutilizaci\u00f3n","text":"<pre><code>log_info() {\n    echo -e \"${GREEN}[INFO]${NC} $1\"\n}\n\nlog_error() {\n    echo -e \"${RED}[ERROR]${NC} $1\" &gt;&amp;2\n}\n\ncheck_service() {\n    local url=$1\n    curl -sf \"$url\" &gt;/dev/null 2&gt;&amp;1\n}\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#5-documenta-el-uso","title":"5. Documenta el Uso","text":"<pre><code>#!/bin/bash\n# Script: my_script.sh\n# Descripci\u00f3n: Hace algo importante\n# Uso: bash my_script.sh [opciones]\n# Opciones:\n#   --force    Forzar operaci\u00f3n\n#   --dry-run  Solo mostrar qu\u00e9 har\u00eda\n</code></pre>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#ejercicios","title":"\ud83d\udd27 Ejercicios","text":""},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#ejercicio-1-crear-script-de-setup","title":"Ejercicio 1: Crear Script de Setup","text":"<p>Crea un script <code>setup.sh</code> que: 1. Verifique Python 3.10+ 2. Cree un venv 3. Instale dependencias 4. Corra tests</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#ejercicio-2-script-de-backup-de-modelos","title":"Ejercicio 2: Script de Backup de Modelos","text":"<p>Crea <code>backup_models.sh</code> que: 1. Liste todos los modelos en <code>models/</code> y <code>artifacts/</code> 2. Los comprima con fecha 3. Los suba a un directorio de backup</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#ejercicio-3-health-check-con-alertas","title":"Ejercicio 3: Health Check con Alertas","text":"<p>Modifica <code>health_check.py</code> para: 1. Enviar alerta si un servicio est\u00e1 ca\u00eddo 2. Guardar historial de checks 3. Calcular uptime</p>"},{"location":"docs/apoyo/GUIA_SCRIPTS_OPERACIONALES/#referencias","title":"\ud83d\udcda Referencias","text":"<ul> <li>MAPA_PORTAFOLIO_1TO1.md \u2014 Mapeo de scripts a m\u00f3dulos</li> <li>12_CI_CD.md \u2014 C\u00f3mo se usan estos scripts en CI</li> <li>13_DOCKER.md \u2014 Docker Compose y orquestaci\u00f3n</li> <li>16_OBSERVABILIDAD.md \u2014 Health checks y monitoreo</li> </ul>   [\u2190 Volver al \u00cdndice](../00_INDICE.md)"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/","title":"\ud83d\udd27 Gu\u00eda de Mantenimiento \u2014 guia_mlops v5","text":"<p>Meta-documento: Esta gu\u00eda describe c\u00f3mo mantener la gu\u00eda MLOps en s\u00ed misma actualizada y funcional.</p> <p>\u26a0\ufe0f \u00bfBuscas contenido sobre operaciones de sistemas ML en producci\u00f3n? Ver: - 17_DESPLIEGUE.md - 16_OBSERVABILIDAD.md \u2014 Monitoreo y alertas - Runbook del Portafolio \u2014 Operaciones end-to-end del portafolio</p> <p>\u00daltima actualizaci\u00f3n: Diciembre 2025</p>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#estado-actual-de-la-guia","title":"\ud83d\udcca Estado Actual de la Gu\u00eda","text":"Componente Cantidad Estado M\u00f3dulos principales 23 \u2705 Completos Ejercicios 42 \u2705 Con soluciones ADRs 14 \u2705 Actualizados Recursos externos 50+ videos \u2705 Curados Glosario 100+ t\u00e9rminos \u2705 Expandido"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#calendario-de-mantenimiento","title":"\ud83d\udcc5 Calendario de Mantenimiento","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#mensual","title":"Mensual","text":"<ul> <li>[ ] Verificar que todos los links funcionan (<code>./scripts/validate_guide.sh</code>)</li> <li>[ ] Actualizar versiones de dependencias en <code>requirements.txt</code></li> <li>[ ] Ejecutar tests de todos los m\u00f3dulos</li> <li>[ ] Verificar que videos de RECURSOS.md siguen disponibles</li> </ul>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#trimestral","title":"Trimestral","text":"<ul> <li>[ ] Revisar y actualizar ejemplos de c\u00f3digo con mejores pr\u00e1cticas</li> <li>[ ] Regenerar <code>requirements.txt</code> con versiones actuales</li> <li>[ ] Verificar compatibilidad con Python m\u00e1s reciente (actualmente 3.11+)</li> <li>[ ] Actualizar templates con mejores pr\u00e1cticas</li> <li>[ ] Revisar y actualizar RECURSOS.md con nuevos videos/cursos</li> </ul>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#semestral","title":"Semestral","text":"<ul> <li>[ ] Revisar estructura completa de la gu\u00eda (23 m\u00f3dulos)</li> <li>[ ] Actualizar referencias y recursos externos</li> <li>[ ] Incorporar feedback de usuarios</li> <li>[ ] Evaluar nuevas herramientas del ecosistema MLOps</li> <li>[ ] Actualizar PLANTILLAS.md con nuevas herramientas</li> <li>[ ] Revisar que el glosario cubre todos los t\u00e9rminos usados en m\u00f3dulos</li> </ul>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#validacion-de-la-guia","title":"\ud83d\udd0d Validaci\u00f3n de la Gu\u00eda","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#script-de-validacion","title":"Script de Validaci\u00f3n","text":"<p>Ejecutar para verificar la integridad de la gu\u00eda:</p> <pre><code># Dar permisos de ejecuci\u00f3n\nchmod +x scripts/validate_guide.sh\n\n# Ejecutar validaci\u00f3n\n./scripts/validate_guide.sh\n</code></pre> <p>El script verifica: 1. Estructura de directorios: Todos los m\u00f3dulos existen 2. Archivos requeridos: mkdocs.yml, requirements.txt, etc. 3. Links en Markdown: No hay links rotos 4. Sintaxis YAML: Archivos de configuraci\u00f3n v\u00e1lidos 5. Tests por m\u00f3dulo: Cada m\u00f3dulo tiene tests 6. Notebooks: Son JSON v\u00e1lidos</p>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#ejecutar-tests-completos","title":"Ejecutar Tests Completos","text":"<pre><code># Activar entorno\nsource .venv/bin/activate\n\n# Ejecutar todos los tests\nmake check-all\n\n# O m\u00f3dulo por m\u00f3dulo\nmake check-01\nmake check-02\n# ...\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#actualizacion-de-dependencias","title":"\ud83d\udce6 Actualizaci\u00f3n de Dependencias","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#verificar-desactualizadas","title":"Verificar Desactualizadas","text":"<pre><code>pip list --outdated\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#proceso-de-actualizacion","title":"Proceso de Actualizaci\u00f3n","text":"<ol> <li> <p>Crear branch de actualizaci\u00f3n <pre><code>git checkout -b chore/update-deps-YYYY-MM\n</code></pre></p> </li> <li> <p>Actualizar dependencias <pre><code>pip install --upgrade package-name\n</code></pre></p> </li> <li> <p>Ejecutar tests <pre><code>pytest docs/ -v\n</code></pre></p> </li> <li> <p>Si pasan, regenerar lockfile <pre><code>pip freeze &gt; requirements.lock\n</code></pre></p> </li> <li> <p>Commit y PR <pre><code>git add requirements.txt requirements.lock\ngit commit -m \"chore: update dependencies YYYY-MM\"\n</code></pre></p> </li> </ol>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#auditoria-de-seguridad","title":"Auditor\u00eda de Seguridad","text":"<pre><code># Instalar herramientas\npip install pip-audit safety\n\n# Verificar vulnerabilidades\npip-audit\nsafety check\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#resolucion-de-problemas","title":"\ud83d\udc1b Resoluci\u00f3n de Problemas","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#tests-fallando","title":"Tests Fallando","text":"<ol> <li>Verificar que el entorno est\u00e1 activado</li> <li>Reinstalar dependencias: <code>pip install -r requirements.txt</code></li> <li>Verificar versi\u00f3n de Python: <code>python --version</code> (3.10+)</li> <li>Ejecutar test individual para m\u00e1s detalles</li> </ol>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#links-rotos","title":"Links Rotos","text":"<ol> <li>Ejecutar <code>./scripts/validate_guide.sh</code></li> <li>Revisar output para links espec\u00edficos</li> <li>Actualizar o eliminar links rotos</li> </ol>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#mkdocs-no-funciona","title":"MkDocs No Funciona","text":"<ol> <li>Verificar instalaci\u00f3n: <code>mkdocs --version</code></li> <li>Reinstalar: <code>pip install mkdocs mkdocs-material</code></li> <li>Verificar sintaxis de <code>mkdocs.yml</code></li> </ol>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#contribuir-a-la-guia","title":"\ud83d\udcdd Contribuir a la Gu\u00eda","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#agregar-nuevo-contenido","title":"Agregar Nuevo Contenido","text":"<ol> <li>Crear branch: <code>git checkout -b feat/new-content</code></li> <li>Agregar contenido en el m\u00f3dulo correspondiente</li> <li>Agregar tests si aplica</li> <li>Actualizar <code>mkdocs.yml</code> si es necesario</li> <li>Ejecutar validaci\u00f3n: <code>./scripts/validate_guide.sh</code></li> <li>Crear PR con descripci\u00f3n clara</li> </ol>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#estructura-de-un-modulo","title":"Estructura de un M\u00f3dulo","text":"<pre><code>docs/XX_nombre_modulo/\n\u251c\u2500\u2500 index.md           # Contenido principal\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_*.py      # Tests del m\u00f3dulo\n\u2514\u2500\u2500 solutions/\n    \u2514\u2500\u2500 *.py           # Soluciones de ejercicios\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#convenciones","title":"Convenciones","text":"<ul> <li>Usar Markdown est\u00e1ndar</li> <li>Incluir ejemplos de c\u00f3digo ejecutables</li> <li>Agregar ejercicios pr\u00e1cticos con tests</li> <li>Mantener links relativos entre m\u00f3dulos</li> </ul>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#metricas-de-calidad","title":"\ud83d\udcca M\u00e9tricas de Calidad","text":""},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#objetivos","title":"Objetivos","text":"M\u00e9trica Objetivo Actual Tests pasando 100% \u2705 Links rotos 0 \u2705 M\u00f3dulos completos 23/23 \u2705 Ejercicios con soluci\u00f3n 42/42 \u2705 ADRs documentados 14/14 \u2705 Glosario t\u00e9rminos 100+ \u2705 Recursos externos 50+ \u2705"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#monitoreo","title":"Monitoreo","text":"<p>Ejecutar semanalmente:</p> <pre><code>./scripts/validate_guide.sh &gt; reports/validation_$(date +%Y%m%d).log\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#estructura-de-archivos-de-la-guia","title":"\ud83d\udcc1 Estructura de Archivos de la Gu\u00eda","text":"<pre><code>docs/guia_mlops/\n\u251c\u2500\u2500 00_INDICE.md              # \u00cdndice principal\n\u251c\u2500\u2500 01-23_*.md                # 23 m\u00f3dulos tem\u00e1ticos\n\u251c\u2500\u2500 EJERCICIOS.md             # 42 ejercicios pr\u00e1cticos\n\u251c\u2500\u2500 EJERCICIOS_SOLUCIONES.md  # Soluciones detalladas\n\u251c\u2500\u2500 RUBRICA_EVALUACION.md     # Sistema de evaluaci\u00f3n (100 puntos)\n\u251c\u2500\u2500 RECURSOS.md    # \ud83d\udcfa Videos y cursos externos\n\u251c\u2500\u2500 PLANTILLAS.md        # 14 ADRs de herramientas\n\u251c\u2500\u2500 apoyo/GLOSARIO.md            # 100+ t\u00e9rminos con ejemplos\n\u251c\u2500\u2500 SIMULACRO_*.md            # Entrevistas t\u00e9cnicas\n\u251c\u2500\u2500 APENDICE_A_SPEECH.md      # Speech de portafolio\n\u251c\u2500\u2500 APENDICE_B_TALKING.md     # Puntos clave\n\u251c\u2500\u2500 SYLLABUS.md               # Programa de 8 semanas\n\u251c\u2500\u2500 PLAN_ESTUDIOS.md          # Cronograma d\u00eda a d\u00eda\n\u251c\u2500\u2500 GUIA_AUDIOVISUAL.md       # Crear demos y videos\n\u251c\u2500\u2500 MAINTENANCE_GUIDE.md      # Esta gu\u00eda\n\u251c\u2500\u2500 templates/                # 13 plantillas reutilizables\n\u2514\u2500\u2500 mkdocs.yml                # Configuraci\u00f3n MkDocs\n</code></pre>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#recursos-internos","title":"\ud83d\udd17 Recursos Internos","text":"Archivo Prop\u00f3sito Actualizaci\u00f3n RECURSOS.md Videos y cursos externos Trimestral PLANTILLAS.md ADRs de herramientas Semestral GLOSARIO.md Definiciones de t\u00e9rminos Mensual RUBRICA_EVALUACION.md Sistema de puntuaci\u00f3n Semestral"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#recursos-externos","title":"Recursos Externos","text":"<ul> <li>MkDocs Documentation</li> <li>Material for MkDocs</li> <li>pytest Documentation</li> </ul>"},{"location":"docs/apoyo/MAINTENANCE_GUIDE/#contacto","title":"\ud83d\udc65 Contacto","text":"<ul> <li>Mantenedor: DuqueOM</li> <li>Repositorio: ML-MLOps-Portfolio</li> </ul>   [\u2190 Volver al \u00cdndice](../00_INDICE.md)"},{"location":"docs/apoyo/PLANTILLAS/","title":"\ud83d\udccb Plantillas Reutilizables \u2014 Gu\u00eda MLOps","text":"<p>Templates listos para usar en tus proyectos ML</p> <p>\ud83d\udcc1 Ver tambi\u00e9n: templates/ contiene las plantillas como archivos individuales descargables.</p>"},{"location":"docs/apoyo/PLANTILLAS/#1-template-readmemd","title":"\ud83d\udcc4 1. Template README.md","text":"<pre><code># \ud83d\ude80 [Nombre del Proyecto]\n\n[![CI](https://github.com/USER/REPO/actions/workflows/ci.yml/badge.svg)](https://github.com/USER/REPO/actions)\n[![Coverage](https://img.shields.io/badge/Coverage-XX%25-brightgreen)](reports/)\n[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://python.org)\n\n&gt; Breve descripci\u00f3n del proyecto en una l\u00ednea.\n\n## \ud83c\udfaf M\u00e9tricas del Modelo\n\n| M\u00e9trica | Valor |\n|---------|-------|\n| Accuracy | XX% |\n| F1-Score | X.XX |\n| Coverage | XX% |\n\n## \u26a1 Quick Start\n\n```bash\n# Clonar\ngit clone https://github.com/USER/REPO.git\ncd REPO\n\n# Instalar\npip install -e \".[dev]\"\n\n# Entrenar\nmake train\n\n# Tests\nmake test\n\n# Servir API\nmake serve\n\\`\\`\\`\n\n## \ud83d\udcc1 Estructura\n\n\\`\\`\\`\nproyecto/\n\u251c\u2500\u2500 src/proyecto/      # C\u00f3digo fuente\n\u251c\u2500\u2500 app/               # APIs\n\u251c\u2500\u2500 tests/             # Tests\n\u251c\u2500\u2500 configs/           # Configuraci\u00f3n\n\u2514\u2500\u2500 artifacts/         # Modelos (gitignored)\n\\`\\`\\`\n\n## \ud83d\udcd6 Documentaci\u00f3n\n\n- [Model Card](docs/model_card.md)\n- [API Reference](docs/api.md)\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#2-template-pyprojecttoml","title":"\ud83d\udcc4 2. Template pyproject.toml","text":"<pre><code>[build-system]\nrequires = [\"setuptools&gt;=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"mi-proyecto\"\nversion = \"1.0.0\"\ndescription = \"Descripci\u00f3n del proyecto\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.10\"\nlicense = {text = \"MIT\"}\n\ndependencies = [\n    \"pandas&gt;=2.0.0\",\n    \"numpy&gt;=1.24.0\",\n    \"scikit-learn&gt;=1.3.0\",\n    \"pydantic&gt;=2.0.0\",\n    \"pyyaml&gt;=6.0\",\n]\n\n[project.optional-dependencies]\napi = [\"fastapi&gt;=0.104.0\", \"uvicorn&gt;=0.24.0\"]\ndev = [\"pytest&gt;=7.4.0\", \"pytest-cov&gt;=4.1.0\", \"black&gt;=23.0.0\", \"ruff&gt;=0.1.0\"]\nall = [\"mi-proyecto[api,dev]\"]\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\naddopts = \"-v --cov=src/\"\n\n[tool.coverage.run]\nsource = [\"src\"]\n\n[tool.coverage.report]\nfail_under = 80\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#3-template-dockerfile","title":"\ud83d\udcc4 3. Template Dockerfile","text":"<pre><code># Stage 1: Builder\nFROM python:3.11-slim AS builder\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --target=/deps -r requirements.txt\n\n# Stage 2: Runtime\nFROM python:3.11-slim\nRUN useradd --create-home appuser\nWORKDIR /app\nCOPY --from=builder /deps /usr/local/lib/python3.11/site-packages/\nCOPY --chown=appuser:appuser src/ ./src/\nCOPY --chown=appuser:appuser app/ ./app/\nCOPY --chown=appuser:appuser artifacts/ ./artifacts/\nUSER appuser\nEXPOSE 8000\nHEALTHCHECK --interval=30s --timeout=3s CMD curl -f http://localhost:8000/health || exit 1\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#4-template-github-actions","title":"\ud83d\udcc4 4. Template GitHub Actions","text":"<pre><code>name: CI\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: ['3.11', '3.12']\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Install dependencies\n        run: pip install -e \".[dev]\"\n\n      - name: Lint\n        run: ruff check src/ tests/\n\n      - name: Test\n        run: pytest --cov=src/ --cov-fail-under=80\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#5-template-conftestpy","title":"\ud83d\udcc4 5. Template conftest.py","text":"<pre><code>import pytest\nimport pandas as pd\nimport numpy as np\n\n@pytest.fixture\ndef sample_data():\n    np.random.seed(42)\n    return pd.DataFrame({\n        'feature1': np.random.randn(100),\n        'feature2': np.random.randn(100),\n        'target': np.random.randint(0, 2, 100)\n    })\n\n@pytest.fixture\ndef config():\n    return {\n        'model': {'n_estimators': 10, 'random_state': 42},\n        'data': {'test_size': 0.2}\n    }\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#6-template-model-card","title":"\ud83d\udcc4 6. Template Model Card","text":"<pre><code># Model Card: [Nombre del Modelo]\n\n## Informaci\u00f3n General\n- **Desarrollador**: [Tu nombre]\n- **Fecha**: [Fecha]\n- **Versi\u00f3n**: 1.0.0\n- **Tipo**: Clasificaci\u00f3n binaria\n\n## Uso Previsto\n- **Usuarios**: [Qui\u00e9n usar\u00e1 el modelo]\n- **Casos de uso**: [Para qu\u00e9 se usar\u00e1]\n\n## M\u00e9tricas\n| M\u00e9trica | Train | Test |\n|---------|-------|------|\n| Accuracy | X% | X% |\n| Precision | X% | X% |\n| Recall | X% | X% |\n| F1 | X% | X% |\n\n## Limitaciones\n- [Limitaci\u00f3n 1]\n- [Limitaci\u00f3n 2]\n\n## Consideraciones \u00c9ticas\n- [Consideraci\u00f3n 1]\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#7-template-gitignore","title":"\ud83d\udcc4 7. Template .gitignore","text":"<pre><code># Python\n__pycache__/\n*.py[cod]\n*.egg-info/\ndist/\nbuild/\n\n# Environments\n.venv/\nvenv/\n\n# Data &amp; Models\ndata/\nartifacts/\n*.joblib\nmlruns/\n\n# IDE\n.vscode/\n.idea/\n\n# Coverage\n.coverage\nhtmlcov/\n\n# Env\n.env\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#8-template-makefile","title":"\ud83d\udcc4 8. Template Makefile","text":"<pre><code>.PHONY: install test lint train serve clean\n\ninstall:\npip install -e \".[dev]\"\n\ntest:\npytest --cov=src/ --cov-fail-under=80\n\nlint:\nruff check src/ tests/\nblack --check src/ tests/\n\nformat:\nblack src/ tests/\nruff check --fix src/ tests/\n\ntrain:\npython -m src.proyecto.training\n\nserve:\nuvicorn app.fastapi_app:app --reload --port 8000\n\nclean:\nrm -rf __pycache__ .pytest_cache .coverage htmlcov\n</code></pre>"},{"location":"docs/apoyo/PLANTILLAS/#modulos-que-usan-estas-plantillas","title":"\ud83d\udcda M\u00f3dulos que Usan Estas Plantillas","text":"Plantilla M\u00f3dulo README, pyproject, Makefile 03_ESTRUCTURA_PROYECTO.md GitHub Actions 12_CI_CD.md Dockerfile 13_DOCKER.md Model Card 19_DOCUMENTACION.md   [\u2190 Volver al \u00cdndice](../00_INDICE.md) | [templates/](../templates/index.md)"},{"location":"docs/apoyo/RECURSOS/","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":""},{"location":"docs/apoyo/RECURSOS/#modulo-23-recursos-y-referencias","title":"M\u00d3DULO 23: RECURSOS Y REFERENCIAS","text":""},{"location":"docs/apoyo/RECURSOS/#links-cursos-y-comunidades","title":"Links, Cursos y Comunidades","text":""},{"location":"docs/apoyo/RECURSOS/#guia-mlops-v20-duqueom-noviembre-2025","title":"Gu\u00eda MLOps v2.0 | DuqueOM | Noviembre 2025","text":""},{"location":"docs/apoyo/RECURSOS/#_2","title":"\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550","text":"# \ud83d\udd17 M\u00d3DULO 23: Recursos y Referencias  **Links, Cursos y Comunidades**  *\"El aprendizaje nunca termina.\"*  | Nivel         | Duraci\u00f3n   | |:-------------:|:----------:| | \ud83d\udcda Referencia | Consulta   |"},{"location":"docs/apoyo/RECURSOS/#recursos-recomendados","title":"\ud83d\udcda Recursos Recomendados","text":"<p>Esta lista contiene los recursos m\u00e1s valiosos para profundizar en cada \u00e1rea de MLOps.</p> <p>\ud83d\udcfa \u00bfBuscas recursos espec\u00edficos por m\u00f3dulo? Ver RECURSOS.md para videos, cursos y documentaci\u00f3n curados para cada m\u00f3dulo con sistema de clasificaci\u00f3n \ud83d\udd34\ud83d\udfe1\ud83d\udfe2.</p> <p>Adem\u00e1s de estos recursos externos, revisa tambi\u00e9n los recursos internos de esta gu\u00eda: PLANTILLAS.md, GUIA_AUDIOVISUAL.md y los scripts <code>generate_pdfs.py</code> / <code>generate_audio.py</code> para exportar la gu\u00eda a PDF y audio.</p>"},{"location":"docs/apoyo/RECURSOS/#cursos-y-programas","title":"\ud83c\udf93 Cursos y Programas","text":""},{"location":"docs/apoyo/RECURSOS/#mlops-fundamentales","title":"MLOps Fundamentales","text":"Recurso Tipo Nivel Costo Made With ML Curso Intermedio Gratis Full Stack Deep Learning Curso Avanzado Gratis MLOps Zoomcamp Bootcamp Intermedio Gratis Coursera MLOps Specialization Especializaci\u00f3n Intermedio Pagado"},{"location":"docs/apoyo/RECURSOS/#herramientas-especificas","title":"Herramientas Espec\u00edficas","text":"Herramienta Recurso Oficial MLflow Docs DVC Docs FastAPI Tutorial Docker Docs Kubernetes Docs GitHub Actions Docs"},{"location":"docs/apoyo/RECURSOS/#libros","title":"\ud83d\udcd6 Libros","text":""},{"location":"docs/apoyo/RECURSOS/#esenciales","title":"Esenciales","text":"T\u00edtulo Autor Tema Designing Machine Learning Systems Chip Huyen MLOps end-to-end Building Machine Learning Pipelines Hapke &amp; Nelson Pipelines con TFX Machine Learning Engineering Andriy Burkov Pr\u00e1cticas de ML Reliable Machine Learning Cathy Chen et al. ML en producci\u00f3n"},{"location":"docs/apoyo/RECURSOS/#python-y-software-engineering","title":"Python y Software Engineering","text":"T\u00edtulo Autor Tema Fluent Python Luciano Ramalho Python avanzado Clean Code Robert C. Martin C\u00f3digo limpio The Pragmatic Programmer Hunt &amp; Thomas Buenas pr\u00e1cticas"},{"location":"docs/apoyo/RECURSOS/#blogs-y-articulos","title":"\ud83d\udd17 Blogs y Art\u00edculos","text":""},{"location":"docs/apoyo/RECURSOS/#blogs-de-empresas","title":"Blogs de Empresas","text":"Empresa Blog Foco Netflix Tech Blog ML a escala Uber Engineering Blog ML en tiempo real Airbnb Tech Blog Feature stores Spotify Engineering Blog Recomendaciones Google AI Blog Investigaci\u00f3n aplicada"},{"location":"docs/apoyo/RECURSOS/#articulos-fundamentales","title":"Art\u00edculos Fundamentales","text":"<ol> <li>Model Cards</li> <li>Model Cards for Model Reporting - Mitchell et al.</li> <li> <p>Hugging Face Model Cards Guide</p> </li> <li> <p>MLOps</p> </li> <li>Hidden Technical Debt in ML Systems - Google</li> <li> <p>Continuous Delivery for ML</p> </li> <li> <p>Testing ML</p> </li> <li>Testing ML Systems - Jeremy Jordan</li> <li>Effective Testing for ML</li> </ol>"},{"location":"docs/apoyo/RECURSOS/#herramientas-por-categoria","title":"\ud83d\udee0\ufe0f Herramientas por Categor\u00eda","text":""},{"location":"docs/apoyo/RECURSOS/#tracking-de-experimentos","title":"Tracking de Experimentos","text":"Herramienta Tipo URL MLflow Open Source mlflow.org Weights &amp; Biases SaaS wandb.ai Neptune SaaS neptune.ai Comet SaaS comet.ml DVC Open Source dvc.org"},{"location":"docs/apoyo/RECURSOS/#feature-stores","title":"Feature Stores","text":"Herramienta Tipo URL Feast Open Source feast.dev Tecton SaaS tecton.ai Hopsworks H\u00edbrido hopsworks.ai"},{"location":"docs/apoyo/RECURSOS/#monitoreo-de-modelos","title":"Monitoreo de Modelos","text":"Herramienta Tipo URL Evidently Open Source evidentlyai.com WhyLabs SaaS whylabs.ai Arize SaaS arize.com NannyML Open Source nannyml.com"},{"location":"docs/apoyo/RECURSOS/#cicd-para-ml","title":"CI/CD para ML","text":"Herramienta Tipo URL GitHub Actions SaaS github.com/features/actions GitLab CI SaaS/Self docs.gitlab.com/ee/ci/ CML Open Source cml.dev Kubeflow Pipelines Open Source kubeflow.org"},{"location":"docs/apoyo/RECURSOS/#serving-de-modelos","title":"Serving de Modelos","text":"Herramienta Tipo URL FastAPI Open Source fastapi.tiangolo.com BentoML Open Source bentoml.com Seldon Open Source seldon.io TensorFlow Serving Open Source tensorflow.org/tfx/guide/serving Triton Open Source developer.nvidia.com/triton-inference-server"},{"location":"docs/apoyo/RECURSOS/#videos-y-charlas","title":"\ud83d\udcfa Videos y Charlas","text":""},{"location":"docs/apoyo/RECURSOS/#conferencias","title":"Conferencias","text":"Conferencia Foco URL MLOps World MLOps mlopsworld.com ML Conf ML Engineering mlconf.com PyData Python + Data pydata.org KubeCon Kubernetes kubecon.io"},{"location":"docs/apoyo/RECURSOS/#charlas-recomendadas","title":"Charlas Recomendadas","text":"<ol> <li>MLOps Overview</li> <li>Practical MLOps - Stanford</li> <li> <p>ML Engineering at Google</p> </li> <li> <p>Testing ML</p> </li> <li> <p>Testing ML Systems - PyCon</p> </li> <li> <p>Production ML</p> </li> <li>ML at Scale - Netflix</li> </ol>"},{"location":"docs/apoyo/RECURSOS/#repositorios-de-referencia","title":"\ud83d\udc19 Repositorios de Referencia","text":""},{"location":"docs/apoyo/RECURSOS/#plantillas-y-ejemplos","title":"Plantillas y Ejemplos","text":"Repositorio Descripci\u00f3n cookiecutter-data-science Plantilla de proyectos DS mlops-python-package Plantilla MLOps made-with-ml Curso completo mlops-zoomcamp Bootcamp MLOps"},{"location":"docs/apoyo/RECURSOS/#proyectos-de-referencia","title":"Proyectos de Referencia","text":"Repositorio Destacado DuqueOM/ML-MLOps-Portfolio Este portafolio kedro Framework de pipelines feast Feature store evidently Monitoreo de drift"},{"location":"docs/apoyo/RECURSOS/#cheat-sheets","title":"\ud83d\udccb Cheat Sheets","text":""},{"location":"docs/apoyo/RECURSOS/#git","title":"Git","text":"<ul> <li>Git Cheat Sheet (GitHub)</li> <li>Git Flow</li> </ul>"},{"location":"docs/apoyo/RECURSOS/#docker","title":"Docker","text":"<ul> <li>Docker Cheat Sheet</li> <li>Docker Compose</li> </ul>"},{"location":"docs/apoyo/RECURSOS/#kubernetes","title":"Kubernetes","text":"<ul> <li>kubectl Cheat Sheet</li> </ul>"},{"location":"docs/apoyo/RECURSOS/#python","title":"Python","text":"<ul> <li>Python Cheat Sheet</li> <li>Pandas Cheat Sheet</li> </ul>"},{"location":"docs/apoyo/RECURSOS/#rutas-de-aprendizaje","title":"\ud83c\udfaf Rutas de Aprendizaje","text":""},{"location":"docs/apoyo/RECURSOS/#ruta-principiante-2-3-meses","title":"Ruta Principiante (2-3 meses)","text":"<pre><code>1. Python b\u00e1sico \u2192 intermedio\n2. Git y GitHub\n3. pandas y sklearn\n4. pytest b\u00e1sico\n5. Docker fundamentals\n</code></pre>"},{"location":"docs/apoyo/RECURSOS/#ruta-intermedia-3-4-meses","title":"Ruta Intermedia (3-4 meses)","text":"<pre><code>1. Pipelines sklearn avanzados\n2. MLflow tracking\n3. DVC para datos\n4. FastAPI\n5. GitHub Actions CI/CD\n6. Testing completo\n</code></pre>"},{"location":"docs/apoyo/RECURSOS/#ruta-avanzada-4-6-meses","title":"Ruta Avanzada (4-6 meses)","text":"<pre><code>1. Kubernetes\n2. Terraform / IaC\n3. Feature stores\n4. Monitoreo de drift\n5. A/B testing\n6. Auto-retraining\n</code></pre>"},{"location":"docs/apoyo/RECURSOS/#comunidades","title":"\ud83d\udcec Comunidades","text":""},{"location":"docs/apoyo/RECURSOS/#discordslack","title":"Discord/Slack","text":"Comunidad Foco URL MLOps Community MLOps mlops.community DataTalks.Club Data Engineering datatalks.club Locally Optimistic Data Teams locallyoptimistic.com"},{"location":"docs/apoyo/RECURSOS/#reddit","title":"Reddit","text":"<ul> <li>r/MachineLearning</li> <li>r/learnmachinelearning</li> <li>r/datascience</li> <li>r/MLOps</li> </ul>"},{"location":"docs/apoyo/RECURSOS/#twitterx","title":"Twitter/X","text":"<p>Cuentas recomendadas: - @ChipHuyen - @kaboroevich - @eugeneyan - @sh_reya</p>"},{"location":"docs/apoyo/RECURSOS/#herramientas-de-productividad","title":"\ud83d\udd27 Herramientas de Productividad","text":"Herramienta Uso URL Notion Documentaci\u00f3n notion.so Obsidian Notas obsidian.md Excalidraw Diagramas excalidraw.com Mermaid Diagramas en c\u00f3digo mermaid.js.org"},{"location":"docs/apoyo/RECURSOS/#datasets-para-practicar","title":"\ud83d\udcca Datasets para Practicar","text":"Dataset Tipo URL Kaggle Variado kaggle.com/datasets UCI ML Repository Cl\u00e1sicos archive.ics.uci.edu/ml Hugging Face Datasets NLP/CV huggingface.co/datasets Google Dataset Search B\u00fasqueda datasetsearch.research.google.com"},{"location":"docs/apoyo/RECURSOS/#mantente-actualizado","title":"\ud83d\udcc5 Mantente Actualizado","text":""},{"location":"docs/apoyo/RECURSOS/#newsletters","title":"Newsletters","text":"Newsletter Foco Frecuencia The Batch AI General Semanal MLOps Community MLOps Semanal Data Elixir Data Science Semanal Python Weekly Python Semanal"},{"location":"docs/apoyo/RECURSOS/#podcasts","title":"Podcasts","text":"Podcast Foco MLOps Coffee Sessions MLOps Practical AI ML aplicado Data Engineering Podcast Data infra Talk Python To Me Python   ### Recursos Relacionados  | Recurso | Descripci\u00f3n | |---------|-------------| | \ud83d\udcfa [RECURSOS.md](RECURSOS.md) | Videos y cursos espec\u00edficos para cada m\u00f3dulo | | \ud83d\udccb [PLANTILLAS.md](PLANTILLAS.md) | Templates reutilizables |  ### Navegaci\u00f3n  | \u25c0\ufe0f Anterior                        | \ud83d\udcd1 \u00cdndice               | \ud83c\udfaf Final             | |:-----------------------------------|:----------------------:|:--------------------| | [CHECKLIST.md](CHECKLIST.md) | [\u00cdndice](../00_INDICE.md) | \ud83c\udf89 \u00a1Gu\u00eda Completada! |  ---  *\u00a9 2025 DuqueOM - Gu\u00eda MLOps v3.0*  **M\u00f3dulo 23 Completado** \u2705  **\ud83c\udf89 \u00a1FELICITACIONES! Has completado toda la gu\u00eda MLOps.**"},{"location":"docs/apoyo/RUBRICA_EVALUACION/","title":"\ud83d\udcca R\u00fabrica de Evaluaci\u00f3n \u2014 Portfolio MLOps","text":"<p>Criterios profesionales para evaluar proyectos ML</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#puntuacion-total-100-puntos","title":"\ud83c\udfaf Puntuaci\u00f3n Total: 100 puntos","text":"Rango Nivel Descripci\u00f3n 90-100 Staff/Principal Listo para liderar equipos ML 80-89 Senior Production-ready, contrataci\u00f3n inmediata 70-79 Mid-Level S\u00f3lido, necesita pulir detalles 60-69 Junior+ Funcional, falta madurez &lt;60 En desarrollo Requiere m\u00e1s trabajo"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#criterios-de-evaluacion","title":"\ud83d\udccb Criterios de Evaluaci\u00f3n","text":""},{"location":"docs/apoyo/RUBRICA_EVALUACION/#1-calidad-del-codigo-20-puntos","title":"1. Calidad del C\u00f3digo (20 puntos)","text":"Aspecto Puntos Criterio Type hints 5 100% de funciones p\u00fablicas tipadas Docstrings 3 Todas las clases y funciones documentadas Pydantic configs 4 Configuraci\u00f3n validada, no dicts crudos src/ layout 4 Estructura profesional instalable SOLID principles 4 C\u00f3digo modular y extensible <p>Ejemplo 5/5 en type hints: <pre><code>def predict(self, features: pd.DataFrame) -&gt; np.ndarray:\n    \"\"\"Generate predictions for input features.\"\"\"\n    return self.model.predict(features)\n</code></pre></p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#2-pipeline-ml-20-puntos","title":"2. Pipeline ML (20 puntos)","text":"Aspecto Puntos Criterio sklearn Pipeline 6 Pipeline unificado (no pasos sueltos) ColumnTransformer 4 Preprocessing organizado Custom Transformer 4 Al menos 1 transformer propio Data leakage prevention 4 drop_columns correcto, sin target leak Reproducibilidad 2 random_state fijado <p>Ejemplo 6/6 en Pipeline: <pre><code>pipe = Pipeline([\n    (\"features\", FeatureEngineer()),\n    (\"preprocess\", ColumnTransformer([...])),\n    (\"model\", RandomForestClassifier())\n])\n</code></pre></p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#3-testing-y-cicd-20-puntos","title":"3. Testing y CI/CD (20 puntos)","text":"Aspecto Puntos Criterio Coverage \u226580% 6 Medido con pytest-cov Unit tests 4 Tests de funciones individuales Integration tests 4 Tests de pipeline completo GitHub Actions 4 CI autom\u00e1tico en cada push Security scanning 2 Bandit, pip-audit, o similar <p>Ejemplo 6/6 en Coverage: <pre><code># ci.yml\n- name: Test with coverage\n  run: pytest --cov=src/ --cov-fail-under=80\n</code></pre></p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#4-containerizacion-y-apis-15-puntos","title":"4. Containerizaci\u00f3n y APIs (15 puntos)","text":"Aspecto Puntos Criterio Dockerfile multi-stage 4 Build y runtime separados Non-root user 2 Seguridad b\u00e1sica FastAPI schemas 4 Pydantic request/response Health endpoint 2 /health funcional Error handling 3 Respuestas HTTP correctas"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#5-experiment-tracking-10-puntos","title":"5. Experiment Tracking (10 puntos)","text":"Aspecto Puntos Criterio MLflow logging 4 Params, metrics, artifacts Model Registry 3 Modelo registrado con versi\u00f3n Comparaci\u00f3n experimentos 3 M\u00faltiples runs comparables"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#6-documentacion-15-puntos","title":"6. Documentaci\u00f3n (15 puntos)","text":"Aspecto Puntos Criterio README profesional 5 Badges, quickstart, arquitectura Model Card 4 Performance, limitaciones, uso Docstrings 3 C\u00f3digo autodocumentado ADRs 3 Decisiones t\u00e9cnicas explicadas"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#checklist-rapido-por-proyecto","title":"\ud83d\udcca Checklist R\u00e1pido por Proyecto","text":""},{"location":"docs/apoyo/RUBRICA_EVALUACION/#bankchurn-predictor","title":"BankChurn-Predictor","text":"<ul> <li>[ ] Pipeline con ResampleClassifier</li> <li>[ ] Coverage \u226579%</li> <li>[ ] MLflow tracking</li> <li>[ ] FastAPI /predict endpoint</li> <li>[ ] Dockerfile funcional</li> </ul>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#carvision-market-intelligence","title":"CarVision-Market-Intelligence","text":"<ul> <li>[ ] FeatureEngineer custom transformer</li> <li>[ ] Coverage \u226580%</li> <li>[ ] Streamlit dashboard</li> <li>[ ] drop_columns para evitar leakage</li> </ul>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#telecomai-customer-intelligence","title":"TelecomAI-Customer-Intelligence","text":"<ul> <li>[ ] Pipeline sklearn completo</li> <li>[ ] Coverage \u226580%</li> <li>[ ] M\u00faltiples modelos comparados</li> <li>[ ] API funcional</li> </ul>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#niveles-de-certificacion","title":"\ud83c\udfc6 Niveles de Certificaci\u00f3n","text":"Nivel Puntuaci\u00f3n Badge MLOps Practitioner 70-79 \ud83e\udd49 MLOps Engineer 80-89 \ud83e\udd48 Senior MLOps Engineer 90-94 \ud83e\udd47 Staff MLOps Engineer 95-100 \ud83d\udc8e"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#evaluacion-por-modulo","title":"\ud83d\udcda Evaluaci\u00f3n por M\u00f3dulo","text":"<p>Sistema de autoevaluaci\u00f3n para cada fase del programa.</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#fase-1-fundamentos-modulos-01-06","title":"Fase 1: Fundamentos (M\u00f3dulos 01-06)","text":"M\u00f3dulo Criterio de Aprobaci\u00f3n Ejercicio Requerido 01 Type hints en 100% funciones, config Pydantic 1.1, 1.2 02 Diagrama C4 de un proyecto, ADR documentado 2.1 03 Proyecto con src/ layout instalable 3.1 04 requirements.txt + lockfile, .env funcional 4.1 05 pre-commit configurado, commits convencionales 5.1 06 DVC pipeline funcional, remote configurado 6.1 <p>Checkpoint Fase 1: Proyecto con estructura profesional, versionado con DVC</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#fase-2-ml-engineering-modulos-07-10","title":"Fase 2: ML Engineering (M\u00f3dulos 07-10)","text":"M\u00f3dulo Criterio de Aprobaci\u00f3n Ejercicio Requerido 07 Pipeline sklearn unificado, ColumnTransformer 7.1, 7.2 08 Custom Transformer (FeatureEngineer o similar) 8.1 09 Clase Trainer con fit/predict, cross-validation 9.1 10 MLflow tracking: params, metrics, artifacts 10.1 <p>Checkpoint Fase 2: Modelo entrenado con pipeline unificado, experimentos en MLflow</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#fase-3-mlops-core-modulos-11-16","title":"Fase 3: MLOps Core (M\u00f3dulos 11-16)","text":"M\u00f3dulo Criterio de Aprobaci\u00f3n Ejercicio Requerido 11 Tests con \u226580% coverage, conftest.py 11.1, 11.2 12 GitHub Actions CI funcionando en cada push 12.1 13 Dockerfile multi-stage, non-root user 13.1 (\u219217.1) 14 FastAPI /predict + /health, schemas Pydantic 14.1, 14.2 15 Dashboard Streamlit funcional 15.1 16 Logging JSON estructurado 16.1 <p>Checkpoint Fase 3: API dockerizada con CI/CD verde, \u226580% coverage</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#fase-4-produccion-modulos-17-18","title":"Fase 4: Producci\u00f3n (M\u00f3dulos 17-18)","text":"M\u00f3dulo Criterio de Aprobaci\u00f3n Ejercicio Requerido 17 Docker Compose con API + MLflow + Prometheus 17.2 18 K8s Deployment con probes, HPA configurado 18.1, 18.2 <p>Checkpoint Fase 4: Stack completo desplegable en K8s local</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#fase-5-especializacion-modulos-19-23","title":"Fase 5: Especializaci\u00f3n (M\u00f3dulos 19-23)","text":"M\u00f3dulo Criterio de Aprobaci\u00f3n Ejercicio Requerido 19 Model Card + Dataset Card completados 19.1, 19.2 20 Script E2E funcionando 20.1 21 Flashcards revisadas, t\u00e9rminos dominados 21.1 22 Auditor\u00eda de proyecto completada 22.1 23 Plan de estudio personalizado 23.1 <p>Checkpoint Fase 5: Portafolio documentado, listo para entrevistas</p>"},{"location":"docs/apoyo/RUBRICA_EVALUACION/#autoevaluacion-rapida","title":"\ud83c\udfaf Autoevaluaci\u00f3n R\u00e1pida","text":"<p>Completa esta tabla honestamente para identificar tus gaps:</p> <pre><code>| Competencia | 1-5 | Gap? | Recurso |\n|-------------|:---:|:----:|---------|\n| Type hints + Pydantic | _ | | M\u00f3dulo 01 |\n| sklearn Pipeline | _ | | M\u00f3dulo 07 |\n| Testing (pytest) | _ | | M\u00f3dulo 11 |\n| GitHub Actions | _ | | M\u00f3dulo 12 |\n| Docker | _ | | M\u00f3dulo 13, 17 |\n| FastAPI | _ | | M\u00f3dulo 14 |\n| MLflow | _ | | M\u00f3dulo 10 |\n| Observabilidad | _ | | M\u00f3dulo 16 |\n| Kubernetes | _ | | M\u00f3dulo 18 |\n</code></pre> <p>\ud83d\udcfa Ver RECURSOS.md para videos y cursos seg\u00fan tus gaps</p>   [\u2190 Volver al \u00cdndice](../00_INDICE.md) | [Apoyo](index.md) | [Recursos Externos](RECURSOS.md)"},{"location":"docs/study_tools/","title":"\ud83d\udcda Herramientas de Estudio","text":"<p>Este directorio contiene recursos pedag\u00f3gicos dise\u00f1ados para maximizar tu aprendizaje y prevenir bloqueos durante el estudio de la gu\u00eda MLOps.</p>"},{"location":"docs/study_tools/#proposito","title":"\ud83c\udfaf Prop\u00f3sito","text":"<p>Las herramientas de estudio te ayudan a:</p> <ul> <li>Estructurar tu proceso de aprendizaje</li> <li>Documentar errores y soluciones para referencia futura</li> <li>Reflexionar sobre tu progreso semanal</li> <li>Desbloquear situaciones de atasco de forma sistem\u00e1tica</li> </ul>"},{"location":"docs/study_tools/#recursos-disponibles","title":"\ud83d\udcc4 Recursos Disponibles","text":"Herramienta Prop\u00f3sito Cu\u00e1ndo Usar Protocolo E Sistema de rescate cognitivo cuando te atoras Cuando llevas &gt;15 min sin avanzar Diario de Errores Registro sistem\u00e1tico de errores y soluciones Cada vez que resuelves un problema no trivial Cierre Semanal Reflexi\u00f3n y planificaci\u00f3n semanal Al final de cada semana de estudio"},{"location":"docs/study_tools/#flujo-recomendado","title":"\ud83d\udd04 Flujo Recomendado","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CICLO DE ESTUDIO SEMANAL                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502   LUNES-VIERNES                         FIN DE SEMANA           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502   \u2502   Estudiar   \u2502                     \u2502    Cierre    \u2502         \u2502\n\u2502   \u2502   M\u00f3dulo     \u2502                     \u2502   Semanal    \u2502         \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502          \u2502                                                      \u2502\n\u2502          \u25bc                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                              \u2502\n\u2502   \u2502  \u00bfAtascado   \u2502\u2500\u2500S\u00ed\u2500\u2500\u25b6 Protocolo E                          \u2502\n\u2502   \u2502   &gt;15 min?   \u2502                                              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                              \u2502\n\u2502          \u2502 No                                                   \u2502\n\u2502          \u25bc                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                              \u2502\n\u2502   \u2502  \u00bfResolviste \u2502\u2500\u2500S\u00ed\u2500\u2500\u25b6 Diario de Errores                    \u2502\n\u2502   \u2502   un error?  \u2502                                              \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                              \u2502\n\u2502          \u2502 No                                                   \u2502\n\u2502          \u25bc                                                      \u2502\n\u2502      Continuar                                                  \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/study_tools/#tips-de-uso","title":"\ud83d\udca1 Tips de Uso","text":"<ol> <li> <p>No subestimes el Diario de Errores: Los errores que documentas hoy son las soluciones instant\u00e1neas de ma\u00f1ana.</p> </li> <li> <p>El Protocolo E no es rendirse: Es un sistema para desbloquear de forma inteligente. Usarlo es una se\u00f1al de madurez, no de debilidad.</p> </li> <li> <p>El Cierre Semanal es obligatorio: 15-20 minutos de reflexi\u00f3n pueden ahorrarte horas de trabajo mal dirigido.</p> </li> <li> <p>S\u00e9 honesto contigo mismo: Estas herramientas solo funcionan si las usas con sinceridad.</p> </li> </ol>"},{"location":"docs/study_tools/#navegacion","title":"\ud83d\udd17 Navegaci\u00f3n","text":"<ul> <li>\u2190 Volver al \u00cdndice Principal</li> <li>\u2192 Protocolo E</li> </ul>"},{"location":"docs/study_tools/CIERRE_SEMANAL/","title":"\ud83d\udcc5 Cierre Semanal","text":"<p>15-20 minutos de reflexi\u00f3n que pueden ahorrarte horas de trabajo mal dirigido.</p>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#proposito","title":"\ud83c\udfaf Prop\u00f3sito","text":"<p>El Cierre Semanal es tu ritual de:</p> <ol> <li>Consolidaci\u00f3n: \u00bfQu\u00e9 aprend\u00ed realmente esta semana?</li> <li>Diagn\u00f3stico: \u00bfD\u00f3nde tuve problemas y por qu\u00e9?</li> <li>Planificaci\u00f3n: \u00bfQu\u00e9 es lo m\u00e1s importante para la pr\u00f3xima semana?</li> <li>Celebraci\u00f3n: \u00bfQu\u00e9 logros merezco reconocer?</li> </ol>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#plantilla-de-cierre-semanal","title":"\ud83d\udccb Plantilla de Cierre Semanal","text":"<pre><code># Cierre Semanal - Semana [N] ([FECHA])\n\n## \ud83d\udcca M\u00e9tricas de la Semana\n\n| M\u00e9trica | Valor |\n|---------|-------|\n| Horas de estudio | |\n| M\u00f3dulos completados | |\n| Ejercicios realizados | |\n| Errores documentados | |\n| Protocolos E activados | |\n\n---\n\n## \u2705 Logros de la Semana\n\n### Conceptos dominados\n- [ ] \n- [ ] \n- [ ] \n\n### Artefactos producidos\n- [ ] \n- [ ] \n\n### Habilidades practicadas\n- [ ] \n- [ ] \n\n---\n\n## \ud83d\udea7 Desaf\u00edos Encontrados\n\n### 1. [Desaf\u00edo principal]\n- **Qu\u00e9 pas\u00f3:** \n- **C\u00f3mo lo resolv\u00ed:** \n- **Qu\u00e9 aprend\u00ed:** \n\n### 2. [Otro desaf\u00edo]\n- **Qu\u00e9 pas\u00f3:** \n- **C\u00f3mo lo resolv\u00ed:** \n- **Qu\u00e9 aprend\u00ed:** \n\n---\n\n## \ud83e\udd14 Reflexiones\n\n### \u00bfQu\u00e9 funcion\u00f3 bien?\n\n\n### \u00bfQu\u00e9 no funcion\u00f3?\n\n\n### \u00bfQu\u00e9 har\u00eda diferente?\n\n\n---\n\n## \ud83d\udcda Conexiones con el Portafolio\n\n### Artefactos del portafolio que ahora entiendo mejor:\n- [ ] \n- [ ] \n\n### C\u00f3digo del portafolio que puedo replicar:\n- [ ] \n- [ ] \n\n### Gaps que a\u00fan tengo:\n- [ ] \n- [ ] \n\n---\n\n## \ud83c\udfaf Plan para la Pr\u00f3xima Semana\n\n### Objetivo principal:\n\n\n### M\u00f3dulos a cubrir:\n- [ ] \n- [ ] \n\n### Entregables esperados:\n- [ ] \n- [ ] \n\n### Tiempo estimado:\n- Lunes: X horas\n- Martes: X horas\n- Mi\u00e9rcoles: X horas\n- Jueves: X horas\n- Viernes: X horas\n- **Total:** X horas\n\n---\n\n## \ud83c\udf1f Celebraci\u00f3n\n\n### Un logro del que estoy orgulloso:\n\n\n### Una cosa que me sorprendi\u00f3 positivamente:\n\n\n---\n\n## \ud83d\udcdd Notas adicionales\n</code></pre>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#proceso-de-cierre-20-min","title":"\ud83d\udd04 Proceso de Cierre (20 min)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FLUJO DE CIERRE SEMANAL                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502   PASO 1 (5 min)           PASO 2 (5 min)                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502   \u2502   Revisar    \u2502         \u2502   Revisar    \u2502                     \u2502\n\u2502   \u2502   Commits    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   Diario de  \u2502                    \u2502\n\u2502   \u2502   de la      \u2502         \u2502   Errores    \u2502                     \u2502\n\u2502   \u2502   semana     \u2502         \u2502              \u2502                     \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                                   \u2502                             \u2502\n\u2502                                   \u25bc                             \u2502\n\u2502   PASO 4 (5 min)           PASO 3 (5 min)                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u2502\n\u2502   \u2502   Planificar \u2502         \u2502   Completar  \u2502                     \u2502\n\u2502   \u2502   pr\u00f3xima    \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502   plantilla  \u2502                     \u2502\n\u2502   \u2502   semana     \u2502         \u2502   de cierre  \u2502                     \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2502\n\u2502                                                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#paso-1-revisar-commits-5-min","title":"Paso 1: Revisar Commits (5 min)","text":"<pre><code># Ver qu\u00e9 hiciste esta semana\ngit log --oneline --since=\"1 week ago\"\n\n# Ver archivos modificados\ngit diff --stat HEAD~10\n</code></pre>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#paso-2-revisar-diario-de-errores-5-min","title":"Paso 2: Revisar Diario de Errores (5 min)","text":"<ul> <li>\u00bfCu\u00e1ntos errores documentaste?</li> <li>\u00bfHay patrones?</li> <li>\u00bfQu\u00e9 herramientas te dieron m\u00e1s problemas?</li> </ul>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#paso-3-completar-plantilla-5-min","title":"Paso 3: Completar Plantilla (5 min)","text":"<p>Usa la plantilla de arriba. No te saltes ninguna secci\u00f3n.</p>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#paso-4-planificar-proxima-semana-5-min","title":"Paso 4: Planificar Pr\u00f3xima Semana (5 min)","text":"<ul> <li>Define UN objetivo principal (no tres, UNO)</li> <li>Lista entregables concretos y verificables</li> <li>Estima tiempo realista</li> </ul>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#preguntas-de-reflexion","title":"\ud83d\udcca Preguntas de Reflexi\u00f3n","text":""},{"location":"docs/study_tools/CIERRE_SEMANAL/#sobre-el-aprendizaje","title":"Sobre el aprendizaje","text":"<ol> <li>\u00bfPuedo explicar los conceptos de esta semana a alguien m\u00e1s?</li> <li>\u00bfQu\u00e9 parte del portafolio entiendo mejor ahora?</li> <li>\u00bfQu\u00e9 conexiones hice entre m\u00f3dulos diferentes?</li> </ol>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#sobre-la-productividad","title":"Sobre la productividad","text":"<ol> <li>\u00bfCu\u00e1nto tiempo perd\u00ed en distracciones?</li> <li>\u00bfCu\u00e1ntas veces activ\u00e9 el Protocolo E?</li> <li>\u00bfMi estimaci\u00f3n de tiempo fue realista?</li> </ol>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#sobre-el-proceso","title":"Sobre el proceso","text":"<ol> <li>\u00bfEstoy siguiendo la ruta del syllabus o me desvi\u00e9?</li> <li>\u00bfEstoy documentando suficiente en el Diario de Errores?</li> <li>\u00bfMis entregables son verificables?</li> </ol>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#tracking-de-progreso","title":"\ud83d\udcc8 Tracking de Progreso","text":""},{"location":"docs/study_tools/CIERRE_SEMANAL/#vista-mensual","title":"Vista Mensual","text":"<pre><code>| Semana | M\u00f3dulos | Horas | Errores | Logro Principal |\n|--------|---------|-------|---------|-----------------|\n| 1      |         |       |         |                 |\n| 2      |         |       |         |                 |\n| 3      |         |       |         |                 |\n| 4      |         |       |         |                 |\n</code></pre>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#vista-trimestral-fase","title":"Vista Trimestral (Fase)","text":"<pre><code>## Fase: [Nombre de la fase]\n\n**Objetivo de la fase:** \n\n**Progreso:**\n- [ ] M\u00f3dulo X\n- [ ] M\u00f3dulo Y\n- [ ] M\u00f3dulo Z\n\n**Entregables principales:**\n- [ ] \n- [ ] \n\n**Estado:** \ud83d\udfe2 En track | \ud83d\udfe1 Atrasado | \ud83d\udd34 Bloqueado\n</code></pre>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#indicadores-de-exito","title":"\ud83c\udfaf Indicadores de \u00c9xito","text":""},{"location":"docs/study_tools/CIERRE_SEMANAL/#semana-exitosa","title":"\ud83d\udfe2 Semana Exitosa","text":"<ul> <li>Completaste el objetivo principal</li> <li>Produjiste al menos un artefacto verificable</li> <li>Documentaste errores en el Diario</li> <li>No te quedaste bloqueado m\u00e1s de 1 hora</li> </ul>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#semana-aceptable","title":"\ud83d\udfe1 Semana Aceptable","text":"<ul> <li>Avanzaste en el objetivo pero no completaste</li> <li>Tuviste algunos bloqueos largos</li> <li>Aprendiste algo nuevo</li> </ul>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#semana-problematica","title":"\ud83d\udd34 Semana Problem\u00e1tica","text":"<ul> <li>No avanzaste en el objetivo</li> <li>M\u00faltiples bloqueos sin resolver</li> <li>No documentaste errores</li> <li>Tiempo de estudio muy por debajo de lo planeado</li> </ul> <p>Nota: Una semana \ud83d\udd34 no es un fracaso. Es informaci\u00f3n. \u00dasala para ajustar tu plan.</p>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#tips-para-un-cierre-efectivo","title":"\ud83d\udca1 Tips para un Cierre Efectivo","text":"<ol> <li>Hazlo siempre el mismo d\u00eda (ej: domingo por la tarde)</li> <li>No lo saltes aunque haya sido una mala semana</li> <li>S\u00e9 honesto contigo mismo</li> <li>Celebra los peque\u00f1os logros</li> <li>Comparte tu progreso si tienes un grupo de estudio</li> </ol>"},{"location":"docs/study_tools/CIERRE_SEMANAL/#navegacion","title":"\ud83d\udd17 Navegaci\u00f3n","text":"<ul> <li>\u2190 Volver a Herramientas de Estudio</li> <li>\u2190 Protocolo E</li> <li>\u2190 Diario de Errores</li> <li>\u2192 Volver al \u00cdndice Principal</li> </ul>"},{"location":"docs/study_tools/DIARIO_ERRORES/","title":"\ud83d\udcd3 Diario de Errores","text":"<p>Tu base de conocimiento personal de problemas resueltos.</p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#proposito","title":"\ud83c\udfaf Prop\u00f3sito","text":"<p>El Diario de Errores es tu segundo cerebro para debugging. Cada error que documentas hoy es una soluci\u00f3n instant\u00e1nea ma\u00f1ana.</p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#beneficios","title":"Beneficios","text":"<ol> <li>Evita resolver el mismo problema dos veces</li> <li>Acelera tu debugging con patrones reconocibles</li> <li>Demuestra tu crecimiento como ingeniero</li> <li>Material para entrevistas: \"Cu\u00e9ntame de un bug dif\u00edcil que resolviste\"</li> </ol>"},{"location":"docs/study_tools/DIARIO_ERRORES/#formato-de-entrada","title":"\ud83d\udccb Formato de Entrada","text":"<p><pre><code>---\n## [FECHA] - [T\u00edtulo descriptivo]\n\n**M\u00f3dulo:** [N\u00famero y nombre del m\u00f3dulo]\n**Herramientas:** [Python, Docker, MLflow, etc.]\n**Tiempo para resolver:** [X minutos/horas]\n**Severidad:** \ud83d\udfe2 Menor | \ud83d\udfe1 Moderado | \ud83d\udd34 Bloqueante\n\n### S\u00edntoma\n[\u00bfQu\u00e9 comportamiento observaste?]\n\n### Error exacto\n</code></pre> [Pegar mensaje de error completo] <pre><code>### Causa ra\u00edz\n[\u00bfPor qu\u00e9 ocurri\u00f3 realmente?]\n\n### Soluci\u00f3n\n```bash\n# Comandos o c\u00f3digo que lo resolvieron\n</code></pre></p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#prevencion","title":"Prevenci\u00f3n","text":"<p>[\u00bfC\u00f3mo evitar que vuelva a pasar?]</p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#tags","title":"Tags","text":"<p><code>#docker</code> <code>#mlflow</code> <code>#python</code> <code>#permisos</code> <code>#dependencias</code></p> <p><pre><code>---\n\n## \ud83d\udcda Ejemplos de Entradas\n\n### Ejemplo 1: Error de Docker\n\n```markdown\n---\n## 2024-01-15 - Container no encuentra m\u00f3dulo Python\n\n**M\u00f3dulo:** 13_DOCKER\n**Herramientas:** Docker, Python, pip\n**Tiempo para resolver:** 45 minutos\n**Severidad:** \ud83d\udd34 Bloqueante\n\n### S\u00edntoma\nLa API funciona localmente pero falla en Docker con ModuleNotFoundError.\n\n### Error exacto\n</code></pre> Traceback (most recent call last):   File \"/app/main.py\", line 3, in      from sklearn.ensemble import RandomForestClassifier ModuleNotFoundError: No module named 'sklearn' <pre><code>### Causa ra\u00edz\nEl Dockerfile instalaba desde `requirements.txt` pero `scikit-learn` \nestaba en `pyproject.toml` como dependencia opcional.\n\n### Soluci\u00f3n\n```dockerfile\n# Antes (incorrecto)\nRUN pip install -r requirements.txt\n\n# Despu\u00e9s (correcto)\nRUN pip install -e \".[all]\"\n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#prevencion_1","title":"Prevenci\u00f3n","text":"<ul> <li>Siempre verificar que las dependencias del Dockerfile coincidan con el entorno local</li> <li>Usar <code>pip freeze &gt; requirements.txt</code> despu\u00e9s de instalar localmente</li> <li>A\u00f1adir test de smoke en CI que importe los m\u00f3dulos principales</li> </ul>"},{"location":"docs/study_tools/DIARIO_ERRORES/#tags_1","title":"Tags","text":"<p><code>#docker</code> <code>#python</code> <code>#dependencias</code> <code>#sklearn</code></p> <p><pre><code>### Ejemplo 2: Error de MLflow\n\n```markdown\n---\n## 2024-01-20 - MLflow no registra modelo en Registry\n\n**M\u00f3dulo:** 10_EXPERIMENT_TRACKING\n**Herramientas:** MLflow, PostgreSQL\n**Tiempo para resolver:** 30 minutos\n**Severidad:** \ud83d\udfe1 Moderado\n\n### S\u00edntoma\n`mlflow.sklearn.log_model()` funciona pero `mlflow.register_model()` falla.\n\n### Error exacto\n</code></pre> mlflow.exceptions.MlflowException: Model registry functionality  is unavailable; got unsupported URI './mlruns' for model registry <pre><code>### Causa ra\u00edz\nModel Registry requiere backend de base de datos (PostgreSQL/MySQL), \nno funciona con el backend de archivos por defecto.\n\n### Soluci\u00f3n\n```bash\n# Iniciar MLflow con backend de PostgreSQL\nmlflow server \\\n    --backend-store-uri postgresql://user:pass@localhost/mlflow \\\n    --default-artifact-root ./mlruns \\\n    --host 0.0.0.0\n</code></pre></p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#prevencion_2","title":"Prevenci\u00f3n","text":"<ul> <li>Leer la documentaci\u00f3n de Model Registry antes de usarlo</li> <li>Usar docker-compose con PostgreSQL desde el inicio</li> <li>A\u00f1adir check de conexi\u00f3n a DB en scripts de setup</li> </ul>"},{"location":"docs/study_tools/DIARIO_ERRORES/#tags_2","title":"Tags","text":"<p><code>#mlflow</code> <code>#model-registry</code> <code>#postgresql</code> <code>#configuracion</code></p> <p><pre><code>### Ejemplo 3: Error de Git/Pre-commit\n\n```markdown\n---\n## 2024-01-25 - Pre-commit bloquea commits\n\n**M\u00f3dulo:** 05_GIT_PROFESIONAL\n**Herramientas:** Git, pre-commit, Black\n**Tiempo para resolver:** 15 minutos\n**Severidad:** \ud83d\udfe2 Menor\n\n### S\u00edntoma\nNo puedo hacer commit, Black reformatea archivos infinitamente.\n\n### Error exacto\n</code></pre> black....................................................................Failed - hook id: black - files were modified by this hook</p> <p>reformatted src/model.py</p> <p>All done! \u2728 \ud83c\udf70 \u2728 1 file reformatted. <pre><code>### Causa ra\u00edz\nBlack reformatea el archivo, pero pre-commit no a\u00f1ade los cambios \nautom\u00e1ticamente, as\u00ed que el siguiente intento vuelve a reformatear.\n\n### Soluci\u00f3n\n```bash\n# Ejecutar Black primero, luego a\u00f1adir cambios\nblack src/\ngit add -u\ngit commit -m \"mensaje\"\n\n# O hacer commit en dos pasos\ngit commit -m \"mensaje\"  # falla y reformatea\ngit add -u               # a\u00f1adir cambios de Black\ngit commit -m \"mensaje\"  # ahora funciona\n</code></pre></p>"},{"location":"docs/study_tools/DIARIO_ERRORES/#prevencion_3","title":"Prevenci\u00f3n","text":"<ul> <li>Ejecutar <code>pre-commit run --all-files</code> antes del primer commit</li> <li>Configurar IDE para formatear con Black al guardar</li> <li>Usar <code>pre-commit install --hook-type pre-commit</code></li> </ul>"},{"location":"docs/study_tools/DIARIO_ERRORES/#tags_3","title":"Tags","text":"<p><code>#git</code> <code>#pre-commit</code> <code>#black</code> <code>#formateo</code></p> <pre><code>---\n\n## \ud83d\udd0d C\u00f3mo Buscar en tu Diario\n\n### Por Tags\n```bash\n# Buscar todos los errores de Docker\ngrep -l \"#docker\" DIARIO_ERRORES.md\n\n# Buscar errores bloqueantes\ngrep -B5 \"\ud83d\udd34 Bloqueante\" DIARIO_ERRORES.md\n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#por-modulo","title":"Por M\u00f3dulo","text":"<pre><code>grep -A20 \"M\u00f3dulo: 13_DOCKER\" DIARIO_ERRORES.md\n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#por-herramienta","title":"Por Herramienta","text":"<pre><code>grep -B2 -A20 \"MLflow\" DIARIO_ERRORES.md\n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#estadisticas-utiles","title":"\ud83d\udcca Estad\u00edsticas \u00datiles","text":"<p>Al final de cada mes, revisa:</p> <pre><code>## Resumen Mensual - [MES]\n\n**Total de errores documentados:** X\n**Tiempo total de debugging:** X horas\n**Error m\u00e1s com\u00fan:** [descripci\u00f3n]\n**Herramienta m\u00e1s problem\u00e1tica:** [nombre]\n**M\u00f3dulo m\u00e1s desafiante:** [n\u00famero]\n\n### Top 3 aprendizajes del mes:\n1. \n2. \n3. \n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#tu-diario-empieza-aqui","title":"\ud83d\ude80 Tu Diario Empieza Aqu\u00ed","text":"<pre><code>---\n## [FECHA] - [Tu primer error]\n\n**M\u00f3dulo:** \n**Herramientas:** \n**Tiempo para resolver:** \n**Severidad:** \ud83d\udfe2 Menor | \ud83d\udfe1 Moderado | \ud83d\udd34 Bloqueante\n\n### S\u00edntoma\n\n\n### Error exacto\n</code></pre> <pre><code>### Causa ra\u00edz\n\n\n### Soluci\u00f3n\n</code></pre> <pre><code>### Prevenci\u00f3n\n\n\n### Tags\n\n\n---\n</code></pre>"},{"location":"docs/study_tools/DIARIO_ERRORES/#navegacion","title":"\ud83d\udd17 Navegaci\u00f3n","text":"<ul> <li>\u2190 Volver a Herramientas de Estudio</li> <li>\u2190 Protocolo E</li> <li>\u2192 Cierre Semanal</li> </ul>"},{"location":"docs/study_tools/PROTOCOLO_E/","title":"\ud83c\udd98 Protocolo E: Sistema de Rescate Cognitivo","text":"<p>\"E\" = Emergencia, Error, Estancamiento</p> <p>Cuando llevas m\u00e1s de 15 minutos atascado en un problema sin avanzar, es momento de activar el Protocolo E.</p>"},{"location":"docs/study_tools/PROTOCOLO_E/#objetivo","title":"\ud83c\udfaf Objetivo","text":"<p>Convertir un bloqueo frustrante en una oportunidad de aprendizaje estructurado, evitando:</p> <ul> <li>P\u00e9rdida de tiempo en loops improductivos</li> <li>Frustraci\u00f3n que lleva al abandono</li> <li>Soluciones \"parche\" que no ense\u00f1an nada</li> </ul>"},{"location":"docs/study_tools/PROTOCOLO_E/#el-protocolo-5-pasos","title":"\ud83d\udccb El Protocolo (5 pasos)","text":""},{"location":"docs/study_tools/PROTOCOLO_E/#paso-1-parar-1-minuto","title":"Paso 1: PARAR (1 minuto)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  \ud83d\uded1 ALTO TOTAL                                                 \u2502\n\u2502                                                                 \u2502\n\u2502  - Quita las manos del teclado                                  \u2502\n\u2502  - Respira profundo 3 veces                                     \u2502\n\u2502  - Reconoce: \"Estoy atascado y eso est\u00e1 bien\"                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#paso-2-documentar-3-5-minutos","title":"Paso 2: DOCUMENTAR (3-5 minutos)","text":"<p>Escribe en tu Diario de Errores:</p> <pre><code>## [FECHA] - [M\u00f3dulo/Tema]\n\n### \u00bfQu\u00e9 intentaba hacer?\n[Descripci\u00f3n clara del objetivo]\n\n### \u00bfQu\u00e9 esperaba que pasara?\n[Resultado esperado]\n\n### \u00bfQu\u00e9 pas\u00f3 en realidad?\n[Resultado actual, error, comportamiento inesperado]\n\n### \u00bfQu\u00e9 ya intent\u00e9?\n- [ ] Intento 1: ...\n- [ ] Intento 2: ...\n- [ ] Intento 3: ...\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#paso-3-reducir-5-minutos","title":"Paso 3: REDUCIR (5 minutos)","text":"<p>Simplifica el problema al m\u00ednimo reproducible:</p> T\u00e9cnica Ejemplo Aislar Si falla en un pipeline, \u00bffalla en un script simple? Reducir datos \u00bfFalla con 10 filas? \u00bfCon 1 fila? Eliminar dependencias \u00bfFalla sin Docker? \u00bfSin la base de datos? Hardcodear \u00bfFalla si pongo valores fijos en vez de variables? <pre><code># Ejemplo de reducci\u00f3n\n# En vez de debuggear todo el pipeline:\nimport pandas as pd\ndf = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})\n# Probar SOLO la operaci\u00f3n que falla\nresult = df.groupby('a').sum()  # \u00bfEsto funciona?\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#paso-4-buscar-10-15-minutos","title":"Paso 4: BUSCAR (10-15 minutos)","text":"<p>Sigue este orden de b\u00fasqueda:</p> <ol> <li>Mensaje de error exacto \u2192 Google/StackOverflow</li> <li>Documentaci\u00f3n oficial de la herramienta</li> <li>Issues de GitHub del proyecto/librer\u00eda</li> <li>Este curso (busca en otros m\u00f3dulos, glosario, FAQ)</li> </ol> <pre><code># Tip: Busca el error exacto entre comillas\n\"ModuleNotFoundError: No module named 'sklearn'\"\n\n# A\u00f1ade contexto relevante\n\"MLflow FileNotFoundError artifact\" site:stackoverflow.com\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#paso-5-escalar-si-todo-lo-anterior-falla","title":"Paso 5: ESCALAR (si todo lo anterior falla)","text":"Opci\u00f3n Cu\u00e1ndo Pregunta estructurada Foros, Discord, StackOverflow Rubber duck debugging Explica el problema en voz alta Cambiar de contexto Trabaja en otro m\u00f3dulo 30 min y vuelve Pedir ayuda A un compa\u00f1ero, mentor, comunidad <p>Formato para preguntas efectivas:</p> <pre><code>## Contexto\n- Estoy en el m\u00f3dulo X de la gu\u00eda MLOps\n- Sistema: Ubuntu 22.04 / Python 3.11 / Docker 24.x\n\n## Objetivo\nQuiero lograr [X]\n\n## Lo que hice\n1. Ejecut\u00e9 `comando`\n2. Esperaba ver [Y]\n3. En cambio, obtuve [Z]\n\n## Error completo\n[Pegar error completo, no resumido]\n\n## Lo que ya intent\u00e9\n- Intento 1: [resultado]\n- Intento 2: [resultado]\n\n## C\u00f3digo m\u00ednimo reproducible\n[C\u00f3digo que reproduce el error]\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#timeboxing-del-protocolo","title":"\u23f1\ufe0f Timeboxing del Protocolo","text":"Paso Tiempo m\u00e1ximo 1. PARAR 1 min 2. DOCUMENTAR 5 min 3. REDUCIR 5 min 4. BUSCAR 15 min 5. ESCALAR Variable TOTAL antes de escalar ~26 min <p>Si despu\u00e9s de 30 minutos no has resuelto el problema, ESCALA. No es rendirse, es ser eficiente.</p>"},{"location":"docs/study_tools/PROTOCOLO_E/#mentalidad-correcta","title":"\ud83e\udde0 Mentalidad Correcta","text":""},{"location":"docs/study_tools/PROTOCOLO_E/#mentalidad-improductiva","title":"\u274c Mentalidad improductiva","text":"<ul> <li>\"Deber\u00eda poder resolver esto solo\"</li> <li>\"Si pregunto van a pensar que soy tonto\"</li> <li>\"Voy a seguir intentando hasta que funcione\"</li> </ul>"},{"location":"docs/study_tools/PROTOCOLO_E/#mentalidad-productiva","title":"\u2705 Mentalidad productiva","text":"<ul> <li>\"Documentar me ayuda a pensar mejor\"</li> <li>\"Una buena pregunta demuestra que entiendo el problema\"</li> <li>\"Mi tiempo es valioso, saber cu\u00e1ndo escalar es una habilidad\"</li> </ul>"},{"location":"docs/study_tools/PROTOCOLO_E/#plantilla-rapida","title":"\ud83d\udcdd Plantilla R\u00e1pida","text":"<p>Copia y pega cuando actives el Protocolo E:</p> <pre><code>## \ud83c\udd98 Protocolo E - [FECHA]\n\n**M\u00f3dulo:** \n**Tiempo atascado:** \n\n### 1. \u00bfQu\u00e9 intentaba?\n\n### 2. \u00bfQu\u00e9 esperaba?\n\n### 3. \u00bfQu\u00e9 pas\u00f3?\n\n### 4. Intentos previos:\n- [ ] \n- [ ] \n- [ ] \n\n### 5. Problema reducido:\n\n### 6. B\u00fasquedas realizadas:\n- [ ] Google: \n- [ ] Docs oficiales: \n- [ ] GitHub Issues: \n\n### 7. Resoluci\u00f3n:\n[ ] Resuelto por m\u00ed | [ ] Escalado | [ ] Pendiente\n\n**Soluci\u00f3n:**\n\n**Aprendizaje:**\n</code></pre>"},{"location":"docs/study_tools/PROTOCOLO_E/#navegacion","title":"\ud83d\udd17 Navegaci\u00f3n","text":"<ul> <li>\u2190 Volver a Herramientas de Estudio</li> <li>\u2192 Diario de Errores</li> <li>\u2192 Cierre Semanal</li> </ul>"},{"location":"docs/templates/","title":"\ud83d\udcc1 Plantillas \u2014 Gu\u00eda MLOps v2","text":"<p>Plantillas reutilizables para proyectos ML/MLOps profesionales</p>"},{"location":"docs/templates/#indice-de-plantillas","title":"\ud83d\udccb \u00cdndice de Plantillas","text":""},{"location":"docs/templates/#documentacion-ml","title":"Documentaci\u00f3n ML","text":"Plantilla Descripci\u00f3n Uso Model Card Documentaci\u00f3n completa de un modelo ML Obligatorio para cada modelo en producci\u00f3n Dataset Card Documentaci\u00f3n de datasets Obligatorio para cada dataset"},{"location":"docs/templates/#cicd","title":"CI/CD","text":"Plantilla Descripci\u00f3n Uso GitHub Actions CI Pipeline CI/CD completo Base para proyectos nuevos CI Template (b\u00e1sico) Versi\u00f3n m\u00ednima de CI Quick start"},{"location":"docs/templates/#infraestructura","title":"Infraestructura","text":"Plantilla Descripci\u00f3n Uso Dockerfile Multi-stage para ML APIs Base para containerizaci\u00f3n Dockerfile Template Versi\u00f3n simplificada Quick start docker-compose.yml Stack completo con servicios Desarrollo local"},{"location":"docs/templates/#proyecto","title":"Proyecto","text":"Plantilla Descripci\u00f3n Uso pyproject.toml Configuraci\u00f3n de paquete Python Base para proyectos nuevos README Template README profesional Todos los proyectos Makefile Automatizaci\u00f3n de tareas Base para proyectos nuevos"},{"location":"docs/templates/#scripts","title":"Scripts","text":"Plantilla Descripci\u00f3n Uso run_demo.sh Script de demo del proyecto Presentaciones"},{"location":"docs/templates/#como-usar-las-plantillas","title":"\ud83c\udfaf C\u00f3mo Usar las Plantillas","text":""},{"location":"docs/templates/#1-copiar-la-plantilla","title":"1. Copiar la plantilla","text":"<pre><code># Copiar Model Card a tu proyecto\ncp templates/model_card_template.md docs/model_card.md\n\n# Copiar CI workflow\ncp templates/ci_github_actions.yml .github/workflows/ci.yml\n</code></pre>"},{"location":"docs/templates/#2-personalizar","title":"2. Personalizar","text":"<p>Reemplaza los placeholders <code>{placeholder}</code> con los valores de tu proyecto.</p>"},{"location":"docs/templates/#3-validar","title":"3. Validar","text":"<pre><code># Verificar sintaxis YAML\npython -c \"import yaml; yaml.safe_load(open('.github/workflows/ci.yml'))\"\n\n# Verificar Markdown\nmarkdownlint docs/model_card.md\n</code></pre>"},{"location":"docs/templates/#convenciones","title":"\ud83d\udcdd Convenciones","text":""},{"location":"docs/templates/#placeholders","title":"Placeholders","text":"Formato Ejemplo Descripci\u00f3n <code>{nombre}</code> <code>{model_name}</code> Campo obligatorio <code>{ej. valor}</code> <code>{ej. RandomForest}</code> Incluye ejemplo <code>{YYYY-MM-DD}</code> <code>{2024-01-15}</code> Formato de fecha"},{"location":"docs/templates/#secciones-opcionales","title":"Secciones Opcionales","text":"<p>Las secciones marcadas con <code>&lt;!-- OPCIONAL --&gt;</code> pueden eliminarse si no aplican.</p>"},{"location":"docs/templates/#checklist-de-uso","title":"\u2705 Checklist de Uso","text":"<ul> <li>[ ] Copi\u00e9 la plantilla correcta</li> <li>[ ] Reemplac\u00e9 todos los <code>{placeholders}</code></li> <li>[ ] Elimin\u00e9 secciones que no aplican</li> <li>[ ] Valid\u00e9 la sintaxis (YAML/Markdown)</li> <li>[ ] Revis\u00e9 que tenga sentido para mi proyecto</li> </ul>"},{"location":"docs/templates/#referencias","title":"\ud83d\udd17 Referencias","text":"<ul> <li>Model Cards for Model Reporting - Mitchell et al., 2019</li> <li>Datasheets for Datasets - Gebru et al., 2021</li> <li>GitHub Actions Documentation</li> <li>Docker Best Practices</li> </ul>"},{"location":"docs/templates/#modulos-relacionados","title":"\ud83d\udcda M\u00f3dulos Relacionados","text":"Plantilla M\u00f3dulo pyproject, README, Makefile 03_ESTRUCTURA_PROYECTO.md CI workflows 12_CI_CD.md Dockerfile, docker-compose 13_DOCKER.md Model Card, Dataset Card 19_DOCUMENTACION.md   [\u2190 \u00cdndice Principal](../00_INDICE.md) | [PLANTILLAS.md](../apoyo/PLANTILLAS.md)"},{"location":"docs/templates/README_TEMPLATE/","title":"\ud83d\ude80 [Nombre del Proyecto]","text":"<p>Breve descripci\u00f3n del proyecto.</p>"},{"location":"docs/templates/README_TEMPLATE/#metricas","title":"\ud83c\udfaf M\u00e9tricas","text":"M\u00e9trica Valor Accuracy XX% Coverage XX%"},{"location":"docs/templates/README_TEMPLATE/#quick-start","title":"\ud83d\ude80 Quick Start","text":"<pre><code>pip install -e \".[dev]\"\nmake train\nmake test\nmake serve\n</code></pre>"},{"location":"docs/templates/README_TEMPLATE/#estructura","title":"\ud83d\udcc1 Estructura","text":"<pre><code>proyecto/\n\u251c\u2500\u2500 src/proyecto/\n\u251c\u2500\u2500 app/\n\u251c\u2500\u2500 tests/\n\u2514\u2500\u2500 configs/\n</code></pre>"},{"location":"docs/templates/dataset_card_template/","title":"Dataset Card \u2014","text":"<p>Plantilla basada en Datasheets for Datasets (Gebru et al., 2021)</p>"},{"location":"docs/templates/dataset_card_template/#1-informacion-general","title":"1. Informaci\u00f3n General","text":"Campo Valor Nombre del dataset {dataset_name} Versi\u00f3n {version} Fecha de creaci\u00f3n {YYYY-MM-DD} Autor(es)/Fuente {nombre(s) o fuente} Licencia {CC BY 4.0/MIT/Propietaria/etc.} URL {URL del dataset si es p\u00fablico}"},{"location":"docs/templates/dataset_card_template/#2-motivacion","title":"2. Motivaci\u00f3n","text":""},{"location":"docs/templates/dataset_card_template/#21-por-que-se-creo-este-dataset","title":"2.1 \u00bfPor qu\u00e9 se cre\u00f3 este dataset?","text":"<p>{Explicar el prop\u00f3sito original del dataset en 2-3 oraciones}</p>"},{"location":"docs/templates/dataset_card_template/#22-quien-lo-creo-y-con-que-financiamiento","title":"2.2 \u00bfQui\u00e9n lo cre\u00f3 y con qu\u00e9 financiamiento?","text":"<ul> <li>Creadores: {Organizaci\u00f3n/Investigadores}</li> <li>Financiamiento: {Si aplica}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#23-que-tareas-soporta","title":"2.3 \u00bfQu\u00e9 tareas soporta?","text":"<ul> <li>{Tarea 1: ej. Clasificaci\u00f3n binaria de churn}</li> <li>{Tarea 2: ej. An\u00e1lisis exploratorio de clientes}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#3-composicion","title":"3. Composici\u00f3n","text":""},{"location":"docs/templates/dataset_card_template/#31-estadisticas-generales","title":"3.1 Estad\u00edsticas Generales","text":"M\u00e9trica Valor Registros totales {n} Features {n} Tama\u00f1o en disco {n} MB/GB Formato {CSV/Parquet/JSON}"},{"location":"docs/templates/dataset_card_template/#32-descripcion-de-features","title":"3.2 Descripci\u00f3n de Features","text":"Feature Tipo Descripci\u00f3n Ejemplo {feature_1} {int/float/str/bool} {descripci\u00f3n} {valor ejemplo} {feature_2} {int/float/str/bool} {descripci\u00f3n} {valor ejemplo} {feature_3} {int/float/str/bool} {descripci\u00f3n} {valor ejemplo} ... ... ... ..."},{"location":"docs/templates/dataset_card_template/#33-variable-target","title":"3.3 Variable Target","text":"Campo Valor Nombre {target_column} Tipo {Binaria/Multiclase/Continua} Distribuci\u00f3n {ej. 80% clase 0, 20% clase 1}"},{"location":"docs/templates/dataset_card_template/#34-valores-faltantes","title":"3.4 Valores Faltantes","text":"Feature % Missing Estrategia de imputaci\u00f3n {feature_1} {n}% {Media/Mediana/Moda/Eliminar} {feature_2} {n}% {Media/Mediana/Moda/Eliminar}"},{"location":"docs/templates/dataset_card_template/#35-contiene-datos-sensibles","title":"3.5 \u00bfContiene datos sensibles?","text":"<ul> <li>PII (Informaci\u00f3n Personal Identificable): {S\u00ed/No}</li> <li>Datos financieros: {S\u00ed/No}</li> <li>Datos de salud: {S\u00ed/No}</li> <li>Otros datos sensibles: {Describir si aplica}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#4-proceso-de-recoleccion","title":"4. Proceso de Recolecci\u00f3n","text":""},{"location":"docs/templates/dataset_card_template/#41-como-se-recolectaron-los-datos","title":"4.1 \u00bfC\u00f3mo se recolectaron los datos?","text":"<p>{Describir el proceso de recolecci\u00f3n: encuestas, logs, scraping, APIs, etc.}</p>"},{"location":"docs/templates/dataset_card_template/#42-periodo-de-recoleccion","title":"4.2 Per\u00edodo de Recolecci\u00f3n","text":"Campo Valor Fecha inicio {YYYY-MM-DD} Fecha fin {YYYY-MM-DD} Frecuencia {\u00danica/Diaria/Mensual/etc.}"},{"location":"docs/templates/dataset_card_template/#43-quien-recolecto-los-datos","title":"4.3 \u00bfQui\u00e9n recolect\u00f3 los datos?","text":"<p>{Organizaci\u00f3n, equipo, sistema automatizado}</p>"},{"location":"docs/templates/dataset_card_template/#44-mecanismos-de-validacion","title":"4.4 Mecanismos de Validaci\u00f3n","text":"<ul> <li>{Validaci\u00f3n 1: ej. Checks de integridad}</li> <li>{Validaci\u00f3n 2: ej. Revisi\u00f3n manual de muestras}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#5-preprocesamiento-y-limpieza","title":"5. Preprocesamiento y Limpieza","text":""},{"location":"docs/templates/dataset_card_template/#51-transformaciones-aplicadas","title":"5.1 Transformaciones Aplicadas","text":"<ol> <li>{Paso 1: ej. Eliminaci\u00f3n de duplicados}</li> <li>{Paso 2: ej. Normalizaci\u00f3n de fechas}</li> <li>{Paso 3: ej. Correcci\u00f3n de outliers}</li> </ol>"},{"location":"docs/templates/dataset_card_template/#52-se-guardaron-los-datos-crudos","title":"5.2 \u00bfSe guardaron los datos crudos?","text":"<ul> <li>Ubicaci\u00f3n: {ruta o \"No aplica\"}</li> <li>Acceso: {Restringido/P\u00fablico}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#53-software-usado","title":"5.3 Software Usado","text":"<ul> <li>{Herramienta 1: ej. pandas 2.0}</li> <li>{Herramienta 2: ej. Great Expectations}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#6-splits-de-datos","title":"6. Splits de Datos","text":""},{"location":"docs/templates/dataset_card_template/#61-division-para-ml","title":"6.1 Divisi\u00f3n para ML","text":"Split Registros % Estrategia Train {n} {%} {Random/Temporal/Stratified} Validation {n} {%} {Random/Temporal/Stratified} Test {n} {%} {Random/Temporal/Stratified}"},{"location":"docs/templates/dataset_card_template/#62-consideraciones-temporales","title":"6.2 Consideraciones Temporales","text":"<p>{Si los datos son temporales, describir c\u00f3mo se manej\u00f3 para evitar data leakage}</p>"},{"location":"docs/templates/dataset_card_template/#7-usos-del-dataset","title":"7. Usos del Dataset","text":""},{"location":"docs/templates/dataset_card_template/#71-usos-recomendados","title":"7.1 Usos Recomendados","text":"<ul> <li>{Uso 1: ej. Entrenamiento de modelos de clasificaci\u00f3n}</li> <li>{Uso 2: ej. An\u00e1lisis exploratorio}</li> <li>{Uso 3: ej. Benchmarking de algoritmos}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#72-usos-no-recomendados","title":"7.2 Usos NO Recomendados","text":"<ul> <li>{Uso 1: ej. No usar para decisiones automatizadas sin supervisi\u00f3n humana}</li> <li>{Uso 2: ej. No usar para inferir caracter\u00edsticas de poblaciones no representadas}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#73-ha-sido-usado-en-otros-trabajos","title":"7.3 \u00bfHa sido usado en otros trabajos?","text":"Trabajo Tipo Resultado {Paper/Proyecto 1} {Clasificaci\u00f3n} {AUC=0.85} {Paper/Proyecto 2} {Regresi\u00f3n} {RMSE=1.2}"},{"location":"docs/templates/dataset_card_template/#8-sesgos-y-limitaciones","title":"8. Sesgos y Limitaciones","text":""},{"location":"docs/templates/dataset_card_template/#81-sesgos-conocidos","title":"8.1 Sesgos Conocidos","text":"Sesgo Descripci\u00f3n Impacto {Sesgo 1} {descripci\u00f3n} {Alto/Medio/Bajo} {Sesgo 2} {descripci\u00f3n} {Alto/Medio/Bajo}"},{"location":"docs/templates/dataset_card_template/#82-limitaciones","title":"8.2 Limitaciones","text":"<ul> <li>{Limitaci\u00f3n 1: ej. Solo representa clientes de una regi\u00f3n geogr\u00e1fica}</li> <li>{Limitaci\u00f3n 2: ej. Datos de un per\u00edodo espec\u00edfico que puede no generalizar}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#83-grupos-subrepresentados","title":"8.3 Grupos Subrepresentados","text":"Grupo % en Dataset % en Poblaci\u00f3n Real {Grupo 1} {n}% {n}% {Grupo 2} {n}% {n}%"},{"location":"docs/templates/dataset_card_template/#9-consideraciones-eticas","title":"9. Consideraciones \u00c9ticas","text":""},{"location":"docs/templates/dataset_card_template/#91-contiene-informacion-que-pueda-identificar-individuos","title":"9.1 \u00bfContiene informaci\u00f3n que pueda identificar individuos?","text":"<p>{S\u00ed/No - si s\u00ed, describir qu\u00e9 informaci\u00f3n y c\u00f3mo se anonimiz\u00f3}</p>"},{"location":"docs/templates/dataset_card_template/#92-hay-consentimiento-de-los-sujetos","title":"9.2 \u00bfHay consentimiento de los sujetos?","text":"<p>{Describir el proceso de consentimiento o por qu\u00e9 no aplica}</p>"},{"location":"docs/templates/dataset_card_template/#93-puede-el-uso-del-dataset-causar-dano","title":"9.3 \u00bfPuede el uso del dataset causar da\u00f1o?","text":"<p>{Describir potenciales da\u00f1os y mitigaciones}</p>"},{"location":"docs/templates/dataset_card_template/#10-mantenimiento","title":"10. Mantenimiento","text":""},{"location":"docs/templates/dataset_card_template/#101-quien-mantiene-el-dataset","title":"10.1 \u00bfQui\u00e9n mantiene el dataset?","text":"Rol Nombre Contacto Responsable {nombre} {email} Soporte {equipo} {email/slack}"},{"location":"docs/templates/dataset_card_template/#102-con-que-frecuencia-se-actualiza","title":"10.2 \u00bfCon qu\u00e9 frecuencia se actualiza?","text":"<ul> <li>Frecuencia: {No se actualiza/Mensual/Trimestral/etc.}</li> <li>Pol\u00edtica de versiones: {Semver/Fecha/etc.}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#103-como-reportar-errores","title":"10.3 \u00bfC\u00f3mo reportar errores?","text":"<p>{Describir proceso: issue en GitHub, email, formulario}</p>"},{"location":"docs/templates/dataset_card_template/#11-distribucion","title":"11. Distribuci\u00f3n","text":""},{"location":"docs/templates/dataset_card_template/#111-como-se-distribuye","title":"11.1 \u00bfC\u00f3mo se distribuye?","text":"<ul> <li>Formato: {CSV/Parquet/API}</li> <li>Ubicaci\u00f3n: {URL/S3/GCS}</li> <li>Acceso: {P\u00fablico/Restringido/Con registro}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#112-licencia","title":"11.2 Licencia","text":"<ul> <li>Tipo: {CC BY 4.0/MIT/etc.}</li> <li>Restricciones: {Uso comercial permitido/Solo investigaci\u00f3n/etc.}</li> </ul>"},{"location":"docs/templates/dataset_card_template/#113-cita-recomendada","title":"11.3 Cita Recomendada","text":"<pre><code>@dataset{dataset_name,\n  author = {{autor}},\n  title = {{t\u00edtulo}},\n  year = {{a\u00f1o}},\n  url = {{url}}\n}\n</code></pre>"},{"location":"docs/templates/dataset_card_template/#12-changelog","title":"12. Changelog","text":"Versi\u00f3n Fecha Cambios {v1.0.0} {YYYY-MM-DD} Versi\u00f3n inicial {v1.1.0} {YYYY-MM-DD} {Descripci\u00f3n del cambio}"},{"location":"docs/templates/dataset_card_template/#referencias","title":"Referencias","text":"<ul> <li>{T\u00edtulo de referencia 1}</li> <li>{T\u00edtulo de referencia 2}</li> </ul> <p>\u00daltima actualizaci\u00f3n: {YYYY-MM-DD}</p>"},{"location":"docs/templates/model_card_template/","title":"Model Card \u2014","text":"<p>Plantilla basada en Model Cards for Model Reporting (Mitchell et al., 2019)</p>"},{"location":"docs/templates/model_card_template/#1-informacion-general","title":"1. Informaci\u00f3n General","text":"Campo Valor Nombre del modelo {model_name} Versi\u00f3n {version} Fecha de creaci\u00f3n {YYYY-MM-DD} Autor(es) {nombre(s)} Licencia {MIT/Apache 2.0/Propietaria} Repositorio {URL del repo}"},{"location":"docs/templates/model_card_template/#2-proposito-del-modelo","title":"2. Prop\u00f3sito del Modelo","text":""},{"location":"docs/templates/model_card_template/#21-objetivo-principal","title":"2.1 Objetivo Principal","text":"<p>{Describir el objetivo principal del modelo en 2-3 oraciones}</p>"},{"location":"docs/templates/model_card_template/#22-uso-previsto","title":"2.2 Uso Previsto","text":"<ul> <li>Contexto de uso: {Producci\u00f3n/Estimaci\u00f3n/POC/Investigaci\u00f3n}</li> <li>Usuarios objetivo: {Data Scientists/Analistas/Usuarios finales}</li> <li>Decisiones que informa: {Qu\u00e9 decisiones de negocio apoya}</li> </ul>"},{"location":"docs/templates/model_card_template/#23-usos-no-recomendados","title":"2.3 Usos NO Recomendados","text":"<ul> <li>{Caso de uso 1 donde NO usar el modelo}</li> <li>{Caso de uso 2 donde NO usar el modelo}</li> </ul>"},{"location":"docs/templates/model_card_template/#3-datos-de-entrenamiento","title":"3. Datos de Entrenamiento","text":""},{"location":"docs/templates/model_card_template/#31-fuente-de-datos","title":"3.1 Fuente de Datos","text":"Campo Valor Origen {Kaggle/Interno/API externa} Fecha de extracci\u00f3n {YYYY-MM-DD} Per\u00edodo cubierto {Desde-Hasta}"},{"location":"docs/templates/model_card_template/#32-estadisticas-del-dataset","title":"3.2 Estad\u00edsticas del Dataset","text":"M\u00e9trica Valor Registros totales {n} Features {n} Target {nombre de la columna target} Split Train/Val/Test {70/15/15 o el que aplique}"},{"location":"docs/templates/model_card_template/#33-preprocesamiento","title":"3.3 Preprocesamiento","text":"<ol> <li>{Paso 1: ej. Eliminaci\u00f3n de duplicados}</li> <li>{Paso 2: ej. Imputaci\u00f3n de valores nulos}</li> <li>{Paso 3: ej. Encoding de categor\u00edas}</li> <li>{Paso 4: ej. Normalizaci\u00f3n/Estandarizaci\u00f3n}</li> </ol>"},{"location":"docs/templates/model_card_template/#4-arquitectura-del-modelo","title":"4. Arquitectura del Modelo","text":""},{"location":"docs/templates/model_card_template/#41-tipo-de-modelo","title":"4.1 Tipo de Modelo","text":"<ul> <li>Algoritmo base: {RandomForest/XGBoost/LogisticRegression/etc.}</li> <li>Framework: {scikit-learn/TensorFlow/PyTorch}</li> <li>Pipeline: {S\u00ed/No - si s\u00ed, describir componentes}</li> </ul>"},{"location":"docs/templates/model_card_template/#42-hiperparametros-principales","title":"4.2 Hiperpar\u00e1metros Principales","text":"<pre><code># Hiperpar\u00e1metros del modelo final\n{hyperparameter_1}: {value}\n{hyperparameter_2}: {value}\n{hyperparameter_3}: {value}\n</code></pre>"},{"location":"docs/templates/model_card_template/#43-tecnicas-de-optimizacion","title":"4.3 T\u00e9cnicas de Optimizaci\u00f3n","text":"<ul> <li>B\u00fasqueda de hiperpar\u00e1metros: {GridSearch/RandomSearch/Bayesian/etc.}</li> <li>Validaci\u00f3n cruzada: {k-fold, k={n}}</li> <li>Criterio de selecci\u00f3n: {F1/AUC/RMSE/etc.}</li> </ul>"},{"location":"docs/templates/model_card_template/#5-metricas-de-rendimiento","title":"5. M\u00e9tricas de Rendimiento","text":""},{"location":"docs/templates/model_card_template/#51-metrica-principal","title":"5.1 M\u00e9trica Principal","text":"M\u00e9trica Train Validation Test {M\u00e9trica principal} {value} {value} {value}"},{"location":"docs/templates/model_card_template/#52-metricas-secundarias","title":"5.2 M\u00e9tricas Secundarias","text":"M\u00e9trica Train Validation Test Accuracy {value} {value} {value} Precision {value} {value} {value} Recall {value} {value} {value} F1-Score {value} {value} {value} AUC-ROC {value} {value} {value}"},{"location":"docs/templates/model_card_template/#53-matriz-de-confusion-test-set","title":"5.3 Matriz de Confusi\u00f3n (Test Set)","text":"<pre><code>              Predicted\n              Neg    Pos\nActual Neg    TN     FP\n       Pos    FN     TP\n</code></pre>"},{"location":"docs/templates/model_card_template/#6-analisis-de-sesgos-y-fairness","title":"6. An\u00e1lisis de Sesgos y Fairness","text":""},{"location":"docs/templates/model_card_template/#61-grupos-demograficos-analizados","title":"6.1 Grupos Demogr\u00e1ficos Analizados","text":"Grupo M\u00e9trica Valor {Grupo 1} {M\u00e9trica} {value} {Grupo 2} {M\u00e9trica} {value}"},{"location":"docs/templates/model_card_template/#62-sesgos-conocidos","title":"6.2 Sesgos Conocidos","text":"<ul> <li>Sesgo identificado 1: {Descripci\u00f3n y magnitud}</li> <li>Sesgo identificado 2: {Descripci\u00f3n y magnitud}</li> </ul>"},{"location":"docs/templates/model_card_template/#63-mitigaciones-aplicadas","title":"6.3 Mitigaciones Aplicadas","text":"<ul> <li>{Mitigaci\u00f3n 1: ej. Class weighting}</li> <li>{Mitigaci\u00f3n 2: ej. SMOTE para oversampling}</li> </ul>"},{"location":"docs/templates/model_card_template/#7-limitaciones","title":"7. Limitaciones","text":""},{"location":"docs/templates/model_card_template/#71-limitaciones-tecnicas","title":"7.1 Limitaciones T\u00e9cnicas","text":"<ul> <li>{Limitaci\u00f3n 1: ej. No funciona bien con datos fuera del rango de entrenamiento}</li> <li>{Limitaci\u00f3n 2: ej. Requiere features espec\u00edficos que pueden no estar disponibles}</li> </ul>"},{"location":"docs/templates/model_card_template/#72-limitaciones-eticas","title":"7.2 Limitaciones \u00c9ticas","text":"<ul> <li>{Limitaci\u00f3n 1: ej. Puede perpetuar sesgos hist\u00f3ricos en los datos}</li> <li>{Limitaci\u00f3n 2: ej. No debe usarse para decisiones que afecten derechos fundamentales}</li> </ul>"},{"location":"docs/templates/model_card_template/#73-casos-donde-no-usar","title":"7.3 Casos donde NO Usar","text":"<ul> <li>{Caso 1}</li> <li>{Caso 2}</li> </ul>"},{"location":"docs/templates/model_card_template/#8-consideraciones-de-despliegue","title":"8. Consideraciones de Despliegue","text":""},{"location":"docs/templates/model_card_template/#81-requisitos-de-infraestructura","title":"8.1 Requisitos de Infraestructura","text":"Recurso M\u00ednimo Recomendado CPU {n} cores {n} cores RAM {n} GB {n} GB Disco {n} GB {n} GB GPU {S\u00ed/No} {S\u00ed/No}"},{"location":"docs/templates/model_card_template/#82-latencia-esperada","title":"8.2 Latencia Esperada","text":"<ul> <li>Inferencia unitaria: {n} ms</li> <li>Batch (100 registros): {n} ms</li> </ul>"},{"location":"docs/templates/model_card_template/#83-dependencias-criticas","title":"8.3 Dependencias Cr\u00edticas","text":"<pre><code>{package_1}=={version}\n{package_2}=={version}\n{package_3}=={version}\n</code></pre>"},{"location":"docs/templates/model_card_template/#9-monitoreo-y-mantenimiento","title":"9. Monitoreo y Mantenimiento","text":""},{"location":"docs/templates/model_card_template/#91-metricas-a-monitorear","title":"9.1 M\u00e9tricas a Monitorear","text":"<ul> <li>{M\u00e9trica 1: ej. Prediction drift}</li> <li>{M\u00e9trica 2: ej. Feature drift}</li> <li>{M\u00e9trica 3: ej. Latencia de inferencia}</li> </ul>"},{"location":"docs/templates/model_card_template/#92-umbrales-de-alerta","title":"9.2 Umbrales de Alerta","text":"M\u00e9trica Umbral Warning Umbral Cr\u00edtico {M\u00e9trica 1} {value} {value} {M\u00e9trica 2} {value} {value}"},{"location":"docs/templates/model_card_template/#93-plan-de-reentrenamiento","title":"9.3 Plan de Reentrenamiento","text":"<ul> <li>Frecuencia: {Mensual/Trimestral/Por evento}</li> <li>Trigger: {Degradaci\u00f3n de m\u00e9tricas/Nuevo dataset/Cambio en distribuci\u00f3n}</li> <li>Responsable: {Nombre/Equipo}</li> </ul>"},{"location":"docs/templates/model_card_template/#10-versionamiento-y-artefactos","title":"10. Versionamiento y Artefactos","text":""},{"location":"docs/templates/model_card_template/#101-control-de-versiones","title":"10.1 Control de Versiones","text":"Item Referencia C\u00f3digo {commit hash o tag} Modelo serializado {ruta/modelo.pkl} MLflow Run ID {run_id} DVC Hash {hash}"},{"location":"docs/templates/model_card_template/#102-artefactos-generados","title":"10.2 Artefactos Generados","text":"<ul> <li><code>{ruta}/model.pkl</code> \u2014 Modelo serializado</li> <li><code>{ruta}/preprocessor.pkl</code> \u2014 Preprocesador</li> <li><code>{ruta}/metrics.json</code> \u2014 M\u00e9tricas de evaluaci\u00f3n</li> <li><code>{ruta}/feature_importance.csv</code> \u2014 Importancia de features</li> </ul>"},{"location":"docs/templates/model_card_template/#11-changelog","title":"11. Changelog","text":"Versi\u00f3n Fecha Cambios {v1.0.0} {YYYY-MM-DD} Versi\u00f3n inicial {v1.1.0} {YYYY-MM-DD} {Descripci\u00f3n del cambio}"},{"location":"docs/templates/model_card_template/#12-contacto-y-soporte","title":"12. Contacto y Soporte","text":"Rol Nombre Contacto Responsable t\u00e9cnico {nombre} {email} Responsable de negocio {nombre} {email} Soporte {equipo} {email/slack}"},{"location":"docs/templates/model_card_template/#referencias","title":"Referencias","text":"<ul> <li>{T\u00edtulo de referencia 1}</li> <li>{T\u00edtulo de referencia 2}</li> </ul> <p>\u00daltima actualizaci\u00f3n: {YYYY-MM-DD}</p>"},{"location":"exams/EXAM_01_SETUP/","title":"\ud83d\udccb Examen de Hito 1: Setup Profesional","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_01_SETUP/#instrucciones","title":"Instrucciones","text":"<p>Act\u00faa como un Senior MLOps Engineer haciendo code review. Tu tarea es: 1. Identificar TODOS los errores en el c\u00f3digo 2. Clasificar cada error por severidad (\ud83d\udd34 Cr\u00edtico, \ud83d\udfe1 Medio, \ud83d\udfe2 Menor) 3. Proponer la correcci\u00f3n</p>"},{"location":"exams/EXAM_01_SETUP/#ejercicio-1-type-hints-25-puntos","title":"Ejercicio 1: Type Hints (25 puntos)","text":""},{"location":"exams/EXAM_01_SETUP/#codigo-a-revisar","title":"C\u00f3digo a Revisar","text":"<pre><code># archivo: src/bankchurn/training.py\n\ndef load_data(path):\n    \"\"\"Carga datos desde CSV.\"\"\"\n    import pandas as pd\n    return pd.read_csv(path)\n\n\ndef prepare_features(df, target_col, features):\n    X = df[features]\n    y = df[target_col]\n    return X, y\n\n\ndef train_model(X, y, n_estimators=100, max_depth=None):\n    from sklearn.ensemble import RandomForestClassifier\n    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    model.fit(X, y)\n    return model\n\n\ndef evaluate(model, X_test, y_test):\n    from sklearn.metrics import accuracy_score, f1_score\n    predictions = model.predict(X_test)\n    return {\n        \"accuracy\": accuracy_score(y_test, predictions),\n        \"f1\": f1_score(y_test, predictions)\n    }\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#tu-respuesta","title":"Tu Respuesta","text":"<p>\u00bfCu\u00e1ntos problemas encontraste? Clasif\u00edcalos:</p> # L\u00ednea Problema Severidad Correcci\u00f3n 1 2 3 \ud83d\udcdd Ver Soluci\u00f3n (no abrir hasta terminar)  ### Errores Encontrados  | # | L\u00ednea | Problema | Severidad | Correcci\u00f3n | |---|-------|----------|-----------|------------| | 1 | 3 | `load_data(path)` sin type hints | \ud83d\udfe1 Medio | `def load_data(path: str \\| Path) -&gt; pd.DataFrame:` | | 2 | 4 | Import dentro de funci\u00f3n | \ud83d\udfe2 Menor | Mover imports al inicio del archivo | | 3 | 8 | `prepare_features` sin tipos | \ud83d\udfe1 Medio | A\u00f1adir `df: pd.DataFrame, target_col: str, features: list[str]` | | 4 | 8 | Retorno sin tipar | \ud83d\udfe1 Medio | `-&gt; Tuple[pd.DataFrame, pd.Series]` | | 5 | 14 | `train_model` sin tipo de retorno | \ud83d\udfe1 Medio | `-&gt; RandomForestClassifier` o `-&gt; BaseEstimator` | | 6 | 14 | `max_depth=None` sin `Optional[int]` | \ud83d\udfe2 Menor | `max_depth: Optional[int] = None` | | 7 | 21 | `evaluate` retorna `dict` sin tipar | \ud83d\udfe1 Medio | `-&gt; Dict[str, float]` o `TypedDict` |  ### C\u00f3digo Corregido  <pre><code># archivo: src/bankchurn/training.py\nfrom __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, Optional, Tuple, Sequence\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.base import BaseEstimator\n\n\ndef load_data(path: str | Path) -&gt; pd.DataFrame:\n    \"\"\"Carga datos desde CSV.\"\"\"\n    return pd.read_csv(path)\n\n\ndef prepare_features(\n    df: pd.DataFrame,\n    target_col: str,\n    features: Sequence[str]\n) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"Separa features y target.\"\"\"\n    X = df[list(features)]\n    y = df[target_col]\n    return X, y\n\n\ndef train_model(\n    X: pd.DataFrame,\n    y: pd.Series,\n    n_estimators: int = 100,\n    max_depth: Optional[int] = None\n) -&gt; RandomForestClassifier:\n    \"\"\"Entrena modelo Random Forest.\"\"\"\n    model = RandomForestClassifier(\n        n_estimators=n_estimators,\n        max_depth=max_depth,\n        random_state=42  # Reproducibilidad\n    )\n    model.fit(X, y)\n    return model\n\n\ndef evaluate(\n    model: BaseEstimator,\n    X_test: pd.DataFrame,\n    y_test: pd.Series\n) -&gt; Dict[str, float]:\n    \"\"\"Eval\u00faa modelo con m\u00e9tricas de clasificaci\u00f3n.\"\"\"\n    predictions = model.predict(X_test)\n    return {\n        \"accuracy\": float(accuracy_score(y_test, predictions)),\n        \"f1\": float(f1_score(y_test, predictions))\n    }\n</code></pre>  **Puntuaci\u00f3n**:  - 7 errores \u00d7 3 puntos = 21 puntos base - Correcciones correctas: +4 puntos - **Total**: 25/25"},{"location":"exams/EXAM_01_SETUP/#ejercicio-2-pydantic-config-25-puntos","title":"Ejercicio 2: Pydantic Config (25 puntos)","text":""},{"location":"exams/EXAM_01_SETUP/#codigo-a-revisar_1","title":"C\u00f3digo a Revisar","text":"<pre><code># archivo: src/bankchurn/config.py\n\nfrom pydantic import BaseModel\n\nclass Config(BaseModel):\n    test_size: float = 0.2\n    n_estimators: int = 100\n    max_depth: int = 10\n    random_state: int = 42\n    target: str = \"Exited\"\n    features: list = []\n\n    def load_from_yaml(self, path):\n        import yaml\n        with open(path) as f:\n            data = yaml.safe_load(f)\n        return Config(**data)\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#tu-respuesta_1","title":"Tu Respuesta","text":"# L\u00ednea Problema Severidad Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  ### Errores Encontrados  | # | L\u00ednea | Problema | Severidad | Correcci\u00f3n | |---|-------|----------|-----------|------------| | 1 | 6 | `test_size` sin validaci\u00f3n de rango | \ud83d\udd34 Cr\u00edtico | `Field(default=0.2, ge=0.01, le=0.5)` | | 2 | 7 | `n_estimators` sin rango m\u00ednimo | \ud83d\udfe1 Medio | `Field(default=100, ge=10)` | | 3 | 8 | `max_depth` deber\u00eda ser `Optional[int]` | \ud83d\udfe1 Medio | `max_depth: int \\| None = Field(default=10, ge=1)` | | 4 | 11 | `features: list` sin tipo gen\u00e9rico | \ud83d\udfe1 Medio | `features: list[str] = Field(default_factory=list)` | | 5 | 11 | `features: list = []` mutable default | \ud83d\udd34 Cr\u00edtico | Usar `Field(default_factory=list)` | | 6 | 13 | `load_from_yaml` deber\u00eda ser `@classmethod` | \ud83d\udfe1 Medio | Decorar con `@classmethod` | | 7 | 13 | Sin type hints en m\u00e9todo | \ud83d\udfe2 Menor | `def load_from_yaml(cls, path: Path) -&gt; \"Config\":` | | 8 | 14 | Import dentro de m\u00e9todo | \ud83d\udfe2 Menor | Mover al inicio |  ### C\u00f3digo Corregido  <pre><code>from __future__ import annotations\n\nfrom pathlib import Path\n\nimport yaml\nfrom pydantic import BaseModel, Field\n\n\nclass Config(BaseModel):\n    \"\"\"Configuraci\u00f3n del modelo con validaci\u00f3n.\"\"\"\n\n    test_size: float = Field(\n        default=0.2,\n        ge=0.01,\n        le=0.5,\n        description=\"Proporci\u00f3n de datos para test\"\n    )\n    n_estimators: int = Field(default=100, ge=10, le=1000)\n    max_depth: int | None = Field(default=10, ge=1)\n    random_state: int = 42\n    target: str = \"Exited\"\n    features: list[str] = Field(default_factory=list)\n\n    @classmethod\n    def load_from_yaml(cls, path: str | Path) -&gt; \"Config\":\n        \"\"\"Carga configuraci\u00f3n desde archivo YAML.\"\"\"\n        with open(path) as f:\n            data = yaml.safe_load(f)\n        return cls(**data)\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#ejercicio-3-estructura-de-proyecto-25-puntos","title":"Ejercicio 3: Estructura de Proyecto (25 puntos)","text":""},{"location":"exams/EXAM_01_SETUP/#estructura-a-revisar","title":"Estructura a Revisar","text":"<pre><code>myproject/\n\u251c\u2500\u2500 train.py\n\u251c\u2500\u2500 predict.py\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 model.pkl\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 train.csv\n\u2502   \u2514\u2500\u2500 test.csv\n\u251c\u2500\u2500 utils.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 test_train.py\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#tu-respuesta_2","title":"Tu Respuesta","text":"<p>Lista todos los problemas de estructura:</p> \ud83d\udcdd Ver Soluci\u00f3n  ### Problemas de Estructura  | # | Problema | Severidad | Soluci\u00f3n | |---|----------|-----------|----------| | 1 | Sin `src/` layout | \ud83d\udd34 Cr\u00edtico | Mover c\u00f3digo a `src/myproject/` | | 2 | Sin `pyproject.toml` | \ud83d\udd34 Cr\u00edtico | Crear archivo de metadata | | 3 | `model.pkl` en ra\u00edz | \ud83d\udfe1 Medio | Mover a `artifacts/` o `models/` | | 4 | Sin `__init__.py` | \ud83d\udfe1 Medio | Crear para hacer paquete | | 5 | `requirements.txt` en vez de pyproject.toml | \ud83d\udfe2 Menor | Migrar a pyproject.toml | | 6 | Sin `.gitignore` | \ud83d\udfe1 Medio | Crear con patrones comunes | | 7 | Sin `conftest.py` en tests | \ud83d\udfe2 Menor | Crear para fixtures | | 8 | `config.yaml` en ra\u00edz | \ud83d\udfe2 Menor | Mover a `configs/` |  ### Estructura Correcta  <pre><code>myproject/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 myproject/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 config.py\n\u2502       \u251c\u2500\u2500 training.py\n\u2502       \u251c\u2500\u2500 prediction.py\n\u2502       \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u2514\u2500\u2500 test_training.py\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 config.yaml\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 raw/\n\u2502   \u2514\u2500\u2500 processed/\n\u251c\u2500\u2500 artifacts/\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 .gitignore\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#ejercicio-4-pre-commit-25-puntos","title":"Ejercicio 4: Pre-commit (25 puntos)","text":""},{"location":"exams/EXAM_01_SETUP/#archivo-a-revisar","title":"Archivo a Revisar","text":"<pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.0.0\n    hooks:\n      - id: trailing-whitespace\n      - id: check-yaml\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#tu-respuesta_3","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 falta? Lista al menos 5 hooks importantes:</p> \ud83d\udcdd Ver Soluci\u00f3n  ### Hooks Faltantes  | # | Hook | Prop\u00f3sito | Severidad | |---|------|-----------|-----------| | 1 | `end-of-file-fixer` | Asegura newline al final | \ud83d\udfe2 | | 2 | `check-added-large-files` | Evita archivos &gt;500KB | \ud83d\udd34 | | 3 | `ruff` (linting) | Errores de estilo y bugs | \ud83d\udd34 | | 4 | `ruff-format` | Formateo consistente | \ud83d\udfe1 | | 5 | `mypy` | Verificaci\u00f3n de tipos | \ud83d\udd34 | | 6 | `check-merge-conflict` | Evita commits con conflictos | \ud83d\udfe1 |  ### Configuraci\u00f3n Completa  <pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n        args: ['--maxkb=500']\n      - id: check-merge-conflict\n      - id: detect-private-key\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.1.9\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.8.0\n    hooks:\n      - id: mypy\n        additional_dependencies: [pydantic, pandas-stubs]\n</code></pre>"},{"location":"exams/EXAM_01_SETUP/#rubrica-de-evaluacion","title":"R\u00fabrica de Evaluaci\u00f3n","text":"Ejercicio Puntos Tu Puntaje Type Hints 25 Pydantic Config 25 Estructura 25 Pre-commit 25 TOTAL 100 <p>Criterio de aprobaci\u00f3n: \u2265 70 puntos</p>"},{"location":"exams/EXAM_01_SETUP/#reflexion-final","title":"Reflexi\u00f3n Final","text":"<p>Responde estas preguntas:</p> <ol> <li>\u00bfCu\u00e1l fue el error m\u00e1s dif\u00edcil de detectar?</li> <li>\u00bfQu\u00e9 herramienta te habr\u00eda ayudado a detectarlo autom\u00e1ticamente?</li> <li>\u00bfQu\u00e9 cambiar\u00e1s en tu c\u00f3digo despu\u00e9s de este examen?</li> </ol>"},{"location":"exams/EXAM_02_PIPELINE/","title":"\ud83d\udccb Examen de Hito 2: Pipeline Reproducible","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_02_PIPELINE/#ejercicio-1-data-leakage-detection-30-puntos","title":"Ejercicio 1: Data Leakage Detection (30 puntos)","text":""},{"location":"exams/EXAM_02_PIPELINE/#codigo-a-revisar","title":"C\u00f3digo a Revisar","text":"<pre><code># archivo: train.py\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Cargar datos\ndf = pd.read_csv(\"data/customers.csv\")\nX = df.drop(\"Exited\", axis=1)\ny = df[\"Exited\"]\n\n# Preprocesamiento\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # L\u00ednea A\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, random_state=42\n)\n\n# Entrenar\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Evaluar\ny_pred = model.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#tu-respuesta","title":"Tu Respuesta","text":"<ol> <li>\u00bfHay data leakage en este c\u00f3digo? (S\u00ed/No)</li> <li>Si s\u00ed, \u00bfen qu\u00e9 l\u00ednea?</li> <li>\u00bfPor qu\u00e9 es un problema?</li> <li>\u00bfC\u00f3mo lo corregir\u00edas?</li> </ol> \ud83d\udcdd Ver Soluci\u00f3n  ### An\u00e1lisis  1. **\u00bfHay data leakage?** \u2705 S\u00cd  2. **L\u00ednea problem\u00e1tica**: L\u00ednea A - `X_scaled = scaler.fit_transform(X)`  3. **Por qu\u00e9 es un problema**:    - `fit_transform(X)` calcula media y std de TODO el dataset    - Esto incluye datos que luego ser\u00e1n el test set    - El scaler \"sabe\" informaci\u00f3n del futuro (test data)    - En producci\u00f3n, el modelo ver\u00e1 datos que NO conoc\u00eda durante entrenamiento    - El accuracy reportado es **optimista** (el modelo parece mejor de lo que es)  4. **Correcci\u00f3n**:  <pre><code># CORRECTO: Split PRIMERO, fit en train SOLAMENTE\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.pipeline import Pipeline\n\n# Cargar datos\ndf = pd.read_csv(\"data/customers.csv\")\nX = df.drop(\"Exited\", axis=1)\ny = df[\"Exited\"]\n\n# Split PRIMERO (antes de cualquier transformaci\u00f3n)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Opci\u00f3n 1: Pipeline (RECOMENDADO)\npipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"classifier\", RandomForestClassifier(n_estimators=100, random_state=42))\n])\n\npipeline.fit(X_train, y_train)  # fit solo en train\ny_pred = pipeline.predict(X_test)  # transform impl\u00edcito usa stats de train\n\n# Opci\u00f3n 2: Manual (si no usas Pipeline)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)  # fit + transform en train\nX_test_scaled = scaler.transform(X_test)        # SOLO transform en test\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\ny_pred = model.predict(X_test_scaled)\n</code></pre>  **Puntuaci\u00f3n**: - Identificar leakage: 10 pts - L\u00ednea correcta: 5 pts - Explicaci\u00f3n clara: 10 pts - Correcci\u00f3n v\u00e1lida: 5 pts"},{"location":"exams/EXAM_02_PIPELINE/#ejercicio-2-dvc-pipeline-25-puntos","title":"Ejercicio 2: DVC Pipeline (25 puntos)","text":""},{"location":"exams/EXAM_02_PIPELINE/#codigo-a-revisar_1","title":"C\u00f3digo a Revisar","text":"<pre><code># dvc.yaml\nstages:\n  prepare:\n    cmd: python prepare.py\n    outs:\n      - data/processed/train.csv\n\n  train:\n    cmd: python train.py\n    deps:\n      - data/processed/train.csv\n    outs:\n      - models/model.pkl\n\n  evaluate:\n    cmd: python evaluate.py\n    deps:\n      - models/model.pkl\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#tu-respuesta_1","title":"Tu Respuesta","text":"<p>Encuentra al menos 5 problemas:</p> # Problema Impacto Correcci\u00f3n 1 \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Impacto | Correcci\u00f3n | |---|----------|---------|------------| | 1 | `prepare` no tiene `deps` | No re-ejecuta si cambia el script o datos raw | A\u00f1adir `deps: [prepare.py, data/raw/data.csv]` | | 2 | `train` no depende de `train.py` | Cambios en c\u00f3digo no disparan re-entrenamiento | A\u00f1adir `deps: [train.py]` | | 3 | `evaluate` no tiene `outs` | No versiona m\u00e9tricas | A\u00f1adir `metrics: [metrics.json]` | | 4 | `evaluate` no depende de test data | No re-eval\u00faa si cambian datos de test | A\u00f1adir `deps: [data/processed/test.csv]` | | 5 | Sin `plots` para visualizaciones | Pierde trazabilidad de gr\u00e1ficas | A\u00f1adir `plots: [plots/]` | | 6 | `prepare` no genera test.csv | Split no versionado | A\u00f1adir `data/processed/test.csv` a outs |  ### DVC Pipeline Corregido  <pre><code>stages:\n  prepare:\n    cmd: python src/prepare.py\n    deps:\n      - src/prepare.py\n      - data/raw/customers.csv\n    params:\n      - prepare.test_size\n      - prepare.random_state\n    outs:\n      - data/processed/train.csv\n      - data/processed/test.csv\n\n  train:\n    cmd: python src/train.py\n    deps:\n      - src/train.py\n      - data/processed/train.csv\n    params:\n      - model.n_estimators\n      - model.max_depth\n    outs:\n      - models/model.pkl\n\n  evaluate:\n    cmd: python src/evaluate.py\n    deps:\n      - src/evaluate.py\n      - models/model.pkl\n      - data/processed/test.csv\n    metrics:\n      - metrics.json:\n          cache: false\n    plots:\n      - plots/confusion_matrix.png\n      - plots/roc_curve.png\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#ejercicio-3-custom-transformer-25-puntos","title":"Ejercicio 3: Custom Transformer (25 puntos)","text":""},{"location":"exams/EXAM_02_PIPELINE/#codigo-a-revisar_2","title":"C\u00f3digo a Revisar","text":"<pre><code># archivo: transformers.py\nfrom sklearn.base import BaseEstimator\n\nclass FeatureSelector:\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return X[self.columns]\n\n\nclass OutlierRemover(BaseEstimator):\n    def __init__(self, threshold=3):\n        self.threshold = threshold\n\n    def fit(self, X, y=None):\n        self.mean = X.mean()\n        self.std = X.std()\n\n    def transform(self, X):\n        z_scores = (X - self.mean) / self.std\n        return X[abs(z_scores) &lt; self.threshold]\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#tu-respuesta_2","title":"Tu Respuesta","text":"# Clase Problema Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Clase | Problema | Correcci\u00f3n | |---|-------|----------|------------| | 1 | FeatureSelector | No hereda de BaseEstimator | `class FeatureSelector(BaseEstimator):` | | 2 | FeatureSelector | No hereda de TransformerMixin | A\u00f1adir `TransformerMixin` | | 3 | FeatureSelector | fit no retorna self tipado | `def fit(self, X, y=None) -&gt; \"FeatureSelector\":` | | 4 | OutlierRemover | fit no retorna self | A\u00f1adir `return self` | | 5 | OutlierRemover | No hereda de TransformerMixin | A\u00f1adir herencia | | 6 | OutlierRemover | transform cambia n\u00famero de filas | En producci\u00f3n esto rompe el pipeline | | 7 | OutlierRemover | Usar `self.mean_` (convenci\u00f3n sklearn) | Atributos learned terminan en `_` |  ### C\u00f3digo Corregido  <pre><code>from sklearn.base import BaseEstimator, TransformerMixin\nimport numpy as np\nimport pandas as pd\n\nclass FeatureSelector(BaseEstimator, TransformerMixin):\n    \"\"\"Selecciona columnas espec\u00edficas.\"\"\"\n\n    def __init__(self, columns: list[str]):\n        self.columns = columns\n\n    def fit(self, X: pd.DataFrame, y=None) -&gt; \"FeatureSelector\":\n        # Validar que columnas existen\n        missing = set(self.columns) - set(X.columns)\n        if missing:\n            raise ValueError(f\"Columns not found: {missing}\")\n        return self\n\n    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:\n        return X[self.columns].copy()\n\n\nclass OutlierClipper(BaseEstimator, TransformerMixin):\n    \"\"\"Recorta outliers (no elimina filas).\"\"\"\n\n    def __init__(self, factor: float = 1.5):\n        self.factor = factor\n\n    def fit(self, X, y=None) -&gt; \"OutlierClipper\":\n        Q1 = np.percentile(X, 25, axis=0)\n        Q3 = np.percentile(X, 75, axis=0)\n        IQR = Q3 - Q1\n        self.lower_ = Q1 - self.factor * IQR  # Convenci\u00f3n: atributo learned\n        self.upper_ = Q3 + self.factor * IQR\n        return self  # SIEMPRE retornar self\n\n    def transform(self, X):\n        # Clip en vez de eliminar (mantiene n\u00famero de filas)\n        return np.clip(X, self.lower_, self.upper_)\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#ejercicio-4-pandera-schema-20-puntos","title":"Ejercicio 4: Pandera Schema (20 puntos)","text":""},{"location":"exams/EXAM_02_PIPELINE/#codigo-a-revisar_3","title":"C\u00f3digo a Revisar","text":"<pre><code># archivo: schemas.py\nimport pandera as pa\n\nclass CustomerSchema(pa.SchemaModel):\n    age: int\n    balance: float\n    exited: int\n</code></pre>"},{"location":"exams/EXAM_02_PIPELINE/#tu-respuesta_3","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 validaciones faltan para datos de producci\u00f3n?</p> \ud83d\udcdd Ver Soluci\u00f3n <pre><code>import pandera as pa\nfrom pandera.typing import Series\n\nclass CustomerSchema(pa.DataFrameModel):\n    \"\"\"Schema para datos de clientes - producci\u00f3n.\"\"\"\n\n    # Tipos + validaciones de rango\n    CreditScore: Series[int] = pa.Field(\n        ge=300, le=850,\n        description=\"FICO score\"\n    )\n    Age: Series[int] = pa.Field(\n        ge=18, le=100,\n        description=\"Edad del cliente\"\n    )\n    Balance: Series[float] = pa.Field(\n        ge=0,\n        description=\"Balance en cuenta\"\n    )\n    NumOfProducts: Series[int] = pa.Field(\n        ge=1, le=4,\n        description=\"N\u00famero de productos\"\n    )\n    Exited: Series[int] = pa.Field(\n        isin=[0, 1],\n        description=\"Target: 1=churned\"\n    )\n\n    class Config:\n        strict = True       # No permite columnas extra\n        coerce = True       # Convierte tipos autom\u00e1ticamente\n        name = \"CustomerSchema\"\n\n    @pa.check(\"Balance\")\n    def balance_not_negative(cls, series: Series[float]) -&gt; Series[bool]:\n        return series &gt;= 0\n\n    @pa.dataframe_check\n    def no_duplicate_customers(cls, df) -&gt; bool:\n        \"\"\"No debe haber IDs duplicados.\"\"\"\n        return df.index.is_unique\n</code></pre>  **Validaciones a\u00f1adidas**: 1. Rangos realistas (age 18-100, credit 300-850) 2. Valores permitidos (Exited solo 0 o 1) 3. `strict=True` para rechazar columnas inesperadas 4. Custom checks para l\u00f3gica de negocio"},{"location":"exams/EXAM_02_PIPELINE/#rubrica","title":"R\u00fabrica","text":"Ejercicio Puntos Data Leakage 30 DVC Pipeline 25 Custom Transformer 25 Pandera Schema 20 TOTAL 100"},{"location":"exams/EXAM_03_TESTING/","title":"\ud83d\udccb Examen de Hito 3: Testing &amp; CI/CD","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_03_TESTING/#ejercicio-1-tests-con-errores-sutiles-30-puntos","title":"Ejercicio 1: Tests con Errores Sutiles (30 puntos)","text":""},{"location":"exams/EXAM_03_TESTING/#codigo-a-revisar","title":"C\u00f3digo a Revisar","text":"<pre><code># tests/test_training.py\nimport pytest\nimport pandas as pd\nfrom bankchurn.training import ChurnTrainer\nfrom bankchurn.config import BankChurnConfig\n\ndef test_trainer_fits():\n    # Arrange\n    df = pd.read_csv(\"data/raw/customers.csv\")\n    config = BankChurnConfig.from_yaml(\"configs/config.yaml\")\n    trainer = ChurnTrainer(config)\n\n    # Act\n    X = df.drop(\"Exited\", axis=1)\n    y = df[\"Exited\"]\n    trainer.fit(X, y)\n\n    # Assert\n    assert trainer._pipeline is not None\n\ndef test_predictions_are_binary():\n    df = pd.read_csv(\"data/raw/customers.csv\")\n    config = BankChurnConfig.from_yaml(\"configs/config.yaml\")\n    trainer = ChurnTrainer(config)\n\n    X = df.drop(\"Exited\", axis=1)\n    y = df[\"Exited\"]\n    trainer.fit(X, y)\n\n    predictions = trainer.predict(X)\n    assert all(p in [0, 1] for p in predictions)\n\ndef test_accuracy_above_threshold():\n    df = pd.read_csv(\"data/raw/customers.csv\")\n    config = BankChurnConfig.from_yaml(\"configs/config.yaml\")\n    trainer = ChurnTrainer(config)\n\n    X = df.drop(\"Exited\", axis=1)\n    y = df[\"Exited\"]\n    trainer.fit(X, y)\n\n    accuracy = trainer.evaluate(X, y)[\"accuracy\"]\n    assert accuracy &gt; 0.8\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#tu-respuesta","title":"Tu Respuesta","text":"# Problema Severidad Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Severidad | Correcci\u00f3n | |---|----------|-----------|------------| | 1 | Lee archivos reales (no aislado) | \ud83d\udd34 Cr\u00edtico | Usar fixtures con datos sint\u00e9ticos | | 2 | Depende de config.yaml externo | \ud83d\udd34 Cr\u00edtico | Crear config en el test o usar fixture | | 3 | Tests no son independientes | \ud83d\udfe1 Medio | Cada test crea su propio trainer | | 4 | Eval\u00faa en datos de TRAIN (leakage) | \ud83d\udd34 Cr\u00edtico | Usar train_test_split | | 5 | `assert trainer._pipeline` accede privado | \ud83d\udfe2 Menor | Usar m\u00e9todo p\u00fablico `is_fitted()` | | 6 | Mucho c\u00f3digo duplicado | \ud83d\udfe1 Medio | Usar fixtures `@pytest.fixture` | | 7 | `accuracy &gt; 0.8` es fr\u00e1gil | \ud83d\udfe1 Medio | Test debe ser determinista o usar rango |  ### Tests Corregidos  <pre><code># tests/conftest.py\nimport pytest\nimport pandas as pd\nimport numpy as np\nfrom bankchurn.config import BankChurnConfig, ModelConfig, DataConfig\n\n@pytest.fixture\ndef sample_data():\n    \"\"\"Datos sint\u00e9ticos reproducibles.\"\"\"\n    np.random.seed(42)\n    n = 100\n    return pd.DataFrame({\n        \"CreditScore\": np.random.randint(300, 850, n),\n        \"Age\": np.random.randint(18, 80, n),\n        \"Balance\": np.random.uniform(0, 100000, n),\n        \"NumOfProducts\": np.random.randint(1, 4, n),\n        \"Exited\": np.random.randint(0, 2, n),\n    })\n\n@pytest.fixture\ndef config():\n    \"\"\"Configuraci\u00f3n de test (no depende de archivo).\"\"\"\n    return BankChurnConfig(\n        model=ModelConfig(test_size=0.2, random_state=42),\n        data=DataConfig(target_column=\"Exited\"),\n    )\n\n@pytest.fixture\ndef trained_trainer(sample_data, config):\n    \"\"\"Trainer ya entrenado.\"\"\"\n    from bankchurn.training import ChurnTrainer\n    trainer = ChurnTrainer(config)\n    X = sample_data.drop(\"Exited\", axis=1)\n    y = sample_data[\"Exited\"]\n    trainer.fit(X, y)\n    return trainer\n\n\n# tests/test_training.py\nfrom sklearn.model_selection import train_test_split\n\ndef test_trainer_fits(sample_data, config):\n    \"\"\"Test que el trainer puede entrenar.\"\"\"\n    from bankchurn.training import ChurnTrainer\n\n    trainer = ChurnTrainer(config)\n    X = sample_data.drop(\"Exited\", axis=1)\n    y = sample_data[\"Exited\"]\n\n    trainer.fit(X, y)\n\n    assert trainer.is_fitted()  # M\u00e9todo p\u00fablico\n\ndef test_predictions_are_binary(trained_trainer, sample_data):\n    \"\"\"Test que predicciones son 0 o 1.\"\"\"\n    X = sample_data.drop(\"Exited\", axis=1)\n    predictions = trained_trainer.predict(X)\n\n    assert set(predictions.unique()).issubset({0, 1})\n\ndef test_model_generalizes(sample_data, config):\n    \"\"\"Test en datos NO vistos durante entrenamiento.\"\"\"\n    from bankchurn.training import ChurnTrainer\n\n    X = sample_data.drop(\"Exited\", axis=1)\n    y = sample_data[\"Exited\"]\n\n    # Split ANTES de entrenar\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n\n    trainer = ChurnTrainer(config)\n    trainer.fit(X_train, y_train)\n\n    # Evaluar en datos NO vistos\n    metrics = trainer.evaluate(X_test, y_test)\n\n    # Verificar que m\u00e9tricas son razonables (no perfectas)\n    assert 0.3 &lt; metrics[\"accuracy\"] &lt; 1.0  # Rango realista\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#ejercicio-2-github-actions-workflow-25-puntos","title":"Ejercicio 2: GitHub Actions Workflow (25 puntos)","text":""},{"location":"exams/EXAM_03_TESTING/#codigo-a-revisar_1","title":"C\u00f3digo a Revisar","text":"<pre><code># .github/workflows/ci.yml\nname: CI\n\non: push\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.11\n\n      - name: Install\n        run: pip install -r requirements.txt\n\n      - name: Test\n        run: pytest\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#tu-respuesta_1","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 falta o est\u00e1 mal?</p> \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Correcci\u00f3n | |---|----------|------------| | 1 | `on: push` sin filtros | A\u00f1adir `branches: [main, develop]` | | 2 | Sin cache de pip | A\u00f1adir `cache: pip` | | 3 | No instala en modo editable | `pip install -e \".[dev]\"` | | 4 | pytest sin opciones | `pytest -v --cov --cov-fail-under=79` | | 5 | Sin linting (mypy, ruff) | A\u00f1adir steps de lint | | 6 | Sin matrix para m\u00faltiples Python | A\u00f1adir matrix strategy | | 7 | Sin timeout | A\u00f1adir `timeout-minutes: 10` |  ### Workflow Corregido  <pre><code>name: CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \"3.11\"\n          cache: pip\n\n      - name: Install\n        run: pip install -e \".[dev]\"\n\n      - name: Ruff\n        run: ruff check src/ tests/\n\n      - name: Mypy\n        run: mypy src/ --strict\n\n  test:\n    needs: lint\n    runs-on: ubuntu-latest\n    timeout-minutes: 10\n    strategy:\n      matrix:\n        python-version: [\"3.10\", \"3.11\", \"3.12\"]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v5\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: pip\n\n      - name: Install\n        run: pip install -e \".[dev]\"\n\n      - name: Test\n        run: pytest tests/ -v --cov=src --cov-report=xml --cov-fail-under=79\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage.xml\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#ejercicio-3-fixtures-y-mocks-25-puntos","title":"Ejercicio 3: Fixtures y Mocks (25 puntos)","text":""},{"location":"exams/EXAM_03_TESTING/#codigo-a-revisar_2","title":"C\u00f3digo a Revisar","text":"<pre><code># tests/test_api.py\nimport requests\nfrom fastapi.testclient import TestClient\nfrom app.fastapi_app import app\n\ndef test_predict_endpoint():\n    client = TestClient(app)\n\n    # Llama al modelo real\n    response = client.post(\"/predict\", json={\n        \"CreditScore\": 650,\n        \"Age\": 35,\n        \"Balance\": 50000,\n    })\n\n    assert response.status_code == 200\n    assert \"prediction\" in response.json()\n\ndef test_health_calls_database():\n    # Llama a la base de datos real\n    response = requests.get(\"http://localhost:8000/health\")\n    assert response.json()[\"database\"] == \"connected\"\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#tu-respuesta_2","title":"Tu Respuesta","text":"# Problema Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Correcci\u00f3n | |---|----------|------------| | 1 | `/predict` usa modelo real | Mock del modelo | | 2 | Test depende de modelo entrenado | Usar fixture con mock | | 3 | `requests.get` llama servidor real | Usar TestClient | | 4 | Test depende de DB real | Mock de la conexi\u00f3n DB | | 5 | Sin datos de entrada inv\u00e1lidos | A\u00f1adir test de validaci\u00f3n |  ### Tests Corregidos  <pre><code># tests/test_api.py\nimport pytest\nfrom unittest.mock import MagicMock, patch\nfrom fastapi.testclient import TestClient\nfrom app.fastapi_app import app\n\n@pytest.fixture\ndef client():\n    return TestClient(app)\n\n@pytest.fixture\ndef mock_model():\n    \"\"\"Mock del modelo que retorna predicci\u00f3n fija.\"\"\"\n    model = MagicMock()\n    model.predict.return_value = [1]\n    model.predict_proba.return_value = [[0.3, 0.7]]\n    return model\n\ndef test_predict_endpoint(client, mock_model):\n    \"\"\"Test de predicci\u00f3n con modelo mockeado.\"\"\"\n    with patch(\"app.fastapi_app.model\", mock_model):\n        response = client.post(\"/predict\", json={\n            \"CreditScore\": 650,\n            \"Age\": 35,\n            \"Balance\": 50000.0,\n            \"NumOfProducts\": 2,\n        })\n\n    assert response.status_code == 200\n    data = response.json()\n    assert \"prediction\" in data\n    assert data[\"prediction\"] in [0, 1]\n    assert \"probability\" in data\n\ndef test_predict_invalid_input(client):\n    \"\"\"Test de validaci\u00f3n de entrada.\"\"\"\n    response = client.post(\"/predict\", json={\n        \"CreditScore\": -100,  # Inv\u00e1lido\n        \"Age\": 200,           # Inv\u00e1lido\n    })\n\n    assert response.status_code == 422  # Validation error\n\ndef test_health_endpoint(client):\n    \"\"\"Test de health sin dependencias externas.\"\"\"\n    with patch(\"app.fastapi_app.check_database\") as mock_db:\n        mock_db.return_value = True\n        response = client.get(\"/health\")\n\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"healthy\"\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#ejercicio-4-cobertura-de-tests-20-puntos","title":"Ejercicio 4: Cobertura de Tests (20 puntos)","text":""},{"location":"exams/EXAM_03_TESTING/#output-a-analizar","title":"Output a Analizar","text":"<pre><code>---------- coverage: ----------\nName                          Stmts   Miss  Cover\n-------------------------------------------------\nsrc/bankchurn/__init__.py         5      0   100%\nsrc/bankchurn/config.py          45      2    96%\nsrc/bankchurn/training.py        89     45    49%\nsrc/bankchurn/evaluation.py      23      0   100%\nsrc/bankchurn/prediction.py      34     34     0%\n-------------------------------------------------\nTOTAL                           196     81    59%\n\nFAILED: Coverage 59% &lt; 79% minimum\n</code></pre>"},{"location":"exams/EXAM_03_TESTING/#tu-respuesta_3","title":"Tu Respuesta","text":"<ol> <li>\u00bfQu\u00e9 archivo necesita m\u00e1s tests urgentemente?</li> <li>\u00bfQu\u00e9 tipo de tests a\u00f1adir\u00edas?</li> </ol> \ud83d\udcdd Ver Soluci\u00f3n  1. **Archivo m\u00e1s urgente**: `prediction.py` (0% coverage)  2. **Tests a a\u00f1adir**:  <pre><code># tests/test_prediction.py\n\ndef test_predictor_loads_model(tmp_path, trained_model):\n    \"\"\"Test que el predictor carga modelo correctamente.\"\"\"\n    model_path = tmp_path / \"model.pkl\"\n    joblib.dump(trained_model, model_path)\n\n    predictor = ChurnPredictor(model_path)\n\n    assert predictor.model is not None\n\ndef test_predictor_single_prediction(predictor, sample_input):\n    \"\"\"Test predicci\u00f3n de un solo registro.\"\"\"\n    result = predictor.predict_single(sample_input)\n\n    assert \"prediction\" in result\n    assert \"probability\" in result\n    assert result[\"prediction\"] in [0, 1]\n\ndef test_predictor_batch_prediction(predictor, sample_dataframe):\n    \"\"\"Test predicci\u00f3n en batch.\"\"\"\n    results = predictor.predict_batch(sample_dataframe)\n\n    assert len(results) == len(sample_dataframe)\n    assert all(r[\"prediction\"] in [0, 1] for r in results)\n\ndef test_predictor_handles_missing_model():\n    \"\"\"Test error cuando no existe modelo.\"\"\"\n    with pytest.raises(FileNotFoundError):\n        ChurnPredictor(\"nonexistent/model.pkl\")\n</code></pre>  3. **Para `training.py` (49%)**:    - Tests de edge cases (datos vac\u00edos, una sola clase)    - Tests de serializaci\u00f3n (save/load)    - Tests de cross-validation"},{"location":"exams/EXAM_03_TESTING/#rubrica","title":"R\u00fabrica","text":"Ejercicio Puntos Tests con Errores 30 GitHub Actions 25 Fixtures y Mocks 25 Cobertura 20 TOTAL 100"},{"location":"exams/EXAM_04_DEPLOYMENT/","title":"\ud83d\udccb Examen de Hito 4: Deployment","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_04_DEPLOYMENT/#ejercicio-1-dockerfile-con-errores-30-puntos","title":"Ejercicio 1: Dockerfile con Errores (30 puntos)","text":""},{"location":"exams/EXAM_04_DEPLOYMENT/#codigo-a-revisar","title":"C\u00f3digo a Revisar","text":"<pre><code>FROM python:3.11\n\nWORKDIR /app\n\nCOPY . .\n\nRUN pip install -r requirements.txt\n\nEXPOSE 8000\n\nCMD python app/fastapi_app.py\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#tu-respuesta","title":"Tu Respuesta","text":"# Problema Severidad Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Severidad | Correcci\u00f3n | |---|----------|-----------|------------| | 1 | `python:3.11` es muy pesado (~1GB) | \ud83d\udfe1 Medio | Usar `python:3.11-slim` | | 2 | `COPY . .` antes de deps | \ud83d\udd34 Cr\u00edtico | COPY requirements.txt primero (cache) | | 3 | Sin `.dockerignore` | \ud83d\udfe1 Medio | Crear archivo para excluir .git, __pycache__ | | 4 | Sin `--no-cache-dir` en pip | \ud83d\udfe2 Menor | Reduce tama\u00f1o de imagen | | 5 | Corre como root | \ud83d\udd34 Cr\u00edtico | Crear usuario non-root | | 6 | CMD sin exec form | \ud83d\udfe1 Medio | Usar `[\"python\", \"...\"]` | | 7 | Sin multi-stage build | \ud83d\udfe1 Medio | Separar build de runtime | | 8 | Sin HEALTHCHECK | \ud83d\udfe2 Menor | A\u00f1adir healthcheck |  ### Dockerfile Corregido  <pre><code># \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Stage 1: Builder (solo para instalar deps)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim as builder\n\nWORKDIR /app\n\n# Instalar deps de compilaci\u00f3n\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copiar SOLO requirements (cache de Docker)\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --user -r requirements.txt\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Stage 2: Runtime (imagen final ligera)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Variables de entorno\nENV PYTHONDONTWRITEBYTECODE=1 \\\n    PYTHONUNBUFFERED=1 \\\n    PATH=\"/home/appuser/.local/bin:$PATH\"\n\n# Crear usuario non-root\nRUN useradd --create-home --shell /bin/bash appuser\n\n# Copiar deps instaladas desde builder\nCOPY --from=builder /root/.local /home/appuser/.local\n\n# Copiar c\u00f3digo (despu\u00e9s de deps para mejor cache)\nCOPY --chown=appuser:appuser src/ ./src/\nCOPY --chown=appuser:appuser app/ ./app/\nCOPY --chown=appuser:appuser configs/ ./configs/\n\n# Cambiar a usuario non-root\nUSER appuser\n\n# Puerto\nEXPOSE 8000\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Comando (exec form)\nCMD [\"uvicorn\", \"app.fastapi_app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#ejercicio-2-fastapi-con-vulnerabilidades-25-puntos","title":"Ejercicio 2: FastAPI con Vulnerabilidades (25 puntos)","text":""},{"location":"exams/EXAM_04_DEPLOYMENT/#codigo-a-revisar_1","title":"C\u00f3digo a Revisar","text":"<pre><code># app/fastapi_app.py\nfrom fastapi import FastAPI\nimport pickle\nimport pandas as pd\n\napp = FastAPI()\n\nmodel = pickle.load(open(\"model.pkl\", \"rb\"))\n\n@app.post(\"/predict\")\ndef predict(data: dict):\n    df = pd.DataFrame([data])\n    prediction = model.predict(df)[0]\n    return {\"prediction\": prediction}\n\n@app.get(\"/model-info\")\ndef model_info():\n    return {\n        \"type\": str(type(model)),\n        \"params\": model.get_params(),\n    }\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#tu-respuesta_1","title":"Tu Respuesta","text":"# Problema Severidad Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Severidad | Correcci\u00f3n | |---|----------|-----------|------------| | 1 | `data: dict` sin validaci\u00f3n | \ud83d\udd34 Cr\u00edtico | Usar Pydantic model | | 2 | Path hardcodeado `model.pkl` | \ud83d\udfe1 Medio | Usar variable de entorno | | 3 | Carga modelo al importar | \ud83d\udd34 Cr\u00edtico | Lazy loading o startup event | | 4 | Sin manejo de errores | \ud83d\udd34 Cr\u00edtico | try/except con HTTPException | | 5 | `/model-info` expone internos | \ud83d\udfe1 Medio | Limitar informaci\u00f3n o proteger | | 6 | Sin versionado de API | \ud83d\udfe2 Menor | A\u00f1adir `/v1/predict` | | 7 | Sin logging | \ud83d\udfe1 Medio | A\u00f1adir logs estructurados |  ### FastAPI Corregido  <pre><code># app/fastapi_app.py\nimport os\nfrom contextlib import asynccontextmanager\nfrom pathlib import Path\n\nimport joblib\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel, Field\nimport structlog\n\nlogger = structlog.get_logger()\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Schemas de entrada/salida\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nclass PredictRequest(BaseModel):\n    \"\"\"Schema de entrada validado.\"\"\"\n    CreditScore: int = Field(..., ge=300, le=850)\n    Age: int = Field(..., ge=18, le=100)\n    Balance: float = Field(..., ge=0)\n    NumOfProducts: int = Field(..., ge=1, le=4)\n\nclass PredictResponse(BaseModel):\n    \"\"\"Schema de salida.\"\"\"\n    prediction: int\n    probability: float\n    model_version: str\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Lifecycle: cargar modelo al iniciar\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nMODEL_PATH = Path(os.getenv(\"MODEL_PATH\", \"artifacts/model.joblib\"))\nmodel = None\nmodel_version = \"unknown\"\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Carga modelo al iniciar, libera al cerrar.\"\"\"\n    global model, model_version\n\n    if not MODEL_PATH.exists():\n        raise RuntimeError(f\"Model not found: {MODEL_PATH}\")\n\n    logger.info(\"loading_model\", path=str(MODEL_PATH))\n    model = joblib.load(MODEL_PATH)\n    model_version = os.getenv(\"MODEL_VERSION\", \"1.0.0\")\n\n    yield\n\n    logger.info(\"shutting_down\")\n\napp = FastAPI(\n    title=\"BankChurn Predictor\",\n    version=\"1.0.0\",\n    lifespan=lifespan,\n)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Endpoints\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\n@app.post(\"/v1/predict\", response_model=PredictResponse)\nasync def predict(request: PredictRequest):\n    \"\"\"Predice probabilidad de churn.\"\"\"\n    try:\n        import pandas as pd\n        df = pd.DataFrame([request.model_dump()])\n\n        prediction = int(model.predict(df)[0])\n        probability = float(model.predict_proba(df)[0, 1])\n\n        logger.info(\"prediction_made\", prediction=prediction)\n\n        return PredictResponse(\n            prediction=prediction,\n            probability=probability,\n            model_version=model_version,\n        )\n\n    except Exception as e:\n        logger.error(\"prediction_failed\", error=str(e))\n        raise HTTPException(status_code=500, detail=\"Prediction failed\")\n\n@app.get(\"/health\")\nasync def health():\n    \"\"\"Health check para Kubernetes.\"\"\"\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": model is not None,\n        \"model_version\": model_version,\n    }\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#ejercicio-3-kubernetes-manifest-25-puntos","title":"Ejercicio 3: Kubernetes Manifest (25 puntos)","text":""},{"location":"exams/EXAM_04_DEPLOYMENT/#codigo-a-revisar_2","title":"C\u00f3digo a Revisar","text":"<pre><code># k8s/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bankchurn-api\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: bankchurn\n  template:\n    spec:\n      containers:\n      - name: api\n        image: bankchurn:latest\n        ports:\n        - containerPort: 8000\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#tu-respuesta_2","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 falta para producci\u00f3n?</p> \ud83d\udcdd Ver Soluci\u00f3n  | # | Faltante | Impacto | |---|----------|---------| | 1 | Sin `metadata.labels` en template | Selector no funciona | | 2 | Sin resources (limits/requests) | Pod puede consumir todo | | 3 | Sin probes (liveness/readiness) | K8s no sabe si est\u00e1 sano | | 4 | `image: latest` es antipatr\u00f3n | No reproducible | | 5 | Sin imagePullPolicy | Puede usar cache viejo | | 6 | Sin securityContext | Corre como root | | 7 | Sin env vars | Config hardcodeada |  ### Manifest Corregido  <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: bankchurn-api\n  labels:\n    app: bankchurn\n    version: v1\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: bankchurn\n  template:\n    metadata:\n      labels:\n        app: bankchurn\n        version: v1\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n\n      containers:\n      - name: api\n        image: ghcr.io/user/bankchurn:1.0.0  # Tag espec\u00edfico\n        imagePullPolicy: IfNotPresent\n\n        ports:\n        - containerPort: 8000\n          name: http\n\n        env:\n        - name: MODEL_PATH\n          value: \"/app/models/model.joblib\"\n        - name: MODEL_VERSION\n          value: \"1.0.0\"\n\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 10\n          periodSeconds: 30\n\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 5\n          periodSeconds: 10\n\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: bankchurn-api\nspec:\n  selector:\n    app: bankchurn\n  ports:\n  - port: 80\n    targetPort: 8000\n  type: ClusterIP\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#ejercicio-4-terraform-20-puntos","title":"Ejercicio 4: Terraform (20 puntos)","text":""},{"location":"exams/EXAM_04_DEPLOYMENT/#codigo-a-revisar_3","title":"C\u00f3digo a Revisar","text":"<pre><code># main.tf\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_instance\" \"ml_server\" {\n  ami           = \"ami-12345678\"\n  instance_type = \"t2.micro\"\n}\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#tu-respuesta_3","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 problemas tiene para producci\u00f3n?</p> \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Correcci\u00f3n | |---|----------|------------| | 1 | AMI hardcodeada | Usar data source o variable | | 2 | Sin backend para state | A\u00f1adir S3 backend | | 3 | Sin variables | Parametrizar | | 4 | Sin outputs | Exportar IP, DNS | | 5 | Sin tags | A\u00f1adir tags para billing | | 6 | Sin security groups | Definir reglas de red |  ### Terraform Corregido  <pre><code># backend.tf\nterraform {\n  backend \"s3\" {\n    bucket = \"my-terraform-state\"\n    key    = \"bankchurn/terraform.tfstate\"\n    region = \"us-east-1\"\n  }\n}\n\n# variables.tf\nvariable \"environment\" {\n  type    = string\n  default = \"dev\"\n}\n\nvariable \"instance_type\" {\n  type    = string\n  default = \"t3.medium\"\n}\n\n# main.tf\nprovider \"aws\" {\n  region = \"us-east-1\"\n\n  default_tags {\n    tags = {\n      Project     = \"BankChurn\"\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n    }\n  }\n}\n\ndata \"aws_ami\" \"ubuntu\" {\n  most_recent = true\n  owners      = [\"099720109477\"]  # Canonical\n\n  filter {\n    name   = \"name\"\n    values = [\"ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*\"]\n  }\n}\n\nresource \"aws_security_group\" \"ml_server\" {\n  name = \"bankchurn-${var.environment}\"\n\n  ingress {\n    from_port   = 8000\n    to_port     = 8000\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/8\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_instance\" \"ml_server\" {\n  ami                    = data.aws_ami.ubuntu.id\n  instance_type          = var.instance_type\n  vpc_security_group_ids = [aws_security_group.ml_server.id]\n\n  tags = {\n    Name = \"bankchurn-${var.environment}\"\n  }\n}\n\n# outputs.tf\noutput \"instance_ip\" {\n  value = aws_instance.ml_server.public_ip\n}\n</code></pre>"},{"location":"exams/EXAM_04_DEPLOYMENT/#rubrica","title":"R\u00fabrica","text":"Ejercicio Puntos Dockerfile 30 FastAPI 25 Kubernetes 25 Terraform 20 TOTAL 100"},{"location":"exams/EXAM_05_PRODUCTION/","title":"\ud83d\udccb Examen de Hito 5: Producci\u00f3n &amp; Monitoreo","text":"<p>Formato: Self-Correction Code Review Duraci\u00f3n: 45-60 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_05_PRODUCTION/#ejercicio-1-mlflow-con-errores-25-puntos","title":"Ejercicio 1: MLflow con Errores (25 puntos)","text":""},{"location":"exams/EXAM_05_PRODUCTION/#codigo-a-revisar","title":"C\u00f3digo a Revisar","text":"<pre><code># train_mlflow.py\nimport mlflow\nfrom sklearn.ensemble import RandomForestClassifier\n\nmlflow.set_experiment(\"bankchurn\")\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=10)\nmodel.fit(X_train, y_train)\n\naccuracy = model.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy}\")\n\nmlflow.log_metric(\"accuracy\", accuracy)\nmlflow.sklearn.log_model(model, \"model\")\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#tu-respuesta","title":"Tu Respuesta","text":"# Problema Severidad Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Severidad | Correcci\u00f3n | |---|----------|-----------|------------| | 1 | Sin `with mlflow.start_run()` | \ud83d\udd34 Cr\u00edtico | Envolver en context manager | | 2 | No loguea par\u00e1metros | \ud83d\udfe1 Medio | `mlflow.log_params()` | | 3 | Sin run_name | \ud83d\udfe2 Menor | A\u00f1adir nombre descriptivo | | 4 | Sin signature del modelo | \ud83d\udfe1 Medio | `infer_signature()` | | 5 | Sin input_example | \ud83d\udfe2 Menor | A\u00f1adir ejemplo de entrada | | 6 | Solo accuracy (pocas m\u00e9tricas) | \ud83d\udfe1 Medio | Loguear m\u00e1s m\u00e9tricas | | 7 | Sin tags | \ud83d\udfe2 Menor | A\u00f1adir tags de contexto |  ### C\u00f3digo Corregido  <pre><code>import mlflow\nfrom mlflow.models import infer_signature\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport pandas as pd\n\n# Configuraci\u00f3n\nmlflow.set_tracking_uri(\"file:./mlruns\")\nmlflow.set_experiment(\"bankchurn-classifier\")\n\n# Par\u00e1metros\nparams = {\n    \"n_estimators\": 100,\n    \"max_depth\": 10,\n    \"min_samples_split\": 5,\n    \"random_state\": 42,\n}\n\nwith mlflow.start_run(run_name=\"rf-baseline-v1\") as run:\n    # Tags de contexto\n    mlflow.set_tags({\n        \"model_type\": \"random_forest\",\n        \"dataset_version\": \"v1.0\",\n        \"engineer\": \"daniel\",\n    })\n\n    # Loguear par\u00e1metros\n    mlflow.log_params(params)\n\n    # Entrenar\n    model = RandomForestClassifier(**params)\n    model.fit(X_train, y_train)\n\n    # Predecir\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]\n\n    # M\u00e9tricas completas\n    metrics = {\n        \"accuracy\": accuracy_score(y_test, y_pred),\n        \"f1\": f1_score(y_test, y_pred),\n        \"precision\": precision_score(y_test, y_pred),\n        \"recall\": recall_score(y_test, y_pred),\n    }\n    mlflow.log_metrics(metrics)\n\n    # Signature para validaci\u00f3n en inferencia\n    signature = infer_signature(X_train, model.predict(X_train))\n\n    # Input example para documentaci\u00f3n\n    input_example = X_train.head(3)\n\n    # Loguear modelo con metadata\n    mlflow.sklearn.log_model(\n        model,\n        artifact_path=\"model\",\n        signature=signature,\n        input_example=input_example,\n        registered_model_name=\"bankchurn-classifier\",\n    )\n\n    print(f\"Run ID: {run.info.run_id}\")\n    print(f\"Metrics: {metrics}\")\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#ejercicio-2-logging-con-problemas-25-puntos","title":"Ejercicio 2: Logging con Problemas (25 puntos)","text":""},{"location":"exams/EXAM_05_PRODUCTION/#codigo-a-revisar_1","title":"C\u00f3digo a Revisar","text":"<pre><code># prediction.py\ndef predict(data):\n    print(f\"Received data: {data}\")\n\n    try:\n        result = model.predict(data)\n        print(f\"Prediction: {result}\")\n        return result\n    except Exception as e:\n        print(f\"Error: {e}\")\n        raise\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#tu-respuesta_1","title":"Tu Respuesta","text":"# Problema Correcci\u00f3n \ud83d\udcdd Ver Soluci\u00f3n  | # | Problema | Correcci\u00f3n | |---|----------|------------| | 1 | `print()` en vez de logger | Usar logging estructurado | | 2 | Loguea datos sensibles | Sanitizar o no loguear | | 3 | Sin niveles de log | DEBUG, INFO, ERROR | | 4 | Sin contexto (request_id) | A\u00f1adir correlation ID | | 5 | Sin timestamp | Logger lo a\u00f1ade autom\u00e1tico | | 6 | Except gen\u00e9rico sin detalles | Loguear traceback |  ### C\u00f3digo Corregido  <pre><code># prediction.py\nimport structlog\nfrom typing import Any\nimport uuid\n\nlogger = structlog.get_logger()\n\ndef predict(data: dict, request_id: str | None = None) -&gt; dict:\n    \"\"\"Predice con logging estructurado.\"\"\"\n\n    # Generar request_id si no viene\n    request_id = request_id or str(uuid.uuid4())[:8]\n\n    # Bind context para todos los logs de esta request\n    log = logger.bind(request_id=request_id)\n\n    # Log de entrada (sin datos sensibles)\n    log.info(\n        \"prediction_started\",\n        num_features=len(data),\n        features=list(data.keys()),  # Solo nombres, no valores\n    )\n\n    try:\n        result = model.predict(data)\n\n        log.info(\n            \"prediction_completed\",\n            prediction=int(result),\n            latency_ms=elapsed_ms,\n        )\n\n        return {\n            \"prediction\": int(result),\n            \"request_id\": request_id,\n        }\n\n    except ValueError as e:\n        log.warning(\n            \"prediction_validation_error\",\n            error=str(e),\n        )\n        raise\n\n    except Exception as e:\n        log.error(\n            \"prediction_failed\",\n            error=str(e),\n            exc_info=True,  # Incluye traceback\n        )\n        raise\n</code></pre>  ### Configuraci\u00f3n de structlog  <pre><code># logging_config.py\nimport structlog\nimport logging\nimport sys\n\ndef setup_logging(json_logs: bool = True):\n    \"\"\"Configura logging estructurado.\"\"\"\n\n    processors = [\n        structlog.contextvars.merge_contextvars,\n        structlog.processors.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.StackInfoRenderer(),\n    ]\n\n    if json_logs:\n        processors.append(structlog.processors.JSONRenderer())\n    else:\n        processors.append(structlog.dev.ConsoleRenderer())\n\n    structlog.configure(\n        processors=processors,\n        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),\n        context_class=dict,\n        logger_factory=structlog.PrintLoggerFactory(),\n    )\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#ejercicio-3-model-card-incompleto-25-puntos","title":"Ejercicio 3: Model Card Incompleto (25 puntos)","text":""},{"location":"exams/EXAM_05_PRODUCTION/#documento-a-revisar","title":"Documento a Revisar","text":"<p><pre><code># Model Card: BankChurn Predictor\n\n## Model Details\n- Random Forest classifier\n- Trained on customer data\n\n## Usage\n```python\nmodel.predict(data)\n</code></pre> <pre><code>### Tu Respuesta\n\n\u00bfQu\u00e9 secciones cr\u00edticas faltan?\n\n---\n\n&lt;details&gt;\n&lt;summary&gt;\ud83d\udcdd Ver Soluci\u00f3n&lt;/summary&gt;\n\n### Model Card Completo\n\n```markdown\n# Model Card: BankChurn Predictor\n\n## Model Details\n- **Model Type**: Ensemble (Random Forest + Logistic Regression)\n- **Version**: 1.0.0\n- **Framework**: scikit-learn 1.3.0\n- **License**: MIT\n- **Contact**: ml-team@company.com\n\n## Intended Use\n- **Primary Use**: Predecir probabilidad de churn de clientes bancarios\n- **Primary Users**: Equipo de retenci\u00f3n de clientes\n- **Out-of-Scope**: No usar para decisiones de cr\u00e9dito o discriminaci\u00f3n\n\n## Training Data\n- **Source**: Base de datos de clientes (10,000 registros)\n- **Date Range**: 2020-01-01 a 2023-12-31\n- **Features**: 10 (CreditScore, Age, Balance, etc.)\n- **Target**: Exited (binario: 0=retained, 1=churned)\n- **Class Distribution**: 20% churned, 80% retained\n\n## Evaluation Data\n- **Split**: 80% train, 20% test (stratified)\n- **Test Size**: 2,000 registros\n\n## Metrics\n| Metric | Value |\n|--------|-------|\n| Accuracy | 0.847 |\n| Precision | 0.823 |\n| Recall | 0.761 |\n| F1 Score | 0.791 |\n| ROC-AUC | 0.892 |\n\n## Ethical Considerations\n- **Fairness**: Evaluado por Age y Gender - no se detect\u00f3 sesgo significativo\n- **Privacy**: No se usan datos PII en features\n- **Bias Risks**: Posible sesgo geogr\u00e1fico (m\u00e1s datos de Francia)\n\n## Limitations\n- No funciona bien con clientes nuevos (&lt;6 meses)\n- Performance degrada si Balance &gt; $200,000\n- Requiere actualizaci\u00f3n trimestral\n\n## Caveats and Recommendations\n- Monitorear drift de features mensualmente\n- Threshold 0.5 optimizado para recall; ajustar seg\u00fan caso de uso\n- No usar como \u00fanica fuente para decisiones de negocio\n</code></pre></p>"},{"location":"exams/EXAM_05_PRODUCTION/#ejercicio-4-prometheus-metrics-25-puntos","title":"Ejercicio 4: Prometheus Metrics (25 puntos)","text":""},{"location":"exams/EXAM_05_PRODUCTION/#codigo-a-revisar_2","title":"C\u00f3digo a Revisar","text":"<pre><code># metrics.py\nfrom prometheus_client import Counter\n\npredictions_total = Counter(\"predictions\", \"Total predictions\")\n\ndef predict(data):\n    result = model.predict(data)\n    predictions_total.inc()\n    return result\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#tu-respuesta_2","title":"Tu Respuesta","text":"<p>\u00bfQu\u00e9 m\u00e9tricas faltan para monitoreo de ML en producci\u00f3n?</p> \ud83d\udcdd Ver Soluci\u00f3n  ### M\u00e9tricas Completas  <pre><code>from prometheus_client import Counter, Histogram, Gauge, Summary\nimport time\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Counters: Eventos totales\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nprediction_total = Counter(\n    \"ml_predictions_total\",\n    \"Total de predicciones\",\n    [\"model_version\", \"prediction_class\"]  # Labels\n)\n\nprediction_errors = Counter(\n    \"ml_prediction_errors_total\",\n    \"Total de errores en predicci\u00f3n\",\n    [\"error_type\"]\n)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Histograms: Distribuciones (latencia, probabilidades)\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nprediction_latency = Histogram(\n    \"ml_prediction_latency_seconds\",\n    \"Latencia de predicci\u00f3n\",\n    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]\n)\n\nprediction_probability = Histogram(\n    \"ml_prediction_probability\",\n    \"Distribuci\u00f3n de probabilidades predichas\",\n    buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Gauges: Valores actuales\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nmodel_loaded = Gauge(\n    \"ml_model_loaded\",\n    \"1 si el modelo est\u00e1 cargado, 0 si no\"\n)\n\nfeature_drift = Gauge(\n    \"ml_feature_drift_score\",\n    \"Score de drift por feature\",\n    [\"feature_name\"]\n)\n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n# Uso en predicci\u00f3n\n# \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nMODEL_VERSION = \"1.0.0\"\n\ndef predict_with_metrics(data: dict) -&gt; dict:\n    \"\"\"Predicci\u00f3n con m\u00e9tricas de producci\u00f3n.\"\"\"\n\n    start_time = time.time()\n\n    try:\n        # Predicci\u00f3n\n        result = model.predict(data)\n        probability = model.predict_proba(data)[1]\n\n        # M\u00e9tricas\n        prediction_class = \"churn\" if result == 1 else \"no_churn\"\n        prediction_total.labels(\n            model_version=MODEL_VERSION,\n            prediction_class=prediction_class\n        ).inc()\n\n        prediction_probability.observe(probability)\n\n        return {\n            \"prediction\": int(result),\n            \"probability\": float(probability),\n        }\n\n    except Exception as e:\n        prediction_errors.labels(error_type=type(e).__name__).inc()\n        raise\n\n    finally:\n        latency = time.time() - start_time\n        prediction_latency.observe(latency)\n</code></pre>  ### Alertas Recomendadas (Alertmanager)  <pre><code>groups:\n  - name: ml-alerts\n    rules:\n      - alert: HighPredictionLatency\n        expr: histogram_quantile(0.95, ml_prediction_latency_seconds) &gt; 0.5\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Alta latencia en predicciones\"\n\n      - alert: HighErrorRate\n        expr: rate(ml_prediction_errors_total[5m]) &gt; 0.01\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Tasa de errores &gt; 1%\"\n\n      - alert: PredictionDrift\n        expr: ml_feature_drift_score &gt; 0.3\n        for: 15m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Posible drift en features\"\n</code></pre>"},{"location":"exams/EXAM_05_PRODUCTION/#rubrica","title":"R\u00fabrica","text":"Ejercicio Puntos MLflow 25 Logging 25 Model Card 25 Prometheus 25 TOTAL 100"},{"location":"exams/EXAM_06_INTEGRATION/","title":"\ud83d\udccb Examen de Hito 6: Integraci\u00f3n Final","text":"<p>Formato: Self-Correction Code Review + Proyecto Integrador Duraci\u00f3n: 90 minutos Puntaje m\u00ednimo: 70/100</p>"},{"location":"exams/EXAM_06_INTEGRATION/#ejercicio-1-code-review-integral-40-puntos","title":"Ejercicio 1: Code Review Integral (40 puntos)","text":""},{"location":"exams/EXAM_06_INTEGRATION/#proyecto-completo-a-revisar","title":"Proyecto Completo a Revisar","text":"<p>Revisa este proyecto simplificado e identifica TODOS los problemas:</p> <pre><code>project/\n\u251c\u2500\u2500 train.py\n\u251c\u2500\u2500 predict.py\n\u251c\u2500\u2500 model.pkl\n\u251c\u2500\u2500 data.csv\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <pre><code># train.py\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport pickle\n\ndf = pd.read_csv(\"data.csv\")\nX = df.drop(\"target\", axis=1)\ny = df[\"target\"]\n\nmodel = RandomForestClassifier()\nmodel.fit(X, y)\n\nwith open(\"model.pkl\", \"wb\") as f:\n    pickle.dump(model, f)\n\nprint(f\"Trained! Accuracy: {model.score(X, y)}\")\n</code></pre> <pre><code># predict.py\nimport pickle\nimport pandas as pd\n\nmodel = pickle.load(open(\"model.pkl\", \"rb\"))\n\ndef predict(data):\n    return model.predict(pd.DataFrame([data]))[0]\n</code></pre> <pre><code># requirements.txt\npandas\nscikit-learn\n</code></pre>"},{"location":"exams/EXAM_06_INTEGRATION/#tu-respuesta","title":"Tu Respuesta","text":"<p>Clasifica los problemas por categor\u00eda:</p> Categor\u00eda # Problema Severidad Setup 1 Pipeline 2 Testing 3 Deployment 4 Production 5 \ud83d\udcdd Ver Soluci\u00f3n Completa  ### Problemas por Categor\u00eda  #### Setup (M\u00f3dulo 1) | # | Problema | Severidad | |---|----------|-----------| | 1 | Sin src/ layout | \ud83d\udd34 | | 2 | Sin pyproject.toml | \ud83d\udd34 | | 3 | Sin type hints | \ud83d\udfe1 | | 4 | Sin Pydantic config | \ud83d\udfe1 | | 5 | requirements.txt sin versiones | \ud83d\udd34 |  #### Pipeline (M\u00f3dulo 2) | # | Problema | Severidad | |---|----------|-----------| | 6 | Sin DVC para datos | \ud83d\udfe1 | | 7 | Eval\u00faa en train (leakage) | \ud83d\udd34 | | 8 | Sin train_test_split | \ud83d\udd34 | | 9 | Sin sklearn Pipeline | \ud83d\udfe1 | | 10 | Sin random_state | \ud83d\udfe1 |  #### Testing (M\u00f3dulo 3) | # | Problema | Severidad | |---|----------|-----------| | 11 | Sin tests | \ud83d\udd34 | | 12 | Sin CI/CD | \ud83d\udd34 | | 13 | Sin validaci\u00f3n de datos (Pandera) | \ud83d\udfe1 |  #### Deployment (M\u00f3dulo 4) | # | Problema | Severidad | |---|----------|-----------| | 14 | Sin Dockerfile | \ud83d\udfe1 | | 15 | Sin API (FastAPI) | \ud83d\udfe1 | | 16 | Path hardcodeado \"model.pkl\" | \ud83d\udd34 | | 17 | Pickle inseguro | \ud83d\udfe1 |  #### Production (M\u00f3dulo 5) | # | Problema | Severidad | |---|----------|-----------| | 18 | Sin MLflow tracking | \ud83d\udfe1 | | 19 | Sin logging | \ud83d\udfe1 | | 20 | Sin m\u00e9tricas (Prometheus) | \ud83d\udfe2 | | 21 | Sin Model Card | \ud83d\udfe2 |  ### Proyecto Corregido  <pre><code>bankchurn/\n\u251c\u2500\u2500 src/bankchurn/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 config.py          # Pydantic\n\u2502   \u251c\u2500\u2500 schemas.py         # Pandera\n\u2502   \u251c\u2500\u2500 training.py        # Pipeline + Trainer\n\u2502   \u251c\u2500\u2500 evaluation.py\n\u2502   \u2514\u2500\u2500 prediction.py\n\u251c\u2500\u2500 app/\n\u2502   \u2514\u2500\u2500 fastapi_app.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u251c\u2500\u2500 test_training.py\n\u2502   \u2514\u2500\u2500 test_api.py\n\u251c\u2500\u2500 configs/\n\u2502   \u2514\u2500\u2500 config.yaml\n\u251c\u2500\u2500 data/\n\u2502   \u2514\u2500\u2500 raw/.gitkeep\n\u251c\u2500\u2500 artifacts/\n\u2502   \u2514\u2500\u2500 .gitkeep\n\u251c\u2500\u2500 .github/workflows/\n\u2502   \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 dvc.yaml\n\u251c\u2500\u2500 .pre-commit-config.yaml\n\u2514\u2500\u2500 MODEL_CARD.md\n</code></pre>"},{"location":"exams/EXAM_06_INTEGRATION/#ejercicio-2-debugging-en-produccion-30-puntos","title":"Ejercicio 2: Debugging en Producci\u00f3n (30 puntos)","text":""},{"location":"exams/EXAM_06_INTEGRATION/#escenario","title":"Escenario","text":"<p>Tu API est\u00e1 en producci\u00f3n y recibes esta alerta:</p> <pre><code>ALERT: ml_prediction_latency_p95 &gt; 2s for 10 minutes\nALERT: ml_prediction_errors_total increased 500% in last hour\n</code></pre> <p>Los logs muestran:</p> <pre><code>{\"level\": \"error\", \"msg\": \"prediction_failed\", \"error\": \"ValueError: Input contains NaN\"}\n{\"level\": \"error\", \"msg\": \"prediction_failed\", \"error\": \"ValueError: Input contains NaN\"}\n{\"level\": \"warning\", \"msg\": \"high_latency\", \"latency_ms\": 3420}\n</code></pre>"},{"location":"exams/EXAM_06_INTEGRATION/#tu-respuesta_1","title":"Tu Respuesta","text":"<ol> <li>\u00bfCu\u00e1l es la causa ra\u00edz m\u00e1s probable?</li> <li>\u00bfQu\u00e9 revisar\u00edas primero?</li> <li>\u00bfC\u00f3mo prevendr\u00edas esto en el futuro?</li> </ol> \ud83d\udcdd Ver Soluci\u00f3n  ### 1. Causa Ra\u00edz  **Datos de entrada con NaN** que el modelo no puede procesar: - El preprocessing no maneja NaN - O la validaci\u00f3n de entrada es insuficiente - O el upstream (productor de datos) cambi\u00f3 y ahora env\u00eda campos vac\u00edos  ### 2. Qu\u00e9 Revisar (en orden)  <pre><code># 1. Ver ejemplos de requests fallidos\ngrep \"prediction_failed\" /var/log/app.log | tail -20\n\n# 2. Verificar qu\u00e9 campos tienen NaN\n# En el c\u00f3digo, a\u00f1adir logging temporal:\nlogger.info(\"input_debug\", data=data, has_nan=pd.DataFrame([data]).isnull().any().to_dict())\n\n# 3. Comparar con datos hist\u00f3ricos\n# \u00bfCambi\u00f3 el schema del upstream?\n\n# 4. Verificar versi\u00f3n del modelo\n# \u00bfSe deploy\u00f3 nuevo modelo que espera features diferentes?\n</code></pre>  ### 3. Prevenci\u00f3n Futura  <pre><code># A) Validaci\u00f3n estricta con Pydantic\nclass PredictRequest(BaseModel):\n    CreditScore: int = Field(..., ge=300, le=850)  # No permite None\n    Age: int = Field(..., ge=18)\n    # ...\n\n# B) Validaci\u00f3n con Pandera en el pipeline\n@pa.check_types\ndef preprocess(df: DataFrame[InputSchema]) -&gt; DataFrame[ProcessedSchema]:\n    # Pandera rechaza NaN si no est\u00e1 permitido\n    pass\n\n# C) Fallback graceful\ndef predict_safe(data: dict) -&gt; dict:\n    try:\n        # Validar primero\n        validated = PredictRequest(**data)\n        return predict(validated)\n    except ValidationError as e:\n        logger.warning(\"invalid_input\", errors=e.errors())\n        return {\"error\": \"invalid_input\", \"details\": e.errors()}\n\n# D) Monitoreo de data quality\nfeature_null_rate = Gauge(\n    \"ml_feature_null_rate\",\n    \"Tasa de nulos por feature\",\n    [\"feature\"]\n)\n\n# E) Circuit breaker para upstream degradado\n</code></pre>"},{"location":"exams/EXAM_06_INTEGRATION/#ejercicio-3-diseno-de-sistema-30-puntos","title":"Ejercicio 3: Dise\u00f1o de Sistema (30 puntos)","text":""},{"location":"exams/EXAM_06_INTEGRATION/#requisito","title":"Requisito","text":"<p>Dise\u00f1a la arquitectura para servir el modelo BankChurn con estos requisitos: - 1000 requests/segundo - Latencia p99 &lt; 100ms - 99.9% availability - Reentrenamiento semanal autom\u00e1tico</p>"},{"location":"exams/EXAM_06_INTEGRATION/#tu-respuesta_2","title":"Tu Respuesta","text":"<p>Dibuja (o describe) los componentes y flujos.</p> \ud83d\udcdd Ver Soluci\u00f3n  ### Arquitectura  <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              INFERENCE PATH                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Client \u2500\u2500\u25ba Load Balancer \u2500\u2500\u25ba API Gateway \u2500\u2500\u25ba Model Service (K8s)         \u2502\n\u2502                   \u2502                               \u2502                         \u2502\n\u2502                   \u2502                               \u25bc                         \u2502\n\u2502                   \u2502                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502                   \u2502                          \u2502 Redis   \u2502 (cache)            \u2502\n\u2502                   \u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                   \u2502                               \u2502                         \u2502\n\u2502                   \u25bc                               \u25bc                         \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u2502\n\u2502              \u2502Prometheus\u2502\u25c4\u2500\u2500\u2500\u2500metrics\u2500\u2500\u2500\u2500\u2500\u2500\u2502Model Pod \u2502 x 10 replicas      \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2502\n\u2502                   \u2502                               \u2502                         \u2502\n\u2502                   \u25bc                               \u2502                         \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502                         \u2502\n\u2502              \u2502 Grafana \u2502                         \u2502                         \u2502\n\u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502                         \u2502\n\u2502                                                  \u25bc                         \u2502\n\u2502                                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                   \u2502\n\u2502                                          \u2502 MLflow      \u2502 (model registry)  \u2502\n\u2502                                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              TRAINING PATH                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Schedule (Weekly) \u2500\u2500\u25ba Airflow DAG \u2500\u2500\u25ba Training Job (K8s Job)             \u2502\n\u2502                                              \u2502                              \u2502\n\u2502                                              \u25bc                              \u2502\n\u2502                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                                       \u2502 DVC Remote  \u2502 (S3)                  \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                              \u2502                              \u2502\n\u2502                                              \u25bc                              \u2502\n\u2502                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                                       \u2502 MLflow      \u2502                       \u2502\n\u2502                                       \u2502 - log metrics                       \u2502\n\u2502                                       \u2502 - register model                    \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                              \u2502                              \u2502\n\u2502                                              \u25bc                              \u2502\n\u2502                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                                       \u2502 Model Tests \u2502 (pytest)              \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                              \u2502                              \u2502\n\u2502                                         if pass                             \u2502\n\u2502                                              \u25bc                              \u2502\n\u2502                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                                       \u2502 Promote to  \u2502                       \u2502\n\u2502                                       \u2502 Production  \u2502                       \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                              \u2502                              \u2502\n\u2502                                              \u25bc                              \u2502\n\u2502                                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n\u2502                                       \u2502 Rolling     \u2502                       \u2502\n\u2502                                       \u2502 Deployment  \u2502                       \u2502\n\u2502                                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>  ### Componentes Clave  | Componente | Tecnolog\u00eda | Por qu\u00e9 | |------------|------------|---------| | Load Balancer | AWS ALB / GCP LB | Distribuir tr\u00e1fico | | API Gateway | Kong / AWS API GW | Rate limiting, auth | | Model Service | FastAPI + Uvicorn | Async, r\u00e1pido | | Container Orchestration | Kubernetes | Scaling, self-healing | | Cache | Redis | Reducir latencia repetidas | | Model Registry | MLflow | Versionado de modelos | | Data Versioning | DVC + S3 | Reproducibilidad | | Monitoring | Prometheus + Grafana | M\u00e9tricas y alertas | | Orchestration | Airflow | Scheduling de retraining | | CI/CD | GitHub Actions | Automation |  ### C\u00e1lculos de Capacidad  <pre><code>1000 req/s \u00d7 100ms/req = 100 concurrent requests\n\nCon 10 replicas:\n- 100 concurrent / 10 = 10 concurrent per pod\n- Cada pod con 2 workers = 5 req/worker\n- Margen de seguridad OK\n\nMemory per pod: 512MB\nTotal: 5GB para el servicio\n\nRedis cache hit rate esperado: 30%\n- 700 req/s al modelo\n- 300 req/s desde cache (&lt; 5ms)\n</code></pre>"},{"location":"exams/EXAM_06_INTEGRATION/#rubrica-final","title":"R\u00fabrica Final","text":"Ejercicio Puntos Code Review Integral 40 Debugging Producci\u00f3n 30 Dise\u00f1o de Sistema 30 TOTAL 100"},{"location":"exams/EXAM_06_INTEGRATION/#certificacion","title":"Certificaci\u00f3n","text":"<p>Si obtuviste \u226570 puntos en los 6 ex\u00e1menes:</p> <pre><code>\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n\u2551                                                                              \u2551\n\u2551                    \ud83c\udf93 CERTIFICACI\u00d3N MLOps COMPLETADA                         \u2551\n\u2551                                                                              \u2551\n\u2551   Has demostrado competencia en:                                             \u2551\n\u2551   \u2705 Setup profesional (Python moderno, tipos, validaci\u00f3n)                   \u2551\n\u2551   \u2705 Pipelines reproducibles (DVC, sklearn, sin leakage)                     \u2551\n\u2551   \u2705 Testing &amp; CI/CD (pytest, GitHub Actions, coverage)                      \u2551\n\u2551   \u2705 Deployment (Docker, FastAPI, Kubernetes)                                \u2551\n\u2551   \u2705 Producci\u00f3n (MLflow, logging, monitoreo)                                 \u2551\n\u2551   \u2705 Integraci\u00f3n de sistemas ML end-to-end                                   \u2551\n\u2551                                                                              \u2551\n\u2551   Pr\u00f3ximo paso: Replicar el portafolio ML-MLOps-Portfolio                   \u2551\n\u2551                                                                              \u2551\n\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n</code></pre>"},{"location":"notebooks/07_08_sklearn_pipelines/","title":"\ud83d\udd27 Notebook Interactivo: sklearn Pipelines y Feature Engineering","text":"In\u00a0[\u00a0]: Copied! <pre># Instalaci\u00f3n de dependencias (ejecutar solo si es necesario)\n# !pip install pandas scikit-learn numpy\n</pre> # Instalaci\u00f3n de dependencias (ejecutar solo si es necesario) # !pip install pandas scikit-learn numpy In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import accuracy_score, classification_report\n\nprint(\"\u2705 Librer\u00edas cargadas correctamente\")\n</pre> import pandas as pd import numpy as np from sklearn.pipeline import Pipeline from sklearn.compose import ColumnTransformer from sklearn.preprocessing import StandardScaler, OneHotEncoder from sklearn.impute import SimpleImputer from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split, cross_val_score from sklearn.base import BaseEstimator, TransformerMixin from sklearn.metrics import accuracy_score, classification_report  print(\"\u2705 Librer\u00edas cargadas correctamente\") In\u00a0[\u00a0]: Copied! <pre># Crear dataset sint\u00e9tico\nnp.random.seed(42)\nn_samples = 1000\n\ndata = pd.DataFrame({\n    'CreditScore': np.random.randint(300, 850, n_samples),\n    'Age': np.random.randint(18, 92, n_samples),\n    'Tenure': np.random.randint(0, 10, n_samples),\n    'Balance': np.random.uniform(0, 250000, n_samples),\n    'NumOfProducts': np.random.randint(1, 4, n_samples),\n    'HasCrCard': np.random.randint(0, 2, n_samples),\n    'IsActiveMember': np.random.randint(0, 2, n_samples),\n    'EstimatedSalary': np.random.uniform(10000, 200000, n_samples),\n    'Geography': np.random.choice(['France', 'Germany', 'Spain'], n_samples),\n    'Gender': np.random.choice(['Male', 'Female'], n_samples),\n    'Exited': np.random.randint(0, 2, n_samples)  # Target\n})\n\n# Introducir algunos NaN para hacerlo m\u00e1s realista\ndata.loc[np.random.choice(n_samples, 50), 'Balance'] = np.nan\ndata.loc[np.random.choice(n_samples, 30), 'CreditScore'] = np.nan\n\nprint(f\"Dataset shape: {data.shape}\")\nprint(f\"\\nMissing values:\\n{data.isnull().sum()}\")\ndata.head()\n</pre> # Crear dataset sint\u00e9tico np.random.seed(42) n_samples = 1000  data = pd.DataFrame({     'CreditScore': np.random.randint(300, 850, n_samples),     'Age': np.random.randint(18, 92, n_samples),     'Tenure': np.random.randint(0, 10, n_samples),     'Balance': np.random.uniform(0, 250000, n_samples),     'NumOfProducts': np.random.randint(1, 4, n_samples),     'HasCrCard': np.random.randint(0, 2, n_samples),     'IsActiveMember': np.random.randint(0, 2, n_samples),     'EstimatedSalary': np.random.uniform(10000, 200000, n_samples),     'Geography': np.random.choice(['France', 'Germany', 'Spain'], n_samples),     'Gender': np.random.choice(['Male', 'Female'], n_samples),     'Exited': np.random.randint(0, 2, n_samples)  # Target })  # Introducir algunos NaN para hacerlo m\u00e1s realista data.loc[np.random.choice(n_samples, 50), 'Balance'] = np.nan data.loc[np.random.choice(n_samples, 30), 'CreditScore'] = np.nan  print(f\"Dataset shape: {data.shape}\") print(f\"\\nMissing values:\\n{data.isnull().sum()}\") data.head() In\u00a0[\u00a0]: Copied! <pre># \u274c MAL ENFOQUE - No hacer esto en producci\u00f3n\n\n# Separar features y target\nX = data.drop('Exited', axis=1)\ny = data['Exited']\n\n# \u26a0\ufe0f LEAKAGE: fit en TODO el dataset antes del split\nscaler = StandardScaler()\nnumeric_cols = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n\n# Imputar valores nulos (en todo X)\nX[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n\n# Escalar (en todo X) - \u00a1DATA LEAKAGE!\nX[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n\n# Ahora hacer el split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nprint(\"\u26a0\ufe0f Este c\u00f3digo tiene DATA LEAKAGE\")\nprint(\"El scaler vio informaci\u00f3n del test set antes del split\")\n</pre> # \u274c MAL ENFOQUE - No hacer esto en producci\u00f3n  # Separar features y target X = data.drop('Exited', axis=1) y = data['Exited']  # \u26a0\ufe0f LEAKAGE: fit en TODO el dataset antes del split scaler = StandardScaler() numeric_cols = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']  # Imputar valores nulos (en todo X) X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())  # Escalar (en todo X) - \u00a1DATA LEAKAGE! X[numeric_cols] = scaler.fit_transform(X[numeric_cols])  # Ahora hacer el split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  print(\"\u26a0\ufe0f Este c\u00f3digo tiene DATA LEAKAGE\") print(\"El scaler vio informaci\u00f3n del test set antes del split\") In\u00a0[\u00a0]: Copied! <pre># \u2705 BUEN ENFOQUE - Pipeline unificado\n\n# Definir columnas\nnumeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', \n                    'NumOfProducts', 'EstimatedSalary']\ncategorical_features = ['Geography', 'Gender']\nbinary_features = ['HasCrCard', 'IsActiveMember']\n\n# Preprocessor con ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), numeric_features),\n        ('cat', Pipeline([\n            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n        ]), categorical_features),\n        ('bin', 'passthrough', binary_features)\n    ],\n    remainder='drop'  # Elimina columnas no especificadas\n)\n\n# Pipeline completo\npipe = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\n\nprint(\"\u2705 Pipeline creado:\")\nprint(pipe)\n</pre> # \u2705 BUEN ENFOQUE - Pipeline unificado  # Definir columnas numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance',                      'NumOfProducts', 'EstimatedSalary'] categorical_features = ['Geography', 'Gender'] binary_features = ['HasCrCard', 'IsActiveMember']  # Preprocessor con ColumnTransformer preprocessor = ColumnTransformer(     transformers=[         ('num', Pipeline([             ('imputer', SimpleImputer(strategy='median')),             ('scaler', StandardScaler())         ]), numeric_features),         ('cat', Pipeline([             ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),             ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))         ]), categorical_features),         ('bin', 'passthrough', binary_features)     ],     remainder='drop'  # Elimina columnas no especificadas )  # Pipeline completo pipe = Pipeline([     ('preprocessor', preprocessor),     ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)) ])  print(\"\u2705 Pipeline creado:\") print(pipe) In\u00a0[\u00a0]: Copied! <pre># Separar datos ANTES de cualquier transformaci\u00f3n\nX = data.drop('Exited', axis=1)\ny = data['Exited']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Entrenar pipeline (fit solo en train)\npipe.fit(X_train, y_train)\n\n# Evaluar\ny_pred = pipe.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"\\n\u2705 Accuracy: {accuracy:.3f}\")\nprint(f\"\\n\ud83d\udcca Classification Report:\\n{classification_report(y_test, y_pred)}\")\n</pre> # Separar datos ANTES de cualquier transformaci\u00f3n X = data.drop('Exited', axis=1) y = data['Exited']  X_train, X_test, y_train, y_test = train_test_split(     X, y, test_size=0.2, random_state=42, stratify=y )  # Entrenar pipeline (fit solo en train) pipe.fit(X_train, y_train)  # Evaluar y_pred = pipe.predict(X_test) accuracy = accuracy_score(y_test, y_pred)  print(f\"\\n\u2705 Accuracy: {accuracy:.3f}\") print(f\"\\n\ud83d\udcca Classification Report:\\n{classification_report(y_test, y_pred)}\") In\u00a0[\u00a0]: Copied! <pre># Cross-validation con pipeline\ncv_scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n\nprint(f\"CV Scores: {cv_scores}\")\nprint(f\"Mean CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\")\n</pre> # Cross-validation con pipeline cv_scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')  print(f\"CV Scores: {cv_scores}\") print(f\"Mean CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\") In\u00a0[\u00a0]: Copied! <pre>class AgeGroupTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"Agrupa edades en categor\u00edas.\"\"\"\n    \n    def __init__(self, bins=[0, 25, 35, 50, 65, 100], \n                 labels=['Young', 'Adult', 'Middle', 'Senior', 'Elderly']):\n        self.bins = bins\n        self.labels = labels\n    \n    def fit(self, X, y=None):\n        # No necesita aprender nada de los datos\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        X['AgeGroup'] = pd.cut(X['Age'], bins=self.bins, labels=self.labels)\n        return X\n    \n    def get_feature_names_out(self, input_features=None):\n        return list(input_features) + ['AgeGroup'] if input_features else ['AgeGroup']\n\n\n# Probar el transformer\nage_transformer = AgeGroupTransformer()\ntransformed = age_transformer.fit_transform(X_train[['Age']])\nprint(\"\\n\u2705 AgeGroup distribution:\")\nprint(transformed['AgeGroup'].value_counts())\n</pre> class AgeGroupTransformer(BaseEstimator, TransformerMixin):     \"\"\"Agrupa edades en categor\u00edas.\"\"\"          def __init__(self, bins=[0, 25, 35, 50, 65, 100],                   labels=['Young', 'Adult', 'Middle', 'Senior', 'Elderly']):         self.bins = bins         self.labels = labels          def fit(self, X, y=None):         # No necesita aprender nada de los datos         return self          def transform(self, X):         X = X.copy()         X['AgeGroup'] = pd.cut(X['Age'], bins=self.bins, labels=self.labels)         return X          def get_feature_names_out(self, input_features=None):         return list(input_features) + ['AgeGroup'] if input_features else ['AgeGroup']   # Probar el transformer age_transformer = AgeGroupTransformer() transformed = age_transformer.fit_transform(X_train[['Age']]) print(\"\\n\u2705 AgeGroup distribution:\") print(transformed['AgeGroup'].value_counts()) In\u00a0[\u00a0]: Copied! <pre>class FeatureEngineer(BaseEstimator, TransformerMixin):\n    \"\"\"Custom transformer para crear features derivadas.\n    \n    Similar al FeatureEngineer del portafolio CarVision.\n    \"\"\"\n    \n    def __init__(self, create_balance_salary_ratio=True):\n        self.create_balance_salary_ratio = create_balance_salary_ratio\n        \n    def fit(self, X, y=None):\n        # Guardar columnas originales\n        self.feature_names_in_ = X.columns.tolist()\n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        \n        # Feature 1: Ratio Balance/Salary\n        if self.create_balance_salary_ratio:\n            X['BalanceSalaryRatio'] = X['Balance'] / (X['EstimatedSalary'] + 1)\n        \n        # Feature 2: Tenure por producto\n        X['TenurePerProduct'] = X['Tenure'] / (X['NumOfProducts'] + 0.1)\n        \n        # Feature 3: Cliente maduro (tenure &gt; 5 y activo)\n        X['MatureClient'] = ((X['Tenure'] &gt; 5) &amp; (X['IsActiveMember'] == 1)).astype(int)\n        \n        return X\n    \n    def get_feature_names_out(self, input_features=None):\n        new_features = ['BalanceSalaryRatio', 'TenurePerProduct', 'MatureClient']\n        if input_features is not None:\n            return list(input_features) + new_features\n        return self.feature_names_in_ + new_features\n\n\n# Probar el FeatureEngineer\nfe = FeatureEngineer()\nX_engineered = fe.fit_transform(X_train)\nprint(\"\\n\u2705 Nuevas features creadas:\")\nprint(X_engineered[['Balance', 'EstimatedSalary', 'BalanceSalaryRatio', \n                    'TenurePerProduct', 'MatureClient']].head())\n</pre> class FeatureEngineer(BaseEstimator, TransformerMixin):     \"\"\"Custom transformer para crear features derivadas.          Similar al FeatureEngineer del portafolio CarVision.     \"\"\"          def __init__(self, create_balance_salary_ratio=True):         self.create_balance_salary_ratio = create_balance_salary_ratio              def fit(self, X, y=None):         # Guardar columnas originales         self.feature_names_in_ = X.columns.tolist()         return self          def transform(self, X):         X = X.copy()                  # Feature 1: Ratio Balance/Salary         if self.create_balance_salary_ratio:             X['BalanceSalaryRatio'] = X['Balance'] / (X['EstimatedSalary'] + 1)                  # Feature 2: Tenure por producto         X['TenurePerProduct'] = X['Tenure'] / (X['NumOfProducts'] + 0.1)                  # Feature 3: Cliente maduro (tenure &gt; 5 y activo)         X['MatureClient'] = ((X['Tenure'] &gt; 5) &amp; (X['IsActiveMember'] == 1)).astype(int)                  return X          def get_feature_names_out(self, input_features=None):         new_features = ['BalanceSalaryRatio', 'TenurePerProduct', 'MatureClient']         if input_features is not None:             return list(input_features) + new_features         return self.feature_names_in_ + new_features   # Probar el FeatureEngineer fe = FeatureEngineer() X_engineered = fe.fit_transform(X_train) print(\"\\n\u2705 Nuevas features creadas:\") print(X_engineered[['Balance', 'EstimatedSalary', 'BalanceSalaryRatio',                      'TenurePerProduct', 'MatureClient']].head()) In\u00a0[\u00a0]: Copied! <pre># Pipeline con FeatureEngineer incluido\nnumeric_features_extended = numeric_features + ['BalanceSalaryRatio', 'TenurePerProduct']\nbinary_features_extended = binary_features + ['MatureClient']\n\n# Nuevo preprocessor\npreprocessor_v2 = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), numeric_features_extended),\n        ('cat', Pipeline([\n            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n        ]), categorical_features),\n        ('bin', 'passthrough', binary_features_extended)\n    ],\n    remainder='drop'\n)\n\n# Pipeline completo con feature engineering\npipe_v2 = Pipeline([\n    ('features', FeatureEngineer()),\n    ('preprocessor', preprocessor_v2),\n    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n])\n\nprint(\"\u2705 Pipeline v2 creado con FeatureEngineer\")\nprint(pipe_v2)\n</pre> # Pipeline con FeatureEngineer incluido numeric_features_extended = numeric_features + ['BalanceSalaryRatio', 'TenurePerProduct'] binary_features_extended = binary_features + ['MatureClient']  # Nuevo preprocessor preprocessor_v2 = ColumnTransformer(     transformers=[         ('num', Pipeline([             ('imputer', SimpleImputer(strategy='median')),             ('scaler', StandardScaler())         ]), numeric_features_extended),         ('cat', Pipeline([             ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),             ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))         ]), categorical_features),         ('bin', 'passthrough', binary_features_extended)     ],     remainder='drop' )  # Pipeline completo con feature engineering pipe_v2 = Pipeline([     ('features', FeatureEngineer()),     ('preprocessor', preprocessor_v2),     ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)) ])  print(\"\u2705 Pipeline v2 creado con FeatureEngineer\") print(pipe_v2) In\u00a0[\u00a0]: Copied! <pre># Entrenar y evaluar pipeline v2\npipe_v2.fit(X_train, y_train)\ny_pred_v2 = pipe_v2.predict(X_test)\naccuracy_v2 = accuracy_score(y_test, y_pred_v2)\n\nprint(f\"\\n\ud83d\udcca Comparaci\u00f3n:\")\nprint(f\"Pipeline v1 (sin FeatureEngineer): {accuracy:.3f}\")\nprint(f\"Pipeline v2 (con FeatureEngineer): {accuracy_v2:.3f}\")\nprint(f\"Mejora: {(accuracy_v2 - accuracy)*100:.1f}%\")\n</pre> # Entrenar y evaluar pipeline v2 pipe_v2.fit(X_train, y_train) y_pred_v2 = pipe_v2.predict(X_test) accuracy_v2 = accuracy_score(y_test, y_pred_v2)  print(f\"\\n\ud83d\udcca Comparaci\u00f3n:\") print(f\"Pipeline v1 (sin FeatureEngineer): {accuracy:.3f}\") print(f\"Pipeline v2 (con FeatureEngineer): {accuracy_v2:.3f}\") print(f\"Mejora: {(accuracy_v2 - accuracy)*100:.1f}%\") In\u00a0[\u00a0]: Copied! <pre># \u274c EJEMPLO DE DATA LEAKAGE\n# Crear feature que usa informaci\u00f3n del target\n\ndata_with_leakage = data.copy()\n\n# \u26a0\ufe0f Esta feature usa el target indirectamente\ndata_with_leakage['AvgExitByGeo'] = data_with_leakage.groupby('Geography')['Exited'].transform('mean')\n\nprint(\"\u26a0\ufe0f LEAKAGE: AvgExitByGeo calculado con el target\")\nprint(data_with_leakage[['Geography', 'Exited', 'AvgExitByGeo']].head(10))\n\nprint(\"\\n\ud83d\udd34 Esta feature tiene informaci\u00f3n del futuro (el target).\")\nprint(\"El modelo aprender\u00e1 a 'hacer trampa' usando esta informaci\u00f3n.\")\n</pre> # \u274c EJEMPLO DE DATA LEAKAGE # Crear feature que usa informaci\u00f3n del target  data_with_leakage = data.copy()  # \u26a0\ufe0f Esta feature usa el target indirectamente data_with_leakage['AvgExitByGeo'] = data_with_leakage.groupby('Geography')['Exited'].transform('mean')  print(\"\u26a0\ufe0f LEAKAGE: AvgExitByGeo calculado con el target\") print(data_with_leakage[['Geography', 'Exited', 'AvgExitByGeo']].head(10))  print(\"\\n\ud83d\udd34 Esta feature tiene informaci\u00f3n del futuro (el target).\") print(\"El modelo aprender\u00e1 a 'hacer trampa' usando esta informaci\u00f3n.\") In\u00a0[\u00a0]: Copied! <pre># \u2705 CORRECTO: Calcular estad\u00edsticas solo en el training set\n\nclass TargetEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Target encoding SIN data leakage.\"\"\"\n    \n    def __init__(self, columns):\n        self.columns = columns\n        self.encoding_map_ = {}\n        \n    def fit(self, X, y):\n        \"\"\"Calcula encoding solo con datos de training.\"\"\"\n        df = X.copy()\n        df['__target__'] = y\n        \n        for col in self.columns:\n            self.encoding_map_[col] = df.groupby(col)['__target__'].mean().to_dict()\n            \n        return self\n    \n    def transform(self, X):\n        \"\"\"Aplica encoding aprendido (sin ver y de test).\"\"\"\n        X = X.copy()\n        for col in self.columns:\n            global_mean = np.mean(list(self.encoding_map_[col].values()))\n            X[f'{col}_encoded'] = X[col].map(self.encoding_map_[col]).fillna(global_mean)\n        return X\n\n# Uso correcto\nencoder = TargetEncoder(columns=['Geography'])\nencoder.fit(X_train, y_train)  # Solo usa y_train\n\nX_test_encoded = encoder.transform(X_test)  # No ve y_test\nprint(\"\u2705 Target encoding correcto (sin leakage)\")\nprint(X_test_encoded[['Geography', 'Geography_encoded']].head())\n</pre> # \u2705 CORRECTO: Calcular estad\u00edsticas solo en el training set  class TargetEncoder(BaseEstimator, TransformerMixin):     \"\"\"Target encoding SIN data leakage.\"\"\"          def __init__(self, columns):         self.columns = columns         self.encoding_map_ = {}              def fit(self, X, y):         \"\"\"Calcula encoding solo con datos de training.\"\"\"         df = X.copy()         df['__target__'] = y                  for col in self.columns:             self.encoding_map_[col] = df.groupby(col)['__target__'].mean().to_dict()                      return self          def transform(self, X):         \"\"\"Aplica encoding aprendido (sin ver y de test).\"\"\"         X = X.copy()         for col in self.columns:             global_mean = np.mean(list(self.encoding_map_[col].values()))             X[f'{col}_encoded'] = X[col].map(self.encoding_map_[col]).fillna(global_mean)         return X  # Uso correcto encoder = TargetEncoder(columns=['Geography']) encoder.fit(X_train, y_train)  # Solo usa y_train  X_test_encoded = encoder.transform(X_test)  # No ve y_test print(\"\u2705 Target encoding correcto (sin leakage)\") print(X_test_encoded[['Geography', 'Geography_encoded']].head()) In\u00a0[\u00a0]: Copied! <pre>import joblib\n\n# Guardar pipeline entrenado\njoblib.dump(pipe_v2, 'pipeline_demo.joblib')\nprint(\"\u2705 Pipeline guardado en 'pipeline_demo.joblib'\")\n\n# Cargar pipeline\nloaded_pipe = joblib.load('pipeline_demo.joblib')\n\n# Verificar que funciona igual\ny_pred_loaded = loaded_pipe.predict(X_test)\nassert (y_pred_v2 == y_pred_loaded).all()\nprint(\"\u2705 Pipeline cargado y verificado\")\n</pre> import joblib  # Guardar pipeline entrenado joblib.dump(pipe_v2, 'pipeline_demo.joblib') print(\"\u2705 Pipeline guardado en 'pipeline_demo.joblib'\")  # Cargar pipeline loaded_pipe = joblib.load('pipeline_demo.joblib')  # Verificar que funciona igual y_pred_loaded = loaded_pipe.predict(X_test) assert (y_pred_v2 == y_pred_loaded).all() print(\"\u2705 Pipeline cargado y verificado\") In\u00a0[\u00a0]: Copied! <pre># Limpieza\nimport os\nif os.path.exists('pipeline_demo.joblib'):\n    os.remove('pipeline_demo.joblib')\n    print(\"\ud83e\uddf9 Archivo temporal eliminado\")\n</pre> # Limpieza import os if os.path.exists('pipeline_demo.joblib'):     os.remove('pipeline_demo.joblib')     print(\"\ud83e\uddf9 Archivo temporal eliminado\")"},{"location":"notebooks/07_08_sklearn_pipelines/#notebook-interactivo-sklearn-pipelines-y-feature-engineering","title":"\ud83d\udd27 Notebook Interactivo: sklearn Pipelines y Feature Engineering\u00b6","text":"<p>M\u00f3dulos 07-08 de la Gu\u00eda MLOps</p> <p>Este notebook te permite experimentar con los conceptos de:</p> <ul> <li>sklearn Pipelines</li> <li>ColumnTransformer</li> <li>Custom Transformers</li> <li>Detecci\u00f3n de Data Leakage</li> </ul>"},{"location":"notebooks/07_08_sklearn_pipelines/#1-setup-inicial","title":"1. Setup Inicial\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#2-crear-dataset-de-ejemplo","title":"2. Crear Dataset de Ejemplo\u00b6","text":"<p>Simulamos un dataset de Bank Churn similar al del portafolio.</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#3-pipeline-basico-modulo-07","title":"3. Pipeline B\u00e1sico (M\u00f3dulo 07)\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#31-el-problema-sin-pipeline","title":"3.1 El problema SIN Pipeline\u00b6","text":"<p>\u274c C\u00f3digo fr\u00e1gil y con riesgo de data leakage:</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#32-la-solucion-con-pipeline","title":"3.2 La soluci\u00f3n CON Pipeline\u00b6","text":"<p>\u2705 C\u00f3digo robusto sin data leakage:</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#33-cross-validation-con-pipeline","title":"3.3 Cross-Validation con Pipeline\u00b6","text":"<p>El pipeline garantiza que cada fold se procesa correctamente:</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#4-custom-transformer-modulo-08","title":"4. Custom Transformer (M\u00f3dulo 08)\u00b6","text":"<p>Crear transformers personalizados para feature engineering:</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#5-pipeline-completo-con-custom-transformer","title":"5. Pipeline Completo con Custom Transformer\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#6-deteccion-de-data-leakage-modulo-08","title":"6. Detecci\u00f3n de Data Leakage (M\u00f3dulo 08)\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#ejemplo-de-data-leakage","title":"\ud83d\udd34 Ejemplo de Data Leakage\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#como-evitar-el-leakage","title":"\u2705 C\u00f3mo evitar el leakage\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#7-guardar-y-cargar-pipeline","title":"7. Guardar y Cargar Pipeline\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#8-ejercicios-para-practicar","title":"8. Ejercicios para Practicar\u00b6","text":""},{"location":"notebooks/07_08_sklearn_pipelines/#ejercicio-1-anade-un-nuevo-transformer","title":"Ejercicio 1: A\u00f1ade un nuevo transformer\u00b6","text":"<p>Crea un transformer que agrupe <code>CreditScore</code> en categor\u00edas (Poor, Fair, Good, Excellent).</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#ejercicio-2-detecta-el-leakage","title":"Ejercicio 2: Detecta el leakage\u00b6","text":"<p>\u00bfQu\u00e9 pasa si a\u00f1ades <code>X['ExitedPrediction'] = y</code> antes del split?</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#ejercicio-3-compara-modelos","title":"Ejercicio 3: Compara modelos\u00b6","text":"<p>Reemplaza <code>RandomForestClassifier</code> por <code>GradientBoostingClassifier</code> y compara.</p>"},{"location":"notebooks/07_08_sklearn_pipelines/#recursos","title":"\ud83d\udcda Recursos\u00b6","text":"<ul> <li>M\u00f3dulo 07: sklearn Pipelines</li> <li>M\u00f3dulo 08: Feature Engineering</li> <li>EJERCICIOS.md - Ejercicios 7.1, 7.2, 8.1, 8.2</li> <li>RECURSOS_POR_MODULO.md - Videos recomendados</li> </ul>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/","title":"\ud83d\udd2c Lab 1: \"Funciona en Local, Falla en Docker\"","text":"<p>Escenario: Tu modelo entrena perfecto localmente pero crashea en el contenedor Duraci\u00f3n: 30 minutos Habilidad: Debugging de containerizaci\u00f3n</p>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#el-escenario","title":"El Escenario","text":"<p>Tu equipo reporta:</p> <p>\"El pipeline de training funciona perfecto en mi laptop, pero cuando lo corro en Docker da error de import y luego el modelo predice diferente.\"</p>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-1-reproduce-el-error","title":"Paso 1: Reproduce el Error","text":""},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#codigo-local-funciona","title":"C\u00f3digo Local (funciona)","text":"<pre><code># train.py\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nimport joblib\n\ndf = pd.read_csv(\"data/customers.csv\")\nX = df.drop(\"Exited\", axis=1)\ny = df[\"Exited\"]\n\nmodel = RandomForestClassifier(n_estimators=100)\nmodel.fit(X, y)\njoblib.dump(model, \"model.pkl\")\nprint(\"\u2705 Modelo guardado\")\n</code></pre> <pre><code># Local\npython train.py\n# Output: \u2705 Modelo guardado\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\nCMD [\"python\", \"train.py\"]\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#error-en-docker","title":"Error en Docker","text":"<pre><code>docker build -t mymodel .\ndocker run mymodel\n\n# Output:\n# Traceback (most recent call last):\n#   File \"/app/train.py\", line 2, in &lt;module&gt;\n#     from sklearn.ensemble import RandomForestClassifier\n# ModuleNotFoundError: No module named 'sklearn'\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-2-diagnostico","title":"Paso 2: Diagn\u00f3stico","text":""},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#revisa-requirementstxt","title":"\ud83d\udd0d Revisa requirements.txt","text":"<pre><code>pandas\nscikit-learn\njoblib\n</code></pre> <p>Pregunta: \u00bfVes el problema?</p> \ud83d\udca1 Pista  El archivo tiene formato correcto, pero... - \u00bfLas versiones est\u00e1n especificadas? - \u00bfHay alguna dependencia impl\u00edcita?"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-3-error-1-dependencias-sin-version","title":"Paso 3: Error 1 - Dependencias sin Versi\u00f3n","text":""},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#el-problema","title":"El Problema","text":"<pre><code># requirements.txt MALO\npandas\nscikit-learn\njoblib\n</code></pre> <p>Sin versiones, <code>pip install</code> toma la \u00faltima versi\u00f3n disponible. - En tu laptop: instalaste hace 3 meses - En Docker: instala la versi\u00f3n de HOY</p>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#la-solucion","title":"La Soluci\u00f3n","text":"<pre><code># requirements.txt BUENO\npandas==2.0.3\nscikit-learn==1.3.0\njoblib==1.3.2\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#como-obtener-versiones-exactas","title":"C\u00f3mo Obtener Versiones Exactas","text":"<pre><code>pip freeze &gt; requirements.txt\n# O solo las principales:\npip freeze | grep -E \"pandas|scikit|joblib\"\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-4-error-2-path-hardcodeado","title":"Paso 4: Error 2 - Path Hardcodeado","text":"<p>Despu\u00e9s de arreglar dependencias, nuevo error:</p> <pre><code>docker run mymodel\n\n# Output:\n# FileNotFoundError: [Errno 2] No such file or directory: 'data/customers.csv'\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#el-problema_1","title":"El Problema","text":"<pre><code># \u274c Path relativo asume estructura local\ndf = pd.read_csv(\"data/customers.csv\")\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#la-solucion_1","title":"La Soluci\u00f3n","text":"<pre><code># \u2705 Path relativo al script, no al CWD\nfrom pathlib import Path\n\nSCRIPT_DIR = Path(__file__).parent.resolve()\nDATA_PATH = SCRIPT_DIR / \"data\" / \"customers.csv\"\n\ndf = pd.read_csv(DATA_PATH)\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#o-mejor-variable-de-entorno","title":"O Mejor: Variable de Entorno","text":"<pre><code>import os\nfrom pathlib import Path\n\nDATA_PATH = Path(os.getenv(\"DATA_PATH\", \"data/customers.csv\"))\ndf = pd.read_csv(DATA_PATH)\n</code></pre> <pre><code>ENV DATA_PATH=/app/data/customers.csv\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-5-error-3-modelo-predice-diferente","title":"Paso 5: Error 3 - Modelo Predice Diferente","text":"<p>Ahora el training funciona, pero las predicciones son diferentes:</p> <pre><code># Local\npython predict.py\n# Accuracy: 0.847\n\n# Docker  \ndocker run mymodel python predict.py\n# Accuracy: 0.823  # \u2190 \u00a1Diferente!\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#el-problema_2","title":"El Problema","text":"<pre><code># \u274c Sin random_state\nmodel = RandomForestClassifier(n_estimators=100)\n</code></pre> <p>RandomForest usa n\u00fameros aleatorios. Sin seed fijo: - Cada ejecuci\u00f3n da resultados diferentes - Imposible reproducir</p>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#la-solucion_2","title":"La Soluci\u00f3n","text":"<pre><code># \u2705 Seed fijo para reproducibilidad\nmodel = RandomForestClassifier(\n    n_estimators=100,\n    random_state=42,  # \u2190 Siempre el mismo resultado\n    n_jobs=-1\n)\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#paso-6-error-4-numpypickle-incompatible","title":"Paso 6: Error 4 - NumPy/Pickle Incompatible","text":"<pre><code># Error al cargar modelo en Docker:\n# ValueError: numpy.ndarray size changed, may indicate binary incompatibility\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#el-problema_3","title":"El Problema","text":"<ul> <li>Modelo guardado con <code>numpy==1.24.0</code></li> <li>Docker tiene <code>numpy==1.26.0</code></li> <li>Pickle de sklearn es sensible a versiones</li> </ul>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#la-solucion_3","title":"La Soluci\u00f3n","text":"<p>Opci\u00f3n 1: Pinear versiones exactas</p> <pre><code>numpy==1.24.0\nscikit-learn==1.3.0\n</code></pre> <p>Opci\u00f3n 2: Usar formato ONNX (portable)</p> <pre><code>import skl2onnx\nfrom skl2onnx import convert_sklearn\n\nonnx_model = convert_sklearn(model, initial_types=[...])\nwith open(\"model.onnx\", \"wb\") as f:\n    f.write(onnx_model.SerializeToString())\n</code></pre> <p>Opci\u00f3n 3: MLflow (incluye metadata de versiones)</p> <pre><code>import mlflow.sklearn\n\nmlflow.sklearn.save_model(model, \"model_mlflow\")\n# Guarda pip_requirements.txt autom\u00e1ticamente\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#dockerfile-final-corregido","title":"Dockerfile Final Corregido","text":"<pre><code># \u2705 Dockerfile de producci\u00f3n\nFROM python:3.11-slim as base\n\n# Evita .pyc y buffering\nENV PYTHONDONTWRITEBYTECODE=1\nENV PYTHONUNBUFFERED=1\n\nWORKDIR /app\n\n# Dependencias primero (cache de Docker)\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# C\u00f3digo despu\u00e9s\nCOPY src/ ./src/\nCOPY configs/ ./configs/\n\n# Usuario no-root\nRUN useradd --create-home appuser\nUSER appuser\n\n# Variables de entorno\nENV DATA_PATH=/app/data\nENV MODEL_PATH=/app/models\n\nCMD [\"python\", \"-m\", \"src.train\"]\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#checklist-de-debugging-docker","title":"Checklist de Debugging Docker","text":"<pre><code>\u25a1 requirements.txt tiene versiones exactas\n\u25a1 Paths usan Path() o variables de entorno  \n\u25a1 random_state en todos los modelos\n\u25a1 Versiones de numpy/sklearn coinciden\n\u25a1 Dockerfile copia archivos en orden correcto\n\u25a1 Usuario no-root para seguridad\n\u25a1 Variables de entorno para configuraci\u00f3n\n</code></pre>"},{"location":"notebooks/labs/LAB_01_DOCKER_DEBUG/#ejercicio-final","title":"Ejercicio Final","text":"<p>Dado este error:</p> <pre><code>docker run mymodel\n# RuntimeError: can't start new thread\n</code></pre> <p>\u00bfCu\u00e1l es la causa m\u00e1s probable?</p> \ud83d\udca1 Respuesta  `n_jobs=-1` en RandomForest intenta usar todos los cores. En Docker con recursos limitados, puede fallar.  **Soluci\u00f3n**: <pre><code>model = RandomForestClassifier(\n    n_estimators=100,\n    n_jobs=2,  # Limitar threads\n    random_state=42\n)\n</code></pre>  O en Docker: <pre><code>docker run --cpus=2 mymodel\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/","title":"\ud83d\udd2c Lab 2: Pipeline de Entrenamiento Lento por Pandas","text":"<p>Escenario: El pipeline tarda 10x m\u00e1s de lo esperado Duraci\u00f3n: 30 minutos Habilidad: Optimizaci\u00f3n de Pandas</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#el-escenario","title":"El Escenario","text":"<p>Tu pipeline de features tarda 45 minutos en procesar 1M de filas. El equipo de infra dice: \"Con ese tiempo, no podemos hacer reentrenamiento diario.\"</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#codigo-original-lento","title":"C\u00f3digo Original (Lento)","text":"<pre><code># features.py - VERSI\u00d3N LENTA\nimport pandas as pd\n\ndef engineer_features(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Feature engineering - tarda 45 min en 1M filas.\"\"\"\n\n    # Feature 1: Ratio por fila\n    for idx in range(len(df)):\n        df.loc[idx, \"BalanceRatio\"] = df.loc[idx, \"Balance\"] / (df.loc[idx, \"Salary\"] + 1)\n\n    # Feature 2: Categor\u00eda de edad\n    for idx, row in df.iterrows():\n        if row[\"Age\"] &lt; 25:\n            df.loc[idx, \"AgeGroup\"] = \"young\"\n        elif row[\"Age\"] &lt; 50:\n            df.loc[idx, \"AgeGroup\"] = \"middle\"\n        else:\n            df.loc[idx, \"AgeGroup\"] = \"senior\"\n\n    # Feature 3: Agregaci\u00f3n por grupo\n    for customer_id in df[\"CustomerId\"].unique():\n        mask = df[\"CustomerId\"] == customer_id\n        total = df.loc[mask, \"TransactionAmount\"].sum()\n        df.loc[mask, \"CustomerTotal\"] = total\n\n    return df\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#paso-1-identificar-los-anti-patrones","title":"Paso 1: Identificar los Anti-patrones","text":""},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#anti-patron-1-for-idx-in-rangelendf","title":"\ud83d\udd34 Anti-patr\u00f3n 1: <code>for idx in range(len(df))</code>","text":"<pre><code># \u274c MALO: Iteraci\u00f3n expl\u00edcita\nfor idx in range(len(df)):\n    df.loc[idx, \"NewCol\"] = df.loc[idx, \"A\"] / df.loc[idx, \"B\"]\n</code></pre> <p>Problema:  - <code>df.loc[idx, ...]</code> es O(n) para encontrar la fila - Total: O(n\u00b2) complejidad</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#anti-patron-2-dfiterrows","title":"\ud83d\udd34 Anti-patr\u00f3n 2: <code>df.iterrows()</code>","text":"<pre><code># \u274c MALO: iterrows es lent\u00edsimo\nfor idx, row in df.iterrows():\n    df.loc[idx, \"Category\"] = categorize(row[\"Value\"])\n</code></pre> <p>Problema: - Crea una Series por cada fila (copia de memoria) - ~100x m\u00e1s lento que vectorizado</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#anti-patron-3-loop-sobre-valores-unicos","title":"\ud83d\udd34 Anti-patr\u00f3n 3: Loop sobre valores \u00fanicos","text":"<pre><code># \u274c MALO: Recalcula m\u00e1scara cada vez\nfor group in df[\"Group\"].unique():\n    mask = df[\"Group\"] == group\n    df.loc[mask, \"GroupSum\"] = df.loc[mask, \"Value\"].sum()\n</code></pre> <p>Problema: - Recrea m\u00e1scara booleana en cada iteraci\u00f3n - No usa las optimizaciones de groupby</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#paso-2-soluciones-vectorizadas","title":"Paso 2: Soluciones Vectorizadas","text":""},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#solucion-1-operaciones-vectorizadas","title":"\u2705 Soluci\u00f3n 1: Operaciones Vectorizadas","text":"<pre><code># \u2705 BUENO: Operaci\u00f3n vectorizada (1 l\u00ednea)\ndf[\"BalanceRatio\"] = df[\"Balance\"] / (df[\"Salary\"] + 1)\n</code></pre> <p>Speedup: ~1000x</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#solucion-2-npselect-o-pdcut","title":"\u2705 Soluci\u00f3n 2: np.select o pd.cut","text":"<pre><code># \u2705 BUENO: np.select para condiciones m\u00faltiples\nimport numpy as np\n\nconditions = [\n    df[\"Age\"] &lt; 25,\n    df[\"Age\"] &lt; 50,\n    df[\"Age\"] &gt;= 50\n]\nchoices = [\"young\", \"middle\", \"senior\"]\ndf[\"AgeGroup\"] = np.select(conditions, choices, default=\"unknown\")\n\n# O m\u00e1s limpio con pd.cut:\ndf[\"AgeGroup\"] = pd.cut(\n    df[\"Age\"],\n    bins=[0, 25, 50, 120],\n    labels=[\"young\", \"middle\", \"senior\"]\n)\n</code></pre> <p>Speedup: ~500x</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#solucion-3-groupby-transform","title":"\u2705 Soluci\u00f3n 3: GroupBy + Transform","text":"<pre><code># \u2705 BUENO: groupby().transform() mantiene \u00edndice original\ndf[\"CustomerTotal\"] = df.groupby(\"CustomerId\")[\"TransactionAmount\"].transform(\"sum\")\n</code></pre> <p>Speedup: ~100x</p>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#paso-3-codigo-optimizado-completo","title":"Paso 3: C\u00f3digo Optimizado Completo","text":"<pre><code># features.py - VERSI\u00d3N R\u00c1PIDA\nimport pandas as pd\nimport numpy as np\n\ndef engineer_features(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Feature engineering optimizado - 30 segundos en 1M filas.\"\"\"\n\n    df = df.copy()  # No modificar original\n\n    # Feature 1: Vectorizado\n    df[\"BalanceRatio\"] = df[\"Balance\"] / (df[\"Salary\"] + 1)\n\n    # Feature 2: pd.cut\n    df[\"AgeGroup\"] = pd.cut(\n        df[\"Age\"],\n        bins=[0, 25, 50, 120],\n        labels=[\"young\", \"middle\", \"senior\"]\n    )\n\n    # Feature 3: groupby + transform\n    df[\"CustomerTotal\"] = (\n        df.groupby(\"CustomerId\")[\"TransactionAmount\"]\n        .transform(\"sum\")\n    )\n\n    return df\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#paso-4-benchmark","title":"Paso 4: Benchmark","text":"<pre><code>import time\nimport pandas as pd\nimport numpy as np\n\n# Crear datos de prueba\nn_rows = 1_000_000\ndf = pd.DataFrame({\n    \"CustomerId\": np.random.randint(1, 10000, n_rows),\n    \"Age\": np.random.randint(18, 80, n_rows),\n    \"Balance\": np.random.uniform(0, 100000, n_rows),\n    \"Salary\": np.random.uniform(20000, 150000, n_rows),\n    \"TransactionAmount\": np.random.uniform(10, 1000, n_rows),\n})\n\n# Benchmark\ndef time_function(func, df, name):\n    start = time.time()\n    result = func(df.copy())\n    elapsed = time.time() - start\n    print(f\"{name}: {elapsed:.2f} segundos\")\n    return result\n\n# Resultados t\u00edpicos:\n# Versi\u00f3n lenta: 2700.00 segundos (45 min)\n# Versi\u00f3n r\u00e1pida: 0.89 segundos\n# Speedup: 3000x\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#paso-5-mas-optimizaciones","title":"Paso 5: M\u00e1s Optimizaciones","text":""},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#usar-dtypes-correctos","title":"Usar Dtypes Correctos","text":"<pre><code># \u274c MALO: Todo como object/float64\ndf = pd.read_csv(\"data.csv\")\n\n# \u2705 BUENO: Especificar dtypes\ndf = pd.read_csv(\n    \"data.csv\",\n    dtype={\n        \"CustomerId\": \"int32\",      # vs int64\n        \"Age\": \"int8\",               # vs int64\n        \"Category\": \"category\",      # vs object\n        \"IsActive\": \"bool\",          # vs int64\n    }\n)\n\n# Reducci\u00f3n de memoria: ~70%\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#usar-query-para-filtros","title":"Usar query() para Filtros","text":"<pre><code># \u274c MALO: M\u00e1scaras booleanas complejas\nresult = df[(df[\"Age\"] &gt; 25) &amp; (df[\"Balance\"] &gt; 1000) &amp; (df[\"Status\"] == \"active\")]\n\n# \u2705 BUENO: query() usa numexpr (m\u00e1s r\u00e1pido)\nresult = df.query(\"Age &gt; 25 and Balance &gt; 1000 and Status == 'active'\")\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#usar-eval-para-calculos","title":"Usar eval() para C\u00e1lculos","text":"<pre><code># \u274c MALO: Crea intermedios\ndf[\"Result\"] = (df[\"A\"] + df[\"B\"]) / (df[\"C\"] * df[\"D\"])\n\n# \u2705 BUENO: eval() sin intermedios\ndf[\"Result\"] = df.eval(\"(A + B) / (C * D)\")\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#checklist-de-optimizacion-pandas","title":"Checklist de Optimizaci\u00f3n Pandas","text":"<pre><code>\u25a1 Eliminar loops expl\u00edcitos (for, iterrows)\n\u25a1 Usar operaciones vectorizadas\n\u25a1 Usar np.select/pd.cut para categor\u00edas\n\u25a1 Usar groupby().transform() para agregaciones\n\u25a1 Especificar dtypes al cargar CSV\n\u25a1 Usar category para strings repetitivos\n\u25a1 Usar query() para filtros complejos\n\u25a1 Usar eval() para f\u00f3rmulas\n</code></pre>"},{"location":"notebooks/labs/LAB_02_PANDAS_PERFORMANCE/#ejercicio-final","title":"Ejercicio Final","text":"<p>Optimiza este c\u00f3digo:</p> <pre><code># Tarda 10 minutos\ndef calculate_metrics(df):\n    results = []\n    for customer in df[\"CustomerId\"].unique():\n        customer_data = df[df[\"CustomerId\"] == customer]\n        results.append({\n            \"CustomerId\": customer,\n            \"TotalSpend\": customer_data[\"Amount\"].sum(),\n            \"AvgSpend\": customer_data[\"Amount\"].mean(),\n            \"MaxSpend\": customer_data[\"Amount\"].max(),\n        })\n    return pd.DataFrame(results)\n</code></pre> \ud83d\udca1 Soluci\u00f3n <pre><code># Tarda 0.5 segundos\ndef calculate_metrics(df):\n    return df.groupby(\"CustomerId\")[\"Amount\"].agg(\n        TotalSpend=\"sum\",\n        AvgSpend=\"mean\",\n        MaxSpend=\"max\"\n    ).reset_index()\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/","title":"\ud83d\udd2c Lab 3: Conflicto de Dependencias sklearn/Pickle","text":"<p>Escenario: Modelo no carga en producci\u00f3n por incompatibilidad de versiones Duraci\u00f3n: 30 minutos Habilidad: Gesti\u00f3n de dependencias y serializaci\u00f3n</p>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#el-escenario","title":"El Escenario","text":"<p>Tu equipo reporta:</p> <p>\"El modelo entrena bien en desarrollo pero no carga en el servidor de producci\u00f3n. Da error de numpy o pickle.\"</p>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#paso-1-reproduce-el-error","title":"Paso 1: Reproduce el Error","text":""},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#entorno-de-desarrollo","title":"Entorno de Desarrollo","text":"<pre><code># Tu m\u00e1quina (donde entrenas)\npip freeze | grep -E \"numpy|scikit\"\n# numpy==1.24.3\n# scikit-learn==1.3.0\n</code></pre> <pre><code># train.py\nfrom sklearn.ensemble import RandomForestClassifier\nimport joblib\n\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\njoblib.dump(model, \"model.joblib\")\nprint(\"\u2705 Modelo guardado\")\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#entorno-de-produccion","title":"Entorno de Producci\u00f3n","text":"<pre><code># Servidor (donde cargas)\npip freeze | grep -E \"numpy|scikit\"\n# numpy==1.26.0  # \u2190 DIFERENTE\n# scikit-learn==1.4.0  # \u2190 DIFERENTE\n</code></pre> <pre><code># predict.py\nimport joblib\n\nmodel = joblib.load(\"model.joblib\")\n# \ud83d\udca5 ERROR!\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#el-error","title":"El Error","text":"<pre><code>Traceback (most recent call last):\n  File \"predict.py\", line 3, in &lt;module&gt;\n    model = joblib.load(\"model.joblib\")\n  ...\nModuleNotFoundError: No module named 'sklearn.ensemble._forest'\n\n# O este otro error com\u00fan:\nValueError: numpy.ndarray size changed, may indicate binary incompatibility. \nExpected 88 from C header, got 80 from PyObject\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#paso-2-diagnostico","title":"Paso 2: Diagn\u00f3stico","text":""},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#por-que-ocurre","title":"\u00bfPor qu\u00e9 ocurre?","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EL PROBLEMA DE PICKLE                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   joblib/pickle guarda:                                                     \u2502\n\u2502   \u251c\u2500\u2500 Los pesos del modelo (n\u00fameros)                                        \u2502\n\u2502   \u251c\u2500\u2500 La estructura de clases (sklearn.ensemble._forest.RandomForest...)   \u2502\n\u2502   \u2514\u2500\u2500 Referencias a numpy arrays (con formato binario espec\u00edfico)          \u2502\n\u2502                                                                             \u2502\n\u2502   Si las versiones cambian:                                                 \u2502\n\u2502   \u251c\u2500\u2500 sklearn puede renombrar m\u00f3dulos internos                             \u2502\n\u2502   \u251c\u2500\u2500 numpy puede cambiar el formato binario de arrays                     \u2502\n\u2502   \u2514\u2500\u2500 El pickle no encuentra las clases originales                         \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#verificar-incompatibilidad","title":"Verificar Incompatibilidad","text":"<pre><code># Inspeccionar metadata del modelo\nimport joblib\nimport pickle\n\n# Ver qu\u00e9 versi\u00f3n se us\u00f3 para guardar\nwith open(\"model.joblib\", \"rb\") as f:\n    # joblib no guarda metadata de versi\u00f3n por defecto\n    pass\n\n# En sklearn &gt;= 1.3, puedes verificar:\ntry:\n    model = joblib.load(\"model.joblib\")\n    print(f\"sklearn version: {model.__sklearn_version__}\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#paso-3-soluciones","title":"Paso 3: Soluciones","text":""},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#solucion-1-pinear-versiones-exactas-rapida","title":"Soluci\u00f3n 1: Pinear Versiones Exactas (R\u00e1pida)","text":"<pre><code># requirements.txt\nnumpy==1.24.3\nscikit-learn==1.3.0\njoblib==1.3.2\n</code></pre> <pre><code># En producci\u00f3n\npip install -r requirements.txt\n</code></pre> <p>Pros: F\u00e1cil, r\u00e1pido Cons: No resuelve el problema a largo plazo, dependencias pueden conflictuar</p>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#solucion-2-guardar-con-metadata-recomendada","title":"Soluci\u00f3n 2: Guardar con Metadata (Recomendada)","text":"<pre><code># train.py\nimport joblib\nimport sklearn\nimport numpy as np\nfrom pathlib import Path\n\ndef save_model_with_metadata(model, path: str):\n    \"\"\"Guarda modelo con metadata de versiones.\"\"\"\n    artifact = {\n        \"model\": model,\n        \"metadata\": {\n            \"sklearn_version\": sklearn.__version__,\n            \"numpy_version\": np.__version__,\n            \"python_version\": \"3.11\",\n            \"created_at\": \"2024-01-15\",\n        }\n    }\n    joblib.dump(artifact, path)\n    print(f\"\u2705 Guardado con sklearn={sklearn.__version__}, numpy={np.__version__}\")\n\ndef load_model_with_check(path: str):\n    \"\"\"Carga modelo verificando versiones.\"\"\"\n    artifact = joblib.load(path)\n\n    meta = artifact[\"metadata\"]\n\n    # Verificar compatibilidad\n    if sklearn.__version__ != meta[\"sklearn_version\"]:\n        print(f\"\u26a0\ufe0f WARNING: Modelo entrenado con sklearn {meta['sklearn_version']}, \"\n              f\"pero tienes {sklearn.__version__}\")\n\n    if np.__version__.split(\".\")[:2] != meta[\"numpy_version\"].split(\".\")[:2]:\n        print(f\"\u26a0\ufe0f WARNING: Modelo entrenado con numpy {meta['numpy_version']}, \"\n              f\"pero tienes {np.__version__}\")\n\n    return artifact[\"model\"]\n\n# Uso\nsave_model_with_metadata(model, \"model_v1.joblib\")\nmodel = load_model_with_check(\"model_v1.joblib\")\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#solucion-3-usar-mlflow-profesional","title":"Soluci\u00f3n 3: Usar MLflow (Profesional)","text":"<pre><code># train.py\nimport mlflow\nimport mlflow.sklearn\n\nmlflow.set_experiment(\"bankchurn\")\n\nwith mlflow.start_run():\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n\n    # MLflow guarda autom\u00e1ticamente:\n    # - El modelo\n    # - requirements.txt con versiones exactas\n    # - conda.yaml con entorno completo\n    mlflow.sklearn.log_model(\n        model,\n        artifact_path=\"model\",\n        registered_model_name=\"bankchurn-classifier\"\n    )\n\n# En producci\u00f3n:\nmodel_uri = \"models:/bankchurn-classifier/Production\"\nmodel = mlflow.sklearn.load_model(model_uri)\n# MLflow verifica compatibilidad autom\u00e1ticamente\n</code></pre> <p>Estructura que MLflow crea:</p> <pre><code>mlruns/\n\u2514\u2500\u2500 &lt;run_id&gt;/\n    \u2514\u2500\u2500 artifacts/\n        \u2514\u2500\u2500 model/\n            \u251c\u2500\u2500 MLmodel           # Metadata del modelo\n            \u251c\u2500\u2500 model.pkl         # El modelo serializado\n            \u251c\u2500\u2500 conda.yaml        # Entorno conda completo\n            \u251c\u2500\u2500 requirements.txt  # Versiones pip exactas\n            \u2514\u2500\u2500 python_env.yaml   # Versi\u00f3n de Python\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#solucion-4-onnx-maxima-portabilidad","title":"Soluci\u00f3n 4: ONNX (M\u00e1xima Portabilidad)","text":"<pre><code># train.py\nfrom skl2onnx import convert_sklearn\nfrom skl2onnx.common.data_types import FloatTensorType\n\n# Entrenar modelo sklearn\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Convertir a ONNX\ninitial_type = [(\"float_input\", FloatTensorType([None, X_train.shape[1]]))]\nonnx_model = convert_sklearn(model, initial_types=initial_type)\n\n# Guardar\nwith open(\"model.onnx\", \"wb\") as f:\n    f.write(onnx_model.SerializeToString())\n</code></pre> <pre><code># predict.py (producci\u00f3n)\nimport onnxruntime as rt\nimport numpy as np\n\n# Cargar (NO depende de sklearn!)\nsess = rt.InferenceSession(\"model.onnx\")\n\n# Predecir\ninput_name = sess.get_inputs()[0].name\npredictions = sess.run(None, {input_name: X_test.astype(np.float32)})[0]\n</code></pre> <p>Pros: M\u00e1xima portabilidad, no depende de sklearn en producci\u00f3n Cons: No todos los modelos son convertibles, pierde algunos m\u00e9todos</p>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#paso-4-prevencion","title":"Paso 4: Prevenci\u00f3n","text":""},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#en-pyprojecttoml","title":"En pyproject.toml","text":"<pre><code>[project]\ndependencies = [\n    \"numpy&gt;=1.24.0,&lt;1.25.0\",      # Rango estrecho\n    \"scikit-learn&gt;=1.3.0,&lt;1.4.0\", # Rango estrecho\n    \"joblib&gt;=1.3.0,&lt;1.4.0\",\n]\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#en-cicd","title":"En CI/CD","text":"<pre><code># .github/workflows/ci.yml\n- name: Check model compatibility\n  run: |\n    python -c \"\n    import joblib\n    model = joblib.load('models/model.joblib')\n    print(f'Model loaded successfully')\n    print(f'sklearn version: {model.__sklearn_version__}')\n    \"\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#en-dockerfile","title":"En Dockerfile","text":"<pre><code># Fijar versiones exactas\nCOPY requirements.lock .\nRUN pip install --no-cache-dir -r requirements.lock\n\n# requirements.lock generado con:\n# pip freeze &gt; requirements.lock\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#checklist-de-debugging","title":"Checklist de Debugging","text":"<pre><code>\u25a1 Verificar versiones en desarrollo vs producci\u00f3n\n\u25a1 Comparar numpy major.minor (1.24 vs 1.26 = incompatible)\n\u25a1 Comparar sklearn major.minor (1.3 vs 1.4 = posiblemente incompatible)\n\u25a1 Verificar que requirements.txt tiene versiones exactas\n\u25a1 Considerar MLflow para tracking autom\u00e1tico\n\u25a1 Considerar ONNX para m\u00e1xima portabilidad\n</code></pre>"},{"location":"notebooks/labs/LAB_03_DEPENDENCY_CONFLICTS/#ejercicio-final","title":"Ejercicio Final","text":"<p>Tienes este error:</p> <pre><code>AttributeError: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`.\n</code></pre> <p>\u00bfCu\u00e1l es la causa y c\u00f3mo lo arreglas?</p> \ud83d\udca1 Respuesta  **Causa**:  - El modelo fue entrenado con numpy &lt; 1.24 que ten\u00eda `np.bool` - Producci\u00f3n tiene numpy &gt;= 1.24 donde `np.bool` fue eliminado  **Soluci\u00f3n inmediata**: <pre><code>pip install \"numpy&lt;1.24\"\n</code></pre>  **Soluci\u00f3n correcta**: 1. Reentrenar el modelo con numpy &gt;= 1.24 2. O actualizar el c\u00f3digo que usa `np.bool` a `bool`  **En sklearn**: Esto pasaba en versiones antiguas. Actualizar sklearn &gt;= 1.3 resuelve el problema."}]}