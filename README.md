# ðŸš€ GuÃ­a MLOps â€” Portfolio Edition (24 Semanas)

> **De Cero a Senior/Staff MLOps en 6 Meses**
> 
> Mapa completo para construir el portafolio [ML-MLOps-Portfolio](https://github.com/DuqueOM/ML-MLOps-Portfolio) desde cero.

---

## ðŸ“‹ Tabla de Contenidos

1. [Â¿QuÃ© LograrÃ¡s?](#-quÃ©-lograrÃ¡s)
2. [Estructura del Programa (24 Semanas)](#-estructura-del-programa-24-semanas)
3. [Tabla de Mapeo: Concepto â†’ Herramienta â†’ Portafolio](#-tabla-de-mapeo-concepto--herramienta--portafolio)
4. [Roadmap Visual](#-roadmap-visual)
5. [Contenido por Mes](#-contenido-por-mes)
6. [ExÃ¡menes de Hito (6 Milestones)](#-exÃ¡menes-de-hito-6-milestones)
7. [GuÃ­a de Troubleshooting](#-guÃ­a-de-troubleshooting)
8. [Quick Start](#-quick-start)
9. [Estructura de Carpetas](#-estructura-de-carpetas)

---

## ðŸŽ¯ Â¿QuÃ© LograrÃ¡s?

Al completar esta guÃ­a de 24 semanas serÃ¡s capaz de:

| Habilidad | Nivel | Evidencia en el Portafolio |
|-----------|-------|---------------------------|
| **CÃ³digo Python profesional** | Senior | Type hints, Pydantic, SOLID en los 3 proyectos |
| **Pipelines ML reproducibles** | Senior | sklearn Pipeline unificado, sin data leakage |
| **Versionado de datos y modelos** | Senior | DVC pipelines, MLflow Model Registry |
| **Testing & CI/CD** | Senior | 80%+ coverage, GitHub Actions, matrix testing |
| **APIs de producciÃ³n** | Senior | FastAPI con validaciÃ³n, Docker multi-stage |
| **Observabilidad** | Staff | Prometheus, logging estructurado, drift detection |
| **Infraestructura como CÃ³digo** | Staff | Terraform, Kubernetes manifests |
| **Pasar entrevistas tÃ©cnicas** | Staff | Simulacros completos, speech de 5-7 min |

---

## ðŸ“… Estructura del Programa (24 Semanas)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        RUTA DE APRENDIZAJE (24 SEMANAS / 6 MESES)                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                      â•‘
â•‘  MES 1: FUNDAMENTOS (Semanas 1-4)                                                    â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                    â•‘
â•‘  [S1] Python Moderno + Tipado                                                        â•‘
â•‘  [S2] DiseÃ±o de Sistemas + Arquitectura                                              â•‘
â•‘  [S3] Estructura de Proyecto + Entornos                                              â•‘
â•‘  [S4] Git Profesional + Pre-commit                                                   â•‘
â•‘       ðŸ“‹ EXAMEN HITO 1: Setup Completo                                               â•‘
â•‘                                                                                      â•‘
â•‘  MES 2: DATOS & VERSIONADO (Semanas 5-8)                                             â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                            â•‘
â•‘  [S5] DVC Fundamentos + Remote Storage                                               â•‘
â•‘  [S6] Pipelines DVC + Reproducibilidad                                               â•‘
â•‘  [S7] sklearn Pipelines BÃ¡sicos                                                      â•‘
â•‘  [S8] ColumnTransformer + Custom Transformers                                        â•‘
â•‘       ðŸ“‹ EXAMEN HITO 2: Pipeline Reproducible                                        â•‘
â•‘                                                                                      â•‘
â•‘  MES 3: ML ENGINEERING (Semanas 9-12)                                                â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                â•‘
â•‘  [S9]  IngenierÃ­a de Features                                                        â•‘
â•‘  [S10] Training Profesional + Cross-Validation                                       â•‘
â•‘  [S11] MLflow Tracking + UI                                                          â•‘
â•‘  [S12] MLflow Model Registry + Signatures                                            â•‘
â•‘       ðŸ“‹ EXAMEN HITO 3: Experimento Completo                                         â•‘
â•‘                                                                                      â•‘
â•‘  MES 4: TESTING & CI/CD (Semanas 13-16)                                              â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                              â•‘
â•‘  [S13] Testing Unitario para ML                                                      â•‘
â•‘  [S14] Testing de IntegraciÃ³n + Fixtures                                             â•‘
â•‘  [S15] GitHub Actions + Matrix Testing                                               â•‘
â•‘  [S16] Coverage Gates + Security Scanning                                            â•‘
â•‘       ðŸ“‹ EXAMEN HITO 4: CI/CD Completo                                               â•‘
â•‘                                                                                      â•‘
â•‘  MES 5: DEPLOYMENT (Semanas 17-20)                                                   â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                   â•‘
â•‘  [S17] Docker Fundamentos + Multi-stage                                              â•‘
â•‘  [S18] FastAPI para ML + Schemas Pydantic                                            â•‘
â•‘  [S19] Streamlit Dashboards + Caching                                                â•‘
â•‘  [S20] Observabilidad + Logging Estructurado                                         â•‘
â•‘       ðŸ“‹ EXAMEN HITO 5: API Desplegada                                               â•‘
â•‘                                                                                      â•‘
â•‘  MES 6: PRODUCCIÃ“N & MAESTRÃA (Semanas 21-24)                                        â•‘
â•‘  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â•‘
â•‘  [S21] Estrategias de Despliegue + Cloud                                             â•‘
â•‘  [S22] Infraestructura como CÃ³digo (Terraform)                                       â•‘
â•‘  [S23] DocumentaciÃ³n Profesional + Model Cards                                       â•‘
â•‘  [S24] Proyecto Integrador + PreparaciÃ³n Entrevistas                                 â•‘
â•‘       ðŸ“‹ EXAMEN HITO 6: Portafolio Completo                                          â•‘
â•‘                                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**DedicaciÃ³n sugerida**: 8-10 horas/semana (total ~200 horas)

---

## ðŸ—ºï¸ Tabla de Mapeo: Concepto â†’ Herramienta â†’ Portafolio

Esta tabla conecta cada concepto teÃ³rico con la herramienta prÃ¡ctica y su ubicaciÃ³n exacta en el portafolio:

| Semana | Concepto TeÃ³rico | Herramienta | UbicaciÃ³n en Portafolio | MÃ³dulo GuÃ­a |
|:------:|------------------|-------------|-------------------------|-------------|
| **S1** | Tipado estÃ¡tico | `mypy`, `Pydantic` | `*/src/*/config.py` | [01_PYTHON_MODERNO](docs/01_PYTHON_MODERNO.md) |
| **S2** | Arquitectura ML | ML Canvas, C4 Model | `docs/architecture/` | [02_DISENO_SISTEMAS](docs/02_DISENO_SISTEMAS.md) |
| **S3** | Estructura cÃ³digo | `src/` layout | `BankChurn-Predictor/src/` | [03_ESTRUCTURA_PROYECTO](docs/03_ESTRUCTURA_PROYECTO.md) |
| **S4** | Calidad cÃ³digo | `pre-commit`, `ruff` | `.pre-commit-config.yaml` | [05_GIT_PROFESIONAL](docs/05_GIT_PROFESIONAL.md) |
| **S5** | Versionado datos | **DVC** | `.dvc/`, `data/*.dvc` | [06_VERSIONADO_DATOS](docs/06_VERSIONADO_DATOS.md) |
| **S6** | Pipelines datos | **DVC pipelines** | `dvc.yaml`, `dvc.lock` | [06_VERSIONADO_DATOS](docs/06_VERSIONADO_DATOS.md) |
| **S7** | Preprocesamiento | `sklearn.Pipeline` | `*/src/*/pipeline.py` | [07_SKLEARN_PIPELINES](docs/07_SKLEARN_PIPELINES.md) |
| **S8** | Transformaciones | `ColumnTransformer` | `*/src/*/pipeline.py` | [07_SKLEARN_PIPELINES](docs/07_SKLEARN_PIPELINES.md) |
| **S9** | Feature Engineering | Custom Transformers | `*/src/*/features.py` | [08_INGENIERIA_FEATURES](docs/08_INGENIERIA_FEATURES.md) |
| **S10** | Entrenamiento | `Trainer` class, CV | `*/src/*/trainer.py` | [09_TRAINING_PROFESIONAL](docs/09_TRAINING_PROFESIONAL.md) |
| **S11** | Experiment Tracking | **MLflow** | `mlruns/`, `mlflow.log_*` | [10_EXPERIMENT_TRACKING](docs/10_EXPERIMENT_TRACKING.md) |
| **S12** | Model Registry | **MLflow Registry** | `models:/model_name/` | [10_EXPERIMENT_TRACKING](docs/10_EXPERIMENT_TRACKING.md) |
| **S13** | Testing unitario | **pytest** | `tests/unit/` | [11_TESTING_ML](docs/11_TESTING_ML.md) |
| **S14** | Testing integraciÃ³n | `pytest-fixtures` | `tests/integration/` | [11_TESTING_ML](docs/11_TESTING_ML.md) |
| **S15** | CI/CD | **GitHub Actions** | `.github/workflows/ci.yml` | [12_CI_CD](docs/12_CI_CD.md) |
| **S16** | Security | `gitleaks`, `safety` | `.github/workflows/security.yml` | [12_CI_CD](docs/12_CI_CD.md) |
| **S17** | ContainerizaciÃ³n | **Docker** | `Dockerfile`, `docker-compose.yml` | [13_DOCKER](docs/13_DOCKER.md) |
| **S18** | APIs ML | **FastAPI** | `app/fastapi_app.py` | [14_FASTAPI](docs/14_FASTAPI.md) |
| **S19** | Dashboards | **Streamlit** | `app/streamlit_app.py` | [15_STREAMLIT](docs/15_STREAMLIT.md) |
| **S20** | Observabilidad | `loguru`, Prometheus | `*/src/*/logging.py` | [16_OBSERVABILIDAD](docs/16_OBSERVABILIDAD.md) |
| **S21** | Deploy strategies | Blue-green, Canary | `k8s/`, deployment configs | [17_DESPLIEGUE](docs/17_DESPLIEGUE.md) |
| **S22** | IaC | **Terraform** | `infra/terraform/` | [18_INFRAESTRUCTURA](docs/18_INFRAESTRUCTURA.md) |
| **S23** | DocumentaciÃ³n | Model Cards, MkDocs | `docs/model_card.md` | [19_DOCUMENTACION](docs/19_DOCUMENTACION.md) |
| **S24** | IntegraciÃ³n | Todo el stack | Portafolio completo | [20_PROYECTO_INTEGRADOR](docs/20_PROYECTO_INTEGRADOR.md) |

---

## ðŸ”§ Herramientas del Stack Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              STACK MLOps COMPLETO                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                     â”‚
â”‚  DESARROLLO          â”‚  ML/DATA             â”‚  MLOps              â”‚  PRODUCCIÃ“N     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚  â”€â”€â”€â”€â”€â”€â”€             â”‚  â”€â”€â”€â”€â”€              â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  â€¢ Python 3.10+      â”‚  â€¢ pandas            â”‚  â€¢ DVC              â”‚  â€¢ Docker       â”‚
â”‚  â€¢ Pydantic          â”‚  â€¢ numpy             â”‚  â€¢ MLflow           â”‚  â€¢ FastAPI      â”‚
â”‚  â€¢ mypy              â”‚  â€¢ scikit-learn      â”‚  â€¢ pytest           â”‚  â€¢ Streamlit    â”‚
â”‚  â€¢ ruff              â”‚  â€¢ joblib            â”‚  â€¢ GitHub Actions   â”‚  â€¢ Prometheus   â”‚
â”‚  â€¢ pre-commit        â”‚                      â”‚  â€¢ gitleaks         â”‚  â€¢ Terraform    â”‚
â”‚  â€¢ Poetry/pip        â”‚                      â”‚                     â”‚  â€¢ Kubernetes   â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“š Contenido por Mes

---

### ðŸ—“ï¸ MES 1: FUNDAMENTOS PYTHON PROFESIONAL (Semanas 1-4)

> **Objetivo**: Dominar Python a nivel Staff Engineer â€” el cÃ³digo del Portafolio NO se puede entender sin esto.

---

#### ðŸ“– Semana 1: Type Hints + Pydantic

**ðŸŽ¯ Objetivo**: CÃ³digo con contratos explÃ­citos y configuraciÃ³n validada.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Impacto en MLOps |
|----------|------------|------------------|
| **Tipado EstÃ¡tico** | Declarar tipos en tiempo de escritura | mypy detecta errores ANTES de ejecutar |
| **ValidaciÃ³n en Frontera** | Verificar datos al ENTRAR al sistema | Errores claros vs crashes crÃ­pticos |
| **Fail Fast** | Fallar inmediatamente con error descriptivo | Costo de bug: $1 (cÃ³digo) vs $1000 (producciÃ³n) |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EL PROBLEMA: CÃ³digo Junior sin tipos
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def train(data, config):  # Â¿QuÃ© tipos? Â¿QuÃ© retorna?
    pass  # Error aparece 3 capas despuÃ©s

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LA SOLUCIÃ“N: CÃ³digo Staff con contratos
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from typing import Tuple
import pandas as pd
from pydantic import BaseModel, Field

class TrainConfig(BaseModel):
    test_size: float = Field(default=0.2, ge=0.01, le=0.5)
    n_estimators: int = Field(default=100, ge=10)

def train(
    data: pd.DataFrame,
    config: TrainConfig
) -> Tuple[Pipeline, dict[str, float]]:
    """Contrato claro: mypy verifica, Pydantic valida."""
    ...
```

##### ðŸ’» Comandos Exactos

```bash
pip install pydantic mypy ruff
mypy src/bankchurn/training.py --strict  # 0 errores = listo
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/src/bankchurn/config.py`

**ðŸ“ Tarea**: Tipar TODAS las funciones pÃºblicas de `training.py`

---

#### ðŸ“– Semana 2: OOP para ML â€” Protocolos y ABC

**ðŸŽ¯ Objetivo**: Escribir cÃ³digo intercambiable y extensible con OOP profesional.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Uso en el Portafolio |
|----------|------------|---------------------|
| **Protocol** | Duck typing verificable por mypy | Compatibilidad con sklearn sin herencia |
| **ABC (Abstract Base Class)** | Contrato que OBLIGA implementaciÃ³n | BaseTrainer para los 3 proyectos |
| **Polimorfismo** | Mismo mÃ©todo, diferentes implementaciones | `trainer.fit()` funciona igual en BankChurn, CarVision, TelecomAI |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EL PROBLEMA: 3 trainers con APIs diferentes
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class TrainerA:
    def entrenar(self, X, y): ...  # espaÃ±ol
class TrainerB:
    def fit_model(self, data): ...  # diferente firma

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LA SOLUCIÃ“N: ABC define el contrato
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from abc import ABC, abstractmethod
import pandas as pd

class BaseTrainer(ABC):
    """Todos los trainers del portafolio heredan de aquÃ­."""
    
    @abstractmethod
    def fit(self, X: pd.DataFrame, y: pd.Series) -> "BaseTrainer":
        """Entrenar modelo."""
        pass
    
    @abstractmethod
    def predict(self, X: pd.DataFrame) -> pd.Series:
        """Predecir."""
        pass

# Protocol para sklearn (sin herencia):
from typing import Protocol, runtime_checkable

@runtime_checkable
class Predictor(Protocol):
    def fit(self, X, y): ...
    def predict(self, X): ...

# sklearn cumple automÃ¡ticamente:
from sklearn.ensemble import RandomForestClassifier
assert isinstance(RandomForestClassifier(), Predictor)  # True
```

**ðŸ“¦ Puente al Portafolio**: Crear `common_utils/base.py` con `BaseTrainer`

**ðŸ“ Tarea**: Hacer que `ChurnTrainer` herede de `BaseTrainer`

---

#### ðŸ“– Semana 3: Pandas de ProducciÃ³n + Pandera

**ðŸŽ¯ Objetivo**: Validar DataFrames ANTES de que causen errores en el pipeline.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Por quÃ© es crÃ­tico |
|----------|------------|-------------------|
| **Schema** | Contrato de estructura de datos | Define quÃ© columnas, tipos y rangos son vÃ¡lidos |
| **Pandera** | ValidaciÃ³n de DataFrames con decoradores | Error claro: "Age debe ser >= 18" vs crash en sklearn |
| **Data Contract** | Acuerdo entre productor y consumidor de datos | El pipeline de features ESPERA cierta estructura |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EL PROBLEMA: CÃ³digo Junior asume DataFrame correcto
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def train(df):
    X = df.drop("Exited", axis=1)  # Â¿Y si "Exited" no existe?
    y = df["Exited"]  # Â¿Y si tiene valores invÃ¡lidos como 2 o -1?

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LA SOLUCIÃ“N: Pandera valida en la frontera
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import pandera as pa
from pandera.typing import DataFrame, Series

class BankChurnSchema(pa.DataFrameModel):
    CreditScore: Series[int] = pa.Field(ge=300, le=850)
    Age: Series[int] = pa.Field(ge=18, le=100)
    Balance: Series[float] = pa.Field(ge=0)
    Exited: Series[int] = pa.Field(isin=[0, 1])
    
    class Config:
        strict = True  # No permite columnas extra

@pa.check_types
def train(df: DataFrame[BankChurnSchema]) -> Pipeline:
    """DataFrame GARANTIZADO vÃ¡lido por Pandera."""
    X = df.drop("Exited", axis=1)
    y = df["Exited"]
    ...
```

##### ðŸ’» Comandos Exactos

```bash
pip install pandera
# Crear src/bankchurn/schemas.py con los schemas
pytest tests/test_schemas.py -v
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/src/bankchurn/schemas.py`

**ðŸ“ Tarea**: Crear `RawDataSchema` (permisivo) y `ProcessedDataSchema` (estricto)

---

#### ðŸ“– Semana 4: Estructura de Proyecto + Git Profesional

**ðŸŽ¯ Objetivo**: Organizar cÃ³digo como paquete instalable con calidad automatizada.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Beneficio |
|----------|------------|-----------|
| **src/ Layout** | CÃ³digo en `src/package/` | Fuerza `pip install -e .` â€” evita "funciona en mi mÃ¡quina" |
| **pyproject.toml** | Metadata estÃ¡ndar del proyecto | Un archivo para deps, tools, builds |
| **Pre-commit** | Hooks que corren antes de commit | Calidad GARANTIZADA en cada commit |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```
BankChurn-Predictor/
â”œâ”€â”€ src/bankchurn/          # CÃ³digo fuente
â”‚   â”œâ”€â”€ __init__.py         # Exporta API pÃºblica
â”‚   â”œâ”€â”€ config.py           # Pydantic
â”‚   â”œâ”€â”€ schemas.py          # Pandera  
â”‚   â”œâ”€â”€ training.py         # Trainer
â”‚   â””â”€â”€ cli.py              # CLI
â”œâ”€â”€ tests/                  # Tests (espejo de src/)
â”œâ”€â”€ configs/config.yaml     # Config externa
â”œâ”€â”€ pyproject.toml          # Metadata
â”œâ”€â”€ Makefile                # Comandos
â””â”€â”€ .pre-commit-config.yaml # Hooks
```

##### ðŸ’» Comandos Exactos

```bash
# Instalar en modo editable
pip install -e ".[dev]"

# Verificar import funciona
python -c "from bankchurn import ChurnTrainer; print('OK')"

# Configurar pre-commit
pip install pre-commit
pre-commit install
pre-commit run --all-files

# Commit convencional
git commit -m "feat(training): add type hints to ChurnTrainer"
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/pyproject.toml`

**ðŸ“ Tarea**: `pip install -e ".[dev]"` + `pytest` + `mypy` pasan sin errores

---

### ðŸ—“ï¸ MES 2: DATOS & PIPELINES (Semanas 5-8)

> **Objetivo**: Dominar versionado de datos, pipelines reproducibles y preprocesamiento profesional.

---

#### ðŸ“– Semana 5: DVC â€” Versionado de Datos

**ðŸŽ¯ Objetivo**: Versionar datos como se versiona cÃ³digo.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Por quÃ© es crÃ­tico |
|----------|------------|-------------------|
| **Reproducibilidad** | Obtener EXACTAMENTE el mismo resultado | "Dame los datos de hace 3 meses" |
| **Data Lineage** | Rastrear origen y transformaciones de datos | Debugging y compliance |
| **Content-addressable** | Archivos identificados por hash, no por nombre | Detecta cambios automÃ¡ticamente |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EL PROBLEMA: Datos en carpetas con fechas
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# data/
# â”œâ”€â”€ customers_v1.csv
# â”œâ”€â”€ customers_v2_final.csv
# â”œâ”€â”€ customers_v2_final_REAL.csv  # â† Â¿CuÃ¡l es el bueno?
# â”œâ”€â”€ customers_backup_juan.csv

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LA SOLUCIÃ“N: DVC trackea por contenido
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# data/
# â””â”€â”€ customers.csv.dvc  # â† Git trackea esto (puntero)
# El archivo real estÃ¡ en remote storage, identificado por hash MD5
```

##### ðŸ’» Comandos Exactos

```bash
# Inicializar DVC
dvc init
dvc add data/raw/bank_customers.csv

# Ver el puntero creado
cat data/raw/bank_customers.csv.dvc
# outs:
#   - md5: d41d8cd98f00b204e9800998ecf8427e
#     path: bank_customers.csv

# Commitear puntero (no datos)
git add data/raw/bank_customers.csv.dvc data/raw/.gitignore
git commit -m "data: add raw customer data v1"

# Configurar remote y push
dvc remote add -d storage s3://my-bucket/dvc
dvc push
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/data/*.dvc`, `.dvc/config`

**ðŸ“ Tarea**: `dvc pull` en una carpeta nueva debe traer exactamente los mismos datos

---

#### ï¿½ Semana 6: Pipelines DVC + Reproducibilidad

**ðŸŽ¯ Objetivo**: Crear pipelines de datos reproducibles con DAGs.

##### ðŸ“ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Por quÃ© es crÃ­tico |
|----------|------------|-------------------|
| **DAG** | Directed Acyclic Graph â€” pasos ordenados sin ciclos | Solo re-ejecuta lo que cambiÃ³ |
| **Determinismo** | Mismo input â†’ mismo output siempre | Reproducibilidad cientÃ­fica |
| **Idempotencia** | Ejecutar N veces = ejecutar 1 vez | Safe to retry |

##### ðŸ”§ PrÃ¡ctica de IngenierÃ­a

```yaml
# dvc.yaml â€” Define el pipeline completo
stages:
  prepare:
    cmd: python src/bankchurn/prepare.py
    deps:
      - src/bankchurn/prepare.py
      - data/raw/bank_customers.csv
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  train:
    cmd: python src/bankchurn/train.py
    deps:
      - src/bankchurn/train.py
      - data/processed/train.csv
    outs:
      - models/model.pkl
    metrics:
      - metrics.json:
          cache: false
```

##### ðŸ’» Comandos Exactos

```bash
dvc repro           # Ejecuta pipeline completo
dvc dag             # Visualiza el DAG
dvc metrics show    # Muestra mÃ©tricas
dvc metrics diff    # Compara entre versiones
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/dvc.yaml`, `dvc.lock`

**ðŸ“ Tarea**: `dvc repro` ejecuta sin errores y genera `metrics.json`

---

#### ðŸ“– Semana 7: sklearn Pipelines â€” Sin Data Leakage

**ðŸŽ¯ Objetivo**: Crear pipelines ML que previenen data leakage.

##### ï¿½ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Por quÃ© es crÃ­tico |
|----------|------------|-------------------|
| **Data Leakage** | InformaciÃ³n del test contamina el train | Modelo parece bueno pero falla en producciÃ³n |
| **fit vs transform** | fit aprende estadÃ­sticas, transform las aplica | fit SOLO en train, transform en train Y test |
| **Pipeline** | Cadena de transformaciones como un objeto | Encapsula preprocessing + modelo |

##### ï¿½ PrÃ¡ctica de IngenierÃ­a

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EL PROBLEMA: Data Leakage (error de principiante)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # âŒ fit en TODO X (incluye test)
X_train, X_test = train_test_split(X_scaled)  # Leakage!

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LA SOLUCIÃ“N: Pipeline encapsula todo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
    ("classifier", RandomForestClassifier())
])

# Split ANTES de cualquier fit
X_train, X_test, y_train, y_test = train_test_split(X, y)

# fit_transform SOLO en train
pipeline.fit(X_train, y_train)  # âœ… Aprende de train

# transform implÃ­cito en predict (usa estadÃ­sticas de train)
predictions = pipeline.predict(X_test)  # âœ… Sin leakage
```

**ðŸ“¦ Puente al Portafolio**: `BankChurn-Predictor/src/bankchurn/pipeline.py`

**ðŸ“ Tarea**: Crear `create_pipeline()` que retorna Pipeline completo

---

#### ðŸ“– Semana 8: ColumnTransformer + Custom Transformers

**ðŸŽ¯ Objetivo**: Procesar diferentes tipos de columnas con transformadores custom.

##### ï¿½ TeorÃ­a Fundamental

| Concepto | DefiniciÃ³n | Por quÃ© es crÃ­tico |
|----------|------------|-------------------|
| **ColumnTransformer** | Aplica transformaciones diferentes por grupo de columnas | NumÃ©ricas: escalar, CategÃ³ricas: one-hot |
| **BaseEstimator + TransformerMixin** | Clases base para transformadores sklearn-compatible | Tu transformer funciona en Pipeline |
| **fit/transform API** | Contrato estÃ¡ndar de sklearn | Interoperabilidad garantizada |

##### ï¿½ PrÃ¡ctica de IngenierÃ­a

```python
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.compose import ColumnTransformer
import numpy as np

class OutlierClipper(BaseEstimator, TransformerMixin):
    """Custom transformer que recorta outliers usando IQR."""
    
    def __init__(self, factor: float = 1.5):
        self.factor = factor
    
    def fit(self, X, y=None):
        Q1, Q3 = np.percentile(X, [25, 75], axis=0)
        IQR = Q3 - Q1
        self.lower_ = Q1 - self.factor * IQR
        self.upper_ = Q3 + self.factor * IQR
        return self  # â† Siempre retorna self
    
    def transform(self, X):
        return np.clip(X, self.lower_, self.upper_)

# Uso en ColumnTransformer:
preprocessor = ColumnTransformer([
    ("num", Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("outlier", OutlierClipper()),
        ("scaler", StandardScaler())
    ]), numerical_columns),
    ("cat", Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("encoder", OneHotEncoder(handle_unknown="ignore"))
    ]), categorical_columns)
])
```

**ðŸ“¦ Puente al Portafolio**: `CarVision-Market-Intelligence/src/carvision/features.py`

**ðŸ“ Tarea**: Crear `OutlierClipper` y `FeatureEngineer` como transformers custom

---

### ï¿½ï¸ MES 3: ML ENGINEERING (Semanas 9-12)

> **Objetivo**: Dominar entrenamiento profesional y tracking de experimentos.

---

#### ðŸ“– Semana 9: IngenierÃ­a de Features

**ðŸŽ¯ Objetivo**: Crear features robustos sin data leakage.

##### ï¿½ TeorÃ­a Fundamental

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Feature Engineering** | Preparar ingredientes antes de cocinar | Features buenos = modelo bueno |
| **Target Encoding** | Reemplazar categorÃ­a por promedio del target | Poderoso pero peligroso (leakage) |
| **FeatureEngineer class** | Chef que sabe todas las recetas | Centraliza lÃ³gica, evita duplicaciÃ³n |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > src/bankchurn/features.py << 'EOF'
from sklearn.base import BaseEstimator, TransformerMixin
import pandas as pd

class FeatureEngineer(BaseEstimator, TransformerMixin):
    """Crea features derivados para predicciÃ³n de churn."""
    
    def fit(self, X: pd.DataFrame, y=None):
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        X = X.copy()
        # Feature: Ratio balance/salario
        if "Balance" in X.columns and "EstimatedSalary" in X.columns:
            X["BalanceToSalary"] = X["Balance"] / (X["EstimatedSalary"] + 1)
        # Feature: Es cliente nuevo
        if "Tenure" in X.columns:
            X["IsNewCustomer"] = (X["Tenure"] < 2).astype(int)
        return X
EOF
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `CarVision-Market-Intelligence/src/carvision/features.py`

---

#### ðŸ“– Semana 10: Training Profesional + Cross-Validation

**ðŸŽ¯ Objetivo**: Entrenar modelos con validaciÃ³n robusta.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Cross-Validation** | Varios exÃ¡menes de prÃ¡ctica, no solo uno | EstimaciÃ³n mÃ¡s confiable |
| **Stratified K-Fold** | Cada examen tiene proporciÃ³n similar | Clases desbalanceadas bien representadas |
| **Trainer class** | Entrenador personal con programa estructurado | CÃ³digo organizado, mÃ©tricas consistentes |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > src/bankchurn/trainer.py << 'EOF'
from sklearn.model_selection import cross_val_score, StratifiedKFold
from dataclasses import dataclass
import numpy as np

@dataclass
class TrainingResult:
    cv_scores: list[float]
    mean_score: float
    std_score: float

class ChurnTrainer:
    def __init__(self, pipeline, n_splits: int = 5):
        self.pipeline = pipeline
        self.cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    def train_with_cv(self, X, y, scoring: str = "f1") -> TrainingResult:
        scores = cross_val_score(self.pipeline, X, y, cv=self.cv, scoring=scoring)
        self.pipeline.fit(X, y)
        return TrainingResult(
            cv_scores=scores.tolist(),
            mean_score=float(np.mean(scores)),
            std_score=float(np.std(scores))
        )
EOF
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `BankChurn-Predictor/src/bankchurn/trainer.py`

---

#### ðŸ“– Semana 11: MLflow Tracking + UI

**ðŸŽ¯ Objetivo**: Registrar experimentos de forma sistemÃ¡tica.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **MLflow** | Cuaderno de laboratorio digital | Nunca pierdes un experimento |
| **Run** | Experimento individual | Cada entrenamiento queda registrado |
| **Artifact** | Archivos guardados (modelo, grÃ¡ficas) | Reproducir resultados exactos |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
# 1. Instalar MLflow
pip install mlflow

# 2. Script de entrenamiento con tracking
cat > src/bankchurn/train_mlflow.py << 'EOF'
import mlflow
import mlflow.sklearn
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score

mlflow.set_experiment("bankchurn-classifier")

X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

with mlflow.start_run(run_name="rf-baseline"):
    params = {"n_estimators": 100, "max_depth": 10}
    mlflow.log_params(params)
    
    model = RandomForestClassifier(**params, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    mlflow.log_metrics({"accuracy": accuracy_score(y_test, y_pred), "f1": f1_score(y_test, y_pred)})
    mlflow.sklearn.log_model(model, "model")
EOF

# 3. Ejecutar e iniciar UI
python src/bankchurn/train_mlflow.py
mlflow ui --port 5000
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `mlruns/` en cada proyecto

---

#### ðŸ“– Semana 12: MLflow Model Registry + Signatures

**ðŸŽ¯ Objetivo**: Gestionar modelos en producciÃ³n con versionado.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Model Registry** | CatÃ¡logo de productos con versiones | Sabes quÃ© modelo estÃ¡ en producciÃ³n |
| **Stages** | Estados: Staging â†’ Production â†’ Archived | Control de quÃ© modelo usan usuarios |
| **Signature** | Contrato de entrada/salida | API sabe quÃ© esperar del modelo |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > src/bankchurn/train_registry.py << 'EOF'
import mlflow
from mlflow.models import infer_signature
from sklearn.ensemble import RandomForestClassifier
import pandas as pd

mlflow.set_experiment("bankchurn-classifier")

# Datos con nombres
feature_names = ["age", "balance", "tenure", "products", "salary"]
X = pd.DataFrame([[30, 1000, 2, 1, 50000]], columns=feature_names)

with mlflow.start_run():
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X, [0])
    
    signature = infer_signature(X, model.predict(X))
    mlflow.sklearn.log_model(
        model, "model",
        signature=signature,
        registered_model_name="BankChurnClassifier"
    )
EOF

python src/bankchurn/train_registry.py
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `models:/BankChurn/Production`

---

### ðŸ—“ï¸ MES 4: TESTING & CI/CD (Semanas 13-16)

> **Objetivo**: Implementar testing profesional y automatizaciÃ³n.

#### ðŸ“– Semana 13: Testing Unitario para ML

**ðŸŽ¯ Objetivo**: Escribir tests que validen componentes ML.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Unit Test** | Probar cada pieza antes de ensamblar | Detectas errores temprano |
| **pytest** | Robot que ejecuta todas las pruebas | AutomatizaciÃ³n, reportes claros |
| **Fixture** | Ingredientes pre-preparados para tests | Reutilizas setup, tests mÃ¡s limpios |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
# Crear estructura de tests
mkdir -p tests/unit

cat > tests/conftest.py << 'EOF'
import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_data():
    """Datos de ejemplo para tests."""
    return pd.DataFrame({
        "Balance": [1000, 2000, 0, 5000],
        "Tenure": [1, 5, 3, 10],
        "Age": [30, 45, 25, 60]
    })

@pytest.fixture
def sample_labels():
    return np.array([0, 1, 0, 1])
EOF

cat > tests/unit/test_pipeline.py << 'EOF'
from src.bankchurn.pipeline import create_pipeline

def test_pipeline_creation():
    pipe = create_pipeline()
    assert len(pipe.steps) == 3

def test_pipeline_fit_predict(sample_data, sample_labels):
    pipe = create_pipeline()
    pipe.fit(sample_data.values, sample_labels)
    predictions = pipe.predict(sample_data.values)
    assert len(predictions) == len(sample_labels)
EOF

# Ejecutar tests
pytest tests/ -v
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `tests/unit/`

---

#### ðŸ“– Semana 14: Testing de IntegraciÃ³n + Fixtures

**ðŸŽ¯ Objetivo**: Probar componentes trabajando juntos.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Integration Test** | Probar el carro completo, no solo el motor | Detectas problemas de conexiÃ³n |
| **Mocking** | Usar dobles de prueba (actores) | Tests rÃ¡pidos, sin dependencias externas |
| **conftest.py** | Recetario compartido de fixtures | Un lugar para todos los fixtures |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > tests/integration/test_training_flow.py << 'EOF'
import pytest
from pathlib import Path
import tempfile

def test_full_training_flow(sample_data, sample_labels):
    """Test del flujo completo de entrenamiento."""
    from src.bankchurn.pipeline import create_pipeline
    from src.bankchurn.trainer import ChurnTrainer
    
    pipe = create_pipeline()
    trainer = ChurnTrainer(pipe, n_splits=2)
    
    result = trainer.train_with_cv(sample_data.values, sample_labels)
    
    assert result.mean_score >= 0.0
    assert result.mean_score <= 1.0
    assert len(result.cv_scores) == 2

def test_model_persistence(sample_data, sample_labels):
    """Test de guardado y carga de modelo."""
    import joblib
    from src.bankchurn.pipeline import create_pipeline
    
    pipe = create_pipeline()
    pipe.fit(sample_data.values, sample_labels)
    
    with tempfile.TemporaryDirectory() as tmpdir:
        model_path = Path(tmpdir) / "model.pkl"
        joblib.dump(pipe, model_path)
        
        loaded = joblib.load(model_path)
        assert loaded.predict(sample_data.values).shape == sample_labels.shape
EOF

pytest tests/integration/ -v
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `tests/integration/`

---

#### ðŸ“– Semana 15: GitHub Actions + Matrix Testing

**ðŸŽ¯ Objetivo**: Automatizar tests en cada push.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **GitHub Actions** | Robot que trabaja por ti 24/7 | Tests automÃ¡ticos en cada cambio |
| **Workflow** | Instrucciones para el robot | Define quÃ© hacer y cuÃ¡ndo |
| **Matrix** | Probar en mÃºltiples versiones | Compatibilidad garantizada |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
mkdir -p .github/workflows

cat > .github/workflows/ci.yml << 'EOF'
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          pip install -e ".[dev]"
      
      - name: Run linting
        run: |
          ruff check src/ tests/
      
      - name: Run tests with coverage
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-fail-under=80
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
EOF
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `.github/workflows/ci.yml`

---

#### ðŸ“– Semana 16: Coverage Gates + Security Scanning

**ðŸŽ¯ Objetivo**: Garantizar calidad y seguridad automÃ¡ticamente.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Coverage Gate** | MÃ­nimo de cobertura para aprobar | Garantiza tests suficientes |
| **gitleaks** | Detector de secretos filtrados | Evita exponer passwords/API keys |
| **Dependabot** | Robot que actualiza dependencias | Parches de seguridad automÃ¡ticos |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
# AÃ±adir security scanning al workflow
cat >> .github/workflows/ci.yml << 'EOF'

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Check dependencies
        run: |
          pip install safety
          safety check
EOF

# Crear configuraciÃ³n de gitleaks
cat > .gitleaks.toml << 'EOF'
[allowlist]
description = "Allowlist for secrets"
paths = [
    '''tests/.*''',
    '''docs/.*''',
]
EOF

# Verificar coverage localmente
pytest --cov=src --cov-fail-under=80
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `.github/workflows/security.yml`

---

### ðŸ—“ï¸ MES 5: DEPLOYMENT (Semanas 17-20)

> **Objetivo**: Desplegar modelos como APIs profesionales.

#### ðŸ“– Semana 17: Docker Fundamentos + Multi-stage

**ðŸŽ¯ Objetivo**: Containerizar aplicaciones ML.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Docker** | Caja de mudanza que incluye todo | Funciona igual en cualquier mÃ¡quina |
| **Image** | Foto/snapshot de tu aplicaciÃ³n | VersiÃ³n inmutable para desplegar |
| **Multi-stage** | Cocinar y servir en platos diferentes | Imagen final pequeÃ±a y segura |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > Dockerfile << 'EOF'
# Stage 1: Builder
FROM python:3.11-slim as builder
WORKDIR /app
COPY pyproject.toml .
RUN pip install build && python -m build --wheel

# Stage 2: Runtime
FROM python:3.11-slim as runtime
WORKDIR /app

# Crear usuario no-root
RUN useradd --create-home appuser
USER appuser

# Instalar dependencias
COPY --from=builder /app/dist/*.whl .
RUN pip install --user *.whl

# Copiar cÃ³digo
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser models/ ./models/

EXPOSE 8000
CMD ["python", "-m", "uvicorn", "app.fastapi_app:app", "--host", "0.0.0.0", "--port", "8000"]
EOF

# Construir y ejecutar
docker build -t bankchurn:latest .
docker run -p 8000:8000 bankchurn:latest
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `Dockerfile`

---

#### ðŸ“– Semana 18: FastAPI para ML + Schemas Pydantic

**ðŸŽ¯ Objetivo**: Crear APIs de predicciÃ³n robustas.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **FastAPI** | Recepcionista que valida y dirige peticiones | RÃ¡pido, documentaciÃ³n automÃ¡tica |
| **Schema** | Formulario con campos requeridos | Valida entrada/salida automÃ¡ticamente |
| **/health** | Chequeo mÃ©dico de la API | Saber si el servicio estÃ¡ vivo |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > app/fastapi_app.py << 'EOF'
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
import joblib
from pathlib import Path

app = FastAPI(title="BankChurn API", version="1.0.0")

# Schemas
class PredictionRequest(BaseModel):
    age: int = Field(..., ge=18, le=100)
    balance: float = Field(..., ge=0)
    tenure: int = Field(..., ge=0)
    num_products: int = Field(..., ge=1, le=4)
    
class PredictionResponse(BaseModel):
    prediction: int
    probability: float
    model_version: str

# Cargar modelo
MODEL_PATH = Path("models/model.pkl")
model = joblib.load(MODEL_PATH) if MODEL_PATH.exists() else None

@app.get("/health")
def health_check():
    return {"status": "healthy", "model_loaded": model is not None}

@app.post("/predict", response_model=PredictionResponse)
def predict(request: PredictionRequest):
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    features = [[request.age, request.balance, request.tenure, request.num_products]]
    prediction = int(model.predict(features)[0])
    probability = float(model.predict_proba(features)[0][prediction])
    
    return PredictionResponse(
        prediction=prediction,
        probability=probability,
        model_version="1.0.0"
    )
EOF

# Ejecutar
pip install fastapi uvicorn
uvicorn app.fastapi_app:app --reload --port 8000

# Probar
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"age": 35, "balance": 50000, "tenure": 5, "num_products": 2}'
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `app/fastapi_app.py`

---

#### ðŸ“– Semana 19: Streamlit Dashboards + Caching

**ðŸŽ¯ Objetivo**: Crear dashboards interactivos.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Streamlit** | PowerPoint interactivo con Python | Demos rÃ¡pidos sin JavaScript |
| **st.cache** | Memoria para no repetir cÃ¡lculos | App mÃ¡s rÃ¡pida |
| **Tabs** | PestaÃ±as de navegador | Organiza contenido |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > app/streamlit_app.py << 'EOF'
import streamlit as st
import requests
import pandas as pd

st.set_page_config(page_title="BankChurn Predictor", page_icon="ðŸ¦")

st.title("ðŸ¦ BankChurn Predictor")

# Tabs
tab1, tab2 = st.tabs(["PredicciÃ³n", "InformaciÃ³n"])

with tab1:
    st.header("Predecir Churn de Cliente")
    
    col1, col2 = st.columns(2)
    with col1:
        age = st.slider("Edad", 18, 100, 35)
        balance = st.number_input("Balance", 0, 500000, 50000)
    with col2:
        tenure = st.slider("AÃ±os como cliente", 0, 20, 5)
        num_products = st.selectbox("Productos", [1, 2, 3, 4])
    
    if st.button("Predecir", type="primary"):
        try:
            response = requests.post(
                "http://localhost:8000/predict",
                json={"age": age, "balance": balance, "tenure": tenure, "num_products": num_products}
            )
            result = response.json()
            
            if result["prediction"] == 1:
                st.error(f"âš ï¸ Alto riesgo de churn ({result['probability']:.1%})")
            else:
                st.success(f"âœ… Cliente estable ({1-result['probability']:.1%})")
        except:
            st.error("Error conectando con la API")

with tab2:
    st.header("Sobre el Modelo")
    st.markdown("""
    - **Algoritmo**: Random Forest
    - **Accuracy**: 85%
    - **Features**: Age, Balance, Tenure, Products
    """)
EOF

# Ejecutar
pip install streamlit
streamlit run app/streamlit_app.py
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `app/streamlit_app.py`

---

#### ðŸ“– Semana 20: Observabilidad + Logging Estructurado

**ðŸŽ¯ Objetivo**: Monitorear aplicaciones en producciÃ³n.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Logging estructurado** | BitÃ¡cora con formato fijo | FÃ¡cil de buscar y analizar |
| **Prometheus** | TermÃ³metro de la aplicaciÃ³n | MÃ©tricas en tiempo real |
| **Drift detection** | Detector de cambios en datos | Modelo sigue siendo vÃ¡lido |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
pip install loguru prometheus-client

cat > src/bankchurn/logging.py << 'EOF'
from loguru import logger
import sys

def setup_logging(json_format: bool = True):
    """Configura logging estructurado."""
    logger.remove()
    
    if json_format:
        logger.add(
            sys.stdout,
            format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
            serialize=True  # JSON format
        )
    else:
        logger.add(sys.stdout, colorize=True)
    
    return logger
EOF

cat > app/metrics.py << 'EOF'
from prometheus_client import Counter, Histogram, generate_latest
from fastapi import Response

# MÃ©tricas
PREDICTIONS = Counter("predictions_total", "Total predictions", ["result"])
LATENCY = Histogram("prediction_latency_seconds", "Prediction latency")

def get_metrics():
    return Response(generate_latest(), media_type="text/plain")
EOF

# AÃ±adir a FastAPI
# from app.metrics import PREDICTIONS, LATENCY, get_metrics
# app.get("/metrics")(get_metrics)
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `src/*/logging.py`

---

### ðŸ—“ï¸ MES 6: PRODUCCIÃ“N & MAESTRÃA (Semanas 21-24)

> **Objetivo**: Completar el portafolio y preparar entrevistas.

#### ðŸ“– Semana 21: Estrategias de Despliegue + Cloud

**ðŸŽ¯ Objetivo**: Entender opciones de deployment.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Blue-Green** | Cambiar de carril sin frenar | Zero downtime en updates |
| **Canary** | Probar comida antes de servir | Detectar problemas con pocos usuarios |
| **Serverless** | Taxi vs auto propio | Pagas solo lo que usas |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
# docker-compose para desarrollo local
cat > docker-compose.yml << 'EOF'
version: "3.8"
services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MODEL_PATH=/app/models/model.pkl
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  streamlit:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    ports:
      - "8501:8501"
    depends_on:
      - api
EOF

docker-compose up -d
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `docker-compose.yml`, `k8s/`

---

#### ðŸ“– Semana 22: Infraestructura como CÃ³digo (Terraform)

**ðŸŽ¯ Objetivo**: Definir infraestructura de forma reproducible.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Terraform** | Plano de construcciÃ³n ejecutable | Infraestructura versionada |
| **State** | Inventario de lo construido | Sabe quÃ© existe vs quÃ© falta |
| **Plan** | Presupuesto antes de construir | Ves cambios antes de aplicar |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
mkdir -p infra/terraform

cat > infra/terraform/main.tf << 'EOF'
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

variable "aws_region" {
  default = "us-east-1"
}

variable "project_name" {
  default = "bankchurn"
}

# ECR Repository
resource "aws_ecr_repository" "app" {
  name = "${var.project_name}-api"
  
  image_scanning_configuration {
    scan_on_push = true
  }
}

output "ecr_repository_url" {
  value = aws_ecr_repository.app.repository_url
}
EOF

# Comandos Terraform
# terraform init
# terraform plan
# terraform apply
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `infra/terraform/`

---

#### ðŸ“– Semana 23: DocumentaciÃ³n Profesional + Model Cards

**ðŸŽ¯ Objetivo**: Documentar modelos para producciÃ³n.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **Model Card** | Ficha tÃ©cnica de un electrodomÃ©stico | Usuarios saben limitaciones |
| **Dataset Card** | Etiqueta nutricional de datos | Transparencia sobre fuente |
| **MkDocs** | Wiki profesional automÃ¡tica | DocumentaciÃ³n navegable |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
cat > docs/MODEL_CARD.md << 'EOF'
# Model Card: BankChurn Classifier

## Model Details
- **Developer**: Tu Nombre
- **Model Date**: Diciembre 2024
- **Model Version**: 1.0.0
- **Model Type**: Random Forest Classifier

## Intended Use
- **Primary Use**: Predecir probabilidad de abandono de clientes bancarios
- **Users**: Equipo de retenciÃ³n de clientes
- **Out-of-scope**: No usar para decisiones de crÃ©dito

## Training Data
- **Source**: Dataset sintÃ©tico de clientes bancarios
- **Size**: 10,000 registros
- **Features**: Age, Balance, Tenure, NumOfProducts

## Evaluation
| Metric | Value |
|--------|-------|
| Accuracy | 0.85 |
| F1-Score | 0.78 |
| AUC-ROC | 0.82 |

## Limitations
- Entrenado solo con datos de un banco
- No considera factores externos (economÃ­a, competencia)

## Ethical Considerations
- Evitar discriminaciÃ³n por edad
- Decisiones finales deben ser revisadas por humanos
EOF
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: `docs/model_card.md`

---

#### ðŸ“– Semana 24: Proyecto Integrador + PreparaciÃ³n Entrevistas

**ðŸŽ¯ Objetivo**: Validar portafolio completo y preparar presentaciÃ³n.

##### ðŸ”° Para Principiantes: AnalogÃ­as

| Concepto | AnalogÃ­a | Por quÃ© importa |
|----------|----------|-----------------|
| **RÃºbrica** | Lista de requisitos para aprobar | Sabes si estÃ¡s listo |
| **Speech** | Elevator pitch de tu trabajo | Impresiona en 5 minutos |
| **Live Demo** | Mostrar el producto funcionando | Credibilidad instantÃ¡nea |

##### ðŸ’» PrÃ¡ctica EmpÃ­rica

```bash
# Checklist final de validaciÃ³n
cat > CHECKLIST_FINAL.md << 'EOF'
# Checklist de Portafolio Completo

## BankChurn-Predictor
- [ ] `make test` pasa con 80%+ coverage
- [ ] `make serve` inicia API en localhost:8000
- [ ] `curl localhost:8000/health` retorna OK
- [ ] Dockerfile construye sin errores
- [ ] CI/CD pasa en GitHub Actions

## CarVision-Market-Intelligence  
- [ ] Pipeline de features funciona
- [ ] Dashboard Streamlit funciona
- [ ] Tests pasan

## TelecomAI-Customer-Intelligence
- [ ] Multiclass classification funciona
- [ ] MLflow tracking configurado
- [ ] DocumentaciÃ³n completa

## DocumentaciÃ³n
- [ ] Model Cards para cada proyecto
- [ ] README profesional en cada repo
- [ ] ADRs documentando decisiones

## PreparaciÃ³n Entrevistas
- [ ] Speech de 5-7 min practicado
- [ ] Demo de 3 min funciona
- [ ] Preguntas tÃ©cnicas revisadas
EOF
```

**ðŸ“¦ UbicaciÃ³n en Portafolio**: Portafolio completo

---

## ðŸ“‹ ExÃ¡menes de Hito (6 Milestones)

Cada mes incluye un examen prÃ¡ctico que valida tu progreso. **Debes completar cada hito antes de avanzar al siguiente mes.**

---

### ðŸ† HITO 1: Setup Completo (Fin Mes 1)

**Objetivo**: Demostrar que tienes un entorno de desarrollo profesional funcionando.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| Entorno virtual funcionando | 10 | `python --version` muestra 3.10+ |
| pyproject.toml vÃ¡lido | 15 | `pip install -e ".[dev]"` funciona |
| Pre-commit configurado | 15 | `pre-commit run --all-files` pasa |
| Estructura src/ correcta | 10 | Existe `src/bankchurn/__init__.py` |
| Makefile con comandos bÃ¡sicos | 10 | `make lint` funciona |
| Git con commits convencionales | 10 | `git log --oneline` muestra formato correcto |
| CÃ³digo tipado con mypy | 15 | `mypy src/ --strict` sin errores |
| README.md profesional | 15 | Incluye instalaciÃ³n, uso, estructura |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# Ejecutar todos los checks del Hito 1
make lint                          # Linting pasa
mypy src/ --strict                 # Sin errores de tipos
pre-commit run --all-files         # Hooks pasan
pip install -e ".[dev]"            # InstalaciÃ³n funciona
```

---

### ðŸ† HITO 2: Pipeline Reproducible (Fin Mes 2)

**Objetivo**: Demostrar pipelines de datos y ML reproducibles.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| DVC inicializado | 15 | Existe `.dvc/config` |
| Datos versionados | 15 | Existe `data/*.dvc` |
| Pipeline DVC funcional | 20 | `dvc repro` ejecuta sin errores |
| sklearn Pipeline creado | 20 | `create_pipeline()` retorna Pipeline |
| Custom Transformer | 15 | Clase hereda de BaseEstimator |
| Sin data leakage | 15 | fit solo en train, transform en test |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# Ejecutar todos los checks del Hito 2
dvc status                         # Sin cambios pendientes
dvc repro                          # Pipeline ejecuta completamente
python -c "from src.bankchurn.pipeline import create_pipeline; print(create_pipeline())"
dvc dag                            # Muestra DAG del pipeline
```

---

### ðŸ† HITO 3: Experimento Completo (Fin Mes 3)

**Objetivo**: Demostrar tracking de experimentos y model registry.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| MLflow experiment creado | 15 | `mlflow experiments list` muestra experimento |
| MÃ©tricas logueadas | 20 | accuracy, f1, precision en MLflow UI |
| Modelo registrado | 20 | Modelo en Model Registry |
| Signature definida | 15 | Modelo tiene input/output signature |
| Cross-validation implementada | 15 | Trainer usa StratifiedKFold |
| FeatureEngineer funcional | 15 | Crea features sin leakage |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# Ejecutar todos los checks del Hito 3
mlflow experiments list            # Experimento existe
mlflow runs list --experiment-id 1 # Runs existen
python src/bankchurn/train_mlflow.py  # Entrenamiento completo
mlflow ui                          # UI muestra mÃ©tricas
```

---

### ðŸ† HITO 4: CI/CD Completo (Fin Mes 4)

**Objetivo**: Demostrar testing y automatizaciÃ³n profesional.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| Tests unitarios | 20 | `pytest tests/unit/` pasa |
| Tests integraciÃ³n | 15 | `pytest tests/integration/` pasa |
| Coverage â‰¥ 80% | 20 | `pytest --cov --cov-fail-under=80` |
| GitHub Actions workflow | 20 | `.github/workflows/ci.yml` existe |
| Matrix testing (3.10, 3.11, 3.12) | 10 | CI corre en mÃºltiples versiones |
| Security scanning | 15 | gitleaks configurado |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# Ejecutar todos los checks del Hito 4
pytest tests/ -v --cov=src --cov-report=term-missing --cov-fail-under=80
cat .github/workflows/ci.yml       # Workflow existe
pre-commit run gitleaks --all-files  # Sin secretos expuestos
```

---

### ðŸ† HITO 5: API Desplegada (Fin Mes 5)

**Objetivo**: Demostrar deployment de modelo como servicio.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| Dockerfile multi-stage | 15 | Imagen < 500MB |
| FastAPI /predict funcional | 20 | curl retorna predicciÃ³n |
| FastAPI /health funcional | 10 | curl retorna status |
| Schemas Pydantic validados | 15 | Request invÃ¡lido retorna 422 |
| Streamlit dashboard | 15 | streamlit run funciona |
| Logging estructurado | 10 | Logs en formato JSON |
| MÃ©tricas Prometheus | 15 | /metrics endpoint existe |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# Ejecutar todos los checks del Hito 5
docker build -t bankchurn:latest .
docker run -d -p 8000:8000 bankchurn:latest
sleep 5
curl http://localhost:8000/health
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"age": 35, "balance": 50000, "tenure": 5, "num_products": 2}'
curl http://localhost:8000/metrics
```

---

### ðŸ† HITO 6: Portafolio Completo (Fin Mes 6)

**Objetivo**: Demostrar portafolio production-ready listo para entrevistas.

#### Criterios de EvaluaciÃ³n

| Criterio | Puntos | CÃ³mo Validar |
|----------|:------:|--------------|
| 3 proyectos funcionando | 20 | make test pasa en los 3 |
| Model Cards completos | 15 | docs/MODEL_CARD.md en cada proyecto |
| CI/CD pasando en GitHub | 15 | Badge verde en README |
| docker-compose funcional | 10 | `docker-compose up` levanta todo |
| IaC documentado | 10 | infra/terraform/ con README |
| Speech de 5-7 min preparado | 15 | GrabaciÃ³n de prÃ¡ctica |
| Demo de 3 min funciona | 15 | Video o live demo |

**PuntuaciÃ³n mÃ­nima**: 70/100

#### Comandos de ValidaciÃ³n

```bash
# ValidaciÃ³n final completa
for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do
  echo "=== Testing $project ==="
  cd $project && make test && cd ..
done

# Verificar documentaciÃ³n
ls */docs/MODEL_CARD.md

# Levantar stack completo
docker-compose up -d
curl http://localhost:8000/health
curl http://localhost:8501
```

---

## ðŸ”§ GuÃ­a de Troubleshooting

Errores comunes al configurar el entorno local por sistema operativo.

---

### ðŸªŸ Windows

#### Error: `pip install` falla con permisos

```powershell
# SÃ­ntoma
ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied

# SoluciÃ³n 1: Usar --user
pip install --user -r requirements.txt

# SoluciÃ³n 2: Ejecutar PowerShell como Administrador
# Click derecho > "Ejecutar como administrador"

# SoluciÃ³n 3: Usar entorno virtual (recomendado)
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

#### Error: `python` no reconocido

```powershell
# SÃ­ntoma
'python' is not recognized as an internal or external command

# SoluciÃ³n: AÃ±adir Python al PATH
# 1. Buscar "Variables de entorno" en Windows
# 2. Editar PATH del usuario
# 3. AÃ±adir: C:\Users\TU_USUARIO\AppData\Local\Programs\Python\Python311\

# O reinstalar Python marcando "Add to PATH"
```

#### Error: `make` no encontrado

```powershell
# SÃ­ntoma
'make' is not recognized

# SoluciÃ³n 1: Instalar chocolatey y make
Set-ExecutionPolicy Bypass -Scope Process -Force
iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))
choco install make

# SoluciÃ³n 2: Usar comandos directos sin make
pip install -e ".[dev]"   # en vez de make install
pytest tests/ -v          # en vez de make test
```

#### Error: Docker Desktop no inicia

```powershell
# SÃ­ntoma
Docker Desktop - WSL 2 installation is incomplete

# SoluciÃ³n
# 1. Abrir PowerShell como Admin
wsl --install
# 2. Reiniciar PC
# 3. Abrir Docker Desktop
```

---

### ðŸ§ Linux (Ubuntu/Debian)

#### Error: `python3.10` no disponible

```bash
# SÃ­ntoma
E: Unable to locate package python3.10

# SoluciÃ³n: AÃ±adir deadsnakes PPA
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.10 python3.10-venv python3.10-dev
```

#### Error: `pip` no encontrado

```bash
# SÃ­ntoma
Command 'pip' not found

# SoluciÃ³n
sudo apt install python3-pip
# O usar pip3
pip3 install -r requirements.txt
```

#### Error: Permisos en Docker

```bash
# SÃ­ntoma
Got permission denied while trying to connect to the Docker daemon socket

# SoluciÃ³n: AÃ±adir usuario al grupo docker
sudo usermod -aG docker $USER
newgrp docker
# O cerrar sesiÃ³n y volver a entrar
```

#### Error: `libpq-dev` faltante (para psycopg2)

```bash
# SÃ­ntoma
Error: pg_config executable not found

# SoluciÃ³n
sudo apt install libpq-dev python3-dev
pip install psycopg2-binary  # versiÃ³n sin compilar
```

---

### ðŸŽ macOS

#### Error: `Command Line Tools` faltantes

```bash
# SÃ­ntoma
xcrun: error: invalid active developer path

# SoluciÃ³n
xcode-select --install
```

#### Error: Conflicto con Python del sistema

```bash
# SÃ­ntoma
WARNING: pip is configured with locations that require TLS/SSL

# SoluciÃ³n: Usar pyenv
brew install pyenv
pyenv install 3.11.0
pyenv global 3.11.0
echo 'eval "$(pyenv init -)"' >> ~/.zshrc
source ~/.zshrc
```

#### Error: `libomp` faltante (para scikit-learn)

```bash
# SÃ­ntoma
Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib

# SoluciÃ³n
brew install libomp
```

#### Error: Docker muy lento en Mac M1/M2

```bash
# SÃ­ntoma
Docker builds extremadamente lentos

# SoluciÃ³n 1: Usar Rosetta
# En Docker Desktop > Settings > General > Use Rosetta

# SoluciÃ³n 2: Builds nativos ARM64
docker buildx build --platform linux/arm64 -t myapp .
```

---

### ðŸ Errores Comunes de Dependencias

#### Error: Conflicto de versiones numpy/pandas

```bash
# SÃ­ntoma
ImportError: numpy.core.multiarray failed to import

# SoluciÃ³n: Reinstalar en orden
pip uninstall numpy pandas scikit-learn -y
pip install numpy==1.24.0
pip install pandas==2.0.0
pip install scikit-learn==1.3.0
```

#### Error: MLflow no conecta

```bash
# SÃ­ntoma
ConnectionRefusedError: [Errno 111] Connection refused

# SoluciÃ³n: Verificar que MLflow server estÃ¡ corriendo
mlflow server --host 0.0.0.0 --port 5000 &
# O usar tracking local
export MLFLOW_TRACKING_URI=file:./mlruns
```

#### Error: DVC remote no configurado

```bash
# SÃ­ntoma
ERROR: failed to push data to remote - config file error

# SoluciÃ³n
dvc remote add -d myremote /path/to/storage
dvc remote modify myremote url s3://my-bucket/dvc
dvc push
```

#### Error: pytest no encuentra mÃ³dulos

```bash
# SÃ­ntoma
ModuleNotFoundError: No module named 'src'

# SoluciÃ³n: Instalar en modo editable
pip install -e ".[dev]"

# O aÃ±adir al PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

---

## âš¡ Quick Start

```bash
# 1. Clonar el portafolio
git clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git
cd ML-MLOps-Portfolio

# 2. Configurar entorno
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. Empezar con BankChurn (proyecto base)
cd BankChurn-Predictor
pip install -e ".[dev]"

# 4. Verificar instalaciÃ³n
make lint        # Verificar cÃ³digo
make test        # Ejecutar tests
make train       # Entrenar modelo
make serve       # Iniciar API

# 5. Probar API
curl http://localhost:8000/health
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"age": 35, "balance": 50000, "tenure": 5, "num_products": 2}'
```

---

## ðŸ“ Estructura de Carpetas

```
Guia_MLOps/
â”œâ”€â”€ README.md                    # ðŸ‘ˆ Este archivo (Ã­ndice maestro)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 00_INDICE.md            # Ãndice original (8 semanas)
â”‚   â”œâ”€â”€ 01_PYTHON_MODERNO.md    # MÃ³dulo: Python profesional
â”‚   â”œâ”€â”€ 02_DISENO_SISTEMAS.md   # MÃ³dulo: Arquitectura ML
â”‚   â”œâ”€â”€ 03_ESTRUCTURA_PROYECTO.md
â”‚   â”œâ”€â”€ 04_ENTORNOS.md
â”‚   â”œâ”€â”€ 05_GIT_PROFESIONAL.md
â”‚   â”œâ”€â”€ 06_VERSIONADO_DATOS.md  # DVC
â”‚   â”œâ”€â”€ 07_SKLEARN_PIPELINES.md
â”‚   â”œâ”€â”€ 08_INGENIERIA_FEATURES.md
â”‚   â”œâ”€â”€ 09_TRAINING_PROFESIONAL.md
â”‚   â”œâ”€â”€ 10_EXPERIMENT_TRACKING.md  # MLflow
â”‚   â”œâ”€â”€ 11_TESTING_ML.md
â”‚   â”œâ”€â”€ 12_CI_CD.md             # GitHub Actions
â”‚   â”œâ”€â”€ 13_DOCKER.md
â”‚   â”œâ”€â”€ 14_FASTAPI.md
â”‚   â”œâ”€â”€ 15_STREAMLIT.md
â”‚   â”œâ”€â”€ 16_OBSERVABILIDAD.md
â”‚   â”œâ”€â”€ 17_DESPLIEGUE.md
â”‚   â”œâ”€â”€ 18_INFRAESTRUCTURA.md   # Terraform
â”‚   â”œâ”€â”€ 19_DOCUMENTACION.md     # Model Cards
â”‚   â”œâ”€â”€ 20_PROYECTO_INTEGRADOR.md
â”‚   â”œâ”€â”€ 21_GLOSARIO.md
â”‚   â”œâ”€â”€ 22_CHECKLIST.md
â”‚   â”œâ”€â”€ 23_RECURSOS.md
â”‚   â”œâ”€â”€ EJERCICIOS.md
â”‚   â”œâ”€â”€ EJERCICIOS_SOLUCIONES.md
â”‚   â”œâ”€â”€ SIMULACRO_ENTREVISTA_JUNIOR.md
â”‚   â”œâ”€â”€ SIMULACRO_ENTREVISTA_MID.md
â”‚   â”œâ”€â”€ SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md
â”‚   â”œâ”€â”€ SIMULACRO_ENTREVISTA_SENIOR_PARTE2.md
â”‚   â””â”€â”€ study_tools/            # Herramientas de estudio
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ ci.yml
â”‚   â”œâ”€â”€ model_card_template.md
â”‚   â””â”€â”€ dataset_card_template.md
â”œâ”€â”€ notebooks/                  # Notebooks de prÃ¡ctica
â””â”€â”€ scripts/                    # Scripts auxiliares
```

---

## ðŸ“š Recursos Complementarios

| Recurso | DescripciÃ³n | Link |
|---------|-------------|------|
| **SYLLABUS.md** | Programa detallado macro-mÃ³dulos | [docs/SYLLABUS.md](docs/SYLLABUS.md) |
| **PLAN_ESTUDIOS.md** | Cronograma dÃ­a a dÃ­a (8 semanas) | [docs/PLAN_ESTUDIOS.md](docs/PLAN_ESTUDIOS.md) |
| **EJERCICIOS.md** | Problemas prÃ¡cticos | [docs/EJERCICIOS.md](docs/EJERCICIOS.md) |
| **GLOSARIO.md** | 100+ tÃ©rminos MLOps | [docs/21_GLOSARIO.md](docs/21_GLOSARIO.md) |
| **Speech Portafolio** | GuiÃ³n 5-7 min | [docs/APENDICE_A_SPEECH_PORTAFOLIO.md](docs/APENDICE_A_SPEECH_PORTAFOLIO.md) |

---

## ðŸŽ¯ Los 3 Proyectos del Portafolio

| Proyecto | Problema | Stack Principal | Coverage |
|----------|----------|-----------------|:--------:|
| **BankChurn-Predictor** | ClasificaciÃ³n binaria (churn) | RandomForest, FastAPI, Docker | 79%+ |
| **CarVision-Market-Intelligence** | RegresiÃ³n (precios autos) | FeatureEngineer, Streamlit | 97% |
| **TelecomAI-Customer-Intelligence** | ClasificaciÃ³n multiclase | MLflow, LogisticRegression | 97% |

---

<div align="center">

## ðŸš€ Â¡Empieza Ahora!

**Semana 1** â†’ [Python Moderno](docs/01_PYTHON_MODERNO.md)

---

*Tiempo estimado: 24 semanas (6 meses) a ritmo moderado*

*Ãšltima actualizaciÃ³n: Diciembre 2024*

**Autor**: GuÃ­a MLOps Portfolio Edition

</div>
