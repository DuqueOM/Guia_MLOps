# 03. Estructura de Proyecto ML Profesional

## ğŸ¯ Objetivo del MÃ³dulo

Crear la estructura de proyecto que usarÃ¡s en los 3 proyectos del portafolio.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  Una buena estructura de proyecto es como los cimientos de una casa:         â•‘
â•‘  invisible cuando estÃ¡ bien hecha, DESASTROSA cuando estÃ¡ mal.               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

<a id="00-prerrequisitos"></a>

## 0.0 Prerrequisitos

- Haber completado **[01_PYTHON_MODERNO](01_PYTHON_MODERNO.md)** (type hints + `src/` layout).
- Tener claro quÃ© proyecto del portafolio vas a usar como base (BankChurn, CarVision, TelecomAI).
- Poder ejecutar comandos bÃ¡sicos (instalar deps, correr tests).

---

<a id="01-protocolo-e-como-estudiar-este-modulo"></a>

## 0.1 ğŸ§  Protocolo E: CÃ³mo estudiar este mÃ³dulo

- **Antes de tocar el repo**: abre **[Protocolo E](study_tools/PROTOCOLO_E.md)** y define tu *output mÃ­nimo* (ej: â€œestructura + `pyproject.toml` + Makefile + tests corriendoâ€).
- **Mientras implementas**: si te atoras >15 min (imports, `pip install -e`, targets del Makefile), registra el bloqueo en **[Diario de Errores](study_tools/DIARIO_ERRORES.md)**.
- **Al cerrar la semana**: usa **[Cierre Semanal](study_tools/CIERRE_SEMANAL.md)** para decidir quÃ© mejorar (DX, reproducibilidad, CI).

---

<a id="02-entregables-verificables-minimo-viable"></a>

## 0.2 âœ… Entregables verificables (mÃ­nimo viable)

Al terminar este mÃ³dulo, deberÃ­as poder mostrar (en al menos 1 proyecto del portafolio):

- [ ] **Ãrbol de proyecto** consistente con `src/`, `tests/`, `configs/`, `data/` (gitignored) y `artifacts/` (gitignored).
- [ ] **InstalaciÃ³n editable** funcionando: `pip install -e ".[dev]"`.
- [ ] **Tests ejecutables** desde la raÃ­z: `pytest`.
- [ ] **Makefile** con al menos: `install`, `test`, `lint` (y opcional `train`, `serve`).

---

<a id="03-puente-teoria-codigo-portafolio"></a>

## 0.3 ğŸ§© Puente teorÃ­a â†” cÃ³digo (Portafolio)

Para que esto cuente como progreso real, fuerza este mapeo:

- **Concepto**: estructura del repo / packaging / DX
- **Archivo**: `pyproject.toml`, `Makefile`, `.gitignore`, `src/<paquete>/`, `tests/`
- **Prueba**: `pip install -e ".[dev]"` + `pytest` + `ruff check` + `mypy src/`
- **Evidencia**: un repo que corre igual en tu mÃ¡quina y en CI.

---

## ğŸ“‹ Contenido

- **0.0** [Prerrequisitos](#00-prerrequisitos)
- **0.1** [Protocolo E: CÃ³mo estudiar este mÃ³dulo](#01-protocolo-e-como-estudiar-este-modulo)
- **0.2** [Entregables verificables (mÃ­nimo viable)](#02-entregables-verificables-minimo-viable)
- **0.3** [Puente teorÃ­a â†” cÃ³digo (Portafolio)](#03-puente-teoria-codigo-portafolio)
- [La Estructura del Portafolio](#estructura-portafolio)
- [CÃ³mo se aplica en este portafolio](#como-se-aplica)
- [pyproject.toml completo](#pyproject)
- [Makefile](#makefile)
- [.gitignore](#gitignore)
- [ğŸ”¬ IngenierÃ­a Inversa: Estructura Real](#36-ingenieria-inversa-estructura)
- [Errores habituales y cÃ³mo depurarlos](#errores-habituales)
- [ğŸ““ Refactoring: De Notebook a ProducciÃ³n](#37-refactoring) â­ INTEGRADO
- [ğŸ“¦ LibrerÃ­as Compartidas (common_utils)](#38-common-utils) â­ INTEGRADO
- [ğŸ“ SecciÃ³n PedagÃ³gica: Aprende Haciendo](#39-pedagogia) â­ NUEVO
- [Consejos Profesionales](#consejos-profesionales)
- [Recursos Externos Recomendados](#recursos-externos)
- [Referencias del Glosario](#referencias-glosario)
- [Plantillas Relacionadas](#plantillas-relacionadas)
- [Ejercicios](#ejercicios)

---

<a id="estructura-portafolio"></a>

## ğŸ“‹ La Estructura del Portafolio

```
MiProyecto-ML/
â”‚
â”œâ”€â”€ src/                          # ğŸ“¦ CÃ“DIGO FUENTE (instalable)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ miproyecto/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ data.py               # Carga y validaciÃ³n de datos
â”‚       â”œâ”€â”€ features.py           # Feature engineering
â”‚       â”œâ”€â”€ training.py           # Pipeline de entrenamiento
â”‚       â”œâ”€â”€ evaluation.py         # MÃ©tricas y evaluaciÃ³n
â”‚       â”œâ”€â”€ prediction.py         # Inferencia
â”‚       â””â”€â”€ models.py             # Custom models/transformers
â”‚
â”œâ”€â”€ app/                          # ğŸŒ APLICACIONES
â”‚   â”œâ”€â”€ fastapi_app.py            # API REST
â”‚   â””â”€â”€ streamlit_app.py          # Dashboard (opcional)
â”‚
â”œâ”€â”€ tests/                        # ğŸ§ª TESTS (espejo de src/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidas
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_training.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ configs/                      # âš™ï¸ CONFIGURACIÃ“N
â”‚   â””â”€â”€ config.yaml               # HiperparÃ¡metros, paths, etc.
â”‚
â”œâ”€â”€ data/                         # ğŸ“Š DATOS (gitignored)
â”‚   â”œâ”€â”€ raw/                      # Datos originales
â”‚   â””â”€â”€ processed/                # Datos procesados (opcional)
â”‚
â”œâ”€â”€ artifacts/                    # ğŸ“ ARTEFACTOS (gitignored)
â”‚   â”œâ”€â”€ model.joblib              # Modelo entrenado
â”‚   â””â”€â”€ metrics.json              # MÃ©tricas de entrenamiento
â”‚
â”œâ”€â”€ scripts/                      # ğŸ”§ SCRIPTS AUXILIARES
â”‚   â””â”€â”€ run_mlflow.py             # Script de MLflow
â”‚
â”œâ”€â”€ docs/                         # ğŸ“– DOCUMENTACIÃ“N
â”‚   â”œâ”€â”€ model_card.md
â”‚   â””â”€â”€ data_card.md
â”‚
â”œâ”€â”€ infra/                        # ğŸ—ï¸ INFRAESTRUCTURA (opcional)
â”‚   â””â”€â”€ terraform/
â”‚
â”œâ”€â”€ pyproject.toml                # ğŸ“‹ METADATA DEL PROYECTO
â”œâ”€â”€ requirements.txt              # ğŸ“‹ DEPENDENCIAS (para CI)
â”œâ”€â”€ Makefile                      # ğŸ”¨ COMANDOS COMUNES
â”œâ”€â”€ Dockerfile                    # ğŸ³ CONTAINERIZACIÃ“N
â”œâ”€â”€ .github/workflows/            # ğŸ”„ CI/CD
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ .gitignore                    # ğŸš« ARCHIVOS IGNORADOS
â”œâ”€â”€ .pre-commit-config.yaml       # ğŸ” HOOKS PRE-COMMIT
â””â”€â”€ README.md                     # ğŸ“– DOCUMENTACIÃ“N PRINCIPAL
```

### ğŸ§  Mapa Mental de Conceptos: Estructura de Proyecto

```
                        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                        â•‘   ESTRUCTURA PROFESIONAL DE PROYECTO ML     â•‘
                        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                                   â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¦ CÃ“DIGO        â”‚             â”‚  âš™ï¸ CONFIG       â”‚             â”‚  ğŸ”§ HERRAMIENTAS  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                 â”‚                                 â”‚
â”œâ”€ src/<paquete>/             â”œâ”€ pyproject.toml               â”œâ”€ Makefile
â”œâ”€ app/                       â”œâ”€ configs/*.yaml               â”œâ”€ Dockerfile
â”œâ”€ tests/                     â”œâ”€ .pre-commit                  â”œâ”€ .github/workflows/
â””â”€ scripts/                   â””â”€ .gitignore                   â””â”€ README.md
                                         â”‚
                                         â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  ğŸ“Š DATOS         â”‚
                              â”‚  (gitignored)     â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                              â”œâ”€ data/raw/
                              â”œâ”€ data/processed/
                              â”œâ”€ artifacts/
                              â””â”€ mlruns/
```

**TÃ©rminos clave que debes dominar:**

| Directorio | PropÃ³sito | Gitignored? |
|------------|-----------|-------------|
| **src/** | CÃ³digo fuente instalable | No |
| **tests/** | Tests (espejo de src) | No |
| **app/** | APIs y dashboards | No |
| **configs/** | ConfiguraciÃ³n YAML | No |
| **data/** | Datos raw/procesados | âœ… SÃ­ |
| **artifacts/** | Modelos entrenados | âœ… SÃ­ |
| **mlruns/** | Experimentos MLflow | âœ… SÃ­ |

---

### ğŸ’» Ejercicio Puente: Crear Estructura MÃ­nima

> **Meta**: Antes de estructurar un proyecto ML completo, practica con una estructura mÃ­nima.

**Ejercicio 1: Estructura desde cero**
```bash
# TU TAREA: Crea esta estructura mÃ­nima para un proyecto "myproject"
# 
# myproject/
# â”œâ”€â”€ src/
# â”‚   â””â”€â”€ myproject/
# â”‚       â”œâ”€â”€ __init__.py
# â”‚       â””â”€â”€ main.py
# â”œâ”€â”€ tests/
# â”‚   â””â”€â”€ test_main.py
# â”œâ”€â”€ pyproject.toml
# â””â”€â”€ README.md
#
# PISTA: Usa mkdir -p y touch
```

**Ejercicio 2: Verificar instalaciÃ³n**
```bash
# DespuÃ©s de crear la estructura y pyproject.toml mÃ­nimo
cd myproject
pip install -e .
python -c "from myproject import main; print('âœ… Funciona!')"
```

<details>
<summary>ğŸ” Ver SoluciÃ³n</summary>

```bash
# Crear estructura
mkdir -p myproject/src/myproject myproject/tests
touch myproject/src/myproject/__init__.py
touch myproject/src/myproject/main.py
touch myproject/tests/test_main.py
touch myproject/README.md

# Crear pyproject.toml mÃ­nimo
cat > myproject/pyproject.toml << 'EOF'
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "myproject"
version = "0.1.0"
requires-python = ">=3.10"

[tool.setuptools.packages.find]
where = ["src"]
EOF

# Verificar
cd myproject
pip install -e .
python -c "from myproject import main; print('âœ… Funciona!')"
```
</details>

---

### ğŸ› ï¸ PrÃ¡ctica del Portafolio: Verificar Estructura de BankChurn

> **Tarea**: Verificar que BankChurn-Predictor sigue la estructura profesional.

**Paso 1: Explora la estructura real**
```bash
cd BankChurn-Predictor
tree -L 2 --dirsfirst
# O sin tree: find . -maxdepth 2 -type d | head -20
```

**Paso 2: Checklist de verificaciÃ³n**
```
[ ] Â¿Existe src/bankchurn/__init__.py?
[ ] Â¿Existe tests/conftest.py?
[ ] Â¿Existe pyproject.toml con [tool.setuptools.packages.find] where=["src"]?
[ ] Â¿Existe Makefile con targets: install, test, lint?
[ ] Â¿.gitignore excluye data/, artifacts/, mlruns/?
```

**Paso 3: Ejecuta los comandos del Makefile**
```bash
make install      # Debe funcionar sin errores
make test         # Debe ejecutar pytest
make lint         # Debe ejecutar ruff/mypy
```

**Paso 4: Si algo falla, documenta**
```
Â¿QuÃ© fallÃ³? ___________________
Â¿Por quÃ©? ___________________
Â¿CÃ³mo lo arreglaste? ___________________
```

---

### âœ… Checkpoint de Conocimiento: Estructura de Proyecto

**Pregunta 1**: Â¿Por quÃ© ponemos el cÃ³digo en `src/` en vez de en la raÃ­z?

A) Es mÃ¡s rÃ¡pido  
B) Fuerza que el cÃ³digo estÃ© INSTALADO para importarlo (evita bugs de imports)  
C) GitHub lo requiere  
D) Ocupa menos espacio  

**Pregunta 2**: Â¿Por quÃ© `data/` y `artifacts/` deben estar en .gitignore?

A) Son archivos temporales  
B) Son archivos binarios grandes que no deben versionarse en Git  
C) Git no soporta esos formatos  
D) Hace el repo mÃ¡s rÃ¡pido  

**Pregunta 3**: Â¿CuÃ¡l es el propÃ³sito del archivo `__init__.py`?

A) Almacenar configuraciÃ³n  
B) Marcar un directorio como paquete Python importable  
C) Ejecutar tests  
D) Documentar el proyecto  

**ï¿½ï¿½ Escenario de Debugging:**

```
SituaciÃ³n: Ejecutas pytest en CI y obtienes:
  ModuleNotFoundError: No module named 'bankchurn'

Pero en tu mÃ¡quina local funciona perfectamente.

El workflow de CI tiene:
  - run: pip install -r requirements.txt
  - run: pytest
```

**Â¿CuÃ¡l es el problema y cÃ³mo lo solucionarÃ­as?**

<details>
<summary>ğŸ” Ver Respuestas</summary>

**Pregunta 1**: B) Fuerza que el cÃ³digo estÃ© INSTALADO para importarlo. Esto evita el problema "funciona en mi mÃ¡quina".

**Pregunta 2**: B) Son archivos binarios grandes. Git no estÃ¡ diseÃ±ado para archivos grandes; usa DVC o storage externo.

**Pregunta 3**: B) Marcar un directorio como paquete Python importable.

**Escenario de Debugging**: 
- **Problema**: El CI solo instala dependencias, pero NO instala tu paquete.
- **SoluciÃ³n**: Cambiar el workflow:
```yaml
- run: pip install -e ".[dev]"  # Instala TU paquete + deps
- run: pytest
```
</details>

---

<a id="como-se-aplica"></a>

## ğŸ§© CÃ³mo se aplica en este portafolio

Esta estructura no es teÃ³rica: los **3 proyectos** del portafolio la siguen con ligeras
variaciones. Esto conecta directamente con los macro-mÃ³dulos **00** y **01** de la
**Ruta 0 â†’ Senior/Staff** descrita en el [SYLLABUS](SYLLABUS.md).

| Proyecto | Carpeta raÃ­z | Paquete principal | Archivos clave |
|----------|--------------|-------------------|----------------|
| BankChurn Predictor | `BankChurn-Predictor/` | `src/bankchurn/` | `pyproject.toml`, `main.py`, `Makefile`, `tests/` |
| CarVision Market Intelligence | `CarVision-Market-Intelligence/` | `src/carvision/` | `pyproject.toml`, `main.py`, `Makefile`, `tests/` |
| TelecomAI Customer Intelligence | `TelecomAI-Customer-Intelligence/` | `src/telecom/` | `pyproject.toml`, `main.py`, `Makefile`, `tests/` |

Para aprovechar este mÃ³dulo al mÃ¡ximo en el repositorio real:

- **Compara** el Ã¡rbol genÃ©rico de `MiProyecto-ML/` con, por ejemplo,
  `BankChurn-Predictor/` (fÃ­jate especialmente en `src/`, `configs/`, `tests/`,
  `Makefile` y `pyproject.toml`).
- **Verifica** que los comandos que defines aquÃ­ (`make install`, `make test`,
  `make train`, `make serve`) tienen su equivalente funcional en los Makefiles de
  cada proyecto.
- **Usa** esta plantilla como referencia si creas un **cuarto proyecto** durante el
  [23_PROYECTO_INTEGRADOR](23_PROYECTO_INTEGRADOR.md).

---

<a id="pyproject"></a>

## ğŸ“„ pyproject.toml Completo

```toml
# pyproject.toml - El corazÃ³n del proyecto

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "bankchurn"
version = "1.0.0"
description = "Bank Customer Churn Prediction System"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [
    {name = "Tu Nombre", email = "tu@email.com"}
]
keywords = ["machine-learning", "churn", "prediction"]

dependencies = [
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "scikit-learn>=1.3.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "joblib>=1.3.0",
]

[project.optional-dependencies]
api = [
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
]
mlflow = [
    "mlflow>=2.9.0",
]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "pre-commit>=3.5.0",
]
all = [
    "bankchurn[api,mlflow,dev]",
]

[project.scripts]
bankchurn = "bankchurn.cli:main"

[tool.setuptools.packages.find]
where = ["src"]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=src/bankchurn --cov-report=term-missing"

[tool.coverage.run]
source = ["src"]
omit = ["tests/*"]

[tool.coverage.report]
fail_under = 79

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "W"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.11"
ignore_missing_imports = true
```

---

<a id="makefile"></a>

## ğŸ”¨ Makefile

```makefile
# Makefile - Comandos comunes del proyecto

.PHONY: install test lint format train serve clean  # .PHONY: declara targets que no son archivos.

# InstalaciÃ³n
install:                              # Target por defecto para desarrollo.
	pip install -e ".[all]"           # -e: editable (cambios se reflejan sin reinstalar). [all]: incluye todas las deps.

install-prod:                         # Target para producciÃ³n (sin deps de desarrollo).
	pip install -e ".[api]"           # Solo instala deps de API, no dev/mlflow.

# Testing
test:                                 # Ejecuta tests con coverage.
	pytest --cov=src/ --cov-fail-under=80  # Falla si coverage < 80%.

test-fast:                            # Tests rÃ¡pidos para desarrollo.
	pytest -m "not slow" -x           # -m "not slow": excluye tests lentos. -x: falla al primer error.

# Linting y formato
lint:                                 # Verifica calidad de cÃ³digo.
	ruff check src/ tests/            # Ruff: linter rÃ¡pido.
	mypy src/                         # mypy: verificaciÃ³n de tipos.

format:                               # Auto-formatea cÃ³digo.
	black src/ tests/ app/            # Black: formatter estÃ¡ndar de Python.
	ruff check --fix src/ tests/      # --fix: auto-corrige problemas que puede.

# Entrenamiento
train:                                # Entrena el modelo.
	python main.py --seed 42 train --config configs/config.yaml --input data/raw/Churn.csv

serve:                                # Inicia servidor de desarrollo.
	uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000 --reload  # --reload: reinicia con cambios.

serve-prod:                           # Servidor de producciÃ³n (sin reload).
	uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000

# Docker
docker-build:                         # Construye imagen Docker.
	docker build -t bankchurn:latest .  # -t: tag. .: contexto actual.

docker-run:                           # Ejecuta contenedor.
	docker run -p 8000:8000 bankchurn:latest  # -p host:container: mapea puertos.

# MLflow
mlflow-ui:                            # Inicia UI de MLflow para ver experimentos.
	mlflow ui --host 0.0.0.0 --port 5000

# Limpieza
clean:                                # Elimina archivos generados.
	rm -rf __pycache__ .pytest_cache .mypy_cache .ruff_cache  # Caches de Python/herramientas.
	rm -rf *.egg-info build dist      # Archivos de build.
	rm -rf htmlcov .coverage          # Archivos de coverage.
```

---

<a id="gitignore"></a>

## ğŸš« .gitignore

```gitignore
# Python
__pycache__/
*.py[cod]
*.pyo
.pytest_cache/
.mypy_cache/
*.egg-info/
dist/
build/

# Entornos
.venv/
venv/
env/

# Datos y artefactos (muy grandes para Git)
data/
artifacts/
models/
*.joblib
*.pkl
*.h5

# MLflow
mlruns/

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Coverage
.coverage
htmlcov/

# Env vars
.env
.env.local
```

---

<a id="36-ingenieria-inversa-estructura"></a>

## 3.6 ğŸ”¬ IngenierÃ­a Inversa PedagÃ³gica: Estructura Real del Portafolio

> **Objetivo**: Entender CADA decisiÃ³n detrÃ¡s de la estructura `src/` del portafolio.

### 3.6.1 ğŸ¯ El "Por QuÃ©" ArquitectÃ³nico

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECISIONES ARQUITECTÃ“NICAS DEL PORTAFOLIO                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PROBLEMA 1: Â¿CÃ³mo organizo cÃ³digo importable desde cualquier lugar?            â”‚
â”‚  RIESGO: Sin src/, los imports dependen del directorio actual                   â”‚
â”‚  DECISIÃ“N: src/<paquete>/ con __init__.py que exporta clases pÃºblicas           â”‚
â”‚  RESULTADO: `from bankchurn import ChurnTrainer` funciona siempre               â”‚
â”‚                                                                                 â”‚
â”‚  PROBLEMA 2: Â¿CÃ³mo separo responsabilidades sin crear 50 archivos?              â”‚
â”‚  DECISIÃ“N: Un archivo por dominio: training, prediction, evaluation, config     â”‚
â”‚  RESULTADO: 8 archivos manejables con responsabilidad clara                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.6.2 ğŸ” AnatomÃ­a de `__init__.py`

**Archivo**: `ML-MLOps-Portfolio/BankChurn-Predictor/src/bankchurn/__init__.py`

```python
"""Core BankChurn prediction modules."""
from __future__ import annotations

from .evaluation import ModelEvaluator
from .prediction import ChurnPredictor
from .training import ChurnTrainer

__all__ = ["ChurnPredictor", "ChurnTrainer", "ModelEvaluator"]
# __all__ documenta la API pÃºblica y controla "import *"
```

### 3.6.3 ğŸš¨ Troubleshooting Preventivo

| SÃ­ntoma | Causa | SoluciÃ³n |
|---------|-------|----------|
| **ModuleNotFoundError en tests** | pythonpath no configurado | `pythonpath = ["src"]` en pyproject.toml |
| **Import local OK, CI falla** | pip install -e . faltante | AÃ±adir al workflow de CI |

---

<a id="errores-habituales"></a>

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en la estructura de proyecto

AquÃ­ los problemas ya no son algoritmos, sino **cÃ³mo estÃ¡ organizado el repo**. Son los tÃ­picos errores que hacen que algo â€œfuncione en mi mÃ¡quina pero no en CIâ€ o que el repo se vuelva inmanejable.

Si alguno de estos errores te tomÃ³ **>15 minutos**, regÃ­stralo en el **[Diario de Errores](study_tools/DIARIO_ERRORES.md)** y aplica el flujo de **rescate cognitivo** de **[Protocolo E](study_tools/PROTOCOLO_E.md)**.

### 1) `ModuleNotFoundError` y tests que solo funcionan desde ciertos directorios

**SÃ­ntomas tÃ­picos**

- En local, ejecutar `pytest` desde la raÃ­z funciona, pero en CI falla con:
  ```text
  ModuleNotFoundError: No module named 'miproyecto'
  ```
- Tienes que hacer trucos como `cd src` o modificar `PYTHONPATH` para que los imports funcionen.

**CÃ³mo identificarlo**

- Revisa tu estructura real:
  - Â¿El cÃ³digo estÃ¡ en `src/miproyecto/` o repartido por la raÃ­z?
  - Â¿Los tests importan el paquete (`from miproyecto import ...`) o archivos sueltos (`import training`)?
- Mira tu `pyproject.toml`:
  - `[project.name]` â†’ Â¿coincide con el nombre del paquete (`miproyecto`, `bankchurn`, etc.)?
  - `[tool.setuptools.packages.find] where = ["src"]` â†’ Â¿estÃ¡ configurado?

**CÃ³mo corregirlo**

- Mueve el cÃ³digo a `src/<nombre_paquete>/` siguiendo el Ã¡rbol de este mÃ³dulo.
- AsegÃºrate de que los tests importan siempre el paquete, no rutas relativas.
- Instala en modo editable durante desarrollo/CI:
  ```bash
  pip install -e ".[dev]"
  ```

---

### 2) Datos y modelos dentro de Git (repos gigantes e impracticables)

**SÃ­ntomas tÃ­picos**

- El repo pesa cientos de MB porque hay CSVs y modelos `.pkl`/`.joblib` versionados.
- `git pull` y `git clone` son lentos, y los PRs estÃ¡n llenos de cambios binarios.

**CÃ³mo identificarlo**

- Ejecuta `git status` y revisa si aparecen archivos en `data/`, `artifacts/`, `models/`.
- Abre tu `.gitignore` y comprueba si tienes entradas como:
  - `data/`, `artifacts/`, `models/`, `*.joblib`, `*.pkl`, `mlruns/`.

**CÃ³mo corregirlo**

- AÃ±ade las rutas correctas a `.gitignore` (usa el snippet de este mÃ³dulo como base).
- MantÃ©n en Git **solo**:
  - CÃ³digo (`src/`, `app/`, `tests/`).
  - Config (`configs/`).
  - Infra y docs.
- Para datos/modelos usa DVC o un storage externo (se profundiza en `06_VERSIONADO_DATOS.md`).

---

### 3) Tests que no reflejan el Ã¡rbol de `src/`

**SÃ­ntomas tÃ­picos**

- Cambias algo en `src/miproyecto/features.py` y ningÃºn test falla, aunque has roto lÃ³gica.
- Hay tests sueltos sin relaciÃ³n clara con los mÃ³dulos de producciÃ³n.

**CÃ³mo identificarlo**

- Compara Ã¡rboles:
  - En `src/miproyecto/`: `config.py`, `data.py`, `features.py`, `training.py`, `evaluation.py`, `prediction.py`.
  - En `tests/`: Â¿existen `test_config.py`, `test_data.py`, `test_features.py`, etc.?
- Revisa el `pyproject.toml` o `pytest.ini` para ver quÃ© carpeta se usa como `testpaths`.

**CÃ³mo corregirlo**

- Crea un **espejo sencillo**: por cada mÃ³dulo importante en `src/`, un test correspondiente en `tests/`.
- Usa `conftest.py` para compartir fixtures (datasets pequeÃ±os, config de prueba, etc.).
- Integra `pytest --cov=src/` en tu CI para detectar huecos de cobertura.

---

### 4) Makefile y comandos que no se pueden ejecutar

**SÃ­ntomas tÃ­picos**

- El README dice `make train`, pero:
  - El target `train` no existe.
  - O llama a rutas que no existen (`data/raw/archivo_que_no_existe.csv`).

**CÃ³mo identificarlo**

- Desde la raÃ­z del proyecto, ejecuta:
  ```bash
  make help  # si tienes target de ayuda
  make train
  ```
- Observa los comandos reales que se ejecutan y compÃ¡ralos con:
  - La estructura de carpetas (`data/raw`, `configs/config.yaml`).
  - El CLI real (como `src/bankchurn/cli.py` en BankChurn).

**CÃ³mo corregirlo**

- Ajusta el `Makefile` para que:
  - Use rutas reales (`data/raw/Churn.csv`, etc.).
  - Delegue en el CLI real (`python main.py ...` o `python -m miproyecto.cli ...`).
- MantÃ©n el `Makefile` como **fachada del developer experience**: pocos comandos (`install`, `test`, `train`, `serve`) pero sÃ³lidos.

---

### 5) PatrÃ³n general de debugging de estructura

1. **Revisa el Ã¡rbol de directorios** contra la plantilla de este mÃ³dulo.
2. **Comprueba imports** corriendo un `python -c` que importe tu paquete.
3. **Ejecuta los comandos principales** (`make install`, `make test`, `make train`, `make serve`).
4. **Asegura que datos/artefactos no estÃ¡n en Git** y que `.gitignore` los protege.

Este checklist de estructura es lo primero que un revisor Senior mira cuando abre un repo ML: si esto estÃ¡ bien, todo lo demÃ¡s es mucho mÃ¡s fÃ¡cil de mantener.

---

<a id="consejos-profesionales"></a>

## ğŸ’¼ Consejos Profesionales

> **Recomendaciones para destacar en entrevistas y proyectos reales**

### Para Entrevistas

1. **Explica tu estructura**: Los entrevistadores valoran que puedas justificar cada carpeta y archivo de tu proyecto.

2. **Cookiecutter es tu amigo**: Menciona que usas plantillas estandarizadas para consistencia entre proyectos.

3. **Conoce la diferencia `src/` vs flat**: Explica por quÃ© `src/` layout previene imports accidentales del cÃ³digo local.

### Para Proyectos Reales

| SituaciÃ³n | Consejo |
|-----------|---------|
| Proyecto nuevo | Usa cookiecutter-data-science o similar como base |
| Equipo grande | Documenta convenciones en CONTRIBUTING.md |
| Monorepo vs Multirepo | Monorepo para proyectos relacionados, multirepo para independientes |
| Configs | Nunca hardcodees: usa archivos YAML + variables de entorno |

### Checklist de Proyecto Profesional

- [ ] README.md con badges, instalaciÃ³n, y uso rÃ¡pido
- [ ] pyproject.toml con metadata completa
- [ ] Makefile con comandos estÃ¡ndar (install, test, lint)
- [ ] .pre-commit-config.yaml para calidad automÃ¡tica
- [ ] tests/ con estructura que refleja src/


---

## ğŸ“º Recursos Externos del MÃ³dulo

> ğŸ·ï¸ Sistema: ğŸ”´ Obligatorio | ğŸŸ¡ Recomendado | ğŸŸ¢ Complementario

### ğŸ¬ Videos

| ğŸ·ï¸ | TÃ­tulo | Canal | DuraciÃ³n | Link |
|:--:|:-------|:------|:--------:|:-----|
| ğŸ”´ | **Python Project Structure** | ArjanCodes | 22 min | [YouTube](https://www.youtube.com/watch?v=e8IIYRMnxcE) |
| ğŸŸ¡ | **Packaging Python Projects** | mCoding | 18 min | [YouTube](https://www.youtube.com/watch?v=v6tALyc4C10) |
| ğŸŸ¢ | **Cookiecutter Data Science** | PyData | 35 min | [YouTube](https://www.youtube.com/watch?v=nExL0SgKsDY) |

### ğŸ“„ DocumentaciÃ³n

| ğŸ·ï¸ | Recurso | DescripciÃ³n |
|:--:|:--------|:------------|
| ğŸ”´ | [src Layout vs Flat](https://packaging.python.org/en/latest/discussions/src-layout-vs-flat-layout/) | GuÃ­a oficial de layouts |
| ğŸŸ¡ | [pyproject.toml Spec](https://packaging.python.org/en/latest/specifications/pyproject-toml/) | EspecificaciÃ³n oficial |

---

## âš–ï¸ DecisiÃ³n TÃ©cnica: ADR-014 src/ Layout

**Contexto**: Necesitamos una estructura de proyecto profesional y mantenible.

**DecisiÃ³n**: Usar `src/` layout en todos los proyectos.

**Alternativas Consideradas**:
- **Flat layout**: MÃ¡s simple pero riesgo de imports accidentales
- **Namespace packages**: MÃ¡s complejo, necesario solo para paquetes distribuidos

**Consecuencias**:
- âœ… Evita imports del cÃ³digo local no instalado
- âœ… Tests siempre importan el paquete instalado
- âœ… EstÃ¡ndar profesional reconocido
- âŒ Un nivel de directorio adicional

---

## ğŸ”§ Ejercicios del MÃ³dulo

### Ejercicio 3.1: Crear Estructura de Proyecto
**Objetivo**: Crear estructura profesional desde cero.
**Dificultad**: â­â­

```bash
# TU TAREA: Crear estructura completa para proyecto "mymlproject"
# Debe incluir: src/, tests/, configs/, data/, artifacts/, docs/
```

<details>
<summary>ğŸ’¡ Ver soluciÃ³n</summary>

```bash
# Crear estructura
mkdir -p mymlproject/{src/mymlproject,app,tests,configs,data/{raw,processed},artifacts,scripts,docs}

# Crear archivos Python
touch mymlproject/src/mymlproject/__init__.py
touch mymlproject/src/mymlproject/{config.py,data.py,training.py,prediction.py}
touch mymlproject/app/__init__.py
touch mymlproject/app/fastapi_app.py
touch mymlproject/tests/__init__.py
touch mymlproject/tests/conftest.py

# Crear archivos de proyecto
touch mymlproject/{README.md,pyproject.toml,Makefile,.gitignore}
touch mymlproject/.pre-commit-config.yaml

# Estructura resultante:
# mymlproject/
# â”œâ”€â”€ src/mymlproject/
# â”‚   â”œâ”€â”€ __init__.py
# â”‚   â”œâ”€â”€ config.py
# â”‚   â”œâ”€â”€ data.py
# â”‚   â”œâ”€â”€ training.py
# â”‚   â””â”€â”€ prediction.py
# â”œâ”€â”€ app/fastapi_app.py
# â”œâ”€â”€ tests/conftest.py
# â”œâ”€â”€ configs/
# â”œâ”€â”€ data/{raw,processed}/
# â”œâ”€â”€ artifacts/
# â”œâ”€â”€ scripts/
# â”œâ”€â”€ docs/
# â”œâ”€â”€ pyproject.toml
# â”œâ”€â”€ Makefile
# â””â”€â”€ README.md
```
</details>

---

### Ejercicio 3.2: pyproject.toml Completo
**Objetivo**: Configurar pyproject.toml profesional.
**Dificultad**: â­â­

```toml
# TU TAREA: Completar pyproject.toml para mymlproject
[build-system]
# ???

[project]
name = "mymlproject"
# ???

[project.optional-dependencies]
# ???
```

<details>
<summary>ğŸ’¡ Ver soluciÃ³n</summary>

```toml
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "mymlproject"
version = "0.1.0"
description = "ML project with professional structure"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [{name = "Tu Nombre", email = "tu@email.com"}]

dependencies = [
    "pandas>=2.0",
    "scikit-learn>=1.3",
    "pydantic>=2.0",
    "pyyaml>=6.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "ruff>=0.1",
    "pre-commit>=3.0",
]
api = [
    "fastapi>=0.100",
    "uvicorn>=0.23",
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "UP"]

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-v --cov=mymlproject"
```
</details>

---

<a id="37-refactoring"></a>

## 3.7 ğŸ““ Refactoring: De Notebook a CÃ³digo de ProducciÃ³n

> **Objetivo**: Dominar la transiciÃ³n de cÃ³digo exploratorio en notebooks a mÃ³dulos Python profesionales, mantenibles y testeables.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  "El notebook es donde nacen las ideas.                                      â•‘
â•‘   El mÃ³dulo Python es donde esas ideas se convierten en producto."           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 3.7.1 Â¿Por quÃ© Refactorizar Notebooks?

#### Problemas del CÃ³digo en Notebooks

| Problema | Impacto | SoluciÃ³n |
|----------|---------|----------|
| **Estado global** | Celdas dependen de orden de ejecuciÃ³n | Funciones puras |
| **No testeable** | Bugs ocultos hasta producciÃ³n | MÃ³dulos + pytest |
| **No versionable** | Diffs ilegibles en Git | .py separados |
| **No reutilizable** | Copy-paste entre proyectos | Paquetes Python |
| **Sin tipos** | Errores en runtime | Type hints |

#### CuÃ¡ndo Refactorizar

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CICLO DE VIDA DEL CÃ“DIGO ML                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ğŸ““ NOTEBOOK (ExploraciÃ³n)                                                  â”‚
â”‚  â”œâ”€â”€ EDA rÃ¡pida                                                             â”‚
â”‚  â”œâ”€â”€ Pruebas de hipÃ³tesis                                                   â”‚
â”‚  â”œâ”€â”€ IteraciÃ³n de features                                                  â”‚
â”‚  â””â”€â”€ Prototipos de modelos                                                  â”‚
â”‚       â”‚                                                                     â”‚
â”‚       â–¼ Â¿El cÃ³digo serÃ¡ usado mÃ¡s de una vez?                               â”‚
â”‚       â”‚                                                                     â”‚
â”‚  ğŸ“¦ MÃ“DULO (ProducciÃ³n)                                                    â”‚
â”‚  â”œâ”€â”€ Funciones reutilizables                                                â”‚
â”‚  â”œâ”€â”€ Clases con estado manejado                                             â”‚
â”‚  â”œâ”€â”€ ConfiguraciÃ³n externalizada                                            â”‚
â”‚  â””â”€â”€ Tests automatizados                                                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.7.2 AnatomÃ­a: Notebook vs MÃ³dulo

#### Ejemplo: Celda TÃ­pica de Notebook

```python
# âŒ CÃ³digo tÃ­pico de notebook (difÃ­cil de mantener)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Cargar datos
df = pd.read_csv("data/churn.csv")

# Preprocesar (hardcoded)
df = df.dropna()
df['TenureGroup'] = pd.cut(df['tenure'], bins=[0, 12, 24, 48, 72], labels=['0-1yr', '1-2yr', '2-4yr', '4-6yr'])

# Features y target (hardcoded)
X = df[['CreditScore', 'Age', 'Balance', 'NumOfProducts']]
y = df['Exited']

# Split (seed hardcoded)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar (sin logging)
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluar (print en lugar de return)
print(f"Accuracy: {model.score(X_test, y_test)}")
```

#### Equivalente en MÃ³dulo Profesional

```python
# âœ… src/bankchurn/training.py (cÃ³digo de producciÃ³n)
"""MÃ³dulo de entrenamiento para BankChurn."""

from pathlib import Path                             # Manejo de paths cross-platform.
from typing import Tuple, Dict, Any                  # Type hints.
import logging                                       # Logging estructurado.

import pandas as pd                                  # DataFrames.
import numpy as np                                   # Operaciones numÃ©ricas.
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score

from bankchurn.config import TrainingConfig          # ConfiguraciÃ³n externalizada.


logger = logging.getLogger(__name__)                 # Logger del mÃ³dulo.


def load_data(path: Path) -> pd.DataFrame:
    """
    Carga datos desde archivo CSV.
    
    Args:
        path: Path al archivo CSV.
    
    Returns:
        DataFrame con los datos cargados.
    
    Raises:
        FileNotFoundError: Si el archivo no existe.
        pd.errors.EmptyDataError: Si el archivo estÃ¡ vacÃ­o.
    """
    logger.info(f"Loading data from {path}")
    
    if not path.exists():
        raise FileNotFoundError(f"Data file not found: {path}")
    
    df = pd.read_csv(path)
    logger.info(f"Loaded {len(df)} rows, {len(df.columns)} columns")
    
    return df


def preprocess(
    df: pd.DataFrame,
    config: TrainingConfig,
) -> pd.DataFrame:
    """
    Preprocesa datos segÃºn configuraciÃ³n.
    
    Args:
        df: DataFrame con datos crudos.
        config: ConfiguraciÃ³n de preprocesamiento.
    
    Returns:
        DataFrame preprocesado.
    """
    logger.info("Preprocessing data")
    
    # Eliminar NaN segÃºn estrategia en config.
    if config.drop_na:
        initial_rows = len(df)
        df = df.dropna()
        logger.info(f"Dropped {initial_rows - len(df)} rows with NaN")
    
    # Feature engineering configurable.
    if config.create_tenure_groups:
        df = df.copy()                               # Evitar SettingWithCopyWarning.
        df['TenureGroup'] = pd.cut(
            df['tenure'],
            bins=config.tenure_bins,
            labels=config.tenure_labels,
        )
    
    return df


def split_data(
    df: pd.DataFrame,
    config: TrainingConfig,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    Divide datos en train/test.
    
    Args:
        df: DataFrame preprocesado.
        config: ConfiguraciÃ³n con features, target y split ratio.
    
    Returns:
        Tuple de (X_train, X_test, y_train, y_test).
    """
    X = df[config.feature_columns]
    y = df[config.target_column]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=config.test_size,
        random_state=config.seed,
        stratify=y if config.stratify else None,     # EstratificaciÃ³n opcional.
    )
    
    logger.info(f"Train: {len(X_train)}, Test: {len(X_test)}")
    
    return X_train, X_test, y_train, y_test


def train_model(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    config: TrainingConfig,
) -> RandomForestClassifier:
    """
    Entrena modelo con configuraciÃ³n especificada.
    
    Args:
        X_train: Features de entrenamiento.
        y_train: Target de entrenamiento.
        config: ConfiguraciÃ³n de hiperparÃ¡metros.
    
    Returns:
        Modelo entrenado.
    """
    logger.info(f"Training RandomForest with {config.n_estimators} estimators")
    
    model = RandomForestClassifier(
        n_estimators=config.n_estimators,
        max_depth=config.max_depth,
        random_state=config.seed,
        n_jobs=-1,                                   # Usar todos los cores.
    )
    
    model.fit(X_train, y_train)
    logger.info("Training completed")
    
    return model


def evaluate_model(
    model: RandomForestClassifier,
    X_test: pd.DataFrame,
    y_test: pd.Series,
) -> Dict[str, float]:
    """
    EvalÃºa modelo y retorna mÃ©tricas.
    
    Args:
        model: Modelo entrenado.
        X_test: Features de test.
        y_test: Target de test.
    
    Returns:
        Dict con mÃ©tricas de evaluaciÃ³n.
    """
    y_pred = model.predict(X_test)
    
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "f1_score": f1_score(y_test, y_pred),
    }
    
    logger.info(f"Evaluation metrics: {metrics}")
    
    return metrics


def run_training_pipeline(config: TrainingConfig) -> Dict[str, Any]:
    """
    Ejecuta pipeline completo de entrenamiento.
    
    Esta es la funciÃ³n principal que orquesta todo el proceso.
    
    Args:
        config: ConfiguraciÃ³n completa del entrenamiento.
    
    Returns:
        Dict con modelo y mÃ©tricas.
    """
    # 1. Cargar datos.
    df = load_data(config.data_path)
    
    # 2. Preprocesar.
    df = preprocess(df, config)
    
    # 3. Split.
    X_train, X_test, y_train, y_test = split_data(df, config)
    
    # 4. Entrenar.
    model = train_model(X_train, y_train, config)
    
    # 5. Evaluar.
    metrics = evaluate_model(model, X_test, y_test)
    
    return {
        "model": model,
        "metrics": metrics,
        "config": config,
    }
```

### 3.7.3 Proceso de Refactoring Paso a Paso

#### Checklist de Refactoring

```python
# refactoring_checklist.py
"""Checklist automatizado para refactoring de notebooks."""

from dataclasses import dataclass
from typing import List


@dataclass
class RefactoringStep:
    """Paso de refactoring."""
    name: str
    description: str
    completed: bool = False


def get_refactoring_checklist() -> List[RefactoringStep]:
    """Retorna checklist de refactoring."""
    return [
        RefactoringStep(
            "identify_functions",
            "Identificar bloques de cÃ³digo que hacen UNA cosa"
        ),
        RefactoringStep(
            "extract_config",
            "Extraer valores hardcoded a configuraciÃ³n"
        ),
        RefactoringStep(
            "add_type_hints",
            "AÃ±adir type hints a todas las funciones"
        ),
        RefactoringStep(
            "add_docstrings",
            "Documentar cada funciÃ³n con docstring"
        ),
        RefactoringStep(
            "add_logging",
            "Reemplazar print() con logging"
        ),
        RefactoringStep(
            "add_error_handling",
            "AÃ±adir manejo de errores apropiado"
        ),
        RefactoringStep(
            "remove_global_state",
            "Eliminar variables globales"
        ),
        RefactoringStep(
            "create_tests",
            "Crear tests unitarios para cada funciÃ³n"
        ),
    ]
```

#### Mapeo: Celdas de Notebook â†’ MÃ³dulos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MAPEO: CELDAS DE NOTEBOOK â†’ MÃ“DULOS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Celda de imports           â†’  (se distribuyen en cada mÃ³dulo)              â”‚
â”‚  Celda de carga de datos    â†’  data.py::load_data()                         â”‚
â”‚  Celda de limpieza          â†’  data.py::clean_data()                        â”‚
â”‚  Celda de feature eng.      â†’  features.py::create_features()               â”‚
â”‚  Celda de split             â†’  training.py::split_data()                    â”‚
â”‚  Celda de entrenamiento     â†’  training.py::train_model()                   â”‚
â”‚  Celda de evaluaciÃ³n        â†’  evaluation.py::evaluate_model()              â”‚
â”‚  Celda de predicciÃ³n        â†’  prediction.py::predict()                     â”‚
â”‚  Celda de visualizaciÃ³n     â†’  (queda en notebook o dashboards)             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.7.4 Patrones Comunes de ExtracciÃ³n

#### ConfiguraciÃ³n Externalizada

```python
# src/bankchurn/config.py
"""ConfiguraciÃ³n centralizada del proyecto."""

from pathlib import Path
from typing import List, Optional
from pydantic import BaseModel, Field              # ValidaciÃ³n automÃ¡tica.
import yaml                                        # Lectura de archivos YAML.


class TrainingConfig(BaseModel):
    """ConfiguraciÃ³n de entrenamiento."""
    
    # Paths.
    data_path: Path = Field(..., description="Path al archivo de datos")
    model_output_path: Path = Field(default=Path("artifacts/model.joblib"))
    
    # Preprocesamiento.
    drop_na: bool = Field(default=True)
    create_tenure_groups: bool = Field(default=True)
    tenure_bins: List[int] = Field(default=[0, 12, 24, 48, 72])
    tenure_labels: List[str] = Field(default=['0-1yr', '1-2yr', '2-4yr', '4-6yr'])
    
    # Features.
    feature_columns: List[str] = Field(
        default=['CreditScore', 'Age', 'Balance', 'NumOfProducts']
    )
    target_column: str = Field(default='Exited')
    
    # Split.
    test_size: float = Field(default=0.2, ge=0.0, le=1.0)
    stratify: bool = Field(default=True)
    
    # Modelo.
    n_estimators: int = Field(default=100, ge=1)
    max_depth: Optional[int] = Field(default=None)
    
    # Reproducibilidad.
    seed: int = Field(default=42)
    
    class Config:
        extra = "forbid"  # Error si hay campos desconocidos.


def load_config(path: Path) -> TrainingConfig:
    """Carga configuraciÃ³n desde YAML."""
    with open(path) as f:
        data = yaml.safe_load(f)
    return TrainingConfig(**data)
```

```yaml
# configs/config.yaml
# ConfiguraciÃ³n de entrenamiento.

data_path: "data/raw/Churn.csv"
model_output_path: "artifacts/model.joblib"

# Preprocesamiento.
drop_na: true
create_tenure_groups: true

# Features.
feature_columns:
  - CreditScore
  - Age
  - Balance
  - NumOfProducts
  - IsActiveMember

target_column: Exited

# Split.
test_size: 0.2
stratify: true

# Modelo.
n_estimators: 200
max_depth: 10

# Reproducibilidad.
seed: 42
```

#### De Print a Logging

```python
# âŒ Antes (notebook)
print(f"Loaded {len(df)} rows")
print(f"Training with {n_estimators} trees")
print(f"Accuracy: {accuracy}")

# âœ… DespuÃ©s (mÃ³dulo)
import logging

logger = logging.getLogger(__name__)

logger.info(f"Loaded {len(df)} rows")
logger.info(f"Training with {n_estimators} trees")
logger.info(f"Accuracy: {accuracy:.4f}")

# ConfiguraciÃ³n de logging (en __init__.py o main.py)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("training.log"),
    ]
)
```

#### De Variables Globales a ParÃ¡metros

```python
# âŒ Antes (variables globales)
SEED = 42
N_ESTIMATORS = 100
df = None  # Estado global mutable

def train():
    global df  # Dependencia oculta
    model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=SEED)
    model.fit(df[features], df[target])
    return model

# âœ… DespuÃ©s (parÃ¡metros explÃ­citos)
def train(
    X: pd.DataFrame,
    y: pd.Series,
    n_estimators: int = 100,
    seed: int = 42,
) -> RandomForestClassifier:
    """Todas las dependencias son explÃ­citas."""
    model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)
    model.fit(X, y)
    return model
```

---

<a id="38-common-utils"></a>

## 3.8 ğŸ“¦ LibrerÃ­as Compartidas (common_utils)

> **Objetivo**: Aprender a crear y mantener librerÃ­as de utilidades compartidas entre proyectos ML, siguiendo el patrÃ³n `common_utils/` del Portfolio.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  "DRY (Don't Repeat Yourself) no es solo para cÃ³digo dentro de un proyecto:  â•‘
â•‘   aplica a toda tu organizaciÃ³n. common_utils es DRY a nivel de equipo."     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 3.8.1 Â¿Por quÃ© LibrerÃ­as Compartidas?

#### Problemas que Resuelve

| Problema | Sin common_utils | Con common_utils |
|----------|------------------|------------------|
| **Logging** | Cada proyecto configura diferente | Formato consistente |
| **Seeds** | Olvidar setear todas las librerÃ­as | Una funciÃ³n para todo |
| **Config** | DuplicaciÃ³n de cÃ³digo | ValidaciÃ³n centralizada |
| **Utils** | Copy-paste entre repos | Import compartido |

#### AnÃ¡lisis del Portfolio

```
ML-MLOps-Portfolio/
â”œâ”€â”€ common_utils/              # â† LibrerÃ­a compartida
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py              # Logging consistente
â”‚   â””â”€â”€ seed.py                # Reproducibilidad
â”‚
â”œâ”€â”€ BankChurn-Predictor/
â”‚   â””â”€â”€ src/bankchurn/
â”‚       â””â”€â”€ training.py        # from common_utils import ...
â”‚
â”œâ”€â”€ CarVision-Market-Intelligence/
â”‚   â””â”€â”€ src/carvision/
â”‚       â””â”€â”€ training.py        # from common_utils import ...
â”‚
â””â”€â”€ TelecomAI-Customer-Intelligence/
    â””â”€â”€ src/telecom/
        â””â”€â”€ training.py        # from common_utils import ...
```

### 3.8.2 Estructura de common_utils

#### OrganizaciÃ³n Recomendada

```
common_utils/
â”œâ”€â”€ __init__.py           # Exports pÃºblicos
â”œâ”€â”€ logger.py             # ConfiguraciÃ³n de logging
â”œâ”€â”€ seed.py               # Reproducibilidad
â”œâ”€â”€ config.py             # Utilidades de configuraciÃ³n (opcional)
â”œâ”€â”€ metrics.py            # MÃ©tricas compartidas (opcional)
â”œâ”€â”€ validators.py         # Validadores comunes (opcional)
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_logger.py
    â””â”€â”€ test_seed.py
```

#### __init__.py: API PÃºblica

```python
# common_utils/__init__.py
"""
Utilidades compartidas para proyectos ML.

Este mÃ³dulo proporciona funcionalidades comunes que se usan
en mÃºltiples proyectos del portfolio:
- ConfiguraciÃ³n de logging consistente.
- Reproducibilidad con seeds.
"""

from common_utils.logger import setup_logging
from common_utils.seed import set_seed, DEFAULT_SEED

__version__ = "1.0.0"

__all__ = [
    "setup_logging",
    "set_seed",
    "DEFAULT_SEED",
]
```

### 3.8.3 MÃ³dulo de Logging

```python
# common_utils/logger.py
"""
ConfiguraciÃ³n centralizada de logging para todos los proyectos.

Este mÃ³dulo proporciona una funciÃ³n para configurar logging de manera
consistente, evitando que cada proyecto implemente su propia versiÃ³n.
"""

import logging                                       # LibrerÃ­a estÃ¡ndar de logging.
import sys                                           # Para stdout.
from typing import Optional                          # Type hints.


def setup_logging(
    name: str,                                       # Nombre del logger (usualmente __name__).
    level: int = logging.INFO,                       # Nivel mÃ­nimo de logging.
    log_format: Optional[str] = None,                # Formato personalizado (opcional).
) -> logging.Logger:
    """
    Configura logging consistente para todos los proyectos.
    
    Esta funciÃ³n centraliza la configuraciÃ³n de logging para evitar
    duplicaciÃ³n y garantizar formato consistente en logs.
    
    Args:
        name: Nombre del logger. Usar __name__ del mÃ³dulo que llama.
        level: Nivel de logging (DEBUG, INFO, WARNING, ERROR, CRITICAL).
        log_format: Formato personalizado. Si None, usa formato estÃ¡ndar.
    
    Returns:
        Logger configurado y listo para usar.
    
    Example:
        >>> from common_utils import setup_logging
        >>> logger = setup_logging(__name__)
        >>> logger.info("Training started")
        2024-01-15 10:30:00 - mymodule - INFO - Training started
    """
    # Formato por defecto: timestamp - mÃ³dulo - nivel - mensaje.
    if log_format is None:
        log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    # Crear handler para stdout.
    handler = logging.StreamHandler(sys.stdout)      # Output a stdout (no stderr).
    formatter = logging.Formatter(log_format)        # Aplicar formato.
    handler.setFormatter(formatter)
    
    # Obtener o crear logger.
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    # Prevenir handlers duplicados si se llama mÃºltiples veces.
    # Esto es importante en notebooks donde se puede re-ejecutar celdas.
    if not logger.handlers:
        logger.addHandler(handler)
    
    return logger
```

### 3.8.4 MÃ³dulo de Reproducibilidad (Seed)

```python
# common_utils/seed.py
"""
Helper centralizado para reproducibilidad en experimentos ML.

Este mÃ³dulo configura seeds para todas las librerÃ­as relevantes
(Python, NumPy, PyTorch, TensorFlow) en una sola llamada.
"""

from __future__ import annotations                   # Para type hints modernos.

import os                                            # Variables de entorno.
import random                                        # Random de Python.
from typing import Final                             # Constantes tipadas.

import numpy as np                                   # NumPy.


# Seed por defecto si no se especifica.
DEFAULT_SEED: Final[int] = 42


def set_seed(seed: int | None = None) -> int:
    """
    Configura seeds globales para reproducibilidad.
    
    Esta funciÃ³n setea el seed para:
    - Python's random module
    - NumPy
    - PyTorch (si estÃ¡ instalado)
    - TensorFlow (si estÃ¡ instalado)
    
    Orden de resoluciÃ³n del seed:
    1. Argumento `seed` si se proporciona.
    2. Variable de entorno `SEED` si estÃ¡ definida.
    3. DEFAULT_SEED (42) como fallback.
    
    Args:
        seed: Seed a usar. Si None, se resuelve segÃºn orden descrito.
    
    Returns:
        El seed que fue efectivamente usado.
    
    Example:
        >>> from common_utils import set_seed
        >>> set_seed(42)
        42
        >>> # Ahora todos los experimentos serÃ¡n reproducibles
    
    Note:
        Para reproducibilidad completa en GPU, tambiÃ©n necesitas:
        - torch.backends.cudnn.deterministic = True
        - torch.backends.cudnn.benchmark = False
        Esto se hace automÃ¡ticamente en esta funciÃ³n.
    """
    # Resolver seed segÃºn orden de prioridad.
    if seed is None:
        env_seed = os.getenv("SEED")                 # Buscar en variable de entorno.
        seed = int(env_seed) if env_seed is not None else DEFAULT_SEED
    
    # ========== Core Python / NumPy ==========
    os.environ["PYTHONHASHSEED"] = str(seed)         # Hash determinÃ­stico.
    random.seed(seed)                                # Random de Python.
    np.random.seed(seed)                             # NumPy.
    
    # ========== PyTorch (opcional) ==========
    try:
        import torch
        
        torch.manual_seed(seed)                      # CPU seed.
        
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)         # GPU seed (todas las GPUs).
        
        # Hacer operaciones CUDA determinÃ­sticas.
        if hasattr(torch.backends, "cudnn"):
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False   # Desactivar autotuning.
    
    except ImportError:
        pass  # PyTorch no instalado, skip.
    except Exception:
        pass  # Otros errores (ej: CUDA no disponible).
    
    # ========== TensorFlow (opcional) ==========
    try:
        import tensorflow as tf
        
        tf.random.set_seed(seed)
    
    except ImportError:
        pass  # TensorFlow no instalado, skip.
    except Exception:
        pass
    
    return seed
```

### 3.8.5 Patrones de Uso

#### ImportaciÃ³n desde Proyecto

```python
# OpciÃ³n 1: Import directo (si common_utils estÃ¡ en PYTHONPATH)
from common_utils import setup_logging, set_seed

# OpciÃ³n 2: Import relativo (si es submÃ³dulo)
from ..common_utils import setup_logging, set_seed

# OpciÃ³n 3: AÃ±adir al path en runtime
import sys
sys.path.insert(0, "/path/to/ML-MLOps-Portfolio")
from common_utils import setup_logging, set_seed
```

#### ConfiguraciÃ³n en pyproject.toml

```toml
# pyproject.toml del proyecto que usa common_utils

[project]
name = "bankchurn"
dependencies = [
    # ... otras deps ...
]

[project.optional-dependencies]
dev = [
    # ... deps de desarrollo ...
]

# Si common_utils es un paquete local
[tool.setuptools.package-dir]
"" = "src"
"common_utils" = "../common_utils"
```

#### PatrÃ³n de InicializaciÃ³n

```python
# src/bankchurn/__init__.py
"""
BankChurn Predictor.

Este mÃ³dulo inicializa logging y seed al importar.
"""

from common_utils import setup_logging, set_seed

# Configurar logging al importar el paquete.
_logger = setup_logging("bankchurn")

# Exportar para uso en submÃ³dulos.
__all__ = ["setup_logging", "set_seed"]
```

### 3.8.6 Versionado y DistribuciÃ³n

#### Estructura para PublicaciÃ³n

```
common_utils/
â”œâ”€â”€ pyproject.toml        # Metadata del paquete
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ src/
â”‚   â””â”€â”€ common_utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ seed.py
â””â”€â”€ tests/
    â””â”€â”€ ...
```

#### pyproject.toml para DistribuciÃ³n

```toml
# common_utils/pyproject.toml

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "mlops-common-utils"
version = "1.0.0"
description = "Shared utilities for MLOps projects"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    "numpy>=1.24.0",
]

[project.optional-dependencies]
torch = ["torch>=2.0.0"]
tensorflow = ["tensorflow>=2.13.0"]
all = ["mlops-common-utils[torch,tensorflow]"]

[tool.setuptools.packages.find]
where = ["src"]
```

#### InstalaciÃ³n en Proyectos

```bash
# Desde Git (privado)
pip install git+https://github.com/tu-org/common-utils.git

# Desde path local (desarrollo)
pip install -e /path/to/common_utils

# Desde PyPI (si publicas)
pip install mlops-common-utils
```

---

<a id="39-pedagogia"></a>

## 3.9 ğŸ“ SecciÃ³n PedagÃ³gica: Aprende Haciendo

> **Formato**: Constructivismo aplicado a MLOps  
> **Nivel**: Python bÃ¡sico â†’ Ingeniero MLOps Junior  
> **Tiempo estimado**: 2-3 horas

### 3.9.1 ğŸ“ ExplicaciÃ³n TeÃ³rica con AnalogÃ­as

#### La Estructura de Proyecto como los Planos de una Casa

Imagina que vas a construir una casa. **No empiezas poniendo ladrillos al azar** â€” primero necesitas:

```
ğŸ  CONSTRUCCIÃ“N DE CASA          ğŸ“¦ PROYECTO ML
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Planos arquitectÃ³nicos     â†’     pyproject.toml (metadata)
Cimientos                  â†’     src/ layout (base del cÃ³digo)
Sistema elÃ©ctrico          â†’     configs/ (configuraciÃ³n)
Sistema de plomerÃ­a        â†’     data/ pipelines (flujo de datos)
Cuartos separados          â†’     MÃ³dulos: training.py, prediction.py
InspecciÃ³n de calidad      â†’     tests/ (verificaciÃ³n)
Manual de la casa          â†’     README.md, docs/
```

**Â¿Por quÃ© importa en la industria?**

| Sin estructura profesional | Con estructura profesional |
|---------------------------|---------------------------|
| "Funciona en mi mÃ¡quina" ğŸ¤· | Funciona en cualquier mÃ¡quina âœ… |
| Onboarding de 2 semanas | Onboarding de 2 dÃ­as |
| Bugs difÃ­ciles de rastrear | Bugs localizados rÃ¡pidamente |
| Imposible de escalar | Listo para equipo de 10+ personas |

> ï¿½ **Insight de industria**: Los equipos de ML pierden ~40% del tiempo en "plumbing" (configuraciÃ³n, imports rotos, dependencias). Una buena estructura reduce esto a <10%.

### 3.9.2 ğŸ§  Mapa Mental de Conceptos

Antes de tocar cÃ³digo, domina estos tÃ©rminos:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ ESTRUCTURA ML   â”‚
                    â”‚   PROFESIONAL   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚ CÃ“DIGO  â”‚         â”‚  CONFIG   â”‚        â”‚  CALIDAD  â”‚
   â”‚  FUENTE â”‚         â”‚   & DATA  â”‚        â”‚           â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
   â”‚ src/    â”‚         â”‚ configs/  â”‚        â”‚ tests/    â”‚
   â”‚ layout  â”‚         â”‚ data/     â”‚        â”‚ Makefile  â”‚
   â”‚ __init__â”‚         â”‚ artifacts/â”‚        â”‚ pre-commitâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Conceptos clave para memorizar:**

| Concepto | DefiniciÃ³n de 1 lÃ­nea |
|----------|----------------------|
| **src/ layout** | CÃ³digo en `src/paquete/` para imports limpios |
| **pyproject.toml** | UN archivo para toda la config del proyecto |
| **editable install** | `pip install -e .` = cambios sin reinstalar |
| **Makefile** | Comandos comunes en un solo lugar |
| **.gitignore** | Archivos que Git debe ignorar (datos, modelos) |
| **conftest.py** | Fixtures compartidas para tests |

### 3.9.3 ğŸ’» Ejercicio Puente (Scaffolding)

> **Objetivo**: Practicar la estructura ANTES de replicar el portafolio completo.

#### Mini-Proyecto: Calculadora ML

Crea un proyecto mÃ­nimo con estructura profesional que haga una operaciÃ³n simple.

```bash
# PASO 1: Crear estructura
mkdir -p calculadora-ml/src/calculadora
mkdir -p calculadora-ml/tests
mkdir -p calculadora-ml/configs

# PASO 2: Crear archivos base
touch calculadora-ml/src/calculadora/__init__.py
touch calculadora-ml/src/calculadora/operations.py
touch calculadora-ml/tests/__init__.py
touch calculadora-ml/tests/test_operations.py
touch calculadora-ml/pyproject.toml
touch calculadora-ml/Makefile
```

**Tu tarea**: Completa estos archivos:

```python
# src/calculadora/operations.py
"""Operaciones matemÃ¡ticas simples."""

def add(a: float, b: float) -> float:
    """Suma dos nÃºmeros."""
    # TODO: Implementar
    pass

def multiply(a: float, b: float) -> float:
    """Multiplica dos nÃºmeros."""
    # TODO: Implementar
    pass
```

```python
# tests/test_operations.py
"""Tests para operaciones."""
import pytest
from calculadora.operations import add, multiply

def test_add_positive_numbers():
    """Test suma de positivos."""
    # TODO: Implementar - debe pasar
    pass

def test_multiply_by_zero():
    """Test multiplicar por cero."""
    # TODO: Implementar - debe retornar 0
    pass
```

```toml
# pyproject.toml
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "calculadora"
version = "0.1.0"
# TODO: Completar dependencies y tool configs
```

**Criterio de Ã©xito**: 
```bash
pip install -e .
pytest  # Debe pasar
```

### 3.9.4 ğŸ› ï¸ PrÃ¡ctica del Portafolio (Instrucciones de RÃ©plica)

> **Objetivo**: Replicar la estructura de `BankChurn-Predictor` desde cero.

#### Tarea: Crear estructura para tu proyecto

**NO copies el cÃ³digo** â€” crÃ©alo paso a paso siguiendo estas pistas:

##### Paso 1: Estructura de directorios

```bash
# Pista: Usa el Ã¡rbol de la secciÃ³n 3.1 como referencia
# Crea TODOS los directorios y archivos vacÃ­os primero
mkdir -p mi-proyecto-ml/{src/miproyecto,tests,configs,data/raw,artifacts,docs}
```

##### Paso 2: pyproject.toml

```toml
# Pista: Responde estas preguntas para completarlo
# 1. Â¿CuÃ¡l es el nombre de tu paquete?
# 2. Â¿QuÃ© librerÃ­as necesitas? (pandas, sklearn, pydantic...)
# 3. Â¿DÃ³nde estÃ¡ el cÃ³digo fuente? (src/)

[project]
name = "???"
version = "0.1.0"
dependencies = [
    # ??? - lista tus deps
]

[tool.setuptools.packages.find]
where = ["???"]
```

##### Paso 3: __init__.py con exports

```python
# src/miproyecto/__init__.py
# Pista: Â¿QuÃ© clases/funciones quieres que sean pÃºblicas?
# Mira el __init__.py de bankchurn como referencia

from .??? import ???
__all__ = ["???"]
```

##### Paso 4: Makefile mÃ­nimo

```makefile
# Pista: Â¿CuÃ¡les son los 4 comandos que mÃ¡s usarÃ¡s?
# install, test, lint, ???

.PHONY: install test

install:
	# ??? - comando para instalar en modo editable

test:
	# ??? - comando para correr tests con coverage
```

##### Paso 5: VerificaciÃ³n

```bash
# Tu proyecto debe pasar estas verificaciones:
pip install -e ".[dev]"     # Â¿Instala sin errores?
python -c "import miproyecto"  # Â¿Importa correctamente?
pytest                       # Â¿Tests pasan?
make test                    # Â¿Makefile funciona?
```

### 3.9.5 âœ… Checkpoint de Conocimiento

#### Preguntas TeÃ³ricas (OpciÃ³n MÃºltiple)

**1. Â¿Por quÃ© usamos `src/` layout en lugar de poner cÃ³digo en la raÃ­z?**

- A) Es mÃ¡s rÃ¡pido de ejecutar
- B) Evita que Python importe accidentalmente cÃ³digo local no instalado
- C) GitHub lo requiere
- D) Es solo preferencia estÃ©tica

<details>
<summary>Ver respuesta</summary>

**Respuesta: B**

Con `src/` layout, Python SIEMPRE importa el paquete instalado, no el cÃ³digo local. Esto previene el clÃ¡sico "funciona en mi mÃ¡quina pero no en CI".

</details>

---

**2. Â¿CuÃ¡l es el propÃ³sito de `pip install -e .`?**

- A) Instalar en modo "enterprise"
- B) Instalar una versiÃ³n especÃ­fica
- C) Instalar en modo editable (cambios se reflejan sin reinstalar)
- D) Instalar con dependencias extra

<details>
<summary>Ver respuesta</summary>

**Respuesta: C**

El flag `-e` (editable) crea un symlink al cÃ³digo fuente. Cuando modificas tu cÃ³digo, no necesitas reinstalar â€” los cambios se reflejan inmediatamente.

</details>

---

**3. Â¿QuÃ© archivos NUNCA deben estar en Git para un proyecto ML?**

- A) `pyproject.toml` y `Makefile`
- B) `README.md` y `docs/`
- C) `data/`, `artifacts/`, `*.joblib`, `mlruns/`
- D) `tests/` y `configs/`

<details>
<summary>Ver respuesta</summary>

**Respuesta: C**

Datos, modelos entrenados y artifacts de MLflow son demasiado grandes y cambian frecuentemente. Deben estar en `.gitignore` y manejarse con DVC o storage externo.

</details>

---

#### Escenario de Debugging

**SituaciÃ³n**: Tu colega te pide ayuda. Su proyecto tiene esta estructura:

```
mi-proyecto/
â”œâ”€â”€ training.py
â”œâ”€â”€ prediction.py
â”œâ”€â”€ config.py
â”œâ”€â”€ test_training.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ data/churn.csv
```

Reporta estos problemas:
1. `pytest` falla con `ModuleNotFoundError: No module named 'training'`
2. El repo de Git pesa 500MB
3. En CI, los tests fallan aunque en local funcionan

**Tu diagnÃ³stico**: Â¿CuÃ¡les son las 3 causas raÃ­z y cÃ³mo las solucionarÃ­as?

<details>
<summary>Ver diagnÃ³stico completo</summary>

**Causa 1**: No hay estructura `src/` ni `pyproject.toml`
- **SÃ­ntoma**: `ModuleNotFoundError`
- **SoluciÃ³n**: Mover cÃ³digo a `src/miproyecto/`, crear `pyproject.toml`, usar `pip install -e .`

**Causa 2**: `data/` no estÃ¡ en `.gitignore`
- **SÃ­ntoma**: Repo de 500MB
- **SoluciÃ³n**: AÃ±adir `data/` a `.gitignore`, usar DVC para datos, `git rm --cached data/`

**Causa 3**: Sin instalaciÃ³n editable en CI
- **SÃ­ntoma**: Tests fallan solo en CI
- **SoluciÃ³n**: AÃ±adir `pip install -e .` al workflow de CI antes de `pytest`

**Estructura corregida**:
```
mi-proyecto/
â”œâ”€â”€ src/miproyecto/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ training.py
â”‚   â”œâ”€â”€ prediction.py
â”‚   â””â”€â”€ config.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_training.py
â”œâ”€â”€ data/           # En .gitignore
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile
â””â”€â”€ .gitignore
```

</details>

---

## ï¿½ï¿½ Glosario del MÃ³dulo

| TÃ©rmino | DefiniciÃ³n |
|---------|------------|
| **src/ Layout** | Estructura donde cÃ³digo estÃ¡ en `src/nombre_paquete/` |
| **pyproject.toml** | Archivo unificado de configuraciÃ³n de proyecto Python |
| **Makefile** | Archivo para automatizar comandos comunes del proyecto |
| **editable install** | `pip install -e .` instala paquete en modo desarrollo |
| **Refactoring** | Proceso de reestructurar cÃ³digo sin cambiar funcionalidad |
| **common_utils** | LibrerÃ­a interna compartida entre proyectos |
| **Scaffolding** | Ejercicio puente que prepara para tareas complejas |
| **Constructivismo** | Aprender haciendo, no solo leyendo |

---

<div align="center">

**Siguiente mÃ³dulo** â†’ [04. Entornos](04_ENTORNOS.md)

---

[â† Volver al Ãndice](00_INDICE.md)

</div>
