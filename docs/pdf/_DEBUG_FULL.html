
    <!DOCTYPE html>
    <html>
    <head><meta charset="UTF-8"></head>
    <body>
        
            <div class="cover-page global-cover">
                <div class="cover-content" style="border-color:rgba(96,165,250,0.3);background:rgba(15,23,42,0.6);">
                    <div style="font-size:60pt;margin-bottom:30px;">ğŸš€</div>
                    <div class="global-title">GUÃA MLOPS</div>
                    <div class="cover-subtitle" style="color:#94a3b8;margin-bottom:40px;">De Cero a Senior / Staff</div>
                    <div class="cover-badge" style="background:linear-gradient(90deg,#3b82f6,#8b5cf6);border:none;padding:10px 30px;">VERSION 5.0 â€” PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:11pt;color:#64748b;">DUQUEOM | 2025</div>
            </div>
        
        
            <!-- MÃ“DULO: 00_INDICE.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_00_INDICE" class="cover-title">ÃNDICE</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“š GuÃ­a MLOps â€” Portfolio Edition</h1>
<blockquote>
<p><strong>De Python BÃ¡sico a Senior/Staff en MLOps</strong></p>
<p>Programa completo de 8 semanas para construir el portafolio ML-MLOps-Portfolio desde cero.</p>
</blockquote>
<h2>ğŸ¯ Â¿QuÃ© LograrÃ¡s?</h2>
<p>Al completar esta guÃ­a serÃ¡s capaz de:</p>
<table>
<thead>
<tr>
<th>Habilidad</th>
<th>Nivel</th>
<th>Evidencia en el Portafolio</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CÃ³digo Python profesional</strong></td>
<td>Senior</td>
<td>Type hints, Pydantic, SOLID en los 3 proyectos</td>
</tr>
<tr>
<td><strong>Pipelines ML reproducibles</strong></td>
<td>Senior</td>
<td>sklearn Pipeline unificado, sin data leakage</td>
</tr>
<tr>
<td><strong>Testing &amp; CI/CD</strong></td>
<td>Senior</td>
<td>80%+ coverage, GitHub Actions, matrix testing</td>
</tr>
<tr>
<td><strong>APIs de producciÃ³n</strong></td>
<td>Senior</td>
<td>FastAPI con validaciÃ³n, Docker multi-stage</td>
</tr>
<tr>
<td><strong>Observabilidad</strong></td>
<td>Staff</td>
<td>Prometheus, logging estructurado, drift detection</td>
</tr>
<tr>
<td><strong>Pasar entrevistas tÃ©cnicas</strong></td>
<td>Staff</td>
<td>Simulacros completos, speech de 5-7 min</td>
</tr>
</tbody>
</table>
<h2>ğŸ§­ CÃ³mo Usar Esta GuÃ­a</h2>
<h3>Perfil de Entrada</h3>
<ul>
<li>Python bÃ¡sico (funciones, clases, mÃ³dulos)</li>
<li>Git elemental (clone, commit, push)</li>
<li>Comodidad con la terminal</li>
</ul>
<h3>MÃ©todo de Estudio</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CICLO DE APRENDIZAJE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                            â”‚
â”‚   1. LEER          2. REPLICAR         3. PRACTICAR      4. VALIDAR        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚
â”‚   El mÃ³dulo        En uno de los       Ejercicios de     Comparar con      â”‚
â”‚   teÃ³rico          3 proyectos         EJERCICIOS.md     el portafolio     â”‚
â”‚                                                                            â”‚
â”‚   ğŸ’¡ Cada mÃ³dulo tiene secciÃ³n &quot;ğŸ“¦ CÃ³mo se usÃ³ en el Portafolio&quot; que       â”‚
â”‚      referencia cÃ³digo real de BankChurn, CarVision o TelecomAI.           â”‚
â”‚                                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Rutas de Aprendizaje</h3>
<table>
<thead>
<tr>
<th>Si eres...</th>
<th>Ruta recomendada</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Principiante</strong></td>
<td>Seguir mÃ³dulos 01-23 en orden, 8 semanas</td>
</tr>
<tr>
<td><strong>DS con experiencia</strong></td>
<td>Saltar a Fase 2 (mÃ³dulo 07), revisar Fase 1 como referencia</td>
</tr>
<tr>
<td><strong>Preparando entrevista</strong></td>
<td>Ir directo a mÃ³dulos 20-23 + Simulacros</td>
</tr>
</tbody>
</table>
<h2>ğŸ“Š Roadmap Visual</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                           RUTA DE APRENDIZAJE (8 SEMANAS)                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                  â•‘
â•‘  FASE 1: FUNDAMENTOS (Semanas 1-2)          FASE 2: ML ENGINEERING (Semanas 3-4) â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â•‘
â•‘  [01] Python Moderno â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        [07] sklearn Pipelines â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â•‘
â•‘  [02] DiseÃ±o de Sistemas           â”‚        [08] Feature Engineering        â”‚    â•‘
â•‘  [03] Estructura de Proyecto       â”œâ”€â”€â†’     [09] Training Profesional  â”€â”€â”€â”€â”€â”¼â”€â”€â†’ â•‘
â•‘  [04] Entornos Reproducibles       â”‚        [10] Experiment Tracking        â”‚    â•‘
â•‘  [05] Git Profesional              â”‚                                        â”‚    â•‘
â•‘  [06] Versionado de Datos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚    â•‘
â•‘                                                                             â”‚    â•‘
â•‘  FASE 3: MLOps CORE (Semanas 5-6)           FASE 4: PRODUCCIÃ“N (Semana 7)   â”‚    â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚    â•‘
â•‘  [11] Testing para ML â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜    â•‘
â•‘  [12] CI/CD con GitHub Actions                                                   â•‘
â•‘  [13] Docker Avanzado                       [17] Estrategias de Despliegue       â•‘
â•‘  [14] FastAPI para ML                       [18] Infraestructura como CÃ³digo     â•‘
â•‘  [15] Streamlit Dashboards                                                       â•‘
â•‘  [16] Observabilidad                                                             â•‘
â•‘                                                                                  â•‘
â•‘  FASE 5: ESPECIALIZACIÃ“N (Semana 8)                                              â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â•‘
â•‘  [19] DocumentaciÃ³n (Model Cards)           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘
â•‘  [20] Proyecto Integrador â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  ğŸ¯ PORTAFOLIO COMPLETO          â”‚ â•‘
â•‘  [21] Glosario MLOps                        â”‚     3 proyectos production-ready â”‚ â•‘
â•‘  [22] Checklist Profesional                 â”‚     CI/CD â‰¥80% coverage          â”‚ â•‘
â•‘  [23] Recursos y Referencias                â”‚     Listo para entrevistas       â”‚ â•‘
â•‘                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘
â•‘                                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“– Ãndice de MÃ³dulos</h2>
<h3>FASE 1: Fundamentos de IngenierÃ­a (Semanas 1-2)</h3>
<blockquote>
<p><strong>Objetivo</strong>: Establecer las bases de cÃ³digo profesional que usarÃ¡s en todo el portafolio.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>MÃ³dulo</th>
<th>QuÃ© AprenderÃ¡s</th>
<th style="text-align: center;">Tiempo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">01</td>
<td><a href="#mod_01_PYTHON_MODERNO">Python Moderno</a></td>
<td>Type hints, Pydantic, dataclasses, SOLID</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td><a href="#mod_02_DISENO_SISTEMAS">DiseÃ±o de Sistemas ML</a></td>
<td>ML Canvas, C4 Model, ADRs, arquitectura</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td><a href="#mod_03_ESTRUCTURA_PROYECTO">Estructura de Proyecto</a></td>
<td>src/ layout, pyproject.toml, Makefile</td>
<td style="text-align: center;">3h</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td><a href="#mod_04_ENTORNOS">Entornos Reproducibles</a></td>
<td>venv, Poetry, requirements, lockfiles</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td><a href="#mod_05_GIT_PROFESIONAL">Git Profesional</a></td>
<td>Conventional Commits, pre-commit, branching</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td><a href="#mod_06_VERSIONADO_DATOS">Versionado de Datos</a></td>
<td>DVC, pipelines de datos, remote storage</td>
<td style="text-align: center;">4h</td>
</tr>
</tbody>
</table>
<p><strong>ğŸ“¦ AplicaciÃ³n en el Portafolio</strong>: Todo el cÃ³digo de <code>common_utils/</code>, <code>pyproject.toml</code> y <code>.pre-commit-config.yaml</code>.</p>
<blockquote>
<p>ğŸ¤ <strong>Checkpoint Junior</strong>: Al completar esta fase, practica con <a href="#mod_SIMULACRO_ENTREVISTA_JUNIOR">SIMULACRO_ENTREVISTA_JUNIOR.md</a></p>
</blockquote>
<h3>FASE 2: ML Engineering (Semanas 3-4)</h3>
<blockquote>
<p><strong>Objetivo</strong>: Dominar el core de Machine Learning profesional: pipelines reproducibles y experimentos rastreables.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>MÃ³dulo</th>
<th>QuÃ© AprenderÃ¡s</th>
<th style="text-align: center;">Tiempo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">07</td>
<td><a href="#mod_07_SKLEARN_PIPELINES">sklearn Pipelines</a></td>
<td>Pipeline, ColumnTransformer, Custom Transformers</td>
<td style="text-align: center;">5h</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td><a href="#mod_08_INGENIERIA_FEATURES">IngenierÃ­a de Features</a></td>
<td>Data leakage, FeatureEngineer class, validaciÃ³n</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td><a href="#mod_09_TRAINING_PROFESIONAL">Training Profesional</a></td>
<td>Clase Trainer, cross-validation, mÃ©tricas</td>
<td style="text-align: center;">5h</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td><a href="#mod_10_EXPERIMENT_TRACKING">Experiment Tracking</a></td>
<td>MLflow tracking, Model Registry, signatures</td>
<td style="text-align: center;">4h</td>
</tr>
</tbody>
</table>
<p><strong>ğŸ“¦ AplicaciÃ³n en el Portafolio</strong>:<br />
- <code>BankChurn-Predictor/src/bankchurn/pipeline.py</code> â†’ Pipeline unificado<br />
- <code>CarVision-Market-Intelligence/src/carvision/features.py</code> â†’ FeatureEngineer class<br />
- <code>mlruns/</code> en cada proyecto â†’ Experimentos MLflow</p>
<h3>FASE 3: MLOps Core (Semanas 5-6)</h3>
<blockquote>
<p><strong>Objetivo</strong>: Implementar las prÃ¡cticas que distinguen un proyecto ML profesional: testing, CI/CD, APIs y observabilidad.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>MÃ³dulo</th>
<th>QuÃ© AprenderÃ¡s</th>
<th style="text-align: center;">Tiempo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">11</td>
<td><a href="#mod_11_TESTING_ML">Testing para ML</a></td>
<td>PirÃ¡mide de testing, fixtures, 80%+ coverage</td>
<td style="text-align: center;">6h</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td><a href="#mod_12_CI_CD">CI/CD con GitHub Actions</a></td>
<td>Matrix testing, coverage gates, security scanning</td>
<td style="text-align: center;">5h</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td><a href="#mod_13_DOCKER">Docker Avanzado</a></td>
<td>Multi-stage builds, non-root, docker-compose</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td><a href="#mod_14_FASTAPI">FastAPI para ML</a></td>
<td>Schemas Pydantic, /predict, /health, error handling</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">15</td>
<td><a href="#mod_15_STREAMLIT">Streamlit Dashboards</a></td>
<td>Caching, tabs, visualizaciones, consumo de API</td>
<td style="text-align: center;">3h</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td><a href="#mod_16_OBSERVABILIDAD">Observabilidad</a></td>
<td>Logging estructurado, Prometheus, drift detection</td>
<td style="text-align: center;">4h</td>
</tr>
</tbody>
</table>
<p><strong>ğŸ“¦ AplicaciÃ³n en el Portafolio</strong>:<br />
- <code>tests/</code> en cada proyecto â†’ 80%+ coverage<br />
- <code>.github/workflows/ci-mlops.yml</code> â†’ Pipeline CI/CD real<br />
- <code>app/fastapi_app.py</code> â†’ API de predicciÃ³n<br />
- <code>app/streamlit_app.py</code> â†’ Dashboard interactivo</p>
<blockquote>
<p>ğŸ¤ <strong>Checkpoint Mid</strong>: Al completar esta fase, practica con <a href="#mod_SIMULACRO_ENTREVISTA_MID">SIMULACRO_ENTREVISTA_MID.md</a></p>
</blockquote>
<h3>FASE 4: ProducciÃ³n (Semana 7)</h3>
<blockquote>
<p><strong>Objetivo</strong>: Entender estrategias de despliegue, infraestructura como cÃ³digo y control de costos en cloud.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>MÃ³dulo</th>
<th>QuÃ© AprenderÃ¡s</th>
<th style="text-align: center;">Tiempo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">17</td>
<td><a href="#mod_17_DESPLIEGUE">Estrategias de Despliegue</a></td>
<td>Lambda vs ECS vs K8s, blue-green, canary, anÃ¡lisis de costos</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">18</td>
<td><a href="#mod_18_INFRAESTRUCTURA">Infraestructura como CÃ³digo</a></td>
<td>Terraform basics, Kubernetes intro, Cloud &amp; FinOps (costos en AWS/GCP)</td>
<td style="text-align: center;">3h</td>
</tr>
</tbody>
</table>
<p><strong>ğŸ“¦ AplicaciÃ³n en el Portafolio</strong>:<br />
- <code>infra/terraform/</code> â†’ Templates Terraform<br />
- <code>k8s/</code> â†’ Manifests Kubernetes (incluyendo buenas prÃ¡cticas de costos)<br />
- <code>docker-compose.demo.yml</code> â†’ OrquestaciÃ³n local</p>
<h3>FASE 5: EspecializaciÃ³n y MaestrÃ­a (Semana 8)</h3>
<blockquote>
<p><strong>Objetivo</strong>: DocumentaciÃ³n profesional, validaciÃ³n del portafolio y preparaciÃ³n para entrevistas.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>MÃ³dulo</th>
<th>QuÃ© AprenderÃ¡s</th>
<th style="text-align: center;">Tiempo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">19</td>
<td><a href="#mod_19_DOCUMENTACION">DocumentaciÃ³n ML</a></td>
<td>Model Cards, Dataset Cards, MkDocs</td>
<td style="text-align: center;">3h</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td><a href="#mod_20_PROYECTO_INTEGRADOR">Proyecto Integrador</a></td>
<td>RÃºbrica 100 puntos, checklist final</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">21</td>
<td><a href="#mod_21_GLOSARIO">Glosario MLOps</a></td>
<td>100+ tÃ©rminos esenciales</td>
<td style="text-align: center;">Referencia</td>
</tr>
<tr>
<td style="text-align: center;">22</td>
<td><a href="#mod_22_CHECKLIST">Checklist Profesional</a></td>
<td>VerificaciÃ³n pre-deploy, auditorÃ­a</td>
<td style="text-align: center;">2h</td>
</tr>
<tr>
<td style="text-align: center;">23</td>
<td><a href="#mod_23_RECURSOS">Recursos y Referencias</a></td>
<td>Libros, cursos, papers, comunidades</td>
<td style="text-align: center;">Referencia</td>
</tr>
</tbody>
</table>
<p><strong>ğŸ“¦ AplicaciÃ³n en el Portafolio</strong>:<br />
- <code>docs/</code> en cada proyecto â†’ Model Cards y READMEs profesionales<br />
- <code>RUNBOOK.md</code> â†’ GuÃ­a de operaciones</p>
<blockquote>
<p>ğŸ¤ <strong>Checkpoint Senior</strong>: Al completar toda la guÃ­a, practica con <a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE1">SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md</a> + <a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE2">PARTE2</a></p>
</blockquote>
<h2>ğŸ“š Material Complementario</h2>
<h3>PrÃ¡ctica y EvaluaciÃ³n</h3>
<table>
<thead>
<tr>
<th>Recurso</th>
<th>DescripciÃ³n</th>
<th>CuÃ¡ndo Usarlo</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#mod_EJERCICIOS">Ejercicios</a></td>
<td>Problemas prÃ¡cticos por mÃ³dulo</td>
<td>DespuÃ©s de cada mÃ³dulo</td>
</tr>
<tr>
<td><a href="#mod_EJERCICIOS_SOLUCIONES">Soluciones</a></td>
<td>Respuestas detalladas</td>
<td>Para verificar o desbloquear</td>
</tr>
<tr>
<td><a href="#mod_RUBRICA_EVALUACION">RÃºbrica de EvaluaciÃ³n</a></td>
<td>Criterios 100 puntos</td>
<td>Al finalizar un proyecto</td>
</tr>
</tbody>
</table>
<h3>PreparaciÃ³n de Entrevistas</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">Nivel</th>
<th>Recurso</th>
<th>DescripciÃ³n</th>
<th>CuÃ¡ndo Usarlo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_JUNIOR">Simulacro Junior</a></td>
<td>50 preguntas fundamentales</td>
<td>Semana 4-5</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_MID">Simulacro Mid</a></td>
<td>60 preguntas tÃ©cnicas</td>
<td>Semana 6-7</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE1">Simulacro Senior Parte 1</a></td>
<td>50+ preguntas avanzadas</td>
<td>Semana 8</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE2">Simulacro Senior Parte 2</a></td>
<td>System design, casos prÃ¡cticos</td>
<td>Semana 8</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>Recurso Complementario</th>
<th>DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#mod_APENDICE_A_SPEECH_PORTAFOLIO">Speech de Portafolio</a></td>
<td>GuiÃ³n completo 5-7 min</td>
</tr>
<tr>
<td><a href="#mod_APENDICE_B_TALKING_POINTS">Talking Points</a></td>
<td>Puntos clave concisos</td>
</tr>
</tbody>
</table>
<h3>Recursos Adicionales</h3>
<table>
<thead>
<tr>
<th>Recurso</th>
<th>DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#mod_SYLLABUS">SYLLABUS</a></td>
<td>Programa detallado semana a semana</td>
</tr>
<tr>
<td><a href="#mod_PLAN_ESTUDIOS">Plan de Estudios</a></td>
<td>Cronograma dÃ­a a dÃ­a</td>
</tr>
<tr>
<td><a href="#mod_DECISIONES_TECH">Decisiones TÃ©cnicas</a></td>
<td>ADRs: por quÃ© cada herramienta</td>
</tr>
<tr>
<td><a href="#mod_PLANTILLAS">Plantillas</a></td>
<td>Templates reutilizables</td>
</tr>
<tr>
<td><a href="#mod_GUIA_AUDIOVISUAL">GuÃ­a Audiovisual</a></td>
<td>CÃ³mo crear demos y videos</td>
</tr>
<tr>
<td><a href="#mod_MAINTENANCE_GUIDE">GuÃ­a de Mantenimiento</a></td>
<td>Operaciones y runbooks</td>
</tr>
<tr>
<td>ğŸ“º <strong><a href="#mod_RECURSOS_POR_MODULO">Recursos por MÃ³dulo</a></strong></td>
<td><strong>Videos YouTube, Coursera y documentaciÃ³n por mÃ³dulo</strong></td>
</tr>
</tbody>
</table>
<h2>ğŸ—ï¸ Los 3 Proyectos del Portafolio</h2>
<p>Esta guÃ­a te prepara para construir estos 3 proyectos production-ready:</p>
<h3>1. BankChurn-Predictor</h3>
<pre><code>ğŸ“ BankChurn-Predictor/
â”œâ”€â”€ src/bankchurn/          # CÃ³digo fuente
â”‚   â”œâ”€â”€ config.py           # ConfiguraciÃ³n Pydantic
â”‚   â”œâ”€â”€ pipeline.py         # Pipeline sklearn unificado
â”‚   â””â”€â”€ trainer.py          # Clase de entrenamiento
â”œâ”€â”€ app/                    # APIs
â”‚   â”œâ”€â”€ fastapi_app.py
â”‚   â””â”€â”€ streamlit_app.py
â”œâ”€â”€ tests/                  # 79%+ coverage
â””â”€â”€ Dockerfile              # Multi-stage, non-root
</code></pre>
<ul>
<li><strong>Problema</strong>: ClasificaciÃ³n binaria (churn/no-churn)</li>
<li><strong>TÃ©cnicas</strong>: RandomForest, class weighting, SimpleImputer</li>
<li><strong>MÃ³dulos clave</strong>: 07, 09, 11, 14</li>
</ul>
<h3>2. CarVision-Market-Intelligence</h3>
<pre><code>ğŸ“ CarVision-Market-Intelligence/
â”œâ”€â”€ src/carvision/
â”‚   â”œâ”€â”€ features.py         # FeatureEngineer centralizado
â”‚   â”œâ”€â”€ data.py             # clean_data parameterizado
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py    # Dashboard principal
â”œâ”€â”€ tests/                  # 97% coverage
â””â”€â”€ configs/config.yaml
</code></pre>
<ul>
<li><strong>Problema</strong>: RegresiÃ³n (predicciÃ³n de precios de autos)</li>
<li><strong>TÃ©cnicas</strong>: Custom FeatureEngineer, RandomForest</li>
<li><strong>MÃ³dulos clave</strong>: 08, 15, 11</li>
</ul>
<h3>3. TelecomAI-Customer-Intelligence</h3>
<pre><code>ğŸ“ TelecomAI-Customer-Intelligence/
â”œâ”€â”€ src/telecomai/
â”‚   â”œâ”€â”€ data.py
â”‚   â””â”€â”€ training.py
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ fastapi_app.py
â”‚   â””â”€â”€ example_load.py
â”œâ”€â”€ tests/                  # 97% coverage
â””â”€â”€ docs/
</code></pre>
<ul>
<li><strong>Problema</strong>: ClasificaciÃ³n multiclase (segmentaciÃ³n de clientes)</li>
<li><strong>TÃ©cnicas</strong>: LogisticRegression, GradientBoosting</li>
<li><strong>MÃ³dulos clave</strong>: 09, 10, 12</li>
</ul>
<h2>âš¡ Quick Start</h2>
<pre><code class="language-bash"># 1. Clonar el portafolio
git clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git
cd ML-MLOps-Portfolio

# 2. Empezar con BankChurn (proyecto base)
cd BankChurn-Predictor
pip install -e &quot;.[dev]&quot;

# 3. Ejecutar el flujo completo
make train          # Entrena el modelo
make test           # Ejecuta tests (79%+ coverage)
make serve          # Inicia API en localhost:8000

# 4. Verificar que todo funciona
curl http://localhost:8000/health
</code></pre>
<h2>ğŸ“ˆ Tiempo Estimado</h2>
<table>
<thead>
<tr>
<th>Fase</th>
<th>MÃ³dulos</th>
<th style="text-align: center;">Horas</th>
<th style="text-align: center;">Semanas</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fundamentos</td>
<td>01-06</td>
<td style="text-align: center;">23h</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td>ML Engineering</td>
<td>07-10</td>
<td style="text-align: center;">18h</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td>MLOps Core</td>
<td>11-16</td>
<td style="text-align: center;">26h</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td>ProducciÃ³n</td>
<td>17-18</td>
<td style="text-align: center;">7h</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td>EspecializaciÃ³n</td>
<td>19-23</td>
<td style="text-align: center;">12h</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td><strong>TOTAL</strong></td>
<td>23 mÃ³dulos</td>
<td style="text-align: center;"><strong>~86h</strong></td>
<td style="text-align: center;"><strong>8 semanas</strong></td>
</tr>
</tbody>
</table>
<p><strong>DedicaciÃ³n sugerida</strong>: 10-12 horas/semana</p>
<h2>âœ… Convenciones de la GuÃ­a</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">SÃ­mbolo</th>
<th>Significado</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ’¡</td>
<td>Tip o consejo prÃ¡ctico</td>
</tr>
<tr>
<td style="text-align: center;">âš ï¸</td>
<td>Advertencia importante</td>
</tr>
<tr>
<td style="text-align: center;">âŒ</td>
<td>Anti-patrÃ³n o error comÃºn</td>
</tr>
<tr>
<td style="text-align: center;">âœ…</td>
<td>Buena prÃ¡ctica recomendada</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”§</td>
<td>Ejercicio prÃ¡ctico</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ“</td>
<td>Nota o aclaraciÃ³n</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ¯</td>
<td>Objetivo de aprendizaje</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ“¦</td>
<td>CÃ³mo se usÃ³ en el portafolio</td>
</tr>
</tbody>
</table>
<h2>ğŸš€ Â¡Empieza Ahora!</h2>
<p><strong>MÃ³dulo 1</strong> â†’ <a href="#mod_01_PYTHON_MODERNO">Python Moderno para MLOps</a></p>
<p><em>Tiempo estimado para completar la guÃ­a: 8 semanas a ritmo moderado</em></p>
<p><em>Ãšltima actualizaciÃ³n: Diciembre 2024</em></p>
            </div>
        
            <!-- MÃ“DULO: SYLLABUS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_SYLLABUS" class="cover-title">SYLLABUS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“… SYLLABUS â€” GuÃ­a MLOps (Portfolio Edition)</h1>
<blockquote>
<p><strong>Programa completo de 8 semanas para construir el portafolio ML-MLOps-Portfolio desde cero</strong></p>
<p>ğŸ“Œ <strong>NavegaciÃ³n</strong>: Este documento complementa el <a href="#mod_00_INDICE">Ãndice Principal (00_INDICE.md)</a> con detalles de macro-mÃ³dulos y progresiÃ³n 0 â†’ Senior/Staff. Para la estructura mÃ³dulo por mÃ³dulo, consulta el Ã­ndice.</p>
</blockquote>
<h2>ğŸ¯ Objetivo del Programa</h2>
<p>Al completar este programa serÃ¡s capaz de:</p>
<ul>
<li>âœ… <strong>Reproducir 100%</strong> de los artefactos clave del portafolio (modelos, APIs, dashboards)</li>
<li>âœ… Implementar <strong>CI/CD profesional</strong> con 80%+ coverage</li>
<li>âœ… DiseÃ±ar <strong>arquitecturas ML production-ready</strong></li>
<li>âœ… <strong>Pasar entrevistas tÃ©cnicas</strong> nivel Senior/Staff</li>
<li>âœ… Crear <strong>Model Cards y Dataset Cards</strong> completos</li>
<li>âœ… Implementar <strong>observabilidad y monitoreo</strong> bÃ¡sico</li>
</ul>
<h2>ğŸ“Š Estructura del Programa (12 MÃ³dulos)</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Nombre</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Mini-Proyecto</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">00</td>
<td style="text-align: left;">IntroducciÃ³n</td>
<td style="text-align: center;">0.5 dÃ­as</td>
<td style="text-align: left;">Setup inicial</td>
</tr>
<tr>
<td style="text-align: center;">01</td>
<td style="text-align: left;">Python Moderno</td>
<td style="text-align: center;">2 dÃ­as</td>
<td style="text-align: left;">LibrerÃ­a <code>utils/</code></td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td style="text-align: left;">IngenierÃ­a de Datos</td>
<td style="text-align: center;">4 dÃ­as</td>
<td style="text-align: left;">ETL reproducible</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td style="text-align: left;">Feature Engineering</td>
<td style="text-align: center;">3 dÃ­as</td>
<td style="text-align: left;">Transformadores <code>.pkl</code></td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td style="text-align: left;">Modelado</td>
<td style="text-align: center;">6 dÃ­as</td>
<td style="text-align: left;">Scripts de entrenamiento</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td style="text-align: left;">MLflow &amp; DVC</td>
<td style="text-align: center;">3 dÃ­as</td>
<td style="text-align: left;">Tracking local</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td style="text-align: left;">Despliegue API</td>
<td style="text-align: center;">3 dÃ­as</td>
<td style="text-align: left;">FastAPI <code>/predict</code></td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td style="text-align: left;">Dashboard</td>
<td style="text-align: center;">2 dÃ­as</td>
<td style="text-align: left;">Streamlit app</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td style="text-align: left;">CI/CD &amp; Testing</td>
<td style="text-align: center;">3 dÃ­as</td>
<td style="text-align: left;">GitHub Actions</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td style="text-align: left;">Model &amp; Dataset Cards</td>
<td style="text-align: center;">1.5 dÃ­as</td>
<td style="text-align: left;">DocumentaciÃ³n ML</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: left;">Observabilidad</td>
<td style="text-align: center;">2 dÃ­as</td>
<td style="text-align: left;">Logging + alertas</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: left;">Mantenimiento &amp; AuditorÃ­a</td>
<td style="text-align: center;">2 dÃ­as</td>
<td style="text-align: left;">Runbooks</td>
</tr>
</tbody>
</table>
<p><strong>Tiempo total estimado</strong>: 32 dÃ­as (~6-8 semanas a ritmo moderado)</p>
<h2>ğŸ§­ Ruta 0 â†’ Senior/Staff (macro-mÃ³dulos)</h2>
<blockquote>
<p>Esta ruta agrupa los 23 mÃ³dulos de la guÃ­a en <strong>11 macro-mÃ³dulos</strong> que siguen el plan<br />
"0 â†’ Senior/Staff MLOps" que definiste. No reemplaza la numeraciÃ³n actual (01â€“23),<br />
sino que ofrece una vista de alto nivel basada en madurez.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">Macro-MÃ³dulo</th>
<th>Nombre</th>
<th>Objetivo principal</th>
<th>MÃ³dulos relacionados</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">00</td>
<td>Entorno, Herramientas y Flujo de Trabajo</td>
<td>Poder ejecutar los 3 proyectos del portafolio en tu mÃ¡quina</td>
<td>00_INDICE, 03_ESTRUCTURA_PROYECTO, 04_ENTORNOS, 05_GIT_PROFESIONAL, 17_DESPLIEGUE, PLAN_ESTUDIOS, QUICK_START del repo</td>
</tr>
<tr>
<td style="text-align: center;">01</td>
<td>Python Fundamentos para ProducciÃ³n</td>
<td>Pasar de Python junior a escribir cÃ³digo pythonico y mantenible</td>
<td>01_PYTHON_MODERNO, 03_ESTRUCTURA_PROYECTO, common_utils/*</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td>Fundamentos de Data Science y ML</td>
<td>Tener bases sÃ³lidas de DS/ML antes de entrar a MLOps</td>
<td>07_SKLEARN_PIPELINES, 08_INGENIERIA_FEATURES, 09_TRAINING_PROFESIONAL, notebooks de los proyectos</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td>IngenierÃ­a de Datos Aplicada a ML</td>
<td>Preparar datos como en una empresa, pensando en ML downstream</td>
<td>06_VERSIONADO_DATOS, 08_INGENIERIA_FEATURES, partes de TelecomAI-Customer-Intelligence</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td>Fundamentos de MLOps</td>
<td>Entender reproducibilidad, versionado y artefactos</td>
<td>06_VERSIONADO_DATOS, 10_EXPERIMENT_TRACKING, DECISIONES_TECH, 22_CHECKLIST</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td>Pipelines + CI/CD</td>
<td>Construir pipelines reales con tests y gates de calidad</td>
<td>07_SKLEARN_PIPELINES, 11_TESTING_ML, 12_CI_CD, workflows de .github/workflows/</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td>Model Deployment</td>
<td>Desplegar modelos con nivel Senior (APIs, Docker, serverless)</td>
<td>13_DOCKER, 14_FASTAPI, 17_DESPLIEGUE, docker-compose.demo.yml</td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td>Monitoring, Observabilidad y Alertas</td>
<td>Diferenciarte como Senior mediante observabilidad real</td>
<td>16_OBSERVABILIDAD, 22_CHECKLIST, dashboards de Grafana</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td>Infraestructura y Nube</td>
<td>Operar como engineer: IaC, redes y cloud basics</td>
<td>17_DESPLIEGUE, 18_INFRAESTRUCTURA, infra/terraform/<em>, k8s/</em></td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td>Escalado y Sistemas Distribuidos</td>
<td>Pensar en batch/streaming y K8s para ML a gran escala</td>
<td>18_INFRAESTRUCTURA, partes avanzadas de 17_DESPLIEGUE, tests/load/*</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td>Seguridad, Gobernanza y Cumplimiento</td>
<td>Tratar el portafolio como un sistema empresarial</td>
<td>19_DOCUMENTACION, 12_CI_CD (gitleaks, security), .gitleaks.toml, RUNBOOK.md</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td>Arquitectura MLOps Senior/Staff</td>
<td>Ver el sistema completo: multi-model, observabilidad y gobierno</td>
<td>20_PROYECTO_INTEGRADOR, 21_GLOSARIO, 23_RECURSOS, DECISIONES_TECH, RUNBOOK.md</td>
</tr>
</tbody>
</table>
<p><strong>Guion resumido por macro-mÃ³dulo</strong></p>
<p><strong>MÃ“DULO 00 â€” Entorno, Herramientas y Flujo de Trabajo</strong><br />
 Objetivo: garantizar que puedas ejecutar los 3 proyectos (BankChurn, CarVision, TelecomAI).<br />
 Incluye: Conda/pipx/uv, Docker + Docker Compose, Git + branching, VS Code + DevContainers, Makefiles, estructura estÃ¡ndar ML/MLOps.<br />
 PrÃ¡ctica en este repo: seguir <code>00_INDICE.md</code>, <code>PLAN_ESTUDIOS.md</code> y el QUICK_START de la raÃ­z hasta ejecutar BankChurn end-to-end.</p>
<p><strong>MÃ“DULO 01 â€” Python Fundamentos para ProducciÃ³n</strong><br />
 Objetivo: llevar de Python junior a cÃ³digo pythonico y mantenible.<br />
 Incluye: POO aplicada a ML, tipado estÃ¡tico (mypy), logging profesional, manejo de errores, estructura de paquetes.<br />
 PrÃ¡ctica en este repo: trabajar <code>01_PYTHON_MODERNO.md</code> y refactorizar utilidades en <code>common_utils/</code> y el cÃ³digo de BankChurn.</p>
<p><strong>MÃ“DULO 02 â€” Fundamentos de Data Science y ML</strong><br />
 Objetivo: construir bases sÃ³lidas de DS/ML antes de MLOps.<br />
 Incluye: exploraciÃ³n, limpieza, feature engineering, validaciÃ³n cruzada, overfitting/underfitting.<br />
 PrÃ¡ctica en este repo: rehacer el pipeline de features y validaciÃ³n de BankChurn apoyÃ¡ndote en <code>07_SKLEARN_PIPELINES.md</code>, <code>08_INGENIERIA_FEATURES.md</code> y <code>09_TRAINING_PROFESIONAL.md</code>.</p>
<p><strong>MÃ“DULO 03 â€” IngenierÃ­a de Datos Aplicada a ML</strong><br />
 Objetivo: preparar datos como en una empresa, pensando en su uso en modelos.<br />
 Incluye: ETL/ELT, orquestaciÃ³n ligera, data quality, feature stores.<br />
 PrÃ¡ctica en este repo: usar <code>06_VERSIONADO_DATOS.md</code> y <code>08_INGENIERIA_FEATURES.md</code> para montar un mini feature store inspirado en TelecomAI.</p>
<p><strong>MÃ“DULO 04 â€” Fundamentos de MLOps</strong><br />
 Objetivo: introducir el mindset MLOps (reproducibilidad, versionado, artefactos).<br />
 Incluye: versionado de datos y modelos, ML metadata, experiment tracking, artefactos.<br />
 PrÃ¡ctica en este repo: integrar MLflow y DVC a BankChurn siguiendo <code>06_VERSIONADO_DATOS.md</code>, <code>10_EXPERIMENT_TRACKING.md</code> y <code>DECISIONES_TECH.md</code>.</p>
<p><strong>MÃ“DULO 05 â€” Pipelines + CI/CD</strong><br />
 Objetivo: crear pipelines reales con CI/CD enterprise-like.<br />
 Incluye: GitHub Actions, testing, coverage, code-quality gates.<br />
 PrÃ¡ctica en este repo: combinar <code>07_SKLEARN_PIPELINES.md</code>, <code>11_TESTING_ML.md</code> y <code>12_CI_CD.md</code> para obtener un pipeline completo para los 3 proyectos usando los workflows reales del repositorio.</p>
<p><strong>MÃ“DULO 06 â€” Model Deployment</strong><br />
 Objetivo: desplegar con nivel Senior.<br />
 Incluye: APIs con FastAPI, dockerizaciÃ³n, serverless, patrones de model serving.<br />
 PrÃ¡ctica en este repo: usar <code>13_DOCKER.md</code>, <code>14_FASTAPI.md</code> y <code>17_DESPLIEGUE.md</code> para desplegar CarVision en contenedor + endpoint (local y/o cloud).</p>
<p><strong>MÃ“DULO 07 â€” Monitoring, Observabilidad y Alertas</strong><br />
 Objetivo: incorporar observabilidad que diferencie un junior de un senior.<br />
 Incluye: concept vs data drift, monitoreo de features/predicciones, logging estructurado, Prometheus + Grafana.<br />
 PrÃ¡ctica en este repo: seguir <code>16_OBSERVABILIDAD.md</code> para instrumentar BankChurn con mÃ©tricas y paneles, apoyÃ¡ndote en los manifiestos de <code>k8s/</code> y las reglas de <code>infra/</code>.</p>
<p><strong>MÃ“DULO 08 â€” Infraestructura y Nube</strong><br />
 Objetivo: operar como un engineer en cloud.<br />
 Incluye: IaC (Terraform), fundamentos AWS/GCP, redes, seguridad bÃ¡sica y control de costos (FinOps) para evitar sorpresas en la factura.<br />
 PrÃ¡ctica en este repo: partir de <code>17_DESPLIEGUE.md</code> y <code>18_INFRAESTRUCTURA.md</code> (especialmente la secciÃ³n <em>Cloud y Control de Costos</em>) para desplegar un stack MLOps bÃ¡sico en cloud (o simularlo localmente con los manifests y Terraform). </p>
<p><strong>MÃ“DULO 09 â€” Escalado y Sistemas Distribuidos</strong><br />
 Objetivo: pensar en batch/streaming y K8s para producciÃ³n masiva.<br />
 Incluye: batch vs streaming, Kubernetes, automatizaciÃ³n avanzada.<br />
 PrÃ¡ctica en este repo: usar las secciones avanzadas de <code>18_INFRAESTRUCTURA.md</code>, los manifests en <code>k8s/</code> y los tests de carga en <code>tests/load/</code> como base para diseÃ±ar un despliegue escalable de CarVision.</p>
<p><strong>MÃ“DULO 10 â€” Seguridad, Gobernanza y Cumplimiento</strong><br />
 Objetivo: llevar la senioridad al plano empresarial.<br />
 Incluye: polÃ­ticas, roles, seguridad de repos (secrets, escaneo), Model Cards y Ã©tica.<br />
 PrÃ¡ctica en este repo: combinar <code>19_DOCUMENTACION.md</code>, la configuraciÃ³n de <code>12_CI_CD.md</code> (gitleaks, security scanning) y <code>.gitleaks.toml</code> para definir polÃ­ticas mÃ­nimas y completar Model Cards para los 3 proyectos.</p>
<p><strong>MÃ“DULO 11 â€” Arquitectura MLOps Senior/Staff</strong><br />
 Objetivo: tener visiÃ³n completa de sistemas reales (multi-model, gobierno, observabilidad a gran escala).<br />
 Incluye: arquitecturas event-driven, multi-model governance, patrones de observabilidad.<br />
 PrÃ¡ctica en este repo: usar <code>20_PROYECTO_INTEGRADOR.md</code>, <code>DECISIONES_TECH.md</code> y <code>RUNBOOK.md</code> para diseÃ±ar y documentar una arquitectura MLOps completa que integre los 3 proyectos.</p>
<p>Puedes usar:</p>
<ul>
<li>Esta secciÃ³n para entender el <strong>mapa mental 0 â†’ Senior/Staff</strong>.</li>
<li>El Ã­ndice de 23 mÃ³dulos (<code>00_INDICE.md</code>) y el plan por semanas para avanzar <strong>paso a paso</strong>.</li>
</ul>
<h2>ğŸ“š Detalle por MÃ³dulo</h2>
<h3>MÃ³dulo 00 â€” IntroducciÃ³n (0.5 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Objetivos del curso</td>
<td style="text-align: left;">âœ… Entender el roadmap</td>
</tr>
<tr>
<td style="text-align: left;">CÃ³mo leer la guÃ­a</td>
<td style="text-align: left;">âœ… Setup de herramientas</td>
</tr>
<tr>
<td style="text-align: left;">Requerimientos mÃ­nimos</td>
<td style="text-align: left;">âœ… Entorno listo</td>
</tr>
<tr>
<td style="text-align: left;">Mapa guÃ­a â†’ repo</td>
<td style="text-align: left;">âœ… ComprensiÃ³n de estructura</td>
</tr>
</tbody>
</table>
<p><strong>Output</strong>: Entorno de desarrollo listo, comprensiÃ³n clara del objetivo final.</p>
<h3>MÃ³dulo 01 â€” Python Moderno (2 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Type hints y tipado estÃ¡tico</td>
<td style="text-align: left;">CÃ³digo tipado</td>
</tr>
<tr>
<td style="text-align: left;">Dataclasses y Pydantic</td>
<td style="text-align: left;">Config validado</td>
</tr>
<tr>
<td style="text-align: left;">OOP y SOLID bÃ¡sico</td>
<td style="text-align: left;">Clases bien diseÃ±adas</td>
</tr>
<tr>
<td style="text-align: left;">Estructura de paquete</td>
<td style="text-align: left;"><code>utils/</code> funcional</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: Crear librerÃ­a <code>utils/</code> con <code>config.py</code> (Pydantic) y <code>mathops.py</code> (funciones tipadas).</p>
<p><strong>Validar</strong>: <code>make check-01</code></p>
<h3>MÃ³dulo 02 â€” IngenierÃ­a de Datos (4 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Lectura/escritura de datos</td>
<td style="text-align: left;">Loaders reutilizables</td>
</tr>
<tr>
<td style="text-align: left;">ValidaciÃ³n con schemas</td>
<td style="text-align: left;">Contratos de datos</td>
</tr>
<tr>
<td style="text-align: left;">Transformaciones bÃ¡sicas</td>
<td style="text-align: left;">ETL reproducible</td>
</tr>
<tr>
<td style="text-align: left;">Tests de integridad</td>
<td style="text-align: left;">Datos validados</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: ETL que produce CSV/Parquet reproducible + tests de integridad.</p>
<p><strong>Validar</strong>: <code>make check-02</code></p>
<h3>MÃ³dulo 03 â€” Feature Engineering (3 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Pipelines serializables</td>
<td style="text-align: left;">Pipeline persistido</td>
</tr>
<tr>
<td style="text-align: left;">Custom encoders</td>
<td style="text-align: left;">Transformadores <code>.pkl</code></td>
</tr>
<tr>
<td style="text-align: left;">PrevenciÃ³n de data leakage</td>
<td style="text-align: left;">CÃ³digo seguro</td>
</tr>
<tr>
<td style="text-align: left;">Persistencia de artefactos</td>
<td style="text-align: left;">Artefactos reutilizables</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: <code>FeatureEngineer</code> class con transformadores serializados.</p>
<p><strong>Validar</strong>: <code>make check-03</code></p>
<h3>MÃ³dulo 04 â€” Modelado (6 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Pipelines sklearn completos</td>
<td style="text-align: left;">Pipeline unificado</td>
</tr>
<tr>
<td style="text-align: left;">ValidaciÃ³n temporal/cruzada</td>
<td style="text-align: left;">CV implementado</td>
</tr>
<tr>
<td style="text-align: left;">Hyperparameter tuning</td>
<td style="text-align: left;">BÃºsqueda de hiperparÃ¡metros</td>
</tr>
<tr>
<td style="text-align: left;">ExperimentaciÃ³n reproducible</td>
<td style="text-align: left;">Scripts de entrenamiento</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: Scripts que generan modelos y reportes en <code>outputs/</code>.</p>
<p><strong>Validar</strong>: <code>make check-04</code></p>
<h3>MÃ³dulo 05 â€” MLflow &amp; DVC (3 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">MLflow server local</td>
<td style="text-align: left;"><code>mlflow ui</code> funcionando</td>
</tr>
<tr>
<td style="text-align: left;">Tracking de experimentos</td>
<td style="text-align: left;">MÃ©tricas registradas</td>
</tr>
<tr>
<td style="text-align: left;">DVC init y pipelines</td>
<td style="text-align: left;"><code>dvc.yaml</code> configurado</td>
</tr>
<tr>
<td style="text-align: left;">Versionado de artefactos</td>
<td style="text-align: left;">Datos versionados</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: <code>mlruns/</code> y <code>dvc/</code> que emulan el flujo del repo.</p>
<p><strong>Validar</strong>: <code>make check-05</code></p>
<h3>MÃ³dulo 06 â€” Despliegue API (3 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">FastAPI bÃ¡sico</td>
<td style="text-align: left;">API funcional</td>
</tr>
<tr>
<td style="text-align: left;">Schemas Pydantic</td>
<td style="text-align: left;">Request/Response tipados</td>
</tr>
<tr>
<td style="text-align: left;">Tests de integraciÃ³n</td>
<td style="text-align: left;">Tests pasando</td>
</tr>
<tr>
<td style="text-align: left;">Dockerfile</td>
<td style="text-align: left;">Contenedor listo</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: API local con endpoint <code>/predict</code> funcional.</p>
<p><strong>Validar</strong>: <code>make check-06</code></p>
<h3>MÃ³dulo 07 â€” Dashboard (2 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Streamlit bÃ¡sico</td>
<td style="text-align: left;">App funcionando</td>
</tr>
<tr>
<td style="text-align: left;">Consumo de API</td>
<td style="text-align: left;">IntegraciÃ³n con backend</td>
</tr>
<tr>
<td style="text-align: left;">Caching y optimizaciÃ³n</td>
<td style="text-align: left;">Performance aceptable</td>
</tr>
<tr>
<td style="text-align: left;">Ejemplo desplegable</td>
<td style="text-align: left;">Ready to deploy</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: Dashboard Streamlit que consume la API local.</p>
<p><strong>Validar</strong>: <code>make check-07</code></p>
<h3>MÃ³dulo 08 â€” CI/CD &amp; Testing (3 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GitHub Actions</td>
<td style="text-align: left;">Workflow configurado</td>
</tr>
<tr>
<td style="text-align: left;">Matrix testing</td>
<td style="text-align: left;">Tests multi-versiÃ³n</td>
</tr>
<tr>
<td style="text-align: left;">Coverage reports</td>
<td style="text-align: left;">80%+ coverage</td>
</tr>
<tr>
<td style="text-align: left;">Security scanning</td>
<td style="text-align: left;">gitleaks local</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: <code>ci_template.yml</code> funcional, simulaciÃ³n local con <code>act</code>.</p>
<p><strong>Validar</strong>: <code>make check-08</code></p>
<h3>MÃ³dulo 09 â€” Model &amp; Dataset Cards (1.5 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Plantilla Model Card</td>
<td style="text-align: left;">Template relleno</td>
</tr>
<tr>
<td style="text-align: left;">Plantilla Dataset Card</td>
<td style="text-align: left;">Template relleno</td>
</tr>
<tr>
<td style="text-align: left;">Buenas prÃ¡cticas de documentaciÃ³n</td>
<td style="text-align: left;">Docs completos</td>
</tr>
<tr>
<td style="text-align: left;">Ejemplos del portafolio</td>
<td style="text-align: left;">Cards reales</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: Model Card y Dataset Card completados para un mini-proyecto.</p>
<p><strong>Validar</strong>: <code>make check-09</code></p>
<h3>MÃ³dulo 10 â€” Observabilidad &amp; Monitoring (2 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Logging estructurado</td>
<td style="text-align: left;">Logs configurados</td>
</tr>
<tr>
<td style="text-align: left;">MÃ©tricas bÃ¡sicas</td>
<td style="text-align: left;">Latencia, error rate</td>
</tr>
<tr>
<td style="text-align: left;">SimulaciÃ³n de alertas</td>
<td style="text-align: left;">Scripts de alerta</td>
</tr>
<tr>
<td style="text-align: left;">Drift detection bÃ¡sico</td>
<td style="text-align: left;">Checks implementados</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: Sistema con logging estructurado y scripts de alerta.</p>
<p><strong>Validar</strong>: <code>make check-10</code></p>
<h3>MÃ³dulo 11 â€” Mantenimiento &amp; AuditorÃ­a (2 dÃ­as)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Contenido</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Playbooks de mantenimiento</td>
<td style="text-align: left;">Runbooks documentados</td>
</tr>
<tr>
<td style="text-align: left;">Tests de regresiÃ³n</td>
<td style="text-align: left;">Regression tests</td>
</tr>
<tr>
<td style="text-align: left;">ActualizaciÃ³n de dependencias</td>
<td style="text-align: left;">Proceso documentado</td>
</tr>
<tr>
<td style="text-align: left;">Calendario de revisiones</td>
<td style="text-align: left;">Plan de mantenimiento</td>
</tr>
</tbody>
</table>
<p><strong>Mini-Proyecto</strong>: MAINTENANCE_GUIDE.md y scripts de validaciÃ³n.</p>
<p><strong>Validar</strong>: <code>make check-11</code></p>
<h2>ğŸ“Š RÃºbrica de EvaluaciÃ³n (100 puntos por mÃ³dulo)</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Criterio</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Funcionalidad</strong></td>
<td style="text-align: center;">40</td>
<td style="text-align: left;">Pasa tests mÃ­nimos, produce outputs esperados</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Calidad del cÃ³digo</strong></td>
<td style="text-align: center;">20</td>
<td style="text-align: left;">Linters, type hints, modularidad</td>
</tr>
<tr>
<td style="text-align: left;"><strong>DocumentaciÃ³n</strong></td>
<td style="text-align: center;">15</td>
<td style="text-align: left;">README, Model/Dataset Cards</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Reproducibilidad</strong></td>
<td style="text-align: center;">15</td>
<td style="text-align: left;">Instrucciones make, lockfile, ejecuciÃ³n local</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tests y cobertura</strong></td>
<td style="text-align: center;">10</td>
<td style="text-align: left;">Pruebas unitarias/integraciÃ³n mÃ­nimas</td>
</tr>
</tbody>
</table>
<p><strong>Nota mÃ­nima aprobatoria</strong>: 70/100 por mÃ³dulo</p>
<h2>ğŸ“ˆ Progreso Sugerido</h2>
<pre><code>Semana 1:   MÃ³dulos 00-01 (Fundamentos Python)
Semana 2:   MÃ³dulos 02-03 (Datos y Features)
Semana 3:   MÃ³dulo 04 (Modelado completo)
Semana 4:   MÃ³dulos 05-06 (Tracking + API)
Semana 5:   MÃ³dulos 07-08 (Dashboard + CI/CD)
Semana 6:   MÃ³dulos 09-11 (Docs + Mantenimiento)
</code></pre>
<h2>ğŸ¤ PreparaciÃ³n para Entrevistas</h2>
<p>La guÃ­a incluye simulacros de entrevista adaptados a cada nivel de experiencia:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Nivel</th>
<th>Simulacro</th>
<th style="text-align: center;">Preguntas</th>
<th>CuÃ¡ndo Usar</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¢ Junior</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_JUNIOR">SIMULACRO_ENTREVISTA_JUNIOR.md</a></td>
<td style="text-align: center;">50</td>
<td>Semanas 1-4</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡ Mid</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_MID">SIMULACRO_ENTREVISTA_MID.md</a></td>
<td style="text-align: center;">60</td>
<td>Semanas 5-6</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´ Senior</td>
<td><a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE1">SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md</a> + <a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE2">PARTE2</a></td>
<td style="text-align: center;">115</td>
<td>Semanas 7-8</td>
</tr>
</tbody>
</table>
<p><strong>ProgresiÃ³n recomendada</strong>:<br />
1. <strong>Junior</strong>: Python bÃ¡sico, ML fundamentos, Git, estructura de proyecto<br />
2. <strong>Mid</strong>: Pipelines, testing, CI/CD, Docker, APIs<br />
3. <strong>Senior</strong>: System design, arquitectura, liderazgo, trade-offs</p>
<p><strong>Material complementario</strong>:<br />
- <a href="#mod_APENDICE_A_SPEECH_PORTAFOLIO">Speech de Portafolio</a> â€” GuiÃ³n de 5-7 min<br />
- <a href="#mod_APENDICE_B_TALKING_POINTS">Talking Points</a> â€” Puntos clave concisos</p>
<h2>âœ… Prerrequisitos</h2>
<ul>
<li><strong>Python 3.10+</strong> instalado</li>
<li><strong>Git</strong> bÃ¡sico (clone, commit, push)</li>
<li><strong>LÃ­nea de comandos</strong> bÃ¡sica (bash/zsh)</li>
<li><strong>Cuenta GitHub</strong> activa</li>
<li><strong>Editor/IDE</strong> (VS Code recomendado)</li>
<li><strong>8GB RAM</strong> mÃ­nimo, 16GB recomendado</li>
</ul>
<h2>ğŸ› ï¸ CÃ³mo usar la guÃ­a</h2>
<ol>
<li><strong>Clonar</strong> el repositorio guÃ­a</li>
<li><strong>Ejecutar</strong> <code>make setup</code> para preparar el entorno</li>
<li><strong>Seguir</strong> cada mÃ³dulo en orden</li>
<li><strong>Completar</strong> el mini-proyecto de cada mÃ³dulo</li>
<li><strong>Validar</strong> con <code>make check-XX</code> correspondiente</li>
<li><strong>Revisar</strong> soluciones en <code>solutions/</code> si necesitas ayuda</li>
</ol>
<h2>ğŸ“¦ Entregables Finales</h2>
<p>Al completar la guÃ­a tendrÃ¡s:</p>
<ul>
<li>[ ] Portafolio ML reproducido localmente</li>
<li>[ ] 3 proyectos con CI/CD funcionando</li>
<li>[ ] Model Cards y Dataset Cards completos</li>
<li>[ ] APIs y dashboards desplegables</li>
<li>[ ] Sistema de observabilidad bÃ¡sico</li>
<li>[ ] Runbooks de mantenimiento</li>
</ul>
<p><strong>Â¡Empieza ahora!</strong> â†’ <a href="#mod_00_INDICE">00_INDICE.md</a></p>
            </div>
        
            <!-- MÃ“DULO: PLAN_ESTUDIOS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_PLAN_ESTUDIOS" class="cover-title">PLAN DE ESTUDIOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“… Plan de Estudios â€” 8 Semanas</h1>
<blockquote>
<p><strong>Roadmap detallado para completar el portafolio MLOps</strong></p>
</blockquote>
<h2>ğŸ“Š Vista General</h2>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PLAN DE 8 SEMANAS                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Semana 1-2:  FUNDAMENTOS                                            â”‚
â”‚               Python moderno, estructura, Git, entornos              â”‚
â”‚                                                                      â”‚
â”‚  Semana 3-4:  ML ENGINEERING                                         â”‚
â”‚               Pipelines sklearn, feature engineering, MLflow         â”‚
â”‚                                                                      â”‚
â”‚  Semana 5-6:  MLOps CORE                                             â”‚
â”‚               Testing, CI/CD, Docker, APIs                           â”‚
â”‚                                                                      â”‚
â”‚  Semana 7:    PRODUCCIÃ“N                                             â”‚
â”‚               Deploy, observabilidad, infraestructura                â”‚
â”‚                                                                      â”‚
â”‚  Semana 8:    PROYECTO FINAL                                         â”‚
â”‚               DocumentaciÃ³n, demo, preparaciÃ³n entrevistas           â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<blockquote>
<p><strong>Consejo didÃ¡ctico</strong>: En cada mÃ³dulo, antes de marcar el checkpoint como completado, revisa tambiÃ©n la secciÃ³n de <strong>"Errores habituales y cÃ³mo depurarlos"</strong> para consolidar patrones de debugging.</p>
<p><strong>Ruta 0 â†’ Senior/Staff</strong>: Usa la secciÃ³n <strong>"Ruta 0 â†’ Senior/Staff (macro-mÃ³dulos)"</strong> del <a href="#mod_SYLLABUS">SYLLABUS</a> como mapa de alto nivel, y este plan de 8 semanas como cronograma concreto.</p>
</blockquote>
<h2>ğŸ“š Semana 1: Python Moderno + Estructura</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Dominar type hints y Pydantic</li>
<li>[ ] Crear estructura src/ layout</li>
<li>[ ] Configurar pyproject.toml</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: left;">Leer <a href="#mod_01_PYTHON_MODERNO">01_PYTHON_MODERNO</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Notas</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: left;">Ejercicios type hints</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;">CÃ³digo tipado</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Leer <a href="#mod_02_DISENO_SISTEMAS">02_DISENO_SISTEMAS</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">ML Canvas</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Leer <a href="#mod_03_ESTRUCTURA_PROYECTO">03_ESTRUCTURA_PROYECTO</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Estructura base</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Crear proyecto BankChurn base</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;">Repo inicial</td>
</tr>
</tbody>
</table>
<h3>Recursos</h3>
<ul>
<li><a href="https://docs.pydantic.dev/">Pydantic Docs</a></li>
<li><a href="https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html">Python Type Hints Cheat Sheet</a></li>
</ul>
<h2>ğŸ“š Semana 2: Git + Entornos + DVC</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Configurar pre-commit hooks</li>
<li>[ ] Dominar Conventional Commits</li>
<li>[ ] Inicializar DVC</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: left;">Leer <a href="#mod_04_ENTORNOS">04_ENTORNOS</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">requirements.txt</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: left;">Leer <a href="#mod_05_GIT_PROFESIONAL">05_GIT_PROFESIONAL</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">pre-commit.yaml</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Configurar pre-commit en proyecto</td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Hooks funcionando</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Leer <a href="#mod_06_VERSIONADO_DATOS">06_VERSIONADO_DATOS</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">DVC init</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Versionar datos de BankChurn</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;">.dvc files</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š Semana 3: Pipelines sklearn</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Crear Pipeline unificado</li>
<li>[ ] Implementar ColumnTransformer</li>
<li>[ ] Crear Custom Transformer</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1-2</td>
<td style="text-align: left;">Leer <a href="#mod_07_SKLEARN_PIPELINES">07_SKLEARN_PIPELINES</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">Pipeline bÃ¡sico</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Implementar ColumnTransformer</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;">Preprocessing</td>
</tr>
<tr>
<td style="text-align: center;">4-5</td>
<td style="text-align: left;">Leer <a href="#mod_08_INGENIERIA_FEATURES">08_INGENIERIA_FEATURES</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">FeatureEngineer class</td>
</tr>
</tbody>
</table>
<h3>Proyecto</h3>
<p>Crear <code>src/bankchurn/training.py</code> con pipeline completo.</p>
<h2>ğŸ“š Semana 4: Training + MLflow</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Crear clase Trainer profesional</li>
<li>[ ] Implementar cross-validation</li>
<li>[ ] Integrar MLflow tracking</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1-2</td>
<td style="text-align: left;">Leer <a href="#mod_09_TRAINING_PROFESIONAL">09_TRAINING_PROFESIONAL</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">ChurnTrainer class</td>
</tr>
<tr>
<td style="text-align: center;">3-5</td>
<td style="text-align: left;">Leer <a href="#mod_10_EXPERIMENT_TRACKING">10_EXPERIMENT_TRACKING</a></td>
<td style="text-align: center;">6h</td>
<td style="text-align: left;">MLflow integrado</td>
</tr>
</tbody>
</table>
<h3>Proyecto</h3>
<p>Entrenar modelo con mÃ©tricas en MLflow UI.</p>
<h2>ğŸ“š Semana 5: Testing</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Escribir tests unitarios</li>
<li>[ ] Alcanzar 80% coverage</li>
<li>[ ] Crear fixtures reutilizables</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1-2</td>
<td style="text-align: left;">Leer <a href="#mod_11_TESTING_ML">11_TESTING_ML</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">conftest.py</td>
</tr>
<tr>
<td style="text-align: center;">3-5</td>
<td style="text-align: left;">Escribir tests para BankChurn</td>
<td style="text-align: center;">6h</td>
<td style="text-align: left;">80% coverage</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š Semana 6: CI/CD + Docker + APIs</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Crear GitHub Actions workflow</li>
<li>[ ] Dockerfile multi-stage</li>
<li>[ ] API FastAPI funcional</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: left;">Leer <a href="#mod_12_CI_CD">12_CI_CD</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">ci.yml</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: left;">Leer <a href="#mod_13_DOCKER">13_DOCKER</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Dockerfile</td>
</tr>
<tr>
<td style="text-align: center;">3-4</td>
<td style="text-align: left;">Leer <a href="#mod_14_FASTAPI">14_FASTAPI</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">/predict endpoint</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Leer <a href="#mod_15_STREAMLIT">15_STREAMLIT</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Dashboard bÃ¡sico</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š Semana 7: ProducciÃ³n</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Implementar logging estructurado</li>
<li>[ ] Entender estrategias de deploy</li>
<li>[ ] Conocer Terraform/K8s bÃ¡sico</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1-2</td>
<td style="text-align: left;">Leer <a href="#mod_16_OBSERVABILIDAD">16_OBSERVABILIDAD</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">Logging JSON</td>
</tr>
<tr>
<td style="text-align: center;">3-4</td>
<td style="text-align: left;">Leer <a href="#mod_17_DESPLIEGUE">17_DESPLIEGUE</a></td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;">Estrategia elegida</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Leer <a href="#mod_18_INFRAESTRUCTURA">18_INFRAESTRUCTURA</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Conceptos IaC</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š Semana 8: Proyecto Final</h2>
<h3>Objetivos</h3>
<ul>
<li>[ ] Completar documentaciÃ³n</li>
<li>[ ] Pasar rÃºbrica de evaluaciÃ³n</li>
<li>[ ] Preparar para entrevistas</li>
</ul>
<h3>Actividades Diarias</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">DÃ­a</th>
<th style="text-align: left;">Actividad</th>
<th style="text-align: center;">Tiempo</th>
<th style="text-align: left;">Entregable</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: left;">Leer <a href="#mod_19_DOCUMENTACION">19_DOCUMENTACION</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">Model Card</td>
</tr>
<tr>
<td style="text-align: center;">2-3</td>
<td style="text-align: left;"><a href="#mod_20_PROYECTO_INTEGRADOR">20_PROYECTO_INTEGRADOR</a></td>
<td style="text-align: center;">6h</td>
<td style="text-align: left;">Self-assessment</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Revisar <a href="#mod_21_GLOSARIO">21_GLOSARIO</a></td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;">TÃ©rminos dominados</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Simulacros de entrevista</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;">PreparaciÃ³n lista</td>
</tr>
</tbody>
</table>
<h2>â±ï¸ Tiempo Total Estimado</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Componente</th>
<th style="text-align: right;">Horas</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Lectura de mÃ³dulos</td>
<td style="text-align: right;">40h</td>
</tr>
<tr>
<td style="text-align: left;">Ejercicios prÃ¡cticos</td>
<td style="text-align: right;">30h</td>
</tr>
<tr>
<td style="text-align: left;">Proyecto BankChurn</td>
<td style="text-align: right;">20h</td>
</tr>
<tr>
<td style="text-align: left;">Proyectos adicionales</td>
<td style="text-align: right;">20h</td>
</tr>
<tr>
<td style="text-align: left;"><strong>TOTAL</strong></td>
<td style="text-align: right;"><strong>110h</strong></td>
</tr>
</tbody>
</table>
<p><strong>DedicaciÃ³n sugerida</strong>: 15-20 horas/semana</p>
<h2>âœ… Checklist de FinalizaciÃ³n</h2>
<ul>
<li>[ ] 3 proyectos funcionando (BankChurn, CarVision, TelecomAI)</li>
<li>[ ] CI/CD pasando en los 3</li>
<li>[ ] Coverage â‰¥80% en todos</li>
<li>[ ] APIs dockerizadas</li>
<li>[ ] READMEs profesionales</li>
<li>[ ] Model Cards completos</li>
</ul>
            </div>
        
            <!-- MÃ“DULO: 01_PYTHON_MODERNO.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_01_PYTHON_MODERNO" class="cover-title">PYTHON MODERNO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>01. Python Moderno para MLOps</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Transformar tu cÃ³digo de "funciona en un notebook" a "pasa code review en una empresa FAANG".</p>
<p>En este portafolio aplicarÃ¡s estos patrones sobre <code>common_utils/</code> y el cÃ³digo de los tres proyectos<br />
(BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence), para que<br />
tu Python sea consistente en todo el stack.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   ANTES (Data Scientist tÃ­pico)          DESPUÃ‰S (MLOps Engineer)            â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â•‘
â•‘   â€¢ Un archivo gigante                   â€¢ Paquete instalable                â•‘
â•‘   â€¢ Sin tipos                            â€¢ Type hints en todo                â•‘
â•‘   â€¢ Config hardcodeada                   â€¢ Pydantic validation               â•‘
â•‘   â€¢ &quot;Funciona en mi mÃ¡quina&quot;             â€¢ Funciona en cualquier mÃ¡quina     â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#11-type-hints-tu-contrato-con-el-futuro">Type Hints: Tu Contrato con el Futuro</a></li>
<li><a href="#12-pydantic-validaciÃ³n-automÃ¡tica">Pydantic: ValidaciÃ³n AutomÃ¡tica</a></li>
<li><a href="#13-src-layout-estructura-profesional">src/ Layout: Estructura Profesional</a></li>
<li><a href="#14-principios-solid-para-ml">Principios SOLID para ML</a></li>
<li><a href="#15-ejercicios-prÃ¡cticos">Ejercicios PrÃ¡cticos</a></li>
</ol>
<h2>1.1 Type Hints: Tu Contrato con el Futuro</h2>
<h3>La AnalogÃ­a del Restaurante</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ½ï¸ IMAGINA UN RESTAURANTE:                                               â•‘
â•‘                                                                           â•‘
â•‘  SIN MENÃš (cÃ³digo sin tipos):                                             â•‘
â•‘  - &quot;TrÃ¡eme algo de comer&quot;                                                 â•‘
â•‘  - El chef improvisa                                                      â•‘
â•‘  - El cliente no sabe quÃ© esperar                                         â•‘
â•‘  - Resultado: sorpresas (bugs)                                            â•‘
â•‘                                                                           â•‘
â•‘  CON MENÃš (cÃ³digo con tipos):                                             â•‘
â•‘  - &quot;Quiero el plato #5: Pasta Carbonara&quot;                                  â•‘
â•‘  - El chef sabe exactamente quÃ© preparar                                  â•‘
â•‘  - El cliente sabe quÃ© recibirÃ¡                                           â•‘
â•‘  - Resultado: consistencia                                                â•‘
â•‘                                                                           â•‘
â•‘  TYPE HINTS = El menÃº de tu cÃ³digo                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>CÃ³digo Real del Portafolio: Sin Tipos vs Con Tipos</h3>
<pre><code class="language-python"># âŒ ANTES: Â¿QuÃ© recibe? Â¿QuÃ© retorna? 
# (Esto es lo que encontrarÃ­as en un notebook)

def prepare_features(df, num_cols, cat_cols, target):
    X = df.drop(columns=[target])
    y = df[target]

    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(), cat_cols)
    ])

    X_transformed = preprocessor.fit_transform(X)
    return X_transformed, y, preprocessor
</code></pre>
<pre><code class="language-python"># âœ… DESPUÃ‰S: CÃ³digo real de BankChurn-Predictor/src/bankchurn/training.py

from __future__ import annotations  # Permite usar tipos modernos en Python 3.9+

from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd
from numpy.typing import NDArray
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler

def prepare_features(
    df: pd.DataFrame,
    num_cols: List[str],
    cat_cols: List[str],
    target: str
) -&gt; Tuple[NDArray[np.float64], pd.Series, ColumnTransformer]:
    &quot;&quot;&quot;Prepara features para entrenamiento.

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    num_cols : List[str]
        Nombres de columnas numÃ©ricas.
    cat_cols : List[str]
        Nombres de columnas categÃ³ricas.
    target : str
        Nombre de la columna objetivo.

    Returns
    -------
    Tuple[NDArray, pd.Series, ColumnTransformer]
        Features transformadas, target, y preprocessor fitted.
    &quot;&quot;&quot;
    X = df.drop(columns=[target])
    y = df[target]

    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])

    X_transformed = preprocessor.fit_transform(X)
    return X_transformed, y, preprocessor
</code></pre>
<h3>Los Tipos Esenciales para ML</h3>
<pre><code class="language-python"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS BÃSICOS - Los usarÃ¡s constantemente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import (
    List,       # Lista de elementos: List[str] = [&quot;a&quot;, &quot;b&quot;]
    Dict,       # Diccionario: Dict[str, float] = {&quot;acc&quot;: 0.95}
    Tuple,      # Tupla fija: Tuple[int, int] = (100, 10)
    Optional,   # Puede ser None: Optional[Path] = None
    Union,      # MÃºltiples tipos: Union[str, List[str]]
    Any,        # Cualquier tipo (evitar si posible)
    Literal,    # Valores especÃ­ficos: Literal[&quot;train&quot;, &quot;eval&quot;]
)
from pathlib import Path

# Ejemplos del portafolio real:

# BankChurn: features son listas de strings
features: List[str] = [&quot;CreditScore&quot;, &quot;Age&quot;, &quot;Balance&quot;]

# CarVision: mÃ©tricas son diccionario string-&gt;float
metrics: Dict[str, float] = {&quot;rmse&quot;: 4794.27, &quot;r2&quot;: 0.77}

# TelecomAI: puede recibir path o None
model_path: Optional[Path] = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS PARA ML - EspecÃ­ficos de Machine Learning
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import pandas as pd
import numpy as np
from numpy.typing import NDArray
from sklearn.base import BaseEstimator
from sklearn.pipeline import Pipeline

# DataFrame de pandas
def load_data(path: Path) -&gt; pd.DataFrame:
    return pd.read_csv(path)

# Array NumPy tipado
def predict_proba(X: NDArray[np.float64]) -&gt; NDArray[np.float64]:
    return model.predict_proba(X)[:, 1]

# Modelo sklearn
def train_model(X: NDArray, y: NDArray) -&gt; BaseEstimator:
    model = RandomForestClassifier()
    model.fit(X, y)
    return model

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS AVANZADOS - Para cÃ³digo mÃ¡s robusto
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import TypedDict, Literal

# TypedDict: diccionarios con estructura conocida
class MetricsDict(TypedDict):
    accuracy: float
    precision: float
    recall: float
    f1: float
    roc_auc: float

# Literal: solo valores especÃ­ficos permitidos
ModelType = Literal[&quot;random_forest&quot;, &quot;logistic&quot;, &quot;gradient_boosting&quot;]

def build_model(model_type: ModelType, seed: int) -&gt; BaseEstimator:
    &quot;&quot;&quot;
    mypy SABE que model_type solo puede ser estos 3 valores.
    Si escribes build_model(&quot;xgboost&quot;, 42), mypy darÃ¡ error.
    &quot;&quot;&quot;
    if model_type == &quot;random_forest&quot;:
        return RandomForestClassifier(random_state=seed)
    elif model_type == &quot;logistic&quot;:
        return LogisticRegression(random_state=seed)
    else:  # gradient_boosting
        return GradientBoostingClassifier(random_state=seed)
</code></pre>
<h3>Configurar mypy</h3>
<p>AÃ±ade esto a tu <code>pyproject.toml</code>:</p>
<pre><code class="language-toml"># pyproject.toml - ConfiguraciÃ³n de mypy
[tool.mypy]
python_version = &quot;3.11&quot;
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true      # â† Fuerza tipos en todas las funciones
ignore_missing_imports = true     # â† Para librerÃ­as sin stubs

# Ignorar librerÃ­as de ML que no tienen stubs completos
[[tool.mypy.overrides]]
module = [
    &quot;sklearn.*&quot;,
    &quot;pandas.*&quot;, 
    &quot;numpy.*&quot;,
    &quot;mlflow.*&quot;,
    &quot;joblib.*&quot;,
]
ignore_missing_imports = true
</code></pre>
<p>Ejecutar:</p>
<pre><code class="language-bash">mypy src/  # Verifica tipos en todo el cÃ³digo
</code></pre>
<h2>1.2 Pydantic: ValidaciÃ³n AutomÃ¡tica</h2>
<h3>La AnalogÃ­a del Guardia de Seguridad</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ›¡ï¸ IMAGINA UN EDIFICIO DE OFICINAS:                                      â•‘
â•‘                                                                           â•‘
â•‘  SIN GUARDIA (cÃ³digo sin Pydantic):                                       â•‘
â•‘  - Cualquiera entra con cualquier cosa                                    â•‘
â•‘  - Descubres problemas CUANDO YA PASARON                                  â•‘
â•‘  - &quot;Â¿Por quÃ© hay un test_size de 1.5?&quot; â†’ Error en producciÃ³n              â•‘
â•‘                                                                           â•‘
â•‘  CON GUARDIA (cÃ³digo con Pydantic):                                       â•‘
â•‘  - Verifica credenciales EN LA ENTRADA                                    â•‘
â•‘  - Problemas detectados ANTES de causar daÃ±o                              â•‘
â•‘  - &quot;test_size debe ser entre 0 y 1&quot; â†’ Error inmediato y claro             â•‘
â•‘                                                                           â•‘
â•‘  PYDANTIC = El guardia de tu configuraciÃ³n                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>CÃ³digo Real: BankChurn Config (Nivel Staff)</h3>
<p>Este es el archivo <code>src/bankchurn/config.py</code> del portafolio:</p>
<pre><code class="language-python">&quot;&quot;&quot;Configuration management for BankChurn predictor.

Este mÃ³dulo demuestra Pydantic a nivel profesional:
- ValidaciÃ³n de rangos con Field
- Configuraciones anidadas
- Valores por defecto sensatos
- Carga desde YAML
&quot;&quot;&quot;

from __future__ import annotations

from pathlib import Path
from typing import Any, List

import yaml
from pydantic import BaseModel, Field


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIONES ANIDADAS - Cada componente tiene su propia config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LogisticRegressionConfig(BaseModel):
    &quot;&quot;&quot;HiperparÃ¡metros de Logistic Regression.&quot;&quot;&quot;
    C: float = 0.1
    class_weight: str = &quot;balanced&quot;
    solver: str = &quot;liblinear&quot;
    max_iter: int = 1000


class RandomForestConfig(BaseModel):
    &quot;&quot;&quot;HiperparÃ¡metros de Random Forest.&quot;&quot;&quot;
    n_estimators: int = 100
    max_depth: int = 10
    min_samples_split: int = 10
    min_samples_leaf: int = 5
    class_weight: str = &quot;balanced_subsample&quot;
    n_jobs: int = -1


class EnsembleConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n del ensemble.&quot;&quot;&quot;
    voting: str = Field(&quot;soft&quot;, pattern=&quot;^(hard|soft)$&quot;)  # â† Solo permite &quot;hard&quot; o &quot;soft&quot;
    weights: List[float] = [0.4, 0.6]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N PRINCIPAL - Agrupa todo con validaciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ModelConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n de entrenamiento del modelo.&quot;&quot;&quot;
    type: str = &quot;ensemble&quot;
    test_size: float = Field(0.2, ge=0.0, le=1.0)   # â† VALIDACIÃ“N: entre 0 y 1
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)                   # â† VALIDACIÃ“N: mÃ­nimo 2
    resampling_strategy: str = &quot;none&quot;

    # Configuraciones de modelos especÃ­ficos (anidadas)
    ensemble: EnsembleConfig = EnsembleConfig()
    logistic_regression: LogisticRegressionConfig = LogisticRegressionConfig()
    random_forest: RandomForestConfig = RandomForestConfig()


class DataConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n de datos.&quot;&quot;&quot;
    target_column: str = &quot;Exited&quot;
    categorical_features: List[str] = []
    numerical_features: List[str] = []
    drop_columns: List[str] = []


class MLflowConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n de MLflow tracking.&quot;&quot;&quot;
    tracking_uri: str = &quot;file:./mlruns&quot;
    experiment_name: str = &quot;bankchurn&quot;
    enabled: bool = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N RAÃZ - El punto de entrada
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BankChurnConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n completa de BankChurn.

    Uso:
        config = BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)
        print(config.model.test_size)  # 0.2
    &quot;&quot;&quot;
    model: ModelConfig
    data: DataConfig
    mlflow: MLflowConfig

    @classmethod
    def from_yaml(cls, config_path: str | Path) -&gt; BankChurnConfig:
        &quot;&quot;&quot;Carga configuraciÃ³n desde archivo YAML.

        Parameters
        ----------
        config_path : str or Path
            Ruta al archivo YAML.

        Returns
        -------
        BankChurnConfig
            ConfiguraciÃ³n validada.

        Raises
        ------
        FileNotFoundError
            Si el archivo no existe.
        ValidationError
            Si la configuraciÃ³n es invÃ¡lida.
        &quot;&quot;&quot;
        config_path = Path(config_path)

        if not config_path.exists():
            raise FileNotFoundError(f&quot;Config file not found: {config_path}&quot;)

        with open(config_path, &quot;r&quot;) as f:
            config_dict = yaml.safe_load(f) or {}

        # Valores por defecto para secciones faltantes
        if &quot;model&quot; not in config_dict:
            config_dict[&quot;model&quot;] = ModelConfig().dict()
        if &quot;data&quot; not in config_dict:
            config_dict[&quot;data&quot;] = DataConfig().dict()
        if &quot;mlflow&quot; not in config_dict:
            config_dict[&quot;mlflow&quot;] = MLflowConfig().dict()

        return cls(**config_dict)  # â† Pydantic valida automÃ¡ticamente
</code></pre>
<h3>El YAML Correspondiente</h3>
<pre><code class="language-yaml"># configs/config.yaml
model:
  type: ensemble
  test_size: 0.2         # Si pones 1.5, Pydantic darÃ¡ error
  random_state: 42
  cv_folds: 5            # Si pones 1, Pydantic darÃ¡ error
  resampling_strategy: none

  ensemble:
    voting: soft         # Si pones &quot;maybe&quot;, Pydantic darÃ¡ error
    weights: [0.4, 0.6]

  random_forest:
    n_estimators: 200
    max_depth: 10

data:
  target_column: Exited
  categorical_features:
    - Geography
    - Gender
  numerical_features:
    - CreditScore
    - Age
    - Balance
  drop_columns:
    - RowNumber
    - CustomerId
    - Surname

mlflow:
  tracking_uri: &quot;file:./mlruns&quot;
  experiment_name: bankchurn
  enabled: true
</code></pre>
<h3>Ejemplo de Error de ValidaciÃ³n</h3>
<pre><code class="language-python"># âŒ Esto FALLA inmediatamente con un error claro

config_dict = {
    &quot;model&quot;: {
        &quot;test_size&quot;: 1.5,  # â† Error: debe ser &lt;= 1.0
        &quot;cv_folds&quot;: 1,     # â† Error: debe ser &gt;= 2
    },
    &quot;data&quot;: {},
    &quot;mlflow&quot;: {}
}

try:
    config = BankChurnConfig(**config_dict)
except ValidationError as e:
    print(e)
    # Output:
    # 2 validation errors for BankChurnConfig
    # model -&gt; test_size
    #   ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
    # model -&gt; cv_folds
    #   ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)
</code></pre>
<h2>1.3 src/ Layout: Estructura Profesional</h2>
<h3>La AnalogÃ­a de la Casa</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ  IMAGINA ORGANIZAR UNA CASA:                                           â•‘
â•‘                                                                           â•‘
â•‘  CASA DESORDENADA (cÃ³digo en raÃ­z):                                       â•‘
â•‘  - Todo en el living: ropa, comida, herramientas                          â•‘
â•‘  - Imposible encontrar algo                                               â•‘
â•‘  - Invitas a alguien: &quot;perdÃ³n por el desorden&quot;                            â•‘
â•‘                                                                           â•‘
â•‘  CASA ORGANIZADA (src/ layout):                                           â•‘
â•‘  - Cocina para cocinar, baÃ±o para baÃ±o, closet para ropa                  â•‘
â•‘  - Cada cosa en su lugar                                                  â•‘
â•‘  - Invitas a alguien: &quot;bienvenido, siÃ©ntate&quot;                              â•‘
â•‘                                                                           â•‘
â•‘  src/ layout = OrganizaciÃ³n profesional de cÃ³digo                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Estructura del Portafolio</h3>
<pre><code>BankChurn-Predictor/
â”œâ”€â”€ src/                          # â† TODO el cÃ³digo fuente aquÃ­
â”‚   â”œâ”€â”€ __init__.py               # Hace src/ un paquete
â”‚   â””â”€â”€ bankchurn/                # â† El paquete principal
â”‚       â”œâ”€â”€ __init__.py           # Exporta la API pÃºblica
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ training.py           # Pipeline de entrenamiento
â”‚       â”œâ”€â”€ evaluation.py         # MÃ©tricas y evaluaciÃ³n
â”‚       â”œâ”€â”€ prediction.py         # Inferencia
â”‚       â”œâ”€â”€ models.py             # Custom classifiers
â”‚       â””â”€â”€ cli.py                # Interfaz de lÃ­nea de comandos
â”‚
â”œâ”€â”€ app/                          # â† Aplicaciones (no es un paquete)
â”‚   â””â”€â”€ fastapi_app.py            # API REST
â”‚
â”œâ”€â”€ tests/                        # â† Tests (espejo de src/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidas
â”‚   â”œâ”€â”€ test_config.py            # Tests para config.py
â”‚   â”œâ”€â”€ test_training.py          # Tests para training.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ configs/                      # â† ConfiguraciÃ³n externa
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/                         # â† Datos (gitignored)
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ Churn_Modelling.csv
â”‚
â”œâ”€â”€ artifacts/                    # â† Artefactos generados (gitignored)
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ training_results.json
â”‚
â”œâ”€â”€ pyproject.toml                # â† Metadata del proyecto
â”œâ”€â”€ Makefile                      # â† Comandos comunes
â”œâ”€â”€ Dockerfile                    # â† ContainerizaciÃ³n
â””â”€â”€ README.md                     # â† DocumentaciÃ³n
</code></pre>
<h3>Â¿Por quÃ© src/ y no cÃ³digo en la raÃ­z?</h3>
<pre><code class="language-python"># âŒ PROBLEMA: Sin src/, Python puede importar cÃ³digo no instalado
# Esto causa el famoso &quot;funciona en mi mÃ¡quina pero no en CI&quot;

# Estructura plana (problemÃ¡tica):
# myproject/
# â”œâ”€â”€ mymodule.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
import mymodule  # â† Â¿De dÃ³nde viene? Â¿Del directorio actual? Â¿De pip?

# âœ… SOLUCIÃ“N: Con src/, el cÃ³digo DEBE estar instalado para importar
# myproject/
# â”œâ”€â”€ src/
# â”‚   â””â”€â”€ mymodule/
# â”‚       â””â”€â”€ __init__.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
from mymodule import something  # â† Solo funciona si `pip install -e .`
</code></pre>
<h3>pyproject.toml: El CorazÃ³n del Proyecto</h3>
<pre><code class="language-toml"># pyproject.toml - ConfiguraciÃ³n completa del proyecto
[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;bankchurn&quot;
version = &quot;1.0.0&quot;
description = &quot;Bank Customer Churn Prediction System&quot;
authors = [
    {name = &quot;Daniel Duque&quot;, email = &quot;duque@example.com&quot;}
]
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.10&quot;
license = {text = &quot;MIT&quot;}

dependencies = [
    &quot;pandas&gt;=2.0.0&quot;,
    &quot;scikit-learn&gt;=1.3.0&quot;,
    &quot;pydantic&gt;=2.0.0&quot;,
    &quot;pyyaml&gt;=6.0&quot;,
    &quot;mlflow&gt;=2.9.0&quot;,
    &quot;fastapi&gt;=0.104.0&quot;,
    &quot;uvicorn&gt;=0.24.0&quot;,
]

[project.optional-dependencies]
dev = [
    &quot;pytest&gt;=7.4.0&quot;,
    &quot;pytest-cov&gt;=4.1.0&quot;,
    &quot;black&gt;=23.0.0&quot;,
    &quot;mypy&gt;=1.7.0&quot;,
    &quot;ruff&gt;=0.1.0&quot;,
]

[project.scripts]
bankchurn = &quot;bankchurn.cli:main&quot;  # â† Comando CLI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.setuptools.packages.find]
where = [&quot;src&quot;]  # â† Busca paquetes en src/

[tool.pytest.ini_options]
testpaths = [&quot;tests&quot;]
python_files = [&quot;test_*.py&quot;]
addopts = &quot;-v --cov=src/bankchurn --cov-report=term-missing&quot;

[tool.coverage.run]
source = [&quot;src&quot;]
omit = [&quot;tests/*&quot;]

[tool.coverage.report]
fail_under = 79  # â† Coverage mÃ­nimo para pasar CI

[tool.black]
line-length = 100
target-version = [&quot;py311&quot;]

[tool.mypy]
python_version = &quot;3.11&quot;
warn_return_any = true
disallow_untyped_defs = true
ignore_missing_imports = true
</code></pre>
<h3>InstalaciÃ³n en Modo Editable</h3>
<pre><code class="language-bash"># Instalar el paquete en modo editable (para desarrollo)
pip install -e .

# Ahora puedes importar desde cualquier lugar
python -c &quot;from bankchurn.config import BankChurnConfig; print('âœ… Funciona!')&quot;

# Y los tests tambiÃ©n funcionan
pytest tests/
</code></pre>
<h2>1.4 Principios SOLID para ML</h2>
<h3>Single Responsibility: Un MÃ³dulo, Una Tarea</h3>
<pre><code class="language-python"># âŒ ANTES: Un archivo hace TODO
# training.py (500 lÃ­neas)
def train_model(data_path, config_path, output_path):
    # Carga datos (lÃ­neas 1-50)
    # Limpia datos (lÃ­neas 51-100)
    # Feature engineering (lÃ­neas 101-200)
    # Entrena modelo (lÃ­neas 201-300)
    # EvalÃºa modelo (lÃ­neas 301-400)
    # Guarda artefactos (lÃ­neas 401-450)
    # Loguea a MLflow (lÃ­neas 451-500)
    pass

# âœ… DESPUÃ‰S: Cada archivo tiene UNA responsabilidad
# src/bankchurn/
# â”œâ”€â”€ data.py         â†’ Solo carga y valida datos
# â”œâ”€â”€ features.py     â†’ Solo feature engineering
# â”œâ”€â”€ training.py     â†’ Solo entrenamiento
# â”œâ”€â”€ evaluation.py   â†’ Solo mÃ©tricas
# â””â”€â”€ prediction.py   â†’ Solo inferencia
</code></pre>
<h3>CÃ³digo Real del Portafolio</h3>
<pre><code class="language-python"># src/bankchurn/training.py - SOLO se encarga de entrenar
class ChurnTrainer:
    &quot;&quot;&quot;Training pipeline - Single Responsibility.&quot;&quot;&quot;

    def __init__(self, config: BankChurnConfig):
        self.config = config

    def load_data(self, path: Path) -&gt; pd.DataFrame:
        &quot;&quot;&quot;Delega a mÃ³dulo de datos.&quot;&quot;&quot;
        pass

    def prepare_features(self, df: pd.DataFrame) -&gt; Tuple[pd.DataFrame, pd.Series]:
        &quot;&quot;&quot;Prepara X e y.&quot;&quot;&quot;
        pass

    def build_pipeline(self) -&gt; Pipeline:
        &quot;&quot;&quot;Construye el pipeline sklearn.&quot;&quot;&quot;
        pass

    def fit(self, X: pd.DataFrame, y: pd.Series) -&gt; None:
        &quot;&quot;&quot;Entrena el modelo.&quot;&quot;&quot;
        pass

    def cross_validate(self, X: pd.DataFrame, y: pd.Series) -&gt; Dict[str, float]:
        &quot;&quot;&quot;Valida con CV.&quot;&quot;&quot;
        pass

# src/bankchurn/evaluation.py - SOLO se encarga de evaluar
def evaluate_model(
    model: Pipeline,
    X_test: pd.DataFrame,
    y_test: pd.Series
) -&gt; Dict[str, float]:
    &quot;&quot;&quot;Calcula mÃ©tricas - Single Responsibility.&quot;&quot;&quot;
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    return {
        &quot;accuracy&quot;: accuracy_score(y_test, y_pred),
        &quot;precision&quot;: precision_score(y_test, y_pred),
        &quot;recall&quot;: recall_score(y_test, y_pred),
        &quot;f1&quot;: f1_score(y_test, y_pred),
        &quot;roc_auc&quot;: roc_auc_score(y_test, y_proba),
    }
</code></pre>
<h2>1.5 Ejercicios PrÃ¡cticos</h2>
<h3>Ejercicio 1: AÃ±adir Type Hints</h3>
<pre><code class="language-python"># âŒ CÃ³digo sin tipos (tÃ­pico de notebook)
# Tu tarea: AÃ±ade type hints completos

def process_training_data(df, config):
    target = config[&quot;target&quot;]
    features = config[&quot;features&quot;]

    X = df[features]
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.get(&quot;test_size&quot;, 0.2)
    )

    return X_train, X_test, y_train, y_test


def calculate_metrics(y_true, y_pred):
    return {
        &quot;accuracy&quot;: accuracy_score(y_true, y_pred),
        &quot;f1&quot;: f1_score(y_true, y_pred)
    }
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python">from typing import Dict, List, Tuple, Any
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score


def process_training_data(
    df: pd.DataFrame,
    config: Dict[str, Any]
) -&gt; Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    &quot;&quot;&quot;Procesa datos para entrenamiento.

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    config : Dict[str, Any]
        ConfiguraciÃ³n con keys: &quot;target&quot;, &quot;features&quot;, &quot;test_size&quot; (opcional).

    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]
        X_train, X_test, y_train, y_test
    &quot;&quot;&quot;
    target: str = config[&quot;target&quot;]
    features: List[str] = config[&quot;features&quot;]

    X: pd.DataFrame = df[features]
    y: pd.Series = df[target]

    test_size: float = config.get(&quot;test_size&quot;, 0.2)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )

    return X_train, X_test, y_train, y_test


def calculate_metrics(
    y_true: pd.Series,
    y_pred: pd.Series
) -&gt; Dict[str, float]:
    &quot;&quot;&quot;Calcula mÃ©tricas de clasificaciÃ³n.

    Parameters
    ----------
    y_true : pd.Series
        Labels verdaderos.
    y_pred : pd.Series
        Predicciones del modelo.

    Returns
    -------
    Dict[str, float]
        Diccionario con accuracy y f1.
    &quot;&quot;&quot;
    return {
        &quot;accuracy&quot;: float(accuracy_score(y_true, y_pred)),
        &quot;f1&quot;: float(f1_score(y_true, y_pred))
    }
</code></pre>


</details>

<h3>Ejercicio 2: Crear Config con Pydantic</h3>
<pre><code class="language-python"># Tu tarea: Crea una configuraciÃ³n Pydantic para TelecomAI
# Requisitos:
# - project_name: str
# - random_seed: int (entre 0 y 1000)
# - test_size: float (entre 0.1 y 0.5)
# - model_type: solo puede ser &quot;logreg&quot;, &quot;random_forest&quot;, o &quot;gradient_boosting&quot;
# - features: lista de strings
# - target: str

# Escribe tu cÃ³digo aquÃ­:
from pydantic import BaseModel, Field
from typing import List, Literal

class TelecomConfig(BaseModel):
    # ... tu cÃ³digo
    pass
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python">from pydantic import BaseModel, Field
from typing import List, Literal, Optional, Dict, Any
from pathlib import Path
import yaml


class TelecomConfig(BaseModel):
    &quot;&quot;&quot;ConfiguraciÃ³n para TelecomAI Customer Intelligence.&quot;&quot;&quot;

    project_name: str = Field(..., min_length=1)
    random_seed: int = Field(42, ge=0, le=1000)
    test_size: float = Field(0.2, ge=0.1, le=0.5)
    model_type: Literal[&quot;logreg&quot;, &quot;random_forest&quot;, &quot;gradient_boosting&quot;] = &quot;logreg&quot;
    features: List[str] = Field(..., min_items=1)
    target: str

    # Opcionales
    threshold: float = Field(0.5, ge=0.0, le=1.0)
    mlflow_enabled: bool = True

    @classmethod
    def from_yaml(cls, path: str | Path) -&gt; &quot;TelecomConfig&quot;:
        with open(path) as f:
            data = yaml.safe_load(f)
        return cls(**data)

    class Config:
        extra = &quot;forbid&quot;  # No permite campos extra en el YAML


# Uso:
config = TelecomConfig(
    project_name=&quot;TelecomAI&quot;,
    features=[&quot;calls&quot;, &quot;minutes&quot;, &quot;messages&quot;, &quot;mb_used&quot;],
    target=&quot;is_ultra&quot;
)

# Esto FALLA:
# config = TelecomConfig(
#     project_name=&quot;&quot;,  # Error: min_length=1
#     test_size=0.8,    # Error: le=0.5
#     model_type=&quot;xgboost&quot;,  # Error: not in Literal
#     features=[],      # Error: min_items=1
# )
</code></pre>


</details>

<h3>Ejercicio 3: Convertir a src/ Layout</h3>
<pre><code>Tu tarea: Reorganiza esta estructura plana a src/ layout

ANTES:
myproject/
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ data.csv
â””â”€â”€ test_train.py

DESPUÃ‰S:
myproject/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ???
â””â”€â”€ pyproject.toml
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code>myproject/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ myproject/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ training.py      # Antes: train.py
â”‚       â”œâ”€â”€ prediction.py    # Antes: predict.py
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Fixtures compartidas
â”‚   â””â”€â”€ test_training.py     # Antes: test_train.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ data.csv
â”œâ”€â”€ artifacts/               # Para modelos generados
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
</code></pre>


 </details>

<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos</h2>
<p>En este mÃ³dulo suelen aparecer siempre los mismos problemas. La idea no es solo evitarlos, sino <strong>saber reconocerlos rÃ¡pido</strong> en tus propios proyectos.</p>
<h3>1) Type hints + mypy: errores ruidosos en pandas/sklearn</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>Function is missing a type annotation for parameter 'df'</code></li>
<li><code>Incompatible return value type (got "DataFrame", expected "Series")</code></li>
<li>Cientos de warnings en librerÃ­as externas (<code>pandas.*</code>, <code>sklearn.*</code>).</li>
</ul>
<p><strong>Proceso para identificarlos</strong></p>
<ul>
<li>Ejecuta siempre:<br />
<code>bash
  mypy src/  # o mypy src/bankchurn src/carvision src/telecomai</code></li>
<li>Localiza primero los errores <strong>en tu cÃ³digo</strong> (archivos dentro de <code>src/</code>), ignora de momento los de librerÃ­as.</li>
<li>Si ves muchos errores en <code>site-packages</code> o mÃ³dulos externos, revisa tu secciÃ³n <code>[tool.mypy]</code> del <code>pyproject.toml</code> (ver ejemplo en este mismo mÃ³dulo).</li>
</ul>
<p><strong>CÃ³mo solucionarlos (patrÃ³n general)</strong></p>
<ul>
<li>AÃ±ade tipos a <strong>todas las firmas pÃºblicas</strong> (funciones/clases usadas fuera de su archivo).</li>
<li>Usa tipos especÃ­ficos para ML:</li>
<li><code>pd.DataFrame</code>, <code>pd.Series</code></li>
<li><code>NDArray[np.float64]</code></li>
<li><code>BaseEstimator</code>, <code>Pipeline</code></li>
<li>AÃ­sla tipos muy complejos usando <code>TypedDict</code> o <code>Alias</code>:<br />
<code>python
  class MetricsDict(TypedDict):
      accuracy: float
      f1: float
      roc_auc: float</code></li>
<li>Para <strong>reducir ruido de mypy</strong> con librerÃ­as ML:</li>
<li>Configura <code>ignore_missing_imports = true</code> y los overrides mostrados en este mÃ³dulo.</li>
<li>Re-lanza <code>mypy</code> y verifica que solo quedan errores en tu cÃ³digo.</li>
</ul>
<blockquote>
<p>ğŸ’¡ <strong>Regla prÃ¡ctica</strong>: si mypy empieza a gritar en medio de un refactor, reduce el problema a una funciÃ³n pequeÃ±a, tipa bien esa funciÃ³n, y despuÃ©s propaga los tipos al resto.</p>
</blockquote>
<h3>2) Pydantic: <code>ValidationError</code> por config mal definida</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Al cargar la configuraciÃ³n:<br />
<code>text
  pydantic.error_wrappers.ValidationError: 2 validation errors for ModelConfig
  model -&gt; test_size
    ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
  model -&gt; cv_folds
    ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)</code></li>
<li>Tu servicio/API no arranca porque falla la lectura de <code>config.yaml</code>.</li>
</ul>
<p><strong>Proceso para identificarlos</strong></p>
<ul>
<li>Localiza <strong>quÃ© modelo Pydantic</strong> estÃ¡ fallando (<code>ModelConfig</code>, <code>BankChurnConfig</code>, <code>TelecomConfig</code>, etc.).</li>
<li>Revisa el <code>traceback</code>: casi siempre indica <strong>la ruta completa del campo</strong> (<code>model -&gt; test_size</code>, <code>data -&gt; categorical_features</code>, etc.).</li>
<li>Abre el YAML correspondiente (<code>configs/config.yaml</code>) y compara <strong>valor real</strong> vs <strong>restricciÃ³n en <code>Field(...)</code></strong>.</li>
</ul>
<p><strong>CÃ³mo solucionarlos (patrÃ³n general)</strong></p>
<ul>
<li>Ajusta el YAML para respetar los rangos:</li>
<li><code>test_size</code> entre <code>0.0</code> y <code>1.0</code>.</li>
<li><code>cv_folds</code> â‰¥ 2.</li>
<li>Literales vÃ¡lidos (<code>voting: "hard" | "soft"</code>, <code>model_type: "logreg" | "random_forest" | ...</code>).</li>
<li>Si el error te parece injustificado, revisa la declaraciÃ³n del modelo:<br />
<code>python
  test_size: float = Field(0.2, ge=0.0, le=1.0)</code><br />
  QuizÃ¡ necesitas permitir un rango distinto en tu contexto.</li>
<li>En desarrollo, <strong>falla rÃ¡pido</strong>: no atrapes el <code>ValidationError</code> salvo para mostrar un mensaje mÃ¡s amigable; deja que la app se caiga antes que usar una config corrupta.</li>
</ul>
<blockquote>
<p>ğŸ”§ <strong>Ejercicio mental</strong>: rompe a propÃ³sito tu <code>configs/config.yaml</code> (pon <code>test_size: 1.5</code>) y observa el error. Luego arrÃ©glalo. Hazlo una vez y nunca mÃ¡s te asustarÃ¡ un <code>ValidationError</code> en producciÃ³n.</p>
</blockquote>
<h3>3) src/ layout e imports: <code>ModuleNotFoundError</code> en CI pero no en tu mÃ¡quina</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En local â€œtodo funcionaâ€, pero en GitHub Actions o en otra mÃ¡quina obtienes:<br />
<code>text
  ModuleNotFoundError: No module named 'bankchurn'</code></li>
<li>Los tests solo pasan si ejecutas <code>pytest</code> desde la raÃ­z exacta del proyecto.</li>
</ul>
<p><strong>Proceso para identificarlos</strong></p>
<ul>
<li>Revisa la <strong>estructura</strong> de tu proyecto (deberÃ­a parecerse al diagrama de este mÃ³dulo):</li>
<li>CÃ³digo dentro de <code>src/&lt;paquete&gt;/</code>.</li>
<li>Tests bajo <code>tests/</code> usando imports del paquete, no rutas relativas raras.</li>
<li>Verifica tu <code>pyproject.toml</code>:</li>
<li><code>[project.name]</code> coincide con el paquete (<code>bankchurn</code>, <code>carvision</code>, <code>telecomai</code>).</li>
<li><code>[tool.setuptools.packages.find] where = ["src"]</code>.</li>
<li>Comprueba si instalaste en modo editable:<br />
<code>bash
  pip install -e .
  python -c "import bankchurn; print(bankchurn.__file__)"</code></li>
</ul>
<p><strong>CÃ³mo solucionarlos (patrÃ³n general)</strong></p>
<ul>
<li>Mueve el cÃ³digo de raÃ­z a <code>src/</code> siguiendo el ejemplo de este mÃ³dulo.</li>
<li>Cambia imports tipo:<br />
<code>python
  # âŒ from .training import train_model  (desde scripts sueltos)
  # âœ… from bankchurn.training import train_model</code></li>
<li>AsegÃºrate de que los comandos de CI usan instalaciÃ³n editable:<br />
  ```yaml</li>
<li>name: Install<br />
    run: pip install -e ".[dev]"<br />
  ```</li>
</ul>
<blockquote>
<p>âš ï¸ <strong>Bandera roja</strong>: si tus tests solo funcionan cuando haces <code>cd src</code> o ajustas manualmente <code>PYTHONPATH</code>, tu layout todavÃ­a no estÃ¡ bien resuelto.</p>
</blockquote>
<h3>4) PatrÃ³n general de debugging para este mÃ³dulo</h3>
<ol>
<li><strong>Reproduce el error</strong> con un comando simple y determinista:</li>
<li><code>mypy src/</code></li>
<li><code>python -m src.proyecto.training</code></li>
<li><code>pytest -k nombre_test</code>.</li>
<li><strong>Lee literalmente</strong> el mensaje de error (campo, valor, restricciÃ³n).</li>
<li><strong>Conecta el error con el concepto del mÃ³dulo</strong>:</li>
<li>Type hints â†’ firma de funciÃ³n o tipo de retorno.</li>
<li>Pydantic â†’ <code>Field(...)</code> y YAML.</li>
<li>src/ layout â†’ estructura de carpetas + <code>pyproject.toml</code> + instalaciÃ³n editable.</li>
<li><strong>Aplica el patrÃ³n de soluciÃ³n</strong> que viste arriba.</li>
</ol>
<p>Si automatizas este ciclo en tus tres proyectos del portafolio, tu tiempo de debugging se reduce drÃ¡sticamente y es justo lo que se espera de un perfil Senior/Staff.</p>
<h2>âœ… Checkpoint: Â¿Completaste el MÃ³dulo?</h2>
<p>Antes de continuar, verifica:</p>
<ul>
<li>[ ] Tu cÃ³digo tiene type hints en todas las funciones</li>
<li>[ ] Puedes ejecutar <code>mypy src/</code> sin errores crÃ­ticos</li>
<li>[ ] Tienes al menos una clase Pydantic para configuraciÃ³n</li>
<li>[ ] Tu proyecto tiene estructura src/ layout</li>
<li>[ ] Puedes instalar tu paquete con <code>pip install -e .</code></li>
</ul>
<h2>ğŸ”— ADR: Â¿Por QuÃ© Estas Decisiones?</h2>
<h3>ADR-001: Type Hints Obligatorios</h3>
<p><strong>Contexto</strong>: El cÃ³digo de ML suele ser difÃ­cil de mantener porque las funciones aceptan "cualquier cosa".</p>
<p><strong>DecisiÃ³n</strong>: Requerimos type hints en todas las funciones pÃºblicas.</p>
<p><strong>Consecuencias</strong>:<br />
- âœ… El IDE autocompleta correctamente<br />
- âœ… Errores detectados antes de ejecutar<br />
- âœ… DocumentaciÃ³n implÃ­cita<br />
- âŒ MÃ¡s cÃ³digo que escribir inicialmente<br />
- âŒ Curva de aprendizaje para tipos complejos</p>
<h3>ADR-002: Pydantic para ConfiguraciÃ³n</h3>
<p><strong>Contexto</strong>: Configuraciones en diccionarios son propensas a errores.</p>
<p><strong>DecisiÃ³n</strong>: Toda configuraciÃ³n pasa por Pydantic.</p>
<p><strong>Consecuencias</strong>:<br />
- âœ… ValidaciÃ³n automÃ¡tica<br />
- âœ… Errores claros<br />
- âœ… DocumentaciÃ³n de la config<br />
- âŒ Dependencia adicional<br />
- âŒ MÃ¡s verboso que un dict simple</p>
<h3>ADR-003: src/ Layout</h3>
<p><strong>Contexto</strong>: CÃ³digo en raÃ­z causa problemas de importaciÃ³n.</p>
<p><strong>DecisiÃ³n</strong>: Todo cÃ³digo en <code>src/&lt;paquete&gt;/</code>.</p>
<p><strong>Consecuencias</strong>:<br />
- âœ… Importaciones consistentes<br />
- âœ… Funciona igual en desarrollo y CI<br />
- âœ… EstÃ¡ndar de la industria<br />
- âŒ Requiere <code>pip install -e .</code><br />
- âŒ Path mÃ¡s largo para imports</p>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>Este mÃ³dulo se aplica <strong>directamente</strong> en los 3 proyectos del portafolio. AquÃ­ estÃ¡n los archivos reales que implementan cada concepto:</p>
<h3>Type Hints en el Portafolio</h3>
<pre><code class="language-python"># BankChurn-Predictor/src/bankchurn/config.py (lÃ­neas 89-109)
@classmethod
def from_yaml(cls, config_path: str | Path) -&gt; BankChurnConfig:
    &quot;&quot;&quot;Load configuration from YAML file.

    Parameters
    ----------
    config_path : str or Path
        Path to YAML configuration file.

    Returns
    -------
    config : BankChurnConfig
        Validated configuration object.
    &quot;&quot;&quot;
</code></pre>
<h3>Pydantic en el Portafolio</h3>
<p>Cada proyecto tiene su configuraciÃ³n Pydantic:</p>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Archivo</th>
<th>Clases principales</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>src/bankchurn/config.py</code></td>
<td><code>BankChurnConfig</code>, <code>ModelConfig</code>, <code>DataConfig</code></td>
</tr>
<tr>
<td>CarVision</td>
<td><code>src/carvision/config.py</code></td>
<td><code>CarVisionConfig</code>, <code>FiltersConfig</code></td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>src/telecomai/config.py</code></td>
<td><code>TelecomConfig</code></td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># Ejemplo real: BankChurn-Predictor/src/bankchurn/config.py
class ModelConfig(BaseModel):
    &quot;&quot;&quot;Model training configuration.&quot;&quot;&quot;
    type: str = &quot;ensemble&quot;
    test_size: float = Field(0.2, ge=0.0, le=1.0)  # â† ValidaciÃ³n automÃ¡tica
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)  # â† MÃ­nimo 2 folds
</code></pre>
<h3>src/ Layout en el Portafolio</h3>
<p>Los 3 proyectos siguen exactamente la estructura descrita:</p>
<pre><code>BankChurn-Predictor/
â”œâ”€â”€ src/bankchurn/       â† Paquete instalable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py        â† Pydantic configs
â”‚   â”œâ”€â”€ pipeline.py      â† sklearn Pipeline
â”‚   â””â”€â”€ trainer.py       â† Clase de entrenamiento
â”œâ”€â”€ pyproject.toml       â† Metadata y dependencias
â””â”€â”€ setup.py             â† Fallback para pip install -e .
</code></pre>
<h3>ğŸ”§ Ejercicio: Verifica en el Repo Real</h3>
<pre><code class="language-bash"># 1. Ve al proyecto BankChurn
cd BankChurn-Predictor

# 2. Instala en modo editable
pip install -e &quot;.[dev]&quot;

# 3. Verifica tipos con mypy
mypy src/bankchurn/config.py

# 4. Prueba que Pydantic valida correctamente
python -c &quot;from bankchurn.config import BankChurnConfig; print(BankChurnConfig.from_yaml('configs/config.yaml'))&quot;
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Domina Type Hints</strong>: Los entrevistadores valoran cÃ³digo tipado. Practica explicar por quÃ© <code>def process(data: pd.DataFrame) -&gt; Dict[str, float]</code> es mejor que <code>def process(data)</code>.</p>
</li>
<li>
<p><strong>Conoce Pydantic vs Dataclasses</strong>: Pregunta comÃºn: "Â¿CuÃ¡ndo usarÃ­as uno u otro?" Respuesta: Pydantic para validaciÃ³n de datos externos (APIs, configs), dataclasses para estructuras internas simples.</p>
</li>
<li>
<p><strong>Demuestra comprensiÃ³n de <code>__init__.py</code></strong>: Explica cÃ³mo controla la API pÃºblica de un paquete y por quÃ© <code>from package import *</code> es peligroso.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>CÃ³digo legacy sin tipos</td>
<td>AÃ±ade tipos gradualmente, empezando por funciones pÃºblicas</td>
</tr>
<tr>
<td>ValidaciÃ³n de configs</td>
<td>Usa Pydantic con <code>model_validator</code> para validaciones cruzadas</td>
</tr>
<tr>
<td>Logs en producciÃ³n</td>
<td>Usa <code>structlog</code> o <code>loguru</code> en lugar de <code>print()</code></td>
</tr>
<tr>
<td>Errores en producciÃ³n</td>
<td>Implementa excepciones personalizadas con contexto Ãºtil</td>
</tr>
</tbody>
</table>
<h3>Anti-patrones a Evitar</h3>
<ul>
<li>âŒ <code>from typing import *</code> â€” importa solo lo que necesitas</li>
<li>âŒ <code>except Exception:</code> sin logging â€” siempre registra el error</li>
<li>âŒ Funciones de mÃ¡s de 50 lÃ­neas â€” refactoriza en funciones mÃ¡s pequeÃ±as</li>
<li>âŒ Nombres como <code>data</code>, <code>info</code>, <code>result</code> â€” usa nombres descriptivos</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=dgBCEB2jVU0">Type Hints - ArjanCodes</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=502XOB0u8OY">Pydantic V2 Tutorial</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://realpython.com/python-type-checking/">Python Type Checking - Real Python</a></td>
<td style="text-align: left;">Tutorial</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://peps.python.org/pep-0484/">PEP 484 â€“ Type Hints</a><br />
- <a href="https://docs.pydantic.dev/">Pydantic Documentation</a><br />
- <a href="https://packaging.python.org/">Python Packaging Guide</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Type Hints</strong>: Anotaciones de tipos en Python<br />
- <strong>Pydantic</strong>: ValidaciÃ³n de datos con type hints<br />
- <strong>src/ Layout</strong>: Estructura de proyecto profesional</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 01:<br />
- <strong>1.1</strong>: AÃ±adir type hints a funciones<br />
- <strong>1.2</strong>: Crear config con Pydantic<br />
- <strong>1.3</strong>: Estructurar proyecto con src/ layout</p>
            </div>
        
            <!-- MÃ“DULO: 02_DISENO_SISTEMAS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_02_DISENO_SISTEMAS" class="cover-title">DISEÃ‘O DE SISTEMAS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 02: DISEÃ‘O DE SISTEMAS ML</h1>
<h1>Del Problema de Negocio a la Arquitectura TÃ©cnica</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸ“ MÃ“DULO 02: DiseÃ±o de Sistemas ML</h1>
<h3>Del Problema de Negocio a la Arquitectura TÃ©cnica</h3>
<p><em>"Un arquitecto Senior no dibuja casas bonitas; diseÃ±a sistemas que sobreviven</em><br />
<em>a terremotos, a cambios de requisitos y a desarrolladores que se van."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>5-6 horas</strong></td>
<td style="text-align: center;">40%</td>
<td style="text-align: center;">60%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ ADR de Inicio: Â¿Por QuÃ© DiseÃ±ar Antes de Codificar?</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-002: DiseÃ±o Obligatorio Antes del CÃ³digo                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  CONTEXTO:                                                                    â•‘
â•‘  El 73% de proyectos ML que fallan lo hacen por problemas de DISEÃ‘O,          â•‘
â•‘  no de algoritmos (Sculley et al., &quot;Hidden Technical Debt in ML Systems&quot;).    â•‘
â•‘                                                                               â•‘
â•‘  DECISIÃ“N:                                                                    â•‘
â•‘  Todo proyecto debe completar: ML Canvas + Diagrama de Arquitectura +         â•‘
â•‘  ADRs para decisiones tÃ©cnicas clave ANTES de escribir cÃ³digo.                â•‘
â•‘                                                                               â•‘
â•‘  CONSECUENCIAS:                                                               â•‘
â•‘  (+) Alineamiento stakeholders-equipo desde el inicio                         â•‘
â•‘  (+) DocumentaciÃ³n de trade-offs para futuros desarrolladores                 â•‘
â•‘  (+) Menor retrabajo por requisitos mal entendidos                            â•‘
â•‘  (-) AÃ±ade 1-2 semanas al inicio del proyecto                                 â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Lo Que LograrÃ¡s en Este MÃ³dulo</h3>
<ol>
<li><strong>Traducir</strong> problemas de negocio a problemas de ML con mÃ©tricas claras</li>
<li><strong>Completar</strong> un ML Canvas profesional</li>
<li><strong>DiseÃ±ar</strong> arquitectura usando el modelo C4</li>
<li><strong>Documentar</strong> decisiones tÃ©cnicas con ADRs</li>
<li><strong>Crear</strong> un diagrama de flujo de datos</li>
</ol>
<h2>2.1 TraducciÃ³n Negocio â†’ ML (El Arte del Senior)</h2>
<h3>El Anti-PatrÃ³n: "Tengo Datos, Voy a Hacer ML"</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         âš ï¸ EL ERROR DEL JUNIOR                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   JUNIOR:                                                                     â•‘
â•‘   &quot;Tengo datos de clientes â†’ Voy a probar XGBoost â†’ Algo saldrÃ¡&quot;              â•‘
â•‘                                                                               â•‘
â•‘   PROBLEMA:                                                                   â•‘
â•‘   â€¢ No sabe quÃ© mÃ©trica optimizar (Â¿accuracy? Â¿F1? Â¿costo de negocio?)        â•‘
â•‘   â€¢ No sabe si el modelo genera valor                                         â•‘
â•‘   â€¢ No puede priorizar features porque no entiende el negocio                 â•‘
â•‘   â€¢ Cuando el proyecto &quot;termina&quot;, nadie lo usa                                â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                         âœ… EL ENFOQUE DEL SENIOR                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SENIOR:                                                                     â•‘
â•‘   &quot;El banco pierde $2M/aÃ±o por churn â†’ Predecir top 10% de riesgo â†’           â•‘
â•‘    CampaÃ±a de retenciÃ³n â†’ ROI esperado $400K â†’ MÃ©tricas:                      â•‘
â•‘    Precision@10% &gt; 50%, AUC &gt; 0.85, Latencia &lt; 100ms&quot;                         â•‘
â•‘                                                                               â•‘
â•‘   VENTAJAS:                                                                   â•‘
â•‘   â€¢ MÃ©trica clara conectada a $$$                                             â•‘
â•‘   â€¢ Sabe cuÃ¡ndo el modelo es &quot;suficientemente bueno&quot;                          â•‘
â•‘   â€¢ Puede justificar inversiÃ³n en infraestructura                             â•‘
â•‘   â€¢ El proyecto genera valor medible                                          â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Framework de TraducciÃ³n: Negocio â†’ ML â†’ Sistema</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Negocio[&quot;ğŸ¢ NEGOCIO&quot;]
        A[Problema de Negocio]
        B[KPIs de Ã‰xito]
        C[Restricciones]
    end

    subgraph ML[&quot;ğŸ§  ML&quot;]
        D[Tipo de Problema]
        E[MÃ©tricas TÃ©cnicas]
        F[Features Candidatas]
    end

    subgraph Sistema[&quot;âš™ï¸ SISTEMA&quot;]
        G[Requisitos No-Funcionales]
        H[Arquitectura]
        I[Stack TecnolÃ³gico]
    end

    A --&gt; D
    B --&gt; E
    C --&gt; G
    D --&gt; H
    E --&gt; H
    F --&gt; H
    G --&gt; I
</code></pre>
<h3>Tabla de TraducciÃ³n (Ejemplos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Problema de Negocio</th>
<th style="text-align: left;">Tipo ML</th>
<th style="text-align: left;">MÃ©trica Negocio</th>
<th style="text-align: left;">MÃ©trica TÃ©cnica</th>
<th style="text-align: left;">Requisito Sistema</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Reducir abandono de clientes</td>
<td style="text-align: left;">ClasificaciÃ³n Binaria</td>
<td style="text-align: left;">$ retenido/aÃ±o</td>
<td style="text-align: left;">AUC-ROC, Precision@K</td>
<td style="text-align: left;">Batch diario o API &lt; 100ms</td>
</tr>
<tr>
<td style="text-align: left;">Estimar precio de vehÃ­culos</td>
<td style="text-align: left;">RegresiÃ³n</td>
<td style="text-align: left;">% error en valuaciÃ³n</td>
<td style="text-align: left;">RMSE, MAPE</td>
<td style="text-align: left;">API sÃ­ncrona &lt; 200ms</td>
</tr>
<tr>
<td style="text-align: left;">Detectar fraude en tarjetas</td>
<td style="text-align: left;">Anomaly Detection</td>
<td style="text-align: left;">$ fraude evitado</td>
<td style="text-align: left;">Precision, Recall</td>
<td style="text-align: left;">Streaming &lt; 50ms</td>
</tr>
<tr>
<td style="text-align: left;">Recomendar productos</td>
<td style="text-align: left;">Ranking/RecSys</td>
<td style="text-align: left;">Lift en ventas</td>
<td style="text-align: left;">NDCG@10, MAP</td>
<td style="text-align: left;">API &lt; 100ms, cold-start handling</td>
</tr>
<tr>
<td style="text-align: left;">Predecir demanda</td>
<td style="text-align: left;">Series Temporales</td>
<td style="text-align: left;">% reducciÃ³n stockout</td>
<td style="text-align: left;">MAPE, Bias</td>
<td style="text-align: left;">Batch semanal</td>
</tr>
</tbody>
</table>
<h3>Ejercicio 2.1: Traduce Tu Problema</h3>
<p>Para el proyecto que elegiste (BankChurn, CarVision, TelecomAI o propio):</p>
<ol>
<li><strong>Problema de Negocio</strong>: Â¿QuÃ© duele? Â¿CuÃ¡nto cuesta?</li>
<li><strong>Tipo de ML</strong>: Â¿ClasificaciÃ³n, regresiÃ³n, clustering, etc.?</li>
<li><strong>MÃ©trica de Negocio</strong>: Â¿CÃ³mo se mide el Ã©xito en $$$?</li>
<li><strong>MÃ©trica TÃ©cnica</strong>: Â¿QuÃ© optimizamos? (AUC, RMSE, etc.)</li>
<li><strong>Requisito de Sistema</strong>: Â¿Batch o real-time? Â¿Latencia?</li>
</ol>
<h2>2.2 ML Canvas: El Blueprint del Proyecto</h2>
<h3>Â¿QuÃ© es el ML Canvas?</h3>
<p>El <strong>ML Canvas</strong> es un framework de 1 pÃ¡gina que captura todas las decisiones clave de un proyecto ML. Es como el Business Model Canvas pero para sistemas de ML.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                      ML CANVAS: BANKCHURN PREDICTOR                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ 1. ğŸ¯ PROBLEMA DE NEGOCIO                 â”‚   â”‚ 2. ğŸ’° PROPUESTA DE VALOR                       â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ â€¢ El banco pierde $2M/aÃ±o por clientes    â”‚   â”‚ â€¢ Reducir churn 20% = $400K ahorro/aÃ±o          â”‚  â•‘
â•‘  â”‚   que abandonan sin previo aviso          â”‚   â”‚ â€¢ Identificar top 10% clientes en riesgo        â”‚  â•‘
â•‘  â”‚ â€¢ Equipo de retenciÃ³n actÃºa reactivamente â”‚   â”‚ â€¢ Tiempo de acciÃ³n: de 0 dÃ­as a 30 dÃ­as previo  â”‚  â•‘
â•‘  â”‚ â€¢ Costo de adquisiciÃ³n 5x vs retenciÃ³n    â”‚   â”‚ â€¢ CampaÃ±as personalizadas por segmento riesgo   â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ 3. ğŸ“Š DATOS DISPONIBLES                   â”‚   â”‚ 4. ğŸ”§ FEATURES CANDIDATAS                      â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ FUENTE: Sistema CRM (PostgreSQL)          â”‚   â”‚ DEMOGRÃFICAS:                                   â”‚  â•‘
â•‘  â”‚ â€¢ 10,000 registros histÃ³ricos (2 aÃ±os)    â”‚   â”‚ â€¢ Age, Gender, Geography                        â”‚  â•‘
â•‘  â”‚ â€¢ Label: Exited (0=activo, 1=abandonÃ³)    â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ â€¢ Frecuencia: Snapshot mensual            â”‚   â”‚ FINANCIERAS:                                    â”‚  â•‘
â•‘  â”‚ â€¢ Latencia: T-1 dÃ­a                       â”‚   â”‚ â€¢ CreditScore, Balance, EstimatedSalary         â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ CALIDAD:                                  â”‚   â”‚ COMPORTAMIENTO:                                 â”‚  â•‘
â•‘  â”‚ â€¢ Nulos: &lt; 1%                             â”‚   â”‚ â€¢ Tenure, NumOfProducts, HasCrCard              â”‚  â•‘
â•‘  â”‚ â€¢ Desbalanceo: 20% churn (manejable)      â”‚   â”‚ â€¢ IsActiveMember                                â”‚  â•‘
â•‘  â”‚ â€¢ Data drift: Estacional (navidad)        â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ DERIVADAS (Feature Engineering):                â”‚  â•‘
â•‘  â”‚ RESTRICCIONES LEGALES:                    â”‚   â”‚ â€¢ BalancePerProduct = Balance / NumOfProducts   â”‚  â•‘
â•‘  â”‚ â€¢ GDPR: PseudonimizaciÃ³n requerida        â”‚   â”‚ â€¢ BalanceSalaryRatio = Balance / Salary         â”‚  â•‘
â•‘  â”‚ â€¢ No usar: Raza, ReligiÃ³n, etc.           â”‚   â”‚ â€¢ TenureAgeRatio = Tenure / Age                 â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ 5. ğŸ¤– MODELO                              â”‚   â”‚ 6. ğŸ“ MÃ‰TRICAS DE Ã‰XITO                        â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ TIPO: ClasificaciÃ³n Binaria               â”‚   â”‚ NEGOCIO:                                        â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ $ Retenido por CampaÃ±a &gt; $400K/aÃ±o            â”‚  â•‘
â•‘  â”‚ BASELINE:                                 â”‚   â”‚ â€¢ Lift vs random &gt; 3x                           â”‚  â•‘
â•‘  â”‚ â€¢ Logistic Regression (interpretable)     â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ â€¢ Umbral: 50% churn rate                  â”‚   â”‚ MODELO:                                         â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ AUC-ROC &gt; 0.85 (target)                       â”‚  â•‘
â•‘  â”‚ TARGET:                                   â”‚   â”‚ â€¢ Precision@10% &gt; 50%                           â”‚  â•‘
â•‘  â”‚ â€¢ Random Forest / XGBoost                 â”‚   â”‚ â€¢ Recall &gt; 60% (no perder churners)             â”‚  â•‘
â•‘  â”‚ â€¢ Con class_weight='balanced'             â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ SISTEMA:                                        â”‚  â•‘
â•‘  â”‚ APPROACH:                                 â”‚   â”‚ â€¢ Latencia P99 &lt; 100ms                          â”‚  â•‘
â•‘  â”‚ â€¢ Train/Test split temporal (no random)   â”‚   â”‚ â€¢ Throughput &gt; 100 req/s                        â”‚  â•‘
â•‘  â”‚ â€¢ Cross-validation: TimeSeriesSplit       â”‚   â”‚ â€¢ Uptime &gt; 99.5%                                â”‚  â•‘
â•‘  â”‚ â€¢ Hyperparameter tuning: Optuna           â”‚   â”‚ â€¢ Coverage &gt; 80%                                â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                       â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚ 7. âš ï¸ RIESGOS Y MITIGACIONES              â”‚   â”‚ 8. ğŸš€ PLAN DE DESPLIEGUE                       â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ TÃ‰CNICOS:                                 â”‚   â”‚ MVP (Semana 10):                                â”‚  â•‘
â•‘  â”‚ â€¢ Desbalanceo â†’ class_weight, SMOTE       â”‚   â”‚ â€¢ API REST (FastAPI)                            â”‚  â•‘
â•‘  â”‚ â€¢ Data leakage â†’ ValidaciÃ³n temporal      â”‚   â”‚ â€¢ Docker container                              â”‚  â•‘
â•‘  â”‚ â€¢ Overfitting â†’ RegularizaciÃ³n, CV        â”‚   â”‚ â€¢ Consumidor: Dashboard BI (PowerBI)            â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ Batch scoring diario                          â”‚  â•‘
â•‘  â”‚ OPERACIONALES:                            â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ â€¢ Model decay â†’ Monitoreo + retrain       â”‚   â”‚ V2 (Mes 3):                                     â”‚  â•‘
â•‘  â”‚ â€¢ Data drift â†’ Evidently/NannyML          â”‚   â”‚ â€¢ Kubernetes deployment                         â”‚  â•‘
â•‘  â”‚ â€¢ Latencia alta â†’ Caching, async          â”‚   â”‚ â€¢ IntegraciÃ³n CRM real-time                     â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ A/B testing framework                         â”‚  â•‘
â•‘  â”‚ Ã‰TICOS:                                   â”‚   â”‚ â€¢ Reentrenamiento mensual automatizado          â”‚  â•‘
â•‘  â”‚ â€¢ Sesgo geogrÃ¡fico â†’ Fairness metrics     â”‚   â”‚                                                 â”‚  â•‘
â•‘  â”‚ â€¢ Explicabilidad â†’ SHAP values            â”‚   â”‚ CONSUMIDORES:                                   â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ Equipo de RetenciÃ³n (principal)               â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ Dashboard Ejecutivo (secundario)              â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚ â€¢ CRM para campaÃ±as automatizadas               â”‚  â•‘
â•‘  â”‚                                           â”‚   â”‚                                                 â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•‘                                                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Template VacÃ­o para Tu Proyecto</h3>
<pre><code class="language-markdown"># ML CANVAS: [NOMBRE DEL PROYECTO]

## 1. ğŸ¯ Problema de Negocio
- Â¿QuÃ© duele?
- Â¿CuÃ¡nto cuesta el problema actual?
- Â¿QuiÃ©n sufre?

## 2. ğŸ’° Propuesta de Valor
- Â¿CÃ³mo ML alivia el dolor?
- Â¿CuÃ¡l es el ROI esperado?
- Â¿QuÃ© decisiones habilita?

## 3. ğŸ“Š Datos Disponibles
- Fuente:
- Volumen:
- Frecuencia:
- Calidad (nulos, duplicados):
- Restricciones legales:

## 4. ğŸ”§ Features Candidatas
- DemogrÃ¡ficas:
- Transaccionales:
- Comportamiento:
- Derivadas (feature engineering):

## 5. ğŸ¤– Modelo
- Tipo de problema:
- Baseline:
- Target:
- Approach de validaciÃ³n:

## 6. ğŸ“ MÃ©tricas de Ã‰xito
- Negocio:
- Modelo:
- Sistema:

## 7. âš ï¸ Riesgos y Mitigaciones
- TÃ©cnicos:
- Operacionales:
- Ã‰ticos:

## 8. ğŸš€ Plan de Despliegue
- MVP:
- V2:
- Consumidores:
</code></pre>
<h2>2.3 Arquitectura con el Modelo C4</h2>
<h3>Â¿QuÃ© es C4?</h3>
<p>El <strong>modelo C4</strong> (Context, Container, Component, Code) es un framework para documentar arquitectura de software en 4 niveles de zoom.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         MODELO C4: 4 NIVELES DE ZOOM                          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   NIVEL 1: CONTEXTO (System Context)                                          â•‘
â•‘   â€¢ Vista de pÃ¡jaro: El sistema y sus usuarios/sistemas externos              â•‘
â•‘   â€¢ Audiencia: Todos (stakeholders, devs, ops)                                â•‘
â•‘   â€¢ Pregunta: &quot;Â¿QuÃ© es esto y quiÃ©n lo usa?&quot;                                  â•‘
â•‘                                                                               â•‘
â•‘   NIVEL 2: CONTENEDORES (Container)                                           â•‘
â•‘   â€¢ Zoom in: Aplicaciones, bases de datos, servicios                          â•‘
â•‘   â€¢ Audiencia: Arquitectos, tech leads                                        â•‘
â•‘   â€¢ Pregunta: &quot;Â¿QuÃ© partes tiene el sistema?&quot;                                 â•‘
â•‘                                                                               â•‘
â•‘   NIVEL 3: COMPONENTES (Component)                                            â•‘
â•‘   â€¢ Zoom in++: MÃ³dulos dentro de cada contenedor                              â•‘
â•‘   â€¢ Audiencia: Desarrolladores                                                â•‘
â•‘   â€¢ Pregunta: &quot;Â¿CÃ³mo estÃ¡ organizado internamente?&quot;                           â•‘
â•‘                                                                               â•‘
â•‘   NIVEL 4: CÃ“DIGO (Code)                                                      â•‘
â•‘   â€¢ MÃ¡ximo zoom: Clases, funciones                                            â•‘
â•‘   â€¢ Audiencia: Desarrolladores (el que va a implementar)                      â•‘
â•‘   â€¢ Nota: Usualmente se genera desde el cÃ³digo, no se dibuja                  â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Nivel 1: Contexto del Sistema BankChurn</h3>
<pre><code class="language-mermaid">C4Context
    title Sistema BankChurn - Diagrama de Contexto

    Person(retention_team, &quot;Equipo RetenciÃ³n&quot;, &quot;ActÃºa sobre predicciones para retener clientes&quot;)
    Person(data_team, &quot;Data Team&quot;, &quot;Monitorea y mejora modelos&quot;)

    System(bankchurn, &quot;BankChurn Predictor&quot;, &quot;Predice probabilidad de churn y genera scores de riesgo&quot;)

    System_Ext(crm, &quot;Sistema CRM&quot;, &quot;Fuente de datos de clientes&quot;)
    System_Ext(bi, &quot;Dashboard BI&quot;, &quot;Visualiza scores y mÃ©tricas&quot;)
    System_Ext(campaign, &quot;Sistema CampaÃ±as&quot;, &quot;Ejecuta acciones de retenciÃ³n&quot;)

    Rel(retention_team, bankchurn, &quot;Consulta scores&quot;, &quot;API/Dashboard&quot;)
    Rel(data_team, bankchurn, &quot;Monitorea y retrains&quot;, &quot;MLflow/Grafana&quot;)
    Rel(crm, bankchurn, &quot;EnvÃ­a datos clientes&quot;, &quot;Batch/API&quot;)
    Rel(bankchurn, bi, &quot;EnvÃ­a predicciones&quot;, &quot;API&quot;)
    Rel(bankchurn, campaign, &quot;EnvÃ­a lista de riesgo&quot;, &quot;API/Webhook&quot;)
</code></pre>
<h3>Nivel 2: Contenedores</h3>
<pre><code class="language-mermaid">C4Container
    title Sistema BankChurn - Diagrama de Contenedores

    Person(user, &quot;Usuario&quot;, &quot;Equipo RetenciÃ³n / Data Team&quot;)

    Container_Boundary(bankchurn, &quot;BankChurn Predictor&quot;) {
        Container(api, &quot;API REST&quot;, &quot;FastAPI&quot;, &quot;Expone endpoints de predicciÃ³n y health&quot;)
        Container(model, &quot;ML Pipeline&quot;, &quot;Sklearn&quot;, &quot;Pipeline entrenado: preprocessor + model&quot;)
        Container(mlflow, &quot;MLflow&quot;, &quot;Python&quot;, &quot;Tracking de experimentos y model registry&quot;)
        ContainerDb(db, &quot;Model Storage&quot;, &quot;S3/Local&quot;, &quot;Artefactos .pkl&quot;)
    }

    System_Ext(crm, &quot;CRM&quot;, &quot;PostgreSQL&quot;)
    System_Ext(prometheus, &quot;Prometheus&quot;, &quot;MÃ©tricas&quot;)
    System_Ext(grafana, &quot;Grafana&quot;, &quot;Dashboards&quot;)

    Rel(user, api, &quot;HTTP/JSON&quot;, &quot;REST&quot;)
    Rel(api, model, &quot;Loads&quot;, &quot;joblib&quot;)
    Rel(model, db, &quot;Reads&quot;, &quot;S3/File&quot;)
    Rel(mlflow, db, &quot;Writes&quot;, &quot;Artifacts&quot;)
    Rel(crm, api, &quot;Batch data&quot;, &quot;CSV/API&quot;)
    Rel(api, prometheus, &quot;Exposes /metrics&quot;, &quot;HTTP&quot;)
    Rel(prometheus, grafana, &quot;Scrapes&quot;, &quot;PromQL&quot;)
</code></pre>
<h3>Nivel 3: Componentes (API Container)</h3>
<pre><code class="language-mermaid">C4Component
    title API REST - Diagrama de Componentes

    Container_Boundary(api, &quot;API REST (FastAPI)&quot;) {
        Component(routes, &quot;Routes&quot;, &quot;fastapi.APIRouter&quot;, &quot;Define endpoints: /predict, /health, /metrics&quot;)
        Component(schemas, &quot;Schemas&quot;, &quot;Pydantic&quot;, &quot;Valida requests y responses&quot;)
        Component(inference, &quot;Inference Service&quot;, &quot;Python Class&quot;, &quot;Carga modelo y ejecuta predicciÃ³n&quot;)
        Component(middleware, &quot;Middleware&quot;, &quot;FastAPI&quot;, &quot;Logging, timing, error handling&quot;)
        Component(config, &quot;Config&quot;, &quot;Pydantic Settings&quot;, &quot;Lee variables de entorno&quot;)
    }

    ContainerDb(model_store, &quot;Model Store&quot;, &quot;S3&quot;)
    Container(prometheus, &quot;Prometheus Client&quot;, &quot;prometheus_client&quot;)

    Rel(routes, schemas, &quot;Uses&quot;, &quot;Type validation&quot;)
    Rel(routes, inference, &quot;Calls&quot;, &quot;predict()&quot;)
    Rel(inference, model_store, &quot;Loads&quot;, &quot;joblib.load()&quot;)
    Rel(middleware, prometheus, &quot;Exposes&quot;, &quot;Counters/Histograms&quot;)
    Rel(routes, config, &quot;Reads&quot;, &quot;Settings&quot;)
</code></pre>
<h2>2.4 Diagrama de Flujo de Datos</h2>
<h3>Training Pipeline</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Data[&quot;ğŸ“¦ DATA&quot;]
        RAW[(Raw Data&lt;br/&gt;data/raw/)]
        PROC[(Processed&lt;br/&gt;data/processed/)]
    end

    subgraph Training[&quot;ğŸ”„ TRAINING&quot;]
        LOAD[Load Data]
        FE[Feature&lt;br/&gt;Engineering]
        SPLIT[Train/Test&lt;br/&gt;Split]
        TRAIN[Train Model]
        EVAL[Evaluate]
    end

    subgraph Artifacts[&quot;ğŸ“ ARTIFACTS&quot;]
        MODEL[(Pipeline.pkl&lt;br/&gt;models/)]
        METRICS[(Metrics&lt;br/&gt;mlruns/)]
    end

    subgraph Tracking[&quot;ğŸ“Š TRACKING&quot;]
        MLFLOW[MLflow&lt;br/&gt;Server]
    end

    RAW --&gt; LOAD
    LOAD --&gt; FE
    FE --&gt; PROC
    FE --&gt; SPLIT
    SPLIT --&gt; TRAIN
    TRAIN --&gt; EVAL
    EVAL --&gt; MODEL
    EVAL --&gt; METRICS
    METRICS --&gt; MLFLOW
    MODEL --&gt; MLFLOW

    style Data fill:#e1f5fe
    style Training fill:#fff3e0
    style Artifacts fill:#e8f5e9
    style Tracking fill:#f3e5f5
</code></pre>
<h3>Inference Pipeline</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Client[&quot;ğŸ‘¤ CLIENT&quot;]
        REQ[JSON Request]
        RESP[JSON Response]
    end

    subgraph API[&quot;ğŸŒ API&quot;]
        VALID[Validate&lt;br/&gt;Pydantic]
        INFER[Inference&lt;br/&gt;Service]
        FORMAT[Format&lt;br/&gt;Response]
    end

    subgraph Model[&quot;ğŸ¤– MODEL&quot;]
        LOAD[Load&lt;br/&gt;Pipeline]
        PREDICT[Predict&lt;br/&gt;Proba]
    end

    subgraph Monitor[&quot;ğŸ“Š MONITOR&quot;]
        LOGS[Structured&lt;br/&gt;Logs]
        METRICS[Prometheus&lt;br/&gt;Metrics]
    end

    REQ --&gt; VALID
    VALID --&gt; INFER
    INFER --&gt; LOAD
    LOAD --&gt; PREDICT
    PREDICT --&gt; FORMAT
    FORMAT --&gt; RESP

    INFER --&gt; LOGS
    INFER --&gt; METRICS

    style Client fill:#e3f2fd
    style API fill:#fff8e1
    style Model fill:#e8f5e9
    style Monitor fill:#fce4ec
</code></pre>
<h2>2.5 Architecture Decision Records (ADRs)</h2>
<h3>Â¿QuÃ© es un ADR?</h3>
<p>Un <strong>ADR</strong> documenta una decisiÃ³n arquitectÃ³nica importante: el contexto, la decisiÃ³n tomada, y las consecuencias.</p>
<h3>Template ADR</h3>
<pre><code class="language-markdown"># ADR-XXX: [TÃ­tulo de la DecisiÃ³n]

## Estado
[Propuesto | Aceptado | Deprecado | Superseded por ADR-YYY]

## Contexto
Â¿CuÃ¡l es el problema que estamos tratando de resolver?
Â¿QuÃ© restricciones tenemos?

## DecisiÃ³n
Â¿QuÃ© decidimos hacer?

## Consecuencias

### Positivas
- 

### Negativas
-

### Neutras
-

## Alternativas Consideradas
| Alternativa | Pros | Contras | RazÃ³n de Rechazo |
| ----------- | ---- | ------- | ---------------- |
|             |      |         |                  |

## Referencias
- Links a documentaciÃ³n, papers, etc.
</code></pre>
<h3>ADRs Ejemplo para BankChurn</h3>
<h4>ADR-003: FastAPI sobre Flask</h4>
<pre><code class="language-markdown"># ADR-003: Usar FastAPI para la API REST

## Estado
Aceptado

## Contexto
Necesitamos exponer el modelo como API REST. Las opciones principales son:
- Flask (maduro, amplia adopciÃ³n)
- FastAPI (moderno, async, tipado)
- Django REST (batteries-included, pero pesado)

## DecisiÃ³n
Usaremos **FastAPI** para la API REST.

## Consecuencias

### Positivas
- ValidaciÃ³n automÃ¡tica con Pydantic (ya usamos para config)
- DocumentaciÃ³n OpenAPI generada automÃ¡ticamente
- Soporte nativo async (mejor performance bajo carga)
- Type hints forzados (consistente con nuestro cÃ³digo)
- Mejor performance que Flask (Starlette + Uvicorn)

### Negativas
- Menos tutoriales/recursos que Flask (aunque creciendo rÃ¡pidamente)
- Requiere entender async/await para features avanzados
- Algunos desarrolladores pueden no estar familiarizados

### Neutras
- Similar curva de aprendizaje inicial que Flask

## Alternativas Consideradas
| Alternativa | Pros | Contras | RazÃ³n de Rechazo |
| ----------- | ---- | ------- | ---------------- |
| Flask | Maduro, muchos recursos | Sin async, sin tipos, docs manual | Performance y DX inferior |
| Django REST | Batteries-included | Muy pesado para API simple, ORM no necesario | Overkill para nuestro caso |

## Referencias
- [FastAPI vs Flask Benchmark](https://fastapi.tiangolo.com/benchmarks/)
- [Why FastAPI](https://fastapi.tiangolo.com/features/)
</code></pre>
<h4>ADR-004: DVC sobre Git LFS</h4>
<pre><code class="language-markdown"># ADR-004: Usar DVC para Versionado de Datos

## Estado
Aceptado

## Contexto
Necesitamos versionar:
- Dataset de entrenamiento (CSV ~50MB)
- Modelos entrenados (PKL ~10MB)
- Posible crecimiento a GB en el futuro

## DecisiÃ³n
Usaremos **DVC** (Data Version Control) con remote storage en S3/GCS.

## Consecuencias

### Positivas
- IntegraciÃ³n nativa con Git (cada versiÃ³n de datos linked a commit)
- Pipelines declarativos (dvc.yaml)
- MÃºltiples backends de storage (local, S3, GCS, Azure)
- Reproducibilidad con `dvc repro`
- Comunidad activa, bien documentado

### Negativas
- Curva de aprendizaje adicional
- Requiere setup de remote storage para colaboraciÃ³n
- Puede ser overkill para datasets muy pequeÃ±os

### Neutras
- CLI similar a Git (familiar)

## Alternativas Consideradas
| Alternativa | Pros | Contras | RazÃ³n de Rechazo |
| ----------- | ---- | ------- | ---------------- |
| Git LFS | Simple, integrado en Git | No soporta pipelines, costoso para archivos grandes | Sin reproducibilidad de pipelines |
| Delta Lake | Excelente para data lakes | Requiere Spark, overkill para nuestro caso | Complejidad innecesaria |
| DagsHub | DVC + MLflow hosted | Vendor lock-in, costo | Preferimos self-hosted |

## Referencias
- [DVC vs Git LFS](https://dvc.org/doc/user-guide/large-dataset-optimization)
</code></pre>
<h2>2.6 Ejercicio Integrador: DiseÃ±a Tu Sistema</h2>
<h3>Entregables</h3>
<p>Para tu proyecto elegido, crea los siguientes archivos en <code>docs/</code>:</p>
<ol>
<li><strong><code>ML_CANVAS.md</code></strong>: ML Canvas completo (usa el template)</li>
<li><strong><code>ARCHITECTURE.md</code></strong>: Diagramas C4 (al menos Contexto y Contenedores)</li>
<li><strong><code>decisions/ADR-001.md</code></strong>: Al menos 2 ADRs para decisiones clave</li>
</ol>
<h3>Criterios de EvaluaciÃ³n</h3>
<table>
<thead>
<tr>
<th>Criterio</th>
<th>BÃ¡sico (60-69)</th>
<th>Competente (70-84)</th>
<th>Destacado (85-100)</th>
</tr>
</thead>
<tbody>
<tr>
<td>ML Canvas</td>
<td>Secciones incompletas</td>
<td>Todas las secciones, algunos detalles vagos</td>
<td>Completo con mÃ©tricas especÃ­ficas y cuantificadas</td>
</tr>
<tr>
<td>Diagramas</td>
<td>Solo texto descriptivo</td>
<td>Diagramas ASCII o bÃ¡sicos</td>
<td>Mermaid/PlantUML correctos y claros</td>
</tr>
<tr>
<td>ADRs</td>
<td>Sin ADRs</td>
<td>1 ADR bÃ¡sico</td>
<td>2+ ADRs con alternativas y trade-offs</td>
</tr>
</tbody>
</table>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en el diseÃ±o de sistemas ML</h2>
<p>Este mÃ³dulo es de <strong>arquitectura y diseÃ±o</strong>, asÃ­ que muchos errores no se ven como <em>stack traces</em>, sino como <strong>malas decisiones</strong> que explotan meses despuÃ©s. La idea es aprender a detectarlos temprano.</p>
<h3>1) ML Canvas bonito pero inÃºtil (problema de negocio vago)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El ML Canvas estÃ¡ lleno de buzzwords: <em>â€œmejorar la experiencia del usuarioâ€, â€œoptimizar procesosâ€</em>.</li>
<li>No hay nÃºmeros: ni costo actual, ni ROI esperado, ni objetivo cuantitativo.</li>
<li>Nadie del negocio puede decir si el modelo â€œvaliÃ³ la penaâ€ o no.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Relee tus secciones <strong>1. Problema de Negocio</strong> y <strong>2. Propuesta de Valor</strong>:</li>
<li>Â¿Hay cantidades concretas? (<code>$</code>, %, horas, tickets, churnâ€¦)</li>
<li>Â¿Existe una hipÃ³tesis de mejora <em>medible</em>?</li>
<li>PregÃºntate: <em>â€œsi maÃ±ana entrego el modelo, Â¿cÃ³mo sabrÃ­a si impactÃ³ algo?â€</em>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Fuerza al menos:</li>
<li>1 mÃ©trica de negocio actual (ej: <em>churn 20%</em>, <em>tiempo de resoluciÃ³n 48h</em>).</li>
<li>1 objetivo de mejora (<em>reducir churn a 16%</em>, <em>bajar a 24h</em>).</li>
<li>1 mÃ©trica tÃ©cnica alineada (AUC, RMSE, etc.).</li>
<li>Usa como referencia los ejemplos de <strong>BankChurn</strong>, <strong>CarVision</strong> y <strong>TelecomAI</strong>:</li>
<li>Revisa sus READMEs y mÃ©tricas en MLflow para ver cÃ³mo se conectan a objetivos claros.</li>
</ul>
<h3>2) Diagramas C4 que no reflejan el cÃ³digo real</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El diagrama de contenedores muestra 10 microservicios, pero en el repo solo hay 1 API monolÃ­tica.</li>
<li>Aparecen bases de datos o colas que <strong>no existen</strong> en <code>docker-compose.demo.yml</code> ni en <code>k8s/</code>.</li>
<li>Personas nuevas en el equipo se confunden porque â€œla arquitectura del doc no coincide con la realidadâ€.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Abre simultÃ¡neamente:</li>
<li><code>docs/architecture/*.md</code> en la raÃ­z del portafolio.</li>
<li><code>BankChurn-Predictor/docs/ARCHITECTURE.md</code>, <code>CarVision-Market-Intelligence/docs/ARCHITECTURE.md</code>, <code>TelecomAI-Customer-Intelligence/docs/ARCHITECTURE.md</code>.</li>
<li><code>docker-compose.demo.yml</code> y los manifests de <code>k8s/</code>.</li>
<li>Recorre tu diagrama C4 y marca:</li>
<li>Â¿Existe un <strong>mapeo 1:1</strong> entre contenedores y artefactos reales (servicio Docker, deployment de K8s, app FastAPI/Streamlit)?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Primero, <strong>documenta la arquitectura que realmente existe hoy</strong> (MVP), no la ideal de dentro de 1 aÃ±o.</li>
<li>AsegÃºrate de que cada contenedor en el diagrama:</li>
<li>Tiene un <code>Dockerfile</code> o entrada en <code>docker-compose.demo.yml</code>.</li>
<li>O es un servicio externo claramente etiquetado (MLflow, Prometheus, Grafana, CRM, etc.).</li>
<li>Para la arquitectura futura, sepÃ¡rala explÃ­citamente como <strong>â€œV2 / visiÃ³nâ€</strong> para no confundir.</li>
</ul>
<h3>3) Ignorar requisitos no funcionales (latencia, throughput, observabilidad)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El modelo en notebook va bien, pero la API en producciÃ³n tiene:</li>
<li>Latencias &gt; 2â€“3s.</li>
<li>Timeouts bajo carga.</li>
<li>MÃ©tricas inexistentes o imposibles de interpretar.</li>
<li>No hay lÃ­neas claras en el ML Canvas ni en C4 sobre <strong>SLAs/SLIs</strong>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa las secciones <strong>6. MÃ©tricas de Ã‰xito</strong> y tus diagramas:</li>
<li>Â¿Hablaste de <em>latencia</em>, <em>throughput</em>, <em>uptime</em>, <em>mÃ©tricas de observabilidad</em>?</li>
<li>Â¿Tu diagrama de inferencia incluye Prometheus/Grafana/Logging como en <code>GUIA_AUDIOVISUAL.md</code> y los manifests de <code>k8s/</code>?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AÃ±ade explÃ­citamente en el ML Canvas:</li>
<li><strong>MÃ©tricas de sistema</strong> (latencia P95/P99, QPS, uptime, tiempo de warmup).</li>
<li><strong>MÃ©tricas de monitoreo</strong> (errores 5xx, requests por endpoint, uso de CPU/memoria).</li>
<li>Refleja esos componentes en C4:</li>
<li>Contenedores Prometheus/Grafana.</li>
<li>Endpoints <code>/metrics</code> en las APIs FastAPI.</li>
<li>Conecta esto al futuro mÃ³dulo de <strong>Observabilidad (16_OBSERVABILIDAD)</strong> para que el diseÃ±o no sea â€œciegoâ€.</li>
</ul>
<h3>4) ADRs inexistentes o que nadie lee</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Decisiones importantes viven solo en la cabeza de alguien: <em>â€œeso lo decidiÃ³ X hace mesesâ€</em>.</li>
<li>Existen ADRs, pero:</li>
<li>EstÃ¡n vacÃ­os, sin alternativas ni consecuencias.</li>
<li>Nadie los actualiza cuando se revierte una decisiÃ³n.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa <code>DECISIONES_TECH.md</code> y cualquier carpeta <code>docs/decisions/</code>.</li>
<li>PregÃºntate para cada secciÃ³n del sistema:</li>
<li>Â¿Por quÃ© FastAPI y no Flask?</li>
<li>Â¿Por quÃ© DVC y no Git LFS?</li>
<li>Â¿Por quÃ© MLflow y no W&amp;B?</li>
<li>Si la respuesta no estÃ¡ escrita en un ADR, tienes una <strong>decisiÃ³n tÃ¡cita</strong> peligrosa.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Para cada decisiÃ³n grande (API, tracking, versionado de datos, infraestructura):</li>
<li>Crea un ADR corto siguiendo el template de este mÃ³dulo.</li>
<li>AÃ±ade al menos <strong>1 alternativa rechazada</strong> y la razÃ³n.</li>
<li>Marca el estado (<code>Aceptado</code>, <code>Deprecado</code>, <code>Superseded</code>) cuando cambies de opiniÃ³n.</li>
<li>Enlaza los ADRs desde <code>DECISIONES_TECH.md</code> y desde la documentaciÃ³n de cada proyecto.</li>
</ul>
<h3>5) PatrÃ³n de debugging de diseÃ±o</h3>
<ol>
<li><strong>Empieza en el negocio</strong>: revisa si el problema y el ROI estÃ¡n cuantificados.</li>
<li><strong>Sigue con el Canvas</strong>: Â¿estÃ¡n completas las 8 secciones? Â¿faltan riesgos o restricciones legales?</li>
<li><strong>Baja a C4</strong>: verifica que contextos y contenedores existen realmente en cÃ³digo/infra.</li>
<li><strong>Cierra con ADRs</strong>: asegÃºrate de que las decisiones clave no viven solo en la memoria del equipo.</li>
</ol>
<p>Si recorres este pipeline de pensamiento cada vez que diseÃ±as (o revisas) un sistema, pensarÃ¡s como un arquitecto Senior incluso en proyectos pequeÃ±os.</p>
<h2>2.7 AutoevaluaciÃ³n</h2>
<h3>Checklist</h3>
<pre><code>TRADUCCIÃ“N NEGOCIO â†’ ML:
[ ] Puedo identificar el problema de negocio detrÃ¡s de un proyecto ML
[ ] SÃ© calcular ROI esperado de una soluciÃ³n ML
[ ] Puedo elegir la mÃ©trica tÃ©cnica correcta segÃºn el problema

ML CANVAS:
[ ] Puedo completar las 8 secciones del ML Canvas
[ ] SÃ© identificar riesgos tÃ©cnicos, operacionales y Ã©ticos
[ ] Puedo definir mÃ©tricas de negocio, modelo y sistema

ARQUITECTURA C4:
[ ] Entiendo los 4 niveles del modelo C4
[ ] Puedo dibujar diagramas de Contexto y Contenedores
[ ] SÃ© usar Mermaid para diagramas

ADRs:
[ ] Entiendo el propÃ³sito de los ADRs
[ ] Puedo documentar decisiones con alternativas y trade-offs
[ ] SÃ© cuÃ¡ndo crear un nuevo ADR vs actualizar uno existente
</code></pre>
<h3>Preguntas de ReflexiÃ³n</h3>
<ol>
<li>Â¿Por quÃ© es importante cuantificar el problema de negocio antes de empezar?</li>
<li>Â¿QuÃ© pasa si no documentas las decisiones arquitectÃ³nicas?</li>
<li>Â¿CuÃ¡ndo es apropiado NO usar ML para resolver un problema?</li>
</ol>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El diseÃ±o de sistemas no es solo teorÃ­a. AquÃ­ estÃ¡ cÃ³mo se aplicÃ³ en el portafolio real:</p>
<h3>ML Canvas del Portafolio</h3>
<p>Cada proyecto tiene su Canvas implÃ­cito en la documentaciÃ³n:</p>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Problema de Negocio</th>
<th>MÃ©trica de Negocio</th>
<th>MÃ©trica ML</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td>Reducir pÃ©rdida de clientes</td>
<td>RetenciÃ³n +5%</td>
<td>AUC-ROC, Recall</td>
</tr>
<tr>
<td>CarVision</td>
<td>Pricing automatizado de autos</td>
<td>Error de precio &lt;10%</td>
<td>MAE, RÂ²</td>
</tr>
<tr>
<td>TelecomAI</td>
<td>SegmentaciÃ³n de clientes</td>
<td>CampaÃ±as personalizadas</td>
<td>Accuracy, F1</td>
</tr>
</tbody>
</table>
<h3>Arquitectura C4 del Portafolio</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML-MLOps-Portfolio (CONTEXTO)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   BankChurn     â”‚  â”‚   CarVision     â”‚  â”‚   TelecomAI     â”‚  â”‚
â”‚  â”‚   Predictor     â”‚  â”‚   Market Intel  â”‚  â”‚   Customer Int  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                    â”‚                    â”‚           â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                               â”‚                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                    â”‚   common_utils/     â”‚                      â”‚
â”‚                    â”‚   (logger, seed)    â”‚                      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                               â”‚                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚           â”‚          GitHub Actions CI            â”‚             â”‚
â”‚           â”‚   (ci-mlops.yml, matrix testing)      â”‚             â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>ADRs del Portafolio</h3>
<p>Las decisiones arquitectÃ³nicas estÃ¡n documentadas en:<br />
- <code>docs/guia_mlops/DECISIONES_TECH.md</code> â†’ ADRs globales<br />
- <code>*/docs/ARCHITECTURE.md</code> â†’ ADRs por proyecto</p>
<p><strong>Ejemplo ADR real del portafolio:</strong></p>
<pre><code class="language-markdown"># ADR-001: Pipeline Unificado vs Artefactos Separados

## Contexto
Inicialmente BankChurn guardaba preprocessor.pkl y model.pkl por separado.

## DecisiÃ³n
Unificar todo en un solo pipeline.pkl

## Consecuencias
âœ… Elimina training-serving skew
âœ… Un solo artefacto para deploy
âŒ Archivo mÃ¡s grande
</code></pre>
<h3>ğŸ”§ Ejercicio: Revisa la Arquitectura Real</h3>
<pre><code class="language-bash"># Ver la arquitectura de BankChurn
cat BankChurn-Predictor/docs/architecture.md

# Ver las decisiones tÃ©cnicas globales
cat docs/guia_mlops/DECISIONES_TECH.md
</code></pre>
<h2>ğŸ“Š Diagramas Mermaid de Arquitectura</h2>
<h3>Flujo de Datos MLOps</h3>
<pre><code class="language-mermaid">flowchart LR
    subgraph Data[&quot;ğŸ“Š Data Layer&quot;]
        RAW[(Raw Data)]
        DVC[DVC Storage]
    end

    subgraph Training[&quot;ğŸ¯ Training&quot;]
        PIPE[sklearn Pipeline]
        MLFLOW[MLflow Tracking]
        ART[Artifacts]
    end

    subgraph Serving[&quot;ğŸš€ Serving&quot;]
        API[FastAPI]
        DASH[Streamlit]
    end

    subgraph Ops[&quot;âš™ï¸ Operations&quot;]
        CI[GitHub Actions]
        DOCKER[Docker]
        K8S[Kubernetes]
    end

    RAW --&gt; DVC
    DVC --&gt; PIPE
    PIPE --&gt; MLFLOW
    PIPE --&gt; ART
    ART --&gt; API
    ART --&gt; DASH
    CI --&gt; DOCKER
    DOCKER --&gt; K8S
    K8S --&gt; API
</code></pre>
<h3>Pipeline de ML (C4 - Container)</h3>
<pre><code class="language-mermaid">flowchart TB
    subgraph Pipeline[&quot;sklearn Pipeline&quot;]
        direction TB
        FE[FeatureEngineer]
        CT[ColumnTransformer]
        MODEL[RandomForest]

        FE --&gt; CT --&gt; MODEL
    end

    subgraph Preprocessor[&quot;ColumnTransformer&quot;]
        NUM[Numeric: Imputer + Scaler]
        CAT[Categorical: OneHotEncoder]
        BIN[Binary: Passthrough]
    end

    CT -.-&gt; Preprocessor
</code></pre>
<h3>CI/CD Pipeline</h3>
<pre><code class="language-mermaid">flowchart LR
    PUSH[Git Push] --&gt; LINT[Lint &amp; Format]
    LINT --&gt; TEST[pytest + Coverage]
    TEST --&gt; SEC[Security Scan]
    SEC --&gt; BUILD[Docker Build]
    BUILD --&gt; PUSH_REG[Push to Registry]
    PUSH_REG --&gt; DEPLOY[Deploy to K8s]

    style PUSH fill:#e1f5fe
    style DEPLOY fill:#c8e6c9
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas de System Design</h3>
<ol>
<li>
<p><strong>Siempre empieza con requisitos</strong>: Antes de dibujar, pregunta sobre escala, latencia esperada, y casos de uso principales.</p>
</li>
<li>
<p><strong>Conoce los trade-offs</strong>: "Â¿Por quÃ© elegiste esta arquitectura?" es la pregunta que siempre viene. Ten lista tu justificaciÃ³n.</p>
</li>
<li>
<p><strong>Menciona observabilidad</strong>: Pocos candidatos hablan de logs, mÃ©tricas y alertas. Hacerlo te diferencia.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sistema nuevo</td>
<td>Empieza simple (monolito), escala despuÃ©s</td>
</tr>
<tr>
<td>Alta disponibilidad</td>
<td>DiseÃ±a para fallos: circuit breakers, retries, fallbacks</td>
</tr>
<tr>
<td>Decisiones de arquitectura</td>
<td>Documenta en ADRs (Architecture Decision Records)</td>
</tr>
<tr>
<td>IntegraciÃ³n con ML</td>
<td>Separa serving de training, usa feature stores</td>
</tr>
</tbody>
</table>
<h3>Patrones que Debes Conocer</h3>
<ul>
<li><strong>Batch vs Streaming</strong>: CuÃ¡ndo usar cada uno para ML pipelines</li>
<li><strong>Event-Driven</strong>: Para sistemas desacoplados y escalables</li>
<li><strong>CQRS</strong>: Cuando lectura y escritura tienen requisitos muy diferentes</li>
<li><strong>Saga Pattern</strong>: Para transacciones distribuidas</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=2h2Z2j8PmKc">System Design for ML - Chip Huyen</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=x2-rSnhpw0g">C4 Model - Simon Brown</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://www.ownml.co/machine-learning-canvas">ML Canvas</a></td>
<td style="text-align: left;">Herramienta</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>ADR</strong>: Architecture Decision Record<br />
- <strong>C4 Model</strong>: Modelo de documentaciÃ³n de arquitectura<br />
- <strong>ML Canvas</strong>: Plantilla para diseÃ±o de proyectos ML</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 02:<br />
- <strong>2.1</strong>: Completar ML Canvas para un proyecto<br />
- <strong>2.2</strong>: Escribir un ADR para una decisiÃ³n tÃ©cnica</p>
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con el diseÃ±o completo, es hora de configurar un <strong>entorno de desarrollo profesional</strong>.</p>
<p><strong><a href="#mod_03_ESTRUCTURA_PROYECTO">Ir a MÃ³dulo 03: Estructura de Proyecto â†’</a></strong></p>
            </div>
        
            <!-- MÃ“DULO: 03_ESTRUCTURA_PROYECTO.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_03_ESTRUCTURA_PROYECTO" class="cover-title">ESTRUCTURA DE PROYECTO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>03. Estructura de Proyecto ML Profesional</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Crear la estructura de proyecto que usarÃ¡s en los 3 proyectos del portafolio.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  Una buena estructura de proyecto es como los cimientos de una casa:         â•‘
â•‘  invisible cuando estÃ¡ bien hecha, DESASTROSA cuando estÃ¡ mal.               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ La Estructura del Portafolio</h2>
<pre><code>MiProyecto-ML/
â”‚
â”œâ”€â”€ src/                          # ğŸ“¦ CÃ“DIGO FUENTE (instalable)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ miproyecto/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ data.py               # Carga y validaciÃ³n de datos
â”‚       â”œâ”€â”€ features.py           # Feature engineering
â”‚       â”œâ”€â”€ training.py           # Pipeline de entrenamiento
â”‚       â”œâ”€â”€ evaluation.py         # MÃ©tricas y evaluaciÃ³n
â”‚       â”œâ”€â”€ prediction.py         # Inferencia
â”‚       â””â”€â”€ models.py             # Custom models/transformers
â”‚
â”œâ”€â”€ app/                          # ğŸŒ APLICACIONES
â”‚   â”œâ”€â”€ fastapi_app.py            # API REST
â”‚   â””â”€â”€ streamlit_app.py          # Dashboard (opcional)
â”‚
â”œâ”€â”€ tests/                        # ğŸ§ª TESTS (espejo de src/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidas
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_training.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ configs/                      # âš™ï¸ CONFIGURACIÃ“N
â”‚   â””â”€â”€ config.yaml               # HiperparÃ¡metros, paths, etc.
â”‚
â”œâ”€â”€ data/                         # ğŸ“Š DATOS (gitignored)
â”‚   â”œâ”€â”€ raw/                      # Datos originales
â”‚   â””â”€â”€ processed/                # Datos procesados (opcional)
â”‚
â”œâ”€â”€ artifacts/                    # ğŸ“ ARTEFACTOS (gitignored)
â”‚   â”œâ”€â”€ model.joblib              # Modelo entrenado
â”‚   â””â”€â”€ metrics.json              # MÃ©tricas de entrenamiento
â”‚
â”œâ”€â”€ scripts/                      # ğŸ”§ SCRIPTS AUXILIARES
â”‚   â””â”€â”€ run_mlflow.py             # Script de MLflow
â”‚
â”œâ”€â”€ docs/                         # ğŸ“– DOCUMENTACIÃ“N
â”‚   â”œâ”€â”€ model_card.md
â”‚   â””â”€â”€ data_card.md
â”‚
â”œâ”€â”€ infra/                        # ğŸ—ï¸ INFRAESTRUCTURA (opcional)
â”‚   â””â”€â”€ terraform/
â”‚
â”œâ”€â”€ pyproject.toml                # ğŸ“‹ METADATA DEL PROYECTO
â”œâ”€â”€ requirements.txt              # ğŸ“‹ DEPENDENCIAS (para CI)
â”œâ”€â”€ Makefile                      # ğŸ”¨ COMANDOS COMUNES
â”œâ”€â”€ Dockerfile                    # ğŸ³ CONTAINERIZACIÃ“N
â”œâ”€â”€ .github/workflows/            # ğŸ”„ CI/CD
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ .gitignore                    # ğŸš« ARCHIVOS IGNORADOS
â”œâ”€â”€ .pre-commit-config.yaml       # ğŸ” HOOKS PRE-COMMIT
â””â”€â”€ README.md                     # ğŸ“– DOCUMENTACIÃ“N PRINCIPAL
</code></pre>
<h2>ğŸ§© CÃ³mo se aplica en este portafolio</h2>
<p>Esta estructura no es teÃ³rica: los <strong>3 proyectos</strong> del portafolio la siguen con ligeras<br />
variaciones. Esto conecta directamente con los macro-mÃ³dulos <strong>00</strong> y <strong>01</strong> de la<br />
<strong>Ruta 0 â†’ Senior/Staff</strong> descrita en el <a href="#mod_SYLLABUS">SYLLABUS</a>.</p>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Carpeta raÃ­z</th>
<th>Paquete principal</th>
<th>Archivos clave</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn Predictor</td>
<td><code>BankChurn-Predictor/</code></td>
<td><code>src/bankchurn/</code></td>
<td><code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code></td>
</tr>
<tr>
<td>CarVision Market Intelligence</td>
<td><code>CarVision-Market-Intelligence/</code></td>
<td><code>src/carvision/</code></td>
<td><code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code></td>
</tr>
<tr>
<td>TelecomAI Customer Intelligence</td>
<td><code>TelecomAI-Customer-Intelligence/</code></td>
<td><code>src/telecom/</code></td>
<td><code>pyproject.toml</code>, <code>main.py</code>, <code>Makefile</code>, <code>tests/</code></td>
</tr>
</tbody>
</table>
<p>Para aprovechar este mÃ³dulo al mÃ¡ximo en el repositorio real:</p>
<ul>
<li><strong>Compara</strong> el Ã¡rbol genÃ©rico de <code>MiProyecto-ML/</code> con, por ejemplo,<br />
<code>BankChurn-Predictor/</code> (fÃ­jate especialmente en <code>src/</code>, <code>configs/</code>, <code>tests/</code>,<br />
<code>Makefile</code> y <code>pyproject.toml</code>).</li>
<li><strong>Verifica</strong> que los comandos que defines aquÃ­ (<code>make install</code>, <code>make test</code>,<br />
<code>make train</code>, <code>make serve</code>) tienen su equivalente funcional en los Makefiles de<br />
  cada proyecto.</li>
<li><strong>Usa</strong> esta plantilla como referencia si creas un <strong>cuarto proyecto</strong> durante el<br />
<a href="#mod_20_PROYECTO_INTEGRADOR">20_PROYECTO_INTEGRADOR</a>.</li>
</ul>
<h2>ğŸ“„ pyproject.toml Completo</h2>
<pre><code class="language-toml"># pyproject.toml - El corazÃ³n del proyecto

[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;bankchurn&quot;
version = &quot;1.0.0&quot;
description = &quot;Bank Customer Churn Prediction System&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.10&quot;
license = {text = &quot;MIT&quot;}
authors = [
    {name = &quot;Tu Nombre&quot;, email = &quot;tu@email.com&quot;}
]
keywords = [&quot;machine-learning&quot;, &quot;churn&quot;, &quot;prediction&quot;]

dependencies = [
    &quot;pandas&gt;=2.0.0&quot;,
    &quot;numpy&gt;=1.24.0&quot;,
    &quot;scikit-learn&gt;=1.3.0&quot;,
    &quot;pydantic&gt;=2.0.0&quot;,
    &quot;pyyaml&gt;=6.0&quot;,
    &quot;joblib&gt;=1.3.0&quot;,
]

[project.optional-dependencies]
api = [
    &quot;fastapi&gt;=0.104.0&quot;,
    &quot;uvicorn&gt;=0.24.0&quot;,
]
mlflow = [
    &quot;mlflow&gt;=2.9.0&quot;,
]
dev = [
    &quot;pytest&gt;=7.4.0&quot;,
    &quot;pytest-cov&gt;=4.1.0&quot;,
    &quot;black&gt;=23.0.0&quot;,
    &quot;ruff&gt;=0.1.0&quot;,
    &quot;mypy&gt;=1.7.0&quot;,
    &quot;pre-commit&gt;=3.5.0&quot;,
]
all = [
    &quot;bankchurn[api,mlflow,dev]&quot;,
]

[project.scripts]
bankchurn = &quot;bankchurn.cli:main&quot;

[tool.setuptools.packages.find]
where = [&quot;src&quot;]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.pytest.ini_options]
testpaths = [&quot;tests&quot;]
python_files = [&quot;test_*.py&quot;]
addopts = &quot;-v --cov=src/bankchurn --cov-report=term-missing&quot;

[tool.coverage.run]
source = [&quot;src&quot;]
omit = [&quot;tests/*&quot;]

[tool.coverage.report]
fail_under = 79

[tool.black]
line-length = 100
target-version = [&quot;py311&quot;]

[tool.ruff]
line-length = 100
select = [&quot;E&quot;, &quot;F&quot;, &quot;I&quot;, &quot;W&quot;]
ignore = [&quot;E501&quot;]

[tool.mypy]
python_version = &quot;3.11&quot;
ignore_missing_imports = true
</code></pre>
<h2>ğŸ”¨ Makefile</h2>
<pre><code class="language-makefile"># Makefile - Comandos comunes

.PHONY: install test lint format train serve clean

# InstalaciÃ³n
install:
pip install -e &quot;.[all]&quot;

install-prod:
pip install -e &quot;.[api]&quot;

# Testing
test:
pytest --cov=src/ --cov-fail-under=80

test-fast:
pytest -m &quot;not slow&quot; -x

# Linting y formato
lint:
ruff check src/ tests/
mypy src/

format:
black src/ tests/ app/
ruff check --fix src/ tests/

# Entrenamiento
train:
python main.py --seed 42 train --config configs/config.yaml --input data/raw/Churn.csv
serve:
uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000 --reload

serve-prod:
uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000

# Docker
docker-build:
docker build -t bankchurn:latest .

docker-run:
docker run -p 8000:8000 bankchurn:latest

# MLflow
mlflow-ui:
mlflow ui --host 0.0.0.0 --port 5000

# Limpieza
clean:
rm -rf __pycache__ .pytest_cache .mypy_cache .ruff_cache
rm -rf *.egg-info build dist
rm -rf htmlcov .coverage
</code></pre>
<h2>ğŸš« .gitignore</h2>
<pre><code class="language-gitignore"># Python
__pycache__/
*.py[cod]
*.pyo
.pytest_cache/
.mypy_cache/
*.egg-info/
dist/
build/

# Entornos
.venv/
venv/
env/

# Datos y artefactos (muy grandes para Git)
data/
artifacts/
models/
*.joblib
*.pkl
*.h5

# MLflow
mlruns/

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Coverage
.coverage
htmlcov/

# Env vars
.env
.env.local
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en la estructura de proyecto</h2>
<p>AquÃ­ los problemas ya no son algoritmos, sino <strong>cÃ³mo estÃ¡ organizado el repo</strong>. Son los tÃ­picos errores que hacen que algo â€œfuncione en mi mÃ¡quina pero no en CIâ€ o que el repo se vuelva inmanejable.</p>
<h3>1) <code>ModuleNotFoundError</code> y tests que solo funcionan desde ciertos directorios</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En local, ejecutar <code>pytest</code> desde la raÃ­z funciona, pero en CI falla con:<br />
<code>text
  ModuleNotFoundError: No module named 'miproyecto'</code></li>
<li>Tienes que hacer trucos como <code>cd src</code> o modificar <code>PYTHONPATH</code> para que los imports funcionen.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa tu estructura real:</li>
<li>Â¿El cÃ³digo estÃ¡ en <code>src/miproyecto/</code> o repartido por la raÃ­z?</li>
<li>Â¿Los tests importan el paquete (<code>from miproyecto import ...</code>) o archivos sueltos (<code>import training</code>)?</li>
<li>Mira tu <code>pyproject.toml</code>:</li>
<li><code>[project.name]</code> â†’ Â¿coincide con el nombre del paquete (<code>miproyecto</code>, <code>bankchurn</code>, etc.)?</li>
<li><code>[tool.setuptools.packages.find] where = ["src"]</code> â†’ Â¿estÃ¡ configurado?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Mueve el cÃ³digo a <code>src/&lt;nombre_paquete&gt;/</code> siguiendo el Ã¡rbol de este mÃ³dulo.</li>
<li>AsegÃºrate de que los tests importan siempre el paquete, no rutas relativas.</li>
<li>Instala en modo editable durante desarrollo/CI:<br />
<code>bash
  pip install -e ".[dev]"</code></li>
</ul>
<h3>2) Datos y modelos dentro de Git (repos gigantes e impracticables)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El repo pesa cientos de MB porque hay CSVs y modelos <code>.pkl</code>/<code>.joblib</code> versionados.</li>
<li><code>git pull</code> y <code>git clone</code> son lentos, y los PRs estÃ¡n llenos de cambios binarios.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Ejecuta <code>git status</code> y revisa si aparecen archivos en <code>data/</code>, <code>artifacts/</code>, <code>models/</code>.</li>
<li>Abre tu <code>.gitignore</code> y comprueba si tienes entradas como:</li>
<li><code>data/</code>, <code>artifacts/</code>, <code>models/</code>, <code>*.joblib</code>, <code>*.pkl</code>, <code>mlruns/</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AÃ±ade las rutas correctas a <code>.gitignore</code> (usa el snippet de este mÃ³dulo como base).</li>
<li>MantÃ©n en Git <strong>solo</strong>:</li>
<li>CÃ³digo (<code>src/</code>, <code>app/</code>, <code>tests/</code>).</li>
<li>Config (<code>configs/</code>).</li>
<li>Infra y docs.</li>
<li>Para datos/modelos usa DVC o un storage externo (se profundiza en <code>06_VERSIONADO_DATOS.md</code>).</li>
</ul>
<h3>3) Tests que no reflejan el Ã¡rbol de <code>src/</code></h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Cambias algo en <code>src/miproyecto/features.py</code> y ningÃºn test falla, aunque has roto lÃ³gica.</li>
<li>Hay tests sueltos sin relaciÃ³n clara con los mÃ³dulos de producciÃ³n.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara Ã¡rboles:</li>
<li>En <code>src/miproyecto/</code>: <code>config.py</code>, <code>data.py</code>, <code>features.py</code>, <code>training.py</code>, <code>evaluation.py</code>, <code>prediction.py</code>.</li>
<li>En <code>tests/</code>: Â¿existen <code>test_config.py</code>, <code>test_data.py</code>, <code>test_features.py</code>, etc.?</li>
<li>Revisa el <code>pyproject.toml</code> o <code>pytest.ini</code> para ver quÃ© carpeta se usa como <code>testpaths</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Crea un <strong>espejo sencillo</strong>: por cada mÃ³dulo importante en <code>src/</code>, un test correspondiente en <code>tests/</code>.</li>
<li>Usa <code>conftest.py</code> para compartir fixtures (datasets pequeÃ±os, config de prueba, etc.).</li>
<li>Integra <code>pytest --cov=src/</code> en tu CI para detectar huecos de cobertura.</li>
</ul>
<h3>4) Makefile y comandos que no se pueden ejecutar</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El README dice <code>make train</code>, pero:</li>
<li>El target <code>train</code> no existe.</li>
<li>O llama a rutas que no existen (<code>data/raw/archivo_que_no_existe.csv</code>).</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Desde la raÃ­z del proyecto, ejecuta:<br />
<code>bash
  make help  # si tienes target de ayuda
  make train</code></li>
<li>Observa los comandos reales que se ejecutan y compÃ¡ralos con:</li>
<li>La estructura de carpetas (<code>data/raw</code>, <code>configs/config.yaml</code>).</li>
<li>El CLI real (como <code>src/bankchurn/cli.py</code> en BankChurn).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ajusta el <code>Makefile</code> para que:</li>
<li>Use rutas reales (<code>data/raw/Churn.csv</code>, etc.).</li>
<li>Delegue en el CLI real (<code>python main.py ...</code> o <code>python -m miproyecto.cli ...</code>).</li>
<li>MantÃ©n el <code>Makefile</code> como <strong>fachada del developer experience</strong>: pocos comandos (<code>install</code>, <code>test</code>, <code>train</code>, <code>serve</code>) pero sÃ³lidos.</li>
</ul>
<h3>5) PatrÃ³n general de debugging de estructura</h3>
<ol>
<li><strong>Revisa el Ã¡rbol de directorios</strong> contra la plantilla de este mÃ³dulo.</li>
<li><strong>Comprueba imports</strong> corriendo un <code>python -c</code> que importe tu paquete.</li>
<li><strong>Ejecuta los comandos principales</strong> (<code>make install</code>, <code>make test</code>, <code>make train</code>, <code>make serve</code>).</li>
<li><strong>Asegura que datos/artefactos no estÃ¡n en Git</strong> y que <code>.gitignore</code> los protege.</li>
</ol>
<p>Este checklist de estructura es lo primero que un revisor Senior mira cuando abre un repo ML: si esto estÃ¡ bien, todo lo demÃ¡s es mucho mÃ¡s fÃ¡cil de mantener.</p>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Explica tu estructura</strong>: Los entrevistadores valoran que puedas justificar cada carpeta y archivo de tu proyecto.</p>
</li>
<li>
<p><strong>Cookiecutter es tu amigo</strong>: Menciona que usas plantillas estandarizadas para consistencia entre proyectos.</p>
</li>
<li>
<p><strong>Conoce la diferencia <code>src/</code> vs flat</strong>: Explica por quÃ© <code>src/</code> layout previene imports accidentales del cÃ³digo local.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Proyecto nuevo</td>
<td>Usa cookiecutter-data-science o similar como base</td>
</tr>
<tr>
<td>Equipo grande</td>
<td>Documenta convenciones en CONTRIBUTING.md</td>
</tr>
<tr>
<td>Monorepo vs Multirepo</td>
<td>Monorepo para proyectos relacionados, multirepo para independientes</td>
</tr>
<tr>
<td>Configs</td>
<td>Nunca hardcodees: usa archivos YAML + variables de entorno</td>
</tr>
</tbody>
</table>
<h3>Checklist de Proyecto Profesional</h3>
<ul>
<li>[ ] README.md con badges, instalaciÃ³n, y uso rÃ¡pido</li>
<li>[ ] pyproject.toml con metadata completa</li>
<li>[ ] Makefile con comandos estÃ¡ndar (install, test, lint)</li>
<li>[ ] .pre-commit-config.yaml para calidad automÃ¡tica</li>
<li>[ ] tests/ con estructura que refleja src/</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=e8IIYRMnxcE">Python Project Structure - ArjanCodes</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://packaging.python.org/en/latest/discussions/src-layout-vs-flat-layout/">src Layout - Packaging Guide</a></td>
<td style="text-align: left;">Docs</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>src/ Layout</strong>: Estructura de proyecto profesional<br />
- <strong>pyproject.toml</strong>: Archivo de configuraciÃ³n moderno<br />
- <strong>Makefile</strong>: AutomatizaciÃ³n de comandos</p>
<h2>ğŸ“‹ Plantillas Relacionadas</h2>
<p>Ver <a href="#mod_index">templates/</a> para plantillas listas:<br />
- <a href="templates/pyproject_template.toml">pyproject_template.toml</a> â€” ConfiguraciÃ³n de paquete Python<br />
- <a href="#mod_README_TEMPLATE">README_TEMPLATE.md</a> â€” README profesional<br />
- <a href="templates/Makefile">Makefile</a> â€” AutomatizaciÃ³n de tareas</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 03:<br />
- <strong>3.1</strong>: Crear estructura de proyecto<br />
- <strong>3.2</strong>: Configurar pyproject.toml</p>
<p><strong>Ejercicio rÃ¡pido:</strong></p>
<pre><code class="language-bash">mkdir -p mi-proyecto/{src/miproyecto,app,tests,configs,data/raw,artifacts,scripts,docs}
touch mi-proyecto/src/__init__.py mi-proyecto/src/miproyecto/__init__.py
touch mi-proyecto/tests/__init__.py mi-proyecto/README.md
</code></pre>
            </div>
        
            <!-- MÃ“DULO: 04_ENTORNOS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_04_ENTORNOS" class="cover-title">ENTORNOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 03: ENTORNOS PROFESIONALES</h1>
<h1>Virtualenv vs Conda vs Poetry vs Docker: AnÃ¡lisis Comparativo</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸ”§ MÃ“DULO 03: Entornos Profesionales</h1>
<h3>El Arte de la Reproducibilidad a Nivel de Dependencias</h3>
<p><em>"'Funciona en mi mÃ¡quina' es la excusa mÃ¡s cara de la industria."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>4-5 horas</strong></td>
<td style="text-align: center;">30%</td>
<td style="text-align: center;">70%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ ADR de Inicio: Â¿Por QuÃ© Importan los Entornos?</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-005: GestiÃ³n de Entornos como PrÃ¡ctica Obligatoria                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  CONTEXTO:                                                                    â•‘
â•‘  El 30% de bugs en producciÃ³n ML se deben a diferencias de versiones          â•‘
â•‘  entre desarrollo y producciÃ³n (Google ML Engineering Best Practices).        â•‘
â•‘                                                                               â•‘
â•‘  DECISIÃ“N:                                                                    â•‘
â•‘  Todo proyecto DEBE tener un sistema de gestiÃ³n de dependencias con           â•‘
â•‘  versiones pinneadas y un mÃ©todo documentado de reproducir el entorno.        â•‘
â•‘                                                                               â•‘
â•‘  CONSECUENCIAS:                                                               â•‘
â•‘  (+) Reproducibilidad garantizada entre mÃ¡quinas                              â•‘
â•‘  (+) Onboarding de nuevos desarrolladores en minutos, no dÃ­as                 â•‘
â•‘  (+) CI/CD confiable (mismas versiones siempre)                               â•‘
â•‘  (-) Setup inicial requiere mÃ¡s tiempo                                        â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Lo Que LograrÃ¡s en Este MÃ³dulo</h3>
<ol>
<li><strong>Entender</strong> las diferencias entre venv, Conda, Poetry y Docker</li>
<li><strong>Elegir</strong> la herramienta correcta segÃºn tu proyecto</li>
<li><strong>Configurar</strong> un entorno profesional con lockfiles</li>
<li><strong>Integrar</strong> el entorno con CI/CD</li>
</ol>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>En <strong>BankChurn-Predictor</strong>, <strong>CarVision-Market-Intelligence</strong> y<br />
<strong>TelecomAI-Customer-Intelligence</strong> ya encontrarÃ¡s:</li>
<li>Ficheros <code>requirements-core.txt</code>, <code>requirements.in</code> y <code>requirements.txt</code> para gestionar<br />
    dependencias de forma reproducible.</li>
<li>Un <code>Makefile</code> con targets como <code>install</code>, <code>test</code> y <code>serve</code> que asumen un entorno activo.</li>
<li>Archivos <code>docker-compose.demo.yml</code> y <code>docker-compose.yml</code> que levantan el stack completo<br />
    (APIs, MLflow, dashboards).</li>
<li>Usa este mÃ³dulo para entender <strong>por quÃ©</strong> esas piezas existen y cÃ³mo recrear el mismo entorno<br />
  desde cero en tu mÃ¡quina o en CI/CD.</li>
</ul>
<h2>3.1 El Problema: "Funciona en Mi MÃ¡quina"</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         ğŸ˜± EL HORROR DE LAS DEPENDENCIAS                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ESCENARIO TÃPICO:                                                           â•‘
â•‘                                                                               â•‘
â•‘   Developer A (laptop):                                                       â•‘
â•‘   â€¢ Python 3.11.4                                                             â•‘
â•‘   â€¢ scikit-learn 1.3.0                                                        â•‘
â•‘   â€¢ pandas 2.0.3                                                              â•‘
â•‘   â€¢ numpy 1.24.3                                                              â•‘
â•‘   â†’ &quot;Todo funciona perfecto&quot; âœ…                                               â•‘
â•‘                                                                               â•‘
â•‘   Developer B (otra laptop):                                                  â•‘
â•‘   â€¢ Python 3.9.7                                                              â•‘
â•‘   â€¢ scikit-learn 1.0.2                                                        â•‘
â•‘   â€¢ pandas 1.4.0                                                              â•‘
â•‘   â€¢ numpy 1.21.0                                                              â•‘
â•‘   â†’ &quot;AttributeError: module 'sklearn' has no attribute 'X'&quot; âŒ                â•‘
â•‘                                                                               â•‘
â•‘   Servidor de producciÃ³n:                                                     â•‘
â•‘   â€¢ Python 3.8.10                                                             â•‘
â•‘   â€¢ Versiones &quot;whatever pip installed&quot;                                        â•‘
â•‘   â†’ CRASH EN PRODUCCIÃ“N ğŸ’¥                                                    â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Las 4 Capas de Reproducibilidad</h3>
<pre><code class="language-mermaid">flowchart TB
    subgraph L4[&quot;ğŸ³ NIVEL 4: Contenedor&quot;]
        D[Docker/Podman]
    end

    subgraph L3[&quot;ğŸ“¦ NIVEL 3: Gestor de Paquetes&quot;]
        C[Poetry / pip-tools / Conda]
    end

    subgraph L2[&quot;ğŸ”’ NIVEL 2: Entorno Virtual&quot;]
        B[venv / virtualenv / conda env]
    end

    subgraph L1[&quot;ğŸ NIVEL 1: VersiÃ³n Python&quot;]
        A[pyenv / conda / asdf]
    end

    L1 --&gt; L2 --&gt; L3 --&gt; L4

    style L1 fill:#ffecb3
    style L2 fill:#c8e6c9
    style L3 fill:#bbdefb
    style L4 fill:#e1bee7
</code></pre>
<h2>3.2 Comparativa de Herramientas</h2>
<h3>Matriz de DecisiÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Criterio</th>
<th style="text-align: center;">venv + pip</th>
<th style="text-align: center;">Conda</th>
<th style="text-align: center;">Poetry</th>
<th style="text-align: center;">Docker Dev</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Simplicidad</strong></td>
<td style="text-align: center;">â­â­â­â­â­</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">â­â­â­â­</td>
<td style="text-align: center;">â­â­</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Reproducibilidad</strong></td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">â­â­â­â­â­</td>
<td style="text-align: center;">â­â­â­â­â­</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Deps no-Python</strong></td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Lockfile nativo</strong></td>
<td style="text-align: center;">âŒ (req pip-tools)</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">N/A</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Speed</strong></td>
<td style="text-align: center;">â­â­â­â­â­</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">â­â­â­â­</td>
<td style="text-align: center;">â­â­â­</td>
</tr>
<tr>
<td style="text-align: left;"><strong>CI/CD friendly</strong></td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âš ï¸</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Espacio disco</strong></td>
<td style="text-align: center;">Bajo</td>
<td style="text-align: center;">Alto</td>
<td style="text-align: center;">Bajo</td>
<td style="text-align: center;">Medio-Alto</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Curva aprendizaje</strong></td>
<td style="text-align: center;">Baja</td>
<td style="text-align: center;">Media</td>
<td style="text-align: center;">Baja</td>
<td style="text-align: center;">Media</td>
</tr>
</tbody>
</table>
<h3>Â¿CuÃ¡ndo Usar Cada Uno?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    GUÃA DE SELECCIÃ“N DE HERRAMIENTA                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  USA venv + pip-tools SI:                                                     â•‘
â•‘  â€¢ Proyecto simple, solo dependencias Python                                  â•‘
â•‘  â€¢ Equipo pequeÃ±o, ya conoce pip                                              â•‘
â•‘  â€¢ CI/CD en GitHub Actions (pip es mÃ¡s rÃ¡pido)                                â•‘
â•‘  â€¢ No necesitas lockfile sofisticado                                          â•‘
â•‘                                                                               â•‘
â•‘  USA Conda SI:                                                                â•‘
â•‘  â€¢ Necesitas librerÃ­as con dependencias C/C++ (CUDA, MKL, OpenCV)             â•‘
â•‘  â€¢ Trabajas en Data Science pesado (numpy, scipy optimizados)                 â•‘
â•‘  â€¢ Tu equipo ya usa Conda                                                     â•‘
â•‘  â€¢ Necesitas mÃºltiples versiones de Python fÃ¡cilmente                         â•‘
â•‘                                                                               â•‘
â•‘  USA Poetry SI:                                                               â•‘
â•‘  â€¢ Proyecto serio que necesita reproducibilidad exacta                        â•‘
â•‘  â€¢ Quieres publicar en PyPI                                                   â•‘
â•‘  â€¢ Valoras lockfiles y dependency resolution robusta                          â•‘
â•‘  â€¢ Equipo moderno que aprecia herramientas bien diseÃ±adas                     â•‘
â•‘                                                                               â•‘
â•‘  USA Docker Dev Containers SI:                                                â•‘
â•‘  â€¢ Reproducibilidad TOTAL es crÃ­tica                                          â•‘
â•‘  â€¢ MÃºltiples servicios (DB, Redis, etc.) en desarrollo                        â•‘
â•‘  â€¢ Onboarding debe ser &quot;clone &amp; run&quot;                                          â•‘
â•‘  â€¢ Equipo usa VS Code con extensiÃ³n Dev Containers                            â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>3.3 OpciÃ³n 1: venv + pip-tools (Simple y Efectivo)</h2>
<h3>Setup BÃ¡sico</h3>
<pre><code class="language-bash"># Crear entorno virtual
python3.11 -m venv .venv

# Activar
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instalar pip-tools para lockfiles
pip install pip-tools
</code></pre>
<h3>Estructura de Archivos</h3>
<pre><code>project/
â”œâ”€â”€ requirements.in        # Dependencias directas (lo que escribes)
â”œâ”€â”€ requirements.txt       # Lockfile generado (no editar manualmente)
â”œâ”€â”€ requirements-dev.in    # Dependencias de desarrollo
â”œâ”€â”€ requirements-dev.txt   # Lockfile de desarrollo
â””â”€â”€ .python-version        # VersiÃ³n de Python (para pyenv)
</code></pre>
<h3>requirements.in (Lo que escribes)</h3>
<pre><code># requirements.in - Dependencias directas
# Solo especifica las que usas directamente, pip-tools resuelve el resto

pandas&gt;=2.0.0,&lt;3.0.0
scikit-learn&gt;=1.3.0
pydantic&gt;=2.0.0
fastapi&gt;=0.100.0
mlflow&gt;=2.8.0
pyyaml&gt;=6.0
</code></pre>
<h3>Generar Lockfile</h3>
<pre><code class="language-bash"># Genera requirements.txt con TODAS las versiones exactas
pip-compile requirements.in --output-file=requirements.txt

# Para desarrollo
pip-compile requirements-dev.in --output-file=requirements-dev.txt

# Instalar desde lockfile
pip-sync requirements.txt requirements-dev.txt
</code></pre>
<h3>requirements.txt Generado (NO EDITAR)</h3>
<pre><code># This file is autogenerated by pip-compile with Python 3.11
# Do not edit manually.

annotated-types==0.6.0
    # via pydantic
anyio==4.0.0
    # via
    #   httpx
    #   starlette
certifi==2023.11.17
    # via httpx
fastapi==0.104.1
    # via -r requirements.in
numpy==1.26.2
    # via
    #   pandas
    #   scikit-learn
pandas==2.1.3
    # via -r requirements.in
pydantic==2.5.2
    # via
    #   -r requirements.in
    #   fastapi
# ... etc (versiones EXACTAS)
</code></pre>
<h3>Makefile para AutomatizaciÃ³n</h3>
<pre><code class="language-makefile"># Makefile
.PHONY: venv install lock sync clean

PYTHON := python3.11
VENV := .venv
BIN := $(VENV)/bin

venv:
    $(PYTHON) -m venv $(VENV)
    $(BIN)/pip install --upgrade pip pip-tools

lock: venv
    $(BIN)/pip-compile requirements.in -o requirements.txt
    $(BIN)/pip-compile requirements-dev.in -o requirements-dev.txt

sync: venv
    $(BIN)/pip-sync requirements.txt requirements-dev.txt

install: venv lock sync

clean:
    rm -rf $(VENV)
    rm -f requirements.txt requirements-dev.txt
</code></pre>
<h2>3.4 OpciÃ³n 2: Poetry (Moderno y Robusto)</h2>
<h3>InstalaciÃ³n</h3>
<pre><code class="language-bash"># Instalar Poetry (mÃ©todo oficial)
curl -sSL https://install.python-poetry.org | python3 -

# Verificar
poetry --version
</code></pre>
<h3>Inicializar Proyecto</h3>
<pre><code class="language-bash"># En proyecto existente
poetry init

# O crear nuevo proyecto
poetry new bankchurn-predictor
</code></pre>
<h3>pyproject.toml Completo</h3>
<pre><code class="language-toml">[tool.poetry]
name = &quot;bankchurn&quot;
version = &quot;0.1.0&quot;
description = &quot;Predictor de churn bancario con MLOps&quot;
authors = [&quot;Tu Nombre &lt;tu@email.com&gt;&quot;]
readme = &quot;README.md&quot;
packages = [{include = &quot;bankchurn&quot;, from = &quot;src&quot;}]

[tool.poetry.dependencies]
python = &quot;^3.10&quot;
pandas = &quot;^2.0.0&quot;
scikit-learn = &quot;^1.3.0&quot;
pydantic = &quot;^2.0.0&quot;
fastapi = &quot;^0.104.0&quot;
uvicorn = &quot;^0.24.0&quot;
mlflow = &quot;^2.8.0&quot;
pyyaml = &quot;^6.0&quot;
joblib = &quot;^1.3.0&quot;

[tool.poetry.group.dev.dependencies]
pytest = &quot;^7.4.0&quot;
pytest-cov = &quot;^4.1.0&quot;
mypy = &quot;^1.6.0&quot;
ruff = &quot;^0.1.0&quot;
pre-commit = &quot;^3.5.0&quot;
ipython = &quot;^8.0.0&quot;

[tool.poetry.group.docs.dependencies]
mkdocs = &quot;^1.5.0&quot;
mkdocs-material = &quot;^9.4.0&quot;

[tool.poetry.scripts]
bankchurn-train = &quot;bankchurn.cli:train&quot;
bankchurn-predict = &quot;bankchurn.cli:predict&quot;

[build-system]
requires = [&quot;poetry-core&quot;]
build-backend = &quot;poetry.core.masonry.api&quot;

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N DE HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.ruff]
line-length = 100
select = [&quot;E&quot;, &quot;F&quot;, &quot;I&quot;, &quot;W&quot;, &quot;B&quot;, &quot;C4&quot;, &quot;UP&quot;]
ignore = [&quot;E501&quot;]
src = [&quot;src&quot;]

[tool.mypy]
python_version = &quot;3.11&quot;
warn_return_any = true
disallow_untyped_defs = true
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = [&quot;tests&quot;]
addopts = &quot;-v --cov=src/bankchurn --cov-report=term-missing&quot;

[tool.coverage.run]
source = [&quot;src&quot;]
omit = [&quot;tests/*&quot;]
</code></pre>
<h3>Comandos Esenciales</h3>
<pre><code class="language-bash"># Instalar dependencias (crea poetry.lock automÃ¡ticamente)
poetry install

# AÃ±adir dependencia
poetry add pandas
poetry add --group dev pytest

# Actualizar dependencias
poetry update

# Ejecutar comando en el entorno
poetry run python src/bankchurn/main.py
poetry run pytest

# Activar shell en el entorno
poetry shell

# Exportar a requirements.txt (para Docker)
poetry export -f requirements.txt --output requirements.txt --without-hashes

# Build del paquete
poetry build
</code></pre>
<h3>poetry.lock (Generado AutomÃ¡ticamente)</h3>
<p>El archivo <code>poetry.lock</code> contiene TODAS las versiones exactas de TODAS las dependencias (directas y transitivas). <strong>SIEMPRE</strong> commitear este archivo.</p>
<h2>3.5 OpciÃ³n 3: Conda (Para Data Science Pesado)</h2>
<h3>CuÃ¡ndo Conda es la Mejor OpciÃ³n</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         âœ… USA CONDA SI NECESITAS:                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   â€¢ CUDA / cuDNN para GPU computing                                           â•‘
â•‘   â€¢ NumPy/SciPy compilados con MKL (Intel) o OpenBLAS optimizado              â•‘
â•‘   â€¢ OpenCV con dependencias de sistema                                        â•‘
â•‘   â€¢ R + Python en el mismo entorno                                            â•‘
â•‘   â€¢ LibrerÃ­as geoespaciales (GDAL, GEOS, PROJ)                                â•‘
â•‘   â€¢ Dependencias de sistema que pip no puede instalar                         â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>environment.yml</h3>
<pre><code class="language-yaml"># environment.yml
name: bankchurn
channels:
  - conda-forge  # Preferir conda-forge sobre defaults
  - defaults

dependencies:
  # Python version
  - python=3.11

  # Core data science (optimizados con MKL)
  - numpy=1.26.*
  - pandas=2.1.*
  - scikit-learn=1.3.*

  # Si necesitas GPU
  # - pytorch
  # - cudatoolkit=11.8

  # Dependencias que tienen componentes C
  - pyyaml
  - joblib

  # pip dependencies (las que no estÃ¡n en conda o prefieres de PyPI)
  - pip
  - pip:
    - pydantic&gt;=2.0.0
    - fastapi&gt;=0.104.0
    - uvicorn&gt;=0.24.0
    - mlflow&gt;=2.8.0
    - pytest&gt;=7.4.0
    - mypy&gt;=1.6.0
    - ruff&gt;=0.1.0
</code></pre>
<h3>Comandos Conda</h3>
<pre><code class="language-bash"># Crear entorno desde archivo
conda env create -f environment.yml

# Activar
conda activate bankchurn

# Exportar entorno exacto (para reproducibilidad)
conda env export &gt; environment-lock.yml

# Exportar solo dependencias explÃ­citas
conda env export --from-history &gt; environment.yml

# Actualizar entorno
conda env update -f environment.yml --prune

# Listar entornos
conda env list

# Eliminar entorno
conda env remove -n bankchurn
</code></pre>
<h3>Mamba: Conda Acelerado</h3>
<pre><code class="language-bash"># Instalar mamba (resolver mucho mÃ¡s rÃ¡pido)
conda install -c conda-forge mamba

# Usar mamba en lugar de conda
mamba env create -f environment.yml
mamba install numpy
</code></pre>
<h2>3.6 OpciÃ³n 4: Docker Dev Containers</h2>
<h3>Â¿Por QuÃ© Docker para Desarrollo?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                       DOCKER DEV CONTAINERS: PROS/CONS                        â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   âœ… PROS:                                                                    â•‘
â•‘   â€¢ Reproducibilidad TOTAL (mismo OS, mismas versiones de todo)               â•‘
â•‘   â€¢ Onboarding = &quot;git clone &amp;&amp; code .&quot; (con VS Code Dev Containers)           â•‘
â•‘   â€¢ Mismo entorno en dev, CI y producciÃ³n                                     â•‘
â•‘   â€¢ Puedes incluir servicios (PostgreSQL, Redis, MLflow server)               â•‘
â•‘                                                                               â•‘
â•‘   âŒ CONS:                                                                    â•‘
â•‘   â€¢ Overhead de Docker (memoria, CPU)                                         â•‘
â•‘   â€¢ MÃ¡s complejo de configurar inicialmente                                   â•‘
â•‘   â€¢ Debugging puede ser mÃ¡s difÃ­cil                                           â•‘
â•‘   â€¢ Performance de I/O en volÃºmenes (especialmente macOS)                     â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>.devcontainer/devcontainer.json</h3>
<pre><code class="language-json">{
    &quot;name&quot;: &quot;BankChurn Dev&quot;,
    &quot;dockerComposeFile&quot;: &quot;docker-compose.yml&quot;,
    &quot;service&quot;: &quot;app&quot;,
    &quot;workspaceFolder&quot;: &quot;/workspace&quot;,

    &quot;customizations&quot;: {
        &quot;vscode&quot;: {
            &quot;extensions&quot;: [
                &quot;ms-python.python&quot;,
                &quot;ms-python.vscode-pylance&quot;,
                &quot;charliermarsh.ruff&quot;,
                &quot;ms-toolsai.jupyter&quot;,
                &quot;redhat.vscode-yaml&quot;,
                &quot;GitHub.copilot&quot;
            ],
            &quot;settings&quot;: {
                &quot;python.defaultInterpreterPath&quot;: &quot;/workspace/.venv/bin/python&quot;,
                &quot;python.formatting.provider&quot;: &quot;none&quot;,
                &quot;editor.formatOnSave&quot;: true,
                &quot;[python]&quot;: {
                    &quot;editor.defaultFormatter&quot;: &quot;charliermarsh.ruff&quot;
                }
            }
        }
    },

    &quot;postCreateCommand&quot;: &quot;make install&quot;,

    &quot;forwardPorts&quot;: [8000, 5000, 3000],

    &quot;remoteUser&quot;: &quot;vscode&quot;
}
</code></pre>
<h3>.devcontainer/docker-compose.yml</h3>
<pre><code class="language-yaml">version: '3.8'

services:
  app:
    build:
      context: ..
      dockerfile: .devcontainer/Dockerfile
    volumes:
      - ..:/workspace:cached
      - venv:/workspace/.venv
    environment:
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONUNBUFFERED=1
    command: sleep infinity

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.8.0
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - mlflow-data:/mlflow
    command: mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root /mlflow/artifacts

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: bankchurn
      POSTGRES_PASSWORD: bankchurn
      POSTGRES_DB: bankchurn
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - &quot;5432:5432&quot;

volumes:
  venv:
  mlflow-data:
  postgres-data:
</code></pre>
<h3>.devcontainer/Dockerfile</h3>
<pre><code class="language-dockerfile">FROM python:3.11-slim

# Dependencias del sistema
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    git \
    curl \
    make \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Usuario no-root
ARG USERNAME=vscode
ARG USER_UID=1000
ARG USER_GID=$USER_UID

RUN groupadd --gid $USER_GID $USERNAME \
    &amp;&amp; useradd --uid $USER_UID --gid $USER_GID -m $USERNAME

# Workspace
WORKDIR /workspace

# Cambiar a usuario no-root
USER $USERNAME

# Pre-instalar pip-tools
RUN pip install --user pip-tools

ENV PATH=&quot;/home/${USERNAME}/.local/bin:${PATH}&quot;
</code></pre>
<h2>3.7 IntegraciÃ³n con CI/CD</h2>
<h3>GitHub Actions con pip</h3>
<pre><code class="language-yaml"># .github/workflows/ci.yml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'  # Cachea dependencias

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run tests
        run: pytest tests/ -v --cov
</code></pre>
<h3>GitHub Actions con Poetry</h3>
<pre><code class="language-yaml">name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: 1.7.0
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('poetry.lock') }}

      - name: Install dependencies
        run: poetry install --no-interaction

      - name: Run tests
        run: poetry run pytest tests/ -v --cov
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en entornos</h2>
<p>Los problemas de este mÃ³dulo se manifiestan como <strong>inconsistencias entre mÃ¡quinas</strong>: algo funciona en tu laptop pero no en el servidor, o en CI. AquÃ­ van los patrones mÃ¡s frecuentes y cÃ³mo atacarlos.</p>
<h3>1) Entorno virtual mal activado (<code>pip</code> instala en el sitio equivocado)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Ejecutas <code>pip install</code> y luego <code>python -c "import pandas"</code> y obtienes <code>ModuleNotFoundError</code>.</li>
<li>Tienes varias versiones de Python (<code>python</code>, <code>python3</code>, <code>pyenv</code>, Conda) y no sabes cuÃ¡l estÃ¡ usando tu proyecto.</li>
<li>En CI funciona con una versiÃ³n de paquete y en local con otra.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Ejecuta:<br />
<code>bash
  which python
  python -m pip --version</code><br />
  y verifica que ambos apuntan al <strong>mismo entorno</strong> (<code>.venv/bin/python</code>, por ejemplo).</li>
<li>En Windows, revisa la ruta de <code>Scripts</code> y que estÃ©s en el entorno correcto (<code>(.venv)</code> en el prompt).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa siempre <code>python -m pip</code> en lugar de <code>pip</code> a secas:<br />
<code>bash
  python -m pip install -r requirements.txt</code></li>
<li>Documenta en el README/Makefile <strong>cÃ³mo activar el entorno</strong> (<code>source .venv/bin/activate</code>, <code>poetry shell</code>, <code>conda activate ...</code>).</li>
<li>Si usas <code>.python-version</code> con <code>pyenv</code>, asegÃºrate de que coincide con la versiÃ³n definida en <code>pyproject.toml</code> o <code>environment.yml</code>.</li>
</ul>
<h3>2) Lockfiles ignorados (<code>requirements.txt</code> / <code>poetry.lock</code> / <code>environment-lock.yml</code>)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Dos personas hacen <code>pip install -r requirements.txt</code> y obtienen versiones distintas de las mismas librerÃ­as.</li>
<li>En tu mÃ¡quina funciona con <code>pandas==2.0.3</code> pero en producciÃ³n falla con <code>pandas==2.2.0</code>.</li>
<li><code>poetry.lock</code> o <code>requirements-dev.txt</code> no estÃ¡n commiteados.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa el repositorio:</li>
<li>Â¿Existe <code>requirements.txt</code> generado por pip-tools y estÃ¡ en Git?</li>
<li>Â¿Existe <code>poetry.lock</code> y estÃ¡ versionado?</li>
<li>Â¿Hay algÃºn <code>environment-lock.yml</code> de Conda?</li>
<li>Compara lo que dice el lockfile con lo que tienes instalado:<br />
<code>bash
  pip freeze | grep pandas</code></li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li><strong>Siempre</strong> commitea el lockfile (requirements.txt, poetry.lock, environment-lock.yml).</li>
<li>Define una Ãºnica fuente de verdad: si usas pip-tools, no edites <code>requirements.txt</code> a mano, solo <code>requirements.in</code>.</li>
<li>En CI, instala <strong>desde el lockfile</strong>, no desde las dependencias sueltas.</li>
</ul>
<h3>3) Mezclar gestores (pip + Conda + Poetry + Docker) sin una estrategia clara</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Instalas algo con <code>conda install</code> y luego con <code>pip install</code> y el entorno se rompe.</li>
<li>Tienes <code>environment.yml</code>, <code>requirements.txt</code> y <code>pyproject.toml</code> en el mismo proyecto sin que ninguno estÃ© claro.</li>
<li>El contenedor Docker instala versiones diferentes a las de tu entorno local.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Lista tus archivos de configuraciÃ³n: Â¿hay mÃ¡s de un gestor activo a la vez?</li>
<li>Revisa el <code>Dockerfile</code>: Â¿instala desde <code>requirements.txt</code>, desde <code>pyproject.toml</code> exportado o desde <code>environment.yml</code>?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Elige un <strong>flujo principal</strong> por proyecto:</li>
<li>pip-tools â†’ <code>requirements.in</code> â†’ <code>requirements.txt</code> â†’ Docker/CI.</li>
<li>Poetry â†’ <code>pyproject.toml</code> + <code>poetry.lock</code> â†’ export a <code>requirements.txt</code> solo para Docker.</li>
<li>Conda â†’ <code>environment.yml</code>/<code>environment-lock.yml</code> â†’ <code>conda env create</code> en todas partes.</li>
<li>Documenta en este mÃ³dulo (y en el README del proyecto) <strong>quÃ© gestor es el canÃ³nico</strong> y quÃ© archivos deben editarse.</li>
</ul>
<h3>4) CI instala un entorno distinto al local</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En local todo pasa, pero en GitHub Actions los tests fallan por versiones de librerÃ­as.</li>
<li>Ves que en CI se instala directamente con <code>pip install -r requirements.txt</code> pero en local usas Poetry o Conda.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Abre el workflow (<code>.github/workflows/*.yml</code>) y verifica:</li>
<li>Â¿EstÃ¡ usando la misma versiÃ³n de Python que tÃº?</li>
<li>Â¿Instala dependencias desde los mismos archivos (<code>requirements.txt</code>, <code>poetry.lock</code>, <code>environment.yml</code>)?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Alinea CI con tu flujo local:</li>
<li>pip-tools: usa el snippet de "GitHub Actions con pip" de este mÃ³dulo.</li>
<li>Poetry: usa el bloque de "GitHub Actions con Poetry" y cachea <code>.venv</code>.</li>
<li>Conda: usa <code>conda env create -f environment.yml</code> o <code>mamba</code>.</li>
<li>Haz al menos una vez la prueba de <strong>clonar en limpio</strong> y seguir los pasos de CI en tu mÃ¡quina; esto detecta diferencias.</li>
</ul>
<h3>5) Docker que no refleja el entorno real</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>La aplicaciÃ³n en Docker falla con <code>ImportError</code> o con versiones diferentes de librerÃ­as.</li>
<li>Tu <code>Dockerfile</code> instala con <code>pip install pandas scikit-learn ...</code> en lugar de usar el lockfile.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa el <code>Dockerfile</code> (y <code>.devcontainer/Dockerfile</code> si aplica):</li>
<li>Â¿Copia <code>requirements.txt</code> o usa <code>poetry export</code> antes de instalar?</li>
<li>Â¿Especifica la misma versiÃ³n de Python que usas localmente?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Haz que Docker <strong>derive</strong> de tu configuraciÃ³n de entorno:</li>
<li>Con pip-tools: <code>COPY requirements.txt</code> â†’ <code>pip install -r requirements.txt</code>.</li>
<li>Con Poetry: <code>poetry export -f requirements.txt --output requirements.txt</code> y usa eso en la imagen.</li>
<li>MantÃ©n la versiÃ³n de Python del contenedor alineada con tu <code>.python-version</code> / <code>pyproject.toml</code> / <code>environment.yml</code>.</li>
</ul>
<h3>PatrÃ³n general de debugging de entornos</h3>
<ol>
<li><strong>Congela la versiÃ³n de Python</strong>: pyenv, Conda o imagen base de Docker clara.</li>
<li><strong>Define un Ãºnico gestor principal</strong> (pip-tools, Poetry o Conda) y sigue su flujo.</li>
<li><strong>AsegÃºrate de que CI y Docker consumen el mismo lockfile</strong>.</li>
<li><strong>Verifica el entorno activado</strong> antes de instalar o ejecutar (<code>which python</code>, <code>python -m pip</code>).</li>
</ol>
<p>Con este patrÃ³n, "funciona en mi mÃ¡quina" se convierte en "funciona en cualquier mÃ¡quina que siga estos pasos".</p>
<h2>3.8 Ejercicio PrÃ¡ctico: Configura Tu Entorno</h2>
<h3>OpciÃ³n A: pip-tools (Recomendado para empezar)</h3>
<pre><code class="language-bash"># 1. Crear estructura
mkdir -p bankchurn-predictor &amp;&amp; cd bankchurn-predictor

# 2. Crear archivos
cat &gt; requirements.in &lt;&lt; 'EOF'
pandas&gt;=2.0.0
scikit-learn&gt;=1.3.0
pydantic&gt;=2.0.0
fastapi&gt;=0.104.0
uvicorn&gt;=0.24.0
mlflow&gt;=2.8.0
pyyaml&gt;=6.0
joblib&gt;=1.3.0
EOF

cat &gt; requirements-dev.in &lt;&lt; 'EOF'
-r requirements.in
pytest&gt;=7.4.0
pytest-cov&gt;=4.1.0
mypy&gt;=1.6.0
ruff&gt;=0.1.0
pre-commit&gt;=3.5.0
EOF

# 3. Crear entorno y lockfiles
python3.11 -m venv .venv
source .venv/bin/activate
pip install pip-tools
pip-compile requirements.in
pip-compile requirements-dev.in
pip-sync requirements.txt requirements-dev.txt

# 4. Verificar
python -c &quot;import pandas; print(pandas.__version__)&quot;
</code></pre>
<h3>OpciÃ³n B: Poetry</h3>
<pre><code class="language-bash"># 1. Crear proyecto
poetry new bankchurn-predictor --src
cd bankchurn-predictor

# 2. AÃ±adir dependencias
poetry add pandas scikit-learn pydantic fastapi uvicorn mlflow pyyaml joblib
poetry add --group dev pytest pytest-cov mypy ruff pre-commit

# 3. Instalar
poetry install

# 4. Verificar
poetry run python -c &quot;import pandas; print(pandas.__version__)&quot;
</code></pre>
<h3>Checklist de VerificaciÃ³n</h3>
<pre><code>[ ] Entorno virtual creado y activable
[ ] Lockfile generado con versiones exactas
[ ] Lockfile commiteado en Git
[ ] Puedo recrear el entorno desde cero
[ ] CI puede instalar las mismas versiones
</code></pre>
<h2>3.9 AutoevaluaciÃ³n</h2>
<h3>Checklist de Competencias</h3>
<pre><code>CONCEPTOS:
[ ] Entiendo la diferencia entre dependencias directas y transitivas
[ ] SÃ© quÃ© es un lockfile y por quÃ© es importante
[ ] Puedo explicar cuÃ¡ndo usar Conda vs pip vs Poetry

pip-tools:
[ ] Puedo crear requirements.in con restricciones de versiÃ³n
[ ] SÃ© usar pip-compile y pip-sync
[ ] Entiendo el formato del lockfile generado

Poetry:
[ ] Puedo crear un pyproject.toml funcional
[ ] SÃ© aÃ±adir dependencias y grupos de dependencias
[ ] Puedo exportar a requirements.txt para Docker

CI/CD:
[ ] Puedo configurar caching de dependencias en GitHub Actions
[ ] SÃ© cÃ³mo asegurar reproducibilidad en CI
</code></pre>
<h3>Preguntas de ReflexiÃ³n</h3>
<ol>
<li>Â¿Por quÃ© no basta con <code>pip install pandas</code> sin especificar versiÃ³n?</li>
<li>Â¿CuÃ¡l es la diferencia entre <code>requirements.in</code> y <code>requirements.txt</code>?</li>
<li>Â¿CuÃ¡ndo preferirÃ­as Conda sobre Poetry?</li>
<li>Â¿Por quÃ© es importante cachear dependencias en CI?</li>
</ol>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>Cada proyecto del portafolio implementa la gestiÃ³n de entornos descrita:</p>
<h3>pyproject.toml Real</h3>
<pre><code class="language-toml"># BankChurn-Predictor/pyproject.toml (extracto)
[project]
name = &quot;bankchurn&quot;
version = &quot;0.1.0&quot;
requires-python = &quot;&gt;=3.10&quot;
dependencies = [
    &quot;pandas&gt;=2.0.0&quot;,
    &quot;scikit-learn&gt;=1.3.0&quot;,
    &quot;pydantic&gt;=2.5.0&quot;,
    &quot;mlflow&gt;=2.9.0&quot;,
]

[project.optional-dependencies]
dev = [
    &quot;pytest&gt;=7.4.0&quot;,
    &quot;pytest-cov&gt;=4.1.0&quot;,
    &quot;ruff&gt;=0.1.9&quot;,
]
</code></pre>
<h3>Comandos Make del Portafolio</h3>
<p>Todos los proyectos tienen Makefile con comandos consistentes:</p>
<pre><code class="language-makefile"># Comandos disponibles en los 3 proyectos
make install     # pip install -e &quot;.[dev]&quot;
make test        # pytest con coverage
make lint        # ruff check
make train       # Entrena el modelo
make serve       # Inicia API FastAPI
</code></pre>
<h3>Estructura de Dependencias</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Archivo</th>
<th>Dependencias Core</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>pyproject.toml</code></td>
<td>pandas, sklearn, pydantic, mlflow</td>
</tr>
<tr>
<td>CarVision</td>
<td><code>pyproject.toml</code></td>
<td>pandas, sklearn, pydantic, pyyaml</td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>pyproject.toml</code></td>
<td>pandas, sklearn, pydantic</td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Instala un Proyecto Real</h3>
<pre><code class="language-bash"># 1. Ve a BankChurn
cd BankChurn-Predictor

# 2. Crea entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. Instala con dependencias de desarrollo
pip install -e &quot;.[dev]&quot;

# 4. Verifica que funciona
python -c &quot;from bankchurn.config import BankChurnConfig; print('OK')&quot;
make test
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>"Â¿CÃ³mo manejas dependencias?"</strong>: Explica pip-tools, Poetry, o uv. Menciona lock files y reproducibilidad.</p>
</li>
<li>
<p><strong>Containers vs Virtualenvs</strong>: Conoce cuÃ¡ndo usar cada uno (dev local vs producciÃ³n).</p>
</li>
<li>
<p><strong>DevContainers</strong>: Menciona que usas VS Code DevContainers para entornos reproducibles.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Conflictos de dependencias</td>
<td>Usa pip-compile para resolver y fijar versiones</td>
</tr>
<tr>
<td>CI/CD</td>
<td>Usa la misma imagen Docker en local y CI</td>
</tr>
<tr>
<td>MÃºltiples versiones de Python</td>
<td>pyenv + tox para testing multi-versiÃ³n</td>
</tr>
<tr>
<td>Dependencias de sistema</td>
<td>Documenta en Dockerfile o README</td>
</tr>
</tbody>
</table>
<h3>Herramientas Modernas</h3>
<ul>
<li><strong>uv</strong>: Reemplazo rÃ¡pido de pip (10-100x mÃ¡s rÃ¡pido)</li>
<li><strong>pip-tools</strong>: pip-compile + pip-sync para reproducibilidad</li>
<li><strong>Poetry</strong>: GestiÃ³n completa de dependencias y publicaciÃ³n</li>
<li><strong>Conda</strong>: Para dependencias cientÃ­ficas complejas (CUDA, etc.)</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=Kg1Yvry_Ydk">Python Virtual Environments - Corey Schafer</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=LAig6s9Hkj0">pip-tools Tutorial</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>venv</strong>: Entornos virtuales de Python<br />
- <strong>pip-tools</strong>: GestiÃ³n de dependencias<br />
- <strong>pyproject.toml</strong>: ConfiguraciÃ³n de proyecto moderno</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 04:<br />
- <strong>4.1</strong>: Crear entorno virtual<br />
- <strong>4.2</strong>: Configurar pip-tools</p>
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con el entorno configurado, es hora de dominar <strong>Git profesionalmente</strong>.</p>
<p><strong><a href="#mod_05_GIT_PROFESIONAL">Ir a MÃ³dulo 05: Git Profesional â†’</a></strong></p>
            </div>
        
            <!-- MÃ“DULO: 05_GIT_PROFESIONAL.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_05_GIT_PROFESIONAL" class="cover-title">GIT PROFESIONAL</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 04: GIT PROFESIONAL</h1>
<h1>MÃ¡s AllÃ¡ del Commit: Conventional Commits, Hooks y Branching</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸŒ¿ MÃ“DULO 04: Git Profesional</h1>
<h3>Control de Versiones que Impresiona en Code Review</h3>
<p><em>"Un historial de Git limpio es la documentaciÃ³n que nunca miente."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>4-5 horas</strong></td>
<td style="text-align: center;">25%</td>
<td style="text-align: center;">75%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ Lo Que LograrÃ¡s en Este MÃ³dulo</h2>
<ol>
<li><strong>Escribir</strong> commits que cuentan una historia clara</li>
<li><strong>Configurar</strong> pre-commit hooks que previenen errores</li>
<li><strong>Aplicar</strong> estrategias de branching profesionales</li>
<li><strong>Dominar</strong> comandos avanzados (rebase, cherry-pick, bisect)</li>
</ol>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>El repositorio <code>ML-MLOps-Portfolio</code> y los tres proyectos<br />
  (<code>BankChurn-Predictor</code>, <code>CarVision-Market-Intelligence</code>, <code>TelecomAI-Customer-Intelligence</code>)<br />
  ya usan:</li>
<li>Historial basado en <strong>Conventional Commits</strong>.</li>
<li>Hooks de <strong>pre-commit</strong> configurados en <code>.pre-commit-config.yaml</code>.</li>
<li>Escaneo de seguridad con <strong>Gitleaks</strong> vÃ­a <code>.gitleaks.toml</code> y workflows de CI.</li>
<li>Usa este mÃ³dulo como guÃ­a para entender y ajustar esos flujos en tu propio fork del portafolio<br />
  y para mantener un historial que soporte entrevistas tÃ©cnicas Senior/Staff.</li>
</ul>
<h2>4.1 Conventional Commits: El EstÃ¡ndar de Industria</h2>
<h3>Â¿Por QuÃ© Importa el Formato del Commit?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    âŒ HISTORIAL TÃPICO (CAÃ“TICO)                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   * fix                                                                       â•‘
â•‘   * wip                                                                       â•‘
â•‘   * mÃ¡s cambios                                                               â•‘
â•‘   * asdfgh                                                                    â•‘
â•‘   * funcionaaaa                                                               â•‘
â•‘   * ahora sÃ­                                                                  â•‘
â•‘   * merge conflict resuelto                                                   â•‘
â•‘   * updates                                                                   â•‘
â•‘                                                                               â•‘
â•‘   PROBLEMAS:                                                                  â•‘
â•‘   â€¢ Imposible saber quÃ© cambiÃ³ sin leer el cÃ³digo                             â•‘
â•‘   â€¢ No puedes generar changelog automÃ¡tico                                    â•‘
â•‘   â€¢ git bisect es inÃºtil                                                      â•‘
â•‘   â€¢ Code review es un infierno                                                â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                    âœ… HISTORIAL PROFESIONAL (CONVENTIONAL)                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   * feat(api): add /predict endpoint with batch support                       â•‘
â•‘   * fix(training): handle NaN values in CreditScore column                    â•‘
â•‘   * test(pipeline): add integration tests for full pipeline                   â•‘
â•‘   * docs(readme): update installation instructions                            â•‘
â•‘   * refactor(config): migrate from dict to Pydantic models                    â•‘
â•‘   * ci(actions): add caching for pip dependencies                             â•‘
â•‘   * perf(inference): reduce latency from 150ms to 45ms                        â•‘
â•‘                                                                               â•‘
â•‘   BENEFICIOS:                                                                 â•‘
â•‘   â€¢ Changelog generado automÃ¡ticamente                                        â•‘
â•‘   â€¢ Semantic versioning automÃ¡tico                                            â•‘
â•‘   â€¢ git bisect encuentra bugs rÃ¡pidamente                                     â•‘
â•‘   â€¢ Code review enfocado                                                      â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>AnatomÃ­a de un Conventional Commit</h3>
<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;

[optional body]

[optional footer(s)]
</code></pre>
<h3>Tipos Permitidos</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Tipo</th>
<th style="text-align: left;">CuÃ¡ndo Usar</th>
<th style="text-align: left;">Ejemplo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>feat</code></td>
<td style="text-align: left;">Nueva funcionalidad</td>
<td style="text-align: left;"><code>feat(api): add batch prediction endpoint</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>fix</code></td>
<td style="text-align: left;">CorrecciÃ³n de bug</td>
<td style="text-align: left;"><code>fix(training): handle missing values in Age</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>docs</code></td>
<td style="text-align: left;">Solo documentaciÃ³n</td>
<td style="text-align: left;"><code>docs(readme): add API usage examples</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>style</code></td>
<td style="text-align: left;">Formato (no afecta lÃ³gica)</td>
<td style="text-align: left;"><code>style: apply ruff formatting</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>refactor</code></td>
<td style="text-align: left;">Refactor sin cambio funcional</td>
<td style="text-align: left;"><code>refactor(config): use Pydantic BaseSettings</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>test</code></td>
<td style="text-align: left;">AÃ±adir o corregir tests</td>
<td style="text-align: left;"><code>test(inference): add unit tests for predictor</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>perf</code></td>
<td style="text-align: left;">Mejora de performance</td>
<td style="text-align: left;"><code>perf(pipeline): cache preprocessor transformations</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>ci</code></td>
<td style="text-align: left;">Cambios en CI/CD</td>
<td style="text-align: left;"><code>ci(actions): add Python 3.12 to test matrix</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>build</code></td>
<td style="text-align: left;">Cambios en build/deps</td>
<td style="text-align: left;"><code>build(deps): upgrade scikit-learn to 1.4.0</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>chore</code></td>
<td style="text-align: left;">Mantenimiento general</td>
<td style="text-align: left;"><code>chore: update .gitignore</code></td>
</tr>
</tbody>
</table>
<h3>Scopes Comunes en MLOps</h3>
<pre><code># Por componente
feat(training): ...
feat(inference): ...
feat(api): ...
feat(config): ...
feat(data): ...

# Por capa
feat(model): ...
feat(features): ...
feat(pipeline): ...

# Por herramienta
ci(actions): ...
ci(docker): ...
ci(dvc): ...
</code></pre>
<h3>Ejemplos Completos</h3>
<pre><code class="language-bash"># Simple
git commit -m &quot;feat(api): add health check endpoint&quot;

# Con body explicativo
git commit -m &quot;fix(training): handle class imbalance in target variable

The training was failing silently when class ratio exceeded 1:10.
Added class_weight='balanced' to RandomForestClassifier.

Fixes #123&quot;

# Breaking change (incrementa MAJOR version)
git commit -m &quot;feat(api)!: change response format to include confidence scores

BREAKING CHANGE: The /predict response now returns an object instead of
a single float. Clients must update to handle the new format:
{\&quot;probability\&quot;: 0.85, \&quot;confidence\&quot;: 0.92, \&quot;prediction\&quot;: \&quot;churn\&quot;}&quot;
</code></pre>
<h3>Configurar Commitlint (ValidaciÃ³n AutomÃ¡tica)</h3>
<pre><code class="language-bash"># Instalar commitlint
npm install -g @commitlint/cli @commitlint/config-conventional

# Crear config
cat &gt; commitlint.config.js &lt;&lt; 'EOF'
module.exports = {
  extends: ['@commitlint/config-conventional'],
  rules: {
    'scope-enum': [2, 'always', [
      'api', 'training', 'inference', 'config', 'data',
      'pipeline', 'model', 'features', 'tests', 'docs',
      'ci', 'docker', 'dvc', 'deps'
    ]],
    'subject-case': [2, 'always', 'lower-case'],
  }
};
EOF
</code></pre>
<h2>4.2 Pre-commit Hooks: Prevenir Errores Antes del Commit</h2>
<h3>Â¿QuÃ© Son los Pre-commit Hooks?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         PRE-COMMIT: EL GUARDIÃN                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘                        git commit -m &quot;feat: ...&quot;                              â•‘
â•‘                                    â”‚                                          â•‘
â•‘                                    â–¼                                          â•‘
â•‘                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â•‘
â•‘                    â”‚      PRE-COMMIT HOOKS         â”‚                          â•‘
â•‘                    â”‚                               â”‚                          â•‘
â•‘                    â”‚  âœ“ Formatear cÃ³digo (ruff)    â”‚                          â•‘
â•‘                    â”‚  âœ“ Lint (ruff check)          â”‚                          â•‘
â•‘                    â”‚  âœ“ Type check (mypy)          â”‚                          â•‘
â•‘                    â”‚  âœ“ Tests rÃ¡pidos              â”‚                          â•‘
â•‘                    â”‚  âœ“ Validar YAML/JSON          â”‚                          â•‘
â•‘                    â”‚  âœ“ Detectar secretos          â”‚                          â•‘
â•‘                    â”‚  âœ“ Validar commit message     â”‚                          â•‘
â•‘                    â”‚                               â”‚                          â•‘
â•‘                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â•‘
â•‘                                    â”‚                                          â•‘
â•‘                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â•‘
â•‘                         â–¼                   â–¼                                 â•‘
â•‘                    ALL PASS âœ…          ANY FAIL âŒ                          â•‘
â•‘                    Commit OK            Commit BLOCKED                        â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>InstalaciÃ³n y Setup</h3>
<pre><code class="language-bash"># Instalar pre-commit
pip install pre-commit

# Instalar hooks en el repo
pre-commit install
pre-commit install --hook-type commit-msg  # Para commitlint

# Ejecutar en todos los archivos (primera vez)
pre-commit run --all-files
</code></pre>
<h3>.pre-commit-config.yaml Completo</h3>
<pre><code class="language-yaml"># .pre-commit-config.yaml
repos:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # FORMATEO Y LINTING
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.6
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # TYPE CHECKING
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.0
    hooks:
      - id: mypy
        args: [--ignore-missing-imports]
        additional_dependencies:
          - pydantic&gt;=2.0.0
          - types-PyYAML

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # GENERAL
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
        args: [--unsafe]  # Para YAML con tags como !ref
      - id: check-json
      - id: check-toml
      - id: check-added-large-files
        args: [--maxkb=1000]
      - id: check-merge-conflict
      - id: detect-private-key
      - id: no-commit-to-branch
        args: [--branch, main, --branch, master]

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # SEGURIDAD
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/Yelp/detect-secrets
    rev: v1.4.0
    hooks:
      - id: detect-secrets
        args: [--baseline, .secrets.baseline]

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.5
    hooks:
      - id: bandit
        args: [-c, pyproject.toml]
        additional_dependencies: [&quot;bandit[toml]&quot;]

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # CONVENTIONAL COMMITS
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/compilerla/conventional-pre-commit
    rev: v3.0.0
    hooks:
      - id: conventional-pre-commit
        stages: [commit-msg]
        args: [feat, fix, docs, style, refactor, test, perf, ci, build, chore]

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JUPYTER NOTEBOOKS
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/kynan/nbstripout
    rev: 0.6.1
    hooks:
      - id: nbstripout  # Limpia outputs de notebooks

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # DOCKER
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - repo: https://github.com/hadolint/hadolint
    rev: v2.12.0
    hooks:
      - id: hadolint-docker
        args: [--ignore, DL3008, --ignore, DL3013]

# ConfiguraciÃ³n global
default_language_version:
  python: python3.11

ci:
  autofix_commit_msg: &quot;style: auto-fix by pre-commit hooks&quot;
  autoupdate_commit_msg: &quot;chore: update pre-commit hooks&quot;
</code></pre>
<h3>pyproject.toml SecciÃ³n Bandit</h3>
<pre><code class="language-toml"># pyproject.toml
[tool.bandit]
exclude_dirs = [&quot;tests&quot;, &quot;scripts&quot;]
skips = [&quot;B101&quot;]  # Skip assert warnings in tests
</code></pre>
<h3>Comandos Pre-commit Ãštiles</h3>
<pre><code class="language-bash"># Ejecutar en archivos staged
pre-commit run

# Ejecutar en todos los archivos
pre-commit run --all-files

# Ejecutar hook especÃ­fico
pre-commit run ruff --all-files
pre-commit run mypy --all-files

# Actualizar hooks a Ãºltimas versiones
pre-commit autoupdate

# Skip hooks temporalmente (emergencia)
git commit --no-verify -m &quot;hotfix: emergency fix&quot;
# âš ï¸ USAR SOLO EN EMERGENCIAS
</code></pre>
<h2>4.3 Estrategias de Branching</h2>
<h3>Git Flow vs GitHub Flow vs Trunk-Based</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         COMPARATIVA DE ESTRATEGIAS                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  GIT FLOW (Complejo, releases programados)                                    â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â•‘
â•‘  main â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€                             â•‘
â•‘          \                  / \              /                                â•‘
â•‘  develop  â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—   â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—                                 â•‘
â•‘              \     /                  /                                       â•‘
â•‘  feature      â—â”€â”€â—                   /                                        â•‘
â•‘                    \                /                                         â•‘
â•‘  release            â—â”€â”€â—â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â—                                          â•‘
â•‘                                                                               â•‘
â•‘  âœ… Para: Apps con releases programados, equipos grandes                      â•‘
â•‘  âŒ No para: MLOps (demasiado overhead), startups                             â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  GITHUB FLOW (Simple, CD continuo) â† RECOMENDADO PARA MLOPS                   â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â•‘
â•‘  main â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€                                     â•‘
â•‘          \  /      \  /      \  /                                             â•‘
â•‘  feature  â—         â—         â—                                               â•‘
â•‘           PR       PR        PR                                               â•‘
â•‘                                                                               â•‘
â•‘  âœ… Para: MLOps, CI/CD frecuente, equipos pequeÃ±os-medianos                   â•‘
â•‘  âœ… Simple: Solo main + feature branches                                      â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  TRUNK-BASED (Avanzado, feature flags)                                        â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â•‘
â•‘  main â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€                                        â•‘
â•‘         â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â”‚                                             â•‘
â•‘         â””â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”´â”€â”€â”˜                                             â•‘
â•‘         Commits directos a main (con feature flags)                           â•‘
â•‘                                                                               â•‘
â•‘  âœ… Para: Equipos muy maduros, deploys mÃºltiples/dÃ­a                          â•‘
â•‘  âŒ No para: Equipos nuevos, sin feature flags robustos                       â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>GitHub Flow para MLOps (Recomendado)</h3>
<pre><code class="language-mermaid">gitGraph
    commit id: &quot;initial&quot;
    branch feature/add-mlflow
    commit id: &quot;feat(tracking): add MLflow integration&quot;
    commit id: &quot;test(tracking): add tests for experiment tracking&quot;
    checkout main
    merge feature/add-mlflow id: &quot;PR #12&quot;
    branch feature/api-batch
    commit id: &quot;feat(api): add batch prediction endpoint&quot;
    checkout main
    merge feature/api-batch id: &quot;PR #13&quot;
    branch fix/nan-handling
    commit id: &quot;fix(training): handle NaN in features&quot;
    checkout main
    merge fix/nan-handling id: &quot;PR #14&quot;
</code></pre>
<h3>Convenciones de Naming para Branches</h3>
<pre><code class="language-bash"># Features
feature/add-mlflow-tracking
feature/api-batch-prediction
feature/JIRA-123-user-auth

# Fixes
fix/nan-handling
fix/memory-leak-inference
fix/JIRA-456-login-error

# Refactors
refactor/config-pydantic
refactor/training-pipeline

# Experiments (para ML)
experiment/xgboost-vs-rf
experiment/feature-selection

# Releases (si usas Git Flow)
release/1.2.0
hotfix/1.2.1
</code></pre>
<h2>4.4 Comandos Avanzados que Todo Senior Debe Conocer</h2>
<h3>Rebase Interactivo: Limpiar Historial</h3>
<pre><code class="language-bash"># Ãšltimos 3 commits
git rebase -i HEAD~3

# Opciones en el editor:
# pick   = usar commit as-is
# reword = cambiar mensaje
# edit   = pausar para editar
# squash = combinar con anterior
# fixup  = combinar sin mensaje
# drop   = eliminar commit

# Ejemplo: Combinar 3 commits WIP en uno
# pick abc123 feat(api): add endpoint
# squash def456 wip
# squash ghi789 fix typo
# â†’ Se convierten en un solo commit limpio
</code></pre>
<h3>Cherry-pick: Traer Commits EspecÃ­ficos</h3>
<pre><code class="language-bash"># Traer un commit de otra rama
git cherry-pick abc123

# Traer varios commits
git cherry-pick abc123 def456

# Traer sin commitear (para combinar)
git cherry-pick --no-commit abc123
</code></pre>
<h3>Bisect: Encontrar el Commit que RompiÃ³ Algo</h3>
<pre><code class="language-bash"># Iniciar bisect
git bisect start

# Marcar estado actual como malo
git bisect bad

# Marcar un commit conocido como bueno
git bisect good v1.0.0

# Git te lleva a un commit intermedio
# Testear y marcar:
git bisect good  # Si funciona
git bisect bad   # Si estÃ¡ roto

# Repetir hasta encontrar el commit culpable
# Al final:
git bisect reset
</code></pre>
<h3>Stash: Guardar Cambios Temporalmente</h3>
<pre><code class="language-bash"># Guardar cambios actuales
git stash

# Con mensaje descriptivo
git stash push -m &quot;WIP: refactoring config&quot;

# Listar stashes
git stash list

# Aplicar Ãºltimo stash
git stash pop

# Aplicar stash especÃ­fico
git stash apply stash@{2}

# Crear branch desde stash
git stash branch feature/from-stash
</code></pre>
<h3>Reflog: Recuperar lo "Perdido"</h3>
<pre><code class="language-bash"># Ver historial de operaciones
git reflog

# Recuperar commit &quot;perdido&quot; despuÃ©s de reset
git reflog
# abc123 HEAD@{3}: commit: feat: important change
git checkout abc123
# o
git reset --hard abc123
</code></pre>
<h2>4.5 .gitignore Profesional para MLOps</h2>
<pre><code class="language-gitignore"># .gitignore para proyectos MLOps

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PYTHON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENTORNOS VIRTUALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.venv/
venv/
ENV/
env/
.conda/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IDEs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.idea/
.vscode/
*.swp
*.swo
*~
.spyderproject
.spyproject

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# JUPYTER NOTEBOOKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.ipynb_checkpoints/
*.ipynb_checkpoints/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATOS Y MODELOS (gestionados por DVC)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
data/raw/*
data/processed/*
models/*.pkl
models/*.joblib
!data/raw/.gitkeep
!data/processed/.gitkeep
!models/.gitkeep

# DVC
/data/*.csv
/data/*.parquet

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MLFLOW
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
mlruns/
mlartifacts/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SECRETOS Y CONFIGURACIÃ“N LOCAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.env
.env.*
!.env.example
*.pem
*.key
secrets/
credentials/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TESTING Y COVERAGE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.coverage
.pytest_cache/
htmlcov/
.tox/
.nox/
coverage.xml
*.cover
.hypothesis/

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BUILDS Y DOCS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
site/
docs/_build/
*.log

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
.DS_Store
Thumbs.db
</code></pre>
<h2>4.6 Ejercicio Integrador: Setup Completo de Git</h2>
<h3>Paso 1: Configurar Git Global</h3>
<pre><code class="language-bash"># Identidad
git config --global user.name &quot;Tu Nombre&quot;
git config --global user.email &quot;tu@email.com&quot;

# Editor (VS Code)
git config --global core.editor &quot;code --wait&quot;

# Alias Ãºtiles
git config --global alias.st &quot;status -sb&quot;
git config --global alias.co &quot;checkout&quot;
git config --global alias.br &quot;branch&quot;
git config --global alias.cm &quot;commit -m&quot;
git config --global alias.lg &quot;log --oneline --graph --all&quot;
git config --global alias.last &quot;log -1 HEAD --stat&quot;
git config --global alias.unstage &quot;reset HEAD --&quot;

# Auto-setup remote tracking
git config --global push.autoSetupRemote true

# Default branch
git config --global init.defaultBranch main
</code></pre>
<h3>Paso 2: Inicializar Proyecto</h3>
<pre><code class="language-bash"># Crear repo
mkdir bankchurn-predictor &amp;&amp; cd bankchurn-predictor
git init

# Crear estructura
mkdir -p src/bankchurn/{data,models,utils} tests/{unit,integration} configs docs

# Archivos base
touch src/bankchurn/__init__.py
touch .gitignore .pre-commit-config.yaml pyproject.toml README.md

# Primer commit
git add .
git commit -m &quot;chore: initial project structure&quot;
</code></pre>
<h3>Paso 3: Configurar Pre-commit</h3>
<pre><code class="language-bash"># Instalar
pip install pre-commit

# Copiar el .pre-commit-config.yaml de la secciÃ³n 4.2

# Instalar hooks
pre-commit install
pre-commit install --hook-type commit-msg

# Ejecutar en todos los archivos
pre-commit run --all-files
</code></pre>
<h3>Paso 4: Crear Feature Branch y PR</h3>
<pre><code class="language-bash"># Crear branch
git checkout -b feature/add-config

# Hacer cambios...
# Commit con conventional commits
git commit -m &quot;feat(config): add Pydantic configuration models&quot;

# Push
git push -u origin feature/add-config

# Crear PR en GitHub
# (usar template de PR si existe)
</code></pre>
<h3>Checklist de VerificaciÃ³n</h3>
<pre><code>CONFIGURACIÃ“N:
[ ] Git configurado con nombre y email
[ ] Alias Ãºtiles configurados
[ ] Default branch es main

PRE-COMMIT:
[ ] pre-commit instalado
[ ] Hooks activos (commit + commit-msg)
[ ] Todos los hooks pasan en --all-files

 FLUJO:
 [ ] Puedo crear feature branches correctamente
 [ ] Commits siguen Conventional Commits
 [ ] .gitignore excluye archivos correctos
 ```


## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en Git

Git aquÃ­ no es solo â€œguardar versionesâ€, sino soportar **flujos de trabajo profesionales** con branches, hooks y CI. Estos son los errores mÃ¡s frecuentes en el portafolio y cÃ³mo atacarlos.

### 1) Commits que rompen el formato (Conventional Commits / commitlint / pre-commit)

**SÃ­ntomas tÃ­picos**

- `git commit` falla con mensajes como:
  ```text
  â§—   input: fix: arreglos varios
  âœ–   subject may not be empty [subject-empty]
  âœ–   type must be one of [feat, fix, docs, style, ...]
  ```
- Hooks de `conventional-pre-commit` o `commitlint` bloquean el commit.

**CÃ³mo identificarlo**

- Mira el mensaje de error completo del hook (no solo la Ãºltima lÃ­nea).
- Abre `commitlint.config.js` o `.pre-commit-config.yaml` y revisa:
  - Tipos permitidos (`feat`, `fix`, `docs`, etc.).
  - Scopes permitidos, si hay regla `scope-enum`.

**CÃ³mo corregirlo**

- Ajusta tu mensaje al formato:
  ```bash
  git commit -m &quot;feat(api): add /predict endpoint&quot;
  git commit -m &quot;fix(training): handle NaN in CreditScore&quot;
  ```
- Si necesitas un scope nuevo (ej. `monitoring`), aÃ±Ã¡delo explÃ­citamente a la regla de `scope-enum` y commitea ese cambio primero.


### 2) Hooks de pre-commit que â€œrompen todoâ€ o tardan demasiado

**SÃ­ntomas tÃ­picos**

- Hacer `git commit` tarda mucho porque corre todos los tests y linters siempre.
- No entiendes quÃ© hook falla; solo ves â€œpre-commit failedâ€.

**CÃ³mo identificarlo**

- Ejecuta manualmente:
  ```bash
  pre-commit run --all-files
  ```
  y revisa quÃ© hook estÃ¡ fallando (ruff, mypy, bandit, etc.).
- Abre `.pre-commit-config.yaml` y verifica quÃ© rutas cubre cada hook.

**CÃ³mo corregirlo**

- Para hooks muy pesados (tests completos, mypy en todo el repo):
  - Limita los paths relevantes (`files:` o `types:`) o muÃ©velos a CI.
- Usa `pre-commit autoupdate` si un hook da errores por versiones muy viejas.
- Solo en emergencias, puedes hacer `git commit --no-verify`, pero documenta el motivo y arregla los hooks despuÃ©s.


### 3) Ramas desincronizadas y merges sucios

**SÃ­ntomas tÃ­picos**

- `git push` falla con `non-fast-forward`.
- Merge commits llenos de conflictos y mensajes genÃ©ricos.

**CÃ³mo identificarlo**

- Revisa el historial con:
  ```bash
  git log --oneline --graph --all
  ```
  y mira si tu rama feature estÃ¡ muy alejada de `main`.

**CÃ³mo corregirlo**

- MantÃ©n tu feature branch fresca:
  ```bash
  git checkout feature/mi-feature
  git fetch origin
  git rebase origin/main
  ```
- Si el equipo prefiere `merge` sobre `rebase`, al menos haz `git pull --rebase` para evitar merges de â€œmerge commits vacÃ­osâ€.
- Usa PRs pequeÃ±os y frecuentes en lugar de ramas gigantes de semanas.


### 4) Archivos enormes, datos o secretos en el historial

**SÃ­ntomas tÃ­picos**

- El repo pesa cientos de MB; `git clone` es lento.
- `detect-secrets` o `gitleaks` encuentran claves/API keys en el historial.

**CÃ³mo identificarlo**

- Ejecuta:
  ```bash
  git lfs track
  git rev-list --objects --all | sort -k 2 | tail -n 20
  ```
  para ver los blobs mÃ¡s grandes.
- Corre los hooks de seguridad (`detect-secrets`, `gitleaks`) y revisa sus reportes.

**CÃ³mo corregirlo**

- AÃ±ade en `.gitignore` lo que no deba ir a Git (`data/`, `artifacts/`, `mlruns/`, etc.).
- Para secretos ya commiteados:
  - Rota la credencial en el proveedor (AWS, GCP, etc.).
  - Usa herramientas como `git filter-repo` para limpiar el historial (mencionado solo como referencia; normalmente se hace una vez y con cuidado).


### 5) PatrÃ³n de debugging de Git en el portafolio

1. **Inspecciona el historial** con `git log --oneline --graph --all`.
2. **Verifica configuraciÃ³n local** (`git config --list --show-origin`).
3. **Reproduce el problema** (hook que falla, merge conflict, etc.) y lee el mensaje completo.
4. **Conecta el problema** con el concepto del mÃ³dulo:
   - Formato de commits â†’ Conventional Commits + commitlint.
   - Calidad del cÃ³digo â†’ hooks de pre-commit.
   - Flujo de ramas â†’ GitHub Flow (main + feature branches).
5. **Aplica el patrÃ³n de soluciÃ³n** que ya tienes documentado en este mÃ³dulo.

Con este enfoque, Git deja de ser â€œmagia negraâ€ y se convierte en una herramienta predecible y aliada de tu flujo MLOps.


## 4.7 AutoevaluaciÃ³n

### Preguntas de ReflexiÃ³n

1. Â¿Por quÃ© Conventional Commits permite generar changelogs automÃ¡ticamente?
2. Â¿CuÃ¡l es la diferencia entre `git rebase` y `git merge`?
3. Â¿CuÃ¡ndo usarÃ­as `git stash` vs crear un branch?
4. Â¿Por quÃ© `no-commit-to-branch` es un hook Ãºtil?

### Comandos que Debes Dominar

```bash
# BÃ¡sicos
git status, add, commit, push, pull

# Branching
git branch, checkout -b, merge

# Historial
git log --oneline --graph, diff, show

# Avanzados
git rebase -i, cherry-pick, bisect, stash, reflog

# Pre-commit
pre-commit run, --all-files, autoupdate
</code></pre>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El portafolio implementa todas las prÃ¡cticas de Git profesional descritas:</p>
<h3>.pre-commit-config.yaml Real</h3>
<pre><code class="language-yaml"># ML-MLOps-Portfolio/.pre-commit-config.yaml (extracto)
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=5000']

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.9
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/gitleaks/gitleaks
    rev: v8.18.1
    hooks:
      - id: gitleaks
</code></pre>
<h3>Conventional Commits del Portafolio</h3>
<p>Ejemplos de commits reales en el historial:</p>
<pre><code class="language-bash"># Ejemplos del historial real del portafolio
feat(bankchurn): add unified sklearn pipeline
fix(carvision): prevent data leakage in FeatureEngineer
docs(guia): add module 11 Testing ML
test(telecomai): increase coverage to 97%
ci(actions): add matrix testing for Python 3.10/3.11
refactor(config): migrate to Pydantic v2
</code></pre>
<h3>Branching Strategy</h3>
<p>El portafolio usa <strong>GitHub Flow</strong> simplificado:</p>
<pre><code>main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
       â”‚                    â”‚
       â””â”€â”€ feature/xyz â”€â”€â”€â”€â”€â”˜ (PR + CI verde + merge)
</code></pre>
<h3>ğŸ”§ Ejercicio: Configura Pre-commit</h3>
<pre><code class="language-bash"># 1. Ve a la raÃ­z del portafolio
cd ML-MLOps-Portfolio

# 2. Instala pre-commit
pip install pre-commit

# 3. Instala los hooks
pre-commit install

# 4. Ejecuta en todos los archivos
pre-commit run --all-files

# 5. Haz un commit y verifica que los hooks se ejecutan
echo &quot;# test&quot; &gt;&gt; test.md
git add test.md
git commit -m &quot;test: verify pre-commit hooks&quot;  # Los hooks se ejecutan aquÃ­
git reset --soft HEAD~1  # Deshaz el commit de prueba
rm test.md
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Conventional Commits</strong>: Explica por quÃ© <code>feat:</code>, <code>fix:</code>, <code>docs:</code> facilitan changelogs automÃ¡ticos.</p>
</li>
<li>
<p><strong>Git Flow vs Trunk-Based</strong>: Conoce ambos y cuÃ¡ndo usar cada uno.</p>
</li>
<li>
<p><strong>Rebase vs Merge</strong>: Pregunta clÃ¡sica. Respuesta: rebase para historia limpia, merge para preservar contexto.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Commits grandes</td>
<td>Divide en commits atÃ³micos con <code>git add -p</code></td>
</tr>
<tr>
<td>Historia sucia</td>
<td>Usa <code>git rebase -i</code> antes de PR</td>
</tr>
<tr>
<td>Secretos en repo</td>
<td>Usa git-secrets o gitleaks en pre-commit</td>
</tr>
<tr>
<td>ColaboraciÃ³n</td>
<td>PRs pequeÃ±os (&lt; 400 lÃ­neas) se revisan mejor</td>
</tr>
</tbody>
</table>
<h3>Comandos que Debes Dominar</h3>
<pre><code class="language-bash">git stash push -m &quot;descripciÃ³n&quot;  # Guardar trabajo temporal
git bisect start                 # Encontrar commit que introdujo bug
git reflog                       # Recuperar commits &quot;perdidos&quot;
git cherry-pick &lt;commit&gt;         # Aplicar commit especÃ­fico
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=Uszj_k0DGsg">Git for Professionals - freeCodeCamp</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.conventionalcommits.org/">Conventional Commits</a></td>
<td style="text-align: left;">Docs</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>pre-commit</strong>: Hooks de validaciÃ³n antes de commit<br />
- <strong>Conventional Commits</strong>: Formato estÃ¡ndar de mensajes<br />
- <strong>GitHub Flow</strong>: Workflow de branching</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 05:<br />
- <strong>5.1</strong>: Configurar .gitignore profesional<br />
- <strong>5.2</strong>: Instalar pre-commit hooks</p>
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con Git dominado, es hora de versionar <strong>datos</strong> profesionalmente.</p>
<p><strong><a href="#mod_06_VERSIONADO_DATOS">Ir a MÃ³dulo 06: Versionado de Datos â†’</a></strong></p>
            </div>
        
            <!-- MÃ“DULO: 06_VERSIONADO_DATOS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_06_VERSIONADO_DATOS" class="cover-title">VERSIONADO DE DATOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 05: INGENIERÃA DE DATOS Y DVC</h1>
<h1>Versionado de Datos, DAGs y Reproducibilidad</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸ“Š MÃ“DULO 05: IngenierÃ­a de Datos y DVC</h1>
<h3>El Arte de Versionar lo que Git No Puede</h3>
<p><em>"Si no puedo recrear tus datos, no puedo reproducir tu modelo."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>5-6 horas</strong></td>
<td style="text-align: center;">30%</td>
<td style="text-align: center;">70%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ ADR de Inicio: Â¿CuÃ¡ndo (NO) Usar DVC?</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-006: Criterios para Usar DVC                                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  âœ… USA DVC SI:                                                               â•‘
â•‘  â€¢ Datos &gt; 100MB que no caben cÃ³modamente en Git                              â•‘
â•‘  â€¢ Necesitas reproducibilidad exacta de datasets                              â•‘
â•‘  â€¢ Equipo colabora en el mismo pipeline de datos                              â•‘
â•‘  â€¢ Quieres DAGs declarativos para pipelines                                   â•‘
â•‘  â€¢ Datos son batch (no streaming)                                             â•‘
â•‘                                                                               â•‘
â•‘  âŒ NO USES DVC SI:                                                           â•‘
â•‘  â€¢ Datos &lt; 50MB y no cambian frecuentemente â†’ Git LFS o Git directo           â•‘
â•‘  â€¢ Datos son streaming (Kafka, Kinesis) â†’ No aplica versionado batch          â•‘
â•‘  â€¢ Ya tienes Data Lake con Delta Lake/Iceberg â†’ Usar versionado nativo        â•‘
â•‘  â€¢ Solo 1 persona trabaja en el proyecto â†’ Puede ser overkill                 â•‘
â•‘  â€¢ Pipeline ya estÃ¡ en Airflow/Prefect â†’ Evitar duplicaciÃ³n                   â•‘
â•‘                                                                               â•‘
â•‘  DECISIÃ“N PARA BANKCHURN:                                                     â•‘
â•‘  Usar DVC porque: datos ~50MB con potencial de crecer, equipo colabora,       â•‘
â•‘  queremos reproducibilidad completa, y el pipeline es batch.                  â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Lo Que LograrÃ¡s en Este MÃ³dulo</h3>
<ol>
<li><strong>Entender</strong> el problema del versionado de datos en ML</li>
<li><strong>Configurar</strong> DVC con remote storage</li>
<li><strong>Crear</strong> pipelines reproducibles con <code>dvc.yaml</code></li>
<li><strong>DiseÃ±ar</strong> DAGs para proyectos complejos</li>
</ol>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>En <code>BankChurn-Predictor/</code> ya tienes configurado DVC con:</li>
<li><code>dvc.yaml</code> y <code>params.yaml</code> en la raÃ­z del proyecto.</li>
<li>Carpeta <code>data/</code> con datasets y <code>.dvc/</code> con metadatos de versionado.</li>
<li>Desde esa carpeta puedes practicar el flujo completo de este mÃ³dulo ejecutando:<br />
<code>bash
  cd BankChurn-Predictor
  dvc status
  dvc repro
  dvc pull</code></li>
<li>Aplica los mismos principios a futuros proyectos del portafolio para mantener datos y<br />
  pipelines de forma reproducible, especialmente cuando crees el proyecto integrador.</li>
</ul>
<h2>5.1 El Problema: Git No Escala para Datos</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ˜± EL INFIERNO DEL VERSIONADO DE DATOS                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN VERSIONADO:                                                             â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â”œâ”€â”€ churn.csv                   # Â¿Original o procesado?                    â•‘
â•‘   â”œâ”€â”€ churn_v2.csv                # Â¿QuÃ© cambiÃ³?                              â•‘
â•‘   â”œâ”€â”€ churn_final.csv             # Â¿Es realmente el final?                   â•‘
â•‘   â”œâ”€â”€ churn_final_v2.csv          # ğŸ˜±                                        â•‘
â•‘   â”œâ”€â”€ churn_final_FINAL.csv       # ğŸ’€                                        â•‘
â•‘   â””â”€â”€ churn_20231115_backup.csv   # ???                                       â•‘
â•‘                                                                               â•‘
â•‘   PROBLEMAS:                                                                  â•‘
â•‘   â€¢ No sÃ© quÃ© datos usÃ³ el modelo v1.2.3                                      â•‘
â•‘   â€¢ No puedo reproducir resultados de hace 2 meses                            â•‘
â•‘   â€¢ Git se rompe con archivos grandes                                         â•‘
â•‘   â€¢ ColaboraciÃ³n es imposible (&quot;Â¿tienes el CSV actualizado?&quot;)                 â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   CON DVC:                                                                    â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â””â”€â”€ raw/                                                                    â•‘
â•‘       â””â”€â”€ churn.csv.dvc     # Metadatos en Git, datos en storage              â•‘
â•‘                                                                               â•‘
â•‘   git checkout v1.2.3 &amp;&amp; dvc checkout                                         â•‘
â•‘   â†’ Tengo EXACTAMENTE los datos de esa versiÃ³n                                â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Comparativa de Soluciones</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">SoluciÃ³n</th>
<th style="text-align: center;">TamaÃ±o MÃ¡x</th>
<th style="text-align: center;">Versionado</th>
<th style="text-align: center;">Pipelines</th>
<th style="text-align: center;">Costo</th>
<th style="text-align: center;">Complejidad</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Git directo</td>
<td style="text-align: center;">~10MB</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">Gratis</td>
<td style="text-align: center;">Baja</td>
</tr>
<tr>
<td style="text-align: left;">Git LFS</td>
<td style="text-align: center;">~2GB</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">$$$</td>
<td style="text-align: center;">Baja</td>
</tr>
<tr>
<td style="text-align: left;"><strong>DVC</strong></td>
<td style="text-align: center;">Ilimitado</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">Storage</td>
<td style="text-align: center;">Media</td>
</tr>
<tr>
<td style="text-align: left;">Delta Lake</td>
<td style="text-align: center;">Ilimitado</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">Spark</td>
<td style="text-align: center;">Alta</td>
</tr>
<tr>
<td style="text-align: left;">LakeFS</td>
<td style="text-align: center;">Ilimitado</td>
<td style="text-align: center;">âœ…</td>
<td style="text-align: center;">âŒ</td>
<td style="text-align: center;">Server</td>
<td style="text-align: center;">Alta</td>
</tr>
</tbody>
</table>
<h2>5.2 ConfiguraciÃ³n Inicial de DVC</h2>
<h3>InstalaciÃ³n</h3>
<pre><code class="language-bash"># Con pip
pip install dvc

# Con extras para storage
pip install &quot;dvc[s3]&quot;      # Amazon S3
pip install &quot;dvc[gs]&quot;      # Google Cloud Storage
pip install &quot;dvc[azure]&quot;   # Azure Blob Storage
pip install &quot;dvc[gdrive]&quot;  # Google Drive (para proyectos personales)
</code></pre>
<h3>InicializaciÃ³n</h3>
<pre><code class="language-bash"># En un repo Git existente
cd bankchurn-predictor
dvc init

# Esto crea:
# .dvc/           - Directorio de configuraciÃ³n
# .dvc/.gitignore
# .dvc/config
# .dvcignore      - QuÃ© ignorar (como .gitignore)
</code></pre>
<h3>Configurar Remote Storage</h3>
<pre><code class="language-bash"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 1: Local (para desarrollo)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d localremote /path/to/dvc-storage
# -d = default remote

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 2: Amazon S3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d s3remote s3://my-bucket/dvc-storage
dvc remote modify s3remote region us-east-1
# Credenciales: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY en env

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 3: Google Cloud Storage
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gcsremote gs://my-bucket/dvc-storage
# Credenciales: GOOGLE_APPLICATION_CREDENTIALS en env

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 4: Google Drive (Gratis, bueno para proyectos personales)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gdriveremote gdrive://folder-id
# La primera vez pedirÃ¡ autenticaciÃ³n OAuth

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ver configuraciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cat .dvc/config
</code></pre>
<h3>Estructura de Directorios Recomendada</h3>
<pre><code>bankchurn-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (DVC tracked)
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ churn.csv          # â†’ churn.csv.dvc en Git
â”‚   â”œâ”€â”€ processed/             # Datos procesados (output de pipeline)
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ external/              # Datos de terceros
â”‚       â””â”€â”€ .gitkeep
â”œâ”€â”€ models/                    # Modelos entrenados (DVC tracked)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ .dvc/
â”‚   â””â”€â”€ config
â”œâ”€â”€ .dvcignore
â””â”€â”€ dvc.yaml                   # Pipeline definition
</code></pre>
<h2>5.3 Versionado BÃ¡sico de Archivos</h2>
<h3>AÃ±adir Datos a DVC</h3>
<pre><code class="language-bash"># AÃ±adir archivo
dvc add data/raw/churn.csv

# Esto crea:
# data/raw/churn.csv.dvc   - Metadatos (hash, size)
# data/raw/.gitignore      - Ignora el CSV en Git

# Ver contenido del .dvc
cat data/raw/churn.csv.dvc
</code></pre>
<pre><code class="language-yaml"># data/raw/churn.csv.dvc
outs:
- md5: abc123def456...
  size: 52428800
  hash: md5
  path: churn.csv
</code></pre>
<h3>Flujo de Trabajo</h3>
<pre><code class="language-bash"># 1. Modificar datos
# ... (actualizar churn.csv con nuevos registros)

# 2. Actualizar tracking
dvc add data/raw/churn.csv

# 3. Commit ambos cambios
git add data/raw/churn.csv.dvc data/raw/.gitignore
git commit -m &quot;data(raw): update churn dataset with Q4 2024 data&quot;

# 4. Push datos a remote
dvc push

# 5. Push cÃ³digo a Git
git push
</code></pre>
<h3>Recuperar Datos de VersiÃ³n Anterior</h3>
<pre><code class="language-bash"># Ver versiones del archivo
git log data/raw/churn.csv.dvc

# Checkout versiÃ³n especÃ­fica
git checkout v1.0.0 -- data/raw/churn.csv.dvc
dvc checkout data/raw/churn.csv

# O mÃ¡s simple: checkout todo
git checkout v1.0.0
dvc checkout
# â†’ Ahora tienes cÃ³digo Y datos de v1.0.0
</code></pre>
<h2>5.4 Pipelines con dvc.yaml (El Poder Real)</h2>
<h3>Â¿Por QuÃ© Pipelines?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         PIPELINES DVC: REPRODUCIBILIDAD                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN PIPELINE:                                                               â•‘
â•‘   &quot;Para reproducir, ejecuta preprocess.py, luego train.py, luego...&quot;          â•‘
â•‘   &quot;Ah, pero primero asegÃºrate de tener los datos correctos...&quot;                â•‘
â•‘   &quot;Y usa los mismos hiperparÃ¡metros que estÃ¡n en... algÃºn lugar...&quot;           â•‘
â•‘                                                                               â•‘
â•‘   CON PIPELINE DVC:                                                           â•‘
â•‘   $ dvc repro                                                                 â•‘
â•‘   â†’ Ejecuta TODO automÃ¡ticamente, en orden correcto,                          â•‘
â•‘     saltando stages que no cambiaron.                                         â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>dvc.yaml Completo para BankChurn</h3>
<pre><code class="language-yaml"># dvc.yaml
stages:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 1: PreparaciÃ³n de Datos
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  prepare:
    cmd: python src/bankchurn/data/prepare.py
    deps:
      - src/bankchurn/data/prepare.py
      - data/raw/churn.csv
      - configs/config.yaml
    params:
      - prepare.test_size
      - prepare.random_state
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 2: Feature Engineering
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  featurize:
    cmd: python src/bankchurn/features/build.py
    deps:
      - src/bankchurn/features/build.py
      - data/processed/train.csv
      - data/processed/test.csv
      - configs/config.yaml
    params:
      - features.numerical
      - features.categorical
    outs:
      - data/processed/train_features.pkl
      - data/processed/test_features.pkl

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 3: Entrenamiento
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  train:
    cmd: python src/bankchurn/training.py
    deps:
      - src/bankchurn/training.py
      - data/processed/train_features.pkl
      - configs/config.yaml
    params:
      - train.n_estimators
      - train.max_depth
      - train.random_state
    outs:
      - models/pipeline.pkl
    metrics:
      - metrics/train_metrics.json:
          cache: false

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 4: EvaluaciÃ³n
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  evaluate:
    cmd: python src/bankchurn/evaluate.py
    deps:
      - src/bankchurn/evaluate.py
      - models/pipeline.pkl
      - data/processed/test_features.pkl
    metrics:
      - metrics/eval_metrics.json:
          cache: false
    plots:
      - metrics/roc_curve.json:
          x: fpr
          y: tpr
      - metrics/confusion_matrix.json:
          template: confusion
          x: predicted
          y: actual
</code></pre>
<h3>params.yaml (ConfiguraciÃ³n del Pipeline)</h3>
<pre><code class="language-yaml"># params.yaml
prepare:
  test_size: 0.2
  random_state: 42

features:
  numerical:
    - CreditScore
    - Age
    - Tenure
    - Balance
    - NumOfProducts
    - EstimatedSalary
  categorical:
    - Geography
    - Gender

train:
  n_estimators: 100
  max_depth: 10
  random_state: 42
</code></pre>
<h3>Comandos de Pipeline</h3>
<pre><code class="language-bash"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REPRODUCIR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ejecutar todo el pipeline
dvc repro

# Ejecutar stage especÃ­fico (y sus dependencias)
dvc repro train

# Forzar re-ejecuciÃ³n (aunque no haya cambios)
dvc repro --force

# Ver quÃ© se ejecutarÃ­a sin ejecutar
dvc repro --dry

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZAR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver DAG en terminal
dvc dag

# Generar imagen del DAG
dvc dag --dot | dot -Tpng -o pipeline.png

# Ver dependencias de un stage
dvc dag --outs train
</code></pre>
<h3>VisualizaciÃ³n del DAG</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              DVC DAG: BANKCHURN                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚  data/raw/*.csv â”‚                                    â•‘
â•‘                        â”‚  configs/*.yaml â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                                 â–¼                                             â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚    prepare      â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                                 â–¼                                             â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚   featurize     â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â•‘
â•‘                     â–¼                       â–¼                                 â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â•‘
â•‘            â”‚     train       â”‚    â”‚    (test data)  â”‚                         â•‘
â•‘            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â•‘
â•‘                     â”‚                      â”‚                                  â•‘
â•‘                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â•‘
â•‘                                â–¼                                              â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â•‘
â•‘                       â”‚    evaluate     â”‚                                     â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â•‘
â•‘                                â”‚                                              â•‘
â•‘                                â–¼                                              â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â•‘
â•‘                       â”‚    metrics/     â”‚                                     â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>5.5 MÃ©tricas y Experimentos</h2>
<h3>Tracking de MÃ©tricas</h3>
<pre><code class="language-bash"># Ver mÃ©tricas actuales
dvc metrics show

# Comparar con otra rama/commit
dvc metrics diff HEAD~1

# Output ejemplo:
# Path                     Metric    HEAD     HEAD~1   Change
# metrics/eval_metrics.json  auc_roc   0.8721   0.8534   0.0187
# metrics/eval_metrics.json  f1        0.7234   0.7012   0.0222
</code></pre>
<h3>Experimentos con DVC</h3>
<pre><code class="language-bash"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EJECUTAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Experimento con cambio de parÃ¡metro
dvc exp run --set-param train.n_estimators=200

# MÃºltiples experimentos en paralelo
dvc exp run --queue --set-param train.n_estimators=100
dvc exp run --queue --set-param train.n_estimators=200
dvc exp run --queue --set-param train.n_estimators=300
dvc exp run --run-all --parallel 3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPARAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver todos los experimentos
dvc exp show

# Output:
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
# â”ƒ Experiment    â”ƒ auc_roc     â”ƒ f1          â”ƒ n_estimators   â”ƒ
# â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
# â”‚ main          â”‚ 0.8721      â”‚ 0.7234      â”‚ 100            â”‚
# â”‚ exp-abc123    â”‚ 0.8856      â”‚ 0.7421      â”‚ 200            â”‚
# â”‚ exp-def456    â”‚ 0.8812      â”‚ 0.7356      â”‚ 300            â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APLICAR MEJOR EXPERIMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Aplicar a workspace
dvc exp apply exp-abc123

# O crear branch
dvc exp branch exp-abc123 feature/best-model
</code></pre>
<h2>5.6 Patrones Avanzados</h2>
<h3>Multi-Output Stages</h3>
<pre><code class="language-yaml"># dvc.yaml
stages:
  split:
    cmd: python src/split.py
    deps:
      - data/raw/full_dataset.csv
    outs:
      - data/processed/train.csv
      - data/processed/val.csv
      - data/processed/test.csv
</code></pre>
<h3>Stages Condicionales (foreach)</h3>
<pre><code class="language-yaml"># dvc.yaml - Entrenar mÃºltiples modelos
stages:
  train:
    foreach:
      - random_forest
      - xgboost
      - lightgbm
    do:
      cmd: python src/train.py --model ${item}
      deps:
        - src/train.py
        - data/processed/train.csv
      params:
        - train.${item}
      outs:
        - models/${item}.pkl
      metrics:
        - metrics/${item}_metrics.json:
            cache: false
</code></pre>
<h3>IntegraciÃ³n con MLflow</h3>
<pre><code class="language-python"># src/bankchurn/training.py
import mlflow
import dvc.api
import yaml

def train():
    # Obtener parÃ¡metros de DVC
    params = dvc.api.params_show()

    with mlflow.start_run():
        # Log parÃ¡metros
        mlflow.log_params(params[&quot;train&quot;])

        # Entrenar...
        model = train_model(params[&quot;train&quot;])

        # Log mÃ©tricas
        metrics = evaluate(model)
        mlflow.log_metrics(metrics)

        # Guardar mÃ©tricas para DVC tambiÃ©n
        with open(&quot;metrics/train_metrics.json&quot;, &quot;w&quot;) as f:
            json.dump(metrics, f)

        # Log modelo
        mlflow.sklearn.log_model(model, &quot;model&quot;)
---

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en DVC

Aunque DVC parece â€œsolo aÃ±adir un comando mÃ¡sâ€, en la prÃ¡ctica los errores suelen venir de **desalineaciÃ³n entre Git, datos y configuraciÃ³n**.

### 1) Datos no aparecen al clonar el repo (`dvc pull`/`dvc checkout` olvidados)

**SÃ­ntomas tÃ­picos**

- Clonas el repositorio, ejecutas el cÃ³digo y obtienes errores como:
  ```text
  FileNotFoundError: data/raw/churn.csv not found
  ```
- La carpeta `data/` estÃ¡ vacÃ­a o solo tiene `.gitkeep`.

**CÃ³mo identificarlo**

- Ejecuta:
  ```bash
  dvc list .
  dvc status
  ```
  para ver quÃ© outs estÃ¡n trackeados.
- Mira si existen archivos `.dvc` (`data/raw/churn.csv.dvc`) pero no los datos reales.

**CÃ³mo corregirlo**

- DespuÃ©s de clonar o cambiar de rama/tag, **siempre** ejecuta:
  ```bash
  dvc pull      # trae los datos desde el remote
  dvc checkout  # sincroniza versiones de datos con los .dvc actuales
  ```
- Documenta esto en el README del proyecto y en este mÃ³dulo como parte del flujo estÃ¡ndar.

---

### 2) `.dvc` committeados pero remote sin configurar (`dvc push` fallando)

**SÃ­ntomas tÃ­picos**

- Haces `dvc push` y ves errores tipo:
  ```text
  ERROR: failed to push data to the cloud - config file error
  ```
  o credenciales faltantes.
- CompaÃ±eros de equipo tienen los `.dvc`, pero `dvc pull` no trae nada.

**CÃ³mo identificarlo**

- Revisa `.dvc/config` para ver quÃ© remote estÃ¡ configurado (`localremote`, `s3remote`, etc.).
- Ejecuta `dvc remote list` y valida que el remote por defecto (`-d`) exista y sea accesible.

**CÃ³mo corregirlo**

- AsegÃºrate de que todos usen **el mismo nombre de remote** y que estÃ© configurado en el repo (no solo en local).
- Para remotes cloud (S3, GCS): documenta las variables de entorno necesarias (`AWS_ACCESS_KEY_ID`, etc.).
- Haz un `dvc push` de prueba y luego un `dvc pull` desde otra mÃ¡quina para validar.

---

### 3) `dvc repro` no ejecuta stages que esperas (cambios no detectados)

**SÃ­ntomas tÃ­picos**

- Modificas cÃ³digo o parÃ¡metros, ejecutas `dvc repro` y ves:
  ```text
  Stage 'train' didn't change, skipping
  ```
  aunque esperabas que volviera a entrenar.

**CÃ³mo identificarlo**

- Mira el `dvc.yaml` y verifica que:
  - El script que cambiaste estÃ© en `deps:` del stage.
  - Los parÃ¡metros que tocaste estÃ©n en `params:`.

**CÃ³mo corregirlo**

- AsegÃºrate de listar **todas las dependencias reales** en `deps:` (scripts, configs, datos intermedios).
- Si cambiaste parÃ¡metros en `params.yaml`, agrÃ©galos a la lista `params:` del stage correspondiente.
- Si quieres forzar una re-ejecuciÃ³n puntual, usa `dvc repro --force train`.

---

### 4) Conflictos entre `.gitignore` y `.dvc` (datos en Git por accidente)

**SÃ­ntomas tÃ­picos**

- Ves archivos grandes (`data/raw/*.csv`, `models/*.pkl`) en `git status`.
- Existen `.dvc` pero los datos tambiÃ©n se han aÃ±adido a Git.

**CÃ³mo identificarlo**

- Revisa `data/raw/.gitignore` generado por `dvc add` y el `.gitignore` del proyecto principal; puede que se estÃ©n pisando.

**CÃ³mo corregirlo**

- Respeta el patrÃ³n DVC:
  - Los datos **no** se aÃ±aden a Git, solo los `.dvc`.
  - AsegÃºrate de que `.gitignore` incluya las carpetas de datos/artefactos y que no contradiga los `.gitignore` generados por DVC.
- Si ya has commiteado datos grandes, elimÃ­nalos del historial (o al menos del Ãºltimo commit) y deja solo los `.dvc`.

---

### 5) DVC + CI/CD: pipelines que fallan en GitHub Actions

**SÃ­ntomas tÃ­picos**

- En CI, `dvc repro` falla porque no encuentra datos o no tiene acceso al remote.

**CÃ³mo identificarlo**

- Revisa el workflow de CI y verifica si:
  - Has instalado DVC con los extras correctos (`dvc[s3]`, etc.).
  - Has configurado variables de entorno con credenciales.
  - EstÃ¡s ejecutando `dvc pull` **antes** de correr el pipeline.

**CÃ³mo corregirlo**

- AÃ±ade pasos en tu workflow:
  ```yaml
  - name: Install DVC
    run: pip install &quot;dvc[s3]&quot;

  - name: Pull data with DVC
    run: dvc pull

  - name: Run pipeline
    run: dvc repro
  ```
- Usa `dvc repro --dry` localmente para ver quÃ© deberÃ­a ejecutarse antes de llevarlo a CI.

---

### PatrÃ³n general de debugging en DVC

1. **Inspecciona el estado** con `dvc status` y `dvc dag`.
2. **Verifica remotes y credenciales** (`dvc remote list`, `.dvc/config`).
3. **Comprueba deps/outs/params** en `dvc.yaml` para el stage problemÃ¡tico.
4. **Sincroniza Git + DVC**: `git checkout &lt;tag/branch&gt;` seguido de `dvc checkout` y `dvc pull` si hace falta.

Con este checklist, DVC pasa de ser â€œcaja negra que fallaâ€ a una herramienta controlable para reproducir datos y pipelines.

---

## 5.7 Ejercicio Integrador

### Setup Completo de DVC

```bash

# 1. Inicializar DVC
cd bankchurn-predictor
dvc init

# 2. Configurar remote (local para empezar)
mkdir -p ~/dvc-storage
dvc remote add -d localremote ~/dvc-storage

# 3. Crear estructura de datos
mkdir -p data/{raw,processed} models metrics

# 4. AÃ±adir datos raw

# (asumiendo que tienes churn.csv)
cp /path/to/churn.csv data/raw/
dvc add data/raw/churn.csv

# 5. Crear dvc.yaml (copiar del ejemplo anterior)

# 6. Crear params.yaml

# 7. Commit todo
git add .
git commit -m &quot;data(dvc): setup DVC pipeline&quot;

# 8. Ejecutar pipeline
dvc repro

# 9. Push a remote
dvc push
git push
</code></pre>
<h3>Checklist de VerificaciÃ³n</h3>
<pre><code>CONFIGURACIÃ“N:
[ ] DVC inicializado
[ ] Remote configurado y funcionando
[ ] Datos raw tracked con DVC

PIPELINE:
[ ] dvc.yaml con stages definidos
[ ] params.yaml con parÃ¡metros
[ ] dvc repro ejecuta sin errores

VERSIONADO:
[ ] Puedo hacer git checkout + dvc checkout a versiones anteriores
[ ] dvc push/pull funcionan correctamente
[ ] MÃ©tricas se trackean con dvc metrics show
</code></pre>
<hr />
<h2>5.8 AutoevaluaciÃ³n</h2>
<h3>Preguntas de ReflexiÃ³n</h3>
<ol>
<li>Â¿Por quÃ© DVC usa hashes MD5 en lugar de guardar los archivos?</li>
<li>Â¿QuÃ© pasa si cambio <code>params.yaml</code> pero no el cÃ³digo?</li>
<li>Â¿CuÃ¡ndo DVC salta un stage sin ejecutarlo?</li>
<li>Â¿CÃ³mo integrarÃ­as DVC con GitHub Actions para CI?</li>
</ol>
<hr />
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El portafolio tiene DVC configurado a nivel global:</p>
<h3>Estructura DVC del Portafolio</h3>
<pre><code>ML-MLOps-Portfolio/
â”œâ”€â”€ .dvc/                  # ConfiguraciÃ³n DVC
â”‚   â””â”€â”€ config             # Remote storage config
â”œâ”€â”€ .dvc-storage/          # Remote local (para demo)
â”œâ”€â”€ .dvcignore            # Archivos a ignorar
â””â”€â”€ */data/raw/*.dvc       # Archivos .dvc en cada proyecto
</code></pre>
<h3>Archivos .dvc Reales</h3>
<pre><code class="language-bash">
# BankChurn-Predictor/data/raw/bank_churn.csv.dvc
md5: abc123def456...
size: 1234567
path: bank_churn.csv

# CarVision-Market-Intelligence/data/raw/car_prices.csv.dvc
md5: xyz789ghi012...
size: 2345678
path: car_prices.csv
</code></pre>
<h3>Flujo de Datos en el Portafolio</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE DATOS DVC                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  data/raw/*.csv    â†’    .dvc files    â†’    .dvc-storage/     â”‚
â”‚  (gitignored)           (tracked)          (remote local)    â”‚
â”‚                                                              â”‚
â”‚  Para CI/CD:                                                 â”‚
â”‚  git clone â†’ dvc pull â†’ datos disponibles                    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Comandos DVC del Portafolio</h3>
<pre><code class="language-bash">
# Ver quÃ© datos estÃ¡n trackeados
dvc status

# Obtener datos despuÃ©s de clonar
dvc pull

# Agregar nuevos datos
dvc add data/raw/nuevos_datos.csv
git add data/raw/nuevos_datos.csv.dvc data/raw/.gitignore
git commit -m &quot;data(dvc): add nuevos_datos&quot;
dvc push
</code></pre>
<h3>ğŸ”§ Ejercicio: Trabaja con DVC Real</h3>
<pre><code class="language-bash">
# 1. Ve a la raÃ­z del portafolio
cd ML-MLOps-Portfolio

# 2. Verifica estado de DVC
dvc status

# 3. ObtÃ©n los datos (si no los tienes)
dvc pull

# 4. Verifica que los datos existen
ls -la BankChurn-Predictor/data/raw/
ls -la CarVision-Market-Intelligence/data/raw/

# 5. Experimenta: modifica params y reproduce
cd BankChurn-Predictor
dvc repro  # Si tienes dvc.yaml configurado
</code></pre>
<hr />
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>DVC vs Git LFS</strong>: Explica que DVC es especÃ­fico para ML (pipelines, mÃ©tricas), LFS es genÃ©rico para archivos grandes.</p>
</li>
<li>
<p><strong>Reproducibilidad</strong>: Menciona que puedes recrear cualquier experimento con <code>dvc checkout</code> + <code>git checkout</code>.</p>
</li>
<li>
<p><strong>Data Lineage</strong>: Explica cÃ³mo DVC trackea la procedencia de datos transformados.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Datos sensibles</td>
<td>Usa DVC con storage encriptado (S3 + KMS)</td>
</tr>
<tr>
<td>Datasets grandes</td>
<td>Usa <code>dvc push/pull</code> selectivo por carpeta</td>
</tr>
<tr>
<td>CI/CD</td>
<td>Cachea datos en CI para evitar descargas repetidas</td>
</tr>
<tr>
<td>ColaboraciÃ³n</td>
<td>Documenta dÃ³nde estÃ¡ el remote storage</td>
</tr>
</tbody>
</table>
<h3>Flujo Profesional de Datos</h3>
<ol>
<li>Raw data â†’ nunca modificar, solo agregar</li>
<li>Processed data â†’ versionado con DVC</li>
<li>Features â†’ cacheados para reutilizaciÃ³n</li>
<li>Modelos â†’ versionados con mÃ©tricas</li>
</ol>
<hr />
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=kLKBcPonMYw">DVC Tutorial - DataTalks</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://dvc.org/doc">DVC Documentation</a></td>
<td style="text-align: left;">Docs</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>DVC</strong>: Data Version Control<br />
- <strong>Remote Storage</strong>: Almacenamiento externo para datos<br />
- <strong>dvc.yaml</strong>: DefiniciÃ³n de pipelines reproducibles</p>
<hr />
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 06:<br />
- <strong>6.1</strong>: Configurar DVC en proyecto<br />
- <strong>6.2</strong>: Push/pull de datos</p>
<hr />
<h2>ğŸ¤ Checkpoint: Simulacro Junior</h2>
<blockquote>
<p>ğŸ¯ <strong>Â¡Has completado los fundamentos!</strong> (MÃ³dulos 01-06)</p>
<p>Si buscas posiciones <strong>Junior ML Engineer</strong>, ahora es buen momento para practicar:</p>
<p><strong><a href="#mod_SIMULACRO_ENTREVISTA_JUNIOR">â†’ SIMULACRO_ENTREVISTA_JUNIOR.md</a></strong><br />
- 50 preguntas de Python, ML bÃ¡sico, Git y estructura<br />
- Enfoque en fundamentos y capacidad de aprendizaje</p>
</blockquote>
<hr />
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con datos versionados, es hora de construir <strong>pipelines de sklearn avanzados</strong>.</p>
<p><strong><a href="#mod_07_SKLEARN_PIPELINES">Ir a MÃ³dulo 07: sklearn Pipelines â†’</a></strong></p>
<hr />
<div align="center">

[â† Git Profesional](#mod_05_GIT_PROFESIONAL) | [Siguiente: sklearn Pipelines â†’](#mod_07_SKLEARN_PIPELINES)

</div>
            </div>
        
            <!-- MÃ“DULO: SIMULACRO_ENTREVISTA_JUNIOR.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_SIMULACRO_ENTREVISTA_JUNIOR" class="cover-title">SIMULACRO ENTREVISTA JUNIOR</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ¯ Simulacro de Entrevista Junior ML Engineer</h1>
<h2>Portafolio MLOps â€” 50 Preguntas Fundamentales</h2>
<p><strong>Autor del Portafolio</strong>: Daniel Duque (DuqueOM)<br />
<strong>VersiÃ³n</strong>: 1.0<br />
<strong>Fecha</strong>: Diciembre 2025<br />
<strong>Nivel</strong>: Junior (0-2 aÃ±os de experiencia)</p>
<h2>ğŸ“‹ Ãndice</h2>
<ol>
<li><a href="#1-python-bÃ¡sico-preguntas-1-10">Python BÃ¡sico</a></li>
<li><a href="#2-machine-learning-fundamentos-preguntas-11-20">Machine Learning Fundamentos</a></li>
<li><a href="#3-datos-y-preprocesamiento-preguntas-21-30">Datos y Preprocesamiento</a></li>
<li><a href="#4-git-y-herramientas-preguntas-31-40">Git y Herramientas</a></li>
<li><a href="#5-prÃ¡ctica-con-el-portafolio-preguntas-41-50">PrÃ¡ctica con el Portafolio</a></li>
</ol>
<h2>ğŸ¯ Antes de Empezar</h2>
<h3>Â¿QuÃ© se espera de un Junior?</h3>
<table>
<thead>
<tr>
<th>Lo que SÃ se espera</th>
<th>Lo que NO se espera</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fundamentos sÃ³lidos de Python</td>
<td>DiseÃ±o de arquitecturas complejas</td>
</tr>
<tr>
<td>Entender train/test split</td>
<td>OptimizaciÃ³n de hiperparÃ¡metros avanzada</td>
</tr>
<tr>
<td>Saber quÃ© es overfitting</td>
<td>Implementar MLOps completo</td>
</tr>
<tr>
<td>Usar Git bÃ¡sico</td>
<td>CI/CD avanzado</td>
</tr>
<tr>
<td>Leer y modificar cÃ³digo existente</td>
<td>Escribir cÃ³digo de producciÃ³n desde cero</td>
</tr>
<tr>
<td>Hacer preguntas inteligentes</td>
<td>Tener todas las respuestas</td>
</tr>
</tbody>
</table>
<h3>Consejos para la Entrevista</h3>
<ol>
<li><strong>SÃ© honesto</strong>: "No lo sÃ©, pero lo investigarÃ­a asÃ­..." es mejor que inventar</li>
<li><strong>Muestra curiosidad</strong>: Haz preguntas sobre el cÃ³digo que ves</li>
<li><strong>Relaciona con el portafolio</strong>: "En BankChurn aprendÃ­ que..."</li>
<li><strong>Piensa en voz alta</strong>: El proceso importa mÃ¡s que la respuesta perfecta</li>
</ol>
<h1>1. Python BÃ¡sico (Preguntas 1-10)</h1>
<h2>Pregunta 1: Tipos de Datos</h2>
<p><strong>Â¿CuÃ¡l es la diferencia entre lista, tupla y diccionario?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Lista: mutable, ordenada
features = [&quot;age&quot;, &quot;salary&quot;, &quot;tenure&quot;]
features.append(&quot;score&quot;)  # OK

# Tupla: inmutable, ordenada
coordinates = (40.7, -74.0)
# coordinates[0] = 41.0  # ERROR

# Diccionario: mutable, key-value
customer = {&quot;id&quot;: 123, &quot;name&quot;: &quot;John&quot;, &quot;churn&quot;: False}
customer[&quot;score&quot;] = 0.85  # OK
</code></pre>
<p><strong>CuÃ¡ndo usar cada uno</strong>:<br />
- <strong>Lista</strong>: ColecciÃ³n que cambiarÃ¡ (features a seleccionar)<br />
- <strong>Tupla</strong>: Datos que no deben cambiar (coordenadas, constantes)<br />
- <strong>Diccionario</strong>: Acceso por clave (configuraciÃ³n, datos de cliente)</p>
<h2>Pregunta 2: List Comprehension</h2>
<p><strong>Reescribe este cÃ³digo con list comprehension:</strong></p>
<pre><code class="language-python">result = []
for x in range(10):
    if x % 2 == 0:
        result.append(x**2)
</code></pre>
<h3>Respuesta:</h3>
<pre><code class="language-python">result = [x**2 for x in range(10) if x % 2 == 0]
# [0, 4, 16, 36, 64]
</code></pre>
<p><strong>Ventajas</strong>:<br />
- MÃ¡s conciso<br />
- MÃ¡s rÃ¡pido (optimizado internamente)<br />
- MÃ¡s "pythÃ³nico"</p>
<h2>Pregunta 3: Funciones y Argumentos</h2>
<p><strong>Â¿QuÃ© hace <code>*args</code> y <code>**kwargs</code>?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def log_experiment(*args, **kwargs):
    # args: tupla de argumentos posicionales
    # kwargs: diccionario de argumentos con nombre
    print(f&quot;Metrics: {args}&quot;)
    print(f&quot;Config: {kwargs}&quot;)

log_experiment(0.85, 0.82, model=&quot;rf&quot;, n_estimators=100)
# Metrics: (0.85, 0.82)
# Config: {'model': 'rf', 'n_estimators': 100}
</code></pre>
<p><strong>En el portafolio</strong> (<code>BankChurn/trainer.py</code>):</p>
<pre><code class="language-python">def __init__(self, config: BankChurnConfig, **kwargs):
    self.config = config
    self.extra_params = kwargs  # Flexibilidad para params adicionales
</code></pre>
<h2>Pregunta 4: Manejo de Errores</h2>
<p><strong>Â¿Por quÃ© usamos try/except?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def load_data(path: str) -&gt; pd.DataFrame:
    try:
        df = pd.read_csv(path)
        return df
    except FileNotFoundError:
        print(f&quot;Error: {path} no existe&quot;)
        raise
    except pd.errors.EmptyDataError:
        print(&quot;Error: archivo vacÃ­o&quot;)
        raise
</code></pre>
<p><strong>Buenas prÃ¡cticas</strong>:<br />
- Capturar excepciones especÃ­ficas, no genÃ©ricas<br />
- Hacer logging del error<br />
- Re-lanzar si no puedes manejarlo</p>
<h2>Pregunta 5: Import y MÃ³dulos</h2>
<p><strong>Â¿CuÃ¡l es la diferencia entre estas formas de import?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Importar mÃ³dulo completo
import pandas as pd
df = pd.read_csv(&quot;data.csv&quot;)

# Importar funciÃ³n especÃ­fica
from sklearn.model_selection import train_test_split
X_train, X_test = train_test_split(X)

# Importar todo (âš ï¸ evitar en producciÃ³n)
from math import *  # Contamina el namespace
</code></pre>
<p><strong>Best practice</strong>: Importar lo que necesitas, usar alias estÃ¡ndar (<code>pd</code>, <code>np</code>, <code>plt</code>).</p>
<h2>Pregunta 6: Type Hints</h2>
<p><strong>Â¿QuÃ© significan los type hints y por quÃ© usarlos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def predict_churn(
    credit_score: int,
    age: int,
    is_active: bool
) -&gt; float:
    &quot;&quot;&quot;Retorna probabilidad de churn.&quot;&quot;&quot;
    ...
</code></pre>
<p><strong>Beneficios</strong>:<br />
1. <strong>DocumentaciÃ³n</strong>: Claro quÃ© espera y retorna<br />
2. <strong>IDE support</strong>: Autocompletado, detecciÃ³n de errores<br />
3. <strong>Tooling</strong>: <code>mypy</code> puede verificar tipos</p>
<p><strong>En el portafolio</strong>: Todos los archivos usan type hints (<code>config.py</code>, <code>training.py</code>).</p>
<h2>Pregunta 7: Clases BÃ¡sicas</h2>
<p><strong>Â¿QuÃ© es <code>__init__</code> y <code>self</code>?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class BankChurnTrainer:
    def __init__(self, config):
        # Constructor: se ejecuta al crear instancia
        self.config = config  # self = esta instancia
        self.model_ = None

    def train(self, X, y):
        # self permite acceder a atributos de la instancia
        if self.config.model_type == &quot;rf&quot;:
            self.model_ = RandomForestClassifier()
        self.model_.fit(X, y)

# Uso
trainer = BankChurnTrainer(config)  # __init__ se llama aquÃ­
trainer.train(X, y)
</code></pre>
<h2>Pregunta 8: Lectura de Archivos</h2>
<p><strong>Â¿CÃ³mo lees un archivo CSV con pandas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import pandas as pd

# BÃ¡sico
df = pd.read_csv(&quot;data/raw/Churn.csv&quot;)

# Con opciones
df = pd.read_csv(
    &quot;data/raw/Churn.csv&quot;,
    sep=&quot;,&quot;,
    encoding=&quot;utf-8&quot;,
    na_values=[&quot;&quot;, &quot;NA&quot;, &quot;null&quot;],
    dtype={&quot;customer_id&quot;: str}
)

# Verificar
print(df.shape)       # (10000, 14)
print(df.info())      # Tipos y nulls
print(df.head())      # Primeras filas
</code></pre>
<h2>Pregunta 9: Entornos Virtuales</h2>
<p><strong>Â¿Por quÃ© usamos entornos virtuales?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># Crear entorno
python -m venv .venv

# Activar
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
</code></pre>
<p><strong>Razones</strong>:<br />
1. <strong>Aislamiento</strong>: Cada proyecto tiene sus propias versiones<br />
2. <strong>Reproducibilidad</strong>: Mismo entorno en cualquier mÃ¡quina<br />
3. <strong>Evita conflictos</strong>: sklearn 1.3 en proyecto A, sklearn 1.2 en proyecto B</p>
<h2>Pregunta 10: Debugging BÃ¡sico</h2>
<p><strong>Â¿CÃ³mo depuras cÃ³digo en Python?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Print statements (bÃ¡sico pero Ãºtil)
print(f&quot;X shape: {X.shape}, y shape: {y.shape}&quot;)

# 2. Usar assert
assert X.shape[0] == y.shape[0], &quot;Mismatch en filas&quot;

# 3. Breakpoints en IDE (recomendado)
# Poner breakpoint y usar F5 para debugear

# 4. pdb (en terminal)
import pdb; pdb.set_trace()

# 5. Logging (producciÃ³n)
import logging
logging.debug(f&quot;Loaded {len(df)} rows&quot;)
</code></pre>
<h1>2. Machine Learning Fundamentos (Preguntas 11-20)</h1>
<h2>Pregunta 11: Train/Test Split</h2>
<p><strong>Â¿Por quÃ© separamos datos en train y test?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 80/20 split
    random_state=42,    # Reproducibilidad
    stratify=y          # Mantener proporciÃ³n de clases
)
</code></pre>
<p><strong>RazÃ³n</strong>: Evaluar cÃ³mo el modelo generaliza a datos <strong>nunca vistos</strong>.<br />
- <strong>Train</strong>: Aprende patrones<br />
- <strong>Test</strong>: Simula producciÃ³n, mide rendimiento real</p>
<p><strong>Error comÃºn</strong>: Usar test para ajustar modelo â†’ overfitting al test.</p>
<h2>Pregunta 12: Overfitting vs Underfitting</h2>
<p><strong>Explica overfitting y underfitting.</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Concepto</th>
<th>SÃ­ntomas</th>
<th>Causa</th>
<th>SoluciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Overfitting</strong></td>
<td>Train acc: 99%, Test acc: 70%</td>
<td>Modelo muy complejo</td>
<td>RegularizaciÃ³n, mÃ¡s datos, simplificar</td>
</tr>
<tr>
<td><strong>Underfitting</strong></td>
<td>Train acc: 60%, Test acc: 58%</td>
<td>Modelo muy simple</td>
<td>MÃ¡s features, modelo mÃ¡s complejo</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># Detectar en el portafolio
print(f&quot;Train accuracy: {model.score(X_train, y_train):.2%}&quot;)
print(f&quot;Test accuracy: {model.score(X_test, y_test):.2%}&quot;)

# Si diferencia &gt; 10%, posible overfitting
</code></pre>
<h2>Pregunta 13: ClasificaciÃ³n vs RegresiÃ³n</h2>
<p><strong>Â¿CuÃ¡ndo usar clasificaciÃ³n y cuÃ¡ndo regresiÃ³n?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Problema</th>
<th>Tipo</th>
<th>Target</th>
<th>MÃ©trica</th>
</tr>
</thead>
<tbody>
<tr>
<td>Â¿Cliente harÃ¡ churn?</td>
<td>ClasificaciÃ³n</td>
<td>SÃ­/No (0/1)</td>
<td>Accuracy, F1, AUC</td>
</tr>
<tr>
<td>Â¿CuÃ¡nto cuesta el auto?</td>
<td>RegresiÃ³n</td>
<td>Precio ($)</td>
<td>RMSE, MAE, RÂ²</td>
</tr>
<tr>
<td>Â¿QuÃ© plan elegirÃ¡?</td>
<td>ClasificaciÃ³n multiclase</td>
<td>A/B/C</td>
<td>Accuracy, F1 macro</td>
</tr>
</tbody>
</table>
<p><strong>En el portafolio</strong>:<br />
- <strong>BankChurn</strong>: ClasificaciÃ³n binaria (churn: 0/1)<br />
- <strong>CarVision</strong>: RegresiÃ³n (precio continuo)<br />
- <strong>TelecomAI</strong>: ClasificaciÃ³n multiclase (tipo de plan)</p>
<h2>Pregunta 14: Cross-Validation</h2>
<p><strong>Â¿QuÃ© es cross-validation y por quÃ© usarla?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f&quot;Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})&quot;)
</code></pre>
<p><strong>Proceso K-Fold (K=5)</strong>:<br />
1. Divide datos en 5 partes iguales<br />
2. Entrena en 4, valida en 1<br />
3. Repite 5 veces (cada parte es validaciÃ³n una vez)<br />
4. Promedia resultados</p>
<p><strong>Ventajas</strong>:<br />
- Usa todos los datos para entrenar y validar<br />
- EstimaciÃ³n mÃ¡s robusta del rendimiento<br />
- Detecta variabilidad del modelo</p>
<h2>Pregunta 15: Feature Scaling</h2>
<p><strong>Â¿Por quÃ© normalizamos features?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# Antes: age=[18-92], salary=[20000-200000]
# DespuÃ©s: ambas con media=0, std=1
</code></pre>
<p><strong>Razones</strong>:<br />
1. <strong>Algoritmos sensibles a escala</strong>: SVM, KNN, redes neuronales<br />
2. <strong>Gradiente descent</strong>: Converge mÃ¡s rÃ¡pido<br />
3. <strong>InterpretaciÃ³n</strong>: Coeficientes comparables</p>
<p><strong>Algoritmos que NO necesitan scaling</strong>: Random Forest, Decision Tree, XGBoost.</p>
<h2>Pregunta 16: One-Hot Encoding</h2>
<p><strong>Â¿CÃ³mo manejas variables categÃ³ricas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(df[['Geography', 'Gender']])

# Geography: France, Germany, Spain
# â†’ Geography_France, Geography_Germany, Geography_Spain
</code></pre>
<p><strong>Alternativas</strong>:<br />
- <strong>Label Encoding</strong>: Para ordinales (Bajo &lt; Medio &lt; Alto)<br />
- <strong>Target Encoding</strong>: Codifica con la media del target (âš ï¸ riesgo de leakage)</p>
<h2>Pregunta 17: Missing Values</h2>
<p><strong>Â¿CÃ³mo manejas valores faltantes?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.impute import SimpleImputer

# NumÃ©ricos: media o mediana
imputer_num = SimpleImputer(strategy='median')

# CategÃ³ricos: moda o valor constante
imputer_cat = SimpleImputer(strategy='constant', fill_value='Unknown')
</code></pre>
<p><strong>Estrategias</strong>:</p>
<table>
<thead>
<tr>
<th>Caso</th>
<th>Estrategia</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pocos missing (&lt;5%)</td>
<td>Imputar con media/moda</td>
</tr>
<tr>
<td>Muchos missing</td>
<td>Considerar eliminar columna</td>
</tr>
<tr>
<td>Missing tiene significado</td>
<td>Crear feature <code>is_missing</code></td>
</tr>
</tbody>
</table>
<h2>Pregunta 18: Random Forest</h2>
<p><strong>Explica cÃ³mo funciona Random Forest.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(
    n_estimators=100,  # 100 Ã¡rboles
    max_depth=10,      # Profundidad mÃ¡xima
    random_state=42
)
</code></pre>
<p><strong>Concepto simple</strong>:<br />
1. Crea N Ã¡rboles de decisiÃ³n<br />
2. Cada Ã¡rbol usa subset aleatorio de datos y features<br />
3. PredicciÃ³n final = voto mayoritario (clasificaciÃ³n) o promedio (regresiÃ³n)</p>
<p><strong>Ventajas</strong>: Robusto, pocas configuraciones, maneja bien missing values.</p>
<h2>Pregunta 19: MÃ©tricas de ClasificaciÃ³n</h2>
<p><strong>Â¿QuÃ© es accuracy, precision, recall y F1?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))
</code></pre>
<table>
<thead>
<tr>
<th>MÃ©trica</th>
<th>FÃ³rmula</th>
<th>CuÃ¡ndo priorizar</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Accuracy</strong></td>
<td>Correctos / Total</td>
<td>Clases balanceadas</td>
</tr>
<tr>
<td><strong>Precision</strong></td>
<td>TP / (TP + FP)</td>
<td>Costo alto de falsos positivos</td>
</tr>
<tr>
<td><strong>Recall</strong></td>
<td>TP / (TP + FN)</td>
<td>Costo alto de falsos negativos</td>
</tr>
<tr>
<td><strong>F1</strong></td>
<td>2 Ã— (P Ã— R) / (P + R)</td>
<td>Balance entre P y R</td>
</tr>
</tbody>
</table>
<p><strong>En BankChurn</strong>: Priorizo <strong>Recall</strong> (no queremos perder clientes que harÃ¡n churn).</p>
<h2>Pregunta 20: Curva ROC y AUC</h2>
<p><strong>Â¿QuÃ© es AUC-ROC?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.metrics import roc_auc_score, roc_curve

# AUC: Ãrea bajo la curva ROC
auc = roc_auc_score(y_test, y_pred_proba[:, 1])
print(f&quot;AUC: {auc:.3f}&quot;)
</code></pre>
<p><strong>InterpretaciÃ³n</strong>:<br />
- <strong>AUC = 1.0</strong>: Clasificador perfecto<br />
- <strong>AUC = 0.5</strong>: Clasificador aleatorio<br />
- <strong>AUC &gt; 0.8</strong>: Generalmente bueno</p>
<p><strong>Ventaja</strong>: Funciona bien con clases desbalanceadas.</p>
<h1>3. Datos y Preprocesamiento (Preguntas 21-30)</h1>
<h2>Pregunta 21: ExploraciÃ³n de Datos</h2>
<p><strong>Â¿QuÃ© haces primero cuando recibes un dataset?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import pandas as pd

df = pd.read_csv(&quot;data.csv&quot;)

# 1. Dimensiones
print(f&quot;Shape: {df.shape}&quot;)  # (filas, columnas)

# 2. Tipos de datos
print(df.dtypes)

# 3. Missing values
print(df.isnull().sum())

# 4. EstadÃ­sticas bÃ¡sicas
print(df.describe())

# 5. Primeras filas
print(df.head())

# 6. Target distribution
print(df['target'].value_counts(normalize=True))
</code></pre>
<h2>Pregunta 22: DetecciÃ³n de Outliers</h2>
<p><strong>Â¿CÃ³mo detectas outliers?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import numpy as np

# MÃ©todo IQR
Q1 = df['Balance'].quantile(0.25)
Q3 = df['Balance'].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

outliers = df[(df['Balance'] &lt; lower) | (df['Balance'] &gt; upper)]
print(f&quot;Outliers: {len(outliers)}&quot;)
</code></pre>
<p><strong>QuÃ© hacer con outliers</strong>:<br />
1. Verificar si son errores de datos â†’ corregir<br />
2. Si son legÃ­timos â†’ considerar winsorization o mantener<br />
3. Para modelos sensibles â†’ eliminar o transformar</p>
<h2>Pregunta 23: CorrelaciÃ³n</h2>
<p><strong>Â¿CÃ³mo identificas features correlacionadas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt

# Matriz de correlaciÃ³n
corr = df.corr()

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()

# Features altamente correlacionadas (&gt;0.9)
high_corr = (corr.abs() &gt; 0.9) &amp; (corr != 1.0)
</code></pre>
<p><strong>Â¿Por quÃ© importa?</strong> Features muy correlacionadas son redundantes â†’ considerar eliminar una.</p>
<h2>Pregunta 24: Desbalance de Clases</h2>
<p><strong>Â¿QuÃ© haces cuando tienes 95% clase A y 5% clase B?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Cambiar mÃ©trica (no usar accuracy)
from sklearn.metrics import f1_score, recall_score

# 2. Class weights
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(class_weight='balanced')

# 3. Oversampling (SMOTE)
from imblearn.over_sampling import SMOTE
X_res, y_res = SMOTE().fit_resample(X, y)

# 4. Undersampling
from imblearn.under_sampling import RandomUnderSampler
</code></pre>
<p><strong>En BankChurn</strong>: 80/20 balance â†’ usamos <code>class_weight='balanced'</code> y F1.</p>
<h2>Pregunta 25: Feature Selection</h2>
<p><strong>Â¿CÃ³mo seleccionas features importantes?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier

# 1. Feature importance de RF
rf = RandomForestClassifier().fit(X, y)
importances = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

# 2. CorrelaciÃ³n con target
correlations = df.corr()['target'].abs().sort_values(ascending=False)

# 3. SelectKBest
from sklearn.feature_selection import SelectKBest, f_classif
selector = SelectKBest(f_classif, k=10)
X_selected = selector.fit_transform(X, y)
</code></pre>
<h2>Pregunta 26: Data Leakage</h2>
<p><strong>Â¿QuÃ© es data leakage y cÃ³mo evitarlo?</strong></p>
<h3>Respuesta:</h3>
<p>Data leakage = cuando informaciÃ³n del futuro o del target filtra al entrenamiento.</p>
<pre><code class="language-python"># âŒ MAL: fit scaler en TODO antes de split
scaler.fit(X)  # Ve datos de test
X_train, X_test = train_test_split(X)

# âœ… BIEN: fit solo en train
X_train, X_test = train_test_split(X)
scaler.fit(X_train)  # Solo ve train
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
</code></pre>
<p><strong>En el portafolio</strong>: Usamos Pipeline de sklearn que maneja esto automÃ¡ticamente.</p>
<h2>Pregunta 27: Pipelines de sklearn</h2>
<p><strong>Â¿Por quÃ© usar Pipeline?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

# Un solo fit/predict
pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)
</code></pre>
<p><strong>Beneficios</strong>:<br />
1. <strong>Evita leakage</strong>: fit solo en train automÃ¡ticamente<br />
2. <strong>CÃ³digo limpio</strong>: Todo en un objeto<br />
3. <strong>FÃ¡cil deploy</strong>: <code>joblib.dump(pipe, 'model.joblib')</code><br />
4. <strong>Reproducibilidad</strong>: Mismo proceso siempre</p>
<h2>Pregunta 28: Guardado de Modelos</h2>
<p><strong>Â¿CÃ³mo guardas y cargas un modelo entrenado?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import joblib

# Guardar
joblib.dump(model, 'artifacts/model.joblib')

# Cargar
model = joblib.load('artifacts/model.joblib')

# Usar
prediction = model.predict(new_data)
</code></pre>
<p><strong>En producciÃ³n</strong> (FastAPI):</p>
<pre><code class="language-python">@lru_cache()
def load_model():
    return joblib.load(&quot;artifacts/pipeline.joblib&quot;)
</code></pre>
<h2>Pregunta 29: ValidaciÃ³n de Datos</h2>
<p><strong>Â¿CÃ³mo validas que los datos de entrada son correctos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from pydantic import BaseModel, Field, validator

class CustomerInput(BaseModel):
    credit_score: int = Field(ge=300, le=850)
    age: int = Field(ge=18, le=100)
    geography: str

    @validator('geography')
    def geography_valid(cls, v):
        valid = ['France', 'Germany', 'Spain']
        if v not in valid:
            raise ValueError(f'Must be one of {valid}')
        return v
</code></pre>
<p><strong>Beneficios</strong>: Errores claros antes de llegar al modelo.</p>
<h2>Pregunta 30: Reproducibilidad</h2>
<p><strong>Â¿CÃ³mo garantizas que tu experimento sea reproducible?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import random
import numpy as np

# 1. Fijar seeds
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

# 2. En modelos
model = RandomForestClassifier(random_state=SEED)

# 3. En split
train_test_split(X, y, random_state=SEED)

# 4. Documentar versiones
# requirements.txt o pyproject.toml con versiones fijas
</code></pre>
<h1>4. Git y Herramientas (Preguntas 31-40)</h1>
<h2>Pregunta 31: Git BÃ¡sico</h2>
<p><strong>Â¿CuÃ¡l es el flujo bÃ¡sico de Git?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># 1. Ver estado
git status

# 2. AÃ±adir cambios
git add .                     # Todo
git add archivo.py            # EspecÃ­fico

# 3. Commit
git commit -m &quot;feat: add preprocessing step&quot;

# 4. Push
git push origin main

# 5. Pull (obtener cambios)
git pull origin main
</code></pre>
<h2>Pregunta 32: Branches</h2>
<p><strong>Â¿Por quÃ© usar branches?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># Crear branch
git checkout -b feature/add-validation

# Trabajar...
git add .
git commit -m &quot;feat: add pydantic validation&quot;

# Push branch
git push origin feature/add-validation

# Crear Pull Request en GitHub
# DespuÃ©s de aprobar, merge a main
</code></pre>
<p><strong>Razones</strong>:<br />
- Aislar cambios<br />
- Revisar cÃ³digo antes de merge<br />
- Mantener main siempre funcional</p>
<h2>Pregunta 33: .gitignore</h2>
<p><strong>Â¿QuÃ© debe ir en .gitignore?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-gitignore"># Datos (grandes, sensibles)
data/
*.csv
*.parquet

# Artefactos
artifacts/
*.joblib
*.pkl

# Entornos
.venv/
__pycache__/

# IDEs
.vscode/
.idea/

# Logs
*.log
mlruns/
</code></pre>
<p><strong>Regla</strong>: No subir datos grandes, artefactos binarios, ni secretos.</p>
<h2>Pregunta 34: Requirements</h2>
<p><strong>Â¿CÃ³mo manejas dependencias?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># Crear requirements.txt
pip freeze &gt; requirements.txt

# Mejor: usar pip-tools
pip-compile requirements.in &gt; requirements.txt

# Instalar
pip install -r requirements.txt

# Moderno: pyproject.toml
pip install -e &quot;.[dev]&quot;
</code></pre>
<h2>Pregunta 35: Makefile</h2>
<p><strong>Â¿Para quÃ© sirve un Makefile?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-makefile">.PHONY: install test train

install:
    pip install -e &quot;.[dev]&quot;

test:
    pytest tests/ -v --cov=src

train:
    python main.py --config configs/config.yaml

lint:
    ruff check src/
</code></pre>
<p><strong>Uso</strong>:</p>
<pre><code class="language-bash">make install
make test
make train
</code></pre>
<p><strong>Beneficio</strong>: Comandos estÃ¡ndar, documentados, fÃ¡ciles de recordar.</p>
<h2>Pregunta 36: pytest BÃ¡sico</h2>
<p><strong>Â¿CÃ³mo escribes un test bÃ¡sico?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># tests/test_data.py
import pytest
import pandas as pd

def test_load_data():
    df = pd.read_csv(&quot;data/raw/sample.csv&quot;)
    assert len(df) &gt; 0
    assert &quot;target&quot; in df.columns

def test_no_nulls_in_target():
    df = pd.read_csv(&quot;data/raw/sample.csv&quot;)
    assert df[&quot;target&quot;].isnull().sum() == 0

# Ejecutar
# pytest tests/test_data.py -v
</code></pre>
<h2>Pregunta 37: Estructura de Proyecto</h2>
<p><strong>Â¿CÃ³mo organizas un proyecto ML?</strong></p>
<h3>Respuesta:</h3>
<pre><code>mi-proyecto/
â”œâ”€â”€ src/miproyecto/     # CÃ³digo fuente
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py       # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ data.py         # Carga de datos
â”‚   â”œâ”€â”€ features.py     # Feature engineering
â”‚   â””â”€â”€ training.py     # Entrenamiento
â”œâ”€â”€ app/                # APIs
â”œâ”€â”€ tests/              # Tests
â”œâ”€â”€ configs/            # YAML configs
â”œâ”€â”€ data/raw/           # Datos
â”œâ”€â”€ artifacts/          # Modelos guardados
â”œâ”€â”€ pyproject.toml      # Dependencias
â”œâ”€â”€ Makefile           
â””â”€â”€ README.md
</code></pre>
<h2>Pregunta 38: README</h2>
<p><strong>Â¿QuÃ© debe tener un buen README?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-markdown"># Nombre del Proyecto

## DescripciÃ³n
QuÃ© hace el proyecto, problema que resuelve.

## InstalaciÃ³n
```bash
pip install -e .
</code></pre>
<h2>Uso RÃ¡pido</h2>
<pre><code class="language-python">from miproyecto import predict
result = predict(data)
</code></pre>
<h2>Estructura</h2>
<p>Ãrbol de directorios.</p>
<h2>Tests</h2>
<pre><code class="language-bash">make test
</code></pre>
<h2>Autor</h2>
<p>Nombre, contacto.</p>
<pre><code>

## Pregunta 39: Docker BÃ¡sico
**Â¿QuÃ© es Docker y por quÃ© usarlo?**

### Respuesta:
Docker empaqueta tu aplicaciÃ³n con todas sus dependencias.

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD [&quot;python&quot;, &quot;main.py&quot;]
</code></pre>
<pre><code class="language-bash"># Construir
docker build -t mi-app .

# Ejecutar
docker run mi-app
</code></pre>
<p><strong>Beneficio</strong>: "Funciona en mi mÃ¡quina" â†’ Funciona en cualquier mÃ¡quina.</p>
<h2>Pregunta 40: APIs BÃ¡sicas</h2>
<p><strong>Â¿QuÃ© es una API REST?</strong></p>
<h3>Respuesta:</h3>
<p>API = Interfaz para que otros programas usen tu cÃ³digo.</p>
<pre><code class="language-python">from fastapi import FastAPI

app = FastAPI()

@app.get(&quot;/health&quot;)
def health():
    return {&quot;status&quot;: &quot;ok&quot;}

@app.post(&quot;/predict&quot;)
def predict(data: dict):
    # Usar modelo
    return {&quot;prediction&quot;: result}
</code></pre>
<pre><code class="language-bash"># Ejecutar
uvicorn app:app --reload

# Probar
curl http://localhost:8000/health
</code></pre>
<h1>5. PrÃ¡ctica con el Portafolio (Preguntas 41-50)</h1>
<h2>Pregunta 41: Describir el Portafolio</h2>
<p><strong>CuÃ©ntame sobre el portafolio.</strong></p>
<h3>Respuesta:</h3>
<p>"Es un portafolio de MLOps con 3 proyectos production-ready:</p>
<ol>
<li>
<p><strong>BankChurn-Predictor</strong>: ClasificaciÃ³n binaria para predecir churn de clientes bancarios. Pipeline sklearn unificado, FastAPI, 79% coverage.</p>
</li>
<li>
<p><strong>CarVision-Market-Intelligence</strong>: RegresiÃ³n para predecir precios de autos usados. FeatureEngineer centralizado, Streamlit dashboard.</p>
</li>
<li>
<p><strong>TelecomAI</strong>: ClasificaciÃ³n multiclase para segmentaciÃ³n de clientes de telecom.</p>
</li>
</ol>
<p>Todos siguen las mismas prÃ¡cticas: estructura src/, Pydantic para configs, pytest, GitHub Actions CI."</p>
<h2>Pregunta 42: Ejecutar el Proyecto</h2>
<p><strong>Â¿CÃ³mo ejecuto BankChurn?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># 1. Clonar
git clone https://github.com/duqueom/ML-MLOps-Portfolio.git
cd ML-MLOps-Portfolio/BankChurn-Predictor

# 2. Crear entorno
python -m venv .venv
source .venv/bin/activate

# 3. Instalar
pip install -e &quot;.[dev]&quot;

# 4. Entrenar
python main.py --config configs/config.yaml

# 5. API
uvicorn app.fastapi_app:app --reload

# 6. Tests
pytest tests/ -v
</code></pre>
<h2>Pregunta 43: Entender el Pipeline</h2>
<p><strong>Â¿CÃ³mo funciona el pipeline de BankChurn?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Cargar config
config = BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)

# 2. Cargar datos
df = pd.read_csv(config.data.raw_path)

# 3. Crear trainer
trainer = Trainer(config)

# 4. Entrenar (dentro crea Pipeline sklearn)
trainer.fit(X, y)
# Pipeline = [preprocessor, model]
# preprocessor = ColumnTransformer(numeric_pipe, categorical_pipe)

# 5. Evaluar
metrics = trainer.evaluate(X_test, y_test)

# 6. Guardar
trainer.save(&quot;artifacts/&quot;)
</code></pre>
<h2>Pregunta 44: Modificar el CÃ³digo</h2>
<p><strong>Â¿CÃ³mo aÃ±adirÃ­as una nueva feature?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. En config.yaml, aÃ±adir columna
features:
  numerical:
    - CreditScore
    - Age
    - NewFeature  # Nueva

# 2. Si requiere transformaciÃ³n, editar FeatureEngineer
class FeatureEngineer:
    def transform(self, X):
        X['NewFeature'] = X['Col1'] / X['Col2']
        return X

# 3. Agregar test
def test_new_feature():
    fe = FeatureEngineer()
    result = fe.transform(sample_df)
    assert 'NewFeature' in result.columns

# 4. Ejecutar tests
pytest tests/test_features.py -v
</code></pre>
<h2>Pregunta 45: Leer un Error</h2>
<p><strong>Este cÃ³digo falla. Â¿Por quÃ©?</strong></p>
<pre><code class="language-python">X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)
</code></pre>
<h3>Respuesta:</h3>
<p><strong>Problema</strong>: <code>fit_transform</code> en test causa data leakage.</p>
<pre><code class="language-python"># âœ… Correcto
X_train = scaler.fit_transform(X_train)  # fit + transform
X_test = scaler.transform(X_test)        # solo transform
</code></pre>
<p>El scaler debe aprender (fit) solo de training data.</p>
<h2>Pregunta 46: Interpretar MÃ©tricas</h2>
<p><strong>El modelo tiene accuracy 95% pero el negocio no estÃ¡ contento. Â¿Por quÃ©?</strong></p>
<h3>Respuesta:</h3>
<p>Posibles razones:</p>
<ol>
<li>
<p><strong>Clases desbalanceadas</strong>: Si 95% son clase 0, predecir siempre 0 da 95% accuracy pero es inÃºtil.</p>
</li>
<li>
<p><strong>MÃ©trica incorrecta</strong>: El negocio necesita recall (no perder churners) pero optimizaste accuracy.</p>
</li>
<li>
<p><strong>Falsos negativos costosos</strong>: Cada cliente que hace churn y no detectamos cuesta $X.</p>
</li>
</ol>
<p><strong>SoluciÃ³n</strong>: Usar F1, recall, o una mÃ©trica de negocio (costo).</p>
<h2>Pregunta 47: ConfiguraciÃ³n YAML</h2>
<p><strong>Â¿Por quÃ© usar archivos YAML para configuraciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># configs/config.yaml
model:
  type: &quot;random_forest&quot;
  n_estimators: 100
  max_depth: 10

data:
  raw_path: &quot;data/raw/Churn.csv&quot;
  test_size: 0.2

training:
  random_state: 42
</code></pre>
<p><strong>Ventajas</strong>:<br />
1. <strong>SeparaciÃ³n</strong>: Cambiar parÃ¡metros sin tocar cÃ³digo<br />
2. <strong>Versionable</strong>: Git puede trackear cambios<br />
3. <strong>Legible</strong>: FÃ¡cil de entender<br />
4. <strong>Reproducibilidad</strong>: Guardar config de cada experimento</p>
<h2>Pregunta 48: CI/CD BÃ¡sico</h2>
<p><strong>Â¿QuÃ© hace el workflow de GitHub Actions?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
      - run: pip install -e &quot;.[dev]&quot;
      - run: pytest tests/ -v
</code></pre>
<p><strong>Flujo</strong>:<br />
1. Push cÃ³digo â†’ GitHub Actions se activa<br />
2. Crea mÃ¡quina virtual limpia<br />
3. Instala dependencias<br />
4. Ejecuta tests<br />
5. Reporta pass/fail</p>
<h2>Pregunta 49: Debugging en ProducciÃ³n</h2>
<p><strong>El API retorna error 500. Â¿CÃ³mo lo depuras?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Ver logs
uvicorn app:app --log-level debug

# 2. AÃ±adir logging
import logging
logging.basicConfig(level=logging.DEBUG)

@app.post(&quot;/predict&quot;)
def predict(data: Input):
    logging.debug(f&quot;Input: {data}&quot;)
    try:
        result = model.predict(...)
        logging.debug(f&quot;Result: {result}&quot;)
        return result
    except Exception as e:
        logging.error(f&quot;Error: {e}&quot;)
        raise

# 3. Probar localmente
curl -X POST http://localhost:8000/predict \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;credit_score&quot;: 650, ...}'
</code></pre>
<h2>Pregunta 50: PrÃ³ximos Pasos</h2>
<p><strong>Â¿QuÃ© aprenderÃ­as despuÃ©s de este portafolio?</strong></p>
<h3>Respuesta:</h3>
<p>"Con las bases del portafolio, me gustarÃ­a profundizar en:</p>
<ol>
<li>
<p><strong>MLflow/Experiment Tracking</strong>: Ya estÃ¡ configurado, pero quiero usarlo mÃ¡s para comparar experimentos sistemÃ¡ticamente.</p>
</li>
<li>
<p><strong>Docker avanzado</strong>: Optimizar imÃ¡genes, multi-stage builds.</p>
</li>
<li>
<p><strong>Testing mÃ¡s robusto</strong>: AÃ±adir tests de integraciÃ³n, property-based testing.</p>
</li>
<li>
<p><strong>Kubernetes bÃ¡sico</strong>: Entender cÃ³mo escalar los servicios.</p>
</li>
<li>
<p><strong>Monitoreo en producciÃ³n</strong>: Detectar drift, alertas.</p>
</li>
</ol>
<p>El portafolio me dio la base; ahora quiero profundizar en cada Ã¡rea."</p>
<h1>ğŸ“š Recursos para PreparaciÃ³n</h1>
<h2>MÃ³dulos de la GuÃ­a Relacionados</h2>
<table>
<thead>
<tr>
<th>Pregunta</th>
<th>MÃ³dulo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Python bÃ¡sico</td>
<td><a href="#mod_01_PYTHON_MODERNO">01_PYTHON_MODERNO.md</a></td>
</tr>
<tr>
<td>ML fundamentos</td>
<td><a href="#mod_07_SKLEARN_PIPELINES">07_SKLEARN_PIPELINES.md</a>, <a href="#mod_08_INGENIERIA_FEATURES">08_INGENIERIA_FEATURES.md</a></td>
</tr>
<tr>
<td>Git</td>
<td><a href="#mod_05_GIT_PROFESIONAL">05_GIT_PROFESIONAL.md</a></td>
</tr>
<tr>
<td>Testing</td>
<td><a href="#mod_11_TESTING_ML">11_TESTING_ML.md</a></td>
</tr>
<tr>
<td>APIs</td>
<td><a href="#mod_14_FASTAPI">14_FASTAPI.md</a></td>
</tr>
</tbody>
</table>
<h2>Checklist Pre-Entrevista</h2>
<ul>
<li>[ ] Puedo ejecutar <code>make install &amp;&amp; make test</code> en BankChurn</li>
<li>[ ] Entiendo quÃ© hace cada archivo en <code>src/bankchurn/</code></li>
<li>[ ] SÃ© explicar train/test split y por quÃ© importa</li>
<li>[ ] Puedo leer y modificar el <code>config.yaml</code></li>
<li>[ ] Entiendo el flujo Git bÃ¡sico</li>
</ul>
<p><strong>Â¡Ã‰xito en tu entrevista! ğŸš€</strong></p>
<p><em>Recuerda: ser Junior significa estar aprendiendo. Muestra curiosidad y ganas de aprender.</em></p>
            </div>
        
            <!-- MÃ“DULO: 07_SKLEARN_PIPELINES.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_07_SKLEARN_PIPELINES" class="cover-title">SKLEARN PIPELINES</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>07. sklearn Pipelines: El CorazÃ³n de MLOps</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Dominar el patrÃ³n mÃ¡s importante de ML profesional: <strong>pipelines unificados</strong> que garantizan reproducibilidad desde entrenamiento hasta producciÃ³n.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  ğŸš¨ EL ERROR #1 EN PRODUCCIÃ“N ML:                                            â•‘
â•‘                                                                              â•‘
â•‘  Entrenar con una transformaciÃ³n, servir con otra.                           â•‘
â•‘                                                                              â•‘
â•‘  Ejemplo real:                                                               â•‘
â•‘  â€¢ Training: StandardScaler fitted en train set (mean=45000, std=20000)      â•‘
â•‘  â€¢ Production: StandardScaler fitted en cada request (mean=???, std=???)     â•‘
â•‘  â€¢ Resultado: Predicciones COMPLETAMENTE diferentes                          â•‘
â•‘                                                                              â•‘
â•‘  ğŸ›¡ï¸ LA SOLUCIÃ“N: Pipeline unificado que guarda TODO junto                    â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#71-por-quÃ©-pipelines">Â¿Por QuÃ© Pipelines?</a></li>
<li><a href="#72-columntransformer-transformaciones-paralelas">ColumnTransformer: Transformaciones Paralelas</a></li>
<li><a href="#73-custom-transformers-tu-superpoder">Custom Transformers</a></li>
<li><a href="#74-pipeline-completo-cÃ³digo-real">Pipeline Completo: CÃ³digo Real</a></li>
<li><a href="#75-ejercicios-prÃ¡cticos">Ejercicios PrÃ¡cticos</a></li>
</ol>
<h2>7.1 Â¿Por QuÃ© Pipelines?</h2>
<h3>La AnalogÃ­a de la LÃ­nea de Ensamblaje</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ­ IMAGINA UNA FÃBRICA DE AUTOS:                                         â•‘
â•‘                                                                           â•‘
â•‘  SIN LÃNEA DE ENSAMBLAJE (cÃ³digo suelto):                                 â•‘
â•‘  â€¢ Trabajador 1 pone ruedas, pero a veces se le olvida                    â•‘
â•‘  â€¢ Trabajador 2 pinta, pero usa colores diferentes cada dÃ­a               â•‘
â•‘  â€¢ Trabajador 3 instala motor, pero a veces del modelo equivocado         â•‘
â•‘  â€¢ Resultado: Cada auto es diferente, imposible de mantener               â•‘
â•‘                                                                           â•‘
â•‘  CON LÃNEA DE ENSAMBLAJE (Pipeline):                                      â•‘
â•‘  â€¢ Paso 1: Chasis â†’ Paso 2: Motor â†’ Paso 3: Pintura â†’ Paso 4: Ruedas      â•‘
â•‘  â€¢ Cada paso estÃ¡ definido y es SIEMPRE igual                             â•‘
â•‘  â€¢ El proceso completo es una sola unidad                                 â•‘
â•‘  â€¢ Resultado: Todos los autos son consistentes                            â•‘
â•‘                                                                           â•‘
â•‘  sklearn Pipeline = LÃ­nea de ensamblaje para ML                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>El Problema Real: Training-Serving Skew</h3>
<pre><code class="language-python"># âŒ CÃ“DIGO PROBLEMÃTICO (muy comÃºn en notebooks convertidos a producciÃ³n)

# === ENTRENAMIENTO ===
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Ajustar scaler en datos de entrenamiento
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train[num_cols])  # â† fit aquÃ­

encoder = OneHotEncoder()
X_train_encoded = encoder.fit_transform(X_train[cat_cols])  # â† fit aquÃ­

# Entrenar modelo
model = RandomForestClassifier()
model.fit(X_train_processed, y_train)

# Guardar modelo... pero Â¿y el scaler? Â¿y el encoder?
joblib.dump(model, &quot;model.pkl&quot;)  # â† Solo guarda el modelo!

# === PRODUCCIÃ“N (meses despuÃ©s, otro desarrollador) ===
model = joblib.load(&quot;model.pkl&quot;)

# Â¿CÃ³mo transformo los datos nuevos?
# ğŸ¤· No tengo el scaler ni el encoder fitted
# ğŸ¤· Incluso si los tuviera, Â¿cÃ³mo sÃ© quÃ© columnas usar?
# ğŸ¤· Â¿Era StandardScaler o MinMaxScaler?

# &quot;SoluciÃ³n&quot; del desarrollador desesperado:
scaler = StandardScaler()
X_new_scaled = scaler.fit_transform(X_new[num_cols])  # â† fit en datos NUEVOS!
# âš ï¸ Ahora mean y std son DIFERENTES a los de entrenamiento
# âš ï¸ Las predicciones son BASURA

# ============================================================================
# âœ… SOLUCIÃ“N: Pipeline Unificado
# ============================================================================

# === ENTRENAMIENTO ===
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Definir pipeline completo
pipeline = Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])),
    ('model', RandomForestClassifier())
])

# Un solo fit entrena TODO
pipeline.fit(X_train, y_train)

# Guardar TODO junto
joblib.dump(pipeline, &quot;pipeline.pkl&quot;)  # â† Scaler + Encoder + Model

# === PRODUCCIÃ“N ===
pipeline = joblib.load(&quot;pipeline.pkl&quot;)

# Una sola llamada hace TODO (con los parÃ¡metros de entrenamiento)
predictions = pipeline.predict(X_new)  # â† Transforma Y predice

# âœ… El scaler usa mean/std del entrenamiento
# âœ… El encoder conoce las categorÃ­as del entrenamiento
# âœ… Las predicciones son consistentes
</code></pre>
<h2>7.2 ColumnTransformer: Transformaciones Paralelas</h2>
<h3>El Problema: Diferentes Columnas, Diferentes Tratamientos</h3>
<pre><code>Datos de un banco:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CreditScore â”‚ Geography â”‚ Gender  â”‚   Age   â”‚ Balanceâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     619     â”‚  France   â”‚  Female â”‚    42   â”‚  10000 â”‚
â”‚     608     â”‚   Spain   â”‚  Female â”‚    41   â”‚  83808 â”‚
â”‚     502     â”‚  France   â”‚  Female â”‚    42   â”‚      0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Columnas numÃ©ricas (CreditScore, Age, Balance):
â†’ StandardScaler: normalizar a mean=0, std=1

Columnas categÃ³ricas (Geography, Gender):
â†’ OneHotEncoder: convertir a columnas binarias
</code></pre>
<h3>ColumnTransformer: La SoluciÃ³n Elegante</h3>
<pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# Definir quÃ© columnas son de cada tipo
num_cols = [&quot;CreditScore&quot;, &quot;Age&quot;, &quot;Tenure&quot;, &quot;Balance&quot;, &quot;NumOfProducts&quot;, &quot;EstimatedSalary&quot;]
cat_cols = [&quot;Geography&quot;, &quot;Gender&quot;]

# Pipeline para numÃ©ricas: Imputar NaN â†’ Escalar
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),  # NaN â†’ mediana
    ('scaler', StandardScaler())                     # Normalizar
])

# Pipeline para categÃ³ricas: Imputar NaN â†’ One-Hot
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # CategorÃ­as nuevas â†’ ignorar
])

# ColumnTransformer: Aplica cada pipeline a sus columnas
preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_pipeline, num_cols),  # (nombre, transformer, columnas)
        ('cat', cat_pipeline, cat_cols)
    ],
    remainder='drop'  # Columnas no listadas se eliminan
)

# Resultado: Un solo objeto que sabe transformar todo
X_processed = preprocessor.fit_transform(X_train)
</code></pre>
<h3>VisualizaciÃ³n del Flujo</h3>
<pre><code>                        ColumnTransformer
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚               â”‚               â”‚
              â–¼               â–¼               â–¼
        num_pipeline    cat_pipeline    remainder
              â”‚               â”‚               â”‚
              â”‚               â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚               â”‚
    â”‚                   â”‚     â”‚               â”‚
    â–¼                   â–¼     â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   drop
â”‚Imputer  â”‚       â”‚ Scaler  â”‚ â”‚ Imputer â”‚
â”‚(median) â”‚       â”‚         â”‚ â”‚(Unknown)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ OneHot  â”‚
                              â”‚ Encoder â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                    â”‚                    â”‚
              â–¼                    â–¼                    â–¼
    [6 columnas numÃ©ricas]  [3 Geography cols]  [2 Gender cols]
         escaladas            (France, Spain,     (Female, Male)
                               Germany)

    Output: 11 columnas totales (6 + 3 + 2)
</code></pre>
<h2>7.3 Custom Transformers: Tu Superpoder</h2>
<h3>Â¿CuÃ¡ndo Crear un Custom Transformer?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Crea un Custom Transformer cuando:                                       â•‘
â•‘                                                                           â•‘
â•‘  âœ… Necesitas feature engineering especÃ­fico del dominio                  â•‘
â•‘  âœ… La transformaciÃ³n debe aplicarse igual en train y producciÃ³n          â•‘
â•‘  âœ… sklearn no tiene un transformer que haga lo que necesitas             â•‘
â•‘                                                                           â•‘
â•‘  Ejemplos del portafolio:                                                 â•‘
â•‘  â€¢ CarVision: Calcular vehicle_age desde model_year                       â•‘
â•‘  â€¢ CarVision: Extraer brand desde model                                   â•‘
â•‘  â€¢ BankChurn: Resampling para clases desbalanceadas                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Ejemplo 1: FeatureEngineer (CarVision)</h3>
<pre><code class="language-python"># src/carvision/features.py - CÃ³digo REAL del portafolio

from __future__ import annotations

from typing import Optional

import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin


class FeatureEngineer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;
    Centralized feature engineering to ensure consistency across
    Training, Inference, and Analysis.

    Este transformer garantiza que las mismas transformaciones
    se apliquen en:
    1. Entrenamiento (training.py)
    2. Inferencia API (fastapi_app.py)
    3. Dashboard (streamlit_app.py)

    Attributes
    ----------
    current_year : int, optional
        AÃ±o para calcular vehicle_age. Si None, usa aÃ±o actual.

    Examples
    --------
    &gt;&gt;&gt; fe = FeatureEngineer(current_year=2024)
    &gt;&gt;&gt; df_transformed = fe.fit_transform(df)
    &gt;&gt;&gt; print(df_transformed.columns)
    # Incluye: vehicle_age, brand (derivadas de model_year y model)
    &quot;&quot;&quot;

    def __init__(self, current_year: Optional[int] = None):
        self.current_year = current_year

    def fit(self, X: pd.DataFrame, y: pd.DataFrame = None) -&gt; &quot;FeatureEngineer&quot;:
        &quot;&quot;&quot;Fit no hace nada (stateless transformer).&quot;&quot;&quot;
        # Este transformer es stateless: no aprende nada de los datos
        # Solo necesita fit() para ser compatible con Pipeline
        return self

    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:
        &quot;&quot;&quot;Aplica feature engineering.

        Features creadas:
        - vehicle_age: current_year - model_year
        - brand: primera palabra de model
        - price_per_mile: price / odometer (solo si price existe)
        &quot;&quot;&quot;
        X = X.copy()  # â† Nunca modificar el input original

        # Usar aÃ±o configurado o aÃ±o actual
        year = self.current_year or pd.Timestamp.now().year

        # Feature: Edad del vehÃ­culo
        if &quot;model_year&quot; in X.columns:
            X[&quot;vehicle_age&quot;] = year - X[&quot;model_year&quot;]

        # Feature: Marca (primera palabra del modelo)
        if &quot;model&quot; in X.columns:
            X[&quot;brand&quot;] = X[&quot;model&quot;].astype(str).str.split().str[0]

        # Features derivadas (solo en training, no en inferencia)
        # Porque price no estÃ¡ disponible en inferencia
        if &quot;odometer&quot; in X.columns and &quot;price&quot; in X.columns:
            X[&quot;price_per_mile&quot;] = X[&quot;price&quot;] / (X[&quot;odometer&quot;] + 1)

        return X

    # MÃ©todos opcionales para mejor introspecciÃ³n
    def get_feature_names_out(self, input_features=None):
        &quot;&quot;&quot;Retorna nombres de features de salida.&quot;&quot;&quot;
        base = list(input_features) if input_features else []
        return base + [&quot;vehicle_age&quot;, &quot;brand&quot;]
</code></pre>
<h3>Ejemplo 2: ResampleClassifier (BankChurn)</h3>
<pre><code class="language-python"># src/bankchurn/models.py - CÃ³digo REAL del portafolio

from __future__ import annotations

import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_is_fitted


class ResampleClassifier(BaseEstimator, ClassifierMixin):
    &quot;&quot;&quot;Custom classifier with resampling for imbalanced datasets.

    Implementa oversampling (SMOTE), undersampling, y class weighting
    para mejorar performance en clasificaciÃ³n desbalanceada.

    Este wrapper permite:
    1. Probar diferentes estrategias de resampling fÃ¡cilmente
    2. Mantener la interfaz sklearn estÃ¡ndar (fit/predict)
    3. Ser parte de un Pipeline (incluyendo GridSearchCV)

    Parameters
    ----------
    estimator : estimator object, optional
        Clasificador base. Si None, usa LogisticRegression.
    strategy : {&quot;none&quot;, &quot;oversample&quot;, &quot;undersample&quot;, &quot;class_weight&quot;}
        Estrategia de resampling:
        - &quot;none&quot;: Sin resampling
        - &quot;oversample&quot;: SMOTE oversampling de clase minoritaria
        - &quot;undersample&quot;: Undersampling de clase mayoritaria
        - &quot;class_weight&quot;: Balanceo automÃ¡tico de pesos
    random_state : int, default=42
        Semilla para reproducibilidad.

    Examples
    --------
    &gt;&gt;&gt; clf = ResampleClassifier(
    ...     estimator=RandomForestClassifier(),
    ...     strategy=&quot;oversample&quot;,
    ...     random_state=42
    ... )
    &gt;&gt;&gt; clf.fit(X_train, y_train)
    &gt;&gt;&gt; predictions = clf.predict(X_test)
    &quot;&quot;&quot;

    def __init__(
        self,
        estimator: BaseEstimator | None = None,
        strategy: str = &quot;none&quot;,
        random_state: int = 42,
    ) -&gt; None:
        self.estimator = estimator
        self.strategy = strategy
        self.random_state = random_state

    def fit(self, X: np.ndarray, y: np.ndarray) -&gt; &quot;ResampleClassifier&quot;:
        &quot;&quot;&quot;Entrena el clasificador con resampling opcional.&quot;&quot;&quot;
        from sklearn.linear_model import LogisticRegression

        # Inicializar estimador si no se proporcionÃ³
        if self.estimator is None:
            self.estimator_ = LogisticRegression(random_state=self.random_state)
        else:
            # Clonar para no modificar el original
            from sklearn.base import clone
            self.estimator_ = clone(self.estimator)

        # Guardar clases (requerido por sklearn)
        self.classes_ = np.unique(y)

        # Aplicar estrategia de resampling
        X_resampled, y_resampled = self._apply_resampling(X, y)

        # Entrenar estimador base
        self.estimator_.fit(X_resampled, y_resampled)

        return self

    def _apply_resampling(
        self, X: np.ndarray, y: np.ndarray
    ) -&gt; tuple[np.ndarray, np.ndarray]:
        &quot;&quot;&quot;Aplica la estrategia de resampling.&quot;&quot;&quot;
        if self.strategy == &quot;none&quot;:
            return X, y

        elif self.strategy == &quot;oversample&quot;:
            try:
                from imblearn.over_sampling import SMOTE
                smote = SMOTE(random_state=self.random_state)
                return smote.fit_resample(X, y)
            except ImportError:
                # Si imblearn no estÃ¡ instalado, ignorar
                return X, y

        elif self.strategy == &quot;undersample&quot;:
            try:
                from imblearn.under_sampling import RandomUnderSampler
                rus = RandomUnderSampler(random_state=self.random_state)
                return rus.fit_resample(X, y)
            except ImportError:
                return X, y

        elif self.strategy == &quot;class_weight&quot;:
            # No modifica datos, el estimador maneja los pesos
            if hasattr(self.estimator_, 'class_weight'):
                self.estimator_.set_params(class_weight='balanced')
            return X, y

        else:
            raise ValueError(f&quot;Unknown strategy: {self.strategy}&quot;)

    def predict(self, X: np.ndarray) -&gt; np.ndarray:
        &quot;&quot;&quot;Predice clases.&quot;&quot;&quot;
        check_is_fitted(self, ['estimator_', 'classes_'])
        return self.estimator_.predict(X)

    def predict_proba(self, X: np.ndarray) -&gt; np.ndarray:
        &quot;&quot;&quot;Predice probabilidades.&quot;&quot;&quot;
        check_is_fitted(self, ['estimator_', 'classes_'])
        return self.estimator_.predict_proba(X)
</code></pre>
<h3>La Plantilla: Crea Tu Propio Transformer</h3>
<pre><code class="language-python">from sklearn.base import BaseEstimator, TransformerMixin

class MiTransformer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;
    Plantilla para crear transformers custom.

    REGLAS IMPORTANTES:
    1. __init__ solo guarda parÃ¡metros (no computa nada)
    2. fit() aprende de los datos (puede ser no-op)
    3. transform() aplica la transformaciÃ³n
    4. Nunca modificar input, siempre X.copy()
    &quot;&quot;&quot;

    def __init__(self, param1: str = &quot;default&quot;, param2: int = 10):
        # Solo guardar parÃ¡metros, NO computar nada
        self.param1 = param1
        self.param2 = param2

    def fit(self, X, y=None):
        &quot;&quot;&quot;Aprende de los datos (opcional).

        Ejemplos de quÃ© aprender:
        - Media/std para normalizaciÃ³n
        - Vocabulario para encoding
        - Umbrales para binning
        &quot;&quot;&quot;
        # Si el transformer es stateless, solo retorna self
        # Si aprende algo:
        # self.learned_param_ = compute_something(X)
        return self

    def transform(self, X):
        &quot;&quot;&quot;Aplica la transformaciÃ³n.&quot;&quot;&quot;
        X = X.copy()  # â† Siempre copiar
        # ... tu lÃ³gica de transformaciÃ³n ...
        return X
</code></pre>
<h2>7.4 Pipeline Completo: CÃ³digo Real</h2>
<h3>CarVision: El Pipeline de 3 Etapas</h3>
<pre><code class="language-python"># src/carvision/training.py - Pipeline REAL del portafolio

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor

from src.carvision.features import FeatureEngineer

def build_pipeline(cfg: dict) -&gt; Pipeline:
    &quot;&quot;&quot;Construye el pipeline completo de CarVision.

    Estructura: Features â†’ Preprocessing â†’ Model

    Esta arquitectura de 3 etapas garantiza:
    1. Feature engineering consistente (FeatureEngineer)
    2. Preprocesamiento apropiado por tipo de columna (ColumnTransformer)
    3. Modelo entrenado con datos correctamente transformados
    &quot;&quot;&quot;
    # ParÃ¡metros de configuraciÃ³n
    num_cols = cfg[&quot;preprocessing&quot;][&quot;numeric_features&quot;]
    cat_cols = cfg[&quot;preprocessing&quot;][&quot;categorical_features&quot;]
    dataset_year = cfg.get(&quot;dataset_year&quot;, 2024)
    rf_params = cfg[&quot;training&quot;].get(&quot;random_forest_params&quot;, {})

    # Etapa 1: Feature Engineering
    feature_engineer = FeatureEngineer(current_year=dataset_year)

    # Etapa 2: Preprocessing (despuÃ©s de feature engineering)
    # Nota: Las columnas aquÃ­ son las que EXISTEN despuÃ©s del FeatureEngineer
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler())
            ]), num_cols),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ]), cat_cols)
        ],
        remainder='drop'
    )

    # Etapa 3: Modelo
    model = RandomForestRegressor(**rf_params)

    # Pipeline completo: Una sola unidad entrenable/guardable
    pipeline = Pipeline([
        ('features', feature_engineer),    # Crea vehicle_age, brand
        ('pre', preprocessor),              # Escala y encoda
        ('model', model)                    # Predice
    ])

    return pipeline


# === USO ===
# Entrenamiento
pipeline = build_pipeline(config)
pipeline.fit(X_train, y_train)

# Guardar TODO junto
joblib.dump(pipeline, &quot;artifacts/model.joblib&quot;)

# ProducciÃ³n
pipeline = joblib.load(&quot;artifacts/model.joblib&quot;)
price = pipeline.predict(X_new)  # Una llamada hace TODO
</code></pre>
<h3>BankChurn: Pipeline con Ensemble</h3>
<pre><code class="language-python"># src/bankchurn/training.py - Pipeline REAL del portafolio

def build_pipeline(self) -&gt; Pipeline:
    &quot;&quot;&quot;Construye el pipeline de BankChurn.

    Estructura:
    - Preprocessing: ColumnTransformer (num + cat)
    - Model: VotingClassifier o ResampleClassifier
    &quot;&quot;&quot;
    # Columnas desde config
    num_cols = self.config.data.numerical_features
    cat_cols = self.config.data.categorical_features

    # Preprocessing
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler())
            ]), num_cols),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
                ('encoder', OneHotEncoder(handle_unknown='ignore'))
            ]), cat_cols)
        ]
    )

    # Modelo: Ensemble o single model
    if self.config.model.type == &quot;ensemble&quot;:
        model = VotingClassifier(
            estimators=[
                ('lr', LogisticRegression(
                    **self.config.model.logistic_regression.dict()
                )),
                ('rf', RandomForestClassifier(
                    **self.config.model.random_forest.dict()
                ))
            ],
            voting=self.config.model.ensemble.voting,
            weights=self.config.model.ensemble.weights
        )
    else:
        # Con wrapper de resampling
        model = ResampleClassifier(
            estimator=RandomForestClassifier(
                **self.config.model.random_forest.dict()
            ),
            strategy=self.config.model.resampling_strategy,
            random_state=self.random_state
        )

    # Pipeline final
    return Pipeline([
        ('preprocessor', preprocessor),
        ('model', model)
    ])
</code></pre>
<h2>7.5 Ejercicios PrÃ¡cticos</h2>
<h3>Ejercicio 1: Construir un ColumnTransformer</h3>
<pre><code class="language-python"># Datos de telecom:
# - calls: float (numÃ©rico)
# - minutes: float (numÃ©rico)
# - messages: int (numÃ©rico)
# - mb_used: float (numÃ©rico)
# - plan_type: str (categÃ³rico) - &quot;basic&quot;, &quot;premium&quot;
# - region: str (categÃ³rico) - &quot;north&quot;, &quot;south&quot;, &quot;east&quot;, &quot;west&quot;

# Tu tarea: Crea un ColumnTransformer que:
# 1. Escale las columnas numÃ©ricas con StandardScaler
# 2. Encode las columnas categÃ³ricas con OneHotEncoder
# 3. Maneje valores faltantes apropiadamente

num_cols = [&quot;calls&quot;, &quot;minutes&quot;, &quot;messages&quot;, &quot;mb_used&quot;]
cat_cols = [&quot;plan_type&quot;, &quot;region&quot;]

# Escribe tu cÃ³digo aquÃ­:
preprocessor = ColumnTransformer(
    # ...
)
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

num_cols = [&quot;calls&quot;, &quot;minutes&quot;, &quot;messages&quot;, &quot;mb_used&quot;]
cat_cols = [&quot;plan_type&quot;, &quot;region&quot;]

preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ]), num_cols),
        ('cat', Pipeline([
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
        ]), cat_cols)
    ],
    remainder='drop'
)

# Verificar
print(f&quot;Transformers: {[t[0] for t in preprocessor.transformers]}&quot;)
# Output: ['num', 'cat']
</code></pre>


</details>

<h3>Ejercicio 2: Crear un Custom Transformer</h3>
<pre><code class="language-python"># Tu tarea: Crea un transformer que calcule ratios de uso de telecom
# 
# Features a crear:
# - minutes_per_call = minutes / (calls + 1)
# - mb_per_message = mb_used / (messages + 1)
# - total_usage = calls + messages + (mb_used / 1000)
#
# Requisitos:
# - Debe heredar de BaseEstimator y TransformerMixin
# - fit() debe retornar self
# - transform() debe retornar DataFrame con nuevas columnas

from sklearn.base import BaseEstimator, TransformerMixin

class TelecomFeatureEngineer(BaseEstimator, TransformerMixin):
    # Tu cÃ³digo aquÃ­
    pass
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python">from sklearn.base import BaseEstimator, TransformerMixin
import pandas as pd


class TelecomFeatureEngineer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;Feature engineering para datos de telecom.&quot;&quot;&quot;

    def __init__(self):
        pass

    def fit(self, X: pd.DataFrame, y=None):
        &quot;&quot;&quot;No aprende nada (stateless).&quot;&quot;&quot;
        return self

    def transform(self, X: pd.DataFrame) -&gt; pd.DataFrame:
        &quot;&quot;&quot;Crea features derivadas.&quot;&quot;&quot;
        X = X.copy()

        # Minutos por llamada
        if &quot;minutes&quot; in X.columns and &quot;calls&quot; in X.columns:
            X[&quot;minutes_per_call&quot;] = X[&quot;minutes&quot;] / (X[&quot;calls&quot;] + 1)

        # MB por mensaje
        if &quot;mb_used&quot; in X.columns and &quot;messages&quot; in X.columns:
            X[&quot;mb_per_message&quot;] = X[&quot;mb_used&quot;] / (X[&quot;messages&quot;] + 1)

        # Uso total normalizado
        if all(col in X.columns for col in [&quot;calls&quot;, &quot;messages&quot;, &quot;mb_used&quot;]):
            X[&quot;total_usage&quot;] = X[&quot;calls&quot;] + X[&quot;messages&quot;] + (X[&quot;mb_used&quot;] / 1000)

        return X

    def get_feature_names_out(self, input_features=None):
        &quot;&quot;&quot;Retorna nombres de features creadas.&quot;&quot;&quot;
        return [&quot;minutes_per_call&quot;, &quot;mb_per_message&quot;, &quot;total_usage&quot;]


# Verificar
import pandas as pd

df = pd.DataFrame({
    &quot;calls&quot;: [50, 100],
    &quot;minutes&quot;: [200, 500],
    &quot;messages&quot;: [100, 50],
    &quot;mb_used&quot;: [5000, 10000]
})

fe = TelecomFeatureEngineer()
df_transformed = fe.fit_transform(df)
print(df_transformed.columns.tolist())
# Output incluye: minutes_per_call, mb_per_message, total_usage
</code></pre>


</details>

<h3>Ejercicio 3: Pipeline Completo para TelecomAI</h3>
<pre><code class="language-python"># Tu tarea: Construye un pipeline completo para TelecomAI
# 
# Estructura:
# 1. TelecomFeatureEngineer (del ejercicio anterior)
# 2. ColumnTransformer para preprocessing
# 3. LogisticRegression como modelo
#
# El pipeline debe ser guardable con joblib

# Tu cÃ³digo aquÃ­:
def build_telecom_pipeline():
    pass
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
import joblib


def build_telecom_pipeline(config: dict = None) -&gt; Pipeline:
    &quot;&quot;&quot;Construye pipeline completo para TelecomAI.&quot;&quot;&quot;

    # ConfiguraciÃ³n por defecto
    if config is None:
        config = {
            &quot;num_cols&quot;: [&quot;calls&quot;, &quot;minutes&quot;, &quot;messages&quot;, &quot;mb_used&quot;, 
                        &quot;minutes_per_call&quot;, &quot;mb_per_message&quot;, &quot;total_usage&quot;],
            &quot;cat_cols&quot;: [],
            &quot;random_state&quot;: 42
        }

    num_cols = config[&quot;num_cols&quot;]
    cat_cols = config.get(&quot;cat_cols&quot;, [])

    # Etapa 1: Feature Engineering
    feature_engineer = TelecomFeatureEngineer()

    # Etapa 2: Preprocessing
    transformers = [
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ]), num_cols)
    ]

    if cat_cols:
        transformers.append(
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(handle_unknown='ignore'))
            ]), cat_cols)
        )

    preprocessor = ColumnTransformer(
        transformers=transformers,
        remainder='drop'
    )

    # Etapa 3: Modelo
    model = LogisticRegression(
        random_state=config.get(&quot;random_state&quot;, 42),
        max_iter=1000
    )

    # Pipeline completo
    pipeline = Pipeline([
        ('features', feature_engineer),
        ('preprocessor', preprocessor),
        ('model', model)
    ])

    return pipeline


# Uso
pipeline = build_telecom_pipeline()
# pipeline.fit(X_train, y_train)
# joblib.dump(pipeline, &quot;artifacts/model.joblib&quot;)
</code></pre>


</details>

<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en sklearn Pipelines</h2>
<p>Los errores en este mÃ³dulo rara vez son â€œfallos exÃ³ticosâ€ del algoritmo; casi siempre son <strong>desalineaciones</strong> entre datos, columnas, transformers y cÃ³mo guardas/cargas el pipeline.</p>
<h3>1) <code>ValueError: number of features does not match</code> (mismatch entre train e inference)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En entrenamiento todo bien, pero al predecir obtienes:<br />
<code>text
  ValueError: X has 15 features, but StandardScaler is expecting 12 features as input.</code></li>
<li>O bien errores de Ã­ndice similares en <code>OneHotEncoder</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica que usas <strong>el mismo pipeline serializado</strong> en training e inference:</li>
<li>Â¿Guardas y cargas <code>pipeline.pkl</code>/<code>model.joblib</code>, o solo el modelo suelto?</li>
<li>Comprueba que las columnas de entrada en producciÃ³n tienen el mismo orden y nombres que en entrenamiento.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>En el portafolio, <strong>siempre</strong> serializa el pipeline completo:<br />
<code>python
  joblib.dump(pipeline, "artifacts/model.joblib")
  pipeline = joblib.load("artifacts/model.joblib")</code></li>
<li>AsegÃºrate de que el orden y nombres de columnas que construyes en la API/Streamlit coincidan con las listas <code>num_cols</code> y <code>cat_cols</code> del pipeline.</li>
</ul>
<h3>2) Data leakage por features que usan el target (especialmente en CarVision)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>MÃ©tricas en training/validation son <strong>sospechosamente altas</strong>, pero en producciÃ³n caen.</li>
<li>Features como <code>price_per_mile</code> o <code>price_category</code> dependen de la variable objetivo (<code>price</code>).</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Examina tu <code>FeatureEngineer</code> y lista de columnas que entran al modelo:</li>
<li>Â¿EstÃ¡s incluyendo columnas derivadas del target en el <code>ColumnTransformer</code>?</li>
<li>Revisa tu config (<code>cfg["preprocessing"]["numeric_features"]</code>, etc.) y confirma que solo incluyes features vÃ¡lidos.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AsegÃºrate de que features que dependen del target <strong>no</strong> se usen como input del modelo.</li>
<li>En CarVision, por ejemplo, <code>price_per_mile</code> y <code>price_category</code> se calculan solo para anÃ¡lisis, pero se excluyen de <code>num_cols</code> para el pipeline.</li>
</ul>
<h3>3) Custom transformers que modifican el input in-place o no respetan la API sklearn</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores del tipo:<br />
<code>text
  TypeError: __init__() takes 1 positional argument but 2 were given</code><br />
  o<br />
<code>text
  AttributeError: 'MiTransformer' object has no attribute 'fit'</code></li>
<li>Comportamientos raros donde un transformer â€œensuciaâ€ los datos para otros steps.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa que tu transformer:</li>
<li>Herede de <code>BaseEstimator</code> y <code>TransformerMixin</code>.</li>
<li>Tenga <code>__init__</code>, <code>fit</code>, <code>transform</code> con las firmas estÃ¡ndar.</li>
<li>Use <code>X = X.copy()</code> dentro de <code>transform</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa la plantilla de este mÃ³dulo (<code>MiTransformer</code>) como referencia.</li>
<li>Evita lÃ³gica pesada en <code>__init__</code>; ahÃ­ solo se guardan parÃ¡metros.</li>
<li>AÃ±ade tests unitarios simples (<code>fit_transform</code> sobre un <code>DataFrame</code> pequeÃ±o) para validar que mantiene columnas esperadas.</li>
</ul>
<h3>4) Pipelines diferentes en training y en la API</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El pipeline usado en <code>training.py</code> no coincide con el que se monta en <code>fastapi_app.py</code> o <code>streamlit_app.py</code>.</li>
<li>Bugs donde la API aplica transformaciones manuales <strong>ademÃ¡s</strong> del pipeline.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Busca en el proyecto si estÃ¡s construyendo pipelines duplicados:</li>
<li>En CarVision, la Ãºnica fuente de verdad debe ser <code>build_pipeline</code> en <code>src/carvision/training.py</code>.</li>
<li>La API y Streamlit solo deberÃ­an <strong>cargar</strong> el pipeline serializado, no recrearlo a mano.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Centraliza la construcciÃ³n del pipeline en una funciÃ³n (<code>build_pipeline</code> / <code>build_telecom_pipeline</code>).</li>
<li>En la API/Streamlit, no replicar lÃ³gicas de preprocesado; limitarse a cargar y usar el pipeline.</li>
</ul>
<h3>5) PatrÃ³n general de debugging para pipelines</h3>
<ol>
<li><strong>Reproduce el error</strong> con un input mÃ­nimo (1â€“2 filas de <code>DataFrame</code>).</li>
<li><strong>Inspecciona shapes y columnas</strong> tras cada etapa:</li>
<li>Usa <code>pipeline.named_steps["pre"].transform(X_sample)</code> o similares.</li>
<li><strong>Verifica la serializaciÃ³n</strong>: guarda, vuelve a cargar, y compara predicciones en un mismo batch.</li>
<li><strong>Conecta el problema</strong> con el concepto del mÃ³dulo:</li>
<li>Training-serving skew â†’ pipeline parcial o mal serializado.</li>
<li>Mismatch de columnas â†’ listas <code>num_cols</code>/<code>cat_cols</code> desincronizadas.</li>
<li>Transformers rotos â†’ no respetan <code>fit</code>/<code>transform</code>.</li>
</ol>
<p>Con este enfoque, los pipelines dejan de ser una â€œcaja negra mÃ¡gicaâ€ y se convierten en una lÃ­nea de ensamblaje transparente y depurable.</p>
<h2>âœ… Checkpoint: Â¿Completaste el MÃ³dulo?</h2>
<p>Antes de continuar, verifica:</p>
<ul>
<li>[ ] Entiendes por quÃ© los pipelines previenen training-serving skew</li>
<li>[ ] Sabes usar ColumnTransformer para diferentes tipos de columnas</li>
<li>[ ] Puedes crear un Custom Transformer con fit/transform</li>
<li>[ ] Has construido un pipeline de 3 etapas (features â†’ preprocessing â†’ model)</li>
<li>[ ] Puedes guardar y cargar un pipeline completo con joblib</li>
</ul>
<h2>ğŸ”— ADR: Decisiones de Arquitectura</h2>
<h3>ADR-007: Pipeline Unificado Obligatorio</h3>
<p><strong>Contexto</strong>: Transformaciones separadas causan inconsistencias en producciÃ³n.</p>
<p><strong>DecisiÃ³n</strong>: Todo el flujo (features â†’ preprocessing â†’ model) debe estar en un solo Pipeline.</p>
<p><strong>Consecuencias</strong>:<br />
- âœ… Una sola serializaciÃ³n guarda todo<br />
- âœ… Imposible olvidar una transformaciÃ³n<br />
- âœ… Reproducibilidad garantizada<br />
- âŒ MÃ¡s complejo de debuggear (caja negra)<br />
- âŒ Requiere entender sklearn profundamente</p>
<h3>ADR-008: Custom Transformers para Feature Engineering</h3>
<p><strong>Contexto</strong>: sklearn no tiene transformers para lÃ³gica de negocio especÃ­fica.</p>
<p><strong>DecisiÃ³n</strong>: Crear FeatureEngineer como TransformerMixin.</p>
<p><strong>Consecuencias</strong>:<br />
- âœ… Reutilizable en train, API, y dashboard<br />
- âœ… Testeable unitariamente<br />
- âœ… DocumentaciÃ³n clara de features derivadas<br />
- âŒ MÃ¡s cÃ³digo que escribir<br />
- âŒ Requiere entender BaseEstimator/TransformerMixin</p>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>Los pipelines sklearn son el corazÃ³n de los 3 proyectos del portafolio:</p>
<h3>Pipeline Unificado de BankChurn</h3>
<pre><code class="language-python"># BankChurn-Predictor/src/bankchurn/pipeline.py (estructura real)
def build_pipeline(config: BankChurnConfig) -&gt; Pipeline:
    &quot;&quot;&quot;Pipeline completo de 3 etapas.&quot;&quot;&quot;
    return Pipeline([
        ('preprocessor', ColumnTransformer([
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler())
            ]), config.data.numerical_features),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                ('encoder', OneHotEncoder(handle_unknown='ignore'))
            ]), config.data.categorical_features)
        ])),
        ('model', get_model(config))
    ])
</code></pre>
<h3>FeatureEngineer de CarVision</h3>
<pre><code class="language-python"># CarVision-Market-Intelligence/src/carvision/features.py
class FeatureEngineer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;Custom transformer para features de autos.&quot;&quot;&quot;

    def __init__(self, current_year: int = None):
        self.current_year = current_year

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        # vehicle_age, brand, mileage_category, etc.
        return X
</code></pre>
<h3>Archivos Clave por Proyecto</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Pipeline</th>
<th>Features</th>
<th>Artefacto</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>src/bankchurn/pipeline.py</code></td>
<td>En preprocessor</td>
<td><code>artifacts/pipeline.joblib</code></td>
</tr>
<tr>
<td>CarVision</td>
<td><code>src/carvision/pipeline.py</code></td>
<td><code>src/carvision/features.py</code></td>
<td><code>artifacts/pipeline.joblib</code></td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>src/telecomai/training.py</code></td>
<td>En pipeline</td>
<td><code>artifacts/model.joblib</code></td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Explora los Pipelines Reales</h3>
<pre><code class="language-bash"># 1. Ve a BankChurn y carga el pipeline
cd BankChurn-Predictor
python -c &quot;
import joblib
pipe = joblib.load('artifacts/pipeline.joblib')
print('Steps:', [name for name, _ in pipe.steps])
print('Preprocessor:', pipe.named_steps['preprocessor'])
&quot;

# 2. Inspecciona el FeatureEngineer de CarVision
cat CarVision-Market-Intelligence/src/carvision/features.py
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Â¿Por quÃ© Pipelines?</strong>: Evitan data leakage, garantizan reproducibilidad, simplifican deployment.</p>
</li>
<li>
<p><strong>Custom Transformers</strong>: Demuestra que puedes crear transformadores con <code>fit()</code> y <code>transform()</code>.</p>
</li>
<li>
<p><strong>ColumnTransformer</strong>: Explica cÃ³mo aplicar diferentes transformaciones a diferentes columnas.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Features nuevas</td>
<td>AÃ±ade transformadores al pipeline, no cÃ³digo suelto</td>
</tr>
<tr>
<td>Debugging</td>
<td>Usa <code>pipeline.named_steps</code> para inspeccionar etapas</td>
</tr>
<tr>
<td>ProducciÃ³n</td>
<td>Serializa el pipeline completo, no solo el modelo</td>
</tr>
<tr>
<td>Testing</td>
<td>Testea cada transformador individualmente</td>
</tr>
</tbody>
</table>
<h3>Patrones Avanzados</h3>
<ul>
<li><strong>FeatureUnion</strong>: Combinar features de diferentes fuentes</li>
<li><strong>Pipeline dentro de Pipeline</strong>: Para transformaciones complejas</li>
<li><strong>make_pipeline</strong>: Sintaxis simplificada sin nombres</li>
<li><strong>clone</strong>: Para cross-validation sin modificar original</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=irHhDMbw3xo">sklearn Pipelines - Data School</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=e8IIYRMnxcE">Custom Transformers - ArjanCodes</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://scikit-learn.org/stable/modules/compose.html">sklearn Pipeline</a><br />
- <a href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html">ColumnTransformer</a><br />
- <a href="https://scikit-learn.org/stable/developers/develop.html">Custom Transformers</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Pipeline</strong>: Cadena de transformaciones + modelo<br />
- <strong>ColumnTransformer</strong>: Procesamiento paralelo de columnas<br />
- <strong>Data Leakage</strong>: FiltraciÃ³n de informaciÃ³n del target</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 07:<br />
- <strong>7.1</strong>: Pipeline bÃ¡sico con scaler + modelo<br />
- <strong>7.2</strong>: ColumnTransformer para features mixtas</p>
            </div>
        
            <!-- MÃ“DULO: 08_INGENIERIA_FEATURES.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_08_INGENIERIA_FEATURES" class="cover-title">INGENIERÃA DE FEATURES</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>08. IngenierÃ­a de Features para ML</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Dominar la creaciÃ³n de features sin introducir <strong>data leakage</strong>, el error mÃ¡s peligroso y difÃ­cil de detectar en ML.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  ğŸš¨ DATA LEAKAGE: El Asesino Silencioso de Modelos                           â•‘
â•‘                                                                              â•‘
â•‘  Tu modelo tiene 99% accuracy en validaciÃ³n...                               â•‘
â•‘  ...pero 50% en producciÃ³n.                                                  â•‘
â•‘                                                                              â•‘
â•‘  Â¿Por quÃ©? Porque durante el entrenamiento, el modelo &quot;vio&quot; informaciÃ³n      â•‘
â•‘  que NO tendrÃ¡ disponible cuando haga predicciones reales.                   â•‘
â•‘                                                                              â•‘
â•‘  Es como estudiar para un examen con las respuestas en la mano.              â•‘
â•‘  Sacas 100 en el examen de prÃ¡ctica, pero 0 en el real.                      â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#81-quÃ©-es-data-leakage">Â¿QuÃ© es Data Leakage?</a></li>
<li><a href="#82-tipos-de-leakage">Tipos de Leakage en ML</a></li>
<li><a href="#83-caso-real-carvision">Caso Real: CarVision</a></li>
<li><a href="#84-prevenciÃ³n-con-pipelines">PrevenciÃ³n con Pipelines</a></li>
<li><a href="#85-feature-engineering-seguro">Feature Engineering Seguro</a></li>
</ol>
<h2>8.1 Â¿QuÃ© es Data Leakage?</h2>
<h3>La AnalogÃ­a del Detective</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ” IMAGINA UN DETECTIVE RESOLVIENDO UN CASO:                             â•‘
â•‘                                                                           â•‘
â•‘  SIN LEAKAGE (correcto):                                                  â•‘
â•‘  â€¢ El detective solo tiene las pistas disponibles AL MOMENTO del crimen   â•‘
â•‘  â€¢ Debe deducir quiÃ©n es el culpable con informaciÃ³n limitada             â•‘
â•‘  â€¢ Es difÃ­cil, pero es la realidad                                        â•‘
â•‘                                                                           â•‘
â•‘  CON LEAKAGE (trampa):                                                    â•‘
â•‘  â€¢ El detective tiene acceso al informe FINAL del caso                    â•‘
â•‘  â€¢ Ya sabe quiÃ©n es el culpable antes de investigar                       â•‘
â•‘  â€¢ &quot;Resuelve&quot; el caso fÃ¡cilmente, pero no aprendiÃ³ nada                   â•‘
â•‘                                                                           â•‘
â•‘  EN ML:                                                                   â•‘
â•‘  â€¢ El modelo debe predecir usando SOLO informaciÃ³n disponible             â•‘
â•‘    en el momento de la predicciÃ³n                                         â•‘
â•‘  â€¢ Si usas informaciÃ³n del futuro o del target, es TRAMPA                 â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Ejemplo ClÃ¡sico: Predecir Precio con precio_per_mile</h3>
<pre><code class="language-python"># âŒ LEAKAGE: Usando feature derivada del target

# Datos originales
df = pd.DataFrame({
    'price': [15000, 25000, 35000],      # Target a predecir
    'odometer': [80000, 50000, 20000],
})

# Feature engineering INCORRECTO
df['price_per_mile'] = df['price'] / df['odometer']  # â† LEAKAGE!

# Â¿Por quÃ© es leakage?
# price_per_mile = price / odometer
# Por lo tanto: price = price_per_mile * odometer
# El modelo &quot;aprende&quot; a multiplicar, no a predecir precios reales

# En producciÃ³n:
# - No tienes el price (es lo que quieres predecir)
# - No puedes calcular price_per_mile
# - El modelo no sabe quÃ© hacer
</code></pre>
<h2>8.2 Tipos de Leakage</h2>
<h3>1. Target Leakage (Feature contiene informaciÃ³n del target)</h3>
<pre><code class="language-python"># âŒ MALO: Feature calculada con el target
df['price_category'] = pd.cut(df['price'], bins=[0, 10000, 50000, inf])

# El modelo aprende: &quot;si price_category es 'alto', predice price alto&quot;
# Pero en producciÃ³n NO tienes price_category porque no tienes price
</code></pre>
<h3>2. Train-Test Contamination (Datos de test "filtrados" a train)</h3>
<pre><code class="language-python"># âŒ MALO: Normalizar ANTES de split
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # â† Usa estadÃ­sticas de TODO X
X_train, X_test = train_test_split(X_scaled)
# El scaler &quot;vio&quot; datos de test durante fit

# âœ… CORRECTO: Normalizar DESPUÃ‰S de split
X_train, X_test = train_test_split(X)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Solo train
X_test_scaled = scaler.transform(X_test)        # Usa params de train
</code></pre>
<h3>3. Temporal Leakage (Usar informaciÃ³n del futuro)</h3>
<pre><code class="language-python"># âŒ MALO: Predecir churn de enero usando datos de febrero
df['avg_purchases_next_month'] = ...  # InformaciÃ³n del futuro

# âœ… CORRECTO: Solo usar informaciÃ³n disponible al momento de predicciÃ³n
df['avg_purchases_last_3_months'] = ...  # InformaciÃ³n del pasado
</code></pre>
<h2>8.3 Caso Real: CarVision</h2>
<h3>El Problema Original</h3>
<p>En CarVision, tenÃ­amos features que causaban leakage:</p>
<pre><code class="language-python"># src/carvision/features.py - ANTES (con leakage potencial)

class FeatureEngineer:
    def transform(self, X):
        X = X.copy()

        # âœ… OK: vehicle_age no depende del target
        X['vehicle_age'] = 2024 - X['model_year']

        # âœ… OK: brand no depende del target
        X['brand'] = X['model'].str.split().str[0]

        # âš ï¸ PELIGRO: price_per_mile DEPENDE de price (target)
        X['price_per_mile'] = X['price'] / (X['odometer'] + 1)

        # âš ï¸ PELIGRO: price_category DEPENDE de price (target)
        X['price_category'] = pd.cut(X['price'], ...)

        return X
</code></pre>
<h3>La SoluciÃ³n: drop_columns en Config</h3>
<pre><code class="language-yaml"># configs/config.yaml

preprocessing:
  numeric_features:
    - odometer
    - vehicle_age
  categorical_features:
    - fuel
    - transmission
    - brand
  drop_columns:           # â† Features que causan leakage
    - price_per_mile      # Depende de price
    - price_category      # Depende de price
</code></pre>
<pre><code class="language-python"># src/carvision/data.py

def infer_feature_types(df, target, drop_columns=None, ...):
    &quot;&quot;&quot;Infiere tipos de features, excluyendo las que causan leakage.&quot;&quot;&quot;

    # Columnas a excluir
    exclude = {target}  # Siempre excluir el target
    if drop_columns:
        exclude.update(drop_columns)  # Excluir features con leakage

    # Inferir tipos solo de columnas seguras
    for col in df.columns:
        if col in exclude:
            continue  # Saltar columnas peligrosas
        # ... resto de la lÃ³gica
</code></pre>
<h3>Â¿Por quÃ© NO eliminamos price_per_mile del FeatureEngineer?</h3>
<pre><code class="language-python"># La feature EXISTE en el transformer, pero se ELIMINA antes del modelo

# Motivo: price_per_mile es Ãºtil para ANÃLISIS (no para predicciÃ³n)
# En el dashboard de Streamlit, usamos price_per_mile para visualizaciones
# Pero en el modelo de predicciÃ³n, la eliminamos

# Flujo:
# 1. FeatureEngineer crea price_per_mile (para anÃ¡lisis)
# 2. Config especifica drop_columns = [price_per_mile]
# 3. ColumnTransformer NO incluye price_per_mile en sus transformers
# 4. Modelo entrena sin price_per_mile
</code></pre>
<h2>8.4 PrevenciÃ³n con Pipelines</h2>
<h3>El Pipeline como Barrera Anti-Leakage</h3>
<pre><code class="language-python"># âœ… CORRECTO: Pipeline garantiza orden correcto

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Definir QUÃ‰ columnas usar (excluyendo las peligrosas)
num_cols = ['odometer', 'vehicle_age']  # SIN price_per_mile
cat_cols = ['fuel', 'transmission', 'brand']

# Pipeline aplica transformaciones EN ORDEN
pipeline = Pipeline([
    ('features', FeatureEngineer()),      # Crea features
    ('pre', ColumnTransformer([           # Solo usa features SEGURAS
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(), cat_cols)
    ])),
    ('model', RandomForestRegressor())
])

# fit() entrena todo con datos de TRAIN solamente
pipeline.fit(X_train, y_train)

# predict() aplica las MISMAS transformaciones
# usando parÃ¡metros aprendidos de TRAIN
predictions = pipeline.predict(X_test)
</code></pre>
<h3>Diagrama del Flujo Seguro</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FLUJO ANTI-LEAKAGE CON PIPELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ENTRENAMIENTO:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ X_train  â”‚â”€â”€â”€â–ºâ”‚FeatureEng      â”‚â”€â”€â”€â–ºâ”‚DropDanger  â”‚â”€â”€â”€â–ºâ”‚ Scaler   â”‚       â”‚
â”‚  â”‚          â”‚    â”‚ (crea features)â”‚    â”‚ (elimina   â”‚    â”‚ fit()    â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  leakage)  â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚             â”‚
â”‚                                                               â–¼             â”‚
â”‚                                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                                                        â”‚  Model   â”‚         â”‚
â”‚                                                        â”‚  fit()   â”‚         â”‚
â”‚                                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                             â”‚
â”‚  PREDICCIÃ“N:                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ X_new    â”‚â”€â”€â”€â–ºâ”‚FeatureEng    â”‚â”€â”€â”€â–ºâ”‚DropDanger  â”‚â”€â”€â”€â–ºâ”‚ Scaler   â”‚         â”‚
â”‚  â”‚          â”‚    â”‚ (mismas feat)â”‚    â”‚ (mismas    â”‚    â”‚transform â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  columnas) â”‚    â”‚ (NO fit) â”‚         â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                             â”‚               â”‚
â”‚                                                             â–¼               â”‚
â”‚                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                                                      â”‚  Model   â”‚           â”‚
â”‚                                                      â”‚ predict()â”‚           â”‚
â”‚                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>8.5 Feature Engineering Seguro</h2>
<h3>Checklist Anti-Leakage</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœ… CHECKLIST ANTES DE CREAR UNA FEATURE                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘  1. Â¿Esta feature estarÃ¡ disponible en producciÃ³n?                        â•‘
â•‘     â–¡ SÃ â†’ OK                                                             â•‘
â•‘     â–¡ NO â†’ âŒ NO USAR para predicciÃ³n                                     â•‘
â•‘                                                                           â•‘
â•‘  2. Â¿Esta feature usa informaciÃ³n del target (directa o indirectamente)?  â•‘
â•‘     â–¡ NO â†’ OK                                                             â•‘
â•‘     â–¡ SÃ â†’ âŒ LEAKAGE - eliminar o recalcular sin target                  â•‘
â•‘                                                                           â•‘
â•‘  3. Â¿Esta feature usa informaciÃ³n del futuro?                             â•‘
â•‘     â–¡ NO â†’ OK                                                             â•‘
â•‘     â–¡ SÃ â†’ âŒ TEMPORAL LEAKAGE - usar solo datos pasados                  â•‘
â•‘                                                                           â•‘
â•‘  4. Â¿Las estadÃ­sticas de esta feature se calcularon con datos de test?    â•‘
â•‘     â–¡ NO â†’ OK                                                             â•‘
â•‘     â–¡ SÃ â†’ âŒ TRAIN-TEST CONTAMINATION - recalcular solo con train        â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Features Seguras vs Peligrosas</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th style="text-align: center;">Segura</th>
<th>Motivo</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>vehicle_age = 2024 - model_year</code></td>
<td style="text-align: center;">âœ…</td>
<td>No depende del target</td>
</tr>
<tr>
<td><code>brand = model.split()[0]</code></td>
<td style="text-align: center;">âœ…</td>
<td>No depende del target</td>
</tr>
<tr>
<td><code>is_luxury = brand in ['bmw', 'mercedes']</code></td>
<td style="text-align: center;">âœ…</td>
<td>No depende del target</td>
</tr>
<tr>
<td><code>price_per_mile = price / odometer</code></td>
<td style="text-align: center;">âŒ</td>
<td>Usa el target (price)</td>
</tr>
<tr>
<td><code>price_category = cut(price)</code></td>
<td style="text-align: center;">âŒ</td>
<td>Usa el target (price)</td>
</tr>
<tr>
<td><code>avg_price_by_brand</code> (calculado con todo el dataset)</td>
<td style="text-align: center;">âŒ</td>
<td>Contamina train/test</td>
</tr>
</tbody>
</table>
<h3>CÃ³digo: Feature Engineering Seguro</h3>
<pre><code class="language-python"># src/carvision/features.py - VersiÃ³n SEGURA

class FeatureEngineer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;Feature engineering sin leakage.&quot;&quot;&quot;

    def __init__(self, current_year: int = None):
        self.current_year = current_year

    def fit(self, X, y=None):
        # Stateless: no aprende nada que pueda causar leakage
        return self

    def transform(self, X):
        X = X.copy()
        year = self.current_year or pd.Timestamp.now().year

        # âœ… SEGURO: Solo usa columnas de entrada (no target)
        if 'model_year' in X.columns:
            X['vehicle_age'] = year - X['model_year']

        if 'model' in X.columns:
            X['brand'] = X['model'].astype(str).str.split().str[0]

        # âš ï¸ CONDICIONAL: Solo crear si price existe (para anÃ¡lisis)
        # El modelo NO usarÃ¡ estas features (drop_columns en config)
        if 'price' in X.columns and 'odometer' in X.columns:
            X['price_per_mile'] = X['price'] / (X['odometer'] + 1)

        return X
</code></pre>
<h2>âœ… Ejercicio: Detectar Leakage</h2>
<pre><code class="language-python"># Analiza este cÃ³digo y encuentra todos los casos de leakage

def prepare_data(df):
    # 1. Normalizar todas las features
    scaler = StandardScaler()
    df[['age', 'income']] = scaler.fit_transform(df[['age', 'income']])

    # 2. Crear features
    df['income_category'] = pd.cut(df['target_income'], bins=3)
    df['age_bucket'] = pd.cut(df['age'], bins=[0, 30, 50, 100])

    # 3. Split
    X_train, X_test = train_test_split(df.drop('target_income', axis=1))
    y_train, y_test = train_test_split(df['target_income'])

    return X_train, X_test, y_train, y_test
</code></pre>
<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>


<pre><code class="language-python"># PROBLEMAS DETECTADOS:

# 1. âŒ TRAIN-TEST CONTAMINATION (lÃ­nea 3-4)
# scaler.fit_transform se aplica a TODO el dataset antes del split
# El scaler &quot;ve&quot; estadÃ­sticas de test durante entrenamiento

# 2. âŒ TARGET LEAKAGE (lÃ­nea 7)
# income_category se calcula usando target_income
# El modelo aprenderÃ¡ a &quot;leer&quot; el target desde esta feature

# 3. âŒ SPLIT INCONSISTENTE (lÃ­neas 11-12)
# train_test_split se llama dos veces con diferentes random states
# X_train no corresponde con y_train

# VERSIÃ“N CORREGIDA:
def prepare_data_correct(df):
    # 1. Split PRIMERO
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

    # 2. Features SIN leakage
    for data in [train_df, test_df]:
        data['age_bucket'] = pd.cut(data['age'], bins=[0, 30, 50, 100])
        # NO crear income_category - usa el target

    # 3. Separar X e y
    X_train = train_df.drop('target_income', axis=1)
    y_train = train_df['target_income']
    X_test = test_df.drop('target_income', axis=1)
    y_test = test_df['target_income']

    # 4. Escalar SOLO con datos de train
    scaler = StandardScaler()
    X_train[['age', 'income']] = scaler.fit_transform(X_train[['age', 'income']])
    X_test[['age', 'income']] = scaler.transform(X_test[['age', 'income']])

    return X_train, X_test, y_train, y_test
</code></pre>


</details>

<h2>âœ… Checkpoint</h2>
<ul>
<li>[ ] Entiendes quÃ© es data leakage y por quÃ© es peligroso</li>
<li>[ ] Puedes identificar los 3 tipos de leakage</li>
<li>[ ] Sabes cÃ³mo usar <code>drop_columns</code> para eliminar features peligrosas</li>
<li>[ ] Entiendes por quÃ© el Pipeline previene leakage</li>
<li>[ ] Puedes aplicar el checklist anti-leakage a nuevas features</li>
</ul>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El proyecto <strong>CarVision</strong> es el ejemplo principal de feature engineering seguro:</p>
<h3>FeatureEngineer Centralizado</h3>
<pre><code class="language-python"># CarVision-Market-Intelligence/src/carvision/features.py
class FeatureEngineer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;Centraliza TODO el feature engineering.

    Usado en: training, FastAPI, Streamlit - siempre igual.
    &quot;&quot;&quot;

    def __init__(self, current_year: int = None):
        self.current_year = current_year

    def transform(self, X):
        X = X.copy()
        year = self.current_year or pd.Timestamp.now().year

        # âœ… Features SEGURAS (no usan target)
        X['vehicle_age'] = year - X['model_year']
        X['brand'] = X['model'].str.split().str[0]
        X['mileage_category'] = pd.cut(X['odometer'], bins=[0, 50000, 100000, float('inf')])

        return X
</code></pre>
<h3>PrevenciÃ³n de Leakage en Config</h3>
<pre><code class="language-yaml"># CarVision-Market-Intelligence/configs/config.yaml
data:
  target_column: price
  drop_columns:
    - price_per_mile    # âŒ Usa target
    - price_category    # âŒ Usa target
    - id                # No predictivo
</code></pre>
<h3>Caso Real: Bug Corregido</h3>
<p>El portafolio tuvo un bug de leakage que fue corregido:</p>
<pre><code class="language-python"># âŒ ANTES (con leakage)
X['price_per_mile'] = X['price'] / X['odometer']  # Usaba el target!

# âœ… DESPUÃ‰S (sin leakage)
# price_per_mile se elimina en drop_columns
# Solo se calcula para anÃ¡lisis exploratorio, NO para el modelo
</code></pre>
<h3>Archivos Clave</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Feature Engineering</th>
<th>Anti-Leakage</th>
</tr>
</thead>
<tbody>
<tr>
<td>CarVision</td>
<td><code>src/carvision/features.py</code></td>
<td><code>drop_columns</code> en config</td>
</tr>
<tr>
<td>BankChurn</td>
<td>En <code>ColumnTransformer</code></td>
<td>Sin features derivadas del target</td>
</tr>
<tr>
<td>TelecomAI</td>
<td>En pipeline</td>
<td>Sin features peligrosas</td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Audita CarVision</h3>
<pre><code class="language-bash"># 1. Revisa el FeatureEngineer
cat CarVision-Market-Intelligence/src/carvision/features.py

# 2. Verifica drop_columns en config
cat CarVision-Market-Intelligence/configs/config.yaml | grep -A5 &quot;drop_columns&quot;

# 3. Ejecuta tests para verificar que no hay leakage
cd CarVision-Market-Intelligence
pytest tests/test_features.py -v
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Feature Store</strong>: Explica por quÃ© centralizar features mejora consistencia training/serving.</p>
</li>
<li>
<p><strong>Data Leakage</strong>: Da ejemplos concretos (usar target en features, informaciÃ³n del futuro).</p>
</li>
<li>
<p><strong>Feature Selection</strong>: Conoce mÃ©todos (mutual information, RFE, importancia de modelo).</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Features temporales</td>
<td>Cuidado con leakage: no uses info futura</td>
</tr>
<tr>
<td>CategorÃ­as nuevas</td>
<td>Usa <code>handle_unknown='ignore'</code> en encoders</td>
</tr>
<tr>
<td>Features de texto</td>
<td>TF-IDF para baseline, embeddings para avanzado</td>
</tr>
<tr>
<td>Interacciones</td>
<td>PolynomialFeatures con grado 2 mÃ¡ximo</td>
</tr>
</tbody>
</table>
<h3>Checklist de Feature Engineering</h3>
<ul>
<li>[ ] Sin data leakage verificado</li>
<li>[ ] Transformaciones aplicadas consistentemente train/serve</li>
<li>[ ] Features documentadas (significado, fuente, transformaciÃ³n)</li>
<li>[ ] Outliers manejados (clip, winsorize, o flag)</li>
<li>[ ] Missing values con estrategia clara</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=6WDFfaYtN6s">Feature Engineering for ML - Krish Naik</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=NfOYWZnPK3I">Avoiding Data Leakage</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Data Leakage</strong>: FiltraciÃ³n de informaciÃ³n del target<br />
- <strong>Feature Engineering</strong>: CreaciÃ³n de variables predictivas<br />
- <strong>ColumnTransformer</strong>: Procesamiento paralelo de columnas</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 08:<br />
- <strong>8.1</strong>: Detectar data leakage<br />
- <strong>8.2</strong>: Pipeline sin leakage</p>
            </div>
        
            <!-- MÃ“DULO: 09_TRAINING_PROFESIONAL.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_09_TRAINING_PROFESIONAL" class="cover-title">TRAINING PROFESIONAL</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>09. Training Profesional</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Implementar un pipeline de entrenamiento robusto, reproducible y loggeable como <code>ChurnTrainer</code> de BankChurn.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  NOTEBOOK TÃPICO:                    CÃ“DIGO PROFESIONAL:                     â•‘ 
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â•‘
â•‘  â€¢ 500 lÃ­neas en un archivo          â€¢ Clases modulares                      â•‘
â•‘  â€¢ Variables globales                â€¢ ConfiguraciÃ³n externa                 â•‘
â•‘  â€¢ Sin logging                       â€¢ Logging estructurado                  â•‘
â•‘  â€¢ &quot;FuncionÃ³... creo&quot;                â€¢ MÃ©tricas rastreadas                   â•‘
â•‘  â€¢ Imposible reproducir              â€¢ 100% reproducible                     â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>Este mÃ³dulo se apoya directamente en el cÃ³digo real de <strong>BankChurn-Predictor</strong>:</li>
<li><code>src/bankchurn/training.py</code> (<code>ChurnTrainer</code>).</li>
<li><code>configs/config.yaml</code> (config Pydantic usada en el trainer).</li>
<li>Carpeta <code>artifacts/</code> donde se guardan <code>model.joblib</code> y <code>training_results.json</code>.</li>
<li>TambiÃ©n establece el patrÃ³n que luego deberÃ¡s replicar en <strong>CarVision</strong> y <strong>TelecomAI</strong><br />
  (por ejemplo, implementando tu propio <code>PriceTrainer</code> o <code>TelecomTrainer</code>) y que se conecta<br />
  con los mÃ³dulos de <strong>Experiment Tracking</strong> (MLflow) y <strong>CI/CD</strong>.</li>
</ul>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#91-arquitectura-de-una-clase-trainer">Arquitectura de una Clase Trainer</a></li>
<li><a href="#92-carga-y-validaciÃ³n-de-datos">Carga y ValidaciÃ³n de Datos</a></li>
<li><a href="#93-cross-validation-profesional">Cross-Validation Profesional</a></li>
<li><a href="#94-gestiÃ³n-de-artefactos">GestiÃ³n de Artefactos</a></li>
<li><a href="#95-logging-y-mÃ©tricas">Logging y MÃ©tricas</a></li>
</ol>
<h2>9.1 Arquitectura de una Clase Trainer</h2>
<h3>CÃ³digo Real: ChurnTrainer (BankChurn)</h3>
<pre><code class="language-python"># src/bankchurn/training.py - Estructura REAL del portafolio

from __future__ import annotations

import logging
from pathlib import Path
from typing import Dict, Tuple

import joblib
import mlflow
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.pipeline import Pipeline

from .config import BankChurnConfig

logger = logging.getLogger(__name__)


class ChurnTrainer:
    &quot;&quot;&quot;Pipeline de entrenamiento para predicciÃ³n de churn.

    Esta clase encapsula TODO el flujo de entrenamiento:
    1. Carga y validaciÃ³n de datos
    2. PreparaciÃ³n de features
    3. ConstrucciÃ³n del pipeline
    4. Entrenamiento con cross-validation
    5. EvaluaciÃ³n final
    6. Guardado de artefactos

    Parameters
    ----------
    config : BankChurnConfig
        ConfiguraciÃ³n validada con Pydantic.
    random_state : int, optional
        Semilla para reproducibilidad.

    Attributes
    ----------
    model_ : Pipeline
        Pipeline entrenado (disponible despuÃ©s de fit).
    cv_results_ : dict
        Resultados de cross-validation.
    test_results_ : dict
        Resultados en test set.

    Examples
    --------
    &gt;&gt;&gt; config = BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)
    &gt;&gt;&gt; trainer = ChurnTrainer(config)
    &gt;&gt;&gt; trainer.run(&quot;data/raw/churn.csv&quot;, &quot;artifacts/&quot;)
    &quot;&quot;&quot;

    def __init__(self, config: BankChurnConfig, random_state: int = None):
        self.config = config
        self.random_state = random_state or config.model.random_state

        # Atributos que se llenan durante entrenamiento
        self.model_: Pipeline | None = None
        self.cv_results_: Dict[str, float] | None = None
        self.test_results_: Dict[str, float] | None = None

        # Configurar MLflow si estÃ¡ habilitado
        if self.config.mlflow.enabled:
            self._setup_mlflow()

    def _setup_mlflow(self) -&gt; None:
        &quot;&quot;&quot;Configura MLflow tracking.&quot;&quot;&quot;
        try:
            mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)
            mlflow.set_experiment(self.config.mlflow.experiment_name)
            logger.info(f&quot;MLflow tracking: {self.config.mlflow.tracking_uri}&quot;)
        except Exception as e:
            logger.warning(f&quot;MLflow setup failed: {e}&quot;)

    def run(self, input_path: str | Path, output_dir: str | Path) -&gt; Dict:
        &quot;&quot;&quot;Ejecuta el pipeline completo de entrenamiento.

        Parameters
        ----------
        input_path : str or Path
            Ruta al CSV de entrada.
        output_dir : str or Path
            Directorio para guardar artefactos.

        Returns
        -------
        dict
            Resultados de entrenamiento y evaluaciÃ³n.
        &quot;&quot;&quot;
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        logger.info(&quot;=&quot; * 60)
        logger.info(&quot;INICIANDO ENTRENAMIENTO&quot;)
        logger.info(&quot;=&quot; * 60)

        # 1. Cargar datos
        data = self.load_data(input_path)

        # 2. Preparar features
        X, y = self.prepare_features(data)

        # 3. Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y,
            test_size=self.config.model.test_size,
            random_state=self.random_state,
            stratify=y  # Mantener proporciÃ³n de clases
        )
        logger.info(f&quot;Train: {len(X_train)}, Test: {len(X_test)}&quot;)

        # 4. Construir pipeline
        self.model_ = self.build_pipeline()

        # 5. Cross-validation
        self.cv_results_ = self.cross_validate(X_train, y_train)

        # 6. Entrenar modelo final
        self.model_.fit(X_train, y_train)

        # 7. Evaluar en test
        self.test_results_ = self.evaluate(X_test, y_test)

        # 8. Guardar artefactos
        self.save_artifacts(output_dir)

        # 9. Log a MLflow
        if self.config.mlflow.enabled:
            self._log_to_mlflow()

        logger.info(&quot;=&quot; * 60)
        logger.info(&quot;ENTRENAMIENTO COMPLETADO&quot;)
        logger.info(&quot;=&quot; * 60)

        return {
            &quot;cv_results&quot;: self.cv_results_,
            &quot;test_results&quot;: self.test_results_,
        }
</code></pre>
<h3>Diagrama del Flujo</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ChurnTrainer.run() Flow                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚ Config  â”‚â”€â”€â”€â–ºâ”‚  Load   â”‚â”€â”€â”€â–ºâ”‚ Prepare â”‚â”€â”€â”€â–ºâ”‚  Split   â”‚             â”‚
â”‚   â”‚  YAML   â”‚    â”‚  Data   â”‚    â”‚Features â”‚    â”‚Train/Testâ”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                     â”‚                   â”‚
â”‚                                                     â–¼                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚ MLflow  â”‚â—„â”€â”€â”€â”‚  Save   â”‚â—„â”€â”€â”€â”‚Evaluate â”‚â—„â”€â”€â”€â”‚  Train  â”‚              â”‚
â”‚   â”‚  Log    â”‚    â”‚Artifactsâ”‚    â”‚ (Test)  â”‚    â”‚ + CV    â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                         â”‚
â”‚   OUTPUT:                                                               â”‚
â”‚   â€¢ model.joblib (Pipeline completo)                                    â”‚
â”‚   â€¢ training_results.json (mÃ©tricas)                                    â”‚
â”‚   â€¢ MLflow run (experimento rastreado)                                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>9.2 Carga y ValidaciÃ³n de Datos</h2>
<pre><code class="language-python"># ContinuaciÃ³n de ChurnTrainer

def load_data(self, input_path: str | Path) -&gt; pd.DataFrame:
    &quot;&quot;&quot;Carga y valida datos de entrada.

    Parameters
    ----------
    input_path : str or Path
        Ruta al archivo CSV.

    Returns
    -------
    pd.DataFrame
        Datos cargados y validados.

    Raises
    ------
    FileNotFoundError
        Si el archivo no existe.
    ValueError
        Si faltan columnas requeridas.
    &quot;&quot;&quot;
    input_path = Path(input_path)

    if not input_path.exists():
        raise FileNotFoundError(f&quot;Archivo no encontrado: {input_path}&quot;)

    # Cargar CSV
    data = pd.read_csv(input_path)
    logger.info(f&quot;Datos cargados: {data.shape[0]} filas, {data.shape[1]} columnas&quot;)

    # Validar columnas requeridas
    required = {self.config.data.target_column}
    required.update(self.config.data.numerical_features)
    required.update(self.config.data.categorical_features)

    missing = required - set(data.columns)
    if missing:
        raise ValueError(f&quot;Columnas faltantes: {missing}&quot;)

    # Log de estadÃ­sticas bÃ¡sicas
    target = self.config.data.target_column
    class_dist = data[target].value_counts(normalize=True)
    logger.info(f&quot;DistribuciÃ³n de clases:\n{class_dist}&quot;)

    # Alertar si hay desbalance severo
    minority_pct = class_dist.min()
    if minority_pct &lt; 0.1:
        logger.warning(f&quot;âš ï¸ Desbalance severo: clase minoritaria = {minority_pct:.1%}&quot;)

    return data


def prepare_features(self, data: pd.DataFrame) -&gt; Tuple[pd.DataFrame, pd.Series]:
    &quot;&quot;&quot;Prepara features y target.

    Aplica:
    1. EliminaciÃ³n de columnas innecesarias (drop_columns)
    2. SeparaciÃ³n de X e y
    &quot;&quot;&quot;
    # Columnas a eliminar
    drop_cols = self.config.data.drop_columns + [self.config.data.target_column]
    drop_cols = [c for c in drop_cols if c in data.columns]

    X = data.drop(columns=drop_cols)
    y = data[self.config.data.target_column]

    logger.info(f&quot;Features: {X.shape[1]}, Target: {y.name}&quot;)

    return X, y
</code></pre>
<h2>9.3 Cross-Validation Profesional</h2>
<pre><code class="language-python">def cross_validate(self, X: pd.DataFrame, y: pd.Series) -&gt; Dict[str, float]:
    &quot;&quot;&quot;Ejecuta cross-validation estratificada.

    Stratified K-Fold mantiene la proporciÃ³n de clases en cada fold,
    crucial para datasets desbalanceados.
    &quot;&quot;&quot;
    from sklearn.metrics import f1_score, roc_auc_score

    cv = StratifiedKFold(
        n_splits=self.config.model.cv_folds,
        shuffle=True,
        random_state=self.random_state
    )

    f1_scores = []
    auc_scores = []

    logger.info(f&quot;Cross-validation con {self.config.model.cv_folds} folds...&quot;)

    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), 1):
        X_train_cv = X.iloc[train_idx]
        X_val_cv = X.iloc[val_idx]
        y_train_cv = y.iloc[train_idx]
        y_val_cv = y.iloc[val_idx]

        # Clonar pipeline para este fold
        from sklearn.base import clone
        fold_pipeline = clone(self.model_)

        # Entrenar en este fold
        fold_pipeline.fit(X_train_cv, y_train_cv)

        # Evaluar
        y_pred = fold_pipeline.predict(X_val_cv)
        y_proba = fold_pipeline.predict_proba(X_val_cv)[:, 1]

        f1 = f1_score(y_val_cv, y_pred)
        auc = roc_auc_score(y_val_cv, y_proba)

        f1_scores.append(f1)
        auc_scores.append(auc)

        logger.info(f&quot;  Fold {fold}: F1={f1:.4f}, AUC={auc:.4f}&quot;)

    results = {
        &quot;f1_mean&quot;: np.mean(f1_scores),
        &quot;f1_std&quot;: np.std(f1_scores),
        &quot;auc_mean&quot;: np.mean(auc_scores),
        &quot;auc_std&quot;: np.std(auc_scores),
    }

    logger.info(f&quot;CV Results: F1={results['f1_mean']:.4f} Â± {results['f1_std']:.4f}&quot;)
    logger.info(f&quot;CV Results: AUC={results['auc_mean']:.4f} Â± {results['auc_std']:.4f}&quot;)

    return results
</code></pre>
<h2>9.4 GestiÃ³n de Artefactos</h2>
<pre><code class="language-python">def save_artifacts(self, output_dir: Path) -&gt; None:
    &quot;&quot;&quot;Guarda modelo y resultados.&quot;&quot;&quot;
    import json

    # 1. Guardar modelo (pipeline completo)
    model_path = output_dir / &quot;model.joblib&quot;
    joblib.dump(self.model_, model_path)
    logger.info(f&quot;Modelo guardado: {model_path}&quot;)

    # 2. Guardar resultados como JSON
    results = {
        &quot;cv_results&quot;: self.cv_results_,
        &quot;test_results&quot;: self.test_results_,
        &quot;config&quot;: {
            &quot;model_type&quot;: self.config.model.type,
            &quot;test_size&quot;: self.config.model.test_size,
            &quot;cv_folds&quot;: self.config.model.cv_folds,
            &quot;random_state&quot;: self.random_state,
        }
    }

    results_path = output_dir / &quot;training_results.json&quot;
    with open(results_path, &quot;w&quot;) as f:
        json.dump(results, f, indent=2, default=str)
    logger.info(f&quot;Resultados guardados: {results_path}&quot;)


def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -&gt; Dict:
    &quot;&quot;&quot;EvalÃºa en test set.&quot;&quot;&quot;
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score,
        f1_score, roc_auc_score, confusion_matrix
    )

    y_pred = self.model_.predict(X_test)
    y_proba = self.model_.predict_proba(X_test)[:, 1]

    results = {
        &quot;metrics&quot;: {
            &quot;accuracy&quot;: accuracy_score(y_test, y_pred),
            &quot;precision&quot;: precision_score(y_test, y_pred),
            &quot;recall&quot;: recall_score(y_test, y_pred),
            &quot;f1_score&quot;: f1_score(y_test, y_pred),
            &quot;roc_auc&quot;: roc_auc_score(y_test, y_proba),
        },
        &quot;confusion_matrix&quot;: confusion_matrix(y_test, y_pred).tolist(),
    }

    logger.info(&quot;Test Results:&quot;)
    for metric, value in results[&quot;metrics&quot;].items():
        logger.info(f&quot;  {metric}: {value:.4f}&quot;)

    return results
</code></pre>
<h2>9.5 Logging y MÃ©tricas</h2>
<h3>Configurar Logging Profesional</h3>
<pre><code class="language-python"># src/bankchurn/__init__.py o en el mÃ³dulo principal

import logging
import sys

def setup_logging(level: str = &quot;INFO&quot;) -&gt; None:
    &quot;&quot;&quot;Configura logging estructurado.&quot;&quot;&quot;

    # Formato profesional
    fmt = &quot;%(asctime)s | %(levelname)-8s | %(name)s | %(message)s&quot;
    datefmt = &quot;%Y-%m-%d %H:%M:%S&quot;

    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format=fmt,
        datefmt=datefmt,
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler(&quot;training.log&quot;, mode=&quot;a&quot;),
        ]
    )

    # Reducir verbosidad de librerÃ­as externas
    logging.getLogger(&quot;urllib3&quot;).setLevel(logging.WARNING)
    logging.getLogger(&quot;mlflow&quot;).setLevel(logging.WARNING)


# Uso
setup_logging(&quot;INFO&quot;)
</code></pre>
<h3>IntegraciÃ³n con MLflow</h3>
<pre><code class="language-python">def _log_to_mlflow(self) -&gt; None:
    &quot;&quot;&quot;Loguea mÃ©tricas y artefactos a MLflow.&quot;&quot;&quot;
    with mlflow.start_run(run_name=&quot;training&quot;):
        # ParÃ¡metros
        mlflow.log_params({
            &quot;model_type&quot;: self.config.model.type,
            &quot;test_size&quot;: self.config.model.test_size,
            &quot;cv_folds&quot;: self.config.model.cv_folds,
            &quot;random_state&quot;: self.random_state,
        })

        # MÃ©tricas de CV
        if self.cv_results_:
            mlflow.log_metrics({
                f&quot;cv_{k}&quot;: v for k, v in self.cv_results_.items()
            })

        # MÃ©tricas de test
        if self.test_results_:
            mlflow.log_metrics({
                f&quot;test_{k}&quot;: v 
                for k, v in self.test_results_[&quot;metrics&quot;].items()
            })

        # Artefactos
        mlflow.log_artifact(&quot;artifacts/training_results.json&quot;)

        logger.info(f&quot;MLflow run logged: {mlflow.active_run().info.run_id}&quot;)
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en training</h2>
<p>En este mÃ³dulo, casi todos los problemas vienen de <strong>datos mal preparados</strong>, <strong>splits inconsistentes</strong> o <strong>logging incompleto</strong>. AquÃ­ estÃ¡n los patrones mÃ¡s frecuentes.</p>
<h3>1) <code>KeyError</code> o <code>ValueError</code> al cargar datos (columnas/config mal alineadas)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>ValueError: Columnas faltantes: {'CreditScore', 'Age', ...}</code></li>
<li><code>KeyError: 'Exited'</code> al intentar acceder al target.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara <code>self.config.data.*</code> con las columnas reales del CSV.</li>
<li>Usa <code>load_data</code> como punto Ãºnico de verdad y revisa sus logs (nÃºmero de filas/columnas, distribuciÃ³n de clases).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ajusta <code>configs/config.yaml</code> para que <code>target_column</code>, <code>numerical_features</code>, <code>categorical_features</code> reflejen <strong>exactamente</strong> el dataset.</li>
<li>MantÃ©n <code>prepare_features</code> simple: usar solo <code>drop_columns</code> + separaciÃ³n de <code>X</code> e <code>y</code>.</li>
</ul>
<h3>2) Resultados no reproducibles (semilla mal gestionada)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Cada ejecuciÃ³n de <code>ChurnTrainer.run</code> produce mÃ©tricas distintas sin razÃ³n aparente.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa la inicializaciÃ³n de <code>ChurnTrainer</code> y el uso de <code>random_state</code> en:</li>
<li><code>train_test_split</code>.</li>
<li><code>StratifiedKFold</code>.</li>
<li>Modelos base (<code>RandomForest</code>, etc.).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AsegÃºrate de que la semilla venga de un solo lugar (config) y se pase a todos los componentes relevantes.</li>
<li>Si usas utilidades como <code>common_utils.seed.set_seed</code>, llama a esa funciÃ³n al inicio de <code>run</code> o en el CLI.</li>
</ul>
<h3>3) Cross-validation engaÃ±osa (leakage entre folds o CV desalineado con test)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>MÃ©tricas de CV muy buenas, pero test set mucho peor.</li>
<li>Folds con distribuciÃ³n de clases muy desigual.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica que usas <code>StratifiedKFold</code> para clasificaciÃ³n desbalanceada.</li>
<li>AsegÃºrate de clonar el pipeline (<code>clone(self.model_)</code>) en cada fold, no reutilizar el mismo objeto.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>MantÃ©n el orden: definir pipeline completo <strong>antes</strong> de CV y clonar dentro del loop.</li>
<li>No mezcles datos de test en CV; usa <code>train_test_split</code> una sola vez, luego CV solo en <code>X_train, y_train</code>.</li>
</ul>
<h3>4) Artefactos inconsistentes (modelo y mÃ©tricas que no corresponden)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>training_results.json</code> y <code>model.joblib</code> provienen de ejecuciones distintas.</li>
<li>MLflow muestra mÃ©tricas que no coinciden con los artefactos locales.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa que <code>save_artifacts</code> se llama <strong>despuÃ©s</strong> de entrenar el modelo final y evaluar en test.</li>
<li>Comprueba timestamps y contenido de <code>artifacts/model.joblib</code> y <code>artifacts/training_results.json</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura el orden en <code>run</code>: CV â†’ <code>fit</code> final â†’ <code>evaluate</code> â†’ <code>save_artifacts</code> â†’ <code>_log_to_mlflow</code>.</li>
<li>No reutilices artefactos viejos; limpia la carpeta <code>artifacts/</code> antes de grandes cambios.</li>
</ul>
<h3>5) MLflow no registra nada o registra en el lugar equivocado</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Corres <code>ChurnTrainer.run</code> pero no ves runs nuevos en la UI de MLflow.</li>
<li>MÃ©tricas aparecen en otro experimento o en otro tracking URI.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Imprime/inspecciona <code>self.config.mlflow.tracking_uri</code> y <code>experiment_name</code>.</li>
<li>Verifica variables de entorno (<code>MLFLOW_TRACKING_URI</code>) si las usas en scripts aparte (<code>run_mlflow.py</code>).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Centraliza la configuraciÃ³n en <code>BankChurnConfig</code> y <code>_setup_mlflow</code>, evitando <code>mlflow.set_tracking_uri</code> dispersos en el cÃ³digo.</li>
<li>En <code>run_mlflow.py</code>, asegÃºrate de usar el mismo <code>tracking_uri</code> y <code>experiment</code> que usaste durante el entrenamiento.</li>
</ul>
<h3>PatrÃ³n general de debugging para training</h3>
<ol>
<li><strong>Empieza por los datos</strong>: confirma que <code>load_data</code> y <code>prepare_features</code> producen <code>X, y</code> con las formas y columnas esperadas.</li>
<li><strong>Verifica el split</strong>: revisa distribuciÃ³n de clases en <code>train/test</code> y en cada fold.</li>
<li><strong>Comprueba los artefactos</strong>: que <code>model.joblib</code> y <code>training_results.json</code> se regeneren juntos.</li>
<li><strong>Sincroniza con MLflow</strong>: compara mÃ©tricas locales con lo que ves en la UI.</li>
</ol>
<p>Con este enfoque, el entrenamiento deja de ser â€œcaja negraâ€ y se convierte en un pipeline controlado y auditable, como se espera en un rol Senior/Staff.</p>
<h2>âœ… Ejercicio: Implementar tu Trainer</h2>
<p>Crea una clase <code>PriceTrainer</code> para CarVision siguiendo el patrÃ³n:</p>
<pre><code class="language-python">class PriceTrainer:
    &quot;&quot;&quot;Tu tarea: implementar siguiendo el patrÃ³n de ChurnTrainer.&quot;&quot;&quot;

    def __init__(self, config: dict):
        # TODO: Inicializar atributos
        pass

    def run(self, input_path: Path, output_dir: Path) -&gt; dict:
        # TODO: Implementar flujo completo
        pass

    def load_data(self, path: Path) -&gt; pd.DataFrame:
        # TODO: Cargar y validar
        pass

    def build_pipeline(self) -&gt; Pipeline:
        # TODO: Construir pipeline [features -&gt; pre -&gt; model]
        pass
</code></pre>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El proyecto <strong>BankChurn</strong> implementa el patrÃ³n de training profesional completo:</p>
<h3>Clase ChurnTrainer Real</h3>
<pre><code class="language-python"># BankChurn-Predictor/src/bankchurn/trainer.py (estructura)
class ChurnTrainer:
    &quot;&quot;&quot;Entrenador profesional con CV, MLflow y artefactos.&quot;&quot;&quot;

    def __init__(self, config: BankChurnConfig):
        self.config = config
        self.model_ = None
        self.metrics_ = {}

    def run(self, input_path: Path, output_dir: Path) -&gt; dict:
        &quot;&quot;&quot;Flujo completo: load â†’ split â†’ CV â†’ train â†’ evaluate â†’ save.&quot;&quot;&quot;
        df = self.load_data(input_path)
        X, y = self.prepare_features(df)
        X_train, X_test, y_train, y_test = self.split_data(X, y)

        # Cross-validation
        cv_scores = self.cross_validate(X_train, y_train)

        # Entrenamiento final
        self.model_ = self.build_pipeline()
        self.model_.fit(X_train, y_train)

        # EvaluaciÃ³n
        self.metrics_ = self.evaluate(X_test, y_test)

        # Guardar artefactos
        self.save_artifacts(output_dir)

        return self.metrics_
</code></pre>
<h3>Flujo de Entrenamiento</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE TRAINING                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  load_data â†’ prepare_features â†’ split_data                    â”‚
â”‚      â”‚              â”‚               â”‚                         â”‚
â”‚      â–¼              â–¼               â–¼                         â”‚
â”‚  DataFrame     X, y arrays    train/test split                â”‚
â”‚                                     â”‚                         â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                    â”‚                                 â”‚        â”‚
â”‚              cross_validate                    build_pipeline â”‚
â”‚                    â”‚                                 â”‚        â”‚
â”‚              cv_scores                          Pipeline      â”‚
â”‚                    â”‚                                 â”‚        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                     â”‚                         â”‚
â”‚                              model_.fit()                     â”‚
â”‚                                     â”‚                         â”‚
â”‚                              evaluate()                       â”‚
â”‚                                     â”‚                         â”‚
â”‚                           save_artifacts()                    â”‚
â”‚                                     â”‚                         â”‚
â”‚                       pipeline.joblib + metrics.json          â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Archivos de Training por Proyecto</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Trainer</th>
<th>Config</th>
<th>Artefactos</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>src/bankchurn/trainer.py</code></td>
<td><code>configs/config.yaml</code></td>
<td><code>artifacts/</code></td>
</tr>
<tr>
<td>CarVision</td>
<td><code>main.py</code></td>
<td><code>configs/config.yaml</code></td>
<td><code>artifacts/</code></td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>src/telecomai/training.py</code></td>
<td><code>configs/config.yaml</code></td>
<td><code>artifacts/</code></td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Ejecuta Training Real</h3>
<pre><code class="language-bash"># 1. Ve a BankChurn
cd BankChurn-Predictor

# 2. Entrena el modelo
python main.py --config configs/config.yaml

# 3. Verifica artefactos generados
ls -la artifacts/
cat artifacts/training_results.json

# 4. Verifica MLflow
mlflow ui  # Abre http://localhost:5000
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Cross-Validation</strong>: Explica stratified k-fold, time series split, y cuÃ¡ndo usar cada uno.</p>
</li>
<li>
<p><strong>Hyperparameter Tuning</strong>: RandomSearch vs GridSearch vs Bayesian (Optuna).</p>
</li>
<li>
<p><strong>MÃ©tricas de negocio</strong>: Traduce mÃ©tricas tÃ©cnicas a impacto de negocio.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clases desbalanceadas</td>
<td>SMOTE, class_weight, o threshold tuning</td>
</tr>
<tr>
<td>Overfitting</td>
<td>Early stopping, regularizaciÃ³n, mÃ¡s datos</td>
</tr>
<tr>
<td>Modelo en producciÃ³n</td>
<td>Entrena con todos los datos al final</td>
</tr>
<tr>
<td>Reproducibilidad</td>
<td>Fija seeds en todos los componentes</td>
</tr>
</tbody>
</table>
<h3>Pipeline de Training Profesional</h3>
<pre><code>1. Split estratificado (train/val/test)
2. Feature engineering solo en train
3. Hyperparameter tuning con val
4. EvaluaciÃ³n final en test (una sola vez)
5. Re-entrenamiento con todos los datos
6. Versionado de modelo + mÃ©tricas
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=fSytzGwwBVw">Cross-Validation - StatQuest</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=uQc5BZw5o_g">ML Training Best Practices</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Cross-Validation</strong>: ValidaciÃ³n cruzada para evaluar modelos<br />
- <strong>class_weight</strong>: Manejo de clases desbalanceadas<br />
- <strong>Reproducibility</strong>: Resultados repetibles con random_state</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 09:<br />
- <strong>9.1</strong>: Implementar Trainer class<br />
- <strong>9.2</strong>: Garantizar reproducibilidad</p>
            </div>
        
            <!-- MÃ“DULO: 10_EXPERIMENT_TRACKING.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_10_EXPERIMENT_TRACKING" class="cover-title">EXPERIMENT TRACKING</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>10. Experiment Tracking con MLflow</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Implementar tracking de experimentos como lo hace el portafolio con <code>run_mlflow.py</code>.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  SIN MLFLOW:                           CON MLFLOW:                           â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                          â•‘
â•‘  &quot;Â¿QuÃ© hiperparÃ¡metros usÃ© hace        &quot;MLflow run abc123: RF con            â•‘
â•‘   2 semanas cuando obtuve F1=0.85?&quot;    n_estimators=200, F1=0.85&quot;            â•‘
â•‘                                                                              â•‘
â•‘  &quot;Â¿DÃ³nde guardÃ© ese modelo bueno?&quot;     &quot;Artifacts en run abc123/model.pkl&quot;   â•‘
â•‘                                                                              â•‘
â•‘  &quot;Â¿Por quÃ© este modelo es peor?&quot;       &quot;Comparar runs en UI: diff params&quot;    â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>En <strong>BankChurn-Predictor</strong> ya tienes:</li>
<li><code>scripts/run_mlflow.py</code> como script de logging posterior al entrenamiento.</li>
<li>ConfiguraciÃ³n de MLflow en <code>configs/config.yaml</code> y <code>src/bankchurn/config.py</code>.</li>
<li>El archivo <code>docker-compose.mlflow.yml</code> en la raÃ­z del repo levanta un servidor MLflow<br />
  real que puedes usar para practicar este mÃ³dulo.</li>
<li>El mismo patrÃ³n de logging puedes aplicarlo a <strong>CarVision</strong> y <strong>TelecomAI</strong>, usando<br />
  sus <code>artifacts/</code> y modelos entrenados como fuente de mÃ©tricas y artifacts.</li>
</ul>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#101-conceptos-de-mlflow">Conceptos de MLflow</a></li>
<li><a href="#102-setup-y-configuraciÃ³n">Setup y ConfiguraciÃ³n</a></li>
<li><a href="#103-logging-de-experimentos">Logging de Experimentos</a></li>
<li><a href="#104-model-registry">Model Registry</a></li>
<li><a href="#105-cÃ³digo-real-del-portafolio">CÃ³digo Real del Portafolio</a></li>
</ol>
<h2>10.1 Conceptos de MLflow</h2>
<h3>Los 4 Componentes</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MLFLOW COMPONENTS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. TRACKING                    2. PROJECTS                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ Log params, metrics          â€¢ Empaquetar cÃ³digo                         â”‚
â”‚  â€¢ Guardar artifacts            â€¢ MLproject file                            â”‚
â”‚  â€¢ Comparar runs                â€¢ Reproducibilidad                          â”‚
â”‚                                                                             â”‚
â”‚  3. MODELS                      4. REGISTRY                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  â€¢ Formato estÃ¡ndar             â€¢ Versionado de modelos                     â”‚
â”‚  â€¢ Flavors (sklearn, pytorch)   â€¢ Staging â†’ Production                      â”‚
â”‚  â€¢ Serving                      â€¢ Aprobaciones                              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

EN ESTE PORTAFOLIO USAMOS: Tracking + Registry
</code></pre>
<h3>JerarquÃ­a de MLflow</h3>
<pre><code>MLflow Server
â””â”€â”€ Experiment: &quot;BankChurn&quot;
    â”œâ”€â”€ Run: abc123 (2024-01-15)
    â”‚   â”œâ”€â”€ Parameters: {n_estimators: 100, max_depth: 10}
    â”‚   â”œâ”€â”€ Metrics: {f1: 0.60, auc: 0.85}
    â”‚   â””â”€â”€ Artifacts: [model.pkl, config.yaml]
    â”‚
    â”œâ”€â”€ Run: def456 (2024-01-16)
    â”‚   â”œâ”€â”€ Parameters: {n_estimators: 200, max_depth: 15}
    â”‚   â”œâ”€â”€ Metrics: {f1: 0.62, auc: 0.86}
    â”‚   â””â”€â”€ Artifacts: [model.pkl, config.yaml]
    â”‚
    â””â”€â”€ Run: ghi789 (2024-01-17) â† MEJOR
        â”œâ”€â”€ Parameters: {n_estimators: 200, max_depth: 10}
        â”œâ”€â”€ Metrics: {f1: 0.65, auc: 0.88}
        â””â”€â”€ Artifacts: [model.pkl, config.yaml]
</code></pre>
<h2>10.2 Setup y ConfiguraciÃ³n</h2>
<h3>OpciÃ³n 1: Local (File Store)</h3>
<pre><code class="language-python"># MÃ¡s simple, para desarrollo local
import mlflow

mlflow.set_tracking_uri(&quot;file:./mlruns&quot;)  # Guarda en carpeta local
mlflow.set_experiment(&quot;my-experiment&quot;)
</code></pre>
<h3>OpciÃ³n 2: Servidor MLflow (ProducciÃ³n)</h3>
<pre><code class="language-yaml"># docker-compose.mlflow.yml del portafolio
services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - mlflow-artifacts:/mlflow
    command: &gt;
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
</code></pre>
<pre><code class="language-python"># Conectar al servidor
import mlflow

mlflow.set_tracking_uri(&quot;http://localhost:5000&quot;)
mlflow.set_experiment(&quot;BankChurn&quot;)
</code></pre>
<h3>ConfiguraciÃ³n en el Portafolio</h3>
<pre><code class="language-yaml"># configs/config.yaml (BankChurn)
mlflow:
  tracking_uri: &quot;file:./mlruns&quot;      # Local para desarrollo
  experiment_name: &quot;bankchurn&quot;
  enabled: true
</code></pre>
<pre><code class="language-python"># src/bankchurn/config.py
class MLflowConfig(BaseModel):
    tracking_uri: str = &quot;file:./mlruns&quot;
    experiment_name: str = &quot;bankchurn&quot;
    enabled: bool = True
</code></pre>
<h2>10.3 Logging de Experimentos</h2>
<h3>API BÃ¡sica</h3>
<pre><code class="language-python">import mlflow

# Iniciar un run
with mlflow.start_run(run_name=&quot;experiment-1&quot;):

    # 1. LOG PARAMETERS (hiperparÃ¡metros, config)
    mlflow.log_param(&quot;n_estimators&quot;, 200)
    mlflow.log_param(&quot;max_depth&quot;, 10)
    mlflow.log_params({  # MÃºltiples a la vez
        &quot;learning_rate&quot;: 0.1,
        &quot;model_type&quot;: &quot;random_forest&quot;
    })

    # 2. LOG METRICS (resultados)
    mlflow.log_metric(&quot;f1_score&quot;, 0.65)
    mlflow.log_metric(&quot;auc_roc&quot;, 0.88)
    mlflow.log_metrics({  # MÃºltiples a la vez
        &quot;precision&quot;: 0.70,
        &quot;recall&quot;: 0.61
    })

    # 3. LOG ARTIFACTS (archivos)
    mlflow.log_artifact(&quot;configs/config.yaml&quot;)
    mlflow.log_artifact(&quot;artifacts/training_results.json&quot;)

    # 4. LOG MODEL (modelo serializado con metadata)
    mlflow.sklearn.log_model(
        pipeline,
        artifact_path=&quot;model&quot;,
        registered_model_name=&quot;BankChurnClassifier&quot;
    )
</code></pre>
<h3>MÃ©tricas por Ã‰poca/Paso</h3>
<pre><code class="language-python"># Para modelos que entrenan por Ã©pocas
for epoch in range(100):
    train_loss = train_one_epoch()
    val_loss = validate()

    mlflow.log_metrics({
        &quot;train_loss&quot;: train_loss,
        &quot;val_loss&quot;: val_loss
    }, step=epoch)  # â† step permite graficar evoluciÃ³n
</code></pre>
<h2>10.4 Model Registry</h2>
<h3>Registrar un Modelo</h3>
<pre><code class="language-python"># Durante el run
mlflow.sklearn.log_model(
    pipeline,
    artifact_path=&quot;model&quot;,
    registered_model_name=&quot;BankChurnClassifier&quot;  # â† Registra automÃ¡ticamente
)

# O despuÃ©s del run
mlflow.register_model(
    model_uri=f&quot;runs:/{run_id}/model&quot;,
    name=&quot;BankChurnClassifier&quot;
)
</code></pre>
<h3>Transiciones de Estado</h3>
<pre><code class="language-python">from mlflow.tracking import MlflowClient

client = MlflowClient()

# Promover a Staging
client.transition_model_version_stage(
    name=&quot;BankChurnClassifier&quot;,
    version=1,
    stage=&quot;Staging&quot;
)

# Promover a Production (despuÃ©s de validaciÃ³n)
client.transition_model_version_stage(
    name=&quot;BankChurnClassifier&quot;,
    version=1,
    stage=&quot;Production&quot;
)
</code></pre>
<h3>Cargar Modelo desde Registry</h3>
<pre><code class="language-python"># Cargar versiÃ³n especÃ­fica
model = mlflow.sklearn.load_model(&quot;models:/BankChurnClassifier/1&quot;)

# Cargar stage especÃ­fico
model = mlflow.sklearn.load_model(&quot;models:/BankChurnClassifier/Production&quot;)

# Cargar Ãºltimo modelo (latest)
model = mlflow.sklearn.load_model(&quot;models:/BankChurnClassifier/latest&quot;)
</code></pre>
<h2>10.5 CÃ³digo Real del Portafolio</h2>
<h3>scripts/run_mlflow.py (BankChurn)</h3>
<pre><code class="language-python">#!/usr/bin/env python3
&quot;&quot;&quot;Log training results to MLflow.

Este script se ejecuta DESPUÃ‰S del entrenamiento para:
1. Leer resultados de artifacts/training_results.json
2. Calcular mÃ©tricas de negocio (revenue saved, etc.)
3. Loguear todo a MLflow
4. Opcionalmente registrar el modelo

Uso:
    python scripts/run_mlflow.py

Environment Variables:
    MLFLOW_TRACKING_URI: URI del servidor MLflow
    MLFLOW_EXPERIMENT_NAME: Nombre del experimento
&quot;&quot;&quot;

from __future__ import annotations

import json
import os
from pathlib import Path

import joblib

try:
    import mlflow
    import mlflow.sklearn
    from mlflow.tracking import MlflowClient
except ImportError:
    mlflow = None

from sklearn.pipeline import Pipeline


def main() -&gt; None:
    # ConfiguraciÃ³n desde environment
    tracking_uri = os.getenv(&quot;MLFLOW_TRACKING_URI&quot;, &quot;file:./mlruns&quot;)
    experiment = os.getenv(&quot;MLFLOW_EXPERIMENT_NAME&quot;, &quot;BankChurn&quot;)

    # Cargar resultados del entrenamiento
    results_path = Path(&quot;artifacts/training_results.json&quot;)
    if not results_path.exists():
        print(f&quot;No se encontrÃ³ {results_path}. Ejecuta training primero.&quot;)
        return

    data = json.loads(results_path.read_text())

    # Extraer mÃ©tricas
    cv = data.get(&quot;cv_results&quot;, {})
    test = data.get(&quot;test_results&quot;, {}).get(&quot;metrics&quot;, {})

    metrics = {}
    for k, v in cv.items():
        if isinstance(v, (int, float)):
            metrics[f&quot;cv_{k}&quot;] = float(v)
    for k, v in test.items():
        if isinstance(v, (int, float)):
            metrics[f&quot;test_{k}&quot;] = float(v)

    # Calcular mÃ©tricas de negocio
    cm = data.get(&quot;test_results&quot;, {}).get(&quot;confusion_matrix&quot;)
    if cm and len(cm) == 2:
        tn, fp = cm[0]
        fn, tp = cm[1]

        # ParÃ¡metros de negocio (configurables)
        clv = float(os.getenv(&quot;BC_CLV_USD&quot;, &quot;2300&quot;))  # Customer Lifetime Value
        retention_rate = float(os.getenv(&quot;BC_RETENTION_RATE&quot;, &quot;0.3&quot;))

        saved_customers = tp * retention_rate
        saved_revenue = saved_customers * clv

        metrics.update({
            &quot;biz_detected_churners&quot;: float(tp),
            &quot;biz_saved_customers&quot;: saved_customers,
            &quot;biz_saved_revenue_usd&quot;: saved_revenue,
            &quot;biz_false_positives&quot;: float(fp),
            &quot;biz_missed_churners&quot;: float(fn),
        })

    if mlflow is None:
        print(&quot;MLflow no instalado. MÃ©tricas:&quot;, metrics)
        return

    # Configurar MLflow
    mlflow.set_tracking_uri(tracking_uri)
    mlflow.set_experiment(experiment)

    # Crear run
    with mlflow.start_run(run_name=&quot;demo-logging&quot;):
        # Log parÃ¡metros
        mlflow.log_params({
            &quot;run_type&quot;: &quot;demo&quot;,
            &quot;source&quot;: &quot;run_mlflow.py&quot;
        })

        # Log mÃ©tricas
        mlflow.log_metrics(metrics)

        # Log artifacts
        for artifact in [
            Path(&quot;artifacts/training_results.json&quot;),
            Path(&quot;configs/config.yaml&quot;),
        ]:
            if artifact.exists():
                try:
                    mlflow.log_artifact(str(artifact))
                except PermissionError:
                    print(f&quot;Skipping {artifact}: permission denied&quot;)

        # Log modelo si existe
        model_path = Path(&quot;models/model_v1.0.0.pkl&quot;)
        if model_path.exists():
            try:
                obj = joblib.load(model_path)
                if isinstance(obj, dict) and &quot;pipeline&quot; in obj:
                    pipe = obj[&quot;pipeline&quot;]
                elif isinstance(obj, Pipeline):
                    pipe = obj
                else:
                    pipe = None

                if pipe:
                    mlflow.sklearn.log_model(
                        pipe,
                        artifact_path=&quot;model&quot;,
                        registered_model_name=&quot;BankChurnClassifier&quot;
                    )
            except Exception as e:
                print(f&quot;Model logging skipped: {e}&quot;)

        print(f&quot;âœ… MLflow run logged to {tracking_uri}&quot;)
        print(f&quot;   Experiment: {experiment}&quot;)
        print(f&quot;   Metrics: {len(metrics)} logged&quot;)


if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h3>Makefile Integration</h3>
<pre><code class="language-makefile"># Makefile
.PHONY: mlflow-demo mlflow-ui

mlflow-demo:
@echo &quot;Logging to MLflow...&quot;
MLFLOW_TRACKING_URI=file:./mlruns python scripts/run_mlflow.py

mlflow-ui:
@echo &quot;Starting MLflow UI at http://localhost:5000&quot;
mlflow ui --host 0.0.0.0 --port 5000
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en MLflow</h2>
<p>MLflow aÃ±ade una capa extra (servidor, rutas, artefactos), asÃ­ que muchos errores son de <strong>configuraciÃ³n</strong> mÃ¡s que de cÃ³digo puro.</p>
<h3>1) Runs que no aparecen en la UI (tracking_uri/experimento incorrectos)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Ejecutas training o <code>run_mlflow.py</code> y no ves nada nuevo en <code>http://localhost:5000</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Imprime <code>mlflow.get_tracking_uri()</code> y el experimento actual (<code>mlflow.get_experiment_by_name(...)</code>).</li>
<li>Verifica si estÃ¡s usando <code>file:./mlruns</code> mientras tienes un servidor en Docker (<code>http://localhost:5000</code>).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Define claramente en config:</li>
<li>Desarrollo local â†’ <code>tracking_uri: "file:./mlruns"</code>.</li>
<li>Demo/stack Docker â†’ <code>tracking_uri: "http://mlflow:5000"</code> o <code>http://localhost:5000</code>.</li>
<li>AsegÃºrate de que tanto <code>ChurnTrainer</code> como <code>scripts/run_mlflow.py</code> lean del mismo origen (YAML/env vars).</li>
</ul>
<h3>2) Errores al registrar modelos (<code>MlflowException</code>, permisos, backend)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Al llamar <code>mlflow.sklearn.log_model(..., registered_model_name=...)</code> obtienes errores sobre base de datos o registry no configurado.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Si usas solo <code>file:./mlruns</code> sin servidor, el <strong>registry completo</strong> no estÃ¡ disponible.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Para desarrollo ligero, limita el uso de registry (puedes usar solo tracking + artifacts).</li>
<li>Para un registry completo, usa el <code>docker-compose.mlflow.yml</code> del portafolio con backend SQLite/postgres y apunta <code>MLFLOW_TRACKING_URI</code> al servidor.</li>
</ul>
<h3>3) Artifacts que no se encuentran o no se suben</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores tipo <code>FileNotFoundError</code> al hacer <code>mlflow.log_artifact</code>.</li>
<li>No ves <code>training_results.json</code> ni <code>config.yaml</code> en la pestaÃ±a de artifacts.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa rutas relativas en <code>run_mlflow.py</code> y asegÃºrate de que ejecutas el script desde la raÃ­z del proyecto.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa rutas consistentes (por ejemplo <code>artifacts/training_results.json</code>) y verifica que el archivo exista antes de loguearlo.</li>
<li>Si corres dentro de Docker, revisa que el volumen monte correctamente <code>artifacts/</code> y <code>configs/</code>.</li>
</ul>
<h3>4) Problemas con MLflow en Docker (puertos, hostnames, permisos)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>ConnectionError</code> al intentar conectar a <code>http://localhost:5000</code> desde un contenedor.</li>
<li>Logs que muestran errores de permisos en <code>/mlflow</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Examina <code>docker-compose.mlflow.yml</code> y las variables de entorno de tus servicios.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Dentro de un contenedor, usa el hostname del servicio (<code>http://mlflow:5000</code>) en lugar de <code>localhost</code>.</li>
<li>AsegÃºrate de que el volumen <code>mlflow-artifacts</code> tenga permisos de escritura correctos (usuario del contenedor).</li>
</ul>
<h3>PatrÃ³n general de debugging en MLflow</h3>
<ol>
<li><strong>Comprueba tracking_uri y experimento</strong> antes de iniciar el run.</li>
<li><strong>Valida artifacts y modelos</strong>: que los paths existen y se cargan correctamente.</li>
<li><strong>Reproduce localmente con file store</strong> (<code>file:./mlruns</code>) antes de ir a servidor Docker.</li>
<li><strong>Verifica desde la UI</strong> que params, metrics y artifacts coincidan con lo que esperas de tu cÃ³digo.</li>
</ol>
<p>Con este patrÃ³n, MLflow pasa de ser â€œcaja negraâ€ a una herramienta confiable para explicar, comparar y promover modelos.</p>
<h2>âœ… Ejercicio: Integrar MLflow en TelecomAI</h2>
<ol>
<li>Crea <code>scripts/run_mlflow.py</code> para TelecomAI</li>
<li>Log las mÃ©tricas: accuracy, f1, precision, recall, roc_auc</li>
<li>Calcula mÃ©tricas de negocio (customers retained, revenue saved)</li>
<li>Registra el modelo como "TelecomPlanClassifier"</li>
</ol>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>MLflow estÃ¡ integrado en los 3 proyectos del portafolio:</p>
<h3>ConfiguraciÃ³n MLflow en BankChurn</h3>
<pre><code class="language-python"># BankChurn-Predictor/src/bankchurn/config.py
class MLflowConfig(BaseModel):
    &quot;&quot;&quot;MLflow tracking configuration.&quot;&quot;&quot;
    tracking_uri: str = &quot;file:./mlruns&quot;  # Local por defecto
    experiment_name: str = &quot;bankchurn&quot;
    enabled: bool = True
</code></pre>
<h3>IntegraciÃ³n en Trainer</h3>
<pre><code class="language-python"># BankChurn-Predictor/src/bankchurn/trainer.py (extracto)
def _log_to_mlflow(self):
    &quot;&quot;&quot;Log experimento a MLflow.&quot;&quot;&quot;
    if not self.config.mlflow.enabled:
        return

    mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)
    mlflow.set_experiment(self.config.mlflow.experiment_name)

    with mlflow.start_run():
        # ParÃ¡metros
        mlflow.log_params({
            &quot;model_type&quot;: self.config.model.type,
            &quot;test_size&quot;: self.config.model.test_size,
            &quot;cv_folds&quot;: self.config.model.cv_folds,
        })

        # MÃ©tricas
        mlflow.log_metrics(self.metrics_)

        # Modelo
        mlflow.sklearn.log_model(self.model_, &quot;model&quot;)
</code></pre>
<h3>Estructura de mlruns/</h3>
<pre><code>BankChurn-Predictor/
â””â”€â”€ mlruns/
    â”œâ”€â”€ 0/                    # Default experiment
    â””â”€â”€ 123456789/            # bankchurn experiment
        â””â”€â”€ abc123def456/     # Run ID
            â”œâ”€â”€ artifacts/
            â”‚   â””â”€â”€ model/
            â”œâ”€â”€ metrics/
            â”‚   â”œâ”€â”€ accuracy
            â”‚   â”œâ”€â”€ f1_score
            â”‚   â””â”€â”€ roc_auc
            â”œâ”€â”€ params/
            â”‚   â”œâ”€â”€ model_type
            â”‚   â””â”€â”€ cv_folds
            â””â”€â”€ meta.yaml
</code></pre>
<h3>MLflow por Proyecto</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Tracking URI</th>
<th>Experiment</th>
<th>MÃ©tricas Principales</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>file:./mlruns</code></td>
<td><code>bankchurn</code></td>
<td>accuracy, f1, roc_auc</td>
</tr>
<tr>
<td>CarVision</td>
<td><code>file:./mlruns</code></td>
<td><code>carvision</code></td>
<td>mae, rmse, r2</td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>file:./mlruns</code></td>
<td><code>telecomai</code></td>
<td>accuracy, f1_weighted</td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Explora MLflow Real</h3>
<pre><code class="language-bash"># 1. Ve a BankChurn
cd BankChurn-Predictor

# 2. Entrena con MLflow habilitado
python main.py --config configs/config.yaml

# 3. Inicia la UI de MLflow
mlflow ui --backend-store-uri file:./mlruns

# 4. Abre en navegador
# http://localhost:5000

# 5. Explora:
# - Compara runs
# - Ve artifacts
# - Registra modelo en Model Registry
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>MLflow vs W&amp;B vs Neptune</strong>: Conoce trade-offs (MLflow open-source, W&amp;B mejor UI, Neptune escalabilidad).</p>
</li>
<li>
<p><strong>Model Registry</strong>: Explica stages (Staging â†’ Production â†’ Archived).</p>
</li>
<li>
<p><strong>Reproducibilidad</strong>: CÃ³mo reconstruir cualquier experimento desde el tracking.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Equipo distribuido</td>
<td>Usa servidor MLflow centralizado</td>
</tr>
<tr>
<td>Muchos experimentos</td>
<td>Organiza con tags y naming conventions</td>
</tr>
<tr>
<td>Modelos grandes</td>
<td>Usa artifact storage externo (S3, GCS)</td>
</tr>
<tr>
<td>ComparaciÃ³n</td>
<td>Siempre registra baseline para comparar</td>
</tr>
</tbody>
</table>
<h3>QuÃ© Trackear Siempre</h3>
<ul>
<li><strong>Params</strong>: HiperparÃ¡metros, versiones de datos</li>
<li><strong>Metrics</strong>: Train/val/test, mÃ©tricas de negocio</li>
<li><strong>Artifacts</strong>: Modelo, configs, plots, requirements.txt</li>
<li><strong>Tags</strong>: Git commit, autor, dataset version</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=qdcHHrsXA48">MLflow Tutorial - Krish Naik</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=MHcqGxA6JPs">MLflow Complete Course</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://mlflow.org/docs/latest/tracking.html">MLflow Tracking</a><br />
- <a href="https://mlflow.org/docs/latest/model-registry.html">MLflow Model Registry</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>MLflow</strong>: Plataforma de experiment tracking<br />
- <strong>Model Registry</strong>: Registro de versiones de modelos<br />
- <strong>Artifact</strong>: Archivo asociado a un experimento</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 10:<br />
- <strong>10.1</strong>: MLflow bÃ¡sico (params, metrics, model)<br />
- <strong>10.2</strong>: Comparar mÃºltiples experimentos</p>
            </div>
        
            <!-- MÃ“DULO: 11_TESTING_ML.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_11_TESTING_ML" class="cover-title">TESTING ML</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>11. Testing para Machine Learning</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Dominar el testing en proyectos ML para alcanzar <strong>80%+ de coverage</strong> sin tests frÃ¡giles ni falsos positivos.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  ğŸš¨ LA REALIDAD DEL ML SIN TESTS:                                            â•‘
â•‘                                                                              â•‘
â•‘  &quot;El modelo funcionaba ayer, hoy da predicciones random&quot;                     â•‘
â•‘  &quot;CambiÃ© una lÃ­nea y rompÃ­ todo el pipeline&quot;                                 â•‘
â•‘  &quot;No sÃ© si el bug estÃ¡ en los datos, el preprocesamiento, o el modelo&quot;       â•‘
â•‘                                                                              â•‘
â•‘  ğŸ›¡ï¸ LA REALIDAD CON TESTS:                                                   â•‘
â•‘                                                                              â•‘
â•‘  &quot;CI me avisÃ³ que rompÃ­ algo antes de hacer merge&quot;                           â•‘
â•‘  &quot;SÃ© exactamente quÃ© componente fallÃ³&quot;                                       â•‘
â•‘  &quot;Puedo refactorizar con confianza&quot;                                          â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#111-la-pirÃ¡mide-de-testing-en-ml">La PirÃ¡mide de Testing en ML</a></li>
<li><a href="#112-fixtures-y-conftestpy">Fixtures y conftest.py</a></li>
<li><a href="#113-unit-tests-funciones-individuales">Unit Tests: Funciones Individuales</a></li>
<li><a href="#114-data-tests-validaciÃ³n-de-datos">Data Tests: ValidaciÃ³n de Datos</a></li>
<li><a href="#115-model-tests-comportamiento-del-modelo">Model Tests: Comportamiento del Modelo</a></li>
<li><a href="#116-integration-tests-pipeline-completo">Integration Tests: Pipeline Completo</a></li>
<li><a href="#117-alcanzar-80-coverage">Alcanzar 80% Coverage</a></li>
</ol>
<h3>ğŸ§© CÃ³mo se aplica en este portafolio</h3>
<ul>
<li>Cada uno de los tres proyectos tiene una carpeta <code>tests/</code> rica en ejemplos reales:</li>
<li><strong>BankChurn-Predictor</strong>: tests de pipeline de entrenamiento y mÃ©tricas.</li>
<li><strong>CarVision-Market-Intelligence</strong>: tests de features, datos y modelo (incluidos en este mÃ³dulo).</li>
<li><strong>TelecomAI-Customer-Intelligence</strong>: tests centrados en clasificaciÃ³n y contratos de datos.</li>
<li>El workflow <code>ci-mlops.yml</code> ejecuta estos tests en matrix (3 proyectos Ã— 2 versiones de Python)<br />
  y aplica thresholds de coverage (79â€“80%). Este mÃ³dulo te da el modelo mental para entender<br />
  y extender esos tests sin romper la pirÃ¡mide de testing.</li>
</ul>
<h2>11.1 La PirÃ¡mide de Testing en ML</h2>
<h3>AnalogÃ­a: InspecciÃ³n de un AviÃ³n</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  âœˆï¸ ANTES DE CADA VUELO, SE INSPECCIONA:                                  â•‘
â•‘                                                                           â•‘
â•‘  NIVEL 1 - Componentes individuales (Unit Tests):                         â•‘
â•‘  â€¢ Cada tornillo estÃ¡ apretado                                            â•‘
â•‘  â€¢ Cada cable estÃ¡ conectado                                              â•‘
â•‘  â€¢ Cada sensor funciona                                                   â•‘
â•‘                                                                           â•‘
â•‘  NIVEL 2 - Sistemas (Integration Tests):                                  â•‘
â•‘  â€¢ El motor arranca correctamente                                         â•‘
â•‘  â€¢ Los flaps responden a los controles                                    â•‘
â•‘  â€¢ El sistema hidrÃ¡ulico mantiene presiÃ³n                                 â•‘
â•‘                                                                           â•‘
â•‘  NIVEL 3 - Vuelo de prueba (E2E Tests):                                   â•‘
â•‘  â€¢ El aviÃ³n despega, vuela, y aterriza                                    â•‘
â•‘  â€¢ Todo funciona junto bajo condiciones reales                            â•‘
â•‘                                                                           â•‘
â•‘  EN ML ES IGUAL: Testeas componentes â†’ sistemas â†’ pipeline completo       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>La PirÃ¡mide EspecÃ­fica para ML</h3>
<pre><code>                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    E2E Tests    â”‚ â† 5-10% de tests
                        â”‚   (API real)    â”‚   Lentos, costosos
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   test_api_e2e.py
                                 â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Integration Tests   â”‚ â† 15-20% de tests
                     â”‚  (pipeline.fit())     â”‚   Verifican interacciÃ³n
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   test_training.py
                                 â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚           Model Tests               â”‚ â† 20-25% de tests
              â”‚  (predicciones, mÃ©tricas, shapes)   â”‚   EspecÃ­ficos de ML
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   test_model_logic.py
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 Data Tests                      â”‚ â† 20-25% de tests
        â”‚    (schema, rangos, distribuciones, NaN)        â”‚   Validan datos
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   test_data.py
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           Unit Tests                                    â”‚ â† 30-40% de tests
â”‚              (funciones individuales, transformers)                     â”‚   RÃ¡pidos, muchos
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   test_features.py
</code></pre>
<h3>Coverage del Portafolio Real</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th style="text-align: center;">Coverage</th>
<th style="text-align: center;">Tests</th>
<th>Tipo Principal</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BankChurn</strong></td>
<td style="text-align: center;">79.5%</td>
<td style="text-align: center;">45+</td>
<td>Unit + Integration</td>
</tr>
<tr>
<td><strong>CarVision</strong></td>
<td style="text-align: center;">97%</td>
<td style="text-align: center;">50+</td>
<td>Unit + Data + Model</td>
</tr>
<tr>
<td><strong>TelecomAI</strong></td>
<td style="text-align: center;">97%</td>
<td style="text-align: center;">35+</td>
<td>Unit + Integration</td>
</tr>
</tbody>
</table>
<h2>11.2 Fixtures y conftest.py</h2>
<h3>Â¿QuÃ© es una Fixture?</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§ª FIXTURE = Datos o recursos preparados para tests                      â•‘
â•‘                                                                           â•‘
â•‘  AnalogÃ­a del laboratorio:                                                â•‘
â•‘  â€¢ Antes de cada experimento, preparas tus instrumentos                   â•‘
â•‘  â€¢ Los instrumentos son los mismos para varios experimentos               â•‘
â•‘  â€¢ No los preparas desde cero cada vez                                    â•‘
â•‘                                                                           â•‘
â•‘  En pytest:                                                               â•‘
â•‘  â€¢ Fixture prepara datos/modelos/configs                                  â•‘
â•‘  â€¢ Se reutiliza en mÃºltiples tests                                        â•‘
â•‘  â€¢ Se limpia automÃ¡ticamente despuÃ©s                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>conftest.py del Portafolio (CarVision)</h3>
<pre><code class="language-python"># tests/conftest.py - CÃ³digo REAL del portafolio

import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import yaml

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES DE DATOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@pytest.fixture
def sample_data() -&gt; pd.DataFrame:
    &quot;&quot;&quot;DataFrame pequeÃ±o para tests rÃ¡pidos.

    Este fixture se usa en MUCHOS tests:
    - test_data.py: Verificar carga y limpieza
    - test_features.py: Verificar feature engineering
    - test_model.py: Verificar predicciones
    &quot;&quot;&quot;
    return pd.DataFrame({
        &quot;price&quot;: [15000, 25000, 35000, 45000, 55000],
        &quot;model_year&quot;: [2015, 2018, 2020, 2019, 2021],
        &quot;odometer&quot;: [80000, 45000, 20000, 30000, 10000],
        &quot;model&quot;: [&quot;ford f-150&quot;, &quot;toyota camry&quot;, &quot;honda civic&quot;, 
                  &quot;chevrolet silverado&quot;, &quot;ford mustang&quot;],
        &quot;fuel&quot;: [&quot;gas&quot;, &quot;gas&quot;, &quot;gas&quot;, &quot;diesel&quot;, &quot;gas&quot;],
        &quot;transmission&quot;: [&quot;automatic&quot;, &quot;automatic&quot;, &quot;manual&quot;, 
                        &quot;automatic&quot;, &quot;manual&quot;],
        &quot;condition&quot;: [&quot;good&quot;, &quot;excellent&quot;, &quot;like new&quot;, 
                     &quot;good&quot;, &quot;excellent&quot;],
    })


@pytest.fixture
def sample_data_with_nulls() -&gt; pd.DataFrame:
    &quot;&quot;&quot;DataFrame con valores faltantes para probar imputaciÃ³n.&quot;&quot;&quot;
    return pd.DataFrame({
        &quot;price&quot;: [15000, None, 35000, 45000, None],
        &quot;model_year&quot;: [2015, 2018, None, 2019, 2021],
        &quot;odometer&quot;: [80000, None, 20000, 30000, 10000],
        &quot;model&quot;: [&quot;ford f-150&quot;, None, &quot;honda civic&quot;, None, &quot;ford mustang&quot;],
        &quot;fuel&quot;: [&quot;gas&quot;, &quot;gas&quot;, None, &quot;diesel&quot;, &quot;gas&quot;],
        &quot;transmission&quot;: [None, &quot;automatic&quot;, &quot;manual&quot;, &quot;automatic&quot;, None],
    })


@pytest.fixture
def large_sample_data() -&gt; pd.DataFrame:
    &quot;&quot;&quot;DataFrame mÃ¡s grande para tests de performance.&quot;&quot;&quot;
    np.random.seed(42)
    n = 1000
    return pd.DataFrame({
        &quot;price&quot;: np.random.uniform(5000, 80000, n),
        &quot;model_year&quot;: np.random.randint(2010, 2024, n),
        &quot;odometer&quot;: np.random.uniform(0, 200000, n),
        &quot;model&quot;: np.random.choice([&quot;ford f-150&quot;, &quot;toyota camry&quot;, &quot;honda civic&quot;], n),
        &quot;fuel&quot;: np.random.choice([&quot;gas&quot;, &quot;diesel&quot;, &quot;electric&quot;], n),
        &quot;transmission&quot;: np.random.choice([&quot;automatic&quot;, &quot;manual&quot;], n),
    })


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES DE CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@pytest.fixture
def sample_config() -&gt; dict:
    &quot;&quot;&quot;ConfiguraciÃ³n mÃ­nima para tests.&quot;&quot;&quot;
    return {
        &quot;seed&quot;: 42,
        &quot;dataset_year&quot;: 2024,
        &quot;paths&quot;: {
            &quot;data_path&quot;: &quot;data/raw/vehicles_us.csv&quot;,
            &quot;artifacts_dir&quot;: &quot;artifacts&quot;,
            &quot;model_path&quot;: &quot;artifacts/model.joblib&quot;,
        },
        &quot;preprocessing&quot;: {
            &quot;numeric_features&quot;: [&quot;odometer&quot;, &quot;vehicle_age&quot;],
            &quot;categorical_features&quot;: [&quot;fuel&quot;, &quot;transmission&quot;, &quot;brand&quot;],
            &quot;drop_columns&quot;: [&quot;price_per_mile&quot;, &quot;price_category&quot;],
            &quot;filters&quot;: {
                &quot;price_min&quot;: 1000,
                &quot;price_max&quot;: 100000,
            }
        },
        &quot;training&quot;: {
            &quot;target&quot;: &quot;price&quot;,
            &quot;test_size&quot;: 0.2,
            &quot;val_size&quot;: 0.1,
            &quot;shuffle&quot;: True,
            &quot;model&quot;: &quot;random_forest&quot;,
            &quot;random_forest_params&quot;: {
                &quot;n_estimators&quot;: 10,  # Pocos para tests rÃ¡pidos
                &quot;max_depth&quot;: 5,
                &quot;random_state&quot;: 42,
            }
        }
    }


@pytest.fixture
def temp_config_file(sample_config, tmp_path) -&gt; Path:
    &quot;&quot;&quot;Crea archivo config temporal para tests de carga.&quot;&quot;&quot;
    config_path = tmp_path / &quot;config.yaml&quot;
    with open(config_path, &quot;w&quot;) as f:
        yaml.dump(sample_config, f)
    return config_path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES DE MODELO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@pytest.fixture
def fitted_pipeline(sample_data, sample_config):
    &quot;&quot;&quot;Pipeline entrenado para tests de predicciÃ³n.&quot;&quot;&quot;
    from src.carvision.training import build_pipeline
    from src.carvision.features import FeatureEngineer

    # Preparar datos
    fe = FeatureEngineer(current_year=2024)
    df = fe.transform(sample_data)

    X = df.drop(columns=[&quot;price&quot;])
    y = df[&quot;price&quot;]

    # Construir y entrenar pipeline
    # Nota: Usamos config simplificada para velocidad
    pipeline = build_pipeline(sample_config)
    pipeline.fit(X, y)

    return pipeline


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FIXTURES ESPECIALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@pytest.fixture
def temp_artifacts_dir(tmp_path) -&gt; Path:
    &quot;&quot;&quot;Directorio temporal para artefactos.&quot;&quot;&quot;
    artifacts = tmp_path / &quot;artifacts&quot;
    artifacts.mkdir()
    return artifacts


@pytest.fixture(scope=&quot;module&quot;)
def slow_fixture():
    &quot;&quot;&quot;Fixture que tarda en crearse - se reutiliza en todo el mÃ³dulo.

    scope=&quot;module&quot; significa que se crea UNA vez por archivo de test,
    no una vez por cada test.
    &quot;&quot;&quot;
    import time
    time.sleep(0.1)  # Simula operaciÃ³n lenta
    return {&quot;expensive_resource&quot;: True}
</code></pre>
<h3>Uso de Fixtures en Tests</h3>
<pre><code class="language-python"># tests/test_features.py

def test_feature_engineer_creates_vehicle_age(sample_data):
    &quot;&quot;&quot;Test que usa la fixture sample_data.&quot;&quot;&quot;
    from src.carvision.features import FeatureEngineer

    fe = FeatureEngineer(current_year=2024)
    result = fe.transform(sample_data)

    assert &quot;vehicle_age&quot; in result.columns
    assert result[&quot;vehicle_age&quot;].iloc[0] == 2024 - 2015  # 9 aÃ±os


def test_pipeline_predicts_positive_prices(fitted_pipeline, sample_data):
    &quot;&quot;&quot;Test que usa DOS fixtures.&quot;&quot;&quot;
    X = sample_data.drop(columns=[&quot;price&quot;])
    predictions = fitted_pipeline.predict(X)

    assert all(predictions &gt; 0), &quot;Precios deben ser positivos&quot;
</code></pre>
<h2>11.3 Unit Tests: Funciones Individuales</h2>
<h3>QuÃ© Testear en Unit Tests</h3>
<pre><code class="language-python"># tests/test_features.py - CÃ³digo REAL del portafolio

import pytest
import pandas as pd
from src.carvision.features import FeatureEngineer


class TestFeatureEngineer:
    &quot;&quot;&quot;Tests unitarios para FeatureEngineer.&quot;&quot;&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: CreaciÃ³n de features
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_creates_vehicle_age(self, sample_data):
        &quot;&quot;&quot;Verifica que vehicle_age se calcula correctamente.&quot;&quot;&quot;
        fe = FeatureEngineer(current_year=2024)
        result = fe.transform(sample_data)

        assert &quot;vehicle_age&quot; in result.columns
        # 2024 - 2015 = 9 aÃ±os para el primer registro
        assert result.loc[0, &quot;vehicle_age&quot;] == 9

    def test_creates_brand_from_model(self, sample_data):
        &quot;&quot;&quot;Verifica que brand extrae la primera palabra de model.&quot;&quot;&quot;
        fe = FeatureEngineer(current_year=2024)
        result = fe.transform(sample_data)

        assert &quot;brand&quot; in result.columns
        assert result.loc[0, &quot;brand&quot;] == &quot;ford&quot;  # &quot;ford f-150&quot; â†’ &quot;ford&quot;
        assert result.loc[1, &quot;brand&quot;] == &quot;toyota&quot;  # &quot;toyota camry&quot; â†’ &quot;toyota&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Manejo de edge cases
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_handles_missing_model_year(self):
        &quot;&quot;&quot;Verifica comportamiento con model_year faltante.&quot;&quot;&quot;
        df = pd.DataFrame({
            &quot;price&quot;: [15000],
            &quot;model&quot;: [&quot;ford f-150&quot;],
            # Sin model_year
        })

        fe = FeatureEngineer(current_year=2024)
        result = fe.transform(df)

        # No debe crear vehicle_age si no hay model_year
        assert &quot;vehicle_age&quot; not in result.columns

    def test_handles_missing_model_column(self):
        &quot;&quot;&quot;Verifica comportamiento sin columna model.&quot;&quot;&quot;
        df = pd.DataFrame({
            &quot;price&quot;: [15000],
            &quot;model_year&quot;: [2015],
            # Sin model
        })

        fe = FeatureEngineer(current_year=2024)
        result = fe.transform(df)

        # No debe crear brand si no hay model
        assert &quot;brand&quot; not in result.columns

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Inmutabilidad
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_does_not_modify_input(self, sample_data):
        &quot;&quot;&quot;Verifica que el DataFrame original no se modifica.&quot;&quot;&quot;
        original_columns = sample_data.columns.tolist()
        original_values = sample_data.copy()

        fe = FeatureEngineer(current_year=2024)
        _ = fe.transform(sample_data)

        # Columnas originales sin cambio
        assert sample_data.columns.tolist() == original_columns
        # Valores originales sin cambio
        pd.testing.assert_frame_equal(sample_data, original_values)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Compatibilidad con sklearn
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_fit_returns_self(self, sample_data):
        &quot;&quot;&quot;Verifica que fit() retorna self (requerido por sklearn).&quot;&quot;&quot;
        fe = FeatureEngineer(current_year=2024)
        result = fe.fit(sample_data)

        assert result is fe

    def test_works_in_pipeline(self, sample_data):
        &quot;&quot;&quot;Verifica que funciona dentro de un Pipeline sklearn.&quot;&quot;&quot;
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import StandardScaler

        pipe = Pipeline([
            (&quot;features&quot;, FeatureEngineer(current_year=2024)),
            (&quot;scaler&quot;, StandardScaler())
        ])

        # No debe lanzar excepciÃ³n
        # (Solo probamos que no falla, no el resultado)
        try:
            # Seleccionar solo columnas numÃ©ricas para StandardScaler
            numeric_cols = [&quot;price&quot;, &quot;model_year&quot;, &quot;odometer&quot;]
            result = pipe.fit_transform(sample_data[numeric_cols])
            assert result is not None
        except Exception as e:
            pytest.fail(f&quot;Pipeline fallÃ³: {e}&quot;)
</code></pre>
<h2>11.4 Data Tests: ValidaciÃ³n de Datos</h2>
<h3>Tests de Schema y Calidad de Datos</h3>
<pre><code class="language-python"># tests/test_data.py - CÃ³digo REAL del portafolio

import pytest
import pandas as pd
import numpy as np
from src.carvision.data import load_data, clean_data


class TestDataLoading:
    &quot;&quot;&quot;Tests de carga y validaciÃ³n de datos.&quot;&quot;&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Schema validation
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_required_columns_exist(self, sample_data):
        &quot;&quot;&quot;Verifica que existen las columnas requeridas.&quot;&quot;&quot;
        required = [&quot;price&quot;, &quot;model_year&quot;, &quot;odometer&quot;, &quot;model&quot;, &quot;fuel&quot;]

        for col in required:
            assert col in sample_data.columns, f&quot;Falta columna: {col}&quot;

    def test_column_types(self, sample_data):
        &quot;&quot;&quot;Verifica tipos de datos correctos.&quot;&quot;&quot;
        # NumÃ©ricas
        assert pd.api.types.is_numeric_dtype(sample_data[&quot;price&quot;])
        assert pd.api.types.is_numeric_dtype(sample_data[&quot;model_year&quot;])
        assert pd.api.types.is_numeric_dtype(sample_data[&quot;odometer&quot;])

        # CategÃ³ricas/String
        assert pd.api.types.is_object_dtype(sample_data[&quot;model&quot;])
        assert pd.api.types.is_object_dtype(sample_data[&quot;fuel&quot;])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Value ranges
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_price_is_positive(self, sample_data):
        &quot;&quot;&quot;Verifica que precios son positivos.&quot;&quot;&quot;
        assert (sample_data[&quot;price&quot;] &gt; 0).all(), &quot;Hay precios &lt;= 0&quot;

    def test_price_in_reasonable_range(self, sample_data):
        &quot;&quot;&quot;Verifica que precios estÃ¡n en rango razonable.&quot;&quot;&quot;
        assert sample_data[&quot;price&quot;].min() &gt;= 100, &quot;Precio muy bajo (posible error)&quot;
        assert sample_data[&quot;price&quot;].max() &lt;= 500000, &quot;Precio muy alto (posible error)&quot;

    def test_model_year_in_range(self, sample_data):
        &quot;&quot;&quot;Verifica que aÃ±os son razonables.&quot;&quot;&quot;
        current_year = pd.Timestamp.now().year

        assert sample_data[&quot;model_year&quot;].min() &gt;= 1900, &quot;AÃ±o muy antiguo&quot;
        assert sample_data[&quot;model_year&quot;].max() &lt;= current_year + 1, &quot;AÃ±o futuro&quot;

    def test_odometer_is_non_negative(self, sample_data):
        &quot;&quot;&quot;Verifica que odometer no es negativo.&quot;&quot;&quot;
        assert (sample_data[&quot;odometer&quot;] &gt;= 0).all(), &quot;Hay odometer negativo&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Categorical values
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_fuel_valid_values(self, sample_data):
        &quot;&quot;&quot;Verifica que fuel tiene valores vÃ¡lidos.&quot;&quot;&quot;
        valid_fuels = {&quot;gas&quot;, &quot;diesel&quot;, &quot;electric&quot;, &quot;hybrid&quot;, &quot;other&quot;}
        actual_fuels = set(sample_data[&quot;fuel&quot;].dropna().unique())

        invalid = actual_fuels - valid_fuels
        assert len(invalid) == 0, f&quot;Valores de fuel invÃ¡lidos: {invalid}&quot;

    def test_transmission_valid_values(self, sample_data):
        &quot;&quot;&quot;Verifica que transmission tiene valores vÃ¡lidos.&quot;&quot;&quot;
        valid = {&quot;automatic&quot;, &quot;manual&quot;, &quot;other&quot;}
        actual = set(sample_data[&quot;transmission&quot;].dropna().unique())

        invalid = actual - valid
        assert len(invalid) == 0, f&quot;Valores de transmission invÃ¡lidos: {invalid}&quot;


class TestDataCleaning:
    &quot;&quot;&quot;Tests de limpieza de datos.&quot;&quot;&quot;

    def test_clean_data_removes_invalid_prices(self, sample_data):
        &quot;&quot;&quot;Verifica que clean_data filtra precios fuera de rango.&quot;&quot;&quot;
        # AÃ±adir registro con precio invÃ¡lido
        bad_data = pd.concat([
            sample_data,
            pd.DataFrame({&quot;price&quot;: [100], &quot;model_year&quot;: [2020], 
                         &quot;odometer&quot;: [1000], &quot;model&quot;: [&quot;test&quot;],
                         &quot;fuel&quot;: [&quot;gas&quot;], &quot;transmission&quot;: [&quot;automatic&quot;],
                         &quot;condition&quot;: [&quot;good&quot;]})
        ], ignore_index=True)

        filters = {&quot;price_min&quot;: 1000, &quot;price_max&quot;: 100000}
        cleaned = clean_data(bad_data, filters=filters)

        # El registro con price=100 debe ser eliminado
        assert len(cleaned) == len(sample_data)
        assert (cleaned[&quot;price&quot;] &gt;= 1000).all()

    def test_clean_data_handles_nulls(self, sample_data_with_nulls):
        &quot;&quot;&quot;Verifica que clean_data no falla con NaN.&quot;&quot;&quot;
        # No debe lanzar excepciÃ³n
        filters = {&quot;price_min&quot;: 1000}
        cleaned = clean_data(sample_data_with_nulls, filters=filters)

        assert cleaned is not None
        # Registros con price=None deben ser eliminados o manejados
        assert len(cleaned) &lt;= len(sample_data_with_nulls)
</code></pre>
<h2>11.5 Model Tests: Comportamiento del Modelo</h2>
<h3>Tests EspecÃ­ficos de ML</h3>
<pre><code class="language-python"># tests/test_model_logic.py - CÃ³digo REAL del portafolio

import pytest
import numpy as np
import pandas as pd


class TestModelPredictions:
    &quot;&quot;&quot;Tests de comportamiento del modelo.&quot;&quot;&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Output shape y tipo
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_predict_returns_correct_shape(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que predict retorna un array del tamaÃ±o correcto.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])
        predictions = fitted_pipeline.predict(X)

        assert len(predictions) == len(X), &quot;NÃºmero de predicciones incorrecto&quot;

    def test_predict_returns_numeric(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que predicciones son numÃ©ricas.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])
        predictions = fitted_pipeline.predict(X)

        assert np.issubdtype(predictions.dtype, np.number), &quot;Predicciones no son numÃ©ricas&quot;

    def test_predict_no_nan(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que no hay NaN en predicciones.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])
        predictions = fitted_pipeline.predict(X)

        assert not np.isnan(predictions).any(), &quot;Hay NaN en predicciones&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Rangos razonables
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_predictions_are_positive(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que precios predichos son positivos.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])
        predictions = fitted_pipeline.predict(X)

        assert (predictions &gt; 0).all(), &quot;Hay predicciones &lt;= 0&quot;

    def test_predictions_in_training_range(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que predicciones estÃ¡n en rango similar al training.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])
        y = sample_data[&quot;price&quot;]
        predictions = fitted_pipeline.predict(X)

        # Predicciones deben estar dentro de un margen razonable
        min_price = y.min() * 0.1  # 10% del mÃ­nimo
        max_price = y.max() * 3.0  # 300% del mÃ¡ximo

        assert predictions.min() &gt;= min_price, &quot;PredicciÃ³n muy baja&quot;
        assert predictions.max() &lt;= max_price, &quot;PredicciÃ³n muy alta&quot;

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Consistencia (determinismo)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_predictions_are_deterministic(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que mismos inputs dan mismos outputs.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;])

        pred1 = fitted_pipeline.predict(X)
        pred2 = fitted_pipeline.predict(X)

        np.testing.assert_array_equal(pred1, pred2, 
            &quot;Predicciones no son determinÃ­sticas&quot;)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TEST: Sensibilidad a features
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def test_higher_odometer_lower_price(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que mayor odometer tiende a menor precio.

        Este es un test de &quot;sanity check&quot;: verifica que el modelo
        aprendiÃ³ relaciones bÃ¡sicas del dominio.
        &quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;]).copy()

        # PredicciÃ³n con odometer original
        pred_low_odo = fitted_pipeline.predict(X)

        # Aumentar odometer significativamente
        X_high_odo = X.copy()
        X_high_odo[&quot;odometer&quot;] = X[&quot;odometer&quot;] * 3
        pred_high_odo = fitted_pipeline.predict(X_high_odo)

        # En promedio, mayor odometer â†’ menor precio
        # (No requiere que TODOS sean menores, solo el promedio)
        assert pred_high_odo.mean() &lt; pred_low_odo.mean(), \
            &quot;Modelo no aprendiÃ³ que mayor odometer = menor precio&quot;

    def test_newer_car_higher_price(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que autos mÃ¡s nuevos tienden a mayor precio.&quot;&quot;&quot;
        X = sample_data.drop(columns=[&quot;price&quot;]).copy()

        # PredicciÃ³n con model_year original
        pred_original = fitted_pipeline.predict(X)

        # Hacer autos 5 aÃ±os mÃ¡s nuevos
        X_newer = X.copy()
        X_newer[&quot;model_year&quot;] = X[&quot;model_year&quot;] + 5
        pred_newer = fitted_pipeline.predict(X_newer)

        # En promedio, mÃ¡s nuevo â†’ mayor precio
        assert pred_newer.mean() &gt; pred_original.mean(), \
            &quot;Modelo no aprendiÃ³ que autos nuevos cuestan mÃ¡s&quot;


class TestModelMetrics:
    &quot;&quot;&quot;Tests de mÃ©tricas del modelo.&quot;&quot;&quot;

    def test_rmse_below_threshold(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que RMSE estÃ¡ por debajo de umbral aceptable.&quot;&quot;&quot;
        from sklearn.metrics import mean_squared_error

        X = sample_data.drop(columns=[&quot;price&quot;])
        y = sample_data[&quot;price&quot;]
        predictions = fitted_pipeline.predict(X)

        rmse = np.sqrt(mean_squared_error(y, predictions))

        # RMSE debe ser menor que el 50% del precio promedio
        # (umbral arbitrario para sample data pequeÃ±o)
        threshold = y.mean() * 0.5
        assert rmse &lt; threshold, f&quot;RMSE={rmse:.2f} &gt; threshold={threshold:.2f}&quot;

    def test_r2_above_threshold(self, fitted_pipeline, sample_data):
        &quot;&quot;&quot;Verifica que RÂ² estÃ¡ por encima de umbral mÃ­nimo.&quot;&quot;&quot;
        from sklearn.metrics import r2_score

        X = sample_data.drop(columns=[&quot;price&quot;])
        y = sample_data[&quot;price&quot;]
        predictions = fitted_pipeline.predict(X)

        r2 = r2_score(y, predictions)

        # RÂ² debe ser positivo (mejor que predecir la media)
        # Nota: Con sample data pequeÃ±o, RÂ² puede ser bajo
        assert r2 &gt; 0.0, f&quot;RÂ²={r2:.3f} &lt;= 0 (peor que baseline)&quot;
</code></pre>
<h2>11.6 Integration Tests: Pipeline Completo</h2>
<h3>Tests End-to-End</h3>
<pre><code class="language-python"># tests/test_main_workflow.py - CÃ³digo REAL del portafolio

import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import tempfile
import joblib


class TestTrainingWorkflow:
    &quot;&quot;&quot;Tests de integraciÃ³n del flujo completo de entrenamiento.&quot;&quot;&quot;

    def test_full_training_pipeline(self, sample_data, sample_config, tmp_path):
        &quot;&quot;&quot;Test end-to-end: datos â†’ entrenamiento â†’ modelo guardado.&quot;&quot;&quot;
        from src.carvision.training import train_model

        # Configurar paths temporales
        sample_config[&quot;paths&quot;][&quot;artifacts_dir&quot;] = str(tmp_path)
        sample_config[&quot;paths&quot;][&quot;model_path&quot;] = str(tmp_path / &quot;model.joblib&quot;)

        # Guardar datos temporales
        data_path = tmp_path / &quot;data.csv&quot;
        sample_data.to_csv(data_path, index=False)
        sample_config[&quot;paths&quot;][&quot;data_path&quot;] = str(data_path)

        # Ejecutar entrenamiento
        result = train_model(sample_config)

        # Verificaciones
        assert &quot;rmse&quot; in result, &quot;Falta mÃ©trica RMSE&quot;
        assert result[&quot;rmse&quot;] &gt; 0, &quot;RMSE debe ser positivo&quot;

        # Verificar que modelo se guardÃ³
        model_path = Path(sample_config[&quot;paths&quot;][&quot;model_path&quot;])
        assert model_path.exists(), &quot;Modelo no se guardÃ³&quot;

        # Verificar que modelo se puede cargar
        model = joblib.load(model_path)
        assert model is not None, &quot;Modelo no se puede cargar&quot;

    def test_training_creates_all_artifacts(self, sample_data, sample_config, tmp_path):
        &quot;&quot;&quot;Verifica que entrenamiento crea todos los artefactos esperados.&quot;&quot;&quot;
        from src.carvision.training import train_model

        # Setup
        sample_config[&quot;paths&quot;][&quot;artifacts_dir&quot;] = str(tmp_path)
        sample_config[&quot;paths&quot;][&quot;model_path&quot;] = str(tmp_path / &quot;model.joblib&quot;)
        sample_config[&quot;paths&quot;][&quot;metrics_path&quot;] = str(tmp_path / &quot;metrics.json&quot;)

        data_path = tmp_path / &quot;data.csv&quot;
        sample_data.to_csv(data_path, index=False)
        sample_config[&quot;paths&quot;][&quot;data_path&quot;] = str(data_path)

        # Train
        train_model(sample_config)

        # Verificar artefactos
        assert (tmp_path / &quot;model.joblib&quot;).exists(), &quot;Falta model.joblib&quot;
        # metrics.json es opcional en algunos configs

    def test_loaded_model_predicts_correctly(self, sample_data, sample_config, tmp_path):
        &quot;&quot;&quot;Verifica que modelo guardado predice igual que antes de guardar.&quot;&quot;&quot;
        from src.carvision.training import train_model, build_pipeline
        from src.carvision.features import FeatureEngineer

        # Setup y entrenamiento
        sample_config[&quot;paths&quot;][&quot;artifacts_dir&quot;] = str(tmp_path)
        model_path = tmp_path / &quot;model.joblib&quot;
        sample_config[&quot;paths&quot;][&quot;model_path&quot;] = str(model_path)

        data_path = tmp_path / &quot;data.csv&quot;
        sample_data.to_csv(data_path, index=False)
        sample_config[&quot;paths&quot;][&quot;data_path&quot;] = str(data_path)

        train_model(sample_config)

        # Cargar modelo
        loaded_model = joblib.load(model_path)

        # Predecir con nuevo dato
        new_data = pd.DataFrame({
            &quot;model_year&quot;: [2020],
            &quot;odometer&quot;: [30000],
            &quot;model&quot;: [&quot;ford f-150&quot;],
            &quot;fuel&quot;: [&quot;gas&quot;],
            &quot;transmission&quot;: [&quot;automatic&quot;],
        })

        prediction = loaded_model.predict(new_data)

        # Verificaciones bÃ¡sicas
        assert len(prediction) == 1
        assert prediction[0] &gt; 0
        assert not np.isnan(prediction[0])


class TestAPIWorkflow:
    &quot;&quot;&quot;Tests de integraciÃ³n del API.&quot;&quot;&quot;

    @pytest.mark.slow
    def test_api_prediction_endpoint(self, fitted_pipeline, tmp_path):
        &quot;&quot;&quot;Test E2E del endpoint de predicciÃ³n.&quot;&quot;&quot;
        from fastapi.testclient import TestClient
        import sys

        # Guardar modelo para el API
        model_path = tmp_path / &quot;model.joblib&quot;
        joblib.dump(fitted_pipeline, model_path)

        # Importar app (puede requerir configuraciÃ³n de paths)
        # Este test asume que ARTIFACTS_DIR estÃ¡ configurado
        import os
        os.environ[&quot;ARTIFACTS_DIR&quot;] = str(tmp_path)

        try:
            from app.fastapi_app import app
            client = TestClient(app)

            # Request de predicciÃ³n
            response = client.post(&quot;/predict&quot;, json={
                &quot;model_year&quot;: 2020,
                &quot;odometer&quot;: 30000,
                &quot;model&quot;: &quot;ford f-150&quot;,
                &quot;fuel&quot;: &quot;gas&quot;,
                &quot;transmission&quot;: &quot;automatic&quot;
            })

            assert response.status_code == 200
            data = response.json()
            assert &quot;prediction&quot; in data
            assert data[&quot;prediction&quot;] &gt; 0
        except ImportError:
            pytest.skip(&quot;FastAPI app not available&quot;)
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en testing ML</h2>
<p>Aunque pytest es muy potente, en ML es fÃ¡cil caer en tests frÃ¡giles o engaÃ±osos. Estos son los patrones mÃ¡s comunes y cÃ³mo atacarlos.</p>
<h3>1) Tests que dependen de datos reales o externos</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Tests que leen de <code>data/raw/...</code> o llaman APIs externas.</li>
<li>Fallan solo en CI o solo en ciertas mÃ¡quinas.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Busca en tests accesos directos a rutas del proyecto o a recursos externos.</li>
<li>Revisa que tus fixtures (<code>sample_data</code>, <code>sample_config</code>, etc.) no lean de archivos reales salvo cuando se prueban funciones de I/O.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa <strong>fixtures sintÃ©ticas</strong> en memoria para la mayorÃ­a de tests.</li>
<li>Deja el acceso a disco/red solo en tests de integraciÃ³n marcados (<code>@pytest.mark.integration</code> o <code>@pytest.mark.slow</code>).</li>
</ul>
<h3>2) Fixtures mal definidas (estado compartido, side-effects)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Tests que pasan individualmente pero fallan cuando se ejecutan todos juntos.</li>
<li>MutaciÃ³n de <code>DataFrame</code> compartido entre tests.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa que tus fixtures devuelvan <strong>nuevas instancias</strong> o copias (<code>df.copy()</code>) cuando sea necesario.</li>
<li>Usa <code>scope="function"</code> por defecto; solo usa <code>module</code>/<code>session</code> para recursos pesados cuidadosamente diseÃ±ados.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura inmutabilidad en el cÃ³digo (ej. <code>X = X.copy()</code> en transformers) y en los tests (no reutilizar el mismo objeto mutable entre mÃºltiples asserts sin reset).</li>
</ul>
<h3>3) Coverage alto pero sin cubrir lo importante</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Reporte de coverage muestra 80â€“90%, pero:</li>
<li>No hay tests de datos.</li>
<li>No hay tests de comportamiento del modelo.</li>
<li>Solo se testea â€œfeliz pathâ€.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Usa <code>--cov-report=term-missing</code> para ver <strong>quÃ© lÃ­neas</strong> no se cubren.</li>
<li>Verifica que las capas clave (data, features, training, prediction) tienen tests dedicados.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AÃ±ade tests para:</li>
<li>ValidaciÃ³n de datos (rangos, NaN, tipos).</li>
<li>Comportamiento bÃ¡sico del modelo (shapes, ranges, determinismo).</li>
<li>Al menos un flujo de integraciÃ³n (<code>train_model</code>, API <code>/predict</code>).</li>
</ul>
<h3>4) Tests lentos que bloquean el flujo de trabajo</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>pytest</code> tarda minutos porque ejecuta entrenamiento completo en cada test.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Localiza tests que entrenan modelos con muchos datos o hiperparÃ¡metros pesados.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Para tests, usa:</li>
<li><strong>datasets pequeÃ±os</strong>.</li>
<li>Modelos simplificados (pocos Ã¡rboles, menor profundidad).</li>
<li>Marcadores <code>@pytest.mark.slow</code> para separar tests pesados.</li>
<li>Ajusta tu CI para ejecutar rÃ¡pida y frecuentemente los tests rÃ¡pidos, y los lentos solo en ciertas ramas.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en tests ML</h3>
<ol>
<li><strong>Reproduce el fallo en local</strong> con el mismo comando que CI (<code>pytest</code> con las mismas flags).</li>
<li><strong>AÃ­sla el test problemÃ¡tico</strong> usando <code>-k</code> o el nombre del test.</li>
<li><strong>Inspecciona fixtures y datos</strong>: asegÃºrate de que no hay estado compartido inesperado.</li>
<li><strong>Conecta el problema</strong> con la capa correspondiente (datos, features, modelo, API) y ajusta los tests para cubrir el caso real que quieres proteger.</li>
</ol>
<p>Con esta mentalidad, los tests dejan de ser una carga y se convierten en la red de seguridad que te permite refactorizar con confianza.</p>
<h2>11.7 Alcanzar 80% Coverage</h2>
<h3>ConfiguraciÃ³n de pytest-cov</h3>
<pre><code class="language-toml"># pyproject.toml

[tool.pytest.ini_options]
testpaths = [&quot;tests&quot;]
python_files = [&quot;test_*.py&quot;]
python_classes = [&quot;Test*&quot;]
python_functions = [&quot;test_*&quot;]
addopts = [
    &quot;-v&quot;,
    &quot;--cov=src/carvision&quot;,
    &quot;--cov-report=term-missing&quot;,
    &quot;--cov-report=html&quot;,
    &quot;--cov-fail-under=80&quot;,
]
markers = [
    &quot;slow: marks tests as slow (deselect with '-m \&quot;not slow\&quot;')&quot;,
    &quot;integration: marks tests as integration tests&quot;,
]

[tool.coverage.run]
source = [&quot;src&quot;]
omit = [
    &quot;tests/*&quot;,
    &quot;*/__init__.py&quot;,
    &quot;*/visualization.py&quot;,  # Excluir cÃ³digo de UI
]

[tool.coverage.report]
fail_under = 80
exclude_lines = [
    &quot;pragma: no cover&quot;,
    &quot;if __name__ == .__main__.:&quot;,
    &quot;raise NotImplementedError&quot;,
]
</code></pre>
<h3>Ejecutar Tests con Coverage</h3>
<pre><code class="language-bash"># Tests rÃ¡pidos (sin slow)
pytest -m &quot;not slow&quot;

# Todos los tests con coverage
pytest --cov=src/carvision --cov-report=term-missing

# Solo ver coverage sin ejecutar tests
pytest --cov=src/carvision --cov-report=html
# Abre htmlcov/index.html en el navegador

# Verificar que pasa el threshold
pytest --cov-fail-under=80
</code></pre>
<h3>Estrategias para Aumentar Coverage</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“ˆ CÃ“MO PASAR DE 60% A 80% COVERAGE                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                           â•‘
â•‘  1. IDENTIFICAR GAPS                                                      â•‘
â•‘     pytest --cov-report=term-missing                                      â•‘
â•‘     â†’ Muestra lÃ­neas NO cubiertas                                         â•‘
â•‘                                                                           â•‘
â•‘  2. PRIORIZAR                                                             â•‘
â•‘     â€¢ LÃ³gica de negocio crÃ­tica (training, prediction)                    â•‘
â•‘     â€¢ CÃ³digo que maneja errores                                           â•‘
â•‘     â€¢ Branches condicionales (if/else)                                    â•‘
â•‘                                                                           â•‘
â•‘  3. EXCLUIR LO QUE NO VALE LA PENA                                        â•‘
â•‘     â€¢ CÃ³digo de visualizaciÃ³n (Streamlit, plots)                          â•‘
â•‘     â€¢ Scripts de utilidad one-off                                         â•‘
â•‘     â€¢ CÃ³digo de terceros                                                  â•‘
â•‘                                                                           â•‘
â•‘  4. TESTEAR EDGE CASES                                                    â•‘
â•‘     â€¢ Â¿QuÃ© pasa con NaN?                                                  â•‘
â•‘     â€¢ Â¿QuÃ© pasa con lista vacÃ­a?                                          â•‘
â•‘     â€¢ Â¿QuÃ© pasa con tipos incorrectos?                                    â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>âœ… Checkpoint: Â¿Completaste el MÃ³dulo?</h2>
<p>Antes de continuar, verifica:</p>
<ul>
<li>[ ] Tienes <code>tests/conftest.py</code> con fixtures reutilizables</li>
<li>[ ] Tienes tests unitarios para tus transformers</li>
<li>[ ] Tienes tests de validaciÃ³n de datos</li>
<li>[ ] Tienes tests de comportamiento del modelo</li>
<li>[ ] Tienes al menos un test de integraciÃ³n</li>
<li>[ ] Tu coverage es &gt;= 80%</li>
</ul>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>Los 3 proyectos del portafolio implementan testing profesional con 80%+ coverage:</p>
<h3>Coverage por Proyecto</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th style="text-align: center;">Coverage</th>
<th style="text-align: center;">Tests</th>
<th>Archivos Clave</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td style="text-align: center;">79%+</td>
<td style="text-align: center;">45+</td>
<td><code>tests/conftest.py</code>, <code>test_pipeline.py</code></td>
</tr>
<tr>
<td>CarVision</td>
<td style="text-align: center;">97%</td>
<td style="text-align: center;">50+</td>
<td><code>tests/test_features.py</code>, <code>test_data.py</code></td>
</tr>
<tr>
<td>TelecomAI</td>
<td style="text-align: center;">97%</td>
<td style="text-align: center;">35+</td>
<td><code>tests/test_training.py</code></td>
</tr>
</tbody>
</table>
<h3>conftest.py Real (CarVision)</h3>
<pre><code class="language-python"># CarVision-Market-Intelligence/tests/conftest.py
import pytest
import pandas as pd

@pytest.fixture
def sample_df():
    &quot;&quot;&quot;DataFrame de prueba con datos realistas.&quot;&quot;&quot;
    return pd.DataFrame({
        'model': ['Ford F-150', 'Toyota Camry'],
        'model_year': [2020, 2019],
        'odometer': [50000, 30000],
        'price': [35000, 25000]
    })

@pytest.fixture
def config():
    &quot;&quot;&quot;ConfiguraciÃ³n de prueba.&quot;&quot;&quot;
    return {
        'data': {'target_column': 'price'},
        'model': {'random_state': 42}
    }
</code></pre>
<h3>Estructura de Tests</h3>
<pre><code>tests/
â”œâ”€â”€ conftest.py           # Fixtures compartidas
â”œâ”€â”€ test_config.py        # Tests de configuraciÃ³n
â”œâ”€â”€ test_data.py          # Tests de carga/validaciÃ³n
â”œâ”€â”€ test_features.py      # Tests de FeatureEngineer
â”œâ”€â”€ test_pipeline.py      # Tests de pipeline
â”œâ”€â”€ test_training.py      # Tests de entrenamiento
â””â”€â”€ test_api.py           # Tests de FastAPI
</code></pre>
<h3>ğŸ”§ Ejercicio: Ejecuta Tests Reales</h3>
<pre><code class="language-bash"># 1. Ejecuta tests de CarVision
cd CarVision-Market-Intelligence
pytest tests/ -v --cov=src/carvision --cov-report=term-missing

# 2. Ve quÃ© lÃ­neas NO estÃ¡n cubiertas
pytest --cov-report=html  # Genera htmlcov/index.html

# 3. Compara con BankChurn
cd ../BankChurn-Predictor
pytest tests/ -v --cov=src/bankchurn
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Testing ML es diferente</strong>: Explica tests de datos, modelo, y serving (no solo cÃ³digo).</p>
</li>
<li>
<p><strong>Great Expectations</strong>: Menciona que usas validaciÃ³n de datos como parte del pipeline.</p>
</li>
<li>
<p><strong>Coverage no es todo</strong>: Un modelo con 100% coverage puede fallar en producciÃ³n.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>Tipo de Test</th>
<th>QuÃ© Verificar</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Tests</td>
<td>Schema, rangos, distribuciones, nulls</td>
</tr>
<tr>
<td>Model Tests</td>
<td>MÃ©tricas mÃ­nimas, overfitting, invariancia</td>
</tr>
<tr>
<td>Integration</td>
<td>Pipeline end-to-end, API responses</td>
</tr>
<tr>
<td>Performance</td>
<td>Latencia, throughput, memory</td>
</tr>
</tbody>
</table>
<h3>Estrategia de Testing ML</h3>
<pre><code>Unit Tests:     Transformadores individuales
Integration:    Pipeline completo con datos sintÃ©ticos
Validation:     MÃ©tricas en holdout real
Monitoring:     Drift detection en producciÃ³n
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=cHYq1MRoyI0">pytest Tutorial - ArjanCodes</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=0ysyWk-ox-8">Testing for Data Science - Eric Ma</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://docs.pytest.org/">pytest Documentation</a><br />
- <a href="https://pytest-cov.readthedocs.io/">pytest-cov</a><br />
- <a href="https://greatexpectations.io/">Great Expectations</a> - Data validation</p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>conftest.py</strong>: Fixtures compartidas de pytest<br />
- <strong>Coverage</strong>: Porcentaje de cÃ³digo ejecutado por tests<br />
- <strong>Fixture</strong>: Setup reutilizable para tests</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 11:<br />
- <strong>11.1</strong>: Test de validaciÃ³n de datos<br />
- <strong>11.2</strong>: Test de pipeline ML</p>
            </div>
        
            <!-- MÃ“DULO: 12_CI_CD.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_12_CI_CD" class="cover-title">CI/CD</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>13. CI/CD con GitHub Actions</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Implementar un pipeline CI/CD profesional que valide automÃ¡ticamente tu cÃ³digo en cada push, como el workflow <code>ci-mlops.yml</code> del portafolio.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  ğŸ”„ CI/CD = Tu GuardiÃ¡n AutomÃ¡tico                                          â•‘
â•‘                                                                              â•‘
â•‘  ANTES (sin CI/CD):                                                          â•‘
â•‘  â€¢ &quot;OlvidÃ© correr los tests antes de mergear&quot;                                â•‘
â•‘  â€¢ &quot;RompÃ­ producciÃ³n con un cambio pequeÃ±o&quot;                                  â•‘
â•‘  â€¢ &quot;No sabÃ­a que mi cÃ³digo no pasaba linting&quot;                                â•‘
â•‘                                                                              â•‘
â•‘  DESPUÃ‰S (con CI/CD):                                                        â•‘
â•‘  â€¢ Cada push ejecuta tests automÃ¡ticamente                                   â•‘
â•‘  â€¢ No puedes mergear si los tests fallan                                     â•‘
â•‘  â€¢ Coverage, linting, y seguridad verificados siempre                        â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#131-anatomÃ­a-de-un-workflow">AnatomÃ­a de un Workflow</a></li>
<li><a href="#132-matrix-testing-mÃºltiples-versiones">Matrix Testing: MÃºltiples Versiones</a></li>
<li><a href="#133-coverage-enforcement">Coverage Enforcement</a></li>
<li><a href="#134-security-scanning">Security Scanning</a></li>
<li><a href="#135-docker-build-y-push">Docker Build y Push</a></li>
<li><a href="#136-el-workflow-completo">El Workflow Completo del Portafolio</a></li>
</ol>
<h2>13.1 AnatomÃ­a de un Workflow</h2>
<h3>Estructura BÃ¡sica</h3>
<pre><code class="language-yaml"># .github/workflows/ci.yml

name: CI Pipeline                    # Nombre visible en GitHub

on:                                   # Â¿CuÃ¡ndo ejecutar?
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:                                 # Â¿QuÃ© ejecutar?
  test:
    runs-on: ubuntu-latest           # Sistema operativo
    steps:                           # Pasos secuenciales
      - uses: actions/checkout@v4    # Paso 1: Descargar cÃ³digo
      - uses: actions/setup-python@v5 # Paso 2: Configurar Python
        with:
          python-version: '3.11'
      - run: pip install -r requirements.txt  # Paso 3: Instalar deps
      - run: pytest                           # Paso 4: Correr tests
</code></pre>
<h3>AnalogÃ­a: La LÃ­nea de InspecciÃ³n de Calidad</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ­ IMAGINA UNA FÃBRICA DE AUTOS:                                         â•‘
â•‘                                                                           â•‘
â•‘  Workflow = LÃ­nea de inspecciÃ³n de calidad                                â•‘
â•‘                                                                           â•‘
â•‘  on (trigger):                                                            â•‘
â•‘  â†’ &quot;Cada vez que un auto nuevo llega a la lÃ­nea&quot;                          â•‘
â•‘                                                                           â•‘
â•‘  jobs:                                                                    â•‘
â•‘  â†’ Diferentes estaciones de inspecciÃ³n                                    â•‘
â•‘                                                                           â•‘
â•‘  steps:                                                                   â•‘
â•‘  â†’ Tareas especÃ­ficas en cada estaciÃ³n                                    â•‘
â•‘                                                                           â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â•‘
â•‘  â”‚ Checkoutâ”‚â”€â”€â–ºâ”‚ Install â”‚â”€â”€â–ºâ”‚  Test   â”‚â”€â”€â–ºâ”‚  Build  â”‚                    â•‘
â•‘  â”‚  (get   â”‚   â”‚  (prep  â”‚   â”‚  (run   â”‚   â”‚ (create â”‚                    â•‘
â•‘  â”‚  code)  â”‚   â”‚  tools) â”‚   â”‚  tests) â”‚   â”‚ Docker) â”‚                    â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>13.2 Matrix Testing: MÃºltiples Versiones</h2>
<h3>El Problema: "Funciona en mi versiÃ³n de Python"</h3>
<pre><code class="language-yaml"># âŒ ANTES: Solo pruebas con una versiÃ³n
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'  # Â¿Y si alguien usa 3.12?
</code></pre>
<h3>La SoluciÃ³n: Matrix Strategy</h3>
<pre><code class="language-yaml"># âœ… DESPUÃ‰S: Pruebas con mÃºltiples versiones
# CÃ³digo REAL de ci-mlops.yml del portafolio

jobs:
  tests:
    name: Tests &amp; Coverage
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false                  # No cancelar otros si uno falla
      matrix:
        python-version: ['3.11', '3.12']  # 2 versiones de Python
        project:                           # 3 proyectos
          - BankChurn-Predictor
          - CarVision-Market-Intelligence
          - TelecomAI-Customer-Intelligence

    # Esto crea 2 x 3 = 6 jobs paralelos:
    # - BankChurn con Python 3.11
    # - BankChurn con Python 3.12
    # - CarVision con Python 3.11
    # - CarVision con Python 3.12
    # - TelecomAI con Python 3.11
    # - TelecomAI con Python 3.12

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'  # Cache de dependencias para velocidad

      - name: Install dependencies
        working-directory: ${{ matrix.project }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov

      - name: Run tests
        working-directory: ${{ matrix.project }}
        run: pytest --cov=src/ --cov-fail-under=80
</code></pre>
<h3>VisualizaciÃ³n del Matrix</h3>
<pre><code>                    Python 3.11          Python 3.12
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
BankChurn         â”‚   Job 1     â”‚      â”‚   Job 2     â”‚
                  â”‚   âœ… Pass   â”‚      â”‚   âœ… Pass  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
CarVision         â”‚   Job 3     â”‚      â”‚   Job 4     â”‚
                  â”‚   âœ… Pass   â”‚      â”‚   âœ… Pass  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
TelecomAI         â”‚   Job 5     â”‚      â”‚   Job 6     â”‚
                  â”‚   âœ… Pass   â”‚      â”‚   âœ… Pass  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Total: 6 jobs ejecutÃ¡ndose EN PARALELO
</code></pre>
<h2>13.3 Coverage Enforcement</h2>
<h3>Thresholds por Proyecto</h3>
<pre><code class="language-yaml"># CÃ³digo REAL de ci-mlops.yml

- name: Run tests with coverage
  working-directory: ${{ matrix.project }}
  run: |
    # Cada proyecto puede tener diferente threshold
    if [ &quot;${{ matrix.project }}&quot; = &quot;BankChurn-Predictor&quot; ]; then
      COV_TARGET=&quot;src&quot;
      THRESHOLD=79
    elif [ &quot;${{ matrix.project }}&quot; = &quot;CarVision-Market-Intelligence&quot; ]; then
      COV_TARGET=&quot;src/carvision&quot;
      THRESHOLD=80
    else
      COV_TARGET=&quot;src/telecom&quot;
      THRESHOLD=80
    fi

    pytest --maxfail=1 --disable-warnings -q \
      -m &quot;not slow&quot; \
      --cov=$COV_TARGET \
      --cov-report=xml \
      --cov-report=term-missing \
      --cov-fail-under=$THRESHOLD  # â† FALLA si estÃ¡ por debajo
</code></pre>
<h3>Upload de Coverage a Codecov</h3>
<pre><code class="language-yaml">- name: Upload coverage to Codecov
  uses: codecov/codecov-action@v5
  with:
    files: ${{ matrix.project }}/coverage.xml
    flags: ${{ matrix.project }}
    name: ${{ matrix.project }}-coverage-${{ matrix.python-version }}
    fail_ci_if_error: false  # No fallar si Codecov tiene problemas

- name: Upload coverage artifact
  uses: actions/upload-artifact@v5
  with:
    name: coverage-${{ matrix.project }}-py${{ matrix.python-version }}
    path: ${{ matrix.project }}/coverage.xml
    retention-days: 30
</code></pre>
<h2>13.4 Security Scanning</h2>
<h3>MÃºltiples Capas de Seguridad</h3>
<pre><code class="language-yaml"># Job de seguridad - CÃ³digo REAL del portafolio

security-scan:
  name: Security Scan
  runs-on: ubuntu-latest
  needs: [tests]  # Solo corre si tests pasan

  steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Necesario para gitleaks (analiza historial)

    # 1. GITLEAKS: Detecta secretos en el cÃ³digo
    - name: Gitleaks (Secret Detection)
      uses: gitleaks/gitleaks-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    # 2. BANDIT: AnÃ¡lisis de seguridad de Python
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - name: Run Bandit
      run: |
        pip install bandit
        for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do
          echo &quot;Scanning $project...&quot;
          bandit -r &quot;$project/src&quot; -f json -o &quot;bandit-$project.json&quot; || true
        done

    # 3. PIP-AUDIT: Vulnerabilidades en dependencias
    - name: Run pip-audit
      run: |
        pip install pip-audit
        for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do
          echo &quot;Auditing $project...&quot;
          pip-audit -r &quot;$project/requirements.txt&quot; --format json || true
        done
</code></pre>
<h3>TRIVY: Escaneo de ImÃ¡genes Docker</h3>
<pre><code class="language-yaml">docker-security:
  name: Docker Security Scan
  runs-on: ubuntu-latest
  needs: [docker-build]

  steps:
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'ml-portfolio-bankchurn:latest'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: 'trivy-results.sarif'
</code></pre>
<h2>13.5 Docker Build y Push</h2>
<h3>Build Multi-Proyecto</h3>
<pre><code class="language-yaml">docker-build:
  name: Docker Build
  runs-on: ubuntu-latest
  needs: [tests, quality-gates]
  if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'

  strategy:
    matrix:
      include:
        - project: BankChurn-Predictor
          image: ml-portfolio-bankchurn
        - project: CarVision-Market-Intelligence
          image: ml-portfolio-carvision
        - project: TelecomAI-Customer-Intelligence
          image: ml-portfolio-telecom

  steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Login to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Build and push
      uses: docker/build-push-action@v5
      with:
        context: ./${{ matrix.project }}
        push: true
        tags: |
          ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:latest
          ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
</code></pre>
<h2>13.6 El Workflow Completo del Portafolio</h2>
<h3>Diagrama del Pipeline</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CI/CD Pipeline: ci-mlops.yml                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  TRIGGER: push to main/develop OR pull_request to main                      â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                         JOB 1: tests                                â”‚    â”‚
â”‚  â”‚  Matrix: Python 3.11/3.12 Ã— 3 proyectos = 6 jobs paralelos          â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  Steps:                                                             â”‚    â”‚
â”‚  â”‚  1. Checkout code                                                   â”‚    â”‚
â”‚  â”‚  2. Setup Python (con cache)                                        â”‚    â”‚
â”‚  â”‚  3. Install dependencies                                            â”‚    â”‚
â”‚  â”‚  4. Run linting (flake8, black, isort)                              â”‚    â”‚
â”‚  â”‚  5. Run tests with coverage                                         â”‚    â”‚
â”‚  â”‚  6. Upload coverage to Codecov                                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                      JOB 2: quality-gates                           â”‚    â”‚
â”‚  â”‚  needs: [tests]                                                     â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  Steps:                                                             â”‚    â”‚
â”‚  â”‚  1. Check Black formatting                                          â”‚    â”‚
â”‚  â”‚  2. Check import sorting (isort)                                    â”‚    â”‚
â”‚  â”‚  3. Run flake8 strict                                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                      JOB 3: security-scan                           â”‚    â”‚
â”‚  â”‚  needs: [tests]                                                     â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  Steps:                                                             â”‚    â”‚
â”‚  â”‚  1. Gitleaks (secretos)                                             â”‚    â”‚
â”‚  â”‚  2. Bandit (cÃ³digo Python)                                          â”‚    â”‚
â”‚  â”‚  3. pip-audit (dependencias)                                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                      JOB 4: docker-build                            â”‚    â”‚
â”‚  â”‚  needs: [tests, quality-gates]                                      â”‚    â”‚
â”‚  â”‚  if: push to main                                                   â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  Steps:                                                             â”‚    â”‚
â”‚  â”‚  1. Setup Docker Buildx                                             â”‚    â”‚
â”‚  â”‚  2. Login to GHCR                                                   â”‚    â”‚
â”‚  â”‚  3. Build multi-stage images                                        â”‚    â”‚
â”‚  â”‚  4. Push to registry                                                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                              â”‚
â”‚                              â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        JOB 5: e2e-test                              â”‚    â”‚
â”‚  â”‚  needs: [docker-build]                                              â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  Steps:                                                             â”‚    â”‚
â”‚  â”‚  1. Start Docker Compose stack                                      â”‚    â”‚
â”‚  â”‚  2. Wait for services                                               â”‚    â”‚
â”‚  â”‚  3. Run API health checks                                           â”‚    â”‚
â”‚  â”‚  4. Run integration tests                                           â”‚    â”‚
â”‚  â”‚  5. Cleanup                                                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>El Archivo Completo</h3>
<pre><code class="language-yaml"># .github/workflows/ci-mlops.yml - VersiÃ³n simplificada del portafolio

name: CI/CD MLOps Portfolio

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

permissions:
  actions: read
  contents: read
  security-events: write
  packages: write

env:
  PYTHON_VERSION: '3.12'

jobs:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 1: Tests con Coverage
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  tests:
    name: Tests &amp; Coverage
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        project:
          - BankChurn-Predictor
          - CarVision-Market-Intelligence
          - TelecomAI-Customer-Intelligence

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        working-directory: ${{ matrix.project }}
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt 2&gt;/dev/null || pip install -e .
          pip install pytest pytest-cov flake8 black isort mypy

      - name: Run linting
        working-directory: ${{ matrix.project }}
        run: |
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics || true
          black --check src/ || true

      - name: Run tests with coverage
        working-directory: ${{ matrix.project }}
        run: |
          # Determinar threshold por proyecto
          if [ &quot;${{ matrix.project }}&quot; = &quot;BankChurn-Predictor&quot; ]; then
            THRESHOLD=79
          else
            THRESHOLD=80
          fi

          pytest -m &quot;not slow&quot; \
            --cov=src/ \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=$THRESHOLD

      - name: Upload coverage
        uses: codecov/codecov-action@v5
        with:
          files: ${{ matrix.project }}/coverage.xml
          flags: ${{ matrix.project }}

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 2: Quality Gates
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    needs: [tests]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install tools
        run: pip install black flake8 isort

      - name: Check formatting
        run: |
          for project in BankChurn-Predictor CarVision-Market-Intelligence TelecomAI-Customer-Intelligence; do
            echo &quot;Checking $project...&quot;
            black --check &quot;$project/src&quot; &quot;$project/app&quot; 2&gt;/dev/null || true
            isort --check-only &quot;$project/src&quot; 2&gt;/dev/null || true
          done

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 3: Security Scan
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: [tests]

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Run Bandit
        run: |
          pip install bandit
          bandit -r */src/ -f json -o bandit-report.json || true

      - name: Upload security report
        uses: actions/upload-artifact@v5
        with:
          name: security-reports
          path: bandit-report.json

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # JOB 4: Docker Build (solo en main)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [tests, quality-gates]
    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'

    strategy:
      matrix:
        include:
          - project: BankChurn-Predictor
            image: ml-portfolio-bankchurn
          - project: CarVision-Market-Intelligence
            image: ml-portfolio-carvision
          - project: TelecomAI-Customer-Intelligence
            image: ml-portfolio-telecom

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.project }}
          push: true
          tags: |
            ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:latest
            ghcr.io/${{ github.repository_owner }}/${{ matrix.image }}:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en CI/CD</h2>
<p>En este mÃ³dulo los problemas suelen venir de <strong>triggers mal configurados</strong>, <strong>rutas incorrectas</strong> o <strong>jobs mal encadenados</strong>.</p>
<h3>1) El workflow no se dispara</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Haces push o abres un PR y GitHub no muestra ningÃºn run nuevo.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa la secciÃ³n <code>on:</code> del workflow:</li>
<li>Â¿Incluye las ramas correctas (<code>main</code>, <code>develop</code>, feature branches)?</li>
<li>Â¿EstÃ¡s haciendo push a una rama no contemplada?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ajusta los triggers a tu flujo real:<br />
<code>yaml
  on:
    push:
      branches: [main, develop, "feature/*"]
    pull_request:
      branches: [main]</code></li>
</ul>
<h3>2) Falla solo en un proyecto o en una versiÃ³n de Python</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En la matrix, solo falla <code>CarVision</code> en Python 3.12, el resto pasa.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Mira los logs filtrando por <code>matrix.project</code> y <code>matrix.python-version</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ejecuta localmente con la misma versiÃ³n de Python y el mismo directorio (<code>working-directory</code>) que en el job.</li>
<li>AsegÃºrate de que los paths (<code>src/</code>, <code>app/</code>, <code>requirements.txt</code>) sean correctos para cada proyecto en la matrix.</li>
</ul>
<h3>3) Coverage o linting no respetan el threshold esperado</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Crees haber configurado <code>--cov-fail-under</code>, pero el job pasa aunque el coverage sea bajo.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica la lÃ­nea exacta del comando <code>pytest</code> en el workflow.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AsegÃºrate de que el parÃ¡metro <code>--cov-fail-under</code> se pase realmente al comando que se ejecuta (no a un alias intermedio).</li>
<li>Diferencia claramente entre thresholds por proyecto usando condiciones <code>if</code> en el script del job.</li>
</ul>
<h3>4) Jobs que fallan por falta de dependencias o rutas</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores como <code>ModuleNotFoundError</code> en CI pero no en local.</li>
<li><code>pip install -r requirements.txt</code> falla porque el archivo no existe en ese directorio.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica el <code>working-directory</code> de cada <code>step</code>.</li>
<li>Revisa la estructura real del repo y compara con las rutas usadas en el workflow.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ajusta <code>working-directory</code> para que apunte al proyecto correcto (<code>BankChurn-Predictor</code>, etc.).</li>
<li>Si un proyecto no tiene <code>requirements.txt</code>, instala en modo editable con <code>pip install -e .</code> como fallback.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en GitHub Actions</h3>
<ol>
<li>Reproduce localmente el comando exacto que falla (<code>pytest</code>, <code>docker build</code>, etc.).</li>
<li>Verifica <code>on:</code> y <code>matrix</code> para asegurarte de que el job se ejecuta en los contextos esperados.</li>
<li>Usa <code>working-directory</code> y rutas relativas coherentes con la estructura del repo.</li>
<li>Encadena bien los jobs usando <code>needs</code> para que la lÃ³gica del pipeline sea clara.</li>
</ol>
<p>Con este enfoque, CI/CD pasa de ser una caja negra â€œque a veces fallaâ€ a un pipeline confiable que te protege al hacer cambios en el portafolio.</p>
<h2>âœ… Ejercicio: Crear Tu Propio Workflow</h2>
<h3>Paso 1: Workflow MÃ­nimo</h3>
<p>Crea <code>.github/workflows/ci.yml</code>:</p>
<pre><code class="language-yaml">name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install pytest
      - run: pytest
</code></pre>
<h3>Paso 2: AÃ±adir Coverage</h3>
<pre><code class="language-yaml">      - run: pip install pytest pytest-cov
      - run: pytest --cov=src/ --cov-fail-under=80
</code></pre>
<h3>Paso 3: AÃ±adir Matrix</h3>
<pre><code class="language-yaml">    strategy:
      matrix:
        python-version: ['3.11', '3.12']
</code></pre>
<h3>Paso 4: AÃ±adir Security</h3>
<p>AÃ±ade un job nuevo con Bandit y Gitleaks.</p>
<h2>âœ… Checkpoint</h2>
<ul>
<li>[ ] Tienes un workflow bÃ¡sico que ejecuta tests</li>
<li>[ ] El workflow usa matrix testing (mÃºltiples versiones Python)</li>
<li>[ ] Coverage estÃ¡ enforced con threshold</li>
<li>[ ] Tienes al menos un scan de seguridad</li>
<li>[ ] Los artifacts se suben correctamente</li>
</ul>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>El portafolio tiene un workflow CI/CD real en <code>.github/workflows/ci-mlops.yml</code>:</p>
<h3>Workflow Real del Portafolio</h3>
<pre><code class="language-yaml"># .github/workflows/ci-mlops.yml (extracto)
name: CI/CD MLOps Portfolio

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        project: [BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence]
        python-version: ['3.10', '3.11']

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          cd ${{ matrix.project }}
          pip install -e &quot;.[dev]&quot;

      - name: Run tests with coverage
        run: |
          cd ${{ matrix.project }}
          pytest tests/ --cov=src/ --cov-fail-under=79
</code></pre>
<h3>Features del CI/CD</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>ImplementaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td>Matrix Testing</td>
<td>3 proyectos Ã— 2 versiones Python</td>
</tr>
<tr>
<td>Coverage Gate</td>
<td><code>--cov-fail-under=79</code></td>
</tr>
<tr>
<td>Security Scan</td>
<td>gitleaks en pre-commit</td>
</tr>
<tr>
<td>Artifacts</td>
<td>Coverage reports</td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Revisa el CI Real</h3>
<pre><code class="language-bash"># 1. Ve el workflow real
cat .github/workflows/ci-mlops.yml

# 2. Simula localmente con act (opcional)
act -j test --matrix project:BankChurn-Predictor

# 3. Ve los runs en GitHub
# https://github.com/DuqueOM/ML-MLOps-Portfolio/actions
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>CI vs CD</strong>: CI = integrar cÃ³digo frecuentemente, CD = desplegar automÃ¡ticamente.</p>
</li>
<li>
<p><strong>GitHub Actions vs Jenkins vs GitLab CI</strong>: Trade-offs de cada uno.</p>
</li>
<li>
<p><strong>ML-specific CI</strong>: Explica cÃ³mo CI para ML incluye validaciÃ³n de datos y modelos.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Secrets</td>
<td>Usa GitHub Secrets, nunca hardcodees</td>
</tr>
<tr>
<td>Caching</td>
<td>Cachea dependencias y datos para velocidad</td>
</tr>
<tr>
<td>ParalelizaciÃ³n</td>
<td>Matriz de tests para mÃºltiples versiones</td>
</tr>
<tr>
<td>Rollback</td>
<td>Siempre ten estrategia de rollback</td>
</tr>
</tbody>
</table>
<h3>Pipeline CI/CD para ML</h3>
<pre><code class="language-yaml">1. Lint + Format (ruff, black)
2. Unit Tests (pytest)
3. Integration Tests
4. Security Scan (gitleaks, bandit)
5. Build Docker Image
6. Model Validation
7. Deploy to Staging
8. Smoke Tests
9. Deploy to Production
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=R8_veQiYBjI">GitHub Actions Tutorial - TechWorld Nana</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://madewithml.com/courses/mlops/cicd/">CI/CD for ML - Made With ML</a></td>
<td style="text-align: left;">Tutorial</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://docs.github.com/en/actions">GitHub Actions</a><br />
- <a href="https://pre-commit.com/">pre-commit</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>CI/CD</strong>: IntegraciÃ³n y despliegue continuo<br />
- <strong>GitHub Actions</strong>: AutomatizaciÃ³n de workflows<br />
- <strong>pre-commit</strong>: Hooks de validaciÃ³n antes de commit</p>
<h2>ğŸ“‹ Plantillas Relacionadas</h2>
<p>Ver <a href="#mod_index">templates/</a> para plantillas listas:<br />
- <a href="templates/ci_github_actions.yml">ci_github_actions.yml</a> â€” Pipeline CI/CD completo<br />
- <a href="templates/ci_template.yml">ci_template.yml</a> â€” VersiÃ³n mÃ­nima para quick start</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 12:<br />
- <strong>12.1</strong>: GitHub Actions workflow bÃ¡sico</p>
            </div>
        
            <!-- MÃ“DULO: 13_DOCKER.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_13_DOCKER" class="cover-title">DOCKER</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>14. Docker Avanzado para ML</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Construir imÃ¡genes Docker optimizadas, seguras y pequeÃ±as como las del portafolio.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  NIVEL 1: Funcional       NIVEL 2: Optimizado      NIVEL 3: Production       â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â•‘
â•‘  FROM python:3.11         Multi-stage build        Distroless/Alpine         â•‘
â•‘  COPY . .                 Slim base                Non-root user             â•‘
â•‘  pip install              Layer caching            CVE scanning              â•‘
â•‘                                                                              â•‘
â•‘  ~1.2GB                   ~400MB                   ~150MB                    â•‘
â•‘  âš ï¸ BÃ¡sica                 âœ… Mejor                  ğŸ›¡ï¸ Hardened            â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#141-dockerfile-bÃ¡sico-vs-optimizado">Dockerfile BÃ¡sico vs Optimizado</a></li>
<li><a href="#142-multi-stage-builds">Multi-Stage Builds</a></li>
<li><a href="#143-mejores-prÃ¡cticas">Mejores PrÃ¡cticas</a></li>
<li><a href="#144-dockerfile-real-del-portafolio">Dockerfile Real del Portafolio</a></li>
<li><a href="#145-docker-compose-para-ml">Docker Compose para ML</a></li>
</ol>
<h2>14.1 Dockerfile BÃ¡sico vs Optimizado</h2>
<h3>âŒ Nivel 1: BÃ¡sico (No usar en producciÃ³n)</h3>
<pre><code class="language-dockerfile"># Dockerfile MALO - Solo para demos rÃ¡pidas
FROM python:3.11

WORKDIR /app
COPY . .

RUN pip install -r requirements.txt

CMD [&quot;python&quot;, &quot;main.py&quot;]

# Problemas:
# - Imagen de ~1.2GB
# - Incluye herramientas de desarrollo innecesarias
# - Cache de pip no aprovechado
# - Corre como root (inseguro)
# - Copia archivos innecesarios (.git, tests, etc.)
</code></pre>
<h3>âœ… Nivel 2: Optimizado</h3>
<pre><code class="language-dockerfile"># Dockerfile MEJOR - Para staging/desarrollo

# 1. Usar slim para reducir tamaÃ±o
FROM python:3.11-slim

# 2. Establecer directorio de trabajo
WORKDIR /app

# 3. Copiar SOLO requirements primero (aprovecha cache)
COPY requirements.txt .

# 4. Instalar dependencias (capa cacheada si requirements no cambia)
RUN pip install --no-cache-dir -r requirements.txt

# 5. Copiar cÃ³digo fuente
COPY src/ ./src/
COPY app/ ./app/
COPY configs/ ./configs/

# 6. Usuario no-root
RUN useradd -m appuser &amp;&amp; chown -R appuser:appuser /app
USER appuser

# 7. Puerto y comando
EXPOSE 8000
CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]

# Mejoras:
# - ~400MB (slim base)
# - Cache de layers optimizado
# - No corre como root
# - Solo archivos necesarios
</code></pre>
<h2>14.2 Multi-Stage Builds</h2>
<h3>El Concepto</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MULTI-STAGE BUILD                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  STAGE 1: Builder                    STAGE 2: Runtime                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â”‚
â”‚  â€¢ Imagen completa                   â€¢ Imagen mÃ­nima                        â”‚
â”‚  â€¢ Compila cÃ³digo                    â€¢ Solo runtime                         â”‚
â”‚  â€¢ Instala dependencias              â€¢ Copia solo binarios                  â”‚
â”‚  â€¢ Genera wheels                     â€¢ Sin compiladores                     â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ python:3.11     â”‚                 â”‚ python:3.11-slim â”‚                   â”‚
â”‚  â”‚ + gcc, make     â”‚                 â”‚                  â”‚                   â”‚
â”‚  â”‚ + pip wheel     â”‚   â”€â”€COPYâ”€â”€â–º     â”‚ + wheels only    â”‚                   â”‚
â”‚  â”‚ = 1.2GB         â”‚                 â”‚ = 150-400MB      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                             â”‚
â”‚  Se DESCARTA                         Se USA en producciÃ³n                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>ImplementaciÃ³n</h3>
<pre><code class="language-dockerfile"># Dockerfile Multi-Stage - Nivel 3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1: Builder - Compila dependencias
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS builder

WORKDIR /build

# Instalar herramientas de compilaciÃ³n (temporales)
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements.txt .

# Crear wheels (binarios precompilados)
RUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2: Runtime - Imagen final mÃ­nima
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS runtime

WORKDIR /app

# Copiar SOLO los wheels del builder
COPY --from=builder /wheels /wheels

# Instalar desde wheels (sin compilaciÃ³n)
RUN pip install --no-cache-dir /wheels/* &amp;&amp; rm -rf /wheels

# Copiar cÃ³digo
COPY src/ ./src/
COPY app/ ./app/
COPY configs/ ./configs/

# Copiar modelo pre-entrenado si existe
COPY artifacts/model.joblib ./artifacts/model.joblib 2&gt;/dev/null || true

# Crear usuario no-root
RUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app
USER appuser

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Exponer puerto
EXPOSE 8000

# Comando de inicio
CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<h2>14.3 Mejores PrÃ¡cticas</h2>
<h3>.dockerignore</h3>
<pre><code class="language-dockerignore"># .dockerignore - Excluir archivos innecesarios

# Git
.git
.gitignore

# Python
__pycache__
*.py[cod]
*.pyo
.pytest_cache
.mypy_cache
.coverage
htmlcov/
.venv/
venv/
*.egg-info/

# IDE
.vscode/
.idea/
*.swp

# Tests (no necesarios en producciÃ³n)
tests/
*_test.py
test_*.py
conftest.py

# DocumentaciÃ³n
docs/
*.md
!README.md

# Datos (montar como volumen, no copiar)
data/
*.csv
*.parquet

# Notebooks
*.ipynb
notebooks/

# Logs y temporales
*.log
logs/
tmp/
</code></pre>
<h3>Layer Caching</h3>
<pre><code class="language-dockerfile"># âŒ MALO: Cualquier cambio en cÃ³digo invalida cache de pip
COPY . .
RUN pip install -r requirements.txt

# âœ… BUENO: requirements separado para aprovechar cache
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY src/ ./src/  # Cambios aquÃ­ NO invalidan pip install
</code></pre>
<h3>Security: Non-Root User</h3>
<pre><code class="language-dockerfile"># Crear usuario con UID especÃ­fico (evita conflictos de permisos)
RUN useradd -m -u 1000 appuser

# Dar permisos al directorio de trabajo
RUN chown -R appuser:appuser /app

# Cambiar a usuario no-root ANTES de CMD
USER appuser

# Ahora el proceso corre como appuser, no como root
</code></pre>
<h2>14.4 Dockerfile Real del Portafolio</h2>
<h3>BankChurn-Predictor/Dockerfile</h3>
<pre><code class="language-dockerfile"># BankChurn-Predictor Production Dockerfile
# Multi-stage build optimizado para ML

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Stage 1: Builder
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS builder

WORKDIR /build

# Dependencias de sistema para compilaciÃ³n
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    gcc \
    python3-dev \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Copiar requirements
COPY requirements.txt .

# Crear wheels
RUN pip wheel --no-cache-dir --wheel-dir /wheels -r requirements.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Stage 2: Runtime
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim

# Labels para metadata
LABEL maintainer=&quot;duqueom@example.com&quot;
LABEL version=&quot;1.0.0&quot;
LABEL description=&quot;BankChurn Predictor API&quot;

WORKDIR /app

# Instalar curl para healthcheck
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends curl \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Instalar dependencias desde wheels
COPY --from=builder /wheels /wheels
RUN pip install --no-cache-dir /wheels/* &amp;&amp; rm -rf /wheels

# Copiar cÃ³digo fuente
COPY src/ ./src/
COPY app/ ./app/
COPY configs/ ./configs/

# Copiar modelo (si existe)
COPY models/ ./models/ 2&gt;/dev/null || mkdir -p ./models

# Crear usuario no-root
RUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app
USER appuser

# Variables de entorno
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PORT=8000

# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=45s --retries=3 \
    CMD curl -f http://localhost:${PORT}/health || exit 1

EXPOSE ${PORT}

CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<h2>14.5 Docker Compose para ML</h2>
<h3>docker-compose.demo.yml (Portafolio)</h3>
<pre><code class="language-yaml"># Docker Compose para demo completa del portafolio
version: &quot;3.8&quot;

services:
  # MLflow Server (central)
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    container_name: mlflow-server
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - mlflow-data:/mlflow
    command: &gt;
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:5000/health&quot;]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - ml-network

  # BankChurn API
  bankchurn:
    build:
      context: ./BankChurn-Predictor
      dockerfile: Dockerfile
    container_name: bankchurn-api
    ports:
      - &quot;8001:8000&quot;
    volumes:
      - ./BankChurn-Predictor/models:/app/models:ro
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - ml-network

  # CarVision API
  carvision:
    build:
      context: ./CarVision-Market-Intelligence
      dockerfile: Dockerfile
    container_name: carvision-api
    ports:
      - &quot;8002:8000&quot;
    volumes:
      - ./CarVision-Market-Intelligence/artifacts:/app/artifacts:ro
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - ml-network

  # TelecomAI API
  telecom:
    build:
      context: ./TelecomAI-Customer-Intelligence
      dockerfile: Dockerfile
    container_name: telecom-api
    ports:
      - &quot;8003:8000&quot;
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - ml-network

volumes:
  mlflow-data:

networks:
  ml-network:
    driver: bridge
</code></pre>
<h3>Comandos Ãštiles</h3>
<pre><code class="language-bash"># Construir todas las imÃ¡genes
docker compose -f docker-compose.demo.yml build

# Iniciar todos los servicios
docker compose -f docker-compose.demo.yml up -d

# Ver logs
docker compose -f docker-compose.demo.yml logs -f bankchurn

# Parar todo
docker compose -f docker-compose.demo.yml down

# Limpiar volÃºmenes tambiÃ©n
docker compose -f docker-compose.demo.yml down -v
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en Docker para ML</h2>
<p>En ML es muy comÃºn tener imÃ¡genes gigantes, problemas de permisos o contenedores que â€œfuncionan en mi mÃ¡quina pero no en producciÃ³nâ€.</p>
<h3>1) ImÃ¡genes demasiado grandes</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li><code>docker images</code> muestra tamaÃ±os &gt; 1GB.</li>
<li>Push/pull al registry tarda mucho o falla por timeout.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara tu Dockerfile con los ejemplos <code>python:3.11</code> vs <code>python:3.11-slim</code> del mÃ³dulo.</li>
<li>Revisa si estÃ¡s copiando todo el repo (<code>COPY . .</code>) sin <code>.dockerignore</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa bases <code>slim</code> y <strong>multi-stage builds</strong>.</li>
<li>AÃ±ade un <code>.dockerignore</code> que excluya datos, notebooks, tests y <code>.venv</code>.</li>
</ul>
<h3>2) Errores de permisos al correr como non-root</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El contenedor arranca pero falla al leer modelos, logs o escribir en directorios.</li>
<li>Mensajes tipo <code>Permission denied: '/app/models/model.joblib'</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica que despuÃ©s de copiar archivos hagas <code>chown</code> al usuario de la app.</li>
<li>Revisa que <code>USER appuser</code> aparezca <strong>despuÃ©s</strong> de ajustar permisos.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AsegÃºrate de:<br />
<code>dockerfile
  RUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app
  USER appuser</code></li>
<li>Monta volÃºmenes con permisos compatibles (por ejemplo, propiedad UID 1000 en host).</li>
</ul>
<h3>3) Modelo o artefactos no encontrados dentro del contenedor</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>La API levanta pero responde 500 porque no encuentra el modelo (<code>FileNotFoundError</code>).</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa las rutas de <code>COPY</code> en el Dockerfile y las rutas que tu cÃ³digo usa (<code>./models</code>, <code>./artifacts</code>).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Copia los artefactos a la ruta esperada o monta un volumen de solo lectura:<br />
  ```yaml<br />
  volumes:<ul>
<li>./BankChurn-Predictor/models:/app/models:ro<br />
  ```</li>
</ul>
</li>
</ul>
<h3>4) Contenedores que arrancan pero el healthcheck falla</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El servicio aparece como "unhealthy" en <code>docker ps</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Examina el <code>HEALTHCHECK</code> y verifica que la URL y puerto sean correctos.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AsegÃºrate de que el endpoint <code>/health</code> exista y escuche en el mismo puerto que expones.</li>
<li>Ajusta tiempos de <code>start-period</code> si el modelo tarda mÃ¡s en cargar.</li>
</ul>
<h3>5) PatrÃ³n general de debugging con Docker</h3>
<ol>
<li>Inspecciona el contenedor en ejecuciÃ³n con <code>docker exec -it &lt;container&gt; /bin/bash</code>.</li>
<li>Navega por <code>/app</code> para verificar que el cÃ³digo, modelos y configs estÃ©n donde esperas.</li>
<li>Comprueba permisos (<code>ls -l</code>) y usuario actual (<code>whoami</code>).</li>
<li>Si la imagen es muy grande, revisa el historial de capas con <code>docker history</code>.</li>
</ol>
<p>Con este enfoque, tus imÃ¡genes Docker serÃ¡n reproducibles, ligeras y listas para producciÃ³n.</p>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Multi-stage builds</strong>: Explica cÃ³mo reducen tamaÃ±o de imagen.</p>
</li>
<li>
<p><strong>Layer caching</strong>: Por quÃ© el orden de instrucciones importa.</p>
</li>
<li>
<p><strong>Security</strong>: No correr como root, no incluir secrets en imagen.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImÃ¡genes grandes</td>
<td>Multi-stage + slim base images</td>
</tr>
<tr>
<td>Secrets</td>
<td>Usa build args o secrets mounting</td>
</tr>
<tr>
<td>Debugging</td>
<td>Usa <code>docker exec -it container bash</code></td>
</tr>
<tr>
<td>ProducciÃ³n</td>
<td>Healthchecks obligatorios</td>
</tr>
</tbody>
</table>
<h3>Dockerfile Optimizado</h3>
<pre><code class="language-dockerfile"># Stage 1: Build
FROM python:3.11-slim AS builder
COPY requirements.txt .
RUN pip wheel --no-cache-dir -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim
COPY --from=builder /wheels /wheels
RUN pip install --no-cache /wheels/*
COPY src/ /app/src/
USER nobody
HEALTHCHECK CMD curl -f http://localhost:8000/health
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=3c-iBn73dDE">Docker Tutorial - TechWorld Nana</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=zpkqNPwEzac">Multi-stage Builds</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://docs.docker.com/build/building/multi-stage/">Docker Multi-stage Builds</a><br />
- <a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Dockerfile Best Practices</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Multi-stage Build</strong>: Separar build de runtime<br />
- <strong>Docker Compose</strong>: Orquestar mÃºltiples contenedores<br />
- <strong>Non-root user</strong>: Seguridad en contenedores</p>
<h2>ğŸ“‹ Plantillas Relacionadas</h2>
<p>Ver <a href="#mod_index">templates/</a> para plantillas listas:<br />
- <a href="templates/Dockerfile">Dockerfile</a> â€” Multi-stage completo para ML APIs<br />
- <a href="templates/Dockerfile_template">Dockerfile_template</a> â€” VersiÃ³n simplificada<br />
- <a href="templates/docker-compose.yml">docker-compose.yml</a> â€” Stack con servicios</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 13:<br />
- <strong>13.1</strong>: Dockerfile multi-stage<br />
- <strong>13.2</strong>: Docker Compose para stack ML</p>
            </div>
        
            <!-- MÃ“DULO: 14_FASTAPI.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_14_FASTAPI" class="cover-title">FASTAPI</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>15. FastAPI para ProducciÃ³n</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Construir APIs de ML robustas, documentadas y production-ready como las del portafolio.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  FastAPI = El framework ideal para ML APIs                                   â•‘
â•‘                                                                              â•‘
â•‘  âœ… Type hints nativos (Pydantic)                                            â•‘
â•‘  âœ… DocumentaciÃ³n automÃ¡tica (Swagger/OpenAPI)                               â•‘
â•‘  âœ… Async support (alto throughput)                                          â•‘
â•‘  âœ… ValidaciÃ³n automÃ¡tica de requests                                        â•‘
â•‘  âœ… Dependency Injection built-in                                            â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#151-estructura-de-una-api-ml">Estructura de una API ML</a></li>
<li><a href="#152-schemas-con-pydantic">Schemas con Pydantic</a></li>
<li><a href="#153-endpoints-de-predicciÃ³n">Endpoints de PredicciÃ³n</a></li>
<li><a href="#154-error-handling">Error Handling</a></li>
<li><a href="#155-cÃ³digo-real-del-portafolio">CÃ³digo Real del Portafolio</a></li>
</ol>
<h2>15.1 Estructura de una API ML</h2>
<h3>AnatomÃ­a TÃ­pica</h3>
<pre><code class="language-python"># app/fastapi_app.py - Estructura profesional

from contextlib import asynccontextmanager
from pathlib import Path

import joblib
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware

from .schemas import PredictionRequest, PredictionResponse, HealthResponse


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LIFECYCLE: Cargar modelo al iniciar
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model = None  # Global para acceso en endpoints

@asynccontextmanager
async def lifespan(app: FastAPI):
    &quot;&quot;&quot;Lifecycle: carga modelo al iniciar, limpia al cerrar.&quot;&quot;&quot;
    global model

    # Startup: cargar modelo
    model_path = Path(&quot;artifacts/model.joblib&quot;)
    if model_path.exists():
        model = joblib.load(model_path)
        print(f&quot;âœ… Modelo cargado: {model_path}&quot;)
    else:
        print(f&quot;âš ï¸ Modelo no encontrado: {model_path}&quot;)

    yield  # App corriendo

    # Shutdown: limpiar recursos
    model = None
    print(&quot;ğŸ›‘ App cerrada&quot;)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APP SETUP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = FastAPI(
    title=&quot;BankChurn Predictor API&quot;,
    description=&quot;API para predicciÃ³n de churn de clientes bancarios&quot;,
    version=&quot;1.0.0&quot;,
    lifespan=lifespan,
)

# CORS para permitir requests desde frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=[&quot;*&quot;],  # En prod: especificar dominios
    allow_credentials=True,
    allow_methods=[&quot;*&quot;],
    allow_headers=[&quot;*&quot;],
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENDPOINTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get(&quot;/health&quot;, response_model=HealthResponse)
async def health_check():
    &quot;&quot;&quot;Health check endpoint para load balancers/k8s.&quot;&quot;&quot;
    return HealthResponse(
        status=&quot;healthy&quot; if model is not None else &quot;degraded&quot;,
        model_loaded=model is not None,
        version=&quot;1.0.0&quot;
    )


@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    &quot;&quot;&quot;Predice probabilidad de churn para un cliente.&quot;&quot;&quot;
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Modelo no disponible&quot;)

    # Convertir request a DataFrame
    import pandas as pd
    df = pd.DataFrame([request.dict()])

    # Predecir
    proba = model.predict_proba(df)[0, 1]
    prediction = int(proba &gt;= 0.5)

    return PredictionResponse(
        prediction=prediction,
        probability=round(proba, 4),
        risk_level=&quot;high&quot; if proba &gt;= 0.7 else &quot;medium&quot; if proba &gt;= 0.3 else &quot;low&quot;
    )
</code></pre>
<h2>15.2 Schemas con Pydantic</h2>
<h3>Request/Response Models</h3>
<pre><code class="language-python"># app/schemas.py

from typing import Literal, Optional
from pydantic import BaseModel, Field, validator


class PredictionRequest(BaseModel):
    &quot;&quot;&quot;Schema para request de predicciÃ³n.

    Pydantic valida automÃ¡ticamente:
    - Tipos correctos
    - Rangos vÃ¡lidos
    - Valores permitidos
    &quot;&quot;&quot;

    CreditScore: int = Field(..., ge=300, le=850, description=&quot;Credit score del cliente&quot;)
    Geography: Literal[&quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;] = Field(..., description=&quot;PaÃ­s&quot;)
    Gender: Literal[&quot;Male&quot;, &quot;Female&quot;] = Field(..., description=&quot;GÃ©nero&quot;)
    Age: int = Field(..., ge=18, le=100, description=&quot;Edad&quot;)
    Tenure: int = Field(..., ge=0, le=10, description=&quot;AÃ±os como cliente&quot;)
    Balance: float = Field(..., ge=0, description=&quot;Balance en cuenta&quot;)
    NumOfProducts: int = Field(..., ge=1, le=4, description=&quot;NÃºmero de productos&quot;)
    HasCrCard: Literal[0, 1] = Field(..., description=&quot;Tiene tarjeta de crÃ©dito&quot;)
    IsActiveMember: Literal[0, 1] = Field(..., description=&quot;Es miembro activo&quot;)
    EstimatedSalary: float = Field(..., ge=0, description=&quot;Salario estimado&quot;)

    class Config:
        json_schema_extra = {
            &quot;example&quot;: {
                &quot;CreditScore&quot;: 650,
                &quot;Geography&quot;: &quot;France&quot;,
                &quot;Gender&quot;: &quot;Female&quot;,
                &quot;Age&quot;: 40,
                &quot;Tenure&quot;: 3,
                &quot;Balance&quot;: 60000.0,
                &quot;NumOfProducts&quot;: 2,
                &quot;HasCrCard&quot;: 1,
                &quot;IsActiveMember&quot;: 1,
                &quot;EstimatedSalary&quot;: 50000.0
            }
        }


class PredictionResponse(BaseModel):
    &quot;&quot;&quot;Schema para response de predicciÃ³n.&quot;&quot;&quot;

    prediction: Literal[0, 1] = Field(..., description=&quot;0=No churn, 1=Churn&quot;)
    probability: float = Field(..., ge=0, le=1, description=&quot;Probabilidad de churn&quot;)
    risk_level: Literal[&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;] = Field(..., description=&quot;Nivel de riesgo&quot;)


class HealthResponse(BaseModel):
    &quot;&quot;&quot;Schema para health check.&quot;&quot;&quot;

    status: Literal[&quot;healthy&quot;, &quot;degraded&quot;, &quot;unhealthy&quot;]
    model_loaded: bool
    version: str


class BatchPredictionRequest(BaseModel):
    &quot;&quot;&quot;Schema para predicciÃ³n en batch.&quot;&quot;&quot;

    customers: list[PredictionRequest] = Field(
        ..., 
        min_items=1, 
        max_items=1000,
        description=&quot;Lista de clientes (mÃ¡x 1000)&quot;
    )


class BatchPredictionResponse(BaseModel):
    &quot;&quot;&quot;Schema para response de batch.&quot;&quot;&quot;

    predictions: list[PredictionResponse]
    processed: int
    errors: int = 0
</code></pre>
<h2>15.3 Endpoints de PredicciÃ³n</h2>
<h3>Single Prediction</h3>
<pre><code class="language-python">@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    &quot;&quot;&quot;
    Predice probabilidad de churn para UN cliente.

    - **CreditScore**: Score crediticio (300-850)
    - **Geography**: PaÃ­s (France, Germany, Spain)
    - **Gender**: GÃ©nero
    - **Age**: Edad (18-100)
    - ... etc

    Returns:
    - **prediction**: 0 (no churn) o 1 (churn)
    - **probability**: Probabilidad [0, 1]
    - **risk_level**: low/medium/high
    &quot;&quot;&quot;
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail=&quot;Modelo no disponible. Reinicie el servicio.&quot;
        )

    try:
        import pandas as pd
        df = pd.DataFrame([request.model_dump()])

        proba = model.predict_proba(df)[0, 1]
        prediction = int(proba &gt;= 0.5)

        if proba &gt;= 0.7:
            risk = &quot;high&quot;
        elif proba &gt;= 0.3:
            risk = &quot;medium&quot;
        else:
            risk = &quot;low&quot;

        return PredictionResponse(
            prediction=prediction,
            probability=round(float(proba), 4),
            risk_level=risk
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f&quot;Error en predicciÃ³n: {str(e)}&quot;)
</code></pre>
<h3>Batch Prediction</h3>
<pre><code class="language-python">@app.post(&quot;/predict/batch&quot;, response_model=BatchPredictionResponse)
async def predict_batch(request: BatchPredictionRequest):
    &quot;&quot;&quot;
    Predice churn para mÃºltiples clientes (mÃ¡x 1000).

    Ãštil para scoring masivo de cartera.
    &quot;&quot;&quot;
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Modelo no disponible&quot;)

    import pandas as pd

    results = []
    errors = 0

    # Convertir todos los requests a DataFrame (mÃ¡s eficiente)
    data = [c.model_dump() for c in request.customers]
    df = pd.DataFrame(data)

    try:
        probas = model.predict_proba(df)[:, 1]

        for proba in probas:
            prediction = int(proba &gt;= 0.5)
            risk = &quot;high&quot; if proba &gt;= 0.7 else &quot;medium&quot; if proba &gt;= 0.3 else &quot;low&quot;

            results.append(PredictionResponse(
                prediction=prediction,
                probability=round(float(proba), 4),
                risk_level=risk
            ))

    except Exception as e:
        raise HTTPException(status_code=500, detail=f&quot;Error en batch: {str(e)}&quot;)

    return BatchPredictionResponse(
        predictions=results,
        processed=len(results),
        errors=errors
    )
</code></pre>
<h2>15.4 Error Handling</h2>
<h3>Custom Exception Handlers</h3>
<pre><code class="language-python">from fastapi import Request
from fastapi.responses import JSONResponse

class ModelNotLoadedError(Exception):
    &quot;&quot;&quot;Modelo no cargado.&quot;&quot;&quot;
    pass

class InvalidInputError(Exception):
    &quot;&quot;&quot;Input invÃ¡lido.&quot;&quot;&quot;
    pass


@app.exception_handler(ModelNotLoadedError)
async def model_not_loaded_handler(request: Request, exc: ModelNotLoadedError):
    return JSONResponse(
        status_code=503,
        content={
            &quot;error&quot;: &quot;service_unavailable&quot;,
            &quot;message&quot;: &quot;El modelo no estÃ¡ cargado. Intente mÃ¡s tarde.&quot;,
            &quot;retry_after&quot;: 30
        }
    )


@app.exception_handler(InvalidInputError)
async def invalid_input_handler(request: Request, exc: InvalidInputError):
    return JSONResponse(
        status_code=400,
        content={
            &quot;error&quot;: &quot;invalid_input&quot;,
            &quot;message&quot;: str(exc),
            &quot;hint&quot;: &quot;Verifique que todos los campos tengan valores vÃ¡lidos&quot;
        }
    )


# Catch-all para errores no manejados
@app.exception_handler(Exception)
async def generic_exception_handler(request: Request, exc: Exception):
    return JSONResponse(
        status_code=500,
        content={
            &quot;error&quot;: &quot;internal_error&quot;,
            &quot;message&quot;: &quot;Error interno del servidor&quot;,
            &quot;detail&quot;: str(exc) if app.debug else None
        }
    )
</code></pre>
<h2>15.5 CÃ³digo Real del Portafolio</h2>
<h3>app/fastapi_app.py (BankChurn - Simplificado)</h3>
<pre><code class="language-python">&quot;&quot;&quot;FastAPI application for BankChurn prediction service.&quot;&quot;&quot;

from __future__ import annotations

import logging
import os
from contextlib import asynccontextmanager
from pathlib import Path
from typing import Literal

import joblib
import pandas as pd
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SCHEMAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CustomerInput(BaseModel):
    CreditScore: int = Field(..., ge=300, le=850)
    Geography: str
    Gender: str
    Age: int = Field(..., ge=18, le=100)
    Tenure: int = Field(..., ge=0, le=10)
    Balance: float = Field(..., ge=0)
    NumOfProducts: int = Field(..., ge=1, le=4)
    HasCrCard: int = Field(..., ge=0, le=1)
    IsActiveMember: int = Field(..., ge=0, le=1)
    EstimatedSalary: float = Field(..., ge=0)


class PredictionOutput(BaseModel):
    prediction: int
    probability: float
    risk_level: str


class HealthOutput(BaseModel):
    status: str
    model_loaded: bool


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

model = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global model

    # Buscar modelo en varias ubicaciones
    paths = [
        Path(&quot;models/model_v1.0.0.pkl&quot;),
        Path(&quot;artifacts/model.joblib&quot;),
        Path(os.getenv(&quot;MODEL_PATH&quot;, &quot;model.joblib&quot;)),
    ]

    for path in paths:
        if path.exists():
            model = joblib.load(path)
            logger.info(f&quot;Modelo cargado: {path}&quot;)
            break

    if model is None:
        logger.warning(&quot;âš ï¸ NingÃºn modelo encontrado&quot;)

    yield
    model = None


app = FastAPI(
    title=&quot;BankChurn Predictor&quot;,
    version=&quot;1.0.0&quot;,
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=[&quot;*&quot;],
    allow_methods=[&quot;*&quot;],
    allow_headers=[&quot;*&quot;],
)


@app.get(&quot;/health&quot;, response_model=HealthOutput)
async def health():
    return HealthOutput(
        status=&quot;healthy&quot; if model else &quot;degraded&quot;,
        model_loaded=model is not None
    )


@app.post(&quot;/predict&quot;, response_model=PredictionOutput)
async def predict(customer: CustomerInput):
    if model is None:
        raise HTTPException(503, &quot;Modelo no disponible&quot;)

    df = pd.DataFrame([customer.model_dump()])
    proba = model.predict_proba(df)[0, 1]

    return PredictionOutput(
        prediction=int(proba &gt;= 0.5),
        probability=round(proba, 4),
        risk_level=&quot;high&quot; if proba &gt;= 0.7 else &quot;medium&quot; if proba &gt;= 0.3 else &quot;low&quot;
    )


if __name__ == &quot;__main__&quot;:
    import uvicorn
    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en FastAPI para ML</h2>
<p>FastAPI te da mucho â€œgratisâ€, pero en APIs de ML los fallos suelen venir de modelos no cargados, esquemas desalineados o problemas de tipos/serializaciÃ³n.</p>
<h3>1) El modelo no se carga (503 constantes)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El endpoint <code>/predict</code> responde <code>503 Modelo no disponible</code>.</li>
<li>Logs con mensajes tipo <code>Modelo no encontrado</code> o <code>NingÃºn modelo encontrado</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa la funciÃ³n <code>lifespan</code> o cÃ³digo de startup: Â¿la ruta del modelo (<code>models/</code>, <code>artifacts/</code>) existe dentro del contenedor?</li>
<li>Comprueba variables de entorno como <code>MODEL_PATH</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura rutas consistentes entre entrenamiento, Dockerfile y FastAPI.</li>
<li>En local, imprime (<code>logger.info</code>) la ruta exacta desde la que intentas cargar y verifica que el archivo estÃ© ahÃ­.</li>
</ul>
<h3>2) Esquema Pydantic desalineado con el pipeline</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores <code>KeyError</code> o <code>Column not found</code> al predecir.</li>
<li>El modelo espera columnas con ciertos nombres pero el <code>PredictionRequest</code> usa otros.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara los campos del schema (<code>CreditScore</code>, <code>Geography</code>, etc.) con las columnas que el pipeline de sklearn espera.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa los <strong>mismos nombres de features</strong> que en el training pipeline.</li>
<li>Si renombraste columnas en feature engineering, refleja esos cambios en el schema y en la transformaciÃ³n de entrada antes de llamar al modelo.</li>
</ul>
<h3>3) Problemas de tipos y serializaciÃ³n</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores <code>TypeError: Object of type ... is not JSON serializable</code>.</li>
<li>Respuestas con valores <code>NaN</code> o <code>Infinity</code> que rompen el cliente.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa el tipo real de lo que devuelves en <code>PredictionResponse</code> (por ejemplo, <code>numpy.float32</code> en vez de <code>float</code>).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Convierte explÃ­citamente a tipos nativos de Python (<code>float</code>, <code>int</code>, <code>str</code>).</li>
<li>AsegÃºrate de que no devuelves <code>NaN</code> o <code>inf</code> (redondea o reemplaza por valores vÃ¡lidos).</li>
</ul>
<h3>4) CORS o healthcheck mal configurados</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El frontend no puede llamar al API por errores de CORS.</li>
<li>Kubernetes/Compose marcan el servicio como unhealthy.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa configuraciÃ³n de <code>CORSMiddleware</code> y el endpoint <code>/health</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>En desarrollo puedes usar <code>allow_origins=["*"]</code>, pero en producciÃ³n limita a tus dominios.</li>
<li>Verifica que <code>/health</code> no dependa de modelos pesados para responder rÃ¡pido y con 200.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en APIs de ML</h3>
<ol>
<li>Llama al endpoint con <code>curl</code> o <code>httpie</code> usando el <code>example</code> del schema.</li>
<li>Mira los logs del servidor (uvicorn) para ver tracebacks completos.</li>
<li>Verifica rutas de modelo y variables de entorno que afectan al loading.</li>
<li>AsegÃºrate de que lo que entra/sale del API coincide con lo que tu modelo entrenado espera.</li>
</ol>
<p>Con esta disciplina, tu API FastAPI pasarÃ¡ de â€œfunciona solo en localâ€ a estar lista para producciÃ³n.</p>
<h2>âœ… Ejercicio</h2>
<ol>
<li>Implementa <code>/predict/batch</code> para procesar mÃºltiples clientes</li>
<li>AÃ±ade endpoint <code>/model/info</code> que retorne metadata del modelo</li>
<li>Implementa rate limiting bÃ¡sico</li>
</ol>
<h2>ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio</h2>
<p>Cada proyecto tiene una API FastAPI en <code>app/fastapi_app.py</code>:</p>
<h3>API de BankChurn</h3>
<pre><code class="language-python"># BankChurn-Predictor/app/fastapi_app.py (estructura)
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

app = FastAPI(title=&quot;BankChurn Predictor API&quot;)

class PredictionRequest(BaseModel):
    CreditScore: int
    Geography: str
    Gender: str
    Age: int
    Balance: float
    # ... mÃ¡s features

class PredictionResponse(BaseModel):
    prediction: int
    probability: float
    risk_level: str

@app.get(&quot;/health&quot;)
async def health():
    return {&quot;status&quot;: &quot;healthy&quot;, &quot;model_loaded&quot;: model is not None}

@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    features = request.dict()
    df = pd.DataFrame([features])
    prediction = pipeline.predict(df)[0]
    probability = pipeline.predict_proba(df)[0, 1]
    return PredictionResponse(
        prediction=int(prediction),
        probability=float(probability),
        risk_level=&quot;high&quot; if probability &gt; 0.7 else &quot;low&quot;
    )
</code></pre>
<h3>APIs por Proyecto</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>Endpoint Principal</th>
<th>Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td><code>/predict</code></td>
<td>ClasificaciÃ³n binaria</td>
</tr>
<tr>
<td>CarVision</td>
<td><code>/predict</code></td>
<td>RegresiÃ³n</td>
</tr>
<tr>
<td>TelecomAI</td>
<td><code>/predict</code></td>
<td>ClasificaciÃ³n multiclase</td>
</tr>
</tbody>
</table>
<h3>ğŸ”§ Ejercicio: Prueba las APIs Reales</h3>
<pre><code class="language-bash"># 1. Inicia API de BankChurn
cd BankChurn-Predictor
uvicorn app.fastapi_app:app --reload

# 2. Prueba con curl
curl http://localhost:8000/health

curl -X POST http://localhost:8000/predict \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;CreditScore&quot;: 650, &quot;Geography&quot;: &quot;France&quot;, ...}'

# 3. Ve docs interactivos
# http://localhost:8000/docs
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Pydantic + FastAPI</strong>: Explica cÃ³mo la validaciÃ³n automÃ¡tica reduce cÃ³digo.</p>
</li>
<li>
<p><strong>Async vs Sync</strong>: CuÃ¡ndo usar cada uno (IO-bound vs CPU-bound).</p>
</li>
<li>
<p><strong>OpenAPI/Swagger</strong>: DocumentaciÃ³n automÃ¡tica como feature de FastAPI.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>ML Serving</td>
<td>Carga modelo en startup, no en cada request</td>
</tr>
<tr>
<td>ValidaciÃ³n</td>
<td>Usa Pydantic para input/output schemas</td>
</tr>
<tr>
<td>Errores</td>
<td>HTTPException con cÃ³digos y mensajes claros</td>
</tr>
<tr>
<td>ProducciÃ³n</td>
<td>Gunicorn + Uvicorn workers</td>
</tr>
</tbody>
</table>
<h3>Endpoints Esenciales para ML</h3>
<pre><code class="language-python">/health          â†’ Liveness check
/ready           â†’ Readiness check (modelo cargado)
/predict         â†’ Inferencia principal
/predict/batch   â†’ Inferencia batch
/model/info      â†’ VersiÃ³n, mÃ©tricas, metadata
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=0sOvCWFmrtA">FastAPI Tutorial - SebastiÃ¡n RamÃ­rez</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=kBIX3_cMHzE">ML APIs with FastAPI</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://fastapi.tiangolo.com/">FastAPI Documentation</a><br />
- <a href="https://docs.pydantic.dev/latest/">Pydantic v2</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>FastAPI</strong>: Framework web async para APIs<br />
- <strong>Pydantic</strong>: ValidaciÃ³n de datos con type hints<br />
- <strong>OpenAPI</strong>: EspecificaciÃ³n de APIs (Swagger)</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 14:<br />
- <strong>14.1</strong>: Schemas Pydantic para request/response<br />
- <strong>14.2</strong>: Endpoint de predicciÃ³n completo</p>
            </div>
        
            <!-- MÃ“DULO: 15_STREAMLIT.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_15_STREAMLIT" class="cover-title">STREAMLIT</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>16. Streamlit Dashboards para ML</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Construir dashboards interactivos profesionales como el de CarVision.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  Streamlit = La forma mÃ¡s rÃ¡pida de crear UIs para ML                        â•‘
â•‘                                                                              â•‘
â•‘  âœ… Python puro (sin HTML/CSS/JS)                                            â•‘
â•‘  âœ… Reactivo (cambios automÃ¡ticos)                                           â•‘
â•‘  âœ… Widgets interactivos                                                     â•‘
â•‘  âœ… IntegraciÃ³n con pandas/plotly                                            â•‘
â•‘  âœ… Deploy fÃ¡cil                                                             â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#161-estructura-de-un-dashboard-ml">Estructura de un Dashboard ML</a></li>
<li><a href="#162-caching-para-performance">Caching para Performance</a></li>
<li><a href="#163-tabs-y-secciones">Tabs y Secciones</a></li>
<li><a href="#164-visualizaciones-con-plotly">Visualizaciones con Plotly</a></li>
<li><a href="#165-predictor-interactivo">Predictor Interactivo</a></li>
</ol>
<h2>16.1 Estructura de un Dashboard ML</h2>
<h3>Arquitectura del Dashboard CarVision</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CarVision Dashboard                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Overview   â”‚ â”‚   Market    â”‚ â”‚   Model     â”‚ â”‚    Price    â”‚            â”‚
â”‚  â”‚   (KPIs)    â”‚ â”‚  Analysis   â”‚ â”‚  Metrics    â”‚ â”‚  Predictor  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                             â”‚
â”‚  TAB 1: Overview                TAB 2: Market Analysis                      â”‚
â”‚  â€¢ Total vehicles               â€¢ Investment recommendations                â”‚
â”‚  â€¢ Average price                â€¢ Risk assessment                           â”‚
â”‚  â€¢ Price distribution           â€¢ Market trends                             â”‚
â”‚                                                                             â”‚
â”‚  TAB 3: Model Metrics           TAB 4: Price Predictor                      â”‚
â”‚  â€¢ RMSE, MAE, RÂ², MAPE         â€¢ Input form                                 â”‚
â”‚  â€¢ Bootstrap confidence         â€¢ Single prediction                         â”‚
â”‚  â€¢ Temporal backtest            â€¢ Gauge visualization                       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>CÃ³digo Base</h3>
<pre><code class="language-python"># app/streamlit_app.py - Estructura bÃ¡sica

import streamlit as st
import pandas as pd
import joblib
from pathlib import Path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PAGE CONFIG (debe ser la primera llamada Streamlit)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.set_page_config(
    page_title=&quot;CarVision Market Intelligence&quot;,
    page_icon=&quot;ğŸš—&quot;,
    layout=&quot;wide&quot;,
    initial_sidebar_state=&quot;expanded&quot;
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CACHING: Cargar datos y modelo UNA vez
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data  # Cache para datos (inmutables)
def load_data():
    &quot;&quot;&quot;Carga dataset - cached para performance.&quot;&quot;&quot;
    path = Path(&quot;data/raw/vehicles_us.csv&quot;)
    if path.exists():
        return pd.read_csv(path)
    return None


@st.cache_resource  # Cache para recursos (modelo, conexiones)
def load_model():
    &quot;&quot;&quot;Carga modelo - cached para no recargar en cada interacciÃ³n.&quot;&quot;&quot;
    path = Path(&quot;artifacts/model.joblib&quot;)
    if path.exists():
        return joblib.load(path)
    return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN APP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    st.title(&quot;ï¿½ï¿½ CarVision Market Intelligence&quot;)
    st.markdown(&quot;*AnÃ¡lisis de mercado y predicciÃ³n de precios de vehÃ­culos*&quot;)

    # Cargar datos
    df = load_data()
    model = load_model()

    if df is None:
        st.error(&quot;âŒ No se encontrÃ³ el dataset&quot;)
        return

    # Tabs para organizar contenido
    tab1, tab2, tab3, tab4 = st.tabs([
        &quot;ğŸ“Š Overview&quot;,
        &quot;ğŸ“ˆ Market Analysis&quot;, 
        &quot;ğŸ¯ Model Metrics&quot;,
        &quot;ğŸ’° Price Predictor&quot;
    ])

    with tab1:
        render_overview(df)

    with tab2:
        render_market_analysis(df)

    with tab3:
        render_model_metrics()

    with tab4:
        render_price_predictor(model, df)


if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h2>16.2 Caching para Performance</h2>
<h3>@st.cache_data vs @st.cache_resource</h3>
<pre><code class="language-python"># @st.cache_data: Para DATOS (DataFrames, listas, dicts)
# Se serializa y almacena. Inmutable.

@st.cache_data(ttl=3600)  # TTL: 1 hora
def load_data():
    df = pd.read_csv(&quot;data.csv&quot;)
    return df

@st.cache_data
def compute_statistics(df):
    &quot;&quot;&quot;CÃ¡lculos pesados - cached.&quot;&quot;&quot;
    return {
        &quot;mean&quot;: df[&quot;price&quot;].mean(),
        &quot;median&quot;: df[&quot;price&quot;].median(),
        &quot;std&quot;: df[&quot;price&quot;].std(),
    }


# @st.cache_resource: Para RECURSOS (modelos, conexiones DB)
# No se serializa. Se mantiene la referencia.

@st.cache_resource
def load_model():
    return joblib.load(&quot;model.joblib&quot;)

@st.cache_resource
def get_db_connection():
    return create_engine(&quot;postgresql://...&quot;)
</code></pre>
<h3>PatrÃ³n: Separar Carga de VisualizaciÃ³n</h3>
<pre><code class="language-python"># âŒ MALO: Carga datos cada vez que cambia un widget
def main():
    filter_year = st.slider(&quot;AÃ±o&quot;, 2010, 2024)
    df = pd.read_csv(&quot;data.csv&quot;)  # Se ejecuta en cada interacciÃ³n!
    filtered = df[df[&quot;year&quot;] &gt;= filter_year]
    st.dataframe(filtered)


# âœ… BUENO: Datos cargados una vez, filtrado es rÃ¡pido
@st.cache_data
def load_data():
    return pd.read_csv(&quot;data.csv&quot;)

def main():
    df = load_data()  # Cached - instantÃ¡neo despuÃ©s de la primera carga

    filter_year = st.slider(&quot;AÃ±o&quot;, 2010, 2024)
    filtered = df[df[&quot;year&quot;] &gt;= filter_year]  # OperaciÃ³n rÃ¡pida en memoria
    st.dataframe(filtered)
</code></pre>
<h2>16.3 Tabs y Secciones</h2>
<h3>Tab 1: Overview</h3>
<pre><code class="language-python">def render_overview(df: pd.DataFrame):
    &quot;&quot;&quot;Tab de resumen con KPIs principales.&quot;&quot;&quot;

    st.header(&quot;ğŸ“Š Portfolio Overview&quot;)

    # KPIs en columnas
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label=&quot;Total Vehicles&quot;,
            value=f&quot;{len(df):,}&quot;,
            delta=None
        )

    with col2:
        avg_price = df[&quot;price&quot;].mean()
        st.metric(
            label=&quot;Average Price&quot;,
            value=f&quot;${avg_price:,.0f}&quot;,
            delta=None
        )

    with col3:
        median_price = df[&quot;price&quot;].median()
        st.metric(
            label=&quot;Median Price&quot;,
            value=f&quot;${median_price:,.0f}&quot;,
            delta=f&quot;{((avg_price - median_price) / median_price * 100):+.1f}% vs avg&quot;
        )

    with col4:
        avg_age = 2024 - df[&quot;model_year&quot;].mean()
        st.metric(
            label=&quot;Avg Vehicle Age&quot;,
            value=f&quot;{avg_age:.1f} years&quot;,
            delta=None
        )

    st.divider()

    # DistribuciÃ³n de precios
    st.subheader(&quot;Price Distribution&quot;)

    import plotly.express as px
    fig = px.histogram(
        df, 
        x=&quot;price&quot;, 
        nbins=50,
        title=&quot;Vehicle Price Distribution&quot;
    )
    fig.update_layout(
        xaxis_title=&quot;Price ($)&quot;,
        yaxis_title=&quot;Count&quot;
    )
    st.plotly_chart(fig, use_container_width=True)
</code></pre>
<h3>Tab 3: Model Metrics</h3>
<pre><code class="language-python">def render_model_metrics():
    &quot;&quot;&quot;Tab de mÃ©tricas del modelo.&quot;&quot;&quot;

    st.header(&quot;ğŸ¯ Model Performance&quot;)

    # Cargar mÃ©tricas
    metrics_path = Path(&quot;artifacts/metrics.json&quot;)
    if not metrics_path.exists():
        st.warning(&quot;âš ï¸ MÃ©tricas no disponibles. Entrene el modelo primero.&quot;)
        return

    import json
    metrics = json.loads(metrics_path.read_text())

    # Mostrar mÃ©tricas principales
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(&quot;RMSE&quot;, f&quot;${metrics['rmse']:,.0f}&quot;)
    with col2:
        st.metric(&quot;MAE&quot;, f&quot;${metrics['mae']:,.0f}&quot;)
    with col3:
        st.metric(&quot;RÂ²&quot;, f&quot;{metrics['r2']:.3f}&quot;)
    with col4:
        st.metric(&quot;MAPE&quot;, f&quot;{metrics['mape']:.1f}%&quot;)

    # ExplicaciÃ³n de mÃ©tricas
    with st.expander(&quot;â„¹ï¸ Â¿QuÃ© significan estas mÃ©tricas?&quot;):
        st.markdown(&quot;&quot;&quot;
        - **RMSE** (Root Mean Square Error): Error promedio en dÃ³lares. Menor es mejor.
        - **MAE** (Mean Absolute Error): Error absoluto promedio. MÃ¡s interpretable que RMSE.
        - **RÂ²** (Coefficient of Determination): % de varianza explicada. 1.0 es perfecto.
        - **MAPE** (Mean Absolute Percentage Error): Error porcentual promedio.
        &quot;&quot;&quot;)
</code></pre>
<h2>16.4 Visualizaciones con Plotly</h2>
<h3>GrÃ¡ficos Interactivos</h3>
<pre><code class="language-python">import plotly.express as px
import plotly.graph_objects as go

def create_price_by_brand(df: pd.DataFrame):
    &quot;&quot;&quot;Box plot de precios por marca.&quot;&quot;&quot;

    # Top 10 marcas por volumen
    top_brands = df[&quot;brand&quot;].value_counts().head(10).index
    df_top = df[df[&quot;brand&quot;].isin(top_brands)]

    fig = px.box(
        df_top,
        x=&quot;brand&quot;,
        y=&quot;price&quot;,
        title=&quot;Price Distribution by Brand (Top 10)&quot;,
        color=&quot;brand&quot;
    )

    fig.update_layout(
        xaxis_title=&quot;Brand&quot;,
        yaxis_title=&quot;Price ($)&quot;,
        showlegend=False
    )

    return fig


def create_price_gauge(predicted_price: float, min_price: float, max_price: float):
    &quot;&quot;&quot;Gauge para mostrar predicciÃ³n de precio.&quot;&quot;&quot;

    fig = go.Figure(go.Indicator(
        mode=&quot;gauge+number+delta&quot;,
        value=predicted_price,
        domain={&quot;x&quot;: [0, 1], &quot;y&quot;: [0, 1]},
        title={&quot;text&quot;: &quot;Predicted Price&quot;, &quot;font&quot;: {&quot;size&quot;: 24}},
        number={&quot;prefix&quot;: &quot;$&quot;, &quot;font&quot;: {&quot;size&quot;: 40}},
        gauge={
            &quot;axis&quot;: {&quot;range&quot;: [min_price, max_price], &quot;tickprefix&quot;: &quot;$&quot;},
            &quot;bar&quot;: {&quot;color&quot;: &quot;darkblue&quot;},
            &quot;steps&quot;: [
                {&quot;range&quot;: [min_price, min_price + (max_price-min_price)*0.33], &quot;color&quot;: &quot;lightgreen&quot;},
                {&quot;range&quot;: [min_price + (max_price-min_price)*0.33, min_price + (max_price-min_price)*0.66], &quot;color&quot;: &quot;yellow&quot;},
                {&quot;range&quot;: [min_price + (max_price-min_price)*0.66, max_price], &quot;color&quot;: &quot;salmon&quot;},
            ],
            &quot;threshold&quot;: {
                &quot;line&quot;: {&quot;color&quot;: &quot;red&quot;, &quot;width&quot;: 4},
                &quot;thickness&quot;: 0.75,
                &quot;value&quot;: predicted_price
            }
        }
    ))

    fig.update_layout(height=300)
    return fig
</code></pre>
<h2>16.5 Predictor Interactivo</h2>
<h3>Tab 4: Price Predictor</h3>
<pre><code class="language-python">def render_price_predictor(model, df: pd.DataFrame):
    &quot;&quot;&quot;Tab de predicciÃ³n interactiva de precios.&quot;&quot;&quot;

    st.header(&quot;ğŸ’° Price Predictor&quot;)

    if model is None:
        st.error(&quot;âŒ Modelo no cargado. Entrene el modelo primero.&quot;)
        return

    st.markdown(&quot;Ingrese las caracterÃ­sticas del vehÃ­culo para obtener una estimaciÃ³n de precio.&quot;)

    # Form para inputs
    with st.form(&quot;prediction_form&quot;):
        col1, col2 = st.columns(2)

        with col1:
            model_year = st.number_input(
                &quot;Model Year&quot;,
                min_value=1990,
                max_value=2024,
                value=2018,
                help=&quot;AÃ±o del modelo del vehÃ­culo&quot;
            )

            odometer = st.number_input(
                &quot;Odometer (miles)&quot;,
                min_value=0,
                max_value=500000,
                value=50000,
                step=1000,
                help=&quot;Millaje del vehÃ­culo&quot;
            )

            # Obtener opciones Ãºnicas del dataset
            models = sorted(df[&quot;model&quot;].dropna().unique())
            selected_model = st.selectbox(
                &quot;Model&quot;,
                options=models[:100],  # Limitar para performance
                index=0
            )

        with col2:
            fuel_options = df[&quot;fuel&quot;].dropna().unique().tolist()
            fuel = st.selectbox(&quot;Fuel Type&quot;, options=fuel_options)

            trans_options = df[&quot;transmission&quot;].dropna().unique().tolist()
            transmission = st.selectbox(&quot;Transmission&quot;, options=trans_options)

            condition_options = [&quot;new&quot;, &quot;like new&quot;, &quot;excellent&quot;, &quot;good&quot;, &quot;fair&quot;, &quot;salvage&quot;]
            condition = st.selectbox(&quot;Condition&quot;, options=condition_options, index=3)

        submitted = st.form_submit_button(&quot;ğŸ”® Predict Price&quot;, use_container_width=True)

    # Hacer predicciÃ³n cuando se envÃ­a el form
    if submitted:
        # Preparar datos para predicciÃ³n
        input_data = pd.DataFrame([{
            &quot;model_year&quot;: model_year,
            &quot;odometer&quot;: odometer,
            &quot;model&quot;: selected_model,
            &quot;fuel&quot;: fuel,
            &quot;transmission&quot;: transmission,
            &quot;condition&quot;: condition,
        }])

        try:
            # Predecir
            prediction = model.predict(input_data)[0]

            # Mostrar resultado
            st.success(f&quot;### ğŸ’µ Estimated Price: **${prediction:,.0f}**&quot;)

            # Gauge de visualizaciÃ³n
            min_price = df[&quot;price&quot;].quantile(0.05)
            max_price = df[&quot;price&quot;].quantile(0.95)

            fig = create_price_gauge(prediction, min_price, max_price)
            st.plotly_chart(fig, use_container_width=True)

            # Contexto de mercado
            percentile = (df[&quot;price&quot;] &lt; prediction).mean() * 100
            st.info(f&quot;ğŸ“Š Este precio estÃ¡ en el percentil {percentile:.0f} del mercado.&quot;)

        except Exception as e:
            st.error(f&quot;Error en predicciÃ³n: {str(e)}&quot;)
---

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en Streamlit para ML

En dashboards de ML es fÃ¡cil mezclar lÃ³gica pesada con UI y terminar con apps lentas o que se rompen al mÃ­nimo cambio.

### 1) App muy lenta o que recalcula todo en cada interacciÃ³n

**SÃ­ntomas tÃ­picos**

- Cada vez que mueves un slider, tarda varios segundos.
- Ves en logs que se vuelve a leer el CSV o cargar el modelo a cada cambio.

**CÃ³mo identificarlo**

- Busca lecturas de disco o cargas de modelo dentro de la funciÃ³n `main` o dentro de callbacks de widgets.

**CÃ³mo corregirlo**

- Usa `@st.cache_data` para datos y `@st.cache_resource` para el modelo, como en los ejemplos del mÃ³dulo.
- Separa **carga** (funciones cacheadas) de **visualizaciÃ³n** (funciones ligeras que usan los datos ya cargados).

---

### 2) Errores al filtrar o mapear columnas (DataFrame desalineado)

**SÃ­ntomas tÃ­picos**

- Errores tipo `KeyError: 'price'` o columnas que no existen en ciertos entornos.

**CÃ³mo identificarlo**

- Verifica que el dataset que usas en Streamlit tenga la misma estructura que el usado en entrenamiento.

**CÃ³mo corregirlo**

- Centraliza la carga y preprocesado bÃ¡sico en una funciÃ³n (ej. `load_data`) y reutilÃ­zala en todas las tabs.
- AÃ±ade checks defensivos (`if 'price' not in df.columns: ...`).

---

### 3) Modelo o artefactos que no se encuentran desde Streamlit

**SÃ­ntomas tÃ­picos**

- El predictor muestra `Modelo no cargado. Entrene el modelo primero.` aunque sabes que existe un modelo.

**CÃ³mo identificarlo**

- Inspecciona la ruta usada en `load_model` y compÃ¡rala con la estructura real del proyecto / contenedor.

**CÃ³mo corregirlo**

- Alinea las rutas (`artifacts/`, `models/`) entre training, Docker y Streamlit.
- Si corres en Docker, monta los artefactos en la misma ruta que espera la app.

---

### 4) Comportamiento raro por estado oculto o re-runs

**SÃ­ntomas tÃ­picos**

- Formularios que se envÃ­an varias veces.
- Widgets que vuelven a su valor inicial sin razÃ³n aparente.

**CÃ³mo identificarlo**

- Revisa el uso de `st.session_state` y de formularios (`st.form`).

**CÃ³mo corregirlo**

- Usa `st.form` para agrupar inputs y ejecutar lÃ³gica solo cuando el usuario pulsa el botÃ³n de submit.
- Cuando necesites estado, usa `st.session_state` de forma explÃ­cita y documenta quÃ© claves manejas.

---

### 5) PatrÃ³n general de debugging en Streamlit

1. Reproduce el problema con un **mÃ­nimo ejemplo** (quita tabs/funciones hasta aislar el fallo).
2. AÃ±ade logs (`st.write`, `print`) temporales para ver en quÃ© orden se ejecuta el cÃ³digo.
3. Verifica quÃ© funciones deberÃ­an estar cacheadas y cuÃ¡les no.
4. AsegÃºrate de que las dependencias clave (datos, modelo) estÃ¡n disponibles antes de renderizar la UI.

Con este enfoque, tus dashboards serÃ¡n rÃ¡pidos, robustos y mantenibles.

---

## 16.6 Dashboard Avanzado: Visualizaciones Profesionales

### Gauge Chart para Predicciones

```python
import plotly.graph_objects as go

def create_price_gauge(predicted_price: float, min_price: float = 0, max_price: float = 100000):
    &quot;&quot;&quot;Crea un gauge chart para visualizar predicciÃ³n de precio.&quot;&quot;&quot;

# Determinar color segÃºn rango
    if predicted_price &lt; max_price * 0.3:
        color = &quot;green&quot;
    elif predicted_price &lt; max_price * 0.7:
        color = &quot;orange&quot;
    else:
        color = &quot;red&quot;

    fig = go.Figure(go.Indicator(
        mode=&quot;gauge+number+delta&quot;,
        value=predicted_price,
        domain={'x': [0, 1], 'y': [0, 1]},
        title={'text': &quot;Predicted Price&quot;, 'font': {'size': 24}},
        number={'prefix': &quot;$&quot;, 'font': {'size': 40}},
        gauge={
            'axis': {'range': [min_price, max_price], 'tickwidth': 1},
            'bar': {'color': color},
            'bgcolor': &quot;white&quot;,
            'borderwidth': 2,
            'steps': [
                {'range': [0, max_price * 0.3], 'color': 'lightgreen'},
                {'range': [max_price * 0.3, max_price * 0.7], 'color': 'lightyellow'},
                {'range': [max_price * 0.7, max_price], 'color': 'lightcoral'}
            ],
            'threshold': {
                'line': {'color': &quot;black&quot;, 'width': 4},
                'thickness': 0.75,
                'value': predicted_price
            }
        }
    ))

    fig.update_layout(height=300)
    return fig

# Uso en Streamlit
if prediction is not None:
    gauge = create_price_gauge(prediction, min_price=0, max_price=80000)
    st.plotly_chart(gauge, use_container_width=True)
</code></pre>
<h3>MÃ©tricas con Confianza (Bootstrap)</h3>
<pre><code class="language-python">def display_model_metrics(metrics: dict):
    &quot;&quot;&quot;Muestra mÃ©tricas del modelo con intervalos de confianza.&quot;&quot;&quot;

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label=&quot;RMSE&quot;,
            value=f&quot;${metrics['rmse']:,.0f}&quot;,
            delta=f&quot;Â±{metrics.get('rmse_ci', 500):,.0f}&quot;,
            delta_color=&quot;inverse&quot;  # Menor es mejor
        )

    with col2:
        st.metric(
            label=&quot;MAE&quot;,
            value=f&quot;${metrics['mae']:,.0f}&quot;,
            delta=f&quot;Â±{metrics.get('mae_ci', 300):,.0f}&quot;,
            delta_color=&quot;inverse&quot;
        )

    with col3:
        st.metric(
            label=&quot;RÂ²&quot;,
            value=f&quot;{metrics['r2']:.3f}&quot;,
            delta=f&quot;{metrics.get('r2_improvement', 0):.1%} vs baseline&quot;,
            delta_color=&quot;normal&quot;
        )

    with col4:
        st.metric(
            label=&quot;MAPE&quot;,
            value=f&quot;{metrics['mape']:.1%}&quot;,
            delta=f&quot;Â±{metrics.get('mape_ci', 0.02):.1%}&quot;,
            delta_color=&quot;inverse&quot;
        )
</code></pre>
<h3>Feature Importance Interactivo</h3>
<pre><code class="language-python">import plotly.express as px

def plot_feature_importance(model, feature_names: list, top_n: int = 15):
    &quot;&quot;&quot;GrÃ¡fico interactivo de importancia de features.&quot;&quot;&quot;

# Extraer importancias (asume RandomForest o similar)
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
    elif hasattr(model, 'named_steps'):

# Pipeline sklearn
        clf = model.named_steps.get('classifier') or model.named_steps.get('model')
        importances = clf.feature_importances_
    else:
        st.warning(&quot;Modelo no soporta feature_importances_&quot;)
        return None

# Crear DataFrame y ordenar
    df_imp = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=True).tail(top_n)

# GrÃ¡fico horizontal
    fig = px.bar(
        df_imp, 
        x='importance', 
        y='feature',
        orientation='h',
        title=f'Top {top_n} Feature Importances',
        labels={'importance': 'Importance', 'feature': 'Feature'},
        color='importance',
        color_continuous_scale='Viridis'
    )

    fig.update_layout(height=400, showlegend=False)
    return fig

# Uso
with st.expander(&quot;ğŸ” Feature Importance&quot;, expanded=True):
    fig = plot_feature_importance(model, feature_names)
    if fig:
        st.plotly_chart(fig, use_container_width=True)
</code></pre>
<h3>Multi-page App con Navigation</h3>
<pre><code class="language-python">
# pages/1_ğŸ“Š_Overview.py
import streamlit as st

st.set_page_config(page_title=&quot;Overview&quot;, page_icon=&quot;ğŸ“Š&quot;)
st.title(&quot;ğŸ“Š Dashboard Overview&quot;)

# ... contenido de overview

# pages/2_ğŸ”®_Predictor.py
import streamlit as st

st.set_page_config(page_title=&quot;Predictor&quot;, page_icon=&quot;ğŸ”®&quot;)
st.title(&quot;ğŸ”® Price Predictor&quot;)

# ... contenido de predictor

# Estructura de archivos:

# app/

# â”œâ”€â”€ streamlit_app.py       # Main entry point

# â””â”€â”€ pages/

#     â”œâ”€â”€ 1_ğŸ“Š_Overview.py

#     â”œâ”€â”€ 2_ğŸ“ˆ_Analysis.py

#     â””â”€â”€ 3_ğŸ”®_Predictor.py
</code></pre>
<hr />
<h2>ğŸ“¦ CÃ³mo se usÃ³ en el Portafolio</h2>
<p>El dashboard de CarVision (<code>CarVision-Market-Intelligence/app/streamlit_app.py</code>) implementa:</p>
<table>
<thead>
<tr>
<th>Componente</th>
<th style="text-align: center;">LÃ­neas</th>
<th>TÃ©cnica</th>
</tr>
</thead>
<tbody>
<tr>
<td>4 Tabs navegables</td>
<td style="text-align: center;">150-600</td>
<td><code>st.tabs()</code></td>
</tr>
<tr>
<td>KPIs ejecutivos</td>
<td style="text-align: center;">200-250</td>
<td><code>st.metric()</code> con delta</td>
</tr>
<tr>
<td>Gauge de predicciÃ³n</td>
<td style="text-align: center;">450-500</td>
<td>Plotly <code>go.Indicator</code></td>
</tr>
<tr>
<td>Feature importance</td>
<td style="text-align: center;">350-400</td>
<td>Plotly <code>px.bar</code> horizontal</td>
</tr>
<tr>
<td>Bootstrap validation</td>
<td style="text-align: center;">400-430</td>
<td>MÃ©tricas con intervalos</td>
</tr>
<tr>
<td>Caching de modelo</td>
<td style="text-align: center;">50-80</td>
<td><code>@st.cache_resource</code></td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Streamlit vs Gradio vs Dash</strong>: Trade-offs (Streamlit simple, Gradio para ML demos, Dash para dashboards complejos).</p>
</li>
<li>
<p><strong>Session State</strong>: Explica cÃ³mo mantener estado entre reruns.</p>
</li>
<li>
<p><strong>Caching</strong>: <code>@st.cache_data</code> vs <code>@st.cache_resource</code>.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Modelo pesado</td>
<td>Usa <code>@st.cache_resource</code> para cargarlo una vez</td>
</tr>
<tr>
<td>Datos grandes</td>
<td>Pagina o muestra samples</td>
</tr>
<tr>
<td>Deployment</td>
<td>Streamlit Cloud para demos, Docker para producciÃ³n</td>
</tr>
<tr>
<td>UX</td>
<td>AÃ±ade spinners y progress bars</td>
</tr>
</tbody>
</table>
<h3>Estructura de App Profesional</h3>
<pre><code>app/
â”œâ”€â”€ streamlit_app.py   # Entry point limpio
â”œâ”€â”€ pages/             # Multi-page app
â”œâ”€â”€ components/        # Widgets reutilizables
â””â”€â”€ utils/             # LÃ³gica de negocio
</code></pre>
<hr />
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
<th style="text-align: center;">DuraciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=JwSS70SZdyM">Streamlit Crash Course - Patrick Loeber</a></td>
<td style="text-align: left;">Video</td>
<td style="text-align: center;">45 min</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://30days.streamlit.app/">30 Days of Streamlit</a></td>
<td style="text-align: left;">Curso</td>
<td style="text-align: center;">30 dÃ­as</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=nSw96qUbK9o">Streamlit Multi-page Apps</a></td>
<td style="text-align: left;">Video</td>
<td style="text-align: center;">20 min</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://streamlit.io/gallery">Streamlit Gallery</a></td>
<td style="text-align: left;">Ejemplos</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<hr />
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Streamlit</strong>: Framework para dashboards en Python<br />
- <strong>@st.cache_resource</strong>: Decorator para cachear modelos<br />
- <strong>Plotly</strong>: LibrerÃ­a de visualizaciones interactivas</p>
<hr />
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 15:<br />
- <strong>15.1</strong>: Dashboard de predicciÃ³n</p>
<p><strong>Ejercicio completo:</strong><br />
Crea un dashboard Streamlit para BankChurn con:<br />
1. Tab Overview: DistribuciÃ³n de churn, KPIs<br />
2. Tab Analysis: Factores de riesgo por segmento<br />
3. Tab Predictor: Formulario para predecir churn de un cliente</p>
<p><strong>Bonus</strong>:<br />
- AÃ±ade gauge chart para probabilidad de churn<br />
- Implementa SHAP waterfall plot para explicar predicciones<br />
- Usa multi-page structure</p>
<hr />
<h2>ğŸ¤ Checkpoint: Simulacro Mid</h2>
<blockquote>
<p>ğŸ¯ <strong>Â¡Has completado ML Core + Deploy!</strong> (MÃ³dulos 07-15)</p>
<p>Si buscas posiciones <strong>Mid-Level ML Engineer</strong>, ahora es buen momento para practicar:</p>
<p><strong><a href="#mod_SIMULACRO_ENTREVISTA_MID">â†’ SIMULACRO_ENTREVISTA_MID.md</a></strong><br />
- 60 preguntas de pipelines, testing, CI/CD, Docker, APIs<br />
- Enfoque en implementaciÃ³n end-to-end y debugging</p>
</blockquote>
<hr />
<div align="center">

[â† FastAPI ProducciÃ³n](#mod_14_FASTAPI) | [Siguiente: Observabilidad â†’](#mod_16_OBSERVABILIDAD)

</div>
            </div>
        
            <!-- MÃ“DULO: SIMULACRO_ENTREVISTA_MID.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_SIMULACRO_ENTREVISTA_MID" class="cover-title">SIMULACRO ENTREVISTA MID</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ¯ Simulacro de Entrevista Mid-Level ML Engineer</h1>
<h2>Portafolio MLOps â€” 60 Preguntas TÃ©cnicas</h2>
<p><strong>Nivel</strong>: Mid (2-4 aÃ±os de experiencia)<br />
<strong>VersiÃ³n</strong>: 1.0 | Diciembre 2025</p>
<h2>ğŸ“‹ Ãndice</h2>
<ol>
<li><a href="#1-pipelines-y-arquitectura-preguntas-1-15">Pipelines y Arquitectura</a></li>
<li><a href="#2-mlops-prÃ¡ctico-preguntas-16-30">MLOps PrÃ¡ctico</a></li>
<li><a href="#3-testing-y-calidad-preguntas-31-40">Testing y Calidad</a></li>
<li><a href="#4-deployment-y-apis-preguntas-41-50">Deployment y APIs</a></li>
<li><a href="#5-escenarios-prÃ¡cticos-preguntas-51-60">Escenarios PrÃ¡cticos</a></li>
</ol>
<h2>ğŸ¯ Â¿QuÃ© se espera de un Mid-Level?</h2>
<table>
<thead>
<tr>
<th>SÃ­ se espera</th>
<th>No se espera (aÃºn)</th>
</tr>
</thead>
<tbody>
<tr>
<td>DiseÃ±ar pipelines end-to-end</td>
<td>Arquitecturas distribuidas complejas</td>
</tr>
<tr>
<td>Implementar CI/CD funcional</td>
<td>OptimizaciÃ³n de infraestructura a escala</td>
</tr>
<tr>
<td>Debugging autÃ³nomo</td>
<td>Mentoring de equipos</td>
</tr>
<tr>
<td>Code reviews</td>
<td>Decisiones de arquitectura crÃ­ticas</td>
</tr>
<tr>
<td>Escribir tests comprehensivos</td>
<td>DiseÃ±o de sistemas desde cero</td>
</tr>
</tbody>
</table>
<h1>1. Pipelines y Arquitectura (Preguntas 1-15)</h1>
<h2>Pregunta 1: Pipeline Unificado</h2>
<p><strong>Â¿Por quÃ© usar un Pipeline unificado en lugar de artefactos separados?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># âŒ Antes: artefactos separados
preprocessor = joblib.load(&quot;preprocessor.pkl&quot;)
model = joblib.load(&quot;model.pkl&quot;)
X = preprocessor.transform(X)
pred = model.predict(X)

# âœ… DespuÃ©s: pipeline unificado
pipe = joblib.load(&quot;pipeline.joblib&quot;)
pred = pipe.predict(X)  # Todo en uno
</code></pre>
<p><strong>Beneficios</strong>:<br />
1. Elimina training-serving skew<br />
2. Single source of truth<br />
3. Versionado simple<br />
4. Deploy mÃ¡s limpio</p>
<h2>Pregunta 2: ColumnTransformer</h2>
<p><strong>Explica el ColumnTransformer del portafolio.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">preprocessor = ColumnTransformer([
    ('num', Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ]), numerical_cols),
    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ]), categorical_cols),
], remainder='drop')
</code></pre>
<p><strong>Procesa columnas en paralelo</strong>: numÃ©ricas y categÃ³ricas tienen transformaciones distintas.</p>
<h2>Pregunta 3: Custom Transformer</h2>
<p><strong>Â¿CuÃ¡ndo crear un transformer personalizado?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class FeatureEngineer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self

    def transform(self, X):
        X = X.copy()
        X['vehicle_age'] = 2024 - X['model_year']
        return X
</code></pre>
<p><strong>CuÃ¡ndo usar</strong>:<br />
- LÃ³gica de negocio especÃ­fica<br />
- Features derivadas<br />
- Transformaciones no estÃ¡ndar</p>
<h2>Pregunta 4: Estratified Split</h2>
<p><strong>Â¿Por quÃ© stratify=y en train_test_split?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
</code></pre>
<p>Con clases desbalanceadas (80/20 churn), <code>stratify=y</code> garantiza que train y test mantengan la misma proporciÃ³n. Sin esto, un split aleatorio podrÃ­a dar 85/15 en train y 70/30 en test.</p>
<h2>Pregunta 5: Hyperparameter Tuning</h2>
<p><strong>Â¿CÃ³mo optimizas hiperparÃ¡metros?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'model__n_estimators': [50, 100, 200],
    'model__max_depth': [5, 10, 20, None]
}

search = RandomizedSearchCV(
    pipe, param_dist, n_iter=20, cv=5, scoring='f1'
)
search.fit(X_train, y_train)
print(search.best_params_)
</code></pre>
<p><strong>GridSearch vs RandomizedSearch</strong>: Random es mÃ¡s eficiente con muchos parÃ¡metros.</p>
<h2>Pregunta 6: MÃ©tricas de Negocio</h2>
<p><strong>Â¿CÃ³mo traduces mÃ©tricas ML a valor de negocio?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Costo de falsos negativos (cliente que churns sin detectar)
cost_fn = 500  # Costo de adquisiciÃ³n de nuevo cliente

# Costo de falsos positivos (retenciÃ³n innecesaria)
cost_fp = 50   # Costo de campaÃ±a de retenciÃ³n

# Costo total
total_cost = (FN * cost_fn) + (FP * cost_fp)
</code></pre>
<p>Optimizar para <strong>minimizar costo total</strong>, no solo accuracy.</p>
<h2>Pregunta 7: Ensemble Methods</h2>
<p><strong>Explica VotingClassifier con soft voting.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">ensemble = VotingClassifier([
    ('lr', LogisticRegression()),
    ('rf', RandomForestClassifier())
], voting='soft', weights=[0.4, 0.6])
</code></pre>
<ul>
<li><strong>Soft voting</strong>: Promedia probabilidades (mejor que votos binarios)</li>
<li><strong>Weights</strong>: RF tiene mÃ¡s peso porque tiene mejor AUC individual</li>
<li><strong>Complementariedad</strong>: LR lineal + RF no-lineal = menor varianza</li>
</ul>
<h2>Pregunta 8: Cross-Validation Avanzado</h2>
<p><strong>Â¿CuÃ¡ndo usar TimeSeriesSplit vs StratifiedKFold?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Tipo</th>
<th>Usar cuando</th>
</tr>
</thead>
<tbody>
<tr>
<td>StratifiedKFold</td>
<td>ClasificaciÃ³n con clases desbalanceadas</td>
</tr>
<tr>
<td>TimeSeriesSplit</td>
<td>Datos temporales (evitar data leakage temporal)</td>
</tr>
<tr>
<td>GroupKFold</td>
<td>Datos con grupos (ej: mÃºltiples muestras por paciente)</td>
</tr>
</tbody>
</table>
<pre><code class="language-python">from sklearn.model_selection import TimeSeriesSplit
tscv = TimeSeriesSplit(n_splits=5)
# Train: [1,2,3], Test: [4]
# Train: [1,2,3,4], Test: [5]
</code></pre>
<h2>Pregunta 9: Feature Importance</h2>
<p><strong>Â¿CÃ³mo explicas quÃ© features son importantes?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Importancia de RF
importances = model.feature_importances_

# 2. Permutation importance (mÃ¡s robusto)
from sklearn.inspection import permutation_importance
perm = permutation_importance(model, X_test, y_test)

# 3. SHAP (mÃ¡s interpretable)
import shap
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)
</code></pre>
<h2>Pregunta 10: Handling Categorical High Cardinality</h2>
<p><strong>Â¿CÃ³mo manejas categorÃ­as con muchos valores Ãºnicos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Target encoding (con cuidado de leakage)
from category_encoders import TargetEncoder
encoder = TargetEncoder()

# 2. Frequency encoding
X['brand_freq'] = X['brand'].map(X['brand'].value_counts(normalize=True))

# 3. Grouping rare categories
X['brand'] = X['brand'].apply(lambda x: x if freq[x] &gt; 0.01 else 'Other')
</code></pre>
<h2>Pregunta 11: Reproducibilidad</h2>
<p><strong>Â¿CÃ³mo garantizas experimentos reproducibles?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Seeds
SEED = 42
np.random.seed(SEED)
random.seed(SEED)

# 2. Config versionada
config = BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)

# 3. MLflow tracking
mlflow.log_params(config.model.dict())
mlflow.log_artifact(&quot;configs/config.yaml&quot;)

# 4. Dependencias fijas
# pyproject.toml con versiones especÃ­ficas
</code></pre>
<h2>Pregunta 12: Data Validation</h2>
<p><strong>Â¿CÃ³mo validas datos de entrada en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from pydantic import BaseModel, Field, validator

class PredictionInput(BaseModel):
    credit_score: int = Field(ge=300, le=850)
    age: int = Field(ge=18, le=100)
    geography: str

    @validator('geography')
    def validate_geography(cls, v):
        valid = ['France', 'Germany', 'Spain']
        if v not in valid:
            raise ValueError(f'Must be one of {valid}')
        return v
</code></pre>
<p>Pydantic valida antes de que llegue al modelo.</p>
<h2>Pregunta 13: Config Management</h2>
<p><strong>Â¿Por quÃ© Pydantic para configuraciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class ModelConfig(BaseModel):
    model_type: Literal[&quot;rf&quot;, &quot;lr&quot;, &quot;xgb&quot;]
    n_estimators: int = Field(ge=10, le=1000)

    @validator('n_estimators')
    def validate_estimators(cls, v, values):
        if values.get('model_type') == 'lr' and v != 1:
            raise ValueError('LR no usa n_estimators')
        return v
</code></pre>
<p><strong>Beneficios</strong>: ValidaciÃ³n automÃ¡tica, tipos claros, errores descriptivos, documentaciÃ³n implÃ­cita.</p>
<h2>Pregunta 14: Artifact Management</h2>
<p><strong>Â¿CÃ³mo organizas artefactos del modelo?</strong></p>
<h3>Respuesta:</h3>
<pre><code>artifacts/
â”œâ”€â”€ pipeline.joblib       # Modelo + preprocessor
â”œâ”€â”€ training_results.json # MÃ©tricas
â”œâ”€â”€ config.yaml          # Config usada
â””â”€â”€ feature_names.json   # Features esperadas
</code></pre>
<pre><code class="language-python"># Guardar
joblib.dump(pipe, 'artifacts/pipeline.joblib')
with open('artifacts/training_results.json', 'w') as f:
    json.dump(metrics, f)
</code></pre>
<h2>Pregunta 15: Model Versioning</h2>
<p><strong>Â¿CÃ³mo versionas modelos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. MLflow Model Registry
mlflow.sklearn.log_model(pipe, &quot;model&quot;)
# Registrar como v1, v2, etc.

# 2. Naming convention
model_name = f&quot;bankchurn_v{version}_{timestamp}.joblib&quot;

# 3. Git tags
git tag -a v1.0.0 -m &quot;Model v1.0.0: AUC 0.85&quot;
</code></pre>
<h1>2. MLOps PrÃ¡ctico (Preguntas 16-30)</h1>
<h2>Pregunta 16: MLflow Tracking</h2>
<p><strong>Â¿CÃ³mo usas MLflow para tracking?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import mlflow

with mlflow.start_run():
    mlflow.log_params({&quot;n_estimators&quot;: 100, &quot;max_depth&quot;: 10})
    mlflow.log_metrics({&quot;auc&quot;: 0.85, &quot;f1&quot;: 0.78})
    mlflow.sklearn.log_model(pipe, &quot;model&quot;)
    mlflow.log_artifact(&quot;configs/config.yaml&quot;)
</code></pre>
<h2>Pregunta 17: DVC</h2>
<p><strong>Â¿Para quÃ© usas DVC?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash"># Trackear datos
dvc add data/raw/Churn.csv

# Push a remote
dvc push

# Pull datos
dvc pull
</code></pre>
<p><strong>Beneficio</strong>: Versionar datos grandes sin subirlos a Git.</p>
<h2>Pregunta 18: GitHub Actions CI</h2>
<p><strong>Explica el workflow CI del portafolio.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: pip install -e &quot;.[dev]&quot;
      - run: pytest tests/ --cov=src
      - run: ruff check src/
</code></pre>
<p><strong>Flujo</strong>: Push â†’ Install â†’ Test â†’ Lint â†’ Pass/Fail badge.</p>
<h2>Pregunta 19: Pre-commit Hooks</h2>
<p><strong>Â¿QuÃ© hooks usas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    hooks:
      - id: ruff
      - id: ruff-format
  - repo: https://github.com/pre-commit/mirrors-mypy
    hooks:
      - id: mypy
</code></pre>
<p>Ejecutan automÃ¡ticamente antes de cada commit.</p>
<h2>Pregunta 20: Docker Multi-stage</h2>
<p><strong>Explica el Dockerfile del portafolio.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-dockerfile"># Build stage
FROM python:3.11-slim AS builder
COPY requirements.txt .
RUN pip wheel --no-cache-dir -w /wheels -r requirements.txt

# Runtime stage
FROM python:3.11-slim
COPY --from=builder /wheels /wheels
RUN pip install --no-cache /wheels/*
COPY . /app
USER nonroot
CMD [&quot;uvicorn&quot;, &quot;app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;]
</code></pre>
<p><strong>Multi-stage</strong>: Build pesado en stage 1, runtime ligero en stage 2.</p>
<h2>Pregunta 21: Training-Serving Skew</h2>
<p><strong>Â¿QuÃ© es training-serving skew y cÃ³mo lo evitas?</strong></p>
<h3>Respuesta:</h3>
<p>Training-serving skew ocurre cuando el modelo ve datos diferentes en producciÃ³n vs entrenamiento.</p>
<p><strong>Causas comunes</strong>:</p>
<pre><code class="language-python"># âŒ MAL: Preprocesamiento diferente
# Training
X_train['age_normalized'] = (X_train['age'] - X_train['age'].mean()) / X_train['age'].std()

# Serving (usa stats de producciÃ³n, no de training!)
X_prod['age_normalized'] = (X_prod['age'] - X_prod['age'].mean()) / X_prod['age'].std()
</code></pre>
<p><strong>SoluciÃ³n: Pipeline unificado</strong>:</p>
<pre><code class="language-python"># âœ… BIEN: Todo en un pipeline
pipe = Pipeline([
    ('scaler', StandardScaler()),  # Guarda mean/std de training
    ('model', RandomForestClassifier())
])
pipe.fit(X_train, y_train)
joblib.dump(pipe, 'model.joblib')

# En producciÃ³n: mismo pipeline
pipe = joblib.load('model.joblib')
pred = pipe.predict(X_new)  # Usa stats de training
</code></pre>
<h2>Pregunta 22: Data Drift Detection</h2>
<p><strong>Â¿CÃ³mo detectas data drift en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from evidently.metrics import DataDriftTable
from evidently.report import Report

# Comparar distribuciones
report = Report(metrics=[DataDriftTable()])
report.run(reference_data=X_train, current_data=X_prod)
report.save_html(&quot;drift_report.html&quot;)
</code></pre>
<p><strong>MÃ©todos estadÃ­sticos</strong>:</p>
<table>
<thead>
<tr>
<th>MÃ©todo</th>
<th>Uso</th>
<th>Umbral tÃ­pico</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>PSI</strong> (Population Stability Index)</td>
<td>CategÃ³ricas</td>
<td>&gt;0.2 = drift significativo</td>
</tr>
<tr>
<td><strong>KS-test</strong> (Kolmogorov-Smirnov)</td>
<td>NumÃ©ricas</td>
<td>p-value &lt; 0.05</td>
</tr>
<tr>
<td><strong>JS Divergence</strong></td>
<td>Distribuciones</td>
<td>&gt;0.1 = drift</td>
</tr>
</tbody>
</table>
<p><strong>En el portafolio</strong>: Configurable en <code>16_OBSERVABILIDAD.md</code>.</p>
<h2>Pregunta 23: MÃ©tricas de ProducciÃ³n</h2>
<p><strong>Â¿QuÃ© mÃ©tricas monitoreas en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Prometheus metrics en FastAPI
from prometheus_client import Counter, Histogram

PREDICTIONS = Counter('predictions_total', 'Total predictions', ['model_version'])
LATENCY = Histogram('prediction_latency_seconds', 'Prediction latency')

@app.post(&quot;/predict&quot;)
async def predict(data: Input):
    with LATENCY.time():
        result = model.predict(data)
    PREDICTIONS.labels(model_version=&quot;v1.2&quot;).inc()
    return result
</code></pre>
<p><strong>MÃ©tricas clave</strong>:</p>
<table>
<thead>
<tr>
<th>CategorÃ­a</th>
<th>MÃ©tricas</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Rendimiento</strong></td>
<td>Latencia p50/p95/p99, throughput</td>
</tr>
<tr>
<td><strong>Disponibilidad</strong></td>
<td>Error rate, uptime</td>
</tr>
<tr>
<td><strong>ML especÃ­ficas</strong></td>
<td>Prediction distribution, feature distributions</td>
</tr>
<tr>
<td><strong>Negocio</strong></td>
<td>Conversiones, costos evitados</td>
</tr>
</tbody>
</table>
<h2>Pregunta 24: Rollback de Modelos</h2>
<p><strong>Â¿CÃ³mo haces rollback si un modelo falla?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Versionado de modelos
models/
â”œâ”€â”€ v1.0.0/pipeline.joblib  # â† Rollback aquÃ­
â”œâ”€â”€ v1.1.0/pipeline.joblib
â””â”€â”€ v1.2.0/pipeline.joblib  # Actual (fallando)

# 2. Blue-Green deployment
# deployment.yaml
spec:
  replicas: 2
  selector:
    matchLabels:
      version: v1.1.0  # Cambiar a versiÃ³n anterior

# 3. Con MLflow
client = MlflowClient()
client.transition_model_version_stage(
    name=&quot;bankchurn&quot;,
    version=3,
    stage=&quot;Production&quot;  # Promover versiÃ³n anterior
)
</code></pre>
<p><strong>Proceso de rollback</strong>:<br />
1. Detectar degradaciÃ³n (alertas de mÃ©tricas)<br />
2. Cambiar variable de entorno o config<br />
3. Reiniciar pods / recargar modelo<br />
4. Verificar mÃ©tricas post-rollback</p>
<h2>Pregunta 25: A/B Testing en ML</h2>
<p><strong>Â¿CÃ³mo implementas A/B testing para modelos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import random

@app.post(&quot;/predict&quot;)
async def predict(data: Input, user_id: str):
    # Asignar bucket consistente por usuario
    bucket = hash(user_id) % 100

    if bucket &lt; 10:  # 10% trÃ¡fico
        model = model_v2  # Challenger
        version = &quot;v2&quot;
    else:
        model = model_v1  # Champion
        version = &quot;v1&quot;

    result = model.predict(data)

    # Logging para anÃ¡lisis
    log_prediction(user_id, version, result)

    return {&quot;prediction&quot;: result, &quot;model_version&quot;: version}
</code></pre>
<p><strong>MÃ©tricas a comparar</strong>:<br />
- Accuracy/F1 en cohortes<br />
- MÃ©tricas de negocio (conversiÃ³n, revenue)<br />
- Latencia y error rate</p>
<h2>Pregunta 26: Manejo de Secrets</h2>
<p><strong>Â¿CÃ³mo manejas secrets y credenciales?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># âŒ MAL: Hardcoded
API_KEY = &quot;TU_API_KEY_AQUI&quot;  # EJEMPLO, NO USAR EN PRODUCCIÃ“N

# âœ… BIEN: Variables de entorno
import os
API_KEY = os.getenv(&quot;API_KEY&quot;)

# âœ… MEJOR: python-dotenv
from dotenv import load_dotenv
load_dotenv()  # Carga .env
API_KEY = os.getenv(&quot;API_KEY&quot;)
</code></pre>
<p><strong>.env (nunca en Git)</strong>:</p>
<pre><code class="language-bash"># .env (valores de ejemplo)
API_KEY=REEMPLAZAR_EN_ENTORNO_REAL
DB_PASSWORD=REEMPLAZAR_EN_ENTORNO_REAL
</code></pre>
<p><strong>.gitignore</strong>:</p>
<pre><code class="language-gitignore">.env
.env.*
!.env.example
</code></pre>
<p><strong>En CI/CD</strong>: GitHub Secrets â†’ <code>${{ secrets.API_KEY }}</code></p>
<h2>Pregunta 27: Feature Store</h2>
<p><strong>Â¿QuÃ© es un feature store y cuÃ¡ndo usarlo?</strong></p>
<h3>Respuesta:</h3>
<p>Feature store = repositorio centralizado de features reutilizables.</p>
<pre><code class="language-python"># Sin feature store (problema)
# Equipo A: calcula age_bucket de una forma
# Equipo B: calcula age_bucket de otra forma
# â†’ Inconsistencia

# Con feature store (soluciÃ³n)
from feast import FeatureStore

store = FeatureStore(repo_path=&quot;.&quot;)
features = store.get_online_features(
    features=[&quot;customer:age_bucket&quot;, &quot;customer:tenure_months&quot;],
    entity_rows=[{&quot;customer_id&quot;: &quot;C123&quot;}]
)
</code></pre>
<p><strong>CuÃ¡ndo usar</strong>:</p>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Feature Store</th>
</tr>
</thead>
<tbody>
<tr>
<td>1-2 modelos, equipo pequeÃ±o</td>
<td>No necesario</td>
</tr>
<tr>
<td>MÃºltiples modelos, features compartidas</td>
<td>Recomendado</td>
</tr>
<tr>
<td>Features en tiempo real</td>
<td>Muy recomendado</td>
</tr>
</tbody>
</table>
<h2>Pregunta 28: Escalado de Inferencia</h2>
<p><strong>Â¿CÃ³mo escalas inferencia para alto trÃ¡fico?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># Kubernetes HPA (Horizontal Pod Autoscaler)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
</code></pre>
<p><strong>Estrategias</strong>:</p>
<table>
<thead>
<tr>
<th>Estrategia</th>
<th>CuÃ¡ndo</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>HPA</strong></td>
<td>TrÃ¡fico variable, latencia crÃ­tica</td>
</tr>
<tr>
<td><strong>Batch processing</strong></td>
<td>Alto volumen, latencia flexible</td>
</tr>
<tr>
<td><strong>Caching</strong></td>
<td>Inputs repetidos frecuentes</td>
</tr>
<tr>
<td><strong>Model optimization</strong></td>
<td>Latencia muy baja requerida</td>
</tr>
</tbody>
</table>
<h2>Pregunta 29: Logging en ML</h2>
<p><strong>Â¿QuÃ© informaciÃ³n loggeas en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import logging
import json

logger = logging.getLogger(__name__)

@app.post(&quot;/predict&quot;)
async def predict(data: Input):
    request_id = str(uuid.uuid4())

    # Log de entrada
    logger.info(json.dumps({
        &quot;event&quot;: &quot;prediction_request&quot;,
        &quot;request_id&quot;: request_id,
        &quot;features&quot;: data.dict(),
        &quot;timestamp&quot;: datetime.utcnow().isoformat()
    }))

    start = time.time()
    result = model.predict(data)
    latency = time.time() - start

    # Log de salida
    logger.info(json.dumps({
        &quot;event&quot;: &quot;prediction_response&quot;,
        &quot;request_id&quot;: request_id,
        &quot;prediction&quot;: result,
        &quot;probability&quot;: float(proba),
        &quot;latency_ms&quot;: latency * 1000,
        &quot;model_version&quot;: &quot;v1.2.0&quot;
    }))

    return result
</code></pre>
<p><strong>Logs esenciales</strong>: request_id, inputs, outputs, latencia, versiÃ³n, errores.</p>
<h2>Pregunta 30: Retraining AutomÃ¡tico</h2>
<p><strong>Â¿CÃ³mo automatizas el retraining?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># GitHub Actions scheduled workflow
name: Weekly Retrain
on:
  schedule:
    - cron: '0 2 * * 0'  # Domingos 2am
  workflow_dispatch:  # Manual trigger

jobs:
  retrain:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - run: pip install -e &quot;.[dev]&quot;
      - run: python main.py --config configs/config.yaml
      - run: python scripts/evaluate.py --threshold 0.80
      - run: |
          if [ $? -eq 0 ]; then
            echo &quot;Model passed threshold, deploying...&quot;
            # Deploy logic
          fi
</code></pre>
<p><strong>Triggers de retraining</strong>:</p>
<table>
<thead>
<tr>
<th>Trigger</th>
<th>ImplementaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Scheduled</strong></td>
<td>Cron jobs, Airflow</td>
</tr>
<tr>
<td><strong>Data drift</strong></td>
<td>Alerta â†’ trigger workflow</td>
</tr>
<tr>
<td><strong>Performance degradation</strong></td>
<td>MÃ©tricas bajo umbral</td>
</tr>
<tr>
<td><strong>New data volume</strong></td>
<td>X nuevos registros</td>
</tr>
</tbody>
</table>
<h1>3. Testing y Calidad (Preguntas 31-40)</h1>
<h2>Pregunta 31: Tipos de Tests</h2>
<p><strong>Â¿QuÃ© tipos de tests tiene el portafolio?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Unit test
def test_feature_engineer():
    fe = FeatureEngineer()
    result = fe.transform(sample_df)
    assert 'vehicle_age' in result.columns

# Integration test
def test_training_pipeline():
    trainer = Trainer(config)
    trainer.fit(X, y)
    assert trainer.model_ is not None

# API test
def test_predict_endpoint():
    response = client.post(&quot;/predict&quot;, json=sample_input)
    assert response.status_code == 200
</code></pre>
<h2>Pregunta 32: Fixtures</h2>
<p><strong>Â¿CÃ³mo usas fixtures en pytest?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@pytest.fixture
def sample_data():
    return pd.DataFrame({
        'CreditScore': [650, 700],
        'Age': [35, 45],
        'Exited': [0, 1]
    })

@pytest.fixture
def trained_model(sample_data):
    trainer = Trainer(config)
    trainer.fit(sample_data)
    return trainer

def test_predict(trained_model, sample_data):
    preds = trained_model.predict(sample_data)
    assert len(preds) == len(sample_data)
</code></pre>
<h2>Pregunta 33: Coverage</h2>
<p><strong>Â¿CuÃ¡nto coverage es suficiente?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash">pytest tests/ --cov=src --cov-report=html
</code></pre>
<table>
<thead>
<tr>
<th>Nivel</th>
<th>Coverage</th>
<th>Comentario</th>
</tr>
</thead>
<tbody>
<tr>
<td>MÃ­nimo</td>
<td>70%</td>
<td>Lo bÃ¡sico</td>
</tr>
<tr>
<td>Bueno</td>
<td>80%</td>
<td>EstÃ¡ndar industria</td>
</tr>
<tr>
<td>Excelente</td>
<td>90%+</td>
<td>CÃ³digo crÃ­tico</td>
</tr>
</tbody>
</table>
<p><strong>El portafolio tiene 79% en BankChurn.</strong></p>
<h2>Pregunta 34: Property-Based Testing</h2>
<p><strong>Â¿QuÃ© es property-based testing?</strong></p>
<h3>Respuesta:</h3>
<p>En lugar de casos especÃ­ficos, defines <strong>propiedades</strong> que siempre deben cumplirse.</p>
<pre><code class="language-python">from hypothesis import given, strategies as st

@given(
    credit_score=st.integers(min_value=300, max_value=850),
    age=st.integers(min_value=18, max_value=100)
)
def test_prediction_is_valid(credit_score, age):
    &quot;&quot;&quot;Propiedad: la predicciÃ³n siempre es 0 o 1.&quot;&quot;&quot;
    input_data = {&quot;credit_score&quot;: credit_score, &quot;age&quot;: age}
    pred = model.predict(pd.DataFrame([input_data]))
    assert pred[0] in [0, 1]

@given(df=st.data())
def test_feature_engineer_preserves_rows(df):
    &quot;&quot;&quot;Propiedad: FeatureEngineer no cambia nÃºmero de filas.&quot;&quot;&quot;
    sample = df.draw(st.dataframes(columns=[
        st.column(&quot;age&quot;, dtype=int),
        st.column(&quot;salary&quot;, dtype=float)
    ]))
    result = fe.transform(sample)
    assert len(result) == len(sample)
</code></pre>
<p><strong>Ventaja</strong>: Encuentra edge cases que no pensaste.</p>
<h2>Pregunta 35: Testing de Modelos ML</h2>
<p><strong>Â¿CÃ³mo testeas que un modelo funciona correctamente?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Test de smoke: modelo carga y predice
def test_model_loads_and_predicts():
    model = joblib.load(&quot;artifacts/pipeline.joblib&quot;)
    sample = pd.DataFrame([{&quot;CreditScore&quot;: 650, &quot;Age&quot;: 35}])
    pred = model.predict(sample)
    assert len(pred) == 1

# 2. Test de formato de salida
def test_prediction_format():
    pred = model.predict(X_test)
    assert pred.shape == (len(X_test),)
    assert set(pred).issubset({0, 1})

# 3. Test de rendimiento mÃ­nimo
def test_model_performance():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    assert accuracy &gt;= 0.75, f&quot;Accuracy {accuracy} below threshold&quot;

# 4. Test de invarianza
def test_prediction_deterministic():
    pred1 = model.predict(X_test)
    pred2 = model.predict(X_test)
    assert np.array_equal(pred1, pred2)
</code></pre>
<h2>Pregunta 36: Mocking</h2>
<p><strong>Â¿QuÃ© es mocking y cuÃ¡ndo usarlo?</strong></p>
<h3>Respuesta:</h3>
<p>Mocking = reemplazar dependencias reales con objetos simulados.</p>
<pre><code class="language-python">from unittest.mock import Mock, patch

# Mockear llamada a API externa
@patch('myapp.external_api.get_customer_data')
def test_predict_with_external_data(mock_api):
    # Configurar mock
    mock_api.return_value = {&quot;credit_score&quot;: 700, &quot;age&quot;: 45}

    # Test usa el mock en lugar de API real
    result = predict_for_customer(&quot;C123&quot;)

    # Verificar que se llamÃ³
    mock_api.assert_called_once_with(&quot;C123&quot;)
    assert result is not None

# Mockear modelo para test de API
@patch('app.fastapi_app.model')
def test_predict_endpoint(mock_model):
    mock_model.predict.return_value = np.array([1])
    mock_model.predict_proba.return_value = np.array([[0.2, 0.8]])

    response = client.post(&quot;/predict&quot;, json=sample_input)
    assert response.json()[&quot;prediction&quot;] == 1
</code></pre>
<p><strong>CuÃ¡ndo usar</strong>: APIs externas, base de datos, servicios lentos.</p>
<h2>Pregunta 37: Testing de APIs</h2>
<p><strong>Â¿CÃ³mo testeas endpoints de FastAPI?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from fastapi.testclient import TestClient
from app.fastapi_app import app

client = TestClient(app)

def test_health_endpoint():
    response = client.get(&quot;/health&quot;)
    assert response.status_code == 200
    assert response.json()[&quot;status&quot;] == &quot;healthy&quot;

def test_predict_valid_input():
    response = client.post(&quot;/predict&quot;, json={
        &quot;credit_score&quot;: 650,
        &quot;age&quot;: 35,
        &quot;geography&quot;: &quot;France&quot;
    })
    assert response.status_code == 200
    assert &quot;prediction&quot; in response.json()
    assert &quot;probability&quot; in response.json()

def test_predict_invalid_input():
    response = client.post(&quot;/predict&quot;, json={
        &quot;credit_score&quot;: 9999,  # Fuera de rango
        &quot;age&quot;: 35
    })
    assert response.status_code == 422  # Validation error

def test_predict_missing_field():
    response = client.post(&quot;/predict&quot;, json={
        &quot;credit_score&quot;: 650
        # Falta age
    })
    assert response.status_code == 422
</code></pre>
<h2>Pregunta 38: Parametrized Tests</h2>
<p><strong>Â¿CÃ³mo evitas duplicaciÃ³n en tests?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import pytest

@pytest.mark.parametrize(&quot;credit_score,age,expected&quot;, [
    (300, 18, 0),   # MÃ­nimos vÃ¡lidos
    (850, 100, 1),  # MÃ¡ximos vÃ¡lidos
    (650, 45, 0),   # Caso tÃ­pico
])
def test_prediction_cases(credit_score, age, expected):
    input_data = {&quot;credit_score&quot;: credit_score, &quot;age&quot;: age}
    pred = model.predict(pd.DataFrame([input_data]))
    # Solo verificamos que no falla, no el valor exacto
    assert pred[0] in [0, 1]

@pytest.mark.parametrize(&quot;invalid_input,expected_error&quot;, [
    ({&quot;credit_score&quot;: -1}, &quot;greater than or equal to 300&quot;),
    ({&quot;credit_score&quot;: 1000}, &quot;less than or equal to 850&quot;),
    ({&quot;age&quot;: 5}, &quot;greater than or equal to 18&quot;),
])
def test_validation_errors(invalid_input, expected_error):
    response = client.post(&quot;/predict&quot;, json=invalid_input)
    assert response.status_code == 422
    assert expected_error in str(response.json())
</code></pre>
<h2>Pregunta 39: Testing de Edge Cases</h2>
<p><strong>Â¿CÃ³mo testeas edge cases en ML?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Inputs vacÃ­os
def test_empty_dataframe():
    df = pd.DataFrame()
    with pytest.raises(ValueError):
        model.predict(df)

# 2. Nulls
def test_missing_values():
    df = pd.DataFrame([{&quot;CreditScore&quot;: None, &quot;Age&quot;: 35}])
    # Pipeline debe manejar o fallar graciosamente
    result = model.predict(df)  # O pytest.raises si debe fallar

# 3. Outliers extremos
def test_extreme_values():
    df = pd.DataFrame([{
        &quot;CreditScore&quot;: 850,
        &quot;Age&quot;: 100,
        &quot;Balance&quot;: 1_000_000_000  # Outlier extremo
    }])
    pred = model.predict(df)
    assert pred[0] in [0, 1]  # No falla

# 4. Tipos incorrectos
def test_wrong_types():
    with pytest.raises(Exception):
        model.predict(&quot;not a dataframe&quot;)

# 5. Columnas faltantes
def test_missing_columns():
    df = pd.DataFrame([{&quot;CreditScore&quot;: 650}])  # Falta Age
    with pytest.raises(KeyError):
        model.predict(df)
</code></pre>
<h2>Pregunta 40: Test-Driven Development (TDD)</h2>
<p><strong>Â¿CÃ³mo aplicas TDD en ML?</strong></p>
<h3>Respuesta:</h3>
<p>TDD: Escribir test â†’ Ver que falla â†’ Implementar â†’ Ver que pasa â†’ Refactorizar.</p>
<pre><code class="language-python"># 1. Escribir test primero
def test_feature_engineer_creates_age_bucket():
    df = pd.DataFrame({&quot;age&quot;: [25, 45, 65]})
    fe = FeatureEngineer()
    result = fe.transform(df)

    assert &quot;age_bucket&quot; in result.columns
    assert list(result[&quot;age_bucket&quot;]) == [&quot;young&quot;, &quot;middle&quot;, &quot;senior&quot;]

# 2. Test falla (FeatureEngineer no existe aÃºn)
# 3. Implementar mÃ­nimo para pasar
class FeatureEngineer(BaseEstimator, TransformerMixin):
    def transform(self, X):
        X = X.copy()
        X[&quot;age_bucket&quot;] = pd.cut(
            X[&quot;age&quot;], 
            bins=[0, 30, 50, 100],
            labels=[&quot;young&quot;, &quot;middle&quot;, &quot;senior&quot;]
        )
        return X

# 4. Test pasa âœ“
# 5. Refactorizar si es necesario
</code></pre>
<p><strong>En ML, TDD es Ãºtil para</strong>:<br />
- Feature engineering (definir comportamiento esperado)<br />
- ValidaciÃ³n de datos<br />
- APIs</p>
<h1>4. Deployment y APIs (Preguntas 41-50)</h1>
<h2>Pregunta 41: FastAPI Basics</h2>
<p><strong>Muestra un endpoint de predicciÃ³n.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Input(BaseModel):
    credit_score: int
    age: int

@app.post(&quot;/predict&quot;)
def predict(data: Input):
    X = pd.DataFrame([data.dict()])
    pred = model.predict(X)
    return {&quot;prediction&quot;: int(pred[0])}
</code></pre>
<h2>Pregunta 42: Health Checks</h2>
<p><strong>Â¿Por quÃ© tener /health endpoint?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@app.get(&quot;/health&quot;)
def health():
    return {
        &quot;status&quot;: &quot;healthy&quot;,
        &quot;model_loaded&quot;: model is not None,
        &quot;version&quot;: &quot;1.0.0&quot;
    }
</code></pre>
<p>Kubernetes usa esto para saber si el pod estÃ¡ listo.</p>
<h2>Pregunta 43: Uvicorn y ASGI</h2>
<p><strong>Â¿QuÃ© es uvicorn y por quÃ© usarlo?</strong></p>
<h3>Respuesta:</h3>
<p>Uvicorn = servidor ASGI (Asynchronous Server Gateway Interface) de alto rendimiento.</p>
<pre><code class="language-bash"># Desarrollo
uvicorn app.fastapi_app:app --reload --port 8000

# ProducciÃ³n
uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000 --workers 4
</code></pre>
<p><strong>ConfiguraciÃ³n para producciÃ³n</strong>:</p>
<pre><code class="language-python"># Con gunicorn + uvicorn workers
gunicorn app.fastapi_app:app \
    --workers 4 \
    --worker-class uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:8000
</code></pre>
<p><strong>ASGI vs WSGI</strong>:</p>
<table>
<thead>
<tr>
<th>WSGI</th>
<th>ASGI</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sync only</td>
<td>Async + Sync</td>
</tr>
<tr>
<td>Flask, Django</td>
<td>FastAPI, Starlette</td>
</tr>
<tr>
<td>Una request a la vez por worker</td>
<td>MÃºltiples requests concurrentes</td>
</tr>
</tbody>
</table>
<h2>Pregunta 44: CORS Configuration</h2>
<p><strong>Â¿CÃ³mo manejas CORS en FastAPI?</strong></p>
<h3>Respuesta:</h3>
<p>CORS = Cross-Origin Resource Sharing. Necesario cuando frontend y backend estÃ¡n en dominios distintos.</p>
<pre><code class="language-python">from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        &quot;http://localhost:3000&quot;,      # React dev
        &quot;https://myapp.example.com&quot;,  # Production
    ],
    allow_credentials=True,
    allow_methods=[&quot;GET&quot;, &quot;POST&quot;],
    allow_headers=[&quot;*&quot;],
)
</code></pre>
<p><strong>En producciÃ³n</strong>: Especificar orÃ­genes exactos, no usar <code>"*"</code>.</p>
<h2>Pregunta 45: Async en FastAPI</h2>
<p><strong>Â¿CuÃ¡ndo usar async def vs def?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Sync: operaciones CPU-bound o librerÃ­as sync
@app.post(&quot;/predict&quot;)
def predict(data: Input):
    result = model.predict(data)  # sklearn es sync
    return {&quot;prediction&quot;: result}

# Async: operaciones I/O-bound
@app.get(&quot;/external-data&quot;)
async def get_external():
    async with httpx.AsyncClient() as client:
        response = await client.get(&quot;https://api.example.com/data&quot;)
    return response.json()
</code></pre>
<p><strong>Regla general</strong>:</p>
<table>
<thead>
<tr>
<th>OperaciÃ³n</th>
<th>Usar</th>
</tr>
</thead>
<tbody>
<tr>
<td>sklearn, pandas, joblib</td>
<td><code>def</code> (sync)</td>
</tr>
<tr>
<td>HTTP requests, DB async</td>
<td><code>async def</code></td>
</tr>
<tr>
<td>File I/O masivo</td>
<td><code>async def</code> con aiofiles</td>
</tr>
</tbody>
</table>
<h2>Pregunta 46: Model Caching</h2>
<p><strong>Â¿CÃ³mo evitas cargar el modelo en cada request?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># FastAPI: lru_cache
from functools import lru_cache

@lru_cache()
def get_model():
    return joblib.load(&quot;artifacts/pipeline.joblib&quot;)

@app.post(&quot;/predict&quot;)
def predict(data: Input):
    model = get_model()  # Cacheado despuÃ©s del primer call
    return model.predict(data)

# Alternativa: cargar al inicio
model = None

@app.on_event(&quot;startup&quot;)
async def load_model():
    global model
    model = joblib.load(&quot;artifacts/pipeline.joblib&quot;)
</code></pre>
<p><strong>Streamlit</strong>:</p>
<pre><code class="language-python">@st.cache_resource
def load_model():
    return joblib.load(&quot;artifacts/pipeline.joblib&quot;)

model = load_model()  # Cacheado entre reruns
</code></pre>
<h2>Pregunta 47: Streamlit Dashboard</h2>
<p><strong>Â¿CÃ³mo creas un dashboard de predicciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import streamlit as st
import pandas as pd

st.title(&quot;ğŸ¦ BankChurn Predictor&quot;)

# Sidebar para inputs
st.sidebar.header(&quot;Customer Data&quot;)
credit_score = st.sidebar.slider(&quot;Credit Score&quot;, 300, 850, 650)
age = st.sidebar.slider(&quot;Age&quot;, 18, 100, 35)
geography = st.sidebar.selectbox(&quot;Geography&quot;, [&quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;])

# Cargar modelo (cacheado)
@st.cache_resource
def load_model():
    return joblib.load(&quot;artifacts/pipeline.joblib&quot;)

model = load_model()

# PredicciÃ³n
if st.sidebar.button(&quot;Predict&quot;):
    input_df = pd.DataFrame([{
        &quot;CreditScore&quot;: credit_score,
        &quot;Age&quot;: age,
        &quot;Geography&quot;: geography
    }])

    prediction = model.predict(input_df)[0]
    proba = model.predict_proba(input_df)[0, 1]

    col1, col2 = st.columns(2)
    col1.metric(&quot;Prediction&quot;, &quot;Churn&quot; if prediction else &quot;Stay&quot;)
    col2.metric(&quot;Probability&quot;, f&quot;{proba:.1%}&quot;)
</code></pre>
<h2>Pregunta 48: Docker Compose para ML</h2>
<p><strong>Â¿CÃ³mo orquestas mÃºltiples servicios?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - &quot;8000:8000&quot;
    environment:
      - MODEL_PATH=/app/artifacts/pipeline.joblib
    volumes:
      - ./artifacts:/app/artifacts:ro
    depends_on:
      - mlflow
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:8000/health&quot;]
      interval: 30s
      timeout: 10s
      retries: 3

  mlflow:
    image: python:3.11-slim
    command: mlflow server --host 0.0.0.0
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - ./mlruns:/mlflow/mlruns

  prometheus:
    image: prom/prometheus
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
</code></pre>
<pre><code class="language-bash">docker-compose up -d
docker-compose logs -f api
</code></pre>
<h2>Pregunta 49: Kubernetes Deployment</h2>
<p><strong>Â¿CÃ³mo despliegas en Kubernetes?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bankchurn-api
  template:
    metadata:
      labels:
        app: bankchurn-api
    spec:
      containers:
      - name: api
        image: bankchurn-api:v1.0.0
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: &quot;256Mi&quot;
            cpu: &quot;250m&quot;
          limits:
            memory: &quot;512Mi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: bankchurn-api
spec:
  selector:
    app: bankchurn-api
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
</code></pre>
<pre><code class="language-bash">kubectl apply -f deployment.yaml
kubectl get pods
kubectl logs -f deployment/bankchurn-api
</code></pre>
<h2>Pregunta 50: Horizontal Pod Autoscaler</h2>
<p><strong>Â¿CÃ³mo escalas automÃ¡ticamente?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Esperar 5 min antes de escalar down
    scaleUp:
      stabilizationWindowSeconds: 60   # Escalar up mÃ¡s rÃ¡pido
</code></pre>
<pre><code class="language-bash">kubectl apply -f hpa.yaml
kubectl get hpa
# NAME                  REFERENCE              TARGETS   MINPODS   MAXPODS   REPLICAS
# bankchurn-api-hpa     Deployment/bankchurn   45%/70%   2         10        3
</code></pre>
<h1>5. Escenarios PrÃ¡cticos (Preguntas 51-60)</h1>
<h2>Pregunta 51: Debug de ProducciÃ³n</h2>
<p><strong>El modelo tiene accuracy 85% en dev pero 60% en prod. Â¿Por quÃ©?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Data drift</strong>: DistribuciÃ³n de datos cambiÃ³</li>
<li><strong>Feature mismatch</strong>: Features procesadas diferente</li>
<li><strong>Training-serving skew</strong>: Preprocesamiento distinto</li>
<li><strong>Datos de prod con mÃ¡s ruido</strong>: Edge cases no vistos</li>
</ol>
<p><strong>Acciones</strong>: Comparar distribuciones, revisar pipeline, logging de inputs.</p>
<h2>Pregunta 52: Code Review</h2>
<p><strong>Â¿QuÃ© buscas en un code review de ML?</strong></p>
<h3>Respuesta:</h3>
<ul>
<li>[ ] Data leakage en split/preprocessing</li>
<li>[ ] Tests para features y modelo</li>
<li>[ ] Config externalizada (no hardcoded)</li>
<li>[ ] Type hints y docstrings</li>
<li>[ ] Reproducibilidad (seeds, versiones)</li>
<li>[ ] Logging apropiado</li>
</ul>
<h2>Pregunta 53: Explicabilidad del Modelo</h2>
<p><strong>El cliente dice: "No puedo usar tu modelo si no me explicas por quÃ© toma las decisiones".</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">import shap

# 1. SHAP para explicaciones individuales
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_sample)

# Waterfall plot para una predicciÃ³n
shap.waterfall_plot(shap.Explanation(
    values=shap_values[0],
    base_values=explainer.expected_value,
    data=X_sample.iloc[0]
))

# 2. Feature importance global
shap.summary_plot(shap_values, X_sample)

# 3. En producciÃ³n: incluir en respuesta
@app.post(&quot;/predict&quot;)
def predict(data: Input):
    pred = model.predict(X)[0]

    # Top 3 razones
    shap_vals = explainer.shap_values(X)
    top_features = sorted(
        zip(feature_names, shap_vals[0]),
        key=lambda x: abs(x[1]),
        reverse=True
    )[:3]

    return {
        &quot;prediction&quot;: pred,
        &quot;explanation&quot;: [
            {&quot;feature&quot;: f, &quot;impact&quot;: v} 
            for f, v in top_features
        ]
    }
</code></pre>
<h2>Pregunta 54: OptimizaciÃ³n de Latencia</h2>
<p><strong>El modelo tarda 500ms por predicciÃ³n. El negocio necesita &lt;100ms.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Profiling: Â¿dÃ³nde estÃ¡ el cuello de botella?
import cProfile
cProfile.run('model.predict(X_sample)')

# 2. Opciones de optimizaciÃ³n:

# a) Modelo mÃ¡s ligero
from sklearn.linear_model import LogisticRegression
# LR es 10x mÃ¡s rÃ¡pido que RF

# b) Reducir features
from sklearn.feature_selection import SelectKBest
selector = SelectKBest(k=10)  # Solo top 10 features

# c) Batch predictions
@app.post(&quot;/predict/batch&quot;)
def predict_batch(items: List[Input]):
    X = pd.DataFrame([item.dict() for item in items])
    preds = model.predict(X)  # Una llamada, muchas predicciones
    return {&quot;predictions&quot;: preds.tolist()}

# d) Caching de predicciones frecuentes
from functools import lru_cache

@lru_cache(maxsize=1000)
def predict_cached(credit_score: int, age: int):
    return model.predict([[credit_score, age]])[0]

# e) ONNX para inferencia rÃ¡pida
from skl2onnx import convert_sklearn
onnx_model = convert_sklearn(model, initial_types=[...])
</code></pre>
<p><strong>MÃ©tricas de latencia</strong>:</p>
<table>
<thead>
<tr>
<th>OptimizaciÃ³n</th>
<th>Latencia tÃ­pica</th>
</tr>
</thead>
<tbody>
<tr>
<td>RF sklearn</td>
<td>50-200ms</td>
</tr>
<tr>
<td>LR sklearn</td>
<td>1-5ms</td>
</tr>
<tr>
<td>ONNX</td>
<td>1-10ms</td>
</tr>
<tr>
<td>Caching (hit)</td>
<td>&lt;1ms</td>
</tr>
</tbody>
</table>
<h2>Pregunta 55: Manejo de PII</h2>
<p><strong>El dataset contiene nombres, emails y telÃ©fonos. Â¿CÃ³mo lo manejas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Identificar columnas PII
pii_columns = [&quot;name&quot;, &quot;email&quot;, &quot;phone&quot;, &quot;ssn&quot;, &quot;address&quot;]

# 2. AnonimizaciÃ³n
import hashlib

def anonymize_pii(df: pd.DataFrame) -&gt; pd.DataFrame:
    df = df.copy()
    for col in pii_columns:
        if col in df.columns:
            # Hash irreversible
            df[col] = df[col].apply(
                lambda x: hashlib.sha256(str(x).encode()).hexdigest()[:16]
            )
    return df

# 3. Drop antes de training (mejor opciÃ³n)
X = df.drop(columns=pii_columns, errors='ignore')

# 4. En logs: nunca loggear PII
logger.info(f&quot;Prediction for customer {customer_id[:4]}***&quot;)

# 5. En respuestas de API: mascarar
def mask_email(email: str) -&gt; str:
    parts = email.split(&quot;@&quot;)
    return f&quot;{parts[0][:2]}***@{parts[1]}&quot;
</code></pre>
<p><strong>Compliance checklist</strong>:<br />
- [ ] PII no estÃ¡ en features del modelo<br />
- [ ] PII no aparece en logs<br />
- [ ] PII no se almacena en MLflow/tracking<br />
- [ ] Acceso a datos restringido</p>
<h2>Pregunta 56: Fairness y Bias</h2>
<p><strong>Producto detectÃ³ que el modelo rechaza mÃ¡s a clientes de cierta regiÃ³n.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">from fairlearn.metrics import MetricFrame
from sklearn.metrics import accuracy_score, recall_score

# 1. Calcular mÃ©tricas por grupo
metrics = MetricFrame(
    metrics={
        &quot;accuracy&quot;: accuracy_score,
        &quot;recall&quot;: recall_score
    },
    y_true=y_test,
    y_pred=y_pred,
    sensitive_features=df_test[&quot;geography&quot;]
)

print(metrics.by_group)
#              accuracy  recall
# geography
# France         0.85     0.80
# Germany        0.83     0.78
# Spain          0.70     0.55  # â† Problema

# 2. MitigaciÃ³n
from fairlearn.reductions import ExponentiatedGradient
from fairlearn.constraints import DemographicParity

mitigator = ExponentiatedGradient(
    estimator=base_model,
    constraints=DemographicParity()
)
mitigator.fit(X_train, y_train, sensitive_features=train_geography)

# 3. Monitoreo continuo
# Alertar si la diferencia entre grupos &gt; 10%
</code></pre>
<h2>Pregunta 57: Tests Flaky en CI</h2>
<p><strong>El CI pasa 80% de las veces y falla 20% sin cambios en cÃ³digo.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Problema comÃºn: Random sin seed
# âŒ Mal
model = RandomForestClassifier()

# âœ… Bien
model = RandomForestClassifier(random_state=42)

# 2. Problema: Orden de ejecuciÃ³n
# âŒ Mal: test depende de otro
def test_predict():
    assert model.predict(X) == [1]  # model de test anterior

# âœ… Bien: tests aislados
@pytest.fixture
def trained_model():
    m = Model()
    m.fit(X, y)
    return m

def test_predict(trained_model):
    assert trained_model.predict(X)

# 3. Problema: Timeouts en CI
# âŒ Mal
requests.get(&quot;https://external-api.com&quot;, timeout=5)

# âœ… Bien
@pytest.fixture
def mock_api():
    with patch(&quot;myapp.api.get&quot;) as mock:
        mock.return_value = {&quot;data&quot;: &quot;test&quot;}
        yield mock

# 4. Debug: Correr mÃºltiples veces
pytest tests/ --count=10  # Con pytest-repeat
</code></pre>
<h2>Pregunta 58: Modelo Grande para Deploy</h2>
<p><strong>El modelo pesa 2GB y tarda 30s en cargar. Â¿CÃ³mo optimizas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Quantization (reducir precisiÃ³n)
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic

quantize_dynamic(
    &quot;model.onnx&quot;,
    &quot;model_quantized.onnx&quot;,
    weight_type=ort.QuantType.QInt8
)
# 2GB â†’ ~500MB

# 2. Model distillation (modelo mÃ¡s pequeÃ±o que imita al grande)
teacher = load_large_model()
student = SmallModel()

# Entrenar student con outputs del teacher
student_preds = student(X)
teacher_preds = teacher(X)
loss = mse_loss(student_preds, teacher_preds)

# 3. Feature selection (menos features = modelo mÃ¡s pequeÃ±o)
from sklearn.feature_selection import SelectFromModel
selector = SelectFromModel(model, threshold=&quot;median&quot;)
X_reduced = selector.transform(X)  # Menos columnas

# 4. Lazy loading en API
model = None

@app.on_event(&quot;startup&quot;)
async def load():
    global model
    model = joblib.load(&quot;model.joblib&quot;)  # Solo una vez
</code></pre>
<h2>Pregunta 59: Muchos Falsos Positivos</h2>
<p><strong>El modelo predice churn para clientes que claramente no van a irse.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Ajustar threshold (default=0.5)
y_proba = model.predict_proba(X_test)[:, 1]

# Encontrar threshold Ã³ptimo
from sklearn.metrics import precision_recall_curve

precision, recall, thresholds = precision_recall_curve(y_test, y_proba)

# Threshold que maximiza F1
f1_scores = 2 * (precision * recall) / (precision + recall)
optimal_threshold = thresholds[np.argmax(f1_scores)]
print(f&quot;Optimal threshold: {optimal_threshold}&quot;)  # Ej: 0.65

# Usar nuevo threshold
y_pred = (y_proba &gt;= optimal_threshold).astype(int)

# 2. Revisar balance de datos
print(y_train.value_counts(normalize=True))
# Si muy desbalanceado: SMOTE, class_weight

# 3. Verificar data leakage
# Â¿Hay features que &quot;predicen perfectamente&quot;?
for col in X.columns:
    corr = X[col].corr(y)
    if abs(corr) &gt; 0.9:
        print(f&quot;âš ï¸ {col} tiene correlaciÃ³n {corr}&quot;)
</code></pre>
<h2>Pregunta 60: Comunicar a Stakeholders No TÃ©cnicos</h2>
<p><strong>El VP de producto pregunta: "Â¿Funciona o no funciona tu modelo?"</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Traducir mÃ©tricas tÃ©cnicas a impacto de negocio
&quot;&quot;&quot;
âŒ Mal: &quot;El modelo tiene AUC 0.85 y F1 0.78&quot;

âœ… Bien: 
&quot;Por cada 100 clientes que van a hacer churn:
- Detectamos 78 antes de que se vayan
- De los que marcamos como riesgo, 82% efectivamente se iban

Impacto: Si cada cliente perdido cuesta $500,
el modelo puede prevenir $31,200 en pÃ©rdidas mensuales
(78 clientes Ã— $500 Ã— 80% tasa de retenciÃ³n con intervenciÃ³n)&quot;
&quot;&quot;&quot;

# 2. Visualizaciones claras
import plotly.express as px

# Confusion matrix visual
fig = px.imshow(
    [[TN, FP], [FN, TP]],
    labels=dict(x=&quot;Predicted&quot;, y=&quot;Actual&quot;),
    x=[&quot;Stay&quot;, &quot;Churn&quot;],
    y=[&quot;Stay&quot;, &quot;Churn&quot;],
    text_auto=True
)
fig.show()

# 3. Dashboard ejecutivo en Streamlit
st.metric(&quot;Clientes en Riesgo&quot;, &quot;234&quot;, delta=&quot;-12 vs mes pasado&quot;)
st.metric(&quot;Precision RetenciÃ³n&quot;, &quot;82%&quot;, delta=&quot;+5%&quot;)
st.metric(&quot;Ahorro Estimado&quot;, &quot;$45,000/mes&quot;)
</code></pre>
<p><strong>Regla de oro</strong>: Siempre conectar con dinero o KPIs que el stakeholder ya conoce.</p>
<h1>ğŸ“š Recursos</h1>
<table>
<thead>
<tr>
<th>Tema</th>
<th>MÃ³dulo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pipelines</td>
<td><a href="#mod_07_SKLEARN_PIPELINES">07_SKLEARN_PIPELINES.md</a></td>
</tr>
<tr>
<td>Testing</td>
<td><a href="#mod_11_TESTING_ML">11_TESTING_ML.md</a></td>
</tr>
<tr>
<td>CI/CD</td>
<td><a href="#mod_12_CI_CD">12_CI_CD.md</a></td>
</tr>
<tr>
<td>Docker</td>
<td><a href="#mod_13_DOCKER">13_DOCKER.md</a></td>
</tr>
<tr>
<td>FastAPI</td>
<td><a href="#mod_14_FASTAPI">14_FASTAPI.md</a></td>
</tr>
<tr>
<td>MLflow</td>
<td><a href="#mod_10_EXPERIMENT_TRACKING">10_EXPERIMENT_TRACKING.md</a></td>
</tr>
</tbody>
</table>
<p><strong>Â¡Ã‰xito en tu entrevista! ğŸš€</strong></p>
            </div>
        
            <!-- MÃ“DULO: 16_OBSERVABILIDAD.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_16_OBSERVABILIDAD" class="cover-title">OBSERVABILIDAD</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>17. Observabilidad para ML</h1>
<h2>ğŸ¯ Objetivo del MÃ³dulo</h2>
<p>Implementar monitoreo completo: logs, mÃ©tricas, y drift detection como en el portafolio.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  &quot;Si no puedo verlo en un dashboard, no sÃ© si estÃ¡ funcionando.&quot;             â•‘
â•‘                                        â€” Mentalidad Senior                   â•‘
â•‘                                                                              â•‘
â•‘  OBSERVABILIDAD = LOGS + METRICS + TRACES + ML MONITORING                    â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ Contenido</h2>
<ol>
<li><a href="#171-las-4-seÃ±ales-de-oro">Las 4 SeÃ±ales de Oro</a></li>
<li><a href="#172-prometheus--grafana">Prometheus + Grafana</a></li>
<li><a href="#173-logging-estructurado">Logging Estructurado</a></li>
<li><a href="#174-model-monitoring">Model Monitoring</a></li>
</ol>
<h2>17.1 Las 4 SeÃ±ales de Oro</h2>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ“Š LAS 4 SEÃ‘ALES DE ORO (+ ML)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. LATENCIA          Â¿CuÃ¡nto tarda una predicciÃ³n?                         â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       Target: P99 &lt; 100ms                                   â”‚
â”‚                       Alerta: P99 &gt; 200ms                                   â”‚
â”‚                                                                             â”‚
â”‚  2. TRÃFICO           Â¿CuÃ¡ntas requests por segundo?                        â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€          Monitorear: picos, tendencias, anomalÃ­as              â”‚
â”‚                                                                             â”‚
â”‚  3. ERRORES           Â¿QuÃ© porcentaje de requests falla?                    â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€           Target: Error rate &lt; 0.1%                             â”‚
â”‚                       Alerta: Error rate &gt; 1%                               â”‚
â”‚                                                                             â”‚
â”‚  4. SATURACIÃ“N        Â¿CuÃ¡nto recurso queda?                                â”‚
â”‚     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        Alerta: CPU &gt; 80%, Memory &gt; 85%                       â”‚
â”‚                                                                             â”‚
â”‚  + ML-ESPECÃFICO:                                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚
â”‚  5. DATA DRIFT        Â¿Los datos de entrada cambiaron?                      â”‚
â”‚  6. PREDICTION DRIFT  Â¿Las predicciones cambiaron distribuciÃ³n?             â”‚
â”‚  7. MODEL DECAY       Â¿El accuracy estÃ¡ degradando?                         â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>17.2 Prometheus + Grafana</h2>
<h3>ConfiguraciÃ³n del Portafolio</h3>
<pre><code class="language-yaml"># infra/prometheus-config.yaml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'bankchurn-api'
    static_configs:
      - targets: ['bankchurn:8000']
    metrics_path: /metrics

  - job_name: 'carvision-api'
    static_configs:
      - targets: ['carvision:8000']
    metrics_path: /metrics

  - job_name: 'telecom-api'
    static_configs:
      - targets: ['telecom:8000']
    metrics_path: /metrics
</code></pre>
<h3>MÃ©tricas en FastAPI</h3>
<pre><code class="language-python"># app/metrics.py

from prometheus_client import Counter, Histogram, Gauge, generate_latest
from fastapi import Response

# MÃ©tricas
PREDICTIONS_TOTAL = Counter(
    'predictions_total',
    'Total de predicciones realizadas',
    ['model', 'result']
)

PREDICTION_LATENCY = Histogram(
    'prediction_latency_seconds',
    'Latencia de predicciones',
    ['model'],
    buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]
)

MODEL_LOADED = Gauge(
    'model_loaded',
    'Indica si el modelo estÃ¡ cargado',
    ['model']
)

PREDICTION_PROBABILITY = Histogram(
    'prediction_probability',
    'DistribuciÃ³n de probabilidades predichas',
    ['model'],
    buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
)


# Endpoint de mÃ©tricas
@app.get(&quot;/metrics&quot;)
async def metrics():
    return Response(
        content=generate_latest(),
        media_type=&quot;text/plain&quot;
    )


# Uso en predicciÃ³n
import time

@app.post(&quot;/predict&quot;)
async def predict(request: PredictionRequest):
    start = time.time()

    # ... predicciÃ³n ...
    proba = model.predict_proba(df)[0, 1]
    prediction = int(proba &gt;= 0.5)

    # Registrar mÃ©tricas
    latency = time.time() - start
    PREDICTION_LATENCY.labels(model=&quot;bankchurn&quot;).observe(latency)
    PREDICTIONS_TOTAL.labels(model=&quot;bankchurn&quot;, result=str(prediction)).inc()
    PREDICTION_PROBABILITY.labels(model=&quot;bankchurn&quot;).observe(proba)

    return {&quot;prediction&quot;: prediction, &quot;probability&quot;: proba}
</code></pre>
<h2>17.3 Logging Estructurado</h2>
<h3>ConfiguraciÃ³n Profesional</h3>
<pre><code class="language-python"># src/logging_config.py

import logging
import json
import sys
from datetime import datetime


class JSONFormatter(logging.Formatter):
    &quot;&quot;&quot;Formatter que produce logs en JSON para fÃ¡cil parsing.&quot;&quot;&quot;

    def format(self, record):
        log_obj = {
            &quot;timestamp&quot;: datetime.utcnow().isoformat(),
            &quot;level&quot;: record.levelname,
            &quot;logger&quot;: record.name,
            &quot;message&quot;: record.getMessage(),
            &quot;module&quot;: record.module,
            &quot;function&quot;: record.funcName,
            &quot;line&quot;: record.lineno,
        }

        # AÃ±adir extras si existen
        if hasattr(record, &quot;request_id&quot;):
            log_obj[&quot;request_id&quot;] = record.request_id
        if hasattr(record, &quot;user_id&quot;):
            log_obj[&quot;user_id&quot;] = record.user_id
        if hasattr(record, &quot;prediction&quot;):
            log_obj[&quot;prediction&quot;] = record.prediction

        # AÃ±adir exception si existe
        if record.exc_info:
            log_obj[&quot;exception&quot;] = self.formatException(record.exc_info)

        return json.dumps(log_obj)


def setup_logging(level: str = &quot;INFO&quot;, json_format: bool = True):
    &quot;&quot;&quot;Configura logging para producciÃ³n.&quot;&quot;&quot;

    root = logging.getLogger()
    root.setLevel(getattr(logging, level.upper()))

    handler = logging.StreamHandler(sys.stdout)

    if json_format:
        handler.setFormatter(JSONFormatter())
    else:
        handler.setFormatter(logging.Formatter(
            &quot;%(asctime)s | %(levelname)-8s | %(name)s | %(message)s&quot;
        ))

    root.addHandler(handler)

    # Silenciar loggers ruidosos
    logging.getLogger(&quot;urllib3&quot;).setLevel(logging.WARNING)
    logging.getLogger(&quot;uvicorn.access&quot;).setLevel(logging.WARNING)
</code></pre>
<h3>Logs con Contexto</h3>
<pre><code class="language-python">import logging
import uuid

logger = logging.getLogger(__name__)

@app.post(&quot;/predict&quot;)
async def predict(request: PredictionRequest):
    request_id = str(uuid.uuid4())[:8]

    # Log con contexto
    logger.info(
        &quot;Prediction request received&quot;,
        extra={
            &quot;request_id&quot;: request_id,
            &quot;credit_score&quot;: request.CreditScore,
            &quot;geography&quot;: request.Geography,
        }
    )

    try:
        prediction = model.predict(...)

        logger.info(
            &quot;Prediction completed&quot;,
            extra={
                &quot;request_id&quot;: request_id,
                &quot;prediction&quot;: prediction,
                &quot;latency_ms&quot;: latency * 1000,
            }
        )

        return {&quot;prediction&quot;: prediction}

    except Exception as e:
        logger.error(
            f&quot;Prediction failed: {str(e)}&quot;,
            extra={&quot;request_id&quot;: request_id},
            exc_info=True
        )
        raise
</code></pre>
<h2>17.4 Model Monitoring (Drift Detection)</h2>
<h3>Script de Drift Detection</h3>
<pre><code class="language-python"># monitoring/check_drift.py - CÃ³digo REAL del portafolio

&quot;&quot;&quot;
Detecta drift en datos usando Evidently AI.

Compara datos de referencia (training) con datos actuales (producciÃ³n).
Genera reporte HTML y mÃ©tricas JSON.

Uso:
    python monitoring/check_drift.py --reference data/train.csv --current data/recent.csv
&quot;&quot;&quot;

import argparse
import json
from pathlib import Path
from datetime import datetime

import pandas as pd

try:
    from evidently import ColumnMapping
    from evidently.report import Report
    from evidently.metric_preset import DataDriftPreset, DataQualityPreset
    EVIDENTLY_AVAILABLE = True
except ImportError:
    EVIDENTLY_AVAILABLE = False


def check_drift(
    reference_data: pd.DataFrame,
    current_data: pd.DataFrame,
    output_dir: Path,
    numerical_features: list = None,
    categorical_features: list = None,
) -&gt; dict:
    &quot;&quot;&quot;
    Ejecuta anÃ¡lisis de drift entre datos de referencia y actuales.

    Returns
    -------
    dict
        MÃ©tricas de drift incluyendo:
        - dataset_drift: bool (True si hay drift significativo)
        - drift_share: float (% de features con drift)
        - drifted_features: list (features con drift detectado)
    &quot;&quot;&quot;

    if not EVIDENTLY_AVAILABLE:
        return {&quot;error&quot;: &quot;Evidently no instalado&quot;, &quot;dataset_drift&quot;: None}

    # Column mapping
    column_mapping = ColumnMapping()
    if numerical_features:
        column_mapping.numerical_features = numerical_features
    if categorical_features:
        column_mapping.categorical_features = categorical_features

    # Crear reporte
    report = Report(metrics=[
        DataDriftPreset(),
        DataQualityPreset(),
    ])

    report.run(
        reference_data=reference_data,
        current_data=current_data,
        column_mapping=column_mapping
    )

    # Guardar HTML
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)

    html_path = output_dir / f&quot;drift_report_{timestamp}.html&quot;
    report.save_html(str(html_path))

    # Extraer mÃ©tricas
    results = report.as_dict()

    drift_metrics = {
        &quot;timestamp&quot;: timestamp,
        &quot;reference_rows&quot;: len(reference_data),
        &quot;current_rows&quot;: len(current_data),
        &quot;dataset_drift&quot;: False,
        &quot;drift_share&quot;: 0.0,
        &quot;drifted_features&quot;: [],
        &quot;report_path&quot;: str(html_path),
    }

    # Parsear resultados de Evidently
    for metric in results.get(&quot;metrics&quot;, []):
        if &quot;DataDriftTable&quot; in str(metric.get(&quot;metric&quot;, &quot;&quot;)):
            result = metric.get(&quot;result&quot;, {})
            drift_metrics[&quot;dataset_drift&quot;] = result.get(&quot;dataset_drift&quot;, False)
            drift_metrics[&quot;drift_share&quot;] = result.get(&quot;drift_share&quot;, 0.0)

            # Features con drift
            drift_by_columns = result.get(&quot;drift_by_columns&quot;, {})
            for col, col_data in drift_by_columns.items():
                if col_data.get(&quot;drift_detected&quot;, False):
                    drift_metrics[&quot;drifted_features&quot;].append(col)

    # Guardar mÃ©tricas JSON
    json_path = output_dir / f&quot;drift_metrics_{timestamp}.json&quot;
    with open(json_path, &quot;w&quot;) as f:
        json.dump(drift_metrics, f, indent=2)

    return drift_metrics


def main():
    parser = argparse.ArgumentParser(description=&quot;Check data drift&quot;)
    parser.add_argument(&quot;--reference&quot;, required=True, help=&quot;Path to reference data CSV&quot;)
    parser.add_argument(&quot;--current&quot;, required=True, help=&quot;Path to current data CSV&quot;)
    parser.add_argument(&quot;--output&quot;, default=&quot;artifacts&quot;, help=&quot;Output directory&quot;)
    args = parser.parse_args()

    reference = pd.read_csv(args.reference)
    current = pd.read_csv(args.current)

    metrics = check_drift(reference, current, Path(args.output))

    print(json.dumps(metrics, indent=2))

    # Exit code basado en drift
    if metrics.get(&quot;dataset_drift&quot;):
        print(&quot;âš ï¸ DRIFT DETECTADO&quot;)
        exit(1)
    else:
        print(&quot;âœ… No hay drift significativo&quot;)
        exit(0)


if __name__ == &quot;__main__&quot;:
    main()
</code></pre>
<h3>GitHub Action para Drift Scheduled</h3>
<pre><code class="language-yaml"># .github/workflows/drift-detection.yml

name: Drift Detection

on:
  schedule:
    - cron: '0 2 * * *'  # Diario a las 2am UTC
  workflow_dispatch:

jobs:
  check-drift:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pandas evidently

      - name: Run drift check
        run: |
          python monitoring/check_drift.py \
            --reference data/reference/train.csv \
            --current data/recent/latest.csv \
            --output artifacts/drift

      - name: Upload report
        uses: actions/upload-artifact@v4
        with:
          name: drift-report
          path: artifacts/drift/

      - name: Create issue if drift detected
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'âš ï¸ Data Drift Detected',
              body: 'Drift detection workflow failed. Check the artifacts.',
              labels: ['drift', 'monitoring']
            })
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en Observabilidad ML</h2>
<p>En observabilidad ML es habitual tener dashboards bonitos pero poca seÃ±al Ãºtil, o scripts de drift que fallan en silencio.</p>
<h3>1) MÃ©tricas que no aparecen en Prometheus/Grafana</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En Grafana, los paneles muestran <code>No data</code>.</li>
<li>En Prometheus, la mÃ©trica <code>predictions_total</code> no existe o tiene solo ceros.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica que el endpoint <code>/metrics</code> responde localmente (<code>curl http://localhost:8000/metrics</code>).</li>
<li>Revisa <code>prometheus-config.yaml</code>:</li>
<li>Â¿El <code>job_name</code> y <code>targets</code> apuntan al host/puerto correctos?</li>
<li>Â¿<code>metrics_path</code> es <code>/metrics</code>?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura que el API exponga <code>/metrics</code> y que el contenedor estÃ© accesible desde Prometheus (mismo docker network).</li>
<li>Usa nombres de servicio (<code>bankchurn:8000</code>) coherentes con <code>docker-compose</code>.</li>
</ul>
<h3>2) Alertas demasiado ruidosas (alert fatigue)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Canal de Slack/Email lleno de alertas constantes que el equipo ignora.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa las reglas de alerta: thresholds demasiado agresivos (por ejemplo, alertar por cualquier spike puntual).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa ventanas de tiempo y reglas de severidad (warning vs critical).</li>
<li>Define claramente mÃ©tricas <strong>crÃ­ticas</strong> (latencia P99, error rate, dataset_drift) y otras solo informativas.</li>
</ul>
<h3>3) Logs JSON imposibles de parsear</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>La herramienta de logs (ELK, Loki, etc.) no reconoce campos como <code>request_id</code> o <code>prediction</code>.</li>
<li>Aparecen lÃ­neas mezcladas de formatos distintos.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa <code>setup_logging</code>: Â¿todos los handlers usan <code>JSONFormatter</code> en producciÃ³n?</li>
<li>Busca logs que usen <code>print</code> en vez de <code>logger.info</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Centraliza la configuraciÃ³n de logging y evita crear loggers adicionales con otros formatos.</li>
<li>Usa siempre <code>extra={...}</code> en los logs de negocio en vez de concatenar strings.</li>
</ul>
<h3>4) Script de drift que falla en CI o nunca encuentra drift</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>El workflow <code>drift-detection.yml</code> falla por <code>ImportError: evidently</code> o rutas incorrectas.</li>
<li>El script siempre devuelve "âœ… No hay drift" aunque sabes que los datos cambiaron.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa los paths <code>--reference</code> y <code>--current</code> usados en el workflow.</li>
<li>Comprueba que <code>EVIDENTLY_AVAILABLE</code> es <code>True</code> y que las columnas de referencia/actual coinciden.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Alinea las rutas de datos de referencia y actuales con la estructura de tu repo.</li>
<li>AsegÃºrate de instalar <code>evidently</code> en el job de CI (<code>pip install evidently</code>).</li>
<li>Revisa el JSON de mÃ©tricas generado para validar que <code>drift_share</code> y <code>drifted_features</code> tienen sentido.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en observabilidad ML</h3>
<ol>
<li>Empieza por el <strong>flujo de datos</strong>: API â†’ <code>/metrics</code> â†’ Prometheus â†’ Grafana.</li>
<li>Verifica que logs y mÃ©tricas contengan campos de negocio (no solo tÃ©cnica bÃ¡sica).</li>
<li>Revisa periÃ³dicamente los umbrales de alerta segÃºn el comportamiento real del sistema.</li>
<li>Usa los reports de drift como insumo para decisiones, no como verdad absoluta: combÃ­nalos con mÃ©tricas de negocio.</li>
</ol>
<p>Con esta mentalidad, la observabilidad deja de ser un "extra" y se convierte en tu principal herramienta para operar modelos en producciÃ³n.</p>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Observability vs Monitoring</strong>: Monitoring = mÃ©tricas predefinidas, Observability = entender comportamiento inesperado.</p>
</li>
<li>
<p><strong>Three Pillars</strong>: Logs, Metrics, Traces. Explica cada uno.</p>
</li>
<li>
<p><strong>ML Monitoring</strong>: Model drift, data drift, concept drift.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Alertas</td>
<td>Evita alert fatigue: alerta solo lo accionable</td>
</tr>
<tr>
<td>Dashboards</td>
<td>Un dashboard por audiencia (ops, ML, negocio)</td>
</tr>
<tr>
<td>On-call</td>
<td>Documenta runbooks para cada alerta</td>
</tr>
<tr>
<td>Drift detection</td>
<td>Monitorea distribuciones de features y predictions</td>
</tr>
</tbody>
</table>
<h3>MÃ©tricas Clave para ML</h3>
<ul>
<li><strong>Serving</strong>: Latency p50/p95/p99, error rate, throughput</li>
<li><strong>Model</strong>: Prediction distribution, confidence scores</li>
<li><strong>Data</strong>: Missing values, schema changes, drift</li>
<li><strong>Business</strong>: Conversion, revenue impact</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=7gW5pSM6dlU">Prometheus + Grafana - TechWorld Nana</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=nGFnk7e3R-g">ML Monitoring with Evidently</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<p><strong>DocumentaciÃ³n oficial:</strong><br />
- <a href="https://prometheus.io/docs/">Prometheus</a><br />
- <a href="https://grafana.com/docs/">Grafana</a><br />
- <a href="https://docs.evidentlyai.com/">Evidently AI</a></p>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Data Drift</strong>: Cambio en distribuciÃ³n de features<br />
- <strong>Prometheus</strong>: Sistema de monitoreo y alertas<br />
- <strong>PSI</strong>: Population Stability Index</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 16:<br />
- <strong>16.1</strong>: Logging estructurado JSON</p>
<p><strong>Checkpoint:</strong><br />
- [ ] Tienes endpoint <code>/metrics</code> en tu API<br />
- [ ] Logs en formato JSON estructurado<br />
- [ ] Script de drift detection funcional<br />
- [ ] Alertas configuradas para mÃ©tricas crÃ­ticas</p>
            </div>
        
            <!-- MÃ“DULO: 17_DESPLIEGUE.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_17_DESPLIEGUE" class="cover-title">DESPLIEGUE</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 12: SERVERLESS VS CONTENEDORES</h1>
<h1>CuÃ¡ndo Usar Lambda, ECS o Kubernetes</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸŒ MÃ“DULO 12: Serverless vs Contenedores</h1>
<h3>La DecisiÃ³n que Define tu Arquitectura</h3>
<p><em>"No hay soluciÃ³n universal. Hay trade-offs que debes entender."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>4-5 horas</strong></td>
<td style="text-align: center;">40%</td>
<td style="text-align: center;">60%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ ADR: Â¿DÃ³nde Desplegar?</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-008: SelecciÃ³n de Plataforma de Despliegue                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  OPCIONES:                                                                    â•‘
â•‘  1. Serverless (AWS Lambda, GCP Cloud Functions)                              â•‘
â•‘  2. Contenedores Managed (ECS, Cloud Run)                                     â•‘
â•‘  3. Kubernetes (EKS, GKE, self-managed)                                       â•‘
â•‘                                                                               â•‘
â•‘  FACTORES DE DECISIÃ“N:                                                        â•‘
â•‘  â€¢ TrÃ¡fico esperado (requests/mes)                                            â•‘
â•‘  â€¢ Requisitos de latencia                                                     â•‘
â•‘  â€¢ TamaÃ±o del equipo de Ops                                                   â•‘
â•‘  â€¢ Presupuesto                                                                â•‘
â•‘  â€¢ Complejidad del modelo (GPU, memoria)                                      â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>12.1 Matriz de DecisiÃ³n</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    MATRIZ DE DECISIÃ“N DE DESPLIEGUE                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   Factor              â”‚ Lambda/Serverless â”‚ ECS/Cloud Run â”‚ Kubernetes        â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   TrÃ¡fico             â”‚ &lt; 1M req/mes      â”‚ 1M-100M       â”‚ &gt; 100M            â•‘
â•‘   Latencia            â”‚ Variable (cold)   â”‚ Consistente   â”‚ Consistente       â•‘
â•‘   Costo bajo trÃ¡fico  â”‚ ğŸ’° Muy bajo       â”‚ ğŸ’°ğŸ’° Medio    â”‚ ğŸ’°ğŸ’°ğŸ’° Alto      â•‘
â•‘   Costo alto trÃ¡fico  â”‚ ğŸ’°ğŸ’°ğŸ’° Caro       â”‚ ğŸ’°ğŸ’° Medio    â”‚ ğŸ’° Barato        â•‘
â•‘   Complejidad Ops     â”‚ â­ Baja           â”‚ â­â­ Media   â”‚ â­â­â­â­ Alta  â•‘
â•‘   Equipo necesario    â”‚ 1 persona         â”‚ 2-3 personas  â”‚ 5+ personas       â•‘
â•‘   GPU Support         â”‚ âŒ                â”‚ âœ…           â”‚ âœ…               â•‘
â•‘   Max memoria         â”‚ 10GB              â”‚ 120GB+        â”‚ Ilimitado         â•‘
â•‘   Max timeout         â”‚ 15 min            â”‚ Ilimitado     â”‚ Ilimitado         â•‘
â•‘   Modelo size lÃ­mite  â”‚ ~250MB pkg        â”‚ Sin lÃ­mite    â”‚ Sin lÃ­mite        â•‘
â•‘   Auto-scaling        â”‚ AutomÃ¡tico        â”‚ AutomÃ¡tico    â”‚ Configurable      â•‘
â•‘   Vendor lock-in      â”‚ Alto              â”‚ Medio         â”‚ Bajo              â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>12.2 OpciÃ³n 1: Serverless (AWS Lambda)</h2>
<h3>CuÃ¡ndo Usar</h3>
<pre><code>âœ… USA LAMBDA SI:
â€¢ TrÃ¡fico bajo o esporÃ¡dico (&lt; 1M requests/mes)
â€¢ Modelo pequeÃ±o (&lt; 250MB empaquetado)
â€¢ Latencia variable es aceptable
â€¢ No tienes equipo de DevOps
â€¢ Quieres minimizar costos en bajo trÃ¡fico

âŒ NO USES LAMBDA SI:
â€¢ Necesitas GPU
â€¢ Modelo &gt; 250MB
â€¢ Cold starts son inaceptables (&lt; 100ms requerido)
â€¢ TrÃ¡fico constante y alto
</code></pre>
<h3>Estructura para Lambda</h3>
<pre><code>lambda_function/
â”œâ”€â”€ handler.py          # Entry point
â”œâ”€â”€ model/
â”‚   â””â”€â”€ pipeline.pkl    # Modelo (&lt; 250MB)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ inference.py    # LÃ³gica
â””â”€â”€ requirements.txt
</code></pre>
<h3>handler.py</h3>
<pre><code class="language-python"># handler.py - AWS Lambda Handler
import json
import joblib
import pandas as pd
from pathlib import Path

# Cargar modelo al inicio (fuera del handler para reutilizar)
MODEL_PATH = Path(__file__).parent / &quot;model&quot; / &quot;pipeline.pkl&quot;
model = joblib.load(MODEL_PATH)

def lambda_handler(event, context):
    &quot;&quot;&quot;AWS Lambda handler.&quot;&quot;&quot;
    try:
        # Parse input
        if isinstance(event.get(&quot;body&quot;), str):
            body = json.loads(event[&quot;body&quot;])
        else:
            body = event.get(&quot;body&quot;, event)

        # Crear DataFrame
        df = pd.DataFrame([body])

        # Predecir
        proba = model.predict_proba(df)[0, 1]
        prediction = &quot;churn&quot; if proba &gt;= 0.5 else &quot;no_churn&quot;

        return {
            &quot;statusCode&quot;: 200,
            &quot;headers&quot;: {&quot;Content-Type&quot;: &quot;application/json&quot;},
            &quot;body&quot;: json.dumps({
                &quot;churn_probability&quot;: round(proba, 4),
                &quot;prediction&quot;: prediction,
            })
        }
    except Exception as e:
        return {
            &quot;statusCode&quot;: 500,
            &quot;body&quot;: json.dumps({&quot;error&quot;: str(e)})
        }
</code></pre>
<h3>serverless.yml (Serverless Framework)</h3>
<pre><code class="language-yaml"># serverless.yml
service: bankchurn-predictor

provider:
  name: aws
  runtime: python3.11
  region: us-east-1
  memorySize: 1024
  timeout: 30

functions:
  predict:
    handler: handler.lambda_handler
    events:
      - http:
          path: predict
          method: post
          cors: true

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: true
    slim: true
</code></pre>
<h2>12.3 OpciÃ³n 2: Contenedores Managed (AWS ECS / GCP Cloud Run)</h2>
<h3>CuÃ¡ndo Usar</h3>
<pre><code>âœ… USA ECS/CLOUD RUN SI:
â€¢ TrÃ¡fico medio-alto (1M-100M requests/mes)
â€¢ Necesitas latencia consistente
â€¢ Modelo de cualquier tamaÃ±o
â€¢ Quieres balance entre control y simplicidad
â€¢ Equipo pequeÃ±o de DevOps (2-3 personas)

âŒ NO USES SI:
â€¢ Necesitas control granular de networking
â€¢ Multi-cloud es requisito
â€¢ TrÃ¡fico extremadamente alto (&gt; 100M)
</code></pre>
<h3>AWS ECS Task Definition</h3>
<pre><code class="language-json">{
  &quot;family&quot;: &quot;bankchurn-api&quot;,
  &quot;networkMode&quot;: &quot;awsvpc&quot;,
  &quot;requiresCompatibilities&quot;: [&quot;FARGATE&quot;],
  &quot;cpu&quot;: &quot;512&quot;,
  &quot;memory&quot;: &quot;1024&quot;,
  &quot;containerDefinitions&quot;: [
    {
      &quot;name&quot;: &quot;api&quot;,
      &quot;image&quot;: &quot;123456789.dkr.ecr.us-east-1.amazonaws.com/bankchurn:latest&quot;,
      &quot;portMappings&quot;: [
        {
          &quot;containerPort&quot;: 8000,
          &quot;protocol&quot;: &quot;tcp&quot;
        }
      ],
      &quot;environment&quot;: [
        {&quot;name&quot;: &quot;LOG_LEVEL&quot;, &quot;value&quot;: &quot;INFO&quot;}
      ],
      &quot;healthCheck&quot;: {
        &quot;command&quot;: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:8000/health || exit 1&quot;],
        &quot;interval&quot;: 30,
        &quot;timeout&quot;: 5,
        &quot;retries&quot;: 3
      },
      &quot;logConfiguration&quot;: {
        &quot;logDriver&quot;: &quot;awslogs&quot;,
        &quot;options&quot;: {
          &quot;awslogs-group&quot;: &quot;/ecs/bankchurn&quot;,
          &quot;awslogs-region&quot;: &quot;us-east-1&quot;,
          &quot;awslogs-stream-prefix&quot;: &quot;api&quot;
        }
      }
    }
  ]
}
</code></pre>
<h3>GCP Cloud Run (mÃ¡s simple)</h3>
<pre><code class="language-bash"># Deploy a Cloud Run
gcloud run deploy bankchurn-api \
  --image gcr.io/my-project/bankchurn:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 1Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10 \
  --port 8000
</code></pre>
<h2>12.4 OpciÃ³n 3: Kubernetes</h2>
<h3>CuÃ¡ndo Usar</h3>
<pre><code>âœ… USA KUBERNETES SI:
â€¢ TrÃ¡fico muy alto (&gt; 100M requests/mes)
â€¢ MÃºltiples servicios ML que escalan diferente
â€¢ Necesitas GPU para inferencia
â€¢ Multi-cloud o hybrid cloud
â€¢ Equipo de Ops experimentado (5+ personas)
â€¢ Ya tienes inversiÃ³n en K8s

âŒ NO USES SI:
â€¢ Un solo modelo simple
â€¢ Equipo pequeÃ±o sin experiencia K8s
â€¢ Presupuesto limitado para Ops
</code></pre>
<h3>Manifiestos BÃ¡sicos</h3>
<pre><code class="language-yaml"># k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
  labels:
    app: bankchurn-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bankchurn-api
  template:
    metadata:
      labels:
        app: bankchurn-api
    spec:
      containers:
      - name: api
        image: ghcr.io/username/bankchurn:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: &quot;512Mi&quot;
            cpu: &quot;250m&quot;
          limits:
            memory: &quot;1Gi&quot;
            cpu: &quot;500m&quot;
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 15
          periodSeconds: 10
        env:
        - name: LOG_LEVEL
          value: &quot;INFO&quot;
---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: bankchurn-api
spec:
  selector:
    app: bankchurn-api
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP
---
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
</code></pre>
<h2>12.5 AnÃ¡lisis de Costos (FinOps)</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ANÃLISIS DE COSTOS MENSUAL                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ESCENARIO: 1M requests/mes, ~1 req/seg promedio                             â•‘
â•‘                                                                               â•‘
â•‘   AWS Lambda:                                                                 â•‘
â•‘   â€¢ 1M requests Ã— $0.20/1M = $0.20                                            â•‘
â•‘   â€¢ 1M Ã— 200ms Ã— 1GB = 200K GB-s Ã— $0.0000166 = $3.32                         â•‘
â•‘   â€¢ Total: ~$4/mes âœ… (bajo trÃ¡fico es barato)                                â•‘
â•‘                                                                               â•‘
â•‘   ECS Fargate:                                                                â•‘
â•‘   â€¢ 0.5 vCPU Ã— 730h Ã— $0.04 = $14.60                                          â•‘
â•‘   â€¢ 1GB RAM Ã— 730h Ã— $0.004 = $2.92                                           â•‘
â•‘   â€¢ Total: ~$18/mes (consistente)                                             â•‘
â•‘                                                                               â•‘
â•‘   EKS (3 nodos t3.small):                                                     â•‘
â•‘   â€¢ 3 Ã— $15/mes (EC2) = $45                                                   â•‘
â•‘   â€¢ EKS fee: $72/mes                                                          â•‘
â•‘   â€¢ Total: ~$120/mes (overkill para este volumen)                             â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ESCENARIO: 100M requests/mes, ~40 req/seg promedio                          â•‘
â•‘                                                                               â•‘
â•‘   AWS Lambda:                                                                 â•‘
â•‘   â€¢ 100M Ã— $0.20/1M = $20                                                     â•‘
â•‘   â€¢ 100M Ã— 200ms Ã— 1GB = 20M GB-s Ã— $0.0000166 = $332                         â•‘
â•‘   â€¢ Total: ~$350/mes (ya no tan barato)                                       â•‘
â•‘                                                                               â•‘
â•‘   ECS Fargate (auto-scaling):                                                 â•‘
â•‘   â€¢ ~5 tareas promedio                                                        â•‘
â•‘   â€¢ Total: ~$90/mes âœ…                                                        â•‘
â•‘                                                                               â•‘
â•‘   EKS (auto-scaling):                                                         â•‘
â•‘   â€¢ 5 nodos t3.medium promedio                                                â•‘
â•‘   â€¢ Total: ~$200/mes                                                          â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>12.6 DecisiÃ³n para BankChurn</h2>
<h3>RecomendaciÃ³n por Fase</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Fase</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: left;">RazÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>MVP/Desarrollo</strong></td>
<td style="text-align: left;">Cloud Run o Lambda</td>
<td style="text-align: left;">Simplicidad, bajo costo inicial</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ProducciÃ³n inicial</strong></td>
<td style="text-align: left;">ECS/Cloud Run</td>
<td style="text-align: left;">Balance costo-control</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Escala enterprise</strong></td>
<td style="text-align: left;">Kubernetes</td>
<td style="text-align: left;">Control total, multi-service</td>
</tr>
</tbody>
</table>
<h3>ADR para BankChurn</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-009: Despliegue de BankChurn en Cloud Run                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  DECISIÃ“N: Usar Google Cloud Run para el MVP                                  â•‘
â•‘                                                                               â•‘
â•‘  RAZONES:                                                                     â•‘
â•‘  â€¢ Escala a cero cuando no hay trÃ¡fico (costo mÃ­nimo)                         â•‘
â•‘  â€¢ Sin gestiÃ³n de infraestructura                                             â•‘
â•‘  â€¢ Latencia consistente (mejor que Lambda para ML)                            â•‘
â•‘  â€¢ Soporta contenedores Docker estÃ¡ndar                                       â•‘
â•‘  â€¢ FÃ¡cil migraciÃ³n a GKE si necesario                                         â•‘
â•‘                                                                               â•‘
â•‘  TRADE-OFFS ACEPTADOS:                                                        â•‘
â•‘  â€¢ Vendor lock-in medio (GCP)                                                 â•‘
â•‘  â€¢ Menos control que K8s                                                      â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en despliegue ML</h2>
<p>En despliegue ML es muy fÃ¡cil elegir mal la plataforma o romper detalles como puertos, healthchecks o tamaÃ±os de imagen.</p>
<h3>1) Elegir la plataforma equivocada (costos o latencia inesperados)</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Con Lambda: facturas altas al subir el trÃ¡fico o latencias variables por cold starts.</li>
<li>Con K8s: infraestructura sobredimensionada para un solo modelo simple.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara tu caso con la <strong>matriz de decisiÃ³n</strong> del mÃ³dulo (trÃ¡fico, latencia, equipo Ops, presupuesto).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Para MVPs y trÃ¡fico moderado, prefiere <strong>Cloud Run/ECS</strong> en lugar de K8s.</li>
<li>Reserva K8s para escenarios enterprise con mÃºltiples servicios y trÃ¡fico muy alto.</li>
</ul>
<h3>2) Lambdas que no despliegan o fallan al importar el modelo</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Errores como <code>Unable to import module 'handler'</code>.</li>
<li>Deployment fallido por paquete demasiado grande (&gt; 250MB).</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa el tamaÃ±o del zip y la estructura de <code>lambda_function/</code>.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Empaqueta solo lo necesario (<code>model/</code>, <code>src/</code>, <code>handler.py</code>, <code>requirements.txt</code>).</li>
<li>Usa capas o reduce dependencias pesadas si es posible.</li>
</ul>
<h3>3) Contenedores que arrancan pero nunca pasan el healthcheck</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>En ECS/Cloud Run/K8s el servicio queda en estado <code>UNHEALTHY</code> o se reinicia en bucle.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara el <code>healthCheck</code>/<code>readinessProbe</code> con los endpoints reales (<code>/health</code>, puerto 8000). </li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura que tu API expone exactamente el endpoint y puerto que la plataforma espera.</li>
<li>Ajusta <code>initialDelaySeconds</code>/<code>timeout</code> si el modelo tarda en cargar.</li>
</ul>
<h3>4) Puertos y rutas inconsistentes entre Docker y la plataforma</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Funciona en <code>docker run -p 8000:8000</code> pero falla al desplegar en Cloud Run/ECS.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica que el <code>EXPOSE</code> del Dockerfile, el puerto del servidor (uvicorn) y el puerto configurado en la plataforma coincidan.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Usa un puerto estÃ¡ndar (8000) y mantÃ©n el mismo valor en Dockerfile y manifiestos.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en despliegue ML</h3>
<ol>
<li>Verifica primero que la imagen Docker funciona <strong>en local</strong> (<code>docker run</code> + <code>curl /health</code>).</li>
<li>Revisa logs de la plataforma (Lambda logs, Cloud Run logs, ECS/K8s events) para ver errores reales.</li>
<li>Comprueba healthchecks, puertos y variables de entorno.</li>
<li>Ajusta la plataforma elegida si tus patrones de trÃ¡fico o equipo no encajan con la decisiÃ³n inicial.</li>
</ol>
<p>Con esta disciplina, pasar de local a producciÃ³n se vuelve un proceso repetible y menos doloroso.</p>
<h2>12.7 Ejercicio: Deploy a Cloud Run</h2>
<pre><code class="language-bash"># 1. Build imagen
docker build -t gcr.io/my-project/bankchurn:v1 .

# 2. Push a GCR
docker push gcr.io/my-project/bankchurn:v1

# 3. Deploy
gcloud run deploy bankchurn \
  --image gcr.io/my-project/bankchurn:v1 \
  --platform managed \
  --region us-central1 \
  --memory 1Gi \
  --allow-unauthenticated

# 4. Test
curl -X POST https://bankchurn-xxx.run.app/api/v1/predict \
  -H &quot;Content-Type: application/json&quot; \
  -d '{&quot;credit_score&quot;: 650, &quot;age&quot;: 35, ...}'
</code></pre>
<h2>ğŸ“‹ Operaciones y Runbooks</h2>
<h3>Estructura de un Runbook ML</h3>
<pre><code class="language-markdown"># Runbook: [Nombre del Servicio]

## InformaciÃ³n del Servicio
- **PropÃ³sito**: PredicciÃ³n de churn
- **Owner**: ML Team
- **Criticality**: Tier 2

## Endpoints
| Endpoint | DescripciÃ³n | SLO |
|----------|-------------|-----|
| /health | Health check | 99.9% |
| /predict | PredicciÃ³n | p99 &lt; 200ms |

## Alertas Comunes

### Alta Latencia (&gt; 500ms)
1. Verificar mÃ©tricas: `kubectl top pods`
2. Revisar logs: `kubectl logs -f deploy/bankchurn-api`
3. Escalar si es necesario: `kubectl scale deploy/bankchurn-api --replicas=5`

### Error Rate &gt; 5%
1. Verificar modelo: Â¿CambiÃ³ la distribuciÃ³n de inputs?
2. Revisar logs de errores
3. Rollback si es necesario: `kubectl rollout undo deploy/bankchurn-api`

## Procedimientos de Emergencia
- **Rollback**: `make rollback VERSION=v1.0.0`
- **Escalar**: `kubectl scale deploy/bankchurn-api --replicas=10`
- **Deshabilitar**: `kubectl scale deploy/bankchurn-api --replicas=0`
</code></pre>
<h3>SLOs para APIs ML</h3>
<pre><code class="language-yaml"># Ejemplo de SLOs
slos:
  availability:
    target: 99.5%
    window: 30d

  latency:
    p50: 50ms
    p95: 150ms
    p99: 300ms

  error_rate:
    target: &lt; 1%

  prediction_quality:
    accuracy_drift: &lt; 5%  # vs baseline
</code></pre>
<h3>Checklist de Operaciones</h3>
<ul>
<li>[ ] <strong>Monitoreo activo</strong>: Dashboards y alertas configurados</li>
<li>[ ] <strong>Runbook documentado</strong>: Procedimientos de respuesta</li>
<li>[ ] <strong>Rollback probado</strong>: Capacidad de volver a versiÃ³n anterior</li>
<li>[ ] <strong>Escalado automÃ¡tico</strong>: HPA configurado</li>
<li>[ ] <strong>Logs centralizados</strong>: Acceso a logs histÃ³ricos</li>
<li>[ ] <strong>On-call definido</strong>: RotaciÃ³n y escalamiento</li>
</ul>
<blockquote>
<p>ğŸ“– Ver ejemplo completo en el <a href="#mod_OPERATIONS_PORTFOLIO">Runbook del Portafolio</a>.</p>
</blockquote>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Deployment Strategies</strong>: Blue-green, canary, rolling. Pros y cons de cada uno.</p>
</li>
<li>
<p><strong>A/B Testing</strong>: CÃ³mo evaluar modelos en producciÃ³n con trÃ¡fico real.</p>
</li>
<li>
<p><strong>Rollback</strong>: Siempre ten plan de rollback automÃ¡tico.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Nuevo modelo</td>
<td>Canary deployment con 5% de trÃ¡fico</td>
</tr>
<tr>
<td>Alta disponibilidad</td>
<td>MÃºltiples rÃ©plicas + load balancer</td>
</tr>
<tr>
<td>Modelo grande</td>
<td>Considera serverless o batch serving</td>
</tr>
<tr>
<td>Costos</td>
<td>Autoscaling basado en trÃ¡fico real</td>
</tr>
</tbody>
</table>
<h3>Checklist Pre-Deployment</h3>
<ul>
<li>[ ] Tests pasando en staging</li>
<li>[ ] MÃ©tricas baseline documentadas</li>
<li>[ ] Runbook actualizado</li>
<li>[ ] Rollback probado</li>
<li>[ ] Alertas configuradas</li>
<li>[ ] ComunicaciÃ³n a stakeholders</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=3c-iBn73dDE">Docker Deploy - TechWorld Nana</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=3OP-q55hOUI">Cloud Run Tutorial</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Multi-stage Build</strong>: OptimizaciÃ³n de imÃ¡genes Docker<br />
- <strong>Cloud Run</strong>: Serverless containers de GCP<br />
- <strong>Non-root user</strong>: Seguridad en contenedores</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 17:<br />
- <strong>17.1</strong>: Dockerfile multi-stage<br />
- <strong>17.2</strong>: Docker Compose para stack ML</p>
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con la plataforma elegida, es hora de gestionar <strong>infraestructura como cÃ³digo</strong>.</p>
<p><strong><a href="#mod_18_INFRAESTRUCTURA">Ir a MÃ³dulo 18: Infraestructura como CÃ³digo â†’</a></strong></p>
            </div>
        
            <!-- MÃ“DULO: 18_INFRAESTRUCTURA.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_18_INFRAESTRUCTURA" class="cover-title">INFRAESTRUCTURA</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>18. Infraestructura como CÃ³digo</h1>
<h2>ğŸ¯ Objetivo</h2>
<p>Conceptos de IaC (Terraform) y orquestaciÃ³n (Kubernetes) para despliegue ML.</p>
<blockquote>
<p><strong>Nota</strong>: Este mÃ³dulo es AVANZADO. Para el portafolio actual, Docker + GitHub Actions es suficiente.</p>
</blockquote>
<h2>Terraform BÃ¡sico</h2>
<h3>Concepto</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  TERRAFORM = Definir infraestructura en cÃ³digo                            â•‘
â•‘                                                                           â•‘
â•‘  En lugar de:                                                             â•‘
â•‘  &quot;Crear una instancia EC2 manualmente en la consola AWS&quot;                  â•‘
â•‘                                                                           â•‘
â•‘  Escribes:                                                                â•‘
â•‘  resource &quot;aws_instance&quot; &quot;ml_server&quot; {                                    â•‘
â•‘    ami           = &quot;ami-12345&quot;                                            â•‘
â•‘    instance_type = &quot;t3.medium&quot;                                            â•‘
â•‘  }                                                                        â•‘
â•‘                                                                           â•‘
â•‘  Beneficios:                                                              â•‘
â•‘  â€¢ Reproducible                                                           â•‘
â•‘  â€¢ Versionado en Git                                                      â•‘
â•‘  â€¢ Auditado                                                               â•‘
â•‘  â€¢ Destruir y recrear fÃ¡cilmente                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Estructura TÃ­pica</h3>
<pre><code class="language-hcl"># main.tf

terraform {
  required_providers {
    aws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 5.0&quot;
    }
  }
}

provider &quot;aws&quot; {
  region = var.region
}

# ECS para ML API
resource &quot;aws_ecs_cluster&quot; &quot;ml_cluster&quot; {
  name = &quot;ml-portfolio-cluster&quot;
}

resource &quot;aws_ecs_service&quot; &quot;bankchurn_api&quot; {
  name            = &quot;bankchurn-api&quot;
  cluster         = aws_ecs_cluster.ml_cluster.id
  task_definition = aws_ecs_task_definition.bankchurn.arn
  desired_count   = 2

  load_balancer {
    target_group_arn = aws_lb_target_group.bankchurn.arn
    container_name   = &quot;bankchurn&quot;
    container_port   = 8000
  }
}
</code></pre>
<h2>Kubernetes BÃ¡sico</h2>
<h3>Concepto</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  KUBERNETES = Orquestar contenedores a escala                             â•‘
â•‘                                                                           â•‘
â•‘  Pod: Un contenedor corriendo                                             â•‘
â•‘  Deployment: N rÃ©plicas de un Pod                                         â•‘
â•‘  Service: Exponer Pods a la red                                           â•‘
â•‘  Ingress: Routing HTTP externo                                            â•‘
â•‘                                                                           â•‘
â•‘  Para ML:                                                                 â•‘
â•‘  â€¢ Deployment para API de inferencia                                      â•‘
â•‘  â€¢ HPA (Horizontal Pod Autoscaler) para escalar con carga                 â•‘
â•‘  â€¢ Secrets para API keys y credenciales                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h3>Deployment YAML</h3>
<pre><code class="language-yaml"># k8s/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
  labels:
    app: bankchurn
spec:
  replicas: 2
  selector:
    matchLabels:
      app: bankchurn
  template:
    metadata:
      labels:
        app: bankchurn
    spec:
      containers:
      - name: bankchurn
        image: ghcr.io/user/bankchurn:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: &quot;256Mi&quot;
            cpu: &quot;250m&quot;
          limits:
            memory: &quot;512Mi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        env:
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            secretKeyRef:
              name: ml-secrets
              key: mlflow-uri
---
apiVersion: v1
kind: Service
metadata:
  name: bankchurn-service
spec:
  selector:
    app: bankchurn
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
</code></pre>
<h2>Â¿CuÃ¡ndo Usar QuÃ©?</h2>
<table>
<thead>
<tr>
<th>Escenario</th>
<th>SoluciÃ³n Recomendada</th>
</tr>
</thead>
<tbody>
<tr>
<td>Proyecto personal/demo</td>
<td>Docker + docker-compose</td>
</tr>
<tr>
<td>Startup pequeÃ±a</td>
<td>ECS Fargate o Cloud Run</td>
</tr>
<tr>
<td>Empresa mediana</td>
<td>EKS/GKE con Terraform</td>
</tr>
<tr>
<td>Enterprise</td>
<td>Full K8s + GitOps (ArgoCD)</td>
</tr>
</tbody>
</table>
<h3>Para Este Portafolio</h3>
<p><strong>Docker + GitHub Actions es suficiente.</strong></p>
<p>Terraform y K8s son skills valiosos, pero no necesarios para demostrar competencia MLOps en proyectos de portafolio.</p>
<h2>Cloud y Control de Costos (FinOps para MLOps)</h2>
<blockquote>
<p>Objetivo: que no te llegue una factura de 500 USD por dejar un cluster o una GPU encendidos sin uso.</p>
</blockquote>
<h3>1) Modelo mental de costos en cloud</h3>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  REGLA DE ORO: En cloud, TODO lo que corre o almacena datos tiene costo.  â•‘
â•‘                                                                           â•‘
â•‘  Principales drivers de costo en MLOps:                                   â•‘
â•‘  â€¢ CÃ³mputo: EC2/VMs, nodos de K8s, GPUs, Jobs de entrenamiento            â•‘
â•‘  â€¢ Almacenamiento: S3/GCS, volÃºmenes, snapshots, buckets &quot;olvidados&quot;     â•‘
â•‘  â€¢ Networking: trÃ¡fico de salida (egress), balanceadores de carga         â•‘
â•‘  â€¢ Servicios gestionados: EKS/GKE fee, bases de datos, colas, etc.       â•‘
â•‘                                                                           â•‘
â•‘  Pregunta que siempre debes hacerte:                                      â•‘
â•‘  &quot;Â¿Este recurso estÃ¡ generando valor AHORA MISMO o podrÃ­a estar apagado?&quot;â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<p>Buena parte del FinOps (gestiÃ³n financiera en cloud) se reduce a:</p>
<ul>
<li><strong>Apagar lo que no usas</strong> (clusters, GPUs, VMs demo).</li>
<li><strong>Que los recursos escalen a cero</strong> cuando no hay trÃ¡fico.</li>
<li><strong>Poner lÃ­mites y alertas</strong> antes de que llegue una sorpresa.</li>
</ul>
<h3>2) Alertas de facturaciÃ³n mÃ­nimas en AWS y GCP</h3>
<h4>AWS: AWS Budgets + Cost Explorer</h4>
<ul>
<li><strong>Paso 1</strong>: Ir a <code>Billing &gt; Budgets</code> y crear un <strong>Budget mensual</strong> por cuenta o proyecto.</li>
<li><strong>Paso 2</strong>: Configurar umbrales tÃ­picos, por ejemplo:</li>
<li>50% del presupuesto â†’ alerta informativa.</li>
<li>80% del presupuesto â†’ alerta de acciÃ³n (revisar recursos).</li>
<li>100% del presupuesto â†’ posible freeze de entornos no crÃ­ticos.</li>
<li><strong>Paso 3</strong>: Enviar alertas a:</li>
<li>Email del equipo.</li>
<li>(Opcional) SNS â†’ Slack/Teams.</li>
<li><strong>Paso 4</strong>: Activar <strong>Cost Explorer</strong> para revisar quÃ© servicio estÃ¡ creciendo (EKS, EC2, S3, etc.).</li>
</ul>
<blockquote>
<p>ğŸ’¡ En entrevistas, menciona que siempre configuras <strong>AWS Budgets</strong> en cuentas nuevas y usas <strong>Cost Allocation Tags</strong> (<code>Project</code>, <code>Env</code>, <code>Owner</code>) para saber quiÃ©n gasta quÃ©.</p>
</blockquote>
<h4>GCP: Presupuestos y alertas en Cloud Billing</h4>
<ul>
<li><strong>Paso 1</strong>: Entra a <code>Billing &gt; Budgets &amp; alerts</code> y crea un <strong>presupuesto por proyecto</strong>.</li>
<li><strong>Paso 2</strong>: Define umbrales 50/80/100% y activa notificaciones por correo.</li>
<li><strong>Paso 3</strong>: Opcionalmente integra con <strong>Cloud Monitoring</strong> para disparar alertas a Slack/PagerDuty.</li>
<li><strong>Paso 4</strong>: Usa el reporte de <strong>Cost breakdown</strong> para identificar servicios caros (GKE, Cloud Run, BigQuery, etc.).</li>
</ul>
<p>Checklist rÃ¡pido para cualquier cuenta cloud nueva:</p>
<ul>
<li>[ ] Presupuesto mensual configurado.</li>
<li>[ ] Alertas a 50/80/100% del presupuesto.</li>
<li>[ ] Etiquetas/labels de costo definidas (<code>project</code>, <code>env</code>, <code>owner</code>).</li>
<li>[ ] Entornos <strong>dev/staging</strong> con lÃ­mites de gasto mÃ¡s agresivos.</li>
</ul>
<h3>3) Errores frecuentes de costo en MLOps y cÃ³mo evitarlos</h3>
<h4>a) Dejar un cluster de Kubernetes encendido sin trÃ¡fico</h4>
<p><strong>Escenario tÃ­pico</strong>: EKS/GKE creado para pruebas, sin pods crÃ­ticos, pero:</p>
<ul>
<li>Los <strong>nodos</strong> siguen encendidos.</li>
<li>EKS cobra una <strong>tarifa fija por cluster</strong>.</li>
<li>Hay LoadBalancers y volÃºmenes asociados que nadie recuerda.</li>
</ul>
<p><strong>SeÃ±ales de alarma</strong></p>
<ul>
<li>Factura con lÃ­neas como <code>EKS cluster fee</code>, <code>Compute Engine</code>, <code>Load Balancer</code> sin apenas requests.</li>
<li><code>kubectl get pods -A</code> muestra casi todo idle.</li>
</ul>
<p><strong>Buenas prÃ¡cticas</strong></p>
<ul>
<li>Para <strong>dev/staging</strong>, preferir:</li>
<li>Cloud Run/ECS con <code>min-instances = 0</code> o tareas bajo demanda.</li>
<li>Clusters efÃ­meros destruidos con <code>terraform destroy</code> o scripts programados.</li>
<li>Configurar <strong>cluster autoscaler</strong> con <code>minNodes = 0</code> en nodos no crÃ­ticos.</li>
<li>Revisar mensualmente: <code>kubectl get nodes -A</code> + panel de uso de CPU/RAM.</li>
</ul>
<h4>b) GPUs encendidas 24/7 para entrenamiento puntual</h4>
<ul>
<li><strong>Problema</strong>: nodos GPU (p.ej. <code>p3</code>, <code>a2-highgpu</code>) usados una vez al dÃ­a pero pagando 24/7.</li>
<li><strong>SoluciÃ³n</strong>:</li>
<li>Usar <strong>jobs efÃ­meros</strong> (Spot/Preemptible) y destruirlos al terminar.</li>
<li>Automatizar con IaC (<code>terraform apply</code> / <code>destroy</code>) o workflows de CI/CD.</li>
<li>Para portafolios, priorizar entrenamiento <strong>local</strong> y solo usar GPU cloud en casos concretos.</li>
</ul>
<h4>c) ConfiguraciÃ³n "cÃ³moda" pero cara en serverless</h4>
<ul>
<li>En Cloud Run/Lambda es fÃ¡cil poner:</li>
<li><code>min-instances</code> &gt; 0 en todos los servicios.</li>
<li>Timeouts muy altos con mucha memoria.</li>
<li><strong>Reglas sanas</strong>:</li>
<li>Entornos <strong>dev/staging</strong>: <code>min-instances = 0</code> y lÃ­mites de memoria modestos.</li>
<li>Reservar configuraciones "grandes" para prod con justificaciÃ³n.</li>
</ul>
<h3>4) Checklist de costos por entorno</h3>
<table>
<thead>
<tr>
<th>Entorno</th>
<th>PatrÃ³n recomendado</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dev</td>
<td>Cloud Run/ECS con <code>min-instances = 0</code>, sin clusters K8s dedicados</td>
</tr>
<tr>
<td>Staging</td>
<td>Igual que dev, pero con presupuestos y alertas separados</td>
</tr>
<tr>
<td>Prod</td>
<td>K8s/cloud gestionado solo si hay trÃ¡fico real y equipo de Ops suficiente</td>
</tr>
</tbody>
</table>
<ul>
<li>[ ] Hay un <strong>owner claro</strong> por entorno (quien responde a la factura).</li>
<li>[ ] Cada recurso tiene <strong>tags/labels</strong> de <code>project</code>, <code>env</code>, <code>owner</code>.</li>
<li>[ ] Hay un <strong>runbook</strong> para apagar recursos no crÃ­ticos fuera de horario (scripts/programado).</li>
</ul>
<h3>5) Consejos profesionales orientados a entrevistas</h3>
<ul>
<li><strong>Cuenta una historia realista</strong>: "Nos llegÃ³ una factura alta por X; la mitigaciÃ³n fue: budgets, etiquetado, autoscaling y IaC para destruir entornos efÃ­meros".</li>
<li>Menciona explÃ­citamente:</li>
<li><strong>Presupuestos y alertas de facturaciÃ³n</strong> (AWS Budgets / GCP Budgets).</li>
<li><strong>Autoscaling a cero</strong> para workloads de baja criticidad.</li>
<li><strong>Tags/labels de costo</strong> como requisito obligatorio.</li>
<li>Conecta esta secciÃ³n con:</li>
<li>La <strong>matriz de costo</strong> del mÃ³dulo de despliegue (<code>17_DESPLIEGUE.md</code>).</li>
<li>Las <strong>mÃ©tricas y alertas</strong> vistas en observabilidad (<code>16_OBSERVABILIDAD.md</code>).</li>
</ul>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en Infraestructura como CÃ³digo</h2>
<p>Aunque este mÃ³dulo es avanzado, es comÃºn cometer errores que dejan tu IaC frÃ¡gil o inconsistente.</p>
<h3>1) Terraform aplicado â€œa manoâ€ sin estado controlado</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Se ejecuta <code>terraform apply</code> desde distintas mÃ¡quinas sin control del <code>terraform.tfstate</code>.</li>
<li>Recursos que aparecen duplicados o que se destruyen sin querer.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Verifica dÃ³nde se guarda el estado: local vs backend remoto (S3, GCS, etc.).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Para proyectos serios, usa un <strong>backend remoto</strong> para el estado y controla quiÃ©n puede aplicar cambios.</li>
</ul>
<h3>2) Manifiestos de K8s que funcionan en minikube pero no en cloud</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Deployment correcto en local, pero en EKS/GKE los Pods quedan <code>CrashLoopBackOff</code> o <code>ImagePullBackOff</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa la imagen referenciada (<code>image:</code>) y las credenciales de registry.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Asegura que la imagen estÃ© en un registry accesible desde el cluster (ECR/GCR/GHCR) y que el cluster tenga permisos para leerla.</li>
</ul>
<h3>3) Resources/limits mal configurados en K8s</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Pods que se matan por OOMKilled o throttling excesivo de CPU.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Observa eventos del Pod y mÃ©tricas de consumo real.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Ajusta <code>requests</code> y <code>limits</code> segÃºn el perfil real de uso de tu API ML, empezando conservador y ajustando con mÃ©tricas.</li>
</ul>
<h3>4) Â¿CuÃ¡ndo escalar mÃ¡s allÃ¡ de Docker?</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Intentar introducir Terraform/K8s en un proyecto de portafolio cuando aÃºn no dominas Docker + CI/CD.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Si todavÃ­a no tienes un flujo sÃ³lido con Docker + GitHub Actions, probablemente es pronto para meter K8s.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Sigue la recomendaciÃ³n del mÃ³dulo: primero domina Docker + CI/CD. Usa IaC/K8s solo si tu contexto profesional lo exige.</li>
</ul>
<h3>5) PatrÃ³n general de debugging en IaC</h3>
<ol>
<li>Aplica primero en entornos de prueba pequeÃ±os (playgrounds, sandbox).</li>
<li>Revisa siempre el <strong>plan</strong> (<code>terraform plan</code>, <code>kubectl diff</code>) antes de aplicar.</li>
<li>Usa mÃ©tricas y eventos del cluster para ajustar configuraciÃ³n en lugar de adivinar.</li>
</ol>
<p>Con este enfoque, IaC y K8s se vuelven herramientas que suman, no otra fuente de problemas.</p>
<h2>Horizontal Pod Autoscaler (HPA)</h2>
<p>El HPA escala automÃ¡ticamente los pods basÃ¡ndose en mÃ©tricas como CPU o memoria.</p>
<pre><code class="language-yaml"># k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-hpa
  namespace: mlops
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # Esperar 5 min antes de escalar abajo
    scaleUp:
      stabilizationWindowSeconds: 0    # Escalar arriba inmediatamente
</code></pre>
<p><strong>Â¿Por quÃ© 70% CPU?</strong> Es un balance entre eficiencia (no desperdiciar recursos) y capacidad de respuesta (tener margen para picos).</p>
<h2>ConfigMaps y Secrets</h2>
<h3>ConfigMap (configuraciÃ³n no sensible)</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: bankchurn-config
  namespace: mlops
data:
  LOG_LEVEL: &quot;INFO&quot;
  MODEL_PATH: &quot;/app/artifacts/model.joblib&quot;
  MLFLOW_TRACKING_URI: &quot;http://mlflow-service:5000&quot;
</code></pre>
<h3>Secret (ejemplo didÃ¡ctico, <strong>no usar en producciÃ³n</strong>)</h3>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: ml-secrets
  namespace: mlops
type: Opaque
data:
  # Valores de ejemplo. En un entorno real se inyectan desde el sistema de secretos.
  database-password: REEMPLAZAR_EN_ENTORNO_REAL
  api-key: REEMPLAZAR_EN_ENTORNO_REAL
</code></pre>
<h3>Uso en Deployment</h3>
<pre><code class="language-yaml">spec:
  containers:
  - name: bankchurn
    envFrom:
    - configMapRef:
        name: bankchurn-config
    - secretRef:
        name: ml-secrets
</code></pre>
<h2>Ingress para Routing HTTP</h2>
<pre><code class="language-yaml"># k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: mlops-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: api.mlops.example.com
    http:
      paths:
      - path: /bankchurn
        pathType: Prefix
        backend:
          service:
            name: bankchurn-service
            port:
              number: 80
      - path: /carvision
        pathType: Prefix
        backend:
          service:
            name: carvision-service
            port:
              number: 80
</code></pre>
<h2>ğŸ“¦ CÃ³mo se usÃ³ en el Portafolio</h2>
<p>El directorio <code>k8s/</code> del portafolio contiene 8 manifests production-ready:</p>
<table>
<thead>
<tr>
<th>Archivo</th>
<th>PropÃ³sito</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>namespace.yaml</code></td>
<td>Namespace <code>mlops</code> aislado</td>
</tr>
<tr>
<td><code>bankchurn-deployment.yaml</code></td>
<td>Deployment + Service + HPA</td>
</tr>
<tr>
<td><code>carvision-deployment.yaml</code></td>
<td>Deployment + Service</td>
</tr>
<tr>
<td><code>telecom-deployment.yaml</code></td>
<td>Deployment + Service</td>
</tr>
<tr>
<td><code>prometheus-deployment.yaml</code></td>
<td>Monitoreo</td>
</tr>
<tr>
<td><code>grafana-deployment.yaml</code></td>
<td>Dashboards</td>
</tr>
<tr>
<td><code>ingress.yaml</code></td>
<td>Routing HTTP</td>
</tr>
<tr>
<td><code>storage.yaml</code></td>
<td>PersistentVolumeClaims</td>
</tr>
</tbody>
</table>
<p><strong>Comandos Ãºtiles:</strong></p>
<pre><code class="language-bash"># Aplicar todos los manifests
kubectl apply -f k8s/

# Ver estado de pods
kubectl get pods -n mlops

# Ver logs de un pod
kubectl logs -f deployment/bankchurn-api -n mlops

# Escalar manualmente (si no usas HPA)
kubectl scale deployment bankchurn-api --replicas=3 -n mlops

# Port-forward para testing local
kubectl port-forward svc/bankchurn-service 8001:80 -n mlops
</code></pre>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>IaC (Infrastructure as Code)</strong>: Por quÃ© Terraform/Pulumi sobre click-ops.</p>
</li>
<li>
<p><strong>Kubernetes basics</strong>: Pods, Deployments, Services, ConfigMaps.</p>
</li>
<li>
<p><strong>Cloud agnostic</strong>: DiseÃ±a para portabilidad cuando sea posible.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>SituaciÃ³n</th>
<th>Consejo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multi-environment</td>
<td>Usa Terraform workspaces o directorios</td>
</tr>
<tr>
<td>Secrets</td>
<td>External Secrets Operator o cloud-native solutions</td>
</tr>
<tr>
<td>Costos</td>
<td>Tagging obligatorio para cost allocation</td>
</tr>
<tr>
<td>DR (Disaster Recovery)</td>
<td>Documenta y prueba regularmente</td>
</tr>
</tbody>
</table>
<h3>Stack Recomendado</h3>
<pre><code>IaC:        Terraform + Terragrunt
Containers: Docker + Kubernetes
CI/CD:      GitHub Actions + ArgoCD
Secrets:    Vault o AWS Secrets Manager
Monitoring: Prometheus + Grafana
</code></pre>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
<th style="text-align: center;">DuraciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=X48VuDVv0do">Kubernetes Tutorial - TechWorld Nana</a></td>
<td style="text-align: left;">Video</td>
<td style="text-align: center;">4h</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=7xngnjfIlK4">Terraform Tutorial - freeCodeCamp</a></td>
<td style="text-align: left;">Video</td>
<td style="text-align: center;">2.5h</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://training.linuxfoundation.org/">Kubernetes Fundamentals - LF</a></td>
<td style="text-align: left;">Curso</td>
<td style="text-align: center;">35h</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones detalladas de:<br />
- <strong>Kubernetes</strong>: OrquestaciÃ³n de contenedores<br />
- <strong>HPA</strong>: Horizontal Pod Autoscaler<br />
- <strong>ConfigMap/Secret</strong>: ConfiguraciÃ³n en K8s<br />
- <strong>Terraform</strong>: Infrastructure as Code</p>
<h2>âœ… Checkpoint</h2>
<p>Para este nivel:<br />
- [ ] Entiendes el concepto de IaC (infraestructura como cÃ³digo)<br />
- [ ] Puedes leer un deployment.yaml de K8s<br />
- [ ] Sabes quÃ© hace un HPA y cuÃ¡ndo usarlo<br />
- [ ] Entiendes la diferencia entre ConfigMap y Secret<br />
- [ ] Sabes cuÃ¡ndo escalar mÃ¡s allÃ¡ de Docker</p>
<p><strong>Ejercicios</strong>: Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulos 17-18</p>
            </div>
        
            <!-- MÃ“DULO: 19_DOCUMENTACION.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_19_DOCUMENTACION" class="cover-title">DOCUMENTACIÃ“N</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 16: DOCUMENTACIÃ“N Y Ã‰TICA</h1>
<h1>MkDocs, Model Cards y Responsible AI</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025</h1>
<h1>ğŸ“š MÃ“DULO 16: DocumentaciÃ³n y Ã‰tica</h1>
<h3>Tu Trabajo No Existe Si No EstÃ¡ Documentado</h3>
<p><em>"La documentaciÃ³n es el regalo que le haces a tu yo del futuro."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: center;">TeorÃ­a</th>
<th style="text-align: center;">PrÃ¡ctica</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><strong>4-5 horas</strong></td>
<td style="text-align: center;">30%</td>
<td style="text-align: center;">70%</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ Lo Que LograrÃ¡s</h2>
<ol>
<li><strong>Crear</strong> documentaciÃ³n tÃ©cnica con MkDocs</li>
<li><strong>Escribir</strong> Model Cards profesionales</li>
<li><strong>Implementar</strong> prÃ¡cticas de Responsible AI</li>
<li><strong>Publicar</strong> docs en GitHub Pages</li>
</ol>
<h2>16.1 MkDocs con Material Theme</h2>
<h3>Estructura de Docs</h3>
<pre><code>docs/
â”œâ”€â”€ index.md                # Home
â”œâ”€â”€ getting-started/
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ quickstart.md
â”‚   â””â”€â”€ configuration.md
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ overview.md
â”‚   â”œâ”€â”€ data-flow.md
â”‚   â””â”€â”€ decisions.md
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ endpoints.md
â”‚   â””â”€â”€ schemas.md
â”œâ”€â”€ development/
â”‚   â”œâ”€â”€ contributing.md
â”‚   â””â”€â”€ testing.md
â””â”€â”€ model/
    â””â”€â”€ model-card.md

mkdocs.yml                  # ConfiguraciÃ³n
</code></pre>
<h3>mkdocs.yml</h3>
<pre><code class="language-yaml">site_name: BankChurn Predictor
site_description: API para predicciÃ³n de churn bancario
site_author: Tu Nombre
site_url: https://username.github.io/bankchurn

theme:
  name: material
  language: es
  palette:
    - scheme: default
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-7
        name: Cambiar a modo oscuro
    - scheme: slate
      primary: indigo
      accent: indigo
      toggle:
        icon: material/brightness-4
        name: Cambiar a modo claro
  features:
    - navigation.tabs
    - navigation.sections
    - navigation.expand
    - search.suggest
    - content.code.copy
    - content.tabs.link

nav:
  - Home: index.md
  - Getting Started:
    - InstalaciÃ³n: getting-started/installation.md
    - Quick Start: getting-started/quickstart.md
    - ConfiguraciÃ³n: getting-started/configuration.md
  - Arquitectura:
    - Overview: architecture/overview.md
    - Flujo de Datos: architecture/data-flow.md
    - Decisiones: architecture/decisions.md
  - API Reference:
    - Endpoints: api/endpoints.md
    - Schemas: api/schemas.md
  - Desarrollo:
    - Contribuir: development/contributing.md
    - Testing: development/testing.md
  - Model Card: model/model-card.md

markdown_extensions:
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
  - admonition
  - pymdownx.details
  - attr_list
  - md_in_html
  - tables

plugins:
  - search
  - mkdocstrings:
      handlers:
        python:
          options:
            show_source: true

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/username/bankchurn
</code></pre>
<h3>Comandos MkDocs</h3>
<pre><code class="language-bash"># Instalar
pip install mkdocs mkdocs-material mkdocstrings[python]

# Desarrollo local
mkdocs serve

# Build
mkdocs build

# Deploy a GitHub Pages
mkdocs gh-deploy
</code></pre>
<h2>16.2 Model Card Profesional</h2>
<pre><code class="language-markdown"># Model Card: BankChurn Predictor

## InformaciÃ³n del Modelo

| Campo | Valor |
|-------|-------|
| **Nombre** | BankChurn Predictor |
| **VersiÃ³n** | 1.2.3 |
| **Tipo** | ClasificaciÃ³n Binaria |
| **Framework** | Scikit-learn 1.3.0 |
| **Fecha de Entrenamiento** | 2024-01-15 |
| **Autor** | Tu Nombre |

## PropÃ³sito

### Uso Previsto
- **Caso de uso principal**: Identificar clientes con alta probabilidad de abandonar el banco
- **Usuarios objetivo**: Equipo de RetenciÃ³n de Clientes
- **Decisiones habilitadas**: CampaÃ±as de retenciÃ³n personalizadas

### Uso No Previsto
- âŒ No usar para decisiones crediticias
- âŒ No usar como Ãºnico criterio para cancelar servicios
- âŒ No usar en mercados fuera de Europa (entrenado solo con datos de FR/DE/ES)

## Datos de Entrenamiento

### Dataset
- **Fuente**: Sistema CRM interno
- **PerÃ­odo**: 2022-01-01 a 2023-12-31
- **TamaÃ±o**: 10,000 registros
- **Split**: 80% train, 20% test (estratificado)

### Features
| Feature | Tipo | DescripciÃ³n |
|---------|------|-------------|
| CreditScore | NumÃ©rica | Score crediticio (300-850) |
| Age | NumÃ©rica | Edad del cliente |
| Geography | CategÃ³rica | PaÃ­s (France, Germany, Spain) |
| ... | ... | ... |

### DistribuciÃ³n del Target
- **Churn (1)**: 20%
- **No Churn (0)**: 80%
- **Estrategia**: class_weight='balanced'

## MÃ©tricas de Performance

### MÃ©tricas Globales
| MÃ©trica | Train | Test | Threshold |
|---------|-------|------|-----------|
| AUC-ROC | 0.89 | 0.87 | &gt; 0.85 âœ… |
| Precision | 0.72 | 0.68 | &gt; 0.60 âœ… |
| Recall | 0.78 | 0.74 | &gt; 0.70 âœ… |
| F1 | 0.75 | 0.71 | &gt; 0.65 âœ… |

### MÃ©tricas por Subgrupo (Fairness)
| Subgrupo | AUC-ROC | Precision | Recall |
|----------|---------|-----------|--------|
| Gender: Male | 0.86 | 0.67 | 0.73 |
| Gender: Female | 0.88 | 0.69 | 0.75 |
| Geography: France | 0.87 | 0.68 | 0.74 |
| Geography: Germany | 0.85 | 0.66 | 0.72 |
| Geography: Spain | 0.88 | 0.70 | 0.76 |

**Nota**: La diferencia mÃ¡xima de AUC entre subgrupos es 0.03 (&lt; 0.05 threshold).

## Limitaciones

### Limitaciones Conocidas
1. **Temporal**: Modelo entrenado con datos hasta 2023. Puede degradarse con cambios econÃ³micos.
2. **GeogrÃ¡fico**: Solo vÃ¡lido para Francia, Alemania y EspaÃ±a.
3. **DemogrÃ¡fico**: Menos preciso para clientes &lt; 25 aÃ±os (pocos datos).

### CuÃ¡ndo NO Usar
- Datos con &gt; 30% de valores faltantes
- Clientes corporativos (solo entrenado con personas fÃ­sicas)
- PerÃ­odos de crisis econÃ³mica (cambio de distribuciÃ³n)

## Consideraciones Ã‰ticas

### Fairness
- Se monitorean mÃ©tricas por gÃ©nero y geografÃ­a
- Diferencias de performance &lt; 5% entre grupos
- No se usan features protegidas directamente (pero Geography correlaciona con cultura)

### Privacidad
- Datos pseudonimizados (no PII en features)
- Cumple con GDPR (Art. 22 - derecho a explicaciÃ³n)
- RetenciÃ³n de datos: 24 meses

### Transparencia
- SHAP values disponibles para explicabilidad
- DocumentaciÃ³n de limitaciones pÃºblica
- Proceso de feedback habilitado

## Mantenimiento

### Monitoreo
- Data drift monitoreado diariamente (Evidently)
- Alerta si drift &gt; 10%
- Performance evaluada mensualmente con ground truth

### Retraining
- **Frecuencia**: Trimestral o si drift detectado
- **Proceso**: Automatizado vÃ­a GitHub Actions
- **AprobaciÃ³n**: Requiere validaciÃ³n de Data Science Lead

## Historial de Versiones

| VersiÃ³n | Fecha | Cambios | AUC |
|---------|-------|---------|-----|
| 1.0.0 | 2023-06-01 | VersiÃ³n inicial | 0.82 |
| 1.1.0 | 2023-09-01 | Feature engineering | 0.85 |
| 1.2.0 | 2024-01-01 | Retraining con datos 2023 | 0.87 |
| 1.2.3 | 2024-01-15 | Fix en preprocessing | 0.87 |

## Contacto

- **Responsable**: tu.email@company.com
- **Equipo**: ML Platform Team
- **EscalaciÃ³n**: data-ethics@company.com
</code></pre>
<h2>16.3 Responsible AI Checklist</h2>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    CHECKLIST DE RESPONSIBLE AI                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   FAIRNESS:                                                                   â•‘
â•‘   [ ] MÃ©tricas calculadas por subgrupos demogrÃ¡ficos                          â•‘
â•‘   [ ] Diferencias de performance &lt; 5% entre grupos                            â•‘
â•‘   [ ] Features sensibles identificadas y documentadas                         â•‘
â•‘   [ ] Estrategia de mitigaciÃ³n si hay sesgo                                   â•‘
â•‘                                                                               â•‘
â•‘   TRANSPARENCIA:                                                              â•‘
â•‘   [ ] Model Card completo y pÃºblico                                           â•‘
â•‘   [ ] Explicabilidad disponible (SHAP/LIME)                                   â•‘
â•‘   [ ] Limitaciones claramente documentadas                                    â•‘
â•‘   [ ] Usuarios saben que interactÃºan con ML                                   â•‘
â•‘                                                                               â•‘
â•‘   PRIVACIDAD:                                                                 â•‘
â•‘   [ ] No PII en features                                                      â•‘
â•‘   [ ] Cumplimiento GDPR/CCPA documentado                                      â•‘
â•‘   [ ] PolÃ­tica de retenciÃ³n de datos                                          â•‘
â•‘   [ ] Proceso de eliminaciÃ³n de datos                                         â•‘
â•‘                                                                               â•‘
â•‘   ACCOUNTABILITY:                                                             â•‘
â•‘   [ ] Responsable del modelo identificado                                     â•‘
â•‘   [ ] Proceso de escalaciÃ³n definido                                          â•‘
â•‘   [ ] AuditorÃ­a periÃ³dica programada                                          â•‘
â•‘   [ ] Canal de feedback para usuarios                                         â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>16.4 README Profesional</h2>
<pre><code class="language-markdown"># ğŸ¦ BankChurn Predictor

[![CI](https://github.com/username/bankchurn/actions/workflows/ci.yml/badge.svg)](https://github.com/username/bankchurn/actions)
[![Coverage](https://codecov.io/gh/username/bankchurn/branch/main/graph/badge.svg)](https://codecov.io/gh/username/bankchurn)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)

&gt; API para predicciÃ³n de churn bancario con MLOps completo.

## ğŸš€ Quick Start

```bash

# Clonar
git clone https://github.com/username/bankchurn.git
cd bankchurn

# Instalar
pip install -e &quot;.[dev]&quot;

# Ejecutar tests
pytest

# Iniciar API
uvicorn app.main:app --reload
</code></pre>
<h2>ğŸ“– Documentation</h2>
<ul>
<li><a href="https://username.github.io/bankchurn">DocumentaciÃ³n Completa</a></li>
<li><a href="https://username.github.io/bankchurn/api/endpoints">API Reference</a></li>
<li><a href="https://username.github.io/bankchurn/model/model-card">Model Card</a></li>
</ul>
<h2>ğŸ—ï¸ Architecture</h2>
<pre><code class="language-mermaid">flowchart LR
    Client --&gt; API --&gt; Model --&gt; Response
</code></pre>
<h2>ğŸ“Š Metrics</h2>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>AUC-ROC</td>
<td>0.87</td>
</tr>
<tr>
<td>Latency P99</td>
<td>45ms</td>
</tr>
<tr>
<td>Coverage</td>
<td>85%</td>
</tr>
</tbody>
</table>
<h2>ğŸ“œ License</h2>
<p>MIT Â© Tu Nombre</p>
<pre><code>

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en documentaciÃ³n ML

La documentaciÃ³n suele quedarse para el final, y eso genera READMEs desactualizados y Model Cards incompletas.

### 1) README que no refleja el estado real del proyecto

**SÃ­ntomas tÃ­picos**

- Instrucciones de instalaciÃ³n que no funcionan.
- Comandos de entrenamiento/serve diferentes a los reales.

**CÃ³mo identificarlo**

- Intenta seguir tu propio `Quick Start` desde cero en una mÃ¡quina limpia.

**CÃ³mo corregirlo**

- Actualiza el README cada vez que cambies la CLI, el Makefile o los entornos.
- Copia los comandos reales desde tu `Makefile` o scripts, no los escribas de memoria.


### 2) Model Card incompleta o decorativa

**SÃ­ntomas tÃ­picos**

- Hay secciones de plantilla sin rellenar o con texto genÃ©rico.
- No hay detalles de datos, mÃ©tricas por subgrupo ni limitaciones claras.

**CÃ³mo identificarlo**

- Compara tu Model Card con el ejemplo de este mÃ³dulo: Â¿faltan tablas clave o secciones enteras?

**CÃ³mo corregirlo**

- Completa al menos: propÃ³sito, datos, mÃ©tricas principales, mÃ©tricas por subgrupos, limitaciones y plan de mantenimiento.


### 3) MkDocs que compila pero no se integra en el flujo

**SÃ­ntomas tÃ­picos**

- `mkdocs serve` funciona, pero nadie sabe la URL de docs en el README o en el repo.

**CÃ³mo identificarlo**

- Revisa si tu README enlaza a la documentaciÃ³n generada.

**CÃ³mo corregirlo**

- AÃ±ade enlaces claros en el README (secciÃ³n Documentation) y en la descripciÃ³n del repositorio.


### 4) Responsible AI checklist ignorada

**SÃ­ntomas tÃ­picos**

- El checklist de Responsible AI estÃ¡ en el repo, pero nunca se usa en revisiones.

**CÃ³mo identificarlo**

- Pregunta: Â¿se revisan fairness, privacidad y accountability en los PRs importantes?

**CÃ³mo corregirlo**

- Integra partes del checklist en tu proceso de revisiÃ³n (por ejemplo, una secciÃ³n en la PR template).


### 5) PatrÃ³n general de debugging en documentaciÃ³n

1. Usa tu propia documentaciÃ³n como si fueras un usuario nuevo (installation, quick start).
2. MantÃ©n un lugar Ãºnico de verdad para comandos y rutas (Makefile, docs tÃ©cnicas) y enlÃ¡zalo desde el README.
3. Considera la Model Card como parte del contrato del modelo, no como adorno.

Con esta mentalidad, tu documentaciÃ³n pasa de ser un &quot;nice to have&quot; a convertirse en una parte crÃ­tica de la calidad de tu sistema ML.


## 16.5 Ejercicio: Crea Tu DocumentaciÃ³n

### Checklist

</code></pre>
<p>MKDOCS:<br />
[ ] mkdocs.yml configurado<br />
[ ] Home page con overview<br />
[ ] Getting started completo<br />
[ ] API documentada</p>
<p>MODEL CARD:<br />
[ ] InformaciÃ³n del modelo<br />
[ ] Datos de entrenamiento<br />
[ ] MÃ©tricas de performance<br />
[ ] Limitaciones y Ã©tica</p>
<p>README:<br />
[ ] Badges de CI/Coverage<br />
[ ] Quick Start<br />
[ ] Links a docs<br />
[ ] Arquitectura visual<br />
```</p>
<h2>ğŸ“¹ Material Audiovisual</h2>
<p>Para crear demos profesionales (GIFs, screenshots, videos) de tu documentaciÃ³n y portafolio, consulta:</p>
<p><strong><a href="#mod_GUIA_AUDIOVISUAL">â†’ GuÃ­a Audiovisual Completa</a></strong></p>
<p>Incluye:<br />
- CÃ³mo grabar GIFs demostrativos de APIs y dashboards<br />
- Screenshots profesionales para README<br />
- Video de 5 minutos explicando el portafolio<br />
- Scripts y comandos para levantar el stack demo</p>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Model Cards</strong>: Explica por quÃ© documentar limitaciones y sesgos es crÃ­tico.</p>
</li>
<li>
<p><strong>Documentation as Code</strong>: Docs versionados junto al cÃ³digo.</p>
</li>
<li>
<p><strong>Audience-aware</strong>: Diferentes docs para diferentes audiencias.</p>
</li>
</ol>
<h3>Para Proyectos Reales</h3>
<table>
<thead>
<tr>
<th>Documento</th>
<th>Audiencia</th>
<th>Contenido</th>
</tr>
</thead>
<tbody>
<tr>
<td>README.md</td>
<td>Todos</td>
<td>Quick start, overview</td>
</tr>
<tr>
<td>Model Card</td>
<td>ML team, stakeholders</td>
<td>MÃ©tricas, limitaciones, Ã©tica</td>
</tr>
<tr>
<td>API Docs</td>
<td>Developers</td>
<td>Endpoints, schemas, ejemplos</td>
</tr>
<tr>
<td>Runbook</td>
<td>Ops</td>
<td>Troubleshooting, alertas</td>
</tr>
</tbody>
</table>
<h3>DocumentaciÃ³n que Diferencia</h3>
<ul>
<li><strong>ADRs</strong>: Decisiones arquitectÃ³nicas con contexto</li>
<li><strong>Changelogs</strong>: Generados automÃ¡ticamente desde commits</li>
<li><strong>Diagramas</strong>: Mermaid/PlantUML versionados</li>
<li><strong>Ejemplos</strong>: Notebooks con casos de uso reales</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://modelcards.withgoogle.com/about">Model Cards - Google</a></td>
<td style="text-align: left;">DocumentaciÃ³n</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=Q-YA_dA8C20">MkDocs Tutorial</a></td>
<td style="text-align: left;">Video</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>Model Card</strong>: DocumentaciÃ³n estandarizada de modelos<br />
- <strong>ADR</strong>: Architecture Decision Record<br />
- <strong>MkDocs</strong>: Generador de documentaciÃ³n</p>
<h2>ğŸ“‹ Plantillas Relacionadas</h2>
<p>Ver <a href="#mod_index">templates/</a> para plantillas listas:<br />
- <a href="#mod_model_card_template">model_card_template.md</a> â€” DocumentaciÃ³n completa de modelos<br />
- <a href="#mod_dataset_card_template">dataset_card_template.md</a> â€” DocumentaciÃ³n de datasets</p>
<h2>ğŸ¬ Material Audiovisual</h2>
<p>Documentar tu trabajo tambiÃ©n incluye crear demos visuales profesionales.</p>
<blockquote>
<p>ğŸ“º <strong>Ver <a href="#mod_GUIA_AUDIOVISUAL">GUIA_AUDIOVISUAL.md</a></strong> para:<br />
- Crear GIFs demostrativos de cada proyecto<br />
- Capturar screenshots profesionales<br />
- Producir video principal del portafolio<br />
- Scripts y comandos para demos</p>
</blockquote>
<table>
<thead>
<tr>
<th>Material</th>
<th>PropÃ³sito</th>
</tr>
</thead>
<tbody>
<tr>
<td>GIFs (3-5 por proyecto)</td>
<td>README, documentaciÃ³n rÃ¡pida</td>
</tr>
<tr>
<td>Screenshots</td>
<td>Issues, PRs, documentaciÃ³n</td>
</tr>
<tr>
<td>Video principal (5-7 min)</td>
<td>LinkedIn, presentaciones</td>
</tr>
</tbody>
</table>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 19:<br />
- <strong>19.1</strong>: Crear Model Card<br />
- <strong>19.2</strong>: Crear Dataset Card</p>
<h2>ğŸ”œ Siguiente Paso</h2>
<p>Con documentaciÃ³n lista, es hora del <strong>Proyecto Integrador</strong>.</p>
<p><strong><a href="#mod_20_PROYECTO_INTEGRADOR">Ir a MÃ³dulo 20: Proyecto Integrador â†’</a></strong></p>
            </div>
        
            <!-- MÃ“DULO: 20_PROYECTO_INTEGRADOR.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_20_PROYECTO_INTEGRADOR" class="cover-title">PROYECTO INTEGRADOR</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>20. Proyecto Integrador</h1>
<h2>ğŸ¯ Objetivo</h2>
<p>Construir un proyecto ML completo desde cero, aplicando TODO lo aprendido.</p>
<pre><code>â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘  ğŸ† EL RETO FINAL                                                            â•‘
â•‘                                                                              â•‘
â•‘  Has aprendido los conceptos. Has estudiado el cÃ³digo del portafolio.        â•‘
â•‘  Ahora es momento de DEMOSTRAR que puedes construirlo desde cero.            â•‘
â•‘                                                                              â•‘
â•‘  TIEMPO: 1-2 semanas                                                         â•‘
â•‘  RESULTADO: Un 4to proyecto digno del portafolio                             â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
</code></pre>
<h2>ğŸ“‹ El Proyecto: Sistema de RecomendaciÃ³n de Planes</h2>
<p><strong>Contexto</strong>: Una empresa de telecomunicaciones quiere recomendar planes mÃ³viles basÃ¡ndose en el comportamiento del usuario.</p>
<p><strong>Dataset sugerido</strong>: <a href="https://www.kaggle.com/datasets">Telecom Users Dataset</a> o similar.</p>
<h2>âœ… Checklist de Entrega (100 puntos)</h2>
<h3>Fase 1: Estructura y ConfiguraciÃ³n (20 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Estructura src/ layout</td>
<td style="text-align: center;">3</td>
<td><code>src/planrec/</code></td>
</tr>
<tr>
<td>pyproject.toml completo</td>
<td style="text-align: center;">3</td>
<td><code>pyproject.toml</code></td>
</tr>
<tr>
<td>Makefile con comandos bÃ¡sicos</td>
<td style="text-align: center;">2</td>
<td><code>Makefile</code></td>
</tr>
<tr>
<td>Config Pydantic con validaciÃ³n</td>
<td style="text-align: center;">4</td>
<td><code>src/planrec/config.py</code></td>
</tr>
<tr>
<td>Config YAML externo</td>
<td style="text-align: center;">2</td>
<td><code>configs/config.yaml</code></td>
</tr>
<tr>
<td>.gitignore apropiado</td>
<td style="text-align: center;">2</td>
<td><code>.gitignore</code></td>
</tr>
<tr>
<td>README profesional</td>
<td style="text-align: center;">4</td>
<td><code>README.md</code></td>
</tr>
</tbody>
</table>
<h3>Fase 2: Pipeline ML (25 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Carga y validaciÃ³n de datos</td>
<td style="text-align: center;">3</td>
<td><code>src/planrec/data.py</code></td>
</tr>
<tr>
<td>Feature Engineering como Transformer</td>
<td style="text-align: center;">5</td>
<td><code>src/planrec/features.py</code></td>
</tr>
<tr>
<td>sklearn Pipeline unificado</td>
<td style="text-align: center;">5</td>
<td><code>src/planrec/training.py</code></td>
</tr>
<tr>
<td>Cross-validation estratificada</td>
<td style="text-align: center;">3</td>
<td><code>src/planrec/training.py</code></td>
</tr>
<tr>
<td>MÃ©tricas apropiadas (F1, AUC)</td>
<td style="text-align: center;">3</td>
<td><code>src/planrec/evaluation.py</code></td>
</tr>
<tr>
<td>Guardado de artefactos</td>
<td style="text-align: center;">3</td>
<td><code>artifacts/</code></td>
</tr>
<tr>
<td>PrevenciÃ³n de data leakage</td>
<td style="text-align: center;">3</td>
<td><code>drop_columns</code> en config</td>
</tr>
</tbody>
</table>
<h3>Fase 3: Testing (20 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>conftest.py con fixtures</td>
<td style="text-align: center;">4</td>
<td><code>tests/conftest.py</code></td>
</tr>
<tr>
<td>Tests unitarios (features)</td>
<td style="text-align: center;">4</td>
<td><code>tests/test_features.py</code></td>
</tr>
<tr>
<td>Tests de datos</td>
<td style="text-align: center;">3</td>
<td><code>tests/test_data.py</code></td>
</tr>
<tr>
<td>Tests de modelo</td>
<td style="text-align: center;">3</td>
<td><code>tests/test_model.py</code></td>
</tr>
<tr>
<td>Tests de integraciÃ³n</td>
<td style="text-align: center;">3</td>
<td><code>tests/test_training.py</code></td>
</tr>
<tr>
<td>Coverage â‰¥ 80%</td>
<td style="text-align: center;">3</td>
<td><code>pytest --cov</code></td>
</tr>
</tbody>
</table>
<h3>Fase 4: API y Serving (15 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>FastAPI con Pydantic schemas</td>
<td style="text-align: center;">4</td>
<td><code>app/fastapi_app.py</code></td>
</tr>
<tr>
<td>Endpoint /health</td>
<td style="text-align: center;">2</td>
<td></td>
</tr>
<tr>
<td>Endpoint /predict</td>
<td style="text-align: center;">4</td>
<td></td>
</tr>
<tr>
<td>Dockerfile multi-stage</td>
<td style="text-align: center;">3</td>
<td><code>Dockerfile</code></td>
</tr>
<tr>
<td>Non-root user</td>
<td style="text-align: center;">2</td>
<td></td>
</tr>
</tbody>
</table>
<h3>Fase 5: CI/CD y Calidad (15 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>GitHub Actions workflow</td>
<td style="text-align: center;">5</td>
<td><code>.github/workflows/ci.yml</code></td>
</tr>
<tr>
<td>Tests automÃ¡ticos</td>
<td style="text-align: center;">3</td>
<td></td>
</tr>
<tr>
<td>Coverage enforcement</td>
<td style="text-align: center;">3</td>
<td></td>
</tr>
<tr>
<td>Linting (ruff/black)</td>
<td style="text-align: center;">2</td>
<td></td>
</tr>
<tr>
<td>Pre-commit hooks</td>
<td style="text-align: center;">2</td>
<td><code>.pre-commit-config.yaml</code></td>
</tr>
</tbody>
</table>
<h3>Fase 6: DocumentaciÃ³n (5 puntos)</h3>
<table>
<thead>
<tr>
<th>Requisito</th>
<th style="text-align: center;">Puntos</th>
<th>Archivo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model Card</td>
<td style="text-align: center;">3</td>
<td><code>docs/model_card.md</code></td>
</tr>
<tr>
<td>Data Card</td>
<td style="text-align: center;">2</td>
<td><code>docs/data_card.md</code></td>
</tr>
</tbody>
</table>
<h2>ğŸ“ Plantilla de README</h2>
<pre><code class="language-markdown"># ğŸ“± PlanRec: Mobile Plan Recommender

[![CI](https://github.com/USER/planrec/actions/workflows/ci.yml/badge.svg)](...)
[![Coverage](https://img.shields.io/badge/Coverage-85%25-brightgreen)](...)
[![Python](https://img.shields.io/badge/Python-3.11-blue)](...)

&gt; Sistema de recomendaciÃ³n de planes mÃ³viles basado en comportamiento de usuarios.

## ğŸ¯ Resumen del Proyecto

| MÃ©trica | Valor |
|---------|-------|
| **Accuracy** | 85% |
| **F1-Score** | 0.82 |
| **Coverage** | 85% |

## ğŸš€ Quick Start

\`\`\`bash
# Instalar
pip install -e &quot;.[dev]&quot;

# Entrenar
make train

# Servir API
make serve

# Tests
make test
\`\`\`

## ğŸ“ Estructura

\`\`\`
planrec/
â”œâ”€â”€ src/planrec/       # CÃ³digo fuente
â”œâ”€â”€ app/               # FastAPI
â”œâ”€â”€ tests/             # Tests
â”œâ”€â”€ configs/           # ConfiguraciÃ³n
â””â”€â”€ artifacts/         # Modelos (gitignored)
\`\`\`

## ğŸ“Š Arquitectura

[Diagrama de arquitectura]

## ğŸ› ï¸ Stack TecnolÃ³gico

- **ML**: scikit-learn, pandas, numpy
- **API**: FastAPI, uvicorn
- **Config**: Pydantic, PyYAML
- **Testing**: pytest, pytest-cov
- **CI/CD**: GitHub Actions
- **Container**: Docker

## ğŸ“– DocumentaciÃ³n

- [Model Card](#mod_model_card)
- [Data Card](#mod_data_card)
</code></pre>
<h2>ğŸ¯ RÃºbrica de EvaluaciÃ³n</h2>
<h3>Nivel Junior (50-69 puntos)</h3>
<ul>
<li>Funciona pero con estructura bÃ¡sica</li>
<li>Tests mÃ­nimos</li>
<li>Sin CI/CD</li>
</ul>
<h3>Nivel Mid (70-84 puntos)</h3>
<ul>
<li>Estructura correcta</li>
<li>Tests con coverage &gt; 70%</li>
<li>CI bÃ¡sico</li>
</ul>
<h3>Nivel Senior (85-94 puntos)</h3>
<ul>
<li>Custom Transformer funcionando</li>
<li>Coverage &gt; 80%</li>
<li>CI/CD completo</li>
<li>DocumentaciÃ³n profesional</li>
</ul>
<h3>Nivel Staff (95-100 puntos)</h3>
<ul>
<li>Todo lo anterior</li>
<li>Drift detection</li>
<li>MLflow integration</li>
<li>Model Card completo</li>
<li>Code review pasable en FAANG</li>
</ul>
<h2>ğŸ§¨ Errores habituales y cÃ³mo depurarlos en el Proyecto Integrador</h2>
<p>En el proyecto integrador el mayor reto no es una tecnologÃ­a concreta, sino <strong>coordinar todas las piezas</strong> sin romper nada en el camino.</p>
<h3>1) Empezar por el modelo y olvidar la estructura</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Tienes notebooks y scripts sueltos, pero no un paquete <code>src/planrec</code> ni <code>pyproject.toml</code> claros.</li>
<li>Es difÃ­cil correr el proyecto en otra mÃ¡quina o en CI.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>PregÃºntate: Â¿puedo ejecutar <code>pip install -e .</code> y luego <code>python -m planrec.cli</code> o similar?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Copia la estructura de BankChurn/CarVision: <code>src/</code>, <code>configs/</code>, <code>app/</code>, <code>tests/</code>, <code>artifacts/</code>.</li>
<li>Define desde el inicio <code>pyproject.toml</code>, <code>Makefile</code> y <code>.gitignore</code>.</li>
</ul>
<h3>2) Config dispersa o duplicada</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Rutas de datos, thresholds o hiperparÃ¡metros hardcodeados en varios archivos.</li>
<li>Cambias algo en un sitio y se rompe otra parte.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Busca valores repetidos (por ejemplo, paths o columnas) en mÃºltiples mÃ³dulos.</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Centraliza configuraciÃ³n en <code>configs/config.yaml</code> y una clase Pydantic (<code>Config</code>) que valide todo.</li>
<li>Haz que training, API y scripts lean SIEMPRE desde esa fuente de verdad.</li>
</ul>
<h3>3) Tests que no cubren el flujo completo</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Coverage aceptable, pero sin tests de integraciÃ³n ni de API.</li>
<li>El pipeline entero falla cuando intentas ejecutar <code>make train</code> o el endpoint <code>/predict</code>.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Revisa si tienes al menos:</li>
<li>Tests de features (<code>test_features.py</code>).</li>
<li>Tests de datos (<code>test_data.py</code>).</li>
<li>Tests de entrenamiento/integraciÃ³n (<code>test_training.py</code>).</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>AÃ±ade al menos un test que recorra el flujo E2E con datos pequeÃ±os, similar a los de CarVision.</li>
<li>Usa fixtures y <code>tmp_path</code> para no depender de rutas reales.</li>
</ul>
<h3>4) CI/CD que solo corre en local</h3>
<p><strong>SÃ­ntomas tÃ­picos</strong></p>
<ul>
<li>Tienes un archivo <code>.github/workflows/ci.yml</code> pero los jobs fallan siempre en GitHub.</li>
</ul>
<p><strong>CÃ³mo identificarlo</strong></p>
<ul>
<li>Compara el workflow con el del portafolio: Â¿coinciden <code>working-directory</code>, versiones de Python y comandos?</li>
</ul>
<p><strong>CÃ³mo corregirlo</strong></p>
<ul>
<li>Simplifica primero: un job que haga <code>pip install -e .</code> y <code>pytest</code>.</li>
<li>AÃ±ade coverage y linting cuando el flujo bÃ¡sico sea estable.</li>
</ul>
<h3>5) PatrÃ³n general de debugging del proyecto integrador</h3>
<ol>
<li>Valida la <strong>base</strong>: estructura, instalaciÃ³n (<code>pip install -e .</code>), <code>make test</code>.</li>
<li>AsegÃºrate de que el <strong>pipeline de training</strong> funciona de principio a fin con datos pequeÃ±os.</li>
<li>Solo entonces aÃ±ade API, Docker y CI/CD, verificando cada capa con su propio conjunto de tests.</li>
</ol>
<p>Con este enfoque, reduces la frustraciÃ³n y aumentas la probabilidad de tener un <strong>4Âº proyecto sÃ³lido de portafolio</strong>.</p>
<h2>ğŸ’¡ Tips para Ã‰xito</h2>
<ol>
<li><strong>Empieza por la estructura</strong> - No escribas cÃ³digo sin tener pyproject.toml y Makefile</li>
<li><strong>Tests primero</strong> - TDD te ahorra tiempo a largo plazo</li>
<li><strong>Commits pequeÃ±os</strong> - Un commit por feature, mensajes claros</li>
<li><strong>README actualizado</strong> - ActualÃ­zalo mientras avanzas, no al final</li>
<li><strong>Copia patrones</strong> - Usa el cÃ³digo de BankChurn/CarVision como referencia</li>
</ol>
<h2>ğŸ’¼ Consejos Profesionales</h2>
<blockquote>
<p><strong>Recomendaciones para destacar en entrevistas y proyectos reales</strong></p>
</blockquote>
<h3>Para Entrevistas</h3>
<ol>
<li>
<p><strong>Cuenta una historia</strong>: Tu portafolio debe mostrar progresiÃ³n y aprendizaje.</p>
</li>
<li>
<p><strong>Explica decisiones</strong>: "Â¿Por quÃ© elegiste X?" es la pregunta mÃ¡s comÃºn.</p>
</li>
<li>
<p><strong>Muestra mÃ©tricas</strong>: Impacto cuantificable impresiona mÃ¡s que features.</p>
</li>
</ol>
<h3>Para tu Portafolio</h3>
<table>
<thead>
<tr>
<th>Elemento</th>
<th>Por quÃ© Importa</th>
</tr>
</thead>
<tbody>
<tr>
<td>README profesional</td>
<td>Primera impresiÃ³n, 30 segundos para captar atenciÃ³n</td>
</tr>
<tr>
<td>Demo en vivo</td>
<td>Muestra que funciona, no solo que existe</td>
</tr>
<tr>
<td>CÃ³digo limpio</td>
<td>Los revisores leen tu cÃ³digo</td>
</tr>
<tr>
<td>DocumentaciÃ³n</td>
<td>Demuestra comunicaciÃ³n tÃ©cnica</td>
</tr>
</tbody>
</table>
<h3>Checklist Final del Portafolio</h3>
<ul>
<li>[ ] Cada proyecto tiene problema claro y soluciÃ³n</li>
<li>[ ] MÃ©tricas de performance documentadas</li>
<li>[ ] CI/CD funcionando con badges</li>
<li>[ ] Docker para reproducibilidad</li>
<li>[ ] README con GIFs o screenshots</li>
<li>[ ] Deployed y accesible (demo link)</li>
</ul>
<h2>ğŸ“º Recursos Externos Recomendados</h2>
<blockquote>
<p>Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para la lista completa.</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=S_F_c9e2bz4">End-to-End ML Project - Krish Naik</a></td>
<td style="text-align: left;">Video</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://github.com/DataTalksClub/mlops-zoomcamp">MLOps Zoomcamp - DataTalks</a></td>
<td style="text-align: left;">Curso</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias del Glosario</h2>
<p>Ver <a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> para definiciones de:<br />
- <strong>E2E Pipeline</strong>: Flujo completo de datos a predicciÃ³n<br />
- <strong>Integration Test</strong>: Tests que verifican componentes juntos<br />
- <strong>CI/CD</strong>: IntegraciÃ³n y despliegue continuo</p>
<h2>âœ… Ejercicios</h2>
<p>Ver <a href="#mod_EJERCICIOS">EJERCICIOS.md</a> - MÃ³dulo 20:<br />
- <strong>20.1</strong>: Script E2E completo<br />
- <strong>20.2</strong>: Health Check Script</p>
<h2>ğŸ Entrega</h2>
<ol>
<li>Repositorio pÃºblico en GitHub</li>
<li>CI pasando (verde)</li>
<li>README con badges actualizados</li>
<li>Self-assessment del checklist completado</li>
</ol>
<h2>ğŸ¤ Checkpoint: Simulacro Senior/Lead</h2>
<blockquote>
<p>ğŸ¯ <strong>Â¡Has completado la guÃ­a completa!</strong> (MÃ³dulos 01-20)</p>
<p>Si buscas posiciones <strong>Senior/Lead ML Engineer</strong>, es momento del simulacro completo:</p>
<p><strong><a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE1">â†’ SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md</a></strong> â€” 70 preguntas tÃ©cnicas avanzadas<br />
<strong><a href="#mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE2">â†’ SIMULACRO_ENTREVISTA_SENIOR_PARTE2.md</a></strong> â€” System design, liderazgo, trade-offs</p>
<p>Material complementario:<br />
- <a href="#mod_APENDICE_A_SPEECH_PORTAFOLIO">APENDICE_A_SPEECH_PORTAFOLIO.md</a> â€” GuiÃ³n de presentaciÃ³n 5-7 min<br />
- <a href="#mod_APENDICE_B_TALKING_POINTS">APENDICE_B_TALKING_POINTS.md</a> â€” Puntos clave concisos</p>
</blockquote>
<p><strong>Â¡Ã‰xito en tu proyecto! ğŸš€</strong></p>
            </div>
        
            <!-- MÃ“DULO: SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE1" class="cover-title">SIMULACRO SENIOR (PARTE 1)</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ¯ Simulacro de Entrevista Lead/Senior ML Engineer</h1>
<h2>Portafolio MLOps â€” 100+ Preguntas TÃ©cnicas y Conceptuales</h2>
<p><strong>Autor del Portafolio</strong>: Daniel Duque (DuqueOM)<br />
<strong>VersiÃ³n</strong>: 1.0<br />
<strong>Fecha</strong>: Noviembre 2025  </p>
<h2>ğŸ“‹ Ãndice</h2>
<ol>
<li><a href="#1-fundamentos-de-machine-learning-preguntas-1-15">Fundamentos de ML</a></li>
<li><a href="#2-mlops-y-ciclo-de-vida-preguntas-16-30">MLOps y Ciclo de Vida</a></li>
<li><a href="#3-bankchurn-predictor-preguntas-31-45">BankChurn-Predictor</a></li>
<li><a href="#4-carvision-market-intelligence-preguntas-46-60">CarVision-Market-Intelligence</a></li>
<li><a href="#5-telecomai-preguntas-61-70">TelecomAI-Customer-Intelligence</a></li>
<li><a href="#6-arquitectura-y-diseÃ±o-preguntas-71-80">Arquitectura y DiseÃ±o</a></li>
<li><a href="#7-cicd-y-devops-preguntas-81-90">CI/CD y DevOps</a></li>
<li><a href="#8-infraestructura-preguntas-91-100">Infraestructura K8s/Docker</a></li>
<li><a href="#9-Ã©tica-y-fairness-preguntas-101-105">Ã‰tica y Fairness</a></li>
<li><a href="#10-liderazgo-preguntas-106-115">Liderazgo y Escenarios</a></li>
</ol>
<h1>1. Fundamentos de Machine Learning (Preguntas 1-15)</h1>
<h2>Pregunta 1: Data Leakage</h2>
<p><strong>Â¿QuÃ© es el data leakage y cÃ³mo lo preveniste?</strong></p>
<h3>Respuesta:</h3>
<p>El data leakage ocurre cuando informaciÃ³n del test set o target filtra al training.</p>
<p><strong>PrevenciÃ³n en BankChurn</strong> (<code>training.py:278-293</code>):</p>
<pre><code class="language-python"># CRITICAL: Split BEFORE fitting preprocessor
X_train, X_test, y_train, y_test = train_test_split(X, y, ...)
self.preprocessor_ = self.build_preprocessor(X_train)  # Solo training
X_train = self.preprocessor_.fit_transform(X_train)
X_test = self.preprocessor_.transform(X_test)  # Solo transform
</code></pre>
<p><strong>En CarVision</strong> (<code>config.yaml</code>):</p>
<pre><code class="language-yaml">drop_columns: [&quot;price_per_mile&quot;, &quot;price_category&quot;]  # Dependen del target
</code></pre>
<p><strong>JustificaciÃ³n</strong>: El preprocesador (StandardScaler, OneHotEncoder) debe ajustarse <strong>exclusivamente</strong> con datos de training.</p>
<h2>Pregunta 2: Class Imbalance</h2>
<p><strong>Â¿CÃ³mo manejaste el desbalance 80/20 en churn?</strong></p>
<h3>Respuesta:</h3>
<p>ImplementÃ© mÃºltiples estrategias en <code>ResampleClassifier</code> (<code>models.py</code>):</p>
<pre><code class="language-python">class ResampleClassifier(BaseEstimator, ClassifierMixin):
    # strategy: {&quot;none&quot;, &quot;oversample&quot;, &quot;undersample&quot;, &quot;class_weight&quot;}
    def _apply_resampling(self, X, y):
        if self.strategy == &quot;oversample&quot;:
            return SMOTE(random_state=self.random_state).fit_resample(X, y)
        elif self.strategy == &quot;undersample&quot;:
            return RandomUnderSampler().fit_resample(X, y)
</code></pre>
<p><strong>Estrategias adicionales</strong>:<br />
- <code>LogisticRegression(class_weight="balanced")</code><br />
- <code>RandomForestClassifier(class_weight="balanced_subsample")</code><br />
- <strong>F1-Score</strong> como mÃ©trica primaria (equilibra precision-recall)</p>
<h2>Pregunta 3: Ensemble VotingClassifier</h2>
<p><strong>Explica el VotingClassifier con pesos [0.4, 0.6].</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">ensemble = VotingClassifier(
    estimators=[(&quot;lr&quot;, lr), (&quot;rf&quot;, rf)],
    voting=&quot;soft&quot;,      # Promedia probabilidades
    weights=[0.4, 0.6]  # RF tiene mayor peso
)
</code></pre>
<p><strong>Razones</strong>:<br />
1. <strong>Soft voting</strong>: Aprovecha confianza del modelo (probabilidades)<br />
2. <strong>RF (0.6)</strong>: Mejor AUC individual, captura no-linealidades<br />
3. <strong>LR (0.4)</strong>: RegularizaciÃ³n, interpretabilidad, buen baseline</p>
<p><strong>Complementariedad</strong>: LR asume linealidad, RF captura interacciones â†’ combinaciÃ³n reduce varianza.</p>
<h2>Pregunta 4: FeatureEngineer Centralizado</h2>
<p><strong>Â¿CÃ³mo garantizas consistencia entre training e inference?</strong></p>
<h3>Respuesta:</h3>
<p>Clase <code>FeatureEngineer</code> como sklearn transformer (<code>features.py</code>):</p>
<pre><code class="language-python">class FeatureEngineer(BaseEstimator, TransformerMixin):
    def transform(self, X):
        X = X.copy()
        if &quot;model_year&quot; in X.columns:
            X[&quot;vehicle_age&quot;] = self.current_year - X[&quot;model_year&quot;]
        if &quot;model&quot; in X.columns:
            X[&quot;brand&quot;] = X[&quot;model&quot;].str.split().str[0]
        return X
</code></pre>
<p><strong>Pipeline integrado</strong>:</p>
<pre><code class="language-python">pipe = Pipeline([(&quot;features&quot;, fe), (&quot;pre&quot;, pre), (&quot;model&quot;, model)])
joblib.dump(pipe, &quot;model.joblib&quot;)  # TODO serializado
</code></pre>
<p><strong>Beneficio</strong>: Single Source of Truth para training, API, dashboard.</p>
<h2>Pregunta 5: StratifiedKFold</h2>
<p><strong>Â¿Por quÃ© usaste StratifiedKFold?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
</code></pre>
<p><strong>Razones</strong>:<br />
1. <strong>Preserva proporciÃ³n</strong>: Con 80/20, KFold simple podrÃ­a generar folds 90/10<br />
2. <strong>Representatividad</strong>: Cada fold simula distribuciÃ³n de producciÃ³n<br />
3. <strong>Estabilidad</strong>: Reduce varianza entre folds</p>
<h2>Pregunta 6: MÃ©tricas de RegresiÃ³n</h2>
<p><strong>Â¿CuÃ¡ndo priorizas RMSE vs MAE vs MAPE?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>MÃ©trica</th>
<th>Priorizar cuando</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>RMSE</strong></td>
<td>Errores grandes son costosos (penaliza outliers)</td>
</tr>
<tr>
<td><strong>MAE</strong></td>
<td>Robustez a outliers, interpretaciÃ³n directa</td>
</tr>
<tr>
<td><strong>MAPE</strong></td>
<td>ComparaciÃ³n entre escalas diferentes</td>
</tr>
<tr>
<td><strong>RÂ²</strong></td>
<td>Benchmarking vs baseline</td>
</tr>
</tbody>
</table>
<p><strong>En CarVision priorizo RMSE</strong>: Un error de $10K en auto de $5K es crÃ­tico.</p>
<h2>Pregunta 7: Imputation Strategies</h2>
<p><strong>Â¿Por quÃ© median para numÃ©ricos y "constant" para categÃ³ricos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># NumÃ©ricos: robusta a outliers
(&quot;imputer&quot;, SimpleImputer(strategy=&quot;median&quot;))
# CategÃ³ricos: categorÃ­a explÃ­cita permite aprender patrÃ³n de missing
(&quot;imputer&quot;, SimpleImputer(strategy=&quot;constant&quot;, fill_value=&quot;missing&quot;))
</code></pre>
<p><strong>JustificaciÃ³n</strong>: <code>most_frequent</code> sesga hacia categorÃ­a dominante; "missing" es mÃ¡s informativo.</p>
<h2>Pregunta 8: RegularizaciÃ³n L2</h2>
<p><strong>Â¿QuÃ© significa C=0.1 en LogisticRegression?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">LogisticRegression(C=0.1, solver=&quot;liblinear&quot;)
</code></pre>
<p><strong>C = 1/Î»</strong> (inverso de regularizaciÃ³n L2):<br />
- C bajo (0.1) = regularizaciÃ³n fuerte â†’ modelo simple, menos overfitting<br />
- C alto (10) = regularizaciÃ³n dÃ©bil â†’ mÃ¡s flexibilidad</p>
<p><strong>SelecciÃ³n</strong>: Incluido en espacio de bÃºsqueda Optuna <code>[0.01, 10.0]</code> log scale.</p>
<h2>Pregunta 9: Random Forest Hyperparameters</h2>
<p><strong>Â¿Por quÃ© max_depth=10 y min_samples_leaf=5?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>ParÃ¡metro</th>
<th>Valor</th>
<th>Efecto</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>max_depth=10</code></td>
<td>LÃ­mite profundidad</td>
<td>Previene memorizaciÃ³n</td>
</tr>
<tr>
<td><code>min_samples_leaf=5</code></td>
<td>MÃ­nimo en hojas</td>
<td>Evita hojas con 1-2 samples</td>
</tr>
<tr>
<td><code>n_estimators=100</code></td>
<td>Ãrboles</td>
<td>Balance varianza/costo</td>
</tr>
</tbody>
</table>
<p><strong>ValidaciÃ³n</strong>: ~0.85 AUC con gap train-test &lt; 3%.</p>
<h2>Pregunta 10: GradientBoosting vs RandomForest</h2>
<p><strong>Â¿Por quÃ© GB en TelecomAI y RF en BankChurn?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Aspecto</th>
<th>Random Forest</th>
<th>Gradient Boosting</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Enfoque</strong></td>
<td>Bagging (paralelo)</td>
<td>Boosting (secuencial)</td>
</tr>
<tr>
<td><strong>Dataset</strong></td>
<td>Grande (10K+)</td>
<td>PequeÃ±o (~2K)</td>
</tr>
<tr>
<td><strong>Features</strong></td>
<td>Mix cat/num</td>
<td>NumÃ©ricas simples</td>
</tr>
</tbody>
</table>
<p><strong>TelecomAI</strong> usa GB con <code>max_depth=2, lr=0.05</code>: muchos Ã¡rboles simples â†’ regularizaciÃ³n fuerte.</p>
<h2>Pregunta 11: Cross-Validation con Logging</h2>
<p><strong>Â¿CÃ³mo reportas resultados de CV?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train), 1):
    fold_f1 = f1_score(y_fold_val, y_pred, average=&quot;weighted&quot;)
    cv_scores.append(fold_f1)
    logger.info(f&quot;Fold {fold}/{n_folds}: F1 = {fold_f1:.4f}&quot;)

logger.info(f&quot;CV Mean F1: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})&quot;)
</code></pre>
<p><strong>MÃ©tricas reportadas</strong>: Media Â± desviaciÃ³n estÃ¡ndar para evaluar estabilidad.</p>
<h2>Pregunta 12: Threshold Selection</h2>
<p><strong>Â¿CÃ³mo elegiste el threshold de clasificaciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># prediction.py
def predict(self, X, threshold=0.5):
    results[&quot;prediction&quot;] = (results[&quot;probability&quot;] &gt;= threshold).astype(int)
    results[&quot;risk_level&quot;] = pd.cut(results[&quot;probability&quot;],
        bins=[0, 0.3, 0.7, 1.0], labels=[&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;])
</code></pre>
<p><strong>Default 0.5</strong>, pero configurable vÃ­a API. En producciÃ³n:<br />
- Si costo de FN alto â†’ bajar threshold (mÃ¡s recall)<br />
- Si costo de FP alto â†’ subir threshold (mÃ¡s precision)</p>
<h2>Pregunta 13: Feature Importance</h2>
<p><strong>Â¿CÃ³mo calculas y usas feature importance?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># evaluation.py - error_analysis
feature_importance: true  # En config

# RandomForest tiene .feature_importances_
# Para ensemble, extraemos de sub-modelos
</code></pre>
<p><strong>Uso</strong>: Identificar features dominantes, detectar posibles data leakage, explicabilidad al negocio.</p>
<h2>Pregunta 14: Calibration</h2>
<p><strong>Â¿QuÃ© es la calibraciÃ³n de probabilidades?</strong></p>
<h3>Respuesta:</h3>
<p>Del Model Card:</p>
<pre><code class="language-markdown">## Calibration
- Platt (sigmoid) sobre el modelo final (cv=&quot;prefit&quot;)
</code></pre>
<p><strong>Problema</strong>: <code>predict_proba()</code> puede dar probabilidades que no reflejan frecuencia real.<br />
<strong>SoluciÃ³n</strong>: <code>CalibratedClassifierCV</code> ajusta probabilidades para que 0.7 signifique ~70% de positivos reales.</p>
<h2>Pregunta 15: Baseline Comparison</h2>
<p><strong>Â¿CÃ³mo comparas tu modelo contra un baseline?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># evaluation.py (CarVision)
dummy = DummyRegressor(strategy=&quot;median&quot;)
dummy.fit(X_train, y_train)
baseline_metrics = {&quot;rmse&quot;: rmse(y_test, dummy.predict(X_test))}
</code></pre>
<p><strong>Bootstrap para significancia estadÃ­stica</strong>:</p>
<pre><code class="language-python">delta_rmse_mean = modelo - baseline
p_value_two_sided  # Si &lt; 0.05, diferencia significativa
</code></pre>
<h1>2. MLOps y Ciclo de Vida (Preguntas 16-30)</h1>
<h2>Pregunta 16: MLflow Integration</h2>
<p><strong>Â¿CÃ³mo integraste MLflow?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># training.py
if self.config.mlflow.enabled:
    mlflow.set_tracking_uri(self.config.mlflow.tracking_uri)
    mlflow.set_experiment(self.config.mlflow.experiment_name)

with mlflow.start_run():
    mlflow.log_params(self.config.model.dict())
    mlflow.log_metrics(metrics)
</code></pre>
<p><strong>Config</strong> (<code>config.yaml</code>):</p>
<pre><code class="language-yaml">mlflow:
  tracking_uri: &quot;file:./mlruns&quot;  # Local
  experiment_name: &quot;bankchurn-experiment&quot;
</code></pre>
<h2>Pregunta 17: Reproducibilidad con Seeds</h2>
<p><strong>Â¿CÃ³mo garantizas reproducibilidad?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># common_utils/seed.py
def set_seed(seed=None):
    seed = seed or os.getenv(&quot;SEED&quot;) or 42
    os.environ[&quot;PYTHONHASHSEED&quot;] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    # PyTorch/TensorFlow si instalados
    return seed
</code></pre>
<p><strong>Uso en todos los proyectos</strong>:</p>
<pre><code class="language-python">seed_used = set_seed(args.seed)
logger.info(f&quot;Using seed: {seed_used}&quot;)
</code></pre>
<h2>Pregunta 18: Configuration con Pydantic</h2>
<p><strong>Explica tu sistema de configuraciÃ³n.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># config.py
class ModelConfig(BaseModel):
    test_size: float = Field(0.2, ge=0.0, le=1.0)
    cv_folds: int = Field(5, ge=2)

class BankChurnConfig(BaseModel):
    model: ModelConfig
    data: DataConfig
    mlflow: MLflowConfig

    @classmethod
    def from_yaml(cls, path):
        with open(path) as f:
            return cls(**yaml.safe_load(f))
</code></pre>
<p><strong>Beneficios</strong>: ValidaciÃ³n automÃ¡tica, valores por defecto, type hints, serializaciÃ³n.</p>
<h2>Pregunta 19: Model Versioning</h2>
<p><strong>Â¿CÃ³mo versionas modelos?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Naming</strong>: <code>models/model_v1.0.0.pkl</code></li>
<li><strong>Metadata JSON</strong>: commit_sha, mÃ©tricas, timestamp</li>
<li><strong>K8s ConfigMap</strong>: <code>MODEL_VERSION: "v2.0.0"</code></li>
<li><strong>Docker tags</strong>: <code>bankchurn:v1.0.0</code></li>
<li><strong>MLflow Registry</strong>: Staging â†’ Production</li>
</ol>
<h2>Pregunta 20: DVC Data Versioning</h2>
<p><strong>Â¿Por quÃ© DVC?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-bash">dvc add data/raw/Churn.csv
git add data/raw/Churn.csv.dvc .gitignore
dvc push  # A storage remoto
</code></pre>
<p><strong>Beneficios</strong>: Cada commit Git tiene snapshot exacto de datos, sin almacenarlos en Git.</p>
<h2>Pregunta 21: Pipeline como Artefacto Ãšnico</h2>
<p><strong>Â¿Por quÃ© empaquetar preprocessor + model?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">pipeline = Pipeline([(&quot;preprocess&quot;, pre), (&quot;clf&quot;, clf)])
joblib.dump(pipeline, &quot;model.joblib&quot;)
</code></pre>
<p><strong>Deployment simplificado</strong>:</p>
<pre><code class="language-python">pipe = joblib.load(&quot;model.joblib&quot;)
pred = pipe.predict(raw_df)  # Sin pasos intermedios
</code></pre>
<h2>Pregunta 22: Health Checks</h2>
<p><strong>Â¿CÃ³mo implementaste health checks?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@app.get(&quot;/health&quot;)
async def health_check():
    return {&quot;status&quot;: &quot;healthy&quot; if predictor else &quot;degraded&quot;,
            &quot;model_loaded&quot;: predictor is not None}
</code></pre>
<p><strong>K8s probes</strong>:</p>
<pre><code class="language-yaml">livenessProbe:
  httpGet: {path: /health, port: 8000}
  initialDelaySeconds: 30
readinessProbe:
  httpGet: {path: /health, port: 8000}
  initialDelaySeconds: 10
</code></pre>
<h2>Pregunta 23: Model Loading Strategy</h2>
<p><strong>Â¿CÃ³mo cargas el modelo en FastAPI?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@contextlib.asynccontextmanager
async def lifespan(app: FastAPI):
    global predictor
    predictor = load_model_logic()  # Una vez al iniciar
    yield

app = FastAPI(lifespan=lifespan)
</code></pre>
<p><strong>Beneficio</strong>: Carga Ãºnica, no por request. Fail-fast friendly.</p>
<h2>Pregunta 24: Batch Prediction</h2>
<p><strong>Â¿CÃ³mo manejas predicciones batch?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@app.post(&quot;/predict_batch&quot;)
async def predict_batch(batch_data: BatchCustomerData):
    if len(batch_data.customers) &gt; 1000:
        raise HTTPException(400, &quot;Max 1000 per batch&quot;)

    df = pd.DataFrame([c.dict() for c in batch_data.customers])
    results = predictor.predict(df)
    return {&quot;predictions&quot;: results, &quot;processing_time&quot;: time}
</code></pre>
<h2>Pregunta 25: Metrics Collection</h2>
<p><strong>Â¿QuÃ© mÃ©tricas operacionales colectas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@app.get(&quot;/metrics&quot;)
async def get_metrics():
    return {
        &quot;total_predictions&quot;: request_count,
        &quot;average_prediction_time_ms&quot;: avg_time,
        &quot;model_accuracy&quot;: model_metadata.get(&quot;test_accuracy&quot;)
    }
</code></pre>
<p><strong>Prometheus-ready</strong>: Annotations en K8s para scraping automÃ¡tico.</p>
<h2>Pregunta 26: Error Handling en API</h2>
<p><strong>Â¿CÃ³mo manejas errores?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@app.post(&quot;/predict&quot;)
async def predict(customer: CustomerData):
    if predictor is None:
        raise HTTPException(503, &quot;Model not available&quot;)
    try:
        return predictor.predict(df)
    except Exception as e:
        logger.error(f&quot;Prediction error: {e}&quot;)
        raise HTTPException(500, str(e))
</code></pre>
<p><strong>CÃ³digos apropiados</strong>: 503 servicio no disponible, 500 error interno.</p>
<h2>Pregunta 27: Logging Strategy</h2>
<p><strong>Â¿CÃ³mo estructuraste el logging?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">logging.basicConfig(
    level=logging.INFO,
    format=&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;,
    handlers=[FileHandler(&quot;app.log&quot;), StreamHandler()]
)
logger = logging.getLogger(__name__)
</code></pre>
<p><strong>Niveles usados</strong>: INFO para operaciones normales, WARNING para fallbacks, ERROR para fallos.</p>
<h2>Pregunta 28: API Validation con Pydantic</h2>
<p><strong>Â¿CÃ³mo validas inputs en la API?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class CustomerData(BaseModel):
    CreditScore: int = Field(..., ge=300, le=850)
    Age: int = Field(..., ge=18, le=100)
    Geography: str

    @validator(&quot;Geography&quot;)
    def validate_geo(cls, v):
        if v not in [&quot;France&quot;, &quot;Spain&quot;, &quot;Germany&quot;]:
            raise ValueError(&quot;Invalid geography&quot;)
        return v
</code></pre>
<h2>Pregunta 29: Response Enrichment</h2>
<p><strong>Â¿QuÃ© incluyes en la respuesta de predicciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class PredictionResponse(BaseModel):
    churn_probability: float
    churn_prediction: int
    risk_level: str         # LOW/MEDIUM/HIGH
    confidence: float       # abs(prob - 0.5) * 2
    model_version: str
    prediction_timestamp: str
</code></pre>
<p><strong>Risk level</strong>: CategorizaciÃ³n para decisiones de negocio.</p>
<h2>Pregunta 30: Graceful Degradation</h2>
<p><strong>Â¿QuÃ© pasa si el modelo no carga?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">async def lifespan(app):
    success = load_model_logic()
    if not success:
        logger.warning(&quot;Started without model&quot;)
    yield  # App sigue corriendo

# Health check reporta estado degradado
{&quot;status&quot;: &quot;degraded&quot;, &quot;model_loaded&quot;: false}
</code></pre>
<p><strong>Beneficio</strong>: Health checks funcionan, ops pueden diagnosticar.</p>
<h1>3. BankChurn-Predictor (Preguntas 31-45)</h1>
<h2>Pregunta 31: Arquitectura Modular</h2>
<p><strong>Describe la estructura del proyecto.</strong></p>
<h3>Respuesta:</h3>
<pre><code>src/bankchurn/
â”œâ”€â”€ cli.py        # Entry point CLI
â”œâ”€â”€ config.py     # Pydantic validation
â”œâ”€â”€ models.py     # ResampleClassifier
â”œâ”€â”€ training.py   # ChurnTrainer class
â”œâ”€â”€ evaluation.py # ModelEvaluator class
â””â”€â”€ prediction.py # ChurnPredictor class
</code></pre>
<p><strong>Principio</strong>: Single Responsibility - cada mÃ³dulo una funciÃ³n.</p>
<h2>Pregunta 32: CLI Design</h2>
<p><strong>Â¿CÃ³mo diseÃ±aste la CLI?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># cli.py
parser.add_subparsers(dest=&quot;command&quot;)
train_parser = subparsers.add_parser(&quot;train&quot;)
train_parser.add_argument(&quot;--config&quot;, required=True)

def cli_main(argv=None):
    args = parser.parse_args(argv)
    if args.command == &quot;train&quot;:
        return train_command(args)
</code></pre>
<p><strong>Uso</strong>: <code>python -m bankchurn train --config configs/config.yaml</code></p>
<h2>Pregunta 33: ResampleClassifier</h2>
<p><strong>Explica tu clasificador custom.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">class ResampleClassifier(BaseEstimator, ClassifierMixin):
    def __init__(self, estimator=None, strategy=&quot;none&quot;):
        self.estimator = estimator
        self.strategy = strategy

    def fit(self, X, y):
        X_res, y_res = self._apply_resampling(X, y)
        self.estimator_.fit(X_res, y_res)
        return self
</code></pre>
<p><strong>Implementa interfaz sklearn</strong>: <code>fit</code>, <code>predict</code>, <code>predict_proba</code> â†’ compatible con Pipeline.</p>
<h2>Pregunta 34: Fairness Evaluation</h2>
<p><strong>Â¿CÃ³mo evalÃºas sesgo por grupos?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def compute_fairness_metrics(self, X, y, sensitive_features):
    for feature in sensitive_features:  # [&quot;Geography&quot;, &quot;Gender&quot;]
        for group in X[feature].unique():
            mask = X[feature] == group
            group_f1 = f1_score(y[mask], y_pred[mask])

    # Disparate Impact
    disparate_impact = min(positive_rates) / max(positive_rates)
</code></pre>
<p><strong>Threshold</strong>: Disparate Impact &lt; 0.8 indica discriminaciÃ³n potencial.</p>
<h2>Pregunta 35: Model Card</h2>
<p><strong>Â¿QuÃ© incluyes en tu Model Card?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-markdown"># Model Card - BankChurn
- Model: VotingClassifier (LR + RF)
- Target: Exited (1=churn)
## Intended Use: Priorizar retenciÃ³n, no decisiÃ³n automÃ¡tica
## Limitations: Desbalance 80/20, posible drift temporal
## Fairness: Tests por geografÃ­a/gÃ©nero, gap recall &lt; 0.3
## SLO: Disponibilidad 99.5%, Latencia P95 &lt; 50ms
</code></pre>
<h2>Pregunta 36: Testing Strategy</h2>
<p><strong>Â¿CÃ³mo organizaste los tests?</strong></p>
<h3>Respuesta:</h3>
<pre><code>tests/
â”œâ”€â”€ conftest.py       # Fixtures compartidos
â”œâ”€â”€ test_training.py  # ChurnTrainer
â”œâ”€â”€ test_evaluation.py# ModelEvaluator
â”œâ”€â”€ test_prediction.py# ChurnPredictor
â”œâ”€â”€ test_config.py    # Pydantic validation
â””â”€â”€ test_integration.py# E2E workflow
</code></pre>
<p><strong>Coverage</strong>: 77% con pytest-cov.</p>
<h2>Pregunta 37: Fixture Pattern</h2>
<p><strong>Â¿CÃ³mo usas fixtures en pytest?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@pytest.fixture
def config():
    return BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)

@pytest.fixture
def sample_data():
    return pd.DataFrame({
        &quot;CreditScore&quot;: np.random.randint(300, 850, 200),
        &quot;Exited&quot;: np.random.choice([0, 1], 200, p=[0.8, 0.2])
    })

def test_training(config, sample_data, tmp_path):
    trainer = ChurnTrainer(config)
    # ...
</code></pre>
<h2>Pregunta 38: Integration Test</h2>
<p><strong>Â¿QuÃ© cubre tu test de integraciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def test_full_training_workflow(config, sample_data, tmp_path):
    trainer = ChurnTrainer(config)
    data = trainer.load_data(data_path)
    X, y = trainer.prepare_features(data)
    model, metrics = trainer.train(X, y)
    trainer.save_model(model_path)

    # Verify artifacts
    assert model_path.exists()
    assert metrics[&quot;test_f1&quot;] &gt; 0.5
</code></pre>
<h2>Pregunta 39: Dockerfile Multi-Stage</h2>
<p><strong>Explica tu Dockerfile.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-dockerfile"># Stage 1: Builder
FROM python:3.13-slim AS builder
RUN pip install -r requirements.txt
# Stage 2: Runtime
FROM python:3.13-slim AS runtime
COPY --from=builder /opt/venv /opt/venv
USER appuser  # Non-root
HEALTHCHECK CMD curl -f http://localhost:8000/health
CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;]
</code></pre>
<p><strong>Beneficios</strong>: Imagen final sin build tools, usuario non-root, healthcheck.</p>
<h2>Pregunta 40: CORS Configuration</h2>
<p><strong>Â¿CÃ³mo configuraste CORS?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">app.add_middleware(
    CORSMiddleware,
    allow_origins=[&quot;*&quot;],  # ProducciÃ³n: restringir
    allow_methods=[&quot;GET&quot;, &quot;POST&quot;],
    allow_headers=[&quot;*&quot;],
)
</code></pre>
<p><strong>Nota</strong>: <code>allow_origins=["*"]</code> solo para desarrollo. ProducciÃ³n especifica dominios.</p>
<h2>Pregunta 41-45: [Ver archivo parte 2]</h2>
<h1>4. CarVision-Market-Intelligence (Preguntas 46-60)</h1>
<h2>Pregunta 46: Pipeline [features, pre, model]</h2>
<p><strong>Explica el pipeline de CarVision.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">pipe = Pipeline([
    (&quot;features&quot;, FeatureEngineer(current_year=2024)),
    (&quot;pre&quot;, ColumnTransformer([
        (&quot;num&quot;, numeric_pipeline, num_cols),
        (&quot;cat&quot;, categorical_pipeline, cat_cols)
    ])),
    (&quot;model&quot;, RandomForestRegressor())
])
</code></pre>
<p><strong>Flujo</strong>: Raw DF â†’ Feature Engineering â†’ Preprocessing â†’ Model.</p>
<h2>Pregunta 47: Data Filtering</h2>
<p><strong>Â¿Por quÃ© filtras precios entre $1K-$500K?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def clean_data(df, filters):
    df = df[(df[&quot;price&quot;] &gt; 1000) &amp; (df[&quot;price&quot;] &lt; 500000)]
    df = df[df[&quot;model_year&quot;] &gt;= 1990]
    df = df[df[&quot;odometer&quot;] &lt; 500000]
</code></pre>
<p><strong>RazÃ³n</strong>: &lt; $1K son errores/donaciones, &gt; $500K son coleccionables (mercado diferente).</p>
<h2>Pregunta 48: Bootstrap Confidence Intervals</h2>
<p><strong>Â¿CÃ³mo calculas intervalos de confianza?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">for _ in range(200):
    idx = rng.choice(n, size=n, replace=True)
    deltas.append(rmse(y[idx], y_model[idx]) - rmse(y[idx], y_base[idx]))

ci_low, ci_high = np.percentile(deltas, [2.5, 97.5])
</code></pre>
<p><strong>InterpretaciÃ³n</strong>: CI95 no incluye 0 â†’ diferencia significativa.</p>
<h2>Pregunta 49: Temporal Backtesting</h2>
<p><strong>Â¿CÃ³mo validas con datos temporales?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">df_sorted = df.sort_values(&quot;model_year&quot;)
df_test = df_sorted.tail(int(len(df) * 0.2))  # MÃ¡s recientes
metrics_temporal = evaluate(model, df_test)
</code></pre>
<p><strong>Simula producciÃ³n</strong>: Siempre predecimos el "futuro".</p>
<h2>Pregunta 50: Streamlit Caching</h2>
<p><strong>Â¿CÃ³mo optimizas el dashboard?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">@st.cache_data  # DataFrames (serializable)
def load_data():
    return FeatureEngineer().transform(load_raw_data())

@st.cache_resource  # Modelos (no serializable)
def load_model():
    return joblib.load(&quot;model.joblib&quot;)
</code></pre>
<h2>Preguntas 51-60: [Ver archivo parte 2]</h2>
<h1>5. TelecomAI (Preguntas 61-70)</h1>
<h2>Pregunta 61: Simple Feature Set</h2>
<p><strong>Â¿Por quÃ© solo 4 features?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">features: [calls, minutes, messages, mb_used]
</code></pre>
<p><strong>RazÃ³n</strong>: ~2K muestras, mÃ¡s features = overfitting. AUC 0.84 indica seÃ±al suficiente.</p>
<h2>Pregunta 62: GradientBoosting Shallow</h2>
<p><strong>Â¿Por quÃ© max_depth=2?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">model:
  name: gradient_boosting
  params: {n_estimators: 200, max_depth: 2, learning_rate: 0.05}
</code></pre>
<p><strong>Muchos Ã¡rboles simples</strong>: RegularizaciÃ³n fuerte, reduce overfitting en dataset pequeÃ±o.</p>
<h2>Pregunta 63-70: [Ver archivo parte 2]</h2>
<h1>6. Arquitectura y DiseÃ±o (Preguntas 71-80)</h1>
<h2>Pregunta 71: Design Patterns</h2>
<p><strong>Â¿QuÃ© patrones aplicaste?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Strategy</strong>: <code>ResampleClassifier(strategy="oversample")</code></li>
<li><strong>Factory</strong>: <code>build_model(cfg)</code> crea diferentes clasificadores</li>
<li><strong>Template Method</strong>: <code>ChurnTrainer.train()</code> con pasos customizables</li>
<li><strong>Dependency Injection</strong>: <code>ChurnTrainer(config)</code></li>
</ol>
<h2>Pregunta 72: SOLID Principles</h2>
<p><strong>Â¿CÃ³mo aplicaste SOLID?</strong></p>
<h3>Respuesta:</h3>
<ul>
<li><strong>S</strong>: Un mÃ³dulo, una responsabilidad (training.py solo entrena)</li>
<li><strong>O</strong>: ResampleClassifier abierto a nuevas estrategias</li>
<li><strong>L</strong>: Hereda de sklearn, sustituible donde se espere classifier</li>
<li><strong>I</strong>: Interfaces pequeÃ±as (Predictor, Evaluator, Trainer)</li>
<li><strong>D</strong>: Depende de config, no de valores hardcodeados</li>
</ul>
<h2>Preguntas 73-80: [Ver archivo parte 2]</h2>
<h1>7. CI/CD y DevOps (Preguntas 81-90)</h1>
<h2>Pregunta 81: Unified CI Pipeline</h2>
<p><strong>Explica tu workflow unificado.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># ci-mlops.yml
jobs:
  tests:           # pytest + coverage por proyecto
  quality-gates:   # black, flake8, mypy
  security:        # bandit, gitleaks, pip-audit
  docker:          # build + trivy scan
  integration-test: # docker-compose E2E
</code></pre>
<p><strong>Matrix</strong>: Python 3.11/3.12 Ã— 3 proyectos.</p>
<h2>Pregunta 82: Security Scanning</h2>
<p><strong>Â¿QuÃ© herramientas de seguridad usas?</strong></p>
<h3>Respuesta:</h3>
<ul>
<li><strong>Gitleaks</strong>: Detecta secrets en cÃ³digo</li>
<li><strong>Bandit</strong>: AnÃ¡lisis estÃ¡tico Python</li>
<li><strong>Trivy</strong>: Vulnerabilidades en containers</li>
<li><strong>pip-audit</strong>: Dependencias con CVEs</li>
</ul>
<h2>Preguntas 83-90: [Ver archivo parte 2]</h2>
<h1>8. Infraestructura (Preguntas 91-100)</h1>
<h2>Pregunta 91: Kubernetes Deployment</h2>
<p><strong>Explica tu deployment de K8s.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
spec:
  replicas: 3
  strategy: {type: RollingUpdate}
  template:
    spec:
      containers:
      - name: bankchurn-api
        resources:
          requests: {memory: &quot;512Mi&quot;, cpu: &quot;250m&quot;}
          limits: {memory: &quot;1Gi&quot;, cpu: &quot;1000m&quot;}
        livenessProbe: ...
        readinessProbe: ...
</code></pre>
<h2>Pregunta 92: HorizontalPodAutoscaler</h2>
<p><strong>Â¿CÃ³mo configuras autoscaling?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
spec:
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource: {name: cpu, target: {averageUtilization: 70}}
</code></pre>
<h2>Preguntas 93-100: [Ver archivo parte 2]</h2>
<h1>9. Ã‰tica y Fairness (Preguntas 101-105)</h1>
<h2>Pregunta 101: Responsible AI</h2>
<p><strong>Â¿CÃ³mo abordas responsabilidad en ML?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Model Cards</strong>: Documentan limitaciones y riesgos</li>
<li><strong>Fairness metrics</strong>: Disparate Impact por grupo</li>
<li><strong>Transparencia</strong>: Logs de predicciones, versiones</li>
<li><strong>Human-in-loop</strong>: Modelo como apoyo, no decisiÃ³n final</li>
</ol>
<h2>Pregunta 102-105: [Ver archivo parte 2]</h2>
<h1>10. Liderazgo (Preguntas 106-115)</h1>
<h2>Pregunta 106: Technical Decision Making</h2>
<p><strong>Â¿CÃ³mo decides entre RF y GB?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Factores</strong>: TamaÃ±o dataset, tipo de features, requerimientos de latencia, interpretabilidad.<br />
<strong>Proceso</strong>: Experimento con baseline â†’ comparar mÃ©tricas â†’ considerar trade-offs.</p>
<h2>Preguntas 107-115: [Ver archivo Parte 2]</h2>
<p><strong>[ContinÃºa en SIMULACRO_ENTREVISTA_PARTE2.md]</strong></p>
            </div>
        
            <!-- MÃ“DULO: SIMULACRO_ENTREVISTA_SENIOR_PARTE2.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_SIMULACRO_ENTREVISTA_SENIOR_PARTE2" class="cover-title">SIMULACRO SENIOR (PARTE 2)</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ¯ Simulacro Entrevista Lead/Senior ML Engineer - Parte 2</h1>
<p><strong>ContinuaciÃ³n de preguntas 41-115</strong></p>
<h1>Preguntas 41-45: BankChurn (continuaciÃ³n)</h1>
<h2>Pregunta 41: Risk Level Classification</h2>
<p><strong>Â¿CÃ³mo categorizas el riesgo de churn?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># prediction.py
def _assign_risk_level(self, probability: float) -&gt; str:
    if probability &lt; 0.3:
        return &quot;low&quot;
    elif probability &lt; 0.7:
        return &quot;medium&quot;
    else:
        return &quot;high&quot;
</code></pre>
<p><strong>Uso en negocio</strong>:<br />
- <strong>High</strong>: Contacto proactivo inmediato<br />
- <strong>Medium</strong>: Ofertas de retenciÃ³n<br />
- <strong>Low</strong>: Monitoreo estÃ¡ndar</p>
<h2>Pregunta 42: Feature Contribution Explanation</h2>
<p><strong>Â¿CÃ³mo explicas las predicciones?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># prediction.py
def _generate_explanation(self, X_row) -&gt; Dict[str, float]:
    # Enfoque simplificado: distancia a media por feature
    contributions = {}
    for col in self.feature_names:
        mean_val = self.feature_means.get(col, 0)
        diff = (X_row[col] - mean_val) / (self.feature_stds.get(col, 1) + 1e-8)
        contributions[col] = float(diff)
    return contributions
</code></pre>
<p><strong>LimitaciÃ³n reconocida</strong>: No es SHAP values real, pero da intuiciÃ³n inicial sin dependencia adicional.</p>
<h2>Pregunta 43: Model Metadata</h2>
<p><strong>Â¿QuÃ© metadata guardas con el modelo?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-json">{
  &quot;version&quot;: &quot;1.0.0&quot;,
  &quot;trained_at&quot;: &quot;2024-11-20T10:30:00Z&quot;,
  &quot;config_hash&quot;: &quot;abc123def456&quot;,
  &quot;test_metrics&quot;: {
    &quot;f1_score&quot;: 0.82,
    &quot;auc_roc&quot;: 0.853
  },
  &quot;feature_names&quot;: [&quot;CreditScore&quot;, &quot;Age&quot;, ...],
  &quot;training_samples&quot;: 8000,
  &quot;git_commit&quot;: &quot;abc123&quot;
}
</code></pre>
<p><strong>Uso</strong>: Trazabilidad, comparaciÃ³n entre versiones, debugging.</p>
<h2>Pregunta 44: Lifespan vs On-Event Loading</h2>
<p><strong>Â¿Por quÃ© usas lifespan en lugar de startup event?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># FastAPI &gt;= 0.95 depreca @app.on_event
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    load_model()
    yield
    # Shutdown (cleanup)

app = FastAPI(lifespan=lifespan)
</code></pre>
<p><strong>Beneficios</strong>:<br />
- PatrÃ³n moderno recomendado<br />
- Context manager claro para setup/teardown<br />
- Mejor manejo de recursos async</p>
<h2>Pregunta 45: Test Coverage Strategy</h2>
<p><strong>Â¿CÃ³mo alcanzaste 77% coverage?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># pytest.ini
[pytest]
addopts = --cov=src/bankchurn --cov-report=term-missing

# Estrategia:
# 1. Unit tests por mÃ³dulo
# 2. Integration tests para workflows completos
# 3. Edge cases: datos vacÃ­os, missing columns, tipos invÃ¡lidos
# 4. Error paths: excepciones esperadas
</code></pre>
<p><strong>Cobertura por mÃ³dulo</strong>:<br />
- training.py: 85%<br />
- evaluation.py: 80%<br />
- config.py: 90%<br />
- cli.py: 60% (I/O difÃ­cil de testear)</p>
<h1>Preguntas 51-60: CarVision (continuaciÃ³n)</h1>
<h2>Pregunta 51: Feature Type Inference</h2>
<p><strong>Â¿CÃ³mo detectas tipos de features automÃ¡ticamente?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># data.py
def infer_feature_types(df, cfg):
    num_cfg = cfg.get(&quot;numeric_features&quot;, [])
    cat_cfg = cfg.get(&quot;categorical_features&quot;, [])

    if not num_cfg:
        num_cfg = df.select_dtypes(include=[&quot;int64&quot;, &quot;float64&quot;]).columns.tolist()
    if not cat_cfg:
        cat_cfg = df.select_dtypes(include=[&quot;object&quot;, &quot;category&quot;]).columns.tolist()

    return num_cfg, cat_cfg
</code></pre>
<p><strong>Beneficio</strong>: Config minimalista (<code>[]</code>) usa inferencia automÃ¡tica.</p>
<h2>Pregunta 52: Segment Error Analysis</h2>
<p><strong>Â¿CÃ³mo analizas errores por segmento?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def _analyse_errors_by_segment(df, y_true, y_pred, segment_cols):
    results = []
    for col in segment_cols:  # [&quot;condition&quot;, &quot;type&quot;, &quot;model_year&quot;]
        for val, group in df.groupby(col):
            if len(group) &lt; 30:
                continue
            results.append({
                &quot;segment&quot;: f&quot;{col}={val}&quot;,
                &quot;rmse&quot;: rmse(group[target], y_pred[group.index]),
                &quot;n_samples&quot;: len(group)
            })
    return pd.DataFrame(results)
</code></pre>
<p><strong>Hallazgo tÃ­pico</strong>: Mayor error en autos muy nuevos (pocos datos) o muy viejos (alta variabilidad).</p>
<h2>Pregunta 53: Dual Application (API + Dashboard)</h2>
<p><strong>Â¿CÃ³mo manejas API y Streamlit juntos?</strong></p>
<h3>Respuesta:</h3>
<pre><code>app/
â”œâ”€â”€ fastapi_app.py     # REST API (port 8002)
â””â”€â”€ streamlit_app.py   # Dashboard (port 8501)
</code></pre>
<p><strong>Ambos usan</strong>:</p>
<pre><code class="language-python">from src.carvision.features import FeatureEngineer
from src.carvision.data import clean_data

# Mismo pipeline, diferentes interfaces
model = joblib.load(MODEL_PATH)
</code></pre>
<p><strong>Docker Compose</strong>:</p>
<pre><code class="language-yaml">services:
  carvision-api:
    command: uvicorn app.fastapi_app:app --port 8002
  carvision-dashboard:
    command: streamlit run app/streamlit_app.py --server.port 8501
</code></pre>
<h2>Pregunta 54: Price Category Leakage</h2>
<p><strong>Â¿Por quÃ© price_category causa leakage?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># features.py - ANTES (bug)
X[&quot;price_category&quot;] = pd.cut(X[&quot;price&quot;], bins=[0, 5000, 15000, 50000, np.inf])
</code></pre>
<p><strong>Problema</strong>: <code>price_category</code> depende de <code>price</code> (el target).<br />
- En training: tiene el valor correcto<br />
- En inference: <code>price</code> no existe â†’ error o leakage si se imputa</p>
<p><strong>SoluciÃ³n</strong>: <code>drop_columns: ["price_per_mile", "price_category"]</code> en config.</p>
<h2>Pregunta 55: Split Indices Persistence</h2>
<p><strong>Â¿Por quÃ© guardas los Ã­ndices del split?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">def save_split_indices(indices, path):
    with open(path, &quot;w&quot;) as f:
        json.dump({k: v.tolist() for k, v in indices.items()}, f)
</code></pre>
<p><strong>Uso</strong>:</p>
<pre><code class="language-python"># Reproducir exactamente el mismo split
indices = load_split_indices(&quot;split_indices.json&quot;)
X_train = X.iloc[indices[&quot;train&quot;]]
X_test = X.iloc[indices[&quot;test&quot;]]
</code></pre>
<p><strong>Beneficio</strong>: Comparar modelos con EXACTAMENTE los mismos datos de test.</p>
<h2>Pregunta 56: Dummy Baseline</h2>
<p><strong>Â¿Por quÃ© comparas con DummyRegressor?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">dummy = DummyRegressor(strategy=&quot;median&quot;)
baseline_rmse = rmse(y_test, dummy.fit(X_train, y_train).predict(X_test))
</code></pre>
<p><strong>Estrategias disponibles</strong>:<br />
- <code>mean</code>: Predice promedio<br />
- <code>median</code>: Predice mediana (robusta a outliers)<br />
- <code>constant</code>: Valor fijo</p>
<p><strong>InterpretaciÃ³n</strong>: Si tu modelo no supera dummy, no agrega valor.</p>
<h2>Pregunta 57: Random Forest para RegresiÃ³n</h2>
<p><strong>Â¿Por quÃ© RF y no XGBoost para CarVision?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Criterio</th>
<th>RandomForest</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Simplicidad</strong></td>
<td>Menos hiperparÃ¡metros</td>
<td>Muchos HP crÃ­ticos</td>
</tr>
<tr>
<td><strong>Robustez</strong></td>
<td>Menos sensible a HP</td>
<td>Requiere tuning fino</td>
</tr>
<tr>
<td><strong>Interpretabilidad</strong></td>
<td>Feature importance directa</td>
<td>MÃ¡s complejo</td>
</tr>
<tr>
<td><strong>Performance</strong></td>
<td>Competitivo en tabular</td>
<td>Marginalmente mejor</td>
</tr>
</tbody>
</table>
<p><strong>DecisiÃ³n</strong>: RF es "good enough" con menor riesgo de overfitting y configuraciÃ³n mÃ¡s simple.</p>
<h2>Pregunta 58: MAPE Calculation</h2>
<p><strong>Â¿Por quÃ© sumas epsilon en MAPE?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python">mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100
</code></pre>
<p><strong>Problema</strong>: Si <code>y_true = 0</code>, divisiÃ³n por cero.<br />
<strong>SoluciÃ³n</strong>: <code>+ 1e-8</code> evita divisiÃ³n por cero.</p>
<p><strong>Alternativa mejor para precios</strong>:</p>
<pre><code class="language-python"># Symmetric MAPE
smape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))
</code></pre>
<h2>Pregunta 59: Streamlit Sections</h2>
<p><strong>Â¿CÃ³mo organizas el dashboard?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># streamlit_app.py
tab1, tab2, tab3, tab4 = st.tabs([
    &quot;ğŸ“Š Overview&quot;,
    &quot;ğŸ“ˆ Market Analysis&quot;, 
    &quot;ğŸ¯ Model Metrics&quot;,
    &quot;ğŸ’° Price Predictor&quot;
])

with tab1:
    display_overview_kpis()
with tab4:
    # Formulario de predicciÃ³n
    brand = st.selectbox(&quot;Brand&quot;, brands)
    year = st.slider(&quot;Year&quot;, 1990, 2024)
    if st.button(&quot;Predict&quot;):
        pred = model.predict(features)
        st.success(f&quot;Estimated Price: ${pred:,.0f}&quot;)
</code></pre>
<h2>Pregunta 60: API vs Dashboard Trade-offs</h2>
<p><strong>Â¿CuÃ¡ndo recomiendas API vs Dashboard?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Caso de Uso</th>
<th>RecomendaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td>IntegraciÃ³n con otros sistemas</td>
<td>API</td>
</tr>
<tr>
<td>Usuarios no tÃ©cnicos</td>
<td>Dashboard</td>
</tr>
<tr>
<td>Alto volumen</td>
<td>API</td>
</tr>
<tr>
<td>ExploraciÃ³n ad-hoc</td>
<td>Dashboard</td>
</tr>
<tr>
<td>AutomatizaciÃ³n</td>
<td>API</td>
</tr>
<tr>
<td>Demos/POC</td>
<td>Dashboard</td>
</tr>
</tbody>
</table>
<p><strong>CarVision ofrece ambos</strong>: API para integraciÃ³n con sistemas de dealers, Dashboard para analistas de mercado.</p>
<h1>Preguntas 63-70: TelecomAI (continuaciÃ³n)</h1>
<h2>Pregunta 63: Unified Pipeline Benefit</h2>
<p><strong>Â¿Por quÃ© un solo artefacto pipeline?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># ANTES (2 archivos)
preprocessor = joblib.load(&quot;preprocessor.pkl&quot;)
model = joblib.load(&quot;model.pkl&quot;)
X_proc = preprocessor.transform(X)
pred = model.predict(X_proc)

# AHORA (1 archivo)
pipeline = joblib.load(&quot;model.joblib&quot;)
pred = pipeline.predict(X)
</code></pre>
<p><strong>Beneficios</strong>:<br />
1. Deployment mÃ¡s simple<br />
2. Imposible desincronizar preprocessor/model<br />
3. Una sola versiÃ³n para auditar</p>
<h2>Pregunta 64: Config YAML Structure</h2>
<p><strong>Â¿CÃ³mo estructuras el config de TelecomAI?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">project_name: TelecomAI-Customer-Intelligence
random_seed: 42

paths:
  data_csv: users_behavior.csv
  model_path: artifacts/model.joblib

features: [calls, minutes, messages, mb_used]
target: is_ultra

split:
  test_size: 0.2
  stratify: true

model:
  name: gradient_boosting
  params:
    n_estimators: 200
    max_depth: 2
</code></pre>
<p><strong>Principio</strong>: Toda configuraciÃ³n externalizada, ningÃºn valor hardcodeado.</p>
<h2>Pregunta 65: Stratify con ClasificaciÃ³n Binaria</h2>
<p><strong>Â¿CuÃ¡ndo es crÃ­tica la estratificaciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<p><strong>CrÃ­tica cuando</strong>:<br />
- Clases desbalanceadas (&lt; 70/30)<br />
- Dataset pequeÃ±o (&lt; 5K samples)<br />
- MÃ©trica sensible a distribuciÃ³n (precision, recall)</p>
<pre><code class="language-python"># Sin estratificaciÃ³n en 2K samples con 30% positivos:
# Test set podrÃ­a tener 20% o 40% positivos â†’ mÃ©tricas no comparables
</code></pre>
<h2>Pregunta 66: Simple Model Debugging</h2>
<p><strong>Â¿CÃ³mo debuggeas un modelo simple?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># 1. Check feature distributions
print(X_train.describe())
print(X_test.describe())  # DeberÃ­a ser similar

# 2. Check target distribution
print(y_train.value_counts(normalize=True))
print(y_test.value_counts(normalize=True))

# 3. Learning curve
from sklearn.model_selection import learning_curve
train_sizes, train_scores, val_scores = learning_curve(
    model, X, y, cv=5, scoring=&quot;roc_auc&quot;
)
</code></pre>
<h2>Pregunta 67: Gradient Boosting Learning Rate</h2>
<p><strong>Â¿QuÃ© pasa si lr es muy alto o muy bajo?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>lr</th>
<th>Efecto</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0.5+ (alto)</strong></td>
<td>Convergencia rÃ¡pida, riesgo de overfitting</td>
</tr>
<tr>
<td><strong>0.01-0.1 (medio)</strong></td>
<td>Balance tÃ­pico</td>
</tr>
<tr>
<td><strong>&lt; 0.01 (bajo)</strong></td>
<td>Necesita muchos estimators, mÃ¡s robusto</td>
</tr>
</tbody>
</table>
<pre><code class="language-python"># TelecomAI usa lr=0.05, n_estimators=200
# Conservador pero estable
</code></pre>
<p><strong>Regla prÃ¡ctica</strong>: <code>lr * n_estimators â‰ˆ 10-20</code> para convergencia.</p>
<h2>Pregunta 68: Evaluation Metrics Save</h2>
<p><strong>Â¿CÃ³mo persistes mÃ©tricas?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># evaluation.py
def evaluate_model(pipeline, X_test, y_test, cfg):
    metrics = compute_classification_metrics(y_test, y_pred, y_proba)

    # Save to YAML
    with open(cfg.paths[&quot;metrics_path&quot;], &quot;w&quot;) as f:
        yaml.safe_dump(metrics, f)

    return metrics
</code></pre>
<p><strong>Formato YAML</strong> para legibilidad humana:</p>
<pre><code class="language-yaml">accuracy: 0.812
precision: 0.785
recall: 0.743
f1: 0.763
roc_auc: 0.840
</code></pre>
<h2>Pregunta 69: FastAPI App TelecomAI</h2>
<p><strong>Â¿CÃ³mo estructuras la API?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># app/fastapi_app.py
class UserBehavior(BaseModel):
    calls: int
    minutes: float
    messages: int
    mb_used: float

@app.post(&quot;/predict&quot;)
async def predict_plan(user: UserBehavior):
    features = pd.DataFrame([user.dict()])
    pred = pipeline.predict(features)[0]
    proba = pipeline.predict_proba(features)[0][1]
    return {
        &quot;recommended_plan&quot;: &quot;Ultra&quot; if pred == 1 else &quot;Basic&quot;,
        &quot;confidence&quot;: float(proba)
    }
</code></pre>
<h2>Pregunta 70: TelecomAI Business Context</h2>
<p><strong>Â¿CÃ³mo se usa el modelo en el negocio?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Contexto</strong>: Recomendar plan de datos (Basic vs Ultra) basado en patrones de uso.</p>
<p><strong>Flujo</strong>:<br />
1. Cliente usa servicio por periodo de prueba<br />
2. Sistema recolecta mÃ©tricas: calls, minutes, messages, mb_used<br />
3. Modelo predice plan Ã³ptimo<br />
4. Ventas contacta con oferta personalizada</p>
<p><strong>Valor</strong>:<br />
- Reduce churn por plan inadecuado<br />
- Aumenta ARPU en usuarios infraservidos<br />
- Mejora satisfacciÃ³n del cliente</p>
<h1>Preguntas 73-80: Arquitectura (continuaciÃ³n)</h1>
<h2>Pregunta 73: Error Handling Philosophy</h2>
<p><strong>Â¿CuÃ¡l es tu filosofÃ­a de manejo de errores?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Fail fast</strong>: Validar inputs al inicio</li>
<li><strong>Errores especÃ­ficos</strong>: <code>ValueError</code> vs <code>FileNotFoundError</code> vs genÃ©rico</li>
<li><strong>Logs contextuales</strong>: Incluir datos relevantes en el error</li>
<li><strong>Graceful degradation</strong>: Servicio funciona con capacidad reducida</li>
</ol>
<pre><code class="language-python"># Malo
try:
    do_something()
except Exception:
    pass

# Bueno
try:
    do_something(input_data)
except ValueError as e:
    logger.error(f&quot;Invalid input {input_data}: {e}&quot;)
    raise HTTPException(400, f&quot;Invalid input: {e}&quot;)
except FileNotFoundError as e:
    logger.error(f&quot;Model file missing: {e}&quot;)
    raise HTTPException(503, &quot;Model not available&quot;)
</code></pre>
<h2>Pregunta 74: Dependency Management</h2>
<p><strong>Â¿CÃ³mo manejas dependencias entre proyectos?</strong></p>
<h3>Respuesta:</h3>
<pre><code>Projects Tripe Ten/
â”œâ”€â”€ common_utils/         # Shared code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ seed.py
â”œâ”€â”€ BankChurn-Predictor/
â”‚   â””â”€â”€ requirements.txt  # Project-specific deps
â”œâ”€â”€ CarVision-Market-Intelligence/
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ TelecomAI-Customer-Intelligence/
    â””â”€â”€ requirements.txt
</code></pre>
<p><strong>common_utils</strong> en cada project:</p>
<pre><code class="language-python">import sys
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
from common_utils.seed import set_seed
</code></pre>
<h2>Pregunta 75: API Versioning</h2>
<p><strong>Â¿CÃ³mo versionarÃ­as la API?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># OpciÃ³n 1: Path versioning
@app.post(&quot;/v1/predict&quot;)
@app.post(&quot;/v2/predict&quot;)

# OpciÃ³n 2: Header versioning
@app.post(&quot;/predict&quot;)
async def predict(request: Request):
    version = request.headers.get(&quot;API-Version&quot;, &quot;1&quot;)

# OpciÃ³n 3: Query param
@app.post(&quot;/predict&quot;)
async def predict(version: str = Query(&quot;1&quot;)):
</code></pre>
<p><strong>RecomendaciÃ³n</strong>: Path versioning es mÃ¡s explÃ­cito y cacheable.</p>
<h2>Pregunta 76: Configuration Hierarchy</h2>
<p><strong>Â¿CÃ³mo manejas diferentes environments?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># configs/config.yaml (base)
mlflow:
  tracking_uri: &quot;file:./mlruns&quot;  # Default: local

# Override via environment variables
# MLFLOW_TRACKING_URI=http://mlflow.prod:5000

# O archivos separados
# configs/config.dev.yaml
# configs/config.prod.yaml
</code></pre>
<p><strong>Carga con override</strong>:</p>
<pre><code class="language-python">config = BankChurnConfig.from_yaml(&quot;configs/config.yaml&quot;)
config.mlflow.tracking_uri = os.getenv(&quot;MLFLOW_URI&quot;, config.mlflow.tracking_uri)
</code></pre>
<h2>Pregunta 77: Async vs Sync en FastAPI</h2>
<p><strong>Â¿CuÃ¡ndo usas async?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Sync - operaciones CPU-bound (ML inference)
@app.post(&quot;/predict&quot;)
def predict_sync(data: CustomerData):
    return model.predict(data)  # CPU bound

# Async - operaciones I/O bound
@app.get(&quot;/health&quot;)
async def health_async():
    await check_external_service()  # Network call
</code></pre>
<p><strong>ML inference es CPU-bound</strong>: <code>def</code> es preferible para evitar bloquear event loop.</p>
<h2>Pregunta 78: Testing Pyramid</h2>
<p><strong>Â¿CÃ³mo estructuras tus tests?</strong></p>
<h3>Respuesta:</h3>
<pre><code>Tests/
â”œâ”€â”€ Unit (70%)
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_evaluation.py
â”œâ”€â”€ Integration (20%)
â”‚   â””â”€â”€ test_training.py (E2E workflow)
â””â”€â”€ E2E (10%)
    â””â”€â”€ test_api.py (requests reales)
</code></pre>
<p><strong>PirÃ¡mide</strong>: Muchos unit tests (rÃ¡pidos), pocos E2E (lentos pero valiosos).</p>
<h2>Pregunta 79: Code Review Checklist</h2>
<p><strong>Â¿QuÃ© revisas en un PR de ML?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Data leakage</strong>: Â¿Split antes de fit?</li>
<li><strong>Reproducibilidad</strong>: Â¿Seeds configurados?</li>
<li><strong>Tests</strong>: Â¿Cubren happy path y edge cases?</li>
<li><strong>Config</strong>: Â¿Valores hardcodeados?</li>
<li><strong>MÃ©tricas</strong>: Â¿Apropiadas para el problema?</li>
<li><strong>Logging</strong>: Â¿Suficiente para debugging?</li>
<li><strong>Documentation</strong>: Â¿Model card actualizado?</li>
</ol>
<h2>Pregunta 80: Technical Debt Management</h2>
<p><strong>Â¿CÃ³mo manejas deuda tÃ©cnica?</strong></p>
<h3>Respuesta:</h3>
<p><strong>CategorizaciÃ³n</strong>:<br />
- <strong>Critical</strong>: Bugs de seguridad, data leakage â†’ Sprint actual<br />
- <strong>High</strong>: Tests faltantes, logging pobre â†’ PrÃ³ximo sprint<br />
- <strong>Medium</strong>: Refactoring, documentaciÃ³n â†’ Backlog priorizado<br />
- <strong>Low</strong>: Nice-to-have â†’ Tech debt day mensual</p>
<p><strong>Tracking</strong>: Issues en GitHub con label <code>tech-debt</code> y estimaciÃ³n de impacto.</p>
<h1>Preguntas 83-90: CI/CD (continuaciÃ³n)</h1>
<h2>Pregunta 83: Matrix Testing Strategy</h2>
<p><strong>Â¿Por quÃ© matrix Python 3.11/3.12?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">strategy:
  matrix:
    python-version: ['3.11', '3.12']
    project: [BankChurn, CarVision, TelecomAI]
</code></pre>
<p><strong>Razones</strong>:<br />
- <strong>3.11</strong>: VersiÃ³n estable ampliamente usada<br />
- <strong>3.12</strong>: VersiÃ³n mÃ¡s reciente, validar compatibilidad<br />
- <strong>3 proyectos</strong>: Detectar regresiones cross-project</p>
<p><strong>Total jobs</strong>: 2 Ã— 3 = 6 combinaciones paralelas.</p>
<h2>Pregunta 84: Fail-Fast Strategy</h2>
<p><strong>Â¿CuÃ¡ndo usar fail-fast: false?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">strategy:
  fail-fast: false  # ContinÃºa aunque un job falle
</code></pre>
<p><strong>Usar <code>false</code> cuando</strong>:<br />
- Quieres ver TODOS los errores, no solo el primero<br />
- Jobs son independientes (matriz de versiones)<br />
- Debugging de problemas de compatibilidad</p>
<p><strong>Usar <code>true</code> cuando</strong>:<br />
- Jobs dependientes<br />
- Quieres feedback rÃ¡pido<br />
- Recursos de CI limitados</p>
<h2>Pregunta 85: Docker Build Caching</h2>
<p><strong>Â¿CÃ³mo optimizas builds de Docker?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-dockerfile"># Orden Ã³ptimo de COPY
COPY requirements.txt .
RUN pip install -r requirements.txt  # Cached si requirements no cambia
COPY src/ ./src/                      # Solo copia cÃ³digo
</code></pre>
<p><strong>CI caching</strong>:</p>
<pre><code class="language-yaml">- uses: docker/build-push-action@v5
  with:
    cache-from: type=gha
    cache-to: type=gha,mode=max
</code></pre>
<h2>Pregunta 86: Security Scanning Results</h2>
<p><strong>Â¿QuÃ© haces con findings de seguridad?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Proceso</strong>:<br />
1. <strong>Critical/High</strong>: Bloquea PR, fix inmediato<br />
2. <strong>Medium</strong>: Documenta, fix en siguiente sprint<br />
3. <strong>Low</strong>: Backlog, evaluar riesgo/esfuerzo<br />
4. <strong>False positives</strong>: AÃ±adir a <code>.gitleaksignore</code> con justificaciÃ³n</p>
<pre><code class="language-yaml"># .gitleaksignore
# False positive: example API key in documentation
docs/examples/api_usage.md:15
</code></pre>
<h2>Pregunta 87: Coverage Thresholds</h2>
<p><strong>Â¿Por quÃ© 70% coverage mÃ­nimo?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">- name: Check coverage threshold
  run: |
    coverage report --fail-under=70
</code></pre>
<p><strong>RazÃ³n del 70%</strong>:<br />
- <strong>&lt; 60%</strong>: Riesgo de bugs no detectados<br />
- <strong>70-80%</strong>: Balance costo/beneficio tÃ­pico<br />
- <strong>&gt; 90%</strong>: Diminishing returns, tests frÃ¡giles</p>
<p><strong>No todo necesita tests</strong>: I/O, logging, error messages triviales.</p>
<h2>Pregunta 88: Integration Test Strategy</h2>
<p><strong>Â¿QuÃ© cubren tus integration tests?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">integration-test:
  steps:
    - run: docker-compose -f docker-compose.demo.yml up -d
    - run: |
        # Wait for services
        sleep 30
        # Test each API
        curl http://localhost:8001/health
        curl http://localhost:8002/health
        curl -X POST http://localhost:8001/predict -d '...'
</code></pre>
<p><strong>Cobertura</strong>: Health checks, predicciones bÃ¡sicas, formato de respuesta.</p>
<h2>Pregunta 89: Documentation Validation</h2>
<p><strong>Â¿CÃ³mo validas documentaciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">doc-validation:
  steps:
    - name: Check markdown links
      run: |
        npm install -g markdown-link-check
        find . -name &quot;*.md&quot; -exec markdown-link-check {} \;

    - name: Build mkdocs
      run: |
        pip install mkdocs
        mkdocs build --strict
</code></pre>
<p><strong>Valida</strong>: Links rotos, sintaxis markdown, build de docs.</p>
<h2>Pregunta 90: Deployment Strategy</h2>
<p><strong>Â¿CÃ³mo desplegarÃ­as a producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">deploy-prod:
  needs: [tests, security, docker-build]
  if: github.ref == 'refs/heads/main'
  steps:
    - name: Push to registry
      run: docker push ghcr.io/${{ github.repository }}:${{ github.sha }}

    - name: Update K8s deployment
      run: |
        kubectl set image deployment/bankchurn \
          bankchurn=ghcr.io/${{ github.repository }}:${{ github.sha }}
</code></pre>
<p><strong>Estrategia</strong>: Rolling update con readiness probes.</p>
<h1>Preguntas 93-100: Infraestructura (continuaciÃ³n)</h1>
<h2>Pregunta 93: Resource Requests vs Limits</h2>
<p><strong>Explica requests vs limits en K8s.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">resources:
  requests:
    memory: &quot;512Mi&quot;  # Garantizado
    cpu: &quot;250m&quot;      # Scheduler usa esto para placement
  limits:
    memory: &quot;1Gi&quot;    # MÃ¡ximo (OOMKill si excede)
    cpu: &quot;1000m&quot;     # Throttling si excede
</code></pre>
<p><strong>Best practice</strong>:<br />
- <code>requests</code>: Uso tÃ­pico (P50)<br />
- <code>limits</code>: Uso pico aceptable (P99)</p>
<h2>Pregunta 94: Prometheus Scraping</h2>
<p><strong>Â¿CÃ³mo configuras Prometheus para scraping?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml"># prometheus-config.yaml
scrape_configs:
  - job_name: 'bankchurn-predictor'
    kubernetes_sd_configs:
    - role: pod
      namespaces:
        names: [ml-portfolio]
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_label_app]
      action: keep
      regex: bankchurn-predictor
</code></pre>
<p><strong>Annotations en Deployment</strong>:</p>
<pre><code class="language-yaml">annotations:
  prometheus.io/scrape: &quot;true&quot;
  prometheus.io/port: &quot;8000&quot;
  prometheus.io/path: &quot;/metrics&quot;
</code></pre>
<h2>Pregunta 95: ConfigMap Usage</h2>
<p><strong>Â¿CuÃ¡ndo usas ConfigMap vs Secret?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Dato</th>
<th>Usar</th>
</tr>
</thead>
<tbody>
<tr>
<td>MODEL_VERSION</td>
<td>ConfigMap</td>
</tr>
<tr>
<td>LOG_LEVEL</td>
<td>ConfigMap</td>
</tr>
<tr>
<td>API_KEY</td>
<td>Secret</td>
</tr>
<tr>
<td>DB_PASSWORD</td>
<td>Secret</td>
</tr>
</tbody>
</table>
<pre><code class="language-yaml"># ConfigMap
apiVersion: v1
kind: ConfigMap
data:
  MODEL_VERSION: &quot;v2.0.0&quot;
  LOG_LEVEL: &quot;INFO&quot;
---
# Montaje en pod
envFrom:
  - configMapRef:
      name: bankchurn-config
</code></pre>
<h2>Pregunta 96: Rolling Update Strategy</h2>
<p><strong>Explica tu estrategia de actualizaciÃ³n.</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  # MÃ¡ximo 1 pod down
      maxSurge: 1        # MÃ¡ximo 1 pod extra temporal
</code></pre>
<p><strong>Flujo con 3 replicas</strong>:<br />
1. Crear 1 nuevo pod (4 total)<br />
2. Cuando nuevo estÃ¡ Ready, terminar 1 viejo (3 total)<br />
3. Repetir hasta todos actualizados</p>
<p><strong>Zero downtime</strong> con readiness probes correctos.</p>
<h2>Pregunta 97: Volume Mounts para Modelos</h2>
<p><strong>Â¿CÃ³mo montas modelos en K8s?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">spec:
  containers:
  - name: bankchurn-api
    volumeMounts:
    - name: models
      mountPath: /app/models
      readOnly: true
  volumes:
  - name: models
    persistentVolumeClaim:
      claimName: ml-models-pvc
</code></pre>
<p><strong>Alternativas</strong>:<br />
- <strong>PVC</strong>: Modelos compartidos entre pods<br />
- <strong>S3/GCS</strong>: Descarga al inicio<br />
- <strong>ConfigMap</strong>: Solo para configs pequeÃ±os</p>
<h2>Pregunta 98: Ingress Configuration</h2>
<p><strong>Â¿CÃ³mo expones servicios externamente?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-yaml">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ml-portfolio-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: bankchurn.example.com
    http:
      paths:
      - path: /
        backend:
          service:
            name: bankchurn-service
            port:
              number: 8000
</code></pre>
<h2>Pregunta 99: Terraform Overview</h2>
<p><strong>Â¿QuÃ© infraestructura defines con Terraform?</strong></p>
<h3>Respuesta:</h3>
<pre><code>infra/terraform/
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ main.tf      # EKS cluster, S3, RDS
â”‚   â”œâ”€â”€ variables.tf
â”‚   â””â”€â”€ outputs.tf
â””â”€â”€ gcp/
    â”œâ”€â”€ main.tf      # GKE, GCS, CloudSQL
    â””â”€â”€ ...
</code></pre>
<p><strong>Recursos tÃ­picos</strong>:<br />
- Container registry (ECR/GCR)<br />
- Kubernetes cluster (EKS/GKE)<br />
- Object storage (S3/GCS) para modelos<br />
- Database (RDS/CloudSQL) para MLflow</p>
<h2>Pregunta 100: Disaster Recovery</h2>
<p><strong>Â¿CÃ³mo manejas DR para ML systems?</strong></p>
<h3>Respuesta:</h3>
<p><strong>1. Model artifacts</strong>:<br />
- S3 versioning + cross-region replication<br />
- Git LFS / DVC como backup secundario</p>
<p><strong>2. MLflow database</strong>:<br />
- RDS multi-AZ + daily snapshots<br />
- Point-in-time recovery</p>
<p><strong>3. Kubernetes</strong>:<br />
- Declarative configs en Git (GitOps)<br />
- Multi-region deployment para HA</p>
<p><strong>RTO/RPO objetivos</strong>:<br />
- RTO (Recovery Time): &lt; 1 hora<br />
- RPO (Recovery Point): &lt; 1 dÃ­a de experimentos</p>
<h1>Preguntas 102-105: Ã‰tica (continuaciÃ³n)</h1>
<h2>Pregunta 102: Bias Detection</h2>
<p><strong>Â¿CÃ³mo detectas bias en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<pre><code class="language-python"># Monitoreo continuo
for segment in [&quot;Geography&quot;, &quot;Gender&quot;, &quot;Age_bucket&quot;]:
    pred_rate = predictions.groupby(segment)[&quot;churn_pred&quot;].mean()
    log_metric(f&quot;pred_rate_{segment}&quot;, pred_rate.to_dict())

    # Alerta si disparate impact &lt; 0.8
    di = pred_rate.min() / pred_rate.max()
    if di &lt; 0.8:
        alert(f&quot;Potential bias in {segment}: DI={di}&quot;)
</code></pre>
<h2>Pregunta 103: Model Card Maintenance</h2>
<p><strong>Â¿Con quÃ© frecuencia actualizas Model Cards?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Actualizar cuando</strong>:<br />
- Nueva versiÃ³n del modelo<br />
- Cambio en datos de entrenamiento<br />
- Descubrimiento de limitaciÃ³n/bias<br />
- Cambio en uso previsto</p>
<p><strong>Versionado</strong>: Model Card versiÃ³n = Model versiÃ³n (<code>v1.0.0</code>).</p>
<h2>Pregunta 104: Human-in-the-Loop</h2>
<p><strong>Â¿CÃ³mo integras supervisiÃ³n humana?</strong></p>
<h3>Respuesta:</h3>
<p><strong>BankChurn</strong>:<br />
- Modelo sugiere clientes en riesgo<br />
- Equipo de retenciÃ³n revisa lista<br />
- DecisiÃ³n final es humana (llamar o no)</p>
<p><strong>No automatizar</strong>: Ofertas, descuentos, cierre de cuentas.</p>
<h2>Pregunta 105: GDPR Compliance</h2>
<p><strong>Â¿CÃ³mo manejas datos personales?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>MinimizaciÃ³n</strong>: Solo features necesarias (no nombre, email)</li>
<li><strong>PseudonimizaciÃ³n</strong>: CustomerID sin mapeo a identidad real</li>
<li><strong>Right to erasure</strong>: Pipeline para eliminar datos de un cliente</li>
<li><strong>Audit trail</strong>: Logs de predicciones (sin PII) para auditorÃ­a</li>
</ol>
<h1>Preguntas 107-115: Liderazgo (continuaciÃ³n)</h1>
<h2>Pregunta 107: Team Communication</h2>
<p><strong>Â¿CÃ³mo comunicas decisiones tÃ©cnicas al equipo?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>ADRs (Architecture Decision Records)</strong>: Documentar why, not just what</li>
<li><strong>Tech talks</strong>: Sesiones de 30 min sobre decisiones importantes</li>
<li><strong>PR descriptions</strong>: Contexto suficiente para reviewers</li>
<li><strong>Diagrams</strong>: Mermaid/Lucidchart para arquitectura</li>
</ol>
<h2>Pregunta 108: Mentoring Junior Engineers</h2>
<p><strong>Â¿CÃ³mo mentoras a juniors en ML?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Pair programming</strong>: En primeros PRs de ML</li>
<li><strong>Code review detallado</strong>: Explicar el "por quÃ©"</li>
<li><strong>Recursos curados</strong>: Pointing to best practices</li>
<li><strong>Proyectos graduales</strong>: Simple â†’ Complejo</li>
</ol>
<p><strong>Errores comunes a prevenir</strong>:<br />
- Data leakage (el mÃ¡s crÃ­tico)<br />
- Overfitting sin validaciÃ³n<br />
- MÃ©tricas incorrectas para el problema</p>
<h2>Pregunta 109: Stakeholder Management</h2>
<p><strong>Â¿CÃ³mo manejas expectativas de stakeholders?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Baseline comparison</strong>: "El modelo mejora X% sobre regla actual"</li>
<li><strong>Confidence intervals</strong>: "PrecisiÃ³n entre 75-85%"</li>
<li><strong>Limitations explÃ­citas</strong>: "No funciona bien para casos X"</li>
<li><strong>Iterative delivery</strong>: MVP â†’ Mejoras incrementales</li>
</ol>
<p><strong>Evitar</strong>: Prometer 99% accuracy, plazos imposibles, omitir limitaciones.</p>
<h2>Pregunta 110: Technical Debt Negotiation</h2>
<p><strong>Â¿CÃ³mo negocias tiempo para tech debt?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Argumentos efectivos</strong>:<br />
1. <strong>Riesgo cuantificado</strong>: "Sin tests, bugs llegan a prod"<br />
2. <strong>Velocity impact</strong>: "Refactor ahora ahorra X horas/semana"<br />
3. <strong>Costo de delay</strong>: "Cada mes aumenta esfuerzo 20%"</p>
<p><strong>Estrategia</strong>: 20% del sprint para tech debt (negociado upfront).</p>
<h2>Pregunta 111: Production Incident Response</h2>
<p><strong>Â¿CÃ³mo manejas un incidente en producciÃ³n?</strong></p>
<h3>Respuesta:</h3>
<p><strong>Playbook</strong>:<br />
1. <strong>Detect</strong>: Alertas de Prometheus/PagerDuty<br />
2. <strong>Triage</strong>: Severity assessment (P1-P4)<br />
3. <strong>Communicate</strong>: Status page update<br />
4. <strong>Mitigate</strong>: Rollback if needed<br />
5. <strong>Fix</strong>: Root cause resolution<br />
6. <strong>Postmortem</strong>: Blameless anÃ¡lisis</p>
<p><strong>Para ML especÃ­fico</strong>: Rollback = deploy versiÃ³n anterior del modelo.</p>
<h2>Pregunta 112: Cross-functional Collaboration</h2>
<p><strong>Â¿CÃ³mo trabajas con Data Scientists vs ML Engineers?</strong></p>
<h3>Respuesta:</h3>
<table>
<thead>
<tr>
<th>Rol</th>
<th>Responsabilidad</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Data Scientist</strong></td>
<td>ExploraciÃ³n, feature engineering, model selection</td>
</tr>
<tr>
<td><strong>ML Engineer</strong></td>
<td>Productionization, CI/CD, monitoring</td>
</tr>
<tr>
<td><strong>Overlap</strong></td>
<td>EvaluaciÃ³n, experiments</td>
</tr>
</tbody>
</table>
<p><strong>Handoff</strong>: DS entrega notebook + requirements, MLE convierte a pipeline.</p>
<h2>Pregunta 113: Prioritization Framework</h2>
<p><strong>Â¿CÃ³mo priorizas features de ML?</strong></p>
<h3>Respuesta:</h3>
<p><strong>RICE Score</strong>:<br />
- <strong>R</strong>each: Â¿CuÃ¡ntos usuarios afecta?<br />
- <strong>I</strong>mpact: Â¿CuÃ¡nto mejora mÃ©tricas?<br />
- <strong>C</strong>onfidence: Â¿QuÃ© tan seguros estamos?<br />
- <strong>E</strong>ffort: Â¿CuÃ¡nto trabajo requiere?</p>
<p><strong>Score = (R Ã— I Ã— C) / E</strong></p>
<h2>Pregunta 114: Remote Team Leadership</h2>
<p><strong>Â¿CÃ³mo lideras equipos remotos?</strong></p>
<h3>Respuesta:</h3>
<ol>
<li><strong>Async by default</strong>: DocumentaciÃ³n &gt; meetings</li>
<li><strong>Overlap hours</strong>: 2-3 horas para sync</li>
<li><strong>Clear ownership</strong>: Cada task tiene responsable</li>
<li><strong>Over-communication</strong>: Status updates frecuentes</li>
<li><strong>Trust + accountability</strong>: Medir outcomes, no horas</li>
</ol>
<h2>Pregunta 115: Career Growth Path</h2>
<p><strong>Â¿CÃ³mo defines el growth path para ML Engineers?</strong></p>
<h3>Respuesta:</h3>
<pre><code>Junior ML Engineer
  â†“ (1-2 aÃ±os)
ML Engineer
  â†“ (2-3 aÃ±os)
Senior ML Engineer
  â†“ (2-4 aÃ±os)
  â”œâ”€â†’ Staff ML Engineer (IC track)
  â””â”€â†’ ML Engineering Manager (Management track)
</code></pre>
<p><strong>Skills por nivel</strong>:<br />
- <strong>Junior</strong>: Implementar pipelines existentes<br />
- <strong>Mid</strong>: DiseÃ±ar nuevos pipelines<br />
- <strong>Senior</strong>: Arquitectura end-to-end, mentoring<br />
- <strong>Staff</strong>: Cross-team influence, technical vision</p>
<h1>ğŸ“š Resumen y Recursos</h1>
<h2>Skills Demostrados en Este Portafolio</h2>
<table>
<thead>
<tr>
<th>Ãrea</th>
<th>Evidencia</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ML Fundamentals</strong></td>
<td>3 proyectos: clasificaciÃ³n, regresiÃ³n, ensemble</td>
</tr>
<tr>
<td><strong>MLOps</strong></td>
<td>MLflow, DVC, CI/CD, monitoring</td>
</tr>
<tr>
<td><strong>Software Engineering</strong></td>
<td>Pydantic, tests, modular design</td>
</tr>
<tr>
<td><strong>DevOps</strong></td>
<td>Docker, K8s, Terraform</td>
</tr>
<tr>
<td><strong>Leadership</strong></td>
<td>Documentation, decisions, trade-offs</td>
</tr>
</tbody>
</table>
<h2>PreparaciÃ³n Adicional Recomendada</h2>
<ol>
<li><strong>System Design</strong>: DiseÃ±ar ML system de principio a fin</li>
<li><strong>Coding Interview</strong>: LeetCode medium (estructuras de datos)</li>
<li><strong>Behavioral</strong>: STAR method para experiencias pasadas</li>
<li><strong>Deep Dive</strong>: Estar listo para explicar CUALQUIER lÃ­nea de cÃ³digo</li>
</ol>
<p><strong>Fin del Simulacro de Entrevista</strong></p>
<p><em>Generado basado en anÃ¡lisis exhaustivo del portafolio ML-MLOps</em></p>
            </div>
        
            <!-- MÃ“DULO: 21_GLOSARIO.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_21_GLOSARIO" class="cover-title">GLOSARIO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 21: GLOSARIO COMPLETO MLOps</h1>
<h1>Diccionario Exhaustivo de A-Z con Explicaciones Profundas, AnalogÃ­as y Ejemplos</h1>
<h1>GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Diciembre 2025</h1>
<h1>ğŸ“– MÃ“DULO 21: Glosario Completo MLOps</h1>
<p><strong>Diccionario Exhaustivo con Explicaciones Profundas, AnalogÃ­as y Ejemplos del Portafolio</strong></p>
<p><em>"Dominar el vocabulario tÃ©cnico es el primer paso para comunicarte como Senior."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Nivel</th>
<th style="text-align: center;">DuraciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ“š Referencia</td>
<td style="text-align: center;">Consulta continua</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š IntroducciÃ³n</h2>
<p>Este glosario define <strong>todos</strong> los tÃ©rminos tÃ©cnicos utilizados en la GuÃ­a MLOps v5.0 y en los proyectos del portafolio (BankChurn, CarVision, TelecomAI). Cada tÃ©rmino incluye:</p>
<ul>
<li><strong>DefiniciÃ³n tÃ©cnica</strong> precisa y completa</li>
<li><strong>ExplicaciÃ³n conceptual</strong> para entender el "por quÃ©"</li>
<li><strong>AnalogÃ­a desarrollada</strong> para facilitar comprensiÃ³n intuitiva</li>
<li><strong>Ejemplo del portafolio</strong> cuando aplica</li>
<li><strong>TÃ©rminos relacionados</strong> para profundizar</li>
</ul>
<h3>CÃ³mo usar este glosario</h3>
<ol>
<li><strong>Primera lectura</strong>: Lee las analogÃ­as para captar la intuiciÃ³n</li>
<li><strong>ProfundizaciÃ³n</strong>: Lee la explicaciÃ³n conceptual completa</li>
<li><strong>AplicaciÃ³n</strong>: Revisa los ejemplos del portafolio</li>
<li><strong>ConexiÃ³n</strong>: Explora los tÃ©rminos relacionados</li>
</ol>
<h2>A</h2>
<h3>Accuracy (Exactitud)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> MÃ©trica de clasificaciÃ³n que mide el porcentaje de predicciones correctas sobre el total. Se calcula como <code>(TP + TN) / (TP + TN + FP + FN)</code> donde TP=True Positives, TN=True Negatives, FP=False Positives, FN=False Negatives.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Accuracy responde a la pregunta "Â¿quÃ© porcentaje de mis predicciones fueron correctas?". Es intuitiva pero <strong>peligrosamente engaÃ±osa</strong> con clases desbalanceadas. Si el 95% de tus clientes NO abandonan (no-churn), un modelo que siempre predice "no-churn" tiene 95% accuracy pero es completamente inÃºtil para detectar churners.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un arquero que dispara 100 flechas a un blanco. Si 85 dan en el blanco, su accuracy es 85%. Pero si el blanco ocupa el 95% del muro, incluso disparando con los ojos cerrados acertarÃ­as 95%. Por eso en ML usamos mÃ©tricas adicionales (Precision, Recall) que nos dicen <em>quÃ© tan bien</em> acertamos a cada zona especÃ­fica.</p>
<p><strong>En el portafolio:</strong> BankChurn tiene ~20% de churners. Un modelo "dummy" que siempre predice "no-churn" tendrÃ­a 80% accuracy. Por eso usamos ROC-AUC (86%) y Recall como mÃ©tricas principales.</p>
<p><strong>Relacionados:</strong> Precision, Recall, F1 Score, ROC-AUC, Class Imbalance</p>
<h3>ADR (Architecture Decision Record)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Documento estructurado que registra una decisiÃ³n de arquitectura significativa junto con su contexto, las alternativas consideradas, la decisiÃ³n tomada y sus consecuencias (positivas y negativas).</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> En proyectos de software, tomamos cientos de decisiones tÃ©cnicas. Meses despuÃ©s, nadie recuerda <em>por quÃ©</em> se eligiÃ³ PostgreSQL en vez de MongoDB, o por quÃ© el modelo usa RandomForest y no XGBoost. Los ADRs resuelven esto: son la "memoria institucional" del proyecto. Siguen un formato estÃ¡ndar (Estado, Contexto, DecisiÃ³n, Consecuencias) que facilita la lectura y bÃºsqueda.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Piensa en un ADR como el acta de una reuniÃ³n de arquitectos. AÃ±os despuÃ©s de construir un edificio, si alguien pregunta "Â¿por quÃ© las vigas son de acero y no de madera?", el acta explica: "En 2020, consideramos madera (mÃ¡s barata) y acero (mÃ¡s resistente). Elegimos acero porque el edificio estÃ¡ en zona sÃ­smica. Consecuencia: costo 20% mayor pero certificaciÃ³n antisÃ­smica garantizada."</p>
<p><strong>Ejemplo del portafolio:</strong></p>
<pre><code class="language-markdown"># ADR-001: Uso de RandomForest sobre XGBoost

## Estado: Aceptado

## Contexto
Necesitamos un modelo de clasificaciÃ³n para churn que sea interpretable 
para el equipo de negocio y robusto sin tuning extensivo.

## DecisiÃ³n
Usamos RandomForestClassifier con class_weight='balanced'.

## Consecuencias
+ Feature importances nativas (explicabilidad)
+ Robusto sin hiperparÃ¡metro tuning complejo
- Puede perder 1-2% AUC vs XGBoost optimizado
</code></pre>
<p><strong>Relacionados:</strong> ML Canvas, C4 Model, DocumentaciÃ³n, DECISIONES_TECH.md</p>
<h3>API (Application Programming Interface)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Contrato que define cÃ³mo dos sistemas de software se comunican. Especifica los endpoints disponibles, los formatos de entrada/salida, los mÃ©todos HTTP soportados y los cÃ³digos de respuesta. En MLOps, las APIs REST son el mecanismo principal para exponer modelos ML como servicios consumibles.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Un modelo ML entrenado es solo un archivo (.pkl, .joblib). Para que sea Ãºtil, otros sistemas deben poder enviarle datos y recibir predicciones. Una API actÃºa como la "ventana al mundo" del modelo: recibe requests HTTP con datos del cliente, los valida, los pasa al modelo, y devuelve la predicciÃ³n en formato estructurado (JSON). Esto desacopla el modelo de los consumidores: la app mÃ³vil, el dashboard, el sistema de CRM pueden todos usar la misma API sin conocer los detalles internos del modelo.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Una API es como el mesero de un restaurante. TÃº (el cliente) no entras a la cocina a preparar tu comida (no cargas el modelo en tu cÃ³digo). En su lugar, le dices al mesero quÃ© quieres (envÃ­as un request), Ã©l lleva el pedido a la cocina (la API invoca al modelo), y te trae el plato preparado (la API devuelve la predicciÃ³n). El menÃº es la documentaciÃ³n de la API: te dice quÃ© puedes pedir y cÃ³mo.</p>
<p><strong>Ejemplo del portafolio (BankChurn FastAPI):</strong></p>
<pre><code class="language-python">from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

class PredictionRequest(BaseModel):
    CreditScore: int = Field(..., ge=300, le=850)
    Age: int = Field(..., ge=18, le=100)
    Balance: float = Field(..., ge=0)
    # ... mÃ¡s features

class PredictionResponse(BaseModel):
    prediction: int
    probability: float
    risk_level: str

@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    df = pd.DataFrame([request.model_dump()])
    proba = model.predict_proba(df)[0, 1]
    return PredictionResponse(
        prediction=int(proba &gt; 0.5),
        probability=proba,
        risk_level=&quot;high&quot; if proba &gt; 0.7 else &quot;medium&quot; if proba &gt; 0.3 else &quot;low&quot;
    )
</code></pre>
<p><strong>Relacionados:</strong> REST, FastAPI, Endpoint, HTTP, Pydantic, OpenAPI/Swagger</p>
<h3>Artefacto (Artifact)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Cualquier archivo generado durante el ciclo de vida de ML que necesita ser versionado, almacenado y potencialmente reproducido. Incluye: modelos serializados (.pkl, .joblib, .onnx), datasets procesados, grÃ¡ficos de evaluaciÃ³n, reportes de mÃ©tricas, logs de entrenamiento, y configuraciones.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Un proyecto ML no es solo cÃ³digoâ€”genera "productos intermedios" en cada etapa. El dataset limpio es un artefacto. El modelo entrenado es un artefacto. El reporte de mÃ©tricas es un artefacto. La gestiÃ³n profesional de artefactos permite: (1) reproducibilidadâ€”volver a cualquier versiÃ³n anterior, (2) trazabilidadâ€”saber quÃ© datos y cÃ³digo produjeron quÃ© modelo, (3) colaboraciÃ³nâ€”compartir resultados entre equipos.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Piensa en una fÃ¡brica de autos. Los planos son artefactos (cÃ³digo). Las piezas moldeadas son artefactos (datasets procesados). El motor ensamblado es un artefacto (modelo entrenado). El auto terminado es un artefacto (pipeline completo). Cada pieza tiene un nÃºmero de serie y registro de quÃ© mÃ¡quina la produjo, cuÃ¡ndo, con quÃ© materiales. Si un auto tiene un defecto, puedes rastrear hacia atrÃ¡s hasta encontrar la pieza defectuosa y quÃ© lote de materiales causÃ³ el problema.</p>
<p><strong>Ejemplo del portafolio:</strong></p>
<pre><code>artifacts/
â”œâ”€â”€ model.joblib          # Modelo serializado (pipeline completo)
â”œâ”€â”€ metrics.json          # {&quot;roc_auc&quot;: 0.86, &quot;recall&quot;: 0.75}
â”œâ”€â”€ feature_importance.png # GrÃ¡fico de importancia
â””â”€â”€ training_config.yaml  # ConfiguraciÃ³n usada
</code></pre>
<p><strong>Relacionados:</strong> MLflow, Model Registry, DVC, Reproducibilidad</p>
<h3>ASGI (Asynchronous Server Gateway Interface)</h3>
<p><strong>DefiniciÃ³n:</strong> EspecificaciÃ³n para servidores web async en Python. Maneja mÃºltiples requests concurrentemente.</p>
<p><strong>AnalogÃ­a:</strong> Mesero que anota pedido mesa 1, mientras espera va a mesa 2, etc. Maneja conversaciones "en paralelo".</p>
<p><strong>Relacionados:</strong> Uvicorn, FastAPI, Async/Await</p>
<h3>AUC-ROC</h3>
<p><strong>DefiniciÃ³n:</strong> Ãrea bajo curva ROC. Mide capacidad de distinguir clases. 1.0 = perfecto, 0.5 = aleatorio.</p>
<p><strong>AnalogÃ­a:</strong> Separando manzanas buenas de malas. AUC 0.9 = 90% de las veces asigna mayor score a la manzana buena.</p>
<p><strong>Relacionados:</strong> ROC Curve, Precision, Recall, Threshold</p>
<h3>Auto-scaling</h3>
<p><strong>DefiniciÃ³n:</strong> Sistema que aumenta/disminuye recursos automÃ¡ticamente segÃºn demanda.</p>
<p><strong>AnalogÃ­a:</strong> Restaurante contratando meseros temporales cuando hay mucha gente.</p>
<p><strong>Relacionados:</strong> HPA, Kubernetes, Load Balancer</p>
<h2>B</h2>
<h3>Backpropagation</h3>
<p><strong>DefiniciÃ³n:</strong> Algoritmo de entrenamiento de redes neuronales que propaga el error hacia atrÃ¡s calculando gradientes.</p>
<p><strong>AnalogÃ­a:</strong> Equipo de relevos donde analizas hacia atrÃ¡s quiÃ©n contribuyÃ³ al fallo.</p>
<p><strong>Relacionados:</strong> Gradient Descent, Learning Rate, Neural Network</p>
<h3>Baseline</h3>
<p><strong>DefiniciÃ³n:</strong> Modelo simple como referencia. Si tu modelo complejo no lo supera, algo estÃ¡ mal.</p>
<p><strong>AnalogÃ­a:</strong> Antes de comprar auto deportivo, verifica que sea mÃ¡s rÃ¡pido que tu bicicleta.</p>
<p><strong>Relacionados:</strong> Benchmark, Model Evaluation</p>
<h3>BaseEstimator</h3>
<p><strong>DefiniciÃ³n:</strong> Clase base sklearn con <code>get_params()</code> y <code>set_params()</code>. Todos los estimadores heredan de ella.</p>
<p><strong>AnalogÃ­a:</strong> Contrato estÃ¡ndar que todos los constructores deben seguir para que el sistema funcione.</p>
<p><strong>Relacionados:</strong> TransformerMixin, Custom Transformer, Pipeline</p>
<h3>Batch Prediction</h3>
<p><strong>DefiniciÃ³n:</strong> Procesar mÃºltiples muestras a la vez, programadamente. Contrasta con online/real-time.</p>
<p><strong>AnalogÃ­a:</strong> Catering (cocinas todo de antemano) vs restaurante a la carta (cocinas cada plato al pedirlo).</p>
<p><strong>Relacionados:</strong> Online Prediction, Latencia</p>
<h3>Black</h3>
<p><strong>DefiniciÃ³n:</strong> Formateador Python opinionado. Aplica estilo consistente automÃ¡ticamente.</p>
<p><strong>AnalogÃ­a:</strong> Corrector que arregla gramÃ¡tica y estilo sin preguntarte.</p>
<pre><code class="language-bash">black src/
</code></pre>
<p><strong>Relacionados:</strong> Linting, Flake8, isort</p>
<h3>Branch (Rama)</h3>
<p><strong>DefiniciÃ³n:</strong> LÃ­nea de desarrollo paralela en Git.</p>
<p><strong>AnalogÃ­a:</strong> Fotocopia del manuscrito para probar final alternativo sin afectar original.</p>
<pre><code class="language-bash">git checkout -b feature/add-mlflow
</code></pre>
<p><strong>Relacionados:</strong> Git, Merge, Pull Request</p>
<h2>C</h2>
<h3>C4 Model</h3>
<p><strong>DefiniciÃ³n:</strong> VisualizaciÃ³n de arquitectura en 4 niveles: Context, Container, Component, Code.</p>
<p><strong>AnalogÃ­a:</strong> Google Maps con zoom. Mundo â†’ PaÃ­s â†’ Ciudad â†’ Calle.</p>
<p><strong>Relacionados:</strong> ADR, Arquitectura</p>
<h3>CI/CD</h3>
<p><strong>DefiniciÃ³n:</strong> Continuous Integration (tests automÃ¡ticos) + Continuous Deployment (deploy automÃ¡tico).</p>
<p><strong>AnalogÃ­a:</strong> FÃ¡brica con control de calidad automatizado que envÃ­a autos aprobados al concesionario.</p>
<p><strong>Relacionados:</strong> GitHub Actions, Pipeline, DevOps</p>
<h3>Classification</h3>
<p><strong>DefiniciÃ³n:</strong> Problema ML supervisado para predecir categorÃ­as discretas.</p>
<p><strong>AnalogÃ­a:</strong> Doctor diagnosticando enfermedades (multiclase) o decidiendo operar/no operar (binaria).</p>
<p><strong>Relacionados:</strong> Regression, Supervised Learning</p>
<h3>Class Imbalance (Desbalance de Clases)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> SituaciÃ³n donde una o mÃ¡s clases estÃ¡n significativamente subrepresentadas en el dataset de entrenamiento. Ratios como 95:5, 99:1 o peores son comunes en problemas reales (fraude, churn, enfermedades raras).</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Los algoritmos de ML optimizan mÃ©tricas globales. Si el 95% de tus datos son "no-fraude", el modelo aprende que la estrategia mÃ¡s "segura" es predecir siempre "no-fraude"â€”obtiene 95% accuracy haciendo nada Ãºtil. El desbalance es quizÃ¡s el problema mÃ¡s comÃºn y subestimado en ML aplicado. Afecta tanto al entrenamiento (el modelo no ve suficientes ejemplos de la clase minoritaria) como a la evaluaciÃ³n (accuracy es engaÃ±osa).</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina entrenar un perro buscador de trufas dÃ¡ndole 1000 piedras y solo 10 trufas. El perro aprende rÃ¡pidamente que decir "piedra" le da premio el 99% de las veces. Nunca aprende realmente a oler trufas. Para entrenarlo bien, necesitas: (1) darle mÃ¡s trufas (oversampling), (2) penalizarlo mÃ¡s cuando falla una trufa (class weights), o (3) medir su Ã©xito por trufas encontradas, no por piedras correctamente ignoradas (mÃ©tricas apropiadas).</p>
<p><strong>Soluciones tÃ©cnicas:</strong></p>
<pre><code class="language-python"># 1. Class weights (penaliza mÃ¡s errores en clase minoritaria)
RandomForestClassifier(class_weight='balanced')

# 2. SMOTE (genera ejemplos sintÃ©ticos de clase minoritaria)
from imblearn.over_sampling import SMOTE
X_resampled, y_resampled = SMOTE().fit_resample(X, y)

# 3. Threshold adjustment (bajar umbral de decisiÃ³n)
proba = model.predict_proba(X)[:, 1]
predictions = (proba &gt; 0.3).astype(int)  # En vez de 0.5

# 4. MÃ©tricas apropiadas
from sklearn.metrics import recall_score, roc_auc_score
# NO usar accuracy como mÃ©trica principal
</code></pre>
<p><strong>En el portafolio:</strong> BankChurn tiene ~20% churners. Usamos <code>class_weight='balanced'</code> y priorizamos Recall sobre Accuracy.</p>
<p><strong>Relacionados:</strong> class_weight, SMOTE, Recall, Precision, ROC-AUC, Threshold</p>
<h3>class_weight</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> ParÃ¡metro de sklearn que asigna pesos diferentes a las clases durante el entrenamiento. Con <code>class_weight='balanced'</code>, los pesos se calculan automÃ¡ticamente como inversamente proporcionales a la frecuencia de cada clase.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Es la forma mÃ¡s simple de manejar desbalance. En lugar de modificar los datos (oversampling/undersampling), modificamos cÃ³mo el modelo "valora" los errores. Un error en la clase minoritaria "cuenta mÃ¡s" que un error en la clase mayoritaria. MatemÃ¡ticamente, es como si tuviÃ©ramos mÃ¡s ejemplos de la clase minoritaria sin realmente duplicarlos.</p>
<p><strong>FÃ³rmula:</strong> <code>weight[i] = n_samples / (n_classes * n_samples_i)</code></p>
<p><strong>Ejemplo del portafolio:</strong></p>
<pre><code class="language-python"># BankChurn: 80% no-churn, 20% churn
# Sin class_weight: modelo ignora churners
# Con class_weight='balanced': churners valen 4x mÃ¡s

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=100,
    class_weight='balanced',  # CrÃ­tico para churn
    random_state=42
)
</code></pre>
<p><strong>Relacionados:</strong> Class Imbalance, SMOTE, RandomForest</p>
<h3>Cold Start</h3>
<p><strong>DefiniciÃ³n:</strong> Tiempo para que servicio estÃ© listo tras iniciarse. Incluye cargar modelo en memoria.</p>
<p><strong>AnalogÃ­a:</strong> Encender auto en invierno. Debes esperar que el motor se caliente.</p>
<p><strong>Relacionados:</strong> Serverless, Lambda, Latencia</p>
<h3>ColumnTransformer</h3>
<p><strong>DefiniciÃ³n:</strong> Sklearn: aplica diferentes transformaciones a diferentes columnas.</p>
<p><strong>AnalogÃ­a:</strong> LavanderÃ­a con mÃ¡quinas diferentes: colorâ†’encoder, blancaâ†’scaler, delicadosâ†’passthrough.</p>
<pre><code class="language-python">preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(), cat_cols),
])
</code></pre>
<p><strong>Relacionados:</strong> Pipeline, Transformer</p>
<h3>Commit</h3>
<p><strong>DefiniciÃ³n:</strong> Snapshot de cambios en Git con hash Ãºnico y mensaje.</p>
<p><strong>AnalogÃ­a:</strong> Foto de tu escritorio. Puedes volver a cualquier foto anterior.</p>
<pre><code class="language-bash">git commit -m &quot;feat: add probability calibration&quot;
</code></pre>
<p><strong>Relacionados:</strong> Git, Branch, Push, Conventional Commits</p>
<h3>conftest.py</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Archivo especial de pytest que contiene fixtures (funciones que proveen datos/recursos) compartidas entre todos los tests del directorio y subdirectorios. pytest lo descubre automÃ¡ticamente sin necesidad de imports.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Los tests necesitan datos de prueba, conexiones a bases de datos mock, modelos pre-entrenados, etc. Sin conftest.py, cada archivo de tests tendrÃ­a que definir o importar estos recursos. conftest.py centraliza esta lÃ³gica: defines las fixtures una vez, y estÃ¡n disponibles automÃ¡ticamente en todos los tests. Es el "almacÃ©n central de recursos de testing".</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un set de filmaciÃ³n. Antes de cada escena, alguien prepara el escenario: pone las luces, coloca los props, prepara el vestuario. conftest.py es ese equipo de preparaciÃ³n. Los actores (tests) llegan y todo estÃ¡ listo. No tienen que traer sus propios propsâ€”solo los piden por nombre y aparecen.</p>
<p><strong>Ejemplo del portafolio (CarVision):</strong></p>
<pre><code class="language-python"># tests/conftest.py
import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_data():
    &quot;&quot;&quot;Datos sintÃ©ticos para tests.&quot;&quot;&quot;
    np.random.seed(42)
    return pd.DataFrame({
        'year': np.random.randint(2010, 2023, 100),
        'mileage': np.random.randint(10000, 150000, 100),
        'price': np.random.uniform(5000, 50000, 100),
    })

@pytest.fixture
def trained_pipeline(sample_data):
    &quot;&quot;&quot;Pipeline entrenado para tests de inferencia.&quot;&quot;&quot;
    from carvision.pipeline import build_pipeline
    pipe = build_pipeline()
    X = sample_data.drop('price', axis=1)
    y = sample_data['price']
    return pipe.fit(X, y)

@pytest.fixture
def config():
    &quot;&quot;&quot;ConfiguraciÃ³n de test.&quot;&quot;&quot;
    return {'model': {'n_estimators': 10}, 'random_state': 42}
</code></pre>
<p><strong>Relacionados:</strong> pytest, Fixture, Unit Test, Integration Test</p>
<h3>Conventional Commits</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> EspecificaciÃ³n para escribir mensajes de commit estandarizados. Formato: <code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;</code>. Types incluyen: feat, fix, docs, style, refactor, test, chore.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Los mensajes de commit son la historia del proyecto. "fixed bug" o "updates" no dicen nada Ãºtil. Conventional Commits impone estructura: el tipo indica quÃ© cambiÃ³ (feature nueva, bug fix, documentaciÃ³n), el scope indica dÃ³nde (api, pipeline, tests), la descripciÃ³n explica quÃ©. Esto permite: (1) generar CHANGELOGs automÃ¡ticamente, (2) determinar versiones semÃ¡nticas, (3) entender la historia del proyecto rÃ¡pidamente.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un libro de bitÃ¡cora de un barco. "Navegamos" no ayuda. "2024-01-15 14:00 - Cambio de rumbo: de Norte a Noroeste para evitar tormenta detectada a 50km" es Ãºtil. Conventional Commits son esa bitÃ¡cora estructurada para cÃ³digo.</p>
<p><strong>Ejemplos del portafolio:</strong></p>
<pre><code class="language-bash"># Formato: &lt;type&gt;(&lt;scope&gt;): &lt;description&gt;

feat(api): add batch prediction endpoint
fix(pipeline): handle NaN values in categorical columns
docs(readme): add quick start guide and badges
test(training): add integration tests for cross-validation
refactor(features): extract FeatureEngineer to separate module
chore(deps): update scikit-learn to 1.3.0
</code></pre>
<p><strong>Relacionados:</strong> Git, pre-commit, Semantic Versioning</p>
<h3>Concept Drift</h3>
<p><strong>DefiniciÃ³n:</strong> Cambio en relaciÃ³n features-target. Patrones aprendidos ya no son vÃ¡lidos.</p>
<p><strong>AnalogÃ­a:</strong> Modelo entrenado pre-pandemia predice gustos de pelÃ­culas post-pandemia incorrectamente.</p>
<p><strong>vs Data Drift:</strong> Data Drift = cambia X. Concept Drift = cambia P(Y|X).</p>
<h3>ConfigMap</h3>
<p><strong>DefiniciÃ³n:</strong> Kubernetes: almacena configuraciÃ³n no sensible como pares clave-valor.</p>
<p><strong>AnalogÃ­a:</strong> TablÃ³n de anuncios de oficina. InformaciÃ³n pÃºblica que todos necesitan.</p>
<h3>Container (Contenedor)</h3>
<p><strong>DefiniciÃ³n:</strong> Software empaquetado con cÃ³digo y dependencias. Ejecuta igual en cualquier ambiente.</p>
<p><strong>AnalogÃ­a:</strong> Contenedor de barco. Funciona igual en cualquier puerto.</p>
<p><strong>Relacionados:</strong> Docker, Image, Kubernetes</p>
<h3>Coverage</h3>
<p><strong>DefiniciÃ³n:</strong> Porcentaje de cÃ³digo ejecutado por tests. No garantiza correcciÃ³n.</p>
<p><strong>AnalogÃ­a:</strong> Inspector que revisÃ³ 80% de habitaciones. No significa que encontrÃ³ todos los problemas.</p>
<pre><code class="language-bash">pytest --cov=src
</code></pre>
<p><strong>Target:</strong> &gt;80% para cÃ³digo crÃ­tico</p>
<h3>Cross-Validation</h3>
<p><strong>DefiniciÃ³n:</strong> Evaluar modelo dividiendo datos en K folds. Entrena K veces con diferentes splits.</p>
<p><strong>AnalogÃ­a:</strong> 5 estudiantes, 5 rondas. En cada ronda, diferente estudiante es evaluado.</p>
<pre><code class="language-python">scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')
</code></pre>
<p><strong>Relacionados:</strong> K-Fold, Overfitting</p>
<h3>Custom Transformer</h3>
<p><strong>DefiniciÃ³n:</strong> Clase sklearn personalizada que hereda BaseEstimator + TransformerMixin.</p>
<p><strong>AnalogÃ­a:</strong> Pieza LEGO personalizada con conexiones estÃ¡ndar (fit/transform).</p>
<pre><code class="language-python">class RatioFeatures(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): return self
    def transform(self, X):
        X['ratio'] = X['Balance'] / (X['Products'] + 1)
        return X
</code></pre>
<h2>D</h2>
<h3>DAG (Directed Acyclic Graph)</h3>
<p><strong>DefiniciÃ³n:</strong> Grafo dirigido sin ciclos. Representa dependencias entre tareas.</p>
<p><strong>AnalogÃ­a:</strong> Instrucciones de receta. No puedes hornear antes de mezclar.</p>
<p><strong>Relacionados:</strong> DVC, Pipeline, Airflow</p>
<h3>Data Drift</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Cambio en la distribuciÃ³n estadÃ­stica de las features (P(X)) entre el momento del entrenamiento y la inferencia en producciÃ³n. No implica necesariamente que la relaciÃ³n feature-target haya cambiado, solo que los datos de entrada son diferentes.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Tu modelo fue entrenado con datos de 2023. Llega 2025 y los patrones de los clientes han cambiado: son mÃ¡s jÃ³venes, usan mÃ¡s canales digitales, tienen balances diferentes. Aunque la "lÃ³gica" de quÃ© causa churn no haya cambiado, tu modelo recibe inputs que nunca vio y puede fallar. Data drift es como un mÃ©dico entrenado solo con pacientes adultos intentando diagnosticar niÃ±osâ€”la anatomÃ­a es diferente aunque las enfermedades sean las mismas.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un modelo que predice si lloverÃ¡ basÃ¡ndose en la presiÃ³n atmosfÃ©rica. Fue entrenado en Madrid. Lo despliegas en Ciudad de MÃ©xico (altitud muy diferente). La presiÃ³n "normal" en CDMX es mucho menor que en Madrid. El modelo ve presiones que interpreta como "muy baja" y siempre predice lluvia. No es que el modelo estÃ© rotoâ€”es que los datos de entrada son muy diferentes a los de entrenamiento.</p>
<p><strong>Tipos de drift:</strong><br />
- <strong>Covariate shift</strong>: Cambia P(X), pero P(Y|X) permanece igual<br />
- <strong>Prior probability shift</strong>: Cambia P(Y), la proporciÃ³n de clases<br />
- <strong>Concept drift</strong>: Cambia P(Y|X), la relaciÃ³n misma</p>
<p><strong>DetecciÃ³n tÃ©cnica:</strong></p>
<pre><code class="language-python"># Kolmogorov-Smirnov test para cada feature
from scipy.stats import ks_2samp

for col in features:
    stat, pvalue = ks_2samp(train_data[col], prod_data[col])
    if pvalue &lt; 0.05:
        print(f&quot;Drift detectado en {col}: KS={stat:.3f}, p={pvalue:.4f}&quot;)

# Population Stability Index (PSI)
# PSI &lt; 0.1: No drift
# PSI 0.1-0.2: Drift moderado
# PSI &gt; 0.2: Drift significativo
</code></pre>
<p><strong>Herramientas:</strong> Evidently, NannyML, Great Expectations</p>
<p><strong>Relacionados:</strong> Concept Drift, Model Monitoring, Evidently, Retraining</p>
<h3>Data Leakage</h3>
<p><strong>DefiniciÃ³n:</strong> InformaciÃ³n del futuro o test filtra al entrenamiento. MÃ©tricas infladas.</p>
<p><strong>AnalogÃ­a:</strong> Estudiar con las respuestas del mismo examen. 100% en prÃ¡ctica, 0% en real.</p>
<p><strong>Ejemplos:</strong> <code>price_per_mile = price / miles</code>, normalizar antes de split.</p>
<h3>Dependency Injection</h3>
<p><strong>DefiniciÃ³n:</strong> Dependencias se pasan desde afuera en lugar de crearse internamente.</p>
<p><strong>AnalogÃ­a:</strong> CafeterÃ­a recibe leche de proveedor en vez de tener vacas propias.</p>
<pre><code class="language-python"># Con DI: fÃ¡cil de testear
class Predictor:
    def __init__(self, model: BaseEstimator):
        self.model = model  # Inyectado
</code></pre>
<p><strong>Relacionados:</strong> SOLID, Testing</p>
<h3>Deployment</h3>
<p><strong>DefiniciÃ³n:</strong> Poner modelo/aplicaciÃ³n en ambiente donde usuarios reales lo usan.</p>
<p><strong>AnalogÃ­a:</strong> Abrir restaurante al pÃºblico despuÃ©s de cocinar en casa y probar con amigos.</p>
<p><strong>Tipos:</strong> Batch, REST API, Edge, Streaming</p>
<h3>Docker</h3>
<p><strong>DefiniciÃ³n:</strong> Plataforma para aplicaciones en contenedores. CÃ³digo + dependencias portables.</p>
<p><strong>AnalogÃ­a:</strong> MÃ¡quina del tiempo para cÃ³digo. Congelas ambiente exacto.</p>
<pre><code class="language-dockerfile">FROM python:3.11-slim
COPY . /app
RUN pip install -r requirements.txt
CMD [&quot;uvicorn&quot;, &quot;app:app&quot;]
</code></pre>
<h3>Docstring</h3>
<p><strong>DefiniciÃ³n:</strong> String de documentaciÃ³n al inicio de funciones/clases.</p>
<p><strong>AnalogÃ­a:</strong> Instrucciones en la caja de un producto.</p>
<pre><code class="language-python">def predict(data: pd.DataFrame) -&gt; np.ndarray:
    &quot;&quot;&quot;
    Genera predicciones de churn.

    Args:
        data: DataFrame con features.
    Returns:
        Array de probabilidades 0-1.
    &quot;&quot;&quot;
</code></pre>
<h3>DVC (Data Version Control)</h3>
<p><strong>DefiniciÃ³n:</strong> Versiona datasets y pipelines ML. Datos grandes en storage remoto, metadatos en Git.</p>
<p><strong>AnalogÃ­a:</strong> Git = Ã¡lbum con miniaturas. DVC = almacÃ©n con fotos originales grandes.</p>
<pre><code class="language-bash">dvc add data/dataset.csv
dvc push
git add data/dataset.csv.dvc
</code></pre>
<h2>E</h2>
<h3>E2E Test</h3>
<p><strong>DefiniciÃ³n:</strong> Test del sistema completo, desde entrada hasta salida final.</p>
<p><strong>AnalogÃ­a:</strong> Test drive de auto completo, no motor aislado.</p>
<h3>Early Stopping</h3>
<p><strong>DefiniciÃ³n:</strong> Detiene entrenamiento cuando validaciÃ³n deja de mejorar. Evita overfitting.</p>
<p><strong>AnalogÃ­a:</strong> Sacar galletas del horno cuando estÃ¡n doradas, antes de que se quemen.</p>
<pre><code class="language-python">EarlyStopping(monitor='val_loss', patience=5)
</code></pre>
<h3>Embedding</h3>
<p><strong>DefiniciÃ³n:</strong> RepresentaciÃ³n vectorial densa de datos de alta dimensionalidad.</p>
<p><strong>AnalogÃ­a:</strong> Mapear ciudades del mundo en papel 2D. Similares quedan cerca.</p>
<p><strong>Uso:</strong> Word2Vec, Entity embeddings</p>
<h3>Endpoint</h3>
<p><strong>DefiniciÃ³n:</strong> URL especÃ­fica de API que realiza operaciÃ³n particular.</p>
<p><strong>AnalogÃ­a:</strong> Ventanillas de banco. Cada una hace algo diferente.</p>
<pre><code class="language-python">@app.get(&quot;/health&quot;)
@app.post(&quot;/predict&quot;)
</code></pre>
<h3>Ensemble</h3>
<p><strong>DefiniciÃ³n:</strong> Combina mÃºltiples modelos para mejores predicciones.</p>
<p><strong>AnalogÃ­a:</strong> 100 doctores opinando en vez de 1. OpiniÃ³n agregada suele ser mejor.</p>
<p><strong>Tipos:</strong> Bagging (Random Forest), Boosting (XGBoost), Stacking</p>
<h3>Environment</h3>
<p><strong>DefiniciÃ³n:</strong> Conjunto aislado de dependencias donde ejecuta cÃ³digo.</p>
<p><strong>AnalogÃ­a:</strong> Diferentes cocinas para diferentes tipos de comida.</p>
<p><strong>Tipos:</strong> Desarrollo, Staging, ProducciÃ³n</p>
<h3>Evidently</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> LibrerÃ­a open-source de Python para monitoreo de modelos ML en producciÃ³n. Genera reportes interactivos de data drift, target drift, data quality, y performance del modelo comparando datasets de referencia con datasets actuales.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Cuando despliegas un modelo, necesitas saber si sigue funcionando bien. Evidently automatiza esta vigilancia: compara los datos que ve el modelo en producciÃ³n con los datos de entrenamiento, detecta cambios estadÃ­sticos (drift), genera alertas, y produce reportes visuales. Es como tener un "chequeo mÃ©dico" continuo para tu modelo.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina que tienes un carro. Evidently es el tablero de instrumentos que te dice si la presiÃ³n de las llantas bajÃ³, si el aceite necesita cambio, si el motor estÃ¡ sobrecalentando. No esperas a que el carro se descompongaâ€”el tablero te avisa antes de que el problema sea grave.</p>
<p><strong>Ejemplo prÃ¡ctico:</strong></p>
<pre><code class="language-python">from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, DataQualityPreset

# Comparar datos de training vs producciÃ³n
report = Report(metrics=[
    DataDriftPreset(),
    DataQualityPreset(),
])

report.run(
    reference_data=train_df,
    current_data=production_df
)

# Generar reporte HTML interactivo
report.save_html(&quot;drift_report.html&quot;)

# O extraer mÃ©tricas programÃ¡ticamente
drift_results = report.as_dict()
if drift_results['metrics'][0]['result']['dataset_drift']:
    print(&quot;âš ï¸ Drift significativo detectado!&quot;)
</code></pre>
<p><strong>Capacidades:</strong><br />
- Data Drift: Detecta cambios en distribuciones de features<br />
- Target Drift: Detecta cambios en distribuciÃ³n del target<br />
- Data Quality: Valores faltantes, outliers, correlaciones<br />
- Model Performance: Accuracy, precision, recall en producciÃ³n<br />
- Regression Performance: MAE, RMSE, error distribution</p>
<p><strong>Relacionados:</strong> Data Drift, Model Monitoring, Observabilidad, NannyML</p>
<h3>Experiment Tracking</h3>
<p><strong>DefiniciÃ³n:</strong> Registrar parÃ¡metros, mÃ©tricas, artefactos de cada experimento ML.</p>
<p><strong>AnalogÃ­a:</strong> Cuaderno de laboratorio de cientÃ­fico.</p>
<p><strong>Herramientas:</strong> MLflow, W&amp;B, Neptune</p>
<h2>F</h2>
<h3>F1 Score</h3>
<p><strong>DefiniciÃ³n:</strong> Media armÃ³nica de Precision y Recall. Balance entre ambas.</p>
<p><strong>FÃ³rmula:</strong> <code>F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)</code></p>
<p><strong>AnalogÃ­a:</strong> Buscador de trufas. No sirve encontrar pocas muy precisamente ni todas con muchas falsas.</p>
<h3>FastAPI</h3>
<p><strong>DefiniciÃ³n:</strong> Framework Python para APIs de alto rendimiento con validaciÃ³n automÃ¡tica.</p>
<p><strong>AnalogÃ­a:</strong> Mesero eficiente que valida pedidos, da menÃº descriptivo, atiende muchas mesas.</p>
<pre><code class="language-python">from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

@app.post(&quot;/predict&quot;)
async def predict(data: PredictionInput):
    return {&quot;probability&quot;: model.predict_proba([data])[0, 1]}
</code></pre>
<p><strong>Relacionados:</strong> Pydantic, Uvicorn, REST</p>
<h3>Feature</h3>
<p><strong>DefiniciÃ³n:</strong> Variable de entrada para predicciones.</p>
<p><strong>AnalogÃ­a:</strong> Ingredientes de receta. Para predecir si pastel sale bien: harina, azÃºcar, temperatura.</p>
<p><strong>Tipos:</strong> NumÃ©ricas, CategÃ³ricas, Binarias, Derivadas</p>
<h3>Feature Engineering</h3>
<p><strong>DefiniciÃ³n:</strong> Crear/transformar/seleccionar features para mejorar modelo.</p>
<p><strong>AnalogÃ­a:</strong> Chef preparando ingredientes. Ingredientes crudos se transforman en algo digerible.</p>
<pre><code class="language-python">df['balance_per_product'] = df['Balance'] / (df['NumOfProducts'] + 1)
</code></pre>
<h3>Feature Store</h3>
<p><strong>DefiniciÃ³n:</strong> Sistema centralizado para almacenar y servir features consistentemente.</p>
<p><strong>AnalogÃ­a:</strong> AlmacÃ©n central de ingredientes preparados para cadena de restaurantes.</p>
<p><strong>Herramientas:</strong> Feast, Tecton</p>
<h3>Fixture (pytest)</h3>
<p><strong>DefiniciÃ³n:</strong> FunciÃ³n que provee datos/recursos reutilizables para tests.</p>
<p><strong>AnalogÃ­a:</strong> Setup de set de filmaciÃ³n antes de cada escena.</p>
<pre><code class="language-python">@pytest.fixture
def sample_customer():
    return {&quot;Age&quot;: 35, &quot;Balance&quot;: 50000}
</code></pre>
<h3>Flake8</h3>
<p><strong>DefiniciÃ³n:</strong> Linting para Python: errores lÃ³gicos, estilo PEP8, complejidad.</p>
<p><strong>AnalogÃ­a:</strong> Corrector de estilo de periÃ³dico.</p>
<pre><code class="language-bash">flake8 src/
</code></pre>
<h2>G</h2>
<h3>Git</h3>
<p><strong>DefiniciÃ³n:</strong> Control de versiones distribuido.</p>
<p><strong>AnalogÃ­a:</strong> "Deshacer" infinito. Volver a cualquier momento, ver quÃ© cambiÃ³ y por quÃ©.</p>
<pre><code class="language-bash">git add . &amp;&amp; git commit -m &quot;mensaje&quot; &amp;&amp; git push
</code></pre>
<h3>GitHub Actions</h3>
<p><strong>DefiniciÃ³n:</strong> CI/CD integrado en GitHub.</p>
<p><strong>AnalogÃ­a:</strong> Mayordomo robot que ejecuta instrucciones automÃ¡ticamente.</p>
<pre><code class="language-yaml">on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - run: pytest tests/
</code></pre>
<h3>Gitleaks</h3>
<p><strong>DefiniciÃ³n:</strong> Detecta secrets accidentalmente commiteados.</p>
<p><strong>AnalogÃ­a:</strong> Detector de metales en aeropuerto para cÃ³digo.</p>
<h3>Gradient Descent</h3>
<p><strong>DefiniciÃ³n:</strong> Algoritmo que encuentra parÃ¡metros que minimizan pÃ©rdida.</p>
<p><strong>AnalogÃ­a:</strong> En montaÃ±a con niebla, das pasos pequeÃ±os siempre cuesta abajo.</p>
<p><strong>Relacionados:</strong> Learning Rate, Loss Function</p>
<h3>Grafana</h3>
<p><strong>DefiniciÃ³n:</strong> VisualizaciÃ³n y dashboards para mÃ©tricas.</p>
<p><strong>AnalogÃ­a:</strong> Tablero de instrumentos de aviÃ³n.</p>
<p><strong>Relacionados:</strong> Prometheus, Observabilidad</p>
<h2>H</h2>
<h3>Health Check</h3>
<p><strong>DefiniciÃ³n:</strong> Endpoint que verifica si servicio funciona.</p>
<p><strong>AnalogÃ­a:</strong> MÃ©dico preguntando "Â¿cÃ³mo te sientes?".</p>
<pre><code class="language-python">@app.get(&quot;/health&quot;)
def health():
    return {&quot;status&quot;: &quot;healthy&quot;}
</code></pre>
<h3>HPA (Horizontal Pod Autoscaler)</h3>
<p><strong>DefiniciÃ³n:</strong> Kubernetes: escala pods automÃ¡ticamente segÃºn mÃ©tricas.</p>
<p><strong>AnalogÃ­a:</strong> Gerente de restaurante que llama mÃ¡s meseros si hay muchas mesas ocupadas.</p>
<h3>Hyperparameter</h3>
<p><strong>DefiniciÃ³n:</strong> ParÃ¡metro configurado ANTES del entrenamiento.</p>
<p><strong>AnalogÃ­a:</strong> Decisiones antes de hornear: temperatura, tiempo, tamaÃ±o de molde.</p>
<p><strong>Ejemplos:</strong> n_estimators, learning_rate, max_depth</p>
<h3>Hyperparameter Tuning</h3>
<p><strong>DefiniciÃ³n:</strong> Encontrar combinaciÃ³n Ã³ptima de hiperparÃ¡metros.</p>
<p><strong>AnalogÃ­a:</strong> Afinar guitarra. Probar perillas hasta mejor sonido.</p>
<p><strong>TÃ©cnicas:</strong> Grid Search, Random Search, Bayesian Optimization</p>
<h2>I</h2>
<h3>Image (Docker)</h3>
<p><strong>DefiniciÃ³n:</strong> Template inmutable para crear contenedores.</p>
<p><strong>AnalogÃ­a:</strong> Receta + ingredientes pre-empaquetados. Imagen es el kit, contenedor es el pastel horneado.</p>
<h3>Imputer</h3>
<p><strong>DefiniciÃ³n:</strong> Rellena valores faltantes (NaN).</p>
<p><strong>AnalogÃ­a:</strong> Restaurador de pinturas rellenando huecos.</p>
<pre><code class="language-python">SimpleImputer(strategy='median')
</code></pre>
<h3>Inference</h3>
<p><strong>DefiniciÃ³n:</strong> Usar modelo entrenado para predicciones sobre datos nuevos.</p>
<p><strong>AnalogÃ­a:</strong> Entrenamiento = estudiar. Inferencia = tomar el examen.</p>
<h3>Ingress</h3>
<p><strong>DefiniciÃ³n:</strong> Kubernetes: gestiona acceso HTTP externo al cluster.</p>
<p><strong>AnalogÃ­a:</strong> RecepciÃ³n de edificio que dirige trÃ¡fico.</p>
<h3>Integration Test</h3>
<p><strong>DefiniciÃ³n:</strong> Verifica que mÃºltiples componentes funcionan juntos.</p>
<p><strong>AnalogÃ­a:</strong> Probar que motor, transmisiÃ³n y ruedas funcionan juntos.</p>
<h3>isort</h3>
<p><strong>DefiniciÃ³n:</strong> Ordena imports de Python automÃ¡ticamente.</p>
<p><strong>AnalogÃ­a:</strong> Organizador de armario que siempre pone ropa en mismo orden.</p>
<h2>J</h2>
<h3>Job (GitHub Actions)</h3>
<p><strong>DefiniciÃ³n:</strong> Conjunto de steps en mismo runner.</p>
<p><strong>Relacionados:</strong> Workflow, Step, Runner</p>
<h3>Joblib</h3>
<p><strong>DefiniciÃ³n:</strong> Serializa objetos Python, especialmente modelos sklearn.</p>
<pre><code class="language-python">joblib.dump(model, &quot;model.pkl&quot;)
model = joblib.load(&quot;model.pkl&quot;)
</code></pre>
<h2>K</h2>
<h3>Kubernetes (K8s)</h3>
<p><strong>DefiniciÃ³n:</strong> Orquestador de contenedores para automatizar despliegue y escalado.</p>
<p><strong>AnalogÃ­a:</strong> Director de orquesta coordinando muchos mÃºsicos (contenedores).</p>
<p><strong>Recursos:</strong> Pod, Deployment, Service, Ingress</p>
<h3>K-Fold</h3>
<p><strong>DefiniciÃ³n:</strong> Dividir datos en K partes para cross-validation.</p>
<p><strong>Relacionados:</strong> Cross-Validation, Stratified</p>
<h2>L</h2>
<h3>Latency (Latencia)</h3>
<p><strong>DefiniciÃ³n:</strong> Tiempo de respuesta del sistema. En APIs ML: milisegundos.</p>
<p><strong>AnalogÃ­a:</strong> Tiempo entre pedir comida y que llegue.</p>
<p><strong>P95:</strong> El 95% de requests responden en menos de X ms.</p>
<h3>Learning Rate</h3>
<p><strong>DefiniciÃ³n:</strong> TamaÃ±o de paso en gradient descent.</p>
<p><strong>AnalogÃ­a:</strong> Paso grande = llegas rÃ¡pido pero puedes pasar el mÃ­nimo. Paso pequeÃ±o = lento pero preciso.</p>
<h3>Linting</h3>
<p><strong>DefiniciÃ³n:</strong> AnÃ¡lisis estÃ¡tico para detectar errores y violaciones de estilo.</p>
<p><strong>Herramientas:</strong> Flake8, pylint, mypy</p>
<h3>Load Balancer</h3>
<p><strong>DefiniciÃ³n:</strong> Distribuye trÃ¡fico entre mÃºltiples servidores.</p>
<p><strong>AnalogÃ­a:</strong> Hostess de restaurante que asigna mesas equitativamente.</p>
<h3>Loss Function (FunciÃ³n de PÃ©rdida)</h3>
<p><strong>DefiniciÃ³n:</strong> Mide quÃ© tan mal son las predicciones. El entrenamiento la minimiza.</p>
<p><strong>Ejemplos:</strong> MSE (regresiÃ³n), Cross-Entropy (clasificaciÃ³n)</p>
<h2>M</h2>
<h3>Makefile</h3>
<p><strong>DefiniciÃ³n:</strong> Archivo con comandos abreviados para tareas comunes.</p>
<pre><code class="language-makefile">test:
    pytest tests/ -v
lint:
    black src/ &amp;&amp; flake8 src/
</code></pre>
<h3>Matrix (GitHub Actions)</h3>
<p><strong>DefiniciÃ³n:</strong> Ejecutar job con mÃºltiples combinaciones de parÃ¡metros.</p>
<pre><code class="language-yaml">strategy:
  matrix:
    python-version: [3.10, 3.11]
</code></pre>
<h3>Metric (MÃ©trica)</h3>
<p><strong>DefiniciÃ³n:</strong> Valor numÃ©rico que mide rendimiento del modelo.</p>
<p><strong>ClasificaciÃ³n:</strong> Accuracy, Precision, Recall, F1, AUC<br />
<strong>RegresiÃ³n:</strong> MSE, RMSE, MAE, RÂ²</p>
<h3>Middleware</h3>
<p><strong>DefiniciÃ³n:</strong> CÃ³digo que intercepta requests/responses entre cliente y aplicaciÃ³n.</p>
<p><strong>AnalogÃ­a:</strong> Portero que revisa credenciales antes de dejarte pasar.</p>
<h3>MLflow</h3>
<p><strong>DefiniciÃ³n:</strong> Plataforma open-source para gestionar ciclo de vida ML.</p>
<p><strong>Componentes:</strong> Tracking, Projects, Models, Registry</p>
<pre><code class="language-python">with mlflow.start_run():
    mlflow.log_params(params)
    mlflow.log_metrics(metrics)
    mlflow.sklearn.log_model(model, &quot;model&quot;)
</code></pre>
<h3>MLOps</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Conjunto de prÃ¡cticas que unifican Machine Learning, DevOps y Data Engineering para automatizar y estandarizar el ciclo de vida completo de modelos ML: desde experimentaciÃ³n hasta producciÃ³n, incluyendo monitoreo, reentrenamiento y gobernanza.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Data Scientists saben entrenar modelos. DevOps sabe desplegar aplicaciones. Data Engineers saben mover datos. MLOps es el puente que conecta estos tres mundos. Sin MLOps, tienes "modelos en notebooks" que nunca llegan a producciÃ³n, o modelos desplegados que nadie monitorea y se degradan silenciosamente. MLOps trae madurez industrial al ML.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina que los Data Scientists son chefs que crean recetas increÃ­bles en su cocina experimental. DevOps es el equipo que opera restaurantes a escala. MLOps es el proceso que convierte esa receta experimental en un menÃº estandarizado, con control de calidad, ingredientes versionados, y alertas si la calidad baja. Sin MLOps, tienes un chef genial cuyas recetas nadie puede reproducir consistentemente.</p>
<p><strong>Pilares de MLOps:</strong><br />
1. <strong>Versionado</strong>: CÃ³digo (Git), Datos (DVC), Modelos (MLflow)<br />
2. <strong>AutomatizaciÃ³n</strong>: CI/CD, pipelines de entrenamiento<br />
3. <strong>Testing</strong>: Datos, modelos, APIs, integraciÃ³n<br />
4. <strong>Monitoreo</strong>: Drift, performance, latencia<br />
5. <strong>Reproducibilidad</strong>: Ambientes, seeds, configuraciones</p>
<p><strong>Relacionados:</strong> DevOps, CI/CD, MLflow, DVC, Model Monitoring</p>
<h3>Multi-stage Build (Docker)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> TÃ©cnica de construcciÃ³n de imÃ¡genes Docker que usa mÃºltiples <code>FROM</code> statements, permitiendo separar el ambiente de compilaciÃ³n/build del ambiente de ejecuciÃ³n. El resultado es una imagen final mÃ¡s pequeÃ±a y segura que solo contiene lo necesario para ejecutar la aplicaciÃ³n.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Cuando construyes una aplicaciÃ³n, necesitas herramientas de compilaciÃ³n, tests, dependencias de desarrollo. Pero en producciÃ³n, solo necesitas el binario final y las dependencias runtime. Multi-stage te permite "cocinar" en una cocina completa y luego servir solo el plato terminado, sin llevar todos los utensilios al comedor.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina construir un mueble IKEA. Necesitas martillo, destornillador, nivel, instrucciones, embalaje. Pero una vez terminado, solo quieres el mueble en tu salaâ€”no el taller completo. Multi-stage es exactamente eso: usas un container "taller" con todas las herramientas, construyes, y luego copias solo el resultado final a un container "sala" limpio y minimalista.</p>
<p><strong>Ejemplo del portafolio:</strong></p>
<pre><code class="language-dockerfile"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1: Builder - Tiene todas las herramientas
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS builder

WORKDIR /app

# Instalar dependencias de compilaciÃ³n (solo en builder)
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    build-essential \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Instalar dependencias Python en directorio aislado
COPY requirements.txt .
RUN pip install --no-cache-dir --target=/app/deps -r requirements.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2: Runtime - Solo lo necesario para ejecutar
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim

# Usuario no-root (seguridad)
RUN useradd --create-home appuser

WORKDIR /app

# Copiar SOLO las dependencias instaladas (no el toolchain)
COPY --from=builder /app/deps /usr/local/lib/python3.11/site-packages/

# Copiar cÃ³digo de aplicaciÃ³n
COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser artifacts/ ./artifacts/

USER appuser

EXPOSE 8000
CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<p><strong>Beneficios:</strong><br />
- <strong>Imagen mÃ¡s pequeÃ±a</strong>: De ~1.5GB a ~500MB<br />
- <strong>MÃ¡s segura</strong>: Sin compiladores ni herramientas de ataque<br />
- <strong>MÃ¡s rÃ¡pida de desplegar</strong>: Menos bytes que transferir</p>
<p><strong>Relacionados:</strong> Docker, Container, Dockerfile, Non-root User</p>
<h3>Model Card</h3>
<p><strong>DefiniciÃ³n:</strong> Documento describiendo modelo: propÃ³sito, datos, mÃ©tricas, limitaciones, Ã©tica.</p>
<p><strong>AnalogÃ­a:</strong> Prospecto de medicamento. InformaciÃ³n completa sobre quÃ© hace y sus efectos.</p>
<h3>Model Registry</h3>
<p><strong>DefiniciÃ³n:</strong> Sistema para versionar y gestionar modelos ML.</p>
<p><strong>Estados:</strong> Staging â†’ Production â†’ Archived</p>
<h3>mypy</h3>
<p><strong>DefiniciÃ³n:</strong> Type checking estÃ¡tico para Python.</p>
<pre><code class="language-bash">mypy src/
</code></pre>
<p><strong>Relacionados:</strong> Type Hints, Pydantic</p>
<h2>N</h2>
<h3>NaN (Not a Number)</h3>
<p><strong>DefiniciÃ³n:</strong> Valor especial para datos faltantes o indefinidos.</p>
<pre><code class="language-python">import numpy as np
np.nan
</code></pre>
<h3>Namespace</h3>
<p><strong>DefiniciÃ³n:</strong> Kubernetes: divisiÃ³n lÃ³gica del cluster para aislamiento.</p>
<p><strong>AnalogÃ­a:</strong> Departamentos en una empresa. Cada uno tiene sus recursos.</p>
<h2>O</h2>
<h3>Observability (Observabilidad)</h3>
<p><strong>DefiniciÃ³n:</strong> Capacidad de entender estado interno de sistema desde outputs externos.</p>
<p><strong>3 Pilares:</strong> Logs, Metrics, Traces</p>
<p><strong>AnalogÃ­a:</strong> Instrumentos de aviÃ³n. Si no puedes ver, no puedes arreglar.</p>
<h3>One-Hot Encoding</h3>
<p><strong>DefiniciÃ³n:</strong> Convierte variables categÃ³ricas en vectores binarios.</p>
<pre><code>Country: [France, Spain, Germany]
France â†’ [1, 0, 0]
Spain  â†’ [0, 1, 0]
</code></pre>
<h3>Overfitting (Sobreajuste)</h3>
<p><strong>DefiniciÃ³n:</strong> Modelo memoriza datos de entrenamiento, no generaliza.</p>
<p><strong>AnalogÃ­a:</strong> Estudiante que memoriza respuestas exactas pero no entiende conceptos.</p>
<p><strong>SeÃ±ales:</strong> Train accuracy muy alta, validation accuracy baja.</p>
<p><strong>Soluciones:</strong> MÃ¡s datos, regularizaciÃ³n, early stopping, dropout</p>
<h2>P</h2>
<h3>Pipeline (sklearn)</h3>
<p><strong>DefiniciÃ³n:</strong> Secuencia de transformaciones y estimador final encadenados.</p>
<p><strong>AnalogÃ­a:</strong> LÃ­nea de ensamblaje. Cada estaciÃ³n hace una transformaciÃ³n.</p>
<pre><code class="language-python">pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])
</code></pre>
<h3>Pod</h3>
<p><strong>DefiniciÃ³n:</strong> Kubernetes: unidad de deployment mÃ¡s pequeÃ±a. Uno o mÃ¡s contenedores.</p>
<p><strong>AnalogÃ­a:</strong> Apartamento en edificio. Contenedores son habitaciones del apartamento.</p>
<h3>Precision (PrecisiÃ³n)</h3>
<p><strong>DefiniciÃ³n:</strong> De predicciones positivas, Â¿cuÃ¡ntas son correctas? TP / (TP + FP)</p>
<p><strong>AnalogÃ­a:</strong> De las personas que detuviste como sospechosas, Â¿cuÃ¡ntas eran realmente criminales?</p>
<h3>Pre-commit Hook</h3>
<p><strong>DefiniciÃ³n:</strong> Script que se ejecuta automÃ¡ticamente antes de cada commit.</p>
<p><strong>AnalogÃ­a:</strong> Control de calidad que revisa tu trabajo antes de entregarlo.</p>
<pre><code class="language-yaml"># .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    hooks:
      - id: black
</code></pre>
<h3>Prometheus</h3>
<p><strong>DefiniciÃ³n:</strong> Sistema de monitoreo y alertas. Recolecta mÃ©tricas de servicios.</p>
<p><strong>Relacionados:</strong> Grafana, Metrics, Observabilidad</p>
<h3>Pull Request (PR)</h3>
<p><strong>DefiniciÃ³n:</strong> Solicitud para integrar cambios con revisiÃ³n de cÃ³digo.</p>
<p><strong>AnalogÃ­a:</strong> Propuesta formal que requiere aprobaciÃ³n antes de aceptarse.</p>
<h3>Pydantic</h3>
<p><strong>DefiniciÃ³n:</strong> ValidaciÃ³n de datos en Python usando type hints.</p>
<pre><code class="language-python">class Customer(BaseModel):
    age: int = Field(ge=18, le=100)
    name: str
</code></pre>
<p><strong>Relacionados:</strong> Type Hints, FastAPI, Validation</p>
<h3>pytest</h3>
<p><strong>DefiniciÃ³n:</strong> Framework de testing para Python.</p>
<pre><code class="language-python">def test_prediction():
    result = model.predict([[35, 50000]])
    assert result[0] in [0, 1]
</code></pre>
<h2>R</h2>
<h3>Random Forest</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Algoritmo de ensemble learning que construye mÃºltiples Ã¡rboles de decisiÃ³n durante el entrenamiento y combina sus predicciones (votaciÃ³n mayoritaria para clasificaciÃ³n, promedio para regresiÃ³n). Cada Ã¡rbol se entrena con un subconjunto aleatorio de datos (bagging) y features (random subspace).</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Un solo Ã¡rbol de decisiÃ³n puede sobreajustarse fÃ¡cilmente y es muy sensible a pequeÃ±os cambios en los datos. Random Forest resuelve esto con la "sabidurÃ­a de las multitudes": entrena cientos de Ã¡rboles "diversos" (cada uno ve datos diferentes) y promedia sus opiniones. Los errores individuales se cancelan, produciendo un modelo robusto y estable.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina 100 doctores, cada uno especializado en diferentes aspectos (algunos ven mÃ¡s casos de ciertas enfermedades, otros atienden diferentes demografÃ­as). Si cada doctor da su diagnÃ³stico individualmente, algunos acertarÃ¡n y otros fallarÃ¡n. Pero si los 100 votan y tomas la opiniÃ³n mayoritaria, casi siempre aciertas. Eso es Random Forest: democracia de Ã¡rboles donde los errores individuales se cancelan.</p>
<p><strong>Por quÃ© es popular en MLOps:</strong><br />
- <strong>Interpretabilidad</strong>: Feature importances nativas<br />
- <strong>Robustez</strong>: Funciona bien "out of the box" sin tuning extensivo<br />
- <strong>Versatilidad</strong>: ClasificaciÃ³n y regresiÃ³n<br />
- <strong>Sin normalizaciÃ³n</strong>: No requiere escalar features</p>
<p><strong>Ejemplo del portafolio (BankChurn):</strong></p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline

# ParÃ¡metros clave:
# - n_estimators: NÃºmero de Ã¡rboles (mÃ¡s = mÃ¡s estable, mÃ¡s lento)
# - max_depth: Profundidad mÃ¡xima (controla overfitting)
# - class_weight: Manejo de desbalance

pipeline = Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', SimpleImputer(strategy='median'), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),
    ])),
    ('classifier', RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        class_weight='balanced',  # CrÃ­tico para churn
        random_state=42,
        n_jobs=-1  # Paralelizar
    ))
])

# Feature importance despuÃ©s de entrenar
importances = pipeline.named_steps['classifier'].feature_importances_
</code></pre>
<p><strong>HiperparÃ¡metros importantes:</strong></p>
<table>
<thead>
<tr>
<th>ParÃ¡metro</th>
<th>Default</th>
<th>Efecto</th>
</tr>
</thead>
<tbody>
<tr>
<td>n_estimators</td>
<td>100</td>
<td>MÃ¡s Ã¡rboles = mÃ¡s estable pero mÃ¡s lento</td>
</tr>
<tr>
<td>max_depth</td>
<td>None</td>
<td>Limitar previene overfitting</td>
</tr>
<tr>
<td>min_samples_split</td>
<td>2</td>
<td>Mayor valor = Ã¡rboles mÃ¡s pequeÃ±os</td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>'balanced' para clases desbalanceadas</td>
</tr>
</tbody>
</table>
<p><strong>Relacionados:</strong> Ensemble, Bagging, Decision Tree, class_weight, Feature Importance</p>
<h3>Recall (Sensibilidad)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> MÃ©trica que mide quÃ© proporciÃ³n de los casos positivos reales fueron correctamente identificados. FÃ³rmula: <code>TP / (TP + FN)</code>. TambiÃ©n llamada Sensibilidad o True Positive Rate.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Recall responde: "De todos los casos positivos reales, Â¿cuÃ¡ntos logrÃ© detectar?". Es crÃ­tica cuando el costo de <strong>no detectar</strong> un positivo es alto: diagnÃ³stico de cÃ¡ncer (no detectar = paciente sin tratamiento), detecciÃ³n de fraude (no detectar = pÃ©rdida financiera), predicciÃ³n de churn (no detectar = cliente perdido).</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un detector de metales en un aeropuerto. Recall es: "De todas las armas reales que pasaron, Â¿cuÃ¡ntas detectÃ³?". Un Recall del 100% significa que detectÃ³ todas las armas (aunque haya generado muchas falsas alarmas con llaves y monedas). En seguridad, preferimos alta sensibilidad aunque suene mÃ¡s veces innecesariamente.</p>
<p><strong>En el portafolio:</strong> BankChurn prioriza Recall porque el costo de no detectar un churner (perderlo) es mayor que el costo de ofrecerle retenciÃ³n a alguien que no iba a irse.</p>
<p><strong>Trade-off Precision vs Recall:</strong></p>
<pre><code>                    PredicciÃ³n
                    Positivo    Negativo
Realidad Positivo   TP          FN (Recall falla aquÃ­)
         Negativo   FP          TN

Recall = TP / (TP + FN) â†’ Maximizar TP, minimizar FN
</code></pre>
<p><strong>Relacionados:</strong> Precision, F1 Score, Threshold, ROC-AUC</p>
<h3>Regression (RegresiÃ³n)</h3>
<p><strong>DefiniciÃ³n:</strong> Problema ML para predecir valor numÃ©rico continuo.</p>
<p><strong>Ejemplos:</strong> Precio de casa, temperatura, ventas</p>
<h3>Regularization (RegularizaciÃ³n)</h3>
<p><strong>DefiniciÃ³n:</strong> TÃ©cnicas para prevenir overfitting penalizando complejidad.</p>
<p><strong>Tipos:</strong> L1 (Lasso), L2 (Ridge), Dropout, Early Stopping</p>
<h3>Replica</h3>
<p><strong>DefiniciÃ³n:</strong> Copia de un pod/servicio para alta disponibilidad.</p>
<p><strong>Relacionados:</strong> Deployment, ReplicaSet</p>
<h3>Reproducibility (Reproducibilidad)</h3>
<p><strong>DefiniciÃ³n:</strong> Obtener mismos resultados con mismo cÃ³digo y datos.</p>
<p><strong>Clave:</strong> Seeds, versionado de datos/cÃ³digo/ambiente</p>
<h3>REST API</h3>
<p><strong>DefiniciÃ³n:</strong> Estilo arquitectÃ³nico con HTTP methods: GET, POST, PUT, DELETE.</p>
<p><strong>Relacionados:</strong> API, HTTP, Endpoint</p>
<h3>Runbook</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Documento operacional que contiene procedimientos paso a paso para manejar incidentes, alertas o tareas de mantenimiento de un sistema en producciÃ³n. Incluye informaciÃ³n del servicio, alertas comunes, y procedimientos de emergencia.</p>
<p><strong>Contenido tÃ­pico:</strong><br />
- InformaciÃ³n del servicio (owner, criticidad, endpoints)<br />
- Procedimientos para alertas comunes<br />
- Comandos de diagnÃ³stico y recuperaciÃ³n<br />
- Escalamiento y contactos</p>
<p><strong>En el portafolio:</strong> Ver <a href="17_DESPLIEGUE.md#-operaciones-y-runbooks">17_DESPLIEGUE.md â†’ Operaciones y Runbooks</a>.</p>
<p><strong>Relacionados:</strong> SLO, SLA, Incident Response, On-call</p>
<h3>Ruff</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Linter y formateador de cÃ³digo Python extremadamente rÃ¡pido, escrito en Rust. Reemplaza mÃºltiples herramientas (Flake8, Black, isort, pyupgrade, etc.) con una sola herramienta 10-100x mÃ¡s rÃ¡pida.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Tradicionalmente, un proyecto Python necesitaba mÃºltiples herramientas para mantener la calidad del cÃ³digo: Black para formatear, Flake8 para detectar errores, isort para ordenar imports, pyupgrade para sintaxis moderna. Cada herramienta tenÃ­a su configuraciÃ³n, versiÃ³n, y tiempo de ejecuciÃ³n. Ruff unifica todo esto: un solo binario que hace todo, instantÃ¡neamente. Es la herramienta moderna que estÃ¡ reemplazando al stack tradicional.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina tener una navaja suiza en vez de cargar tijeras, destornillador, cuchillo y abridor por separado. Ruff es esa navaja suiza: todas las herramientas de calidad de cÃ³digo en una, y ademÃ¡s es mÃ¡s ligera y rÃ¡pida que cualquiera de las individuales.</p>
<p><strong>Por quÃ© importa:</strong><br />
- <strong>Velocidad</strong>: 10-100x mÃ¡s rÃ¡pido que Flake8+Black+isort<br />
- <strong>UnificaciÃ³n</strong>: Una herramienta, una configuraciÃ³n<br />
- <strong>Compatibilidad</strong>: Entiende las reglas de Flake8, Black, isort<br />
- <strong>Moderno</strong>: Soporta Python 3.12+, type hints, f-strings</p>
<p><strong>Ejemplo de configuraciÃ³n (pyproject.toml):</strong></p>
<pre><code class="language-toml">[tool.ruff]
line-length = 88
target-version = &quot;py311&quot;

[tool.ruff.lint]
select = [
    &quot;E&quot;,    # pycodestyle errors
    &quot;W&quot;,    # pycodestyle warnings
    &quot;F&quot;,    # Pyflakes
    &quot;I&quot;,    # isort
    &quot;B&quot;,    # flake8-bugbear
    &quot;C4&quot;,   # flake8-comprehensions
    &quot;UP&quot;,   # pyupgrade
]
ignore = [&quot;E501&quot;]  # Line too long (handled by formatter)

[tool.ruff.lint.isort]
known-first-party = [&quot;bankchurn&quot;, &quot;carvision&quot;, &quot;telecomai&quot;]
</code></pre>
<p><strong>Uso:</strong></p>
<pre><code class="language-bash"># Lint (detectar errores)
ruff check src/

# Lint con auto-fix
ruff check --fix src/

# Format (como Black)
ruff format src/

# Pre-commit hook
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.4.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
</code></pre>
<p><strong>Relacionados:</strong> Linting, Black, Flake8, isort, pre-commit, Code Quality</p>
<h2>S</h2>
<h3>Scaling (Escalado de Features)</h3>
<p><strong>DefiniciÃ³n:</strong> Normalizar features a rango similar.</p>
<p><strong>TÃ©cnicas:</strong> StandardScaler (z-score), MinMaxScaler (0-1)</p>
<h3>Scikit-learn (sklearn)</h3>
<p><strong>DefiniciÃ³n:</strong> LibrerÃ­a Python para ML clÃ¡sico.</p>
<p><strong>MÃ³dulos:</strong> preprocessing, model_selection, ensemble, metrics</p>
<h3>Secret</h3>
<p><strong>DefiniciÃ³n:</strong> Valor sensible (contraseÃ±a, API key) que no debe estar en cÃ³digo.</p>
<p><strong>Kubernetes:</strong> Objeto Secret para almacenar datos sensibles encriptados.</p>
<h3>Seed (Random State)</h3>
<p><strong>DefiniciÃ³n:</strong> Valor para inicializar generadores aleatorios. Garantiza reproducibilidad.</p>
<pre><code class="language-python">np.random.seed(42)
RandomForestClassifier(random_state=42)
</code></pre>
<h3>Service (Kubernetes)</h3>
<p><strong>DefiniciÃ³n:</strong> AbstracciÃ³n que expone pods como servicio de red.</p>
<p><strong>Tipos:</strong> ClusterIP, NodePort, LoadBalancer</p>
<h3>SHAP</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> SHapley Additive exPlanations. Framework de interpretabilidad basado en teorÃ­a de juegos que asigna a cada feature su contribuciÃ³n marginal a una predicciÃ³n especÃ­fica. Funciona con cualquier modelo (model-agnostic).</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Cuando un modelo predice que un cliente va a abandonar, quieres saber <em>por quÃ©</em>. SHAP descompone la predicciÃ³n en contribuciones de cada feature: "El balance alto contribuyÃ³ +0.15 a la probabilidad de churn, la edad joven contribuyÃ³ -0.08, el nÃºmero de productos contribuyÃ³ +0.12...". Esto permite explicar cada predicciÃ³n individual, no solo el modelo en general.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina un jurado de 10 personas que decide un veredicto. SHAP es como analizar cuÃ¡nto influyÃ³ cada jurado en la decisiÃ³n final. "MarÃ­a estaba muy convencida (+0.3), Juan estaba indeciso (+0.05), Pedro iba en contra (-0.2)...". Sumando todas las contribuciones, obtienes el veredicto final.</p>
<p><strong>Relacionados:</strong> Interpretabilidad, Feature Importance, Explainability</p>
<h3>SMOTE (Synthetic Minority Over-sampling Technique)</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> TÃ©cnica de oversampling que genera ejemplos sintÃ©ticos de la clase minoritaria interpolando entre ejemplos existentes y sus k vecinos mÃ¡s cercanos. No duplica ejemplosâ€”crea nuevos puntos en el espacio de features.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Cuando tienes 95% de una clase y 5% de otra, el modelo aprende a ignorar la minoritaria. SMOTE resuelve esto generando ejemplos sintÃ©ticos "plausibles" de la clase minoritaria. Toma un ejemplo real, encuentra sus vecinos mÃ¡s cercanos (tambiÃ©n de la clase minoritaria), y crea nuevos puntos en la lÃ­nea que los conecta. AsÃ­ el modelo ve mÃ¡s variedad de la clase minoritaria sin simplemente copiar los mismos ejemplos.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina que tienes 10 fotos de gatos negros y 1000 de perros. Duplicar la foto del gato 100 veces no ayudaâ€”el modelo memoriza esa Ãºnica foto. SMOTE es como un artista que mira tus 10 fotos de gatos negros y pinta 90 fotos nuevas de gatos negros "plausibles" interpolando caracterÃ­sticas: "este tiene los ojos del gato 1, las orejas del gato 3, el tamaÃ±o del gato 7...".</p>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-python">from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Siempre aplicar DESPUÃ‰S del split (evitar data leakage)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)

# SMOTE solo en training
smote = SMOTE(random_state=42, k_neighbors=5)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Ahora las clases estÃ¡n balanceadas en training
print(f&quot;Original: {y_train.value_counts().to_dict()}&quot;)
print(f&quot;Resampled: {pd.Series(y_train_resampled).value_counts().to_dict()}&quot;)
</code></pre>
<p><strong>CuÃ¡ndo usar SMOTE vs class_weight:</strong><br />
- <strong>SMOTE</strong>: Cuando quieres mÃ¡s variedad en ejemplos minoritarios<br />
- <strong>class_weight</strong>: MÃ¡s simple, no modifica datos, funciona bien en la mayorÃ­a de casos</p>
<p><strong>Relacionados:</strong> Class Imbalance, Oversampling, class_weight, imblearn</p>
<h3>SOLID</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Cinco principios de diseÃ±o de software orientado a objetos que promueven cÃ³digo mantenible, extensible y testeable.</p>
<p><strong>Los 5 principios:</strong></p>
<ol>
<li><strong>S - Single Responsibility</strong>: Una clase debe tener una sola razÃ³n para cambiar<br />
   ```python<br />
   # âŒ Mal: Clase hace demasiado<br />
   class ChurnPredictor:<br />
       def load_data(self): ...<br />
       def clean_data(self): ...<br />
       def train(self): ...<br />
       def save_to_s3(self): ...</li>
</ol>
<p># âœ… Bien: Responsabilidades separadas<br />
   class DataLoader: ...<br />
   class FeatureEngineer: ...<br />
   class ChurnTrainer: ...<br />
   class S3Uploader: ...<br />
   ```</p>
<ol>
<li><strong>O - Open/Closed</strong>: Abierto para extensiÃ³n, cerrado para modificaciÃ³n<br />
   ```python<br />
   # Puedes aÃ±adir nuevos modelos sin modificar cÃ³digo existente<br />
   class BaseTrainer(ABC):<br />
       @abstractmethod<br />
       def train(self, X, y): ...</li>
</ol>
<p>class RandomForestTrainer(BaseTrainer): ...<br />
   class XGBoostTrainer(BaseTrainer): ...  # ExtensiÃ³n, no modificaciÃ³n<br />
   ```</p>
<ol>
<li>
<p><strong>L - Liskov Substitution</strong>: Subclases deben ser substituibles por sus padres</p>
</li>
<li>
<p><strong>I - Interface Segregation</strong>: Interfaces pequeÃ±as y especÃ­ficas</p>
</li>
<li>
<p><strong>D - Dependency Inversion</strong>: Depender de abstracciones, no de implementaciones</p>
</li>
</ol>
<p><strong>En el portafolio:</strong> <code>FeatureEngineer</code>, <code>ChurnTrainer</code> siguen Single Responsibility. El uso de sklearn Pipeline permite Open/Closed (cambiar modelo sin modificar pipeline).</p>
<p><strong>Relacionados:</strong> Clean Code, Design Patterns, Testing</p>
<h3>src/ Layout</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Estructura de proyecto Python donde el cÃ³digo fuente reside en un subdirectorio <code>src/</code> en lugar de la raÃ­z. El paquete se instala con <code>pip install -e .</code> para desarrollo.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> La estructura "flat" (cÃ³digo en raÃ­z) causa problemas: Python puede importar archivos locales en vez del paquete instalado, tests pueden pasar localmente pero fallar en CI, y es difÃ­cil distinguir cÃ³digo de proyecto de configuraciÃ³n. <code>src/</code> layout resuelve esto forzando que el cÃ³digo solo sea accesible como paquete instalado.</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina una tienda donde los productos estÃ¡n tanto en el almacÃ©n como en el piso de venta. ConfusiÃ³n garantizada: Â¿el cliente estÃ¡ comprando del almacÃ©n o del piso? src/ layout es como tener una puerta clara entre almacÃ©n (desarrollo) y piso de venta (paquete instalado).</p>
<p><strong>Estructura del portafolio:</strong></p>
<pre><code>BankChurn-Predictor/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bankchurn/           # Paquete principal
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py        # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ pipeline.py      # Pipeline sklearn
â”‚       â””â”€â”€ trainer.py       # Clase de entrenamiento
â”œâ”€â”€ tests/                   # Tests (fuera de src/)
â”œâ”€â”€ app/                     # APIs (fuera de src/)
â”œâ”€â”€ configs/                 # Configuraciones YAML
â”œâ”€â”€ artifacts/               # Modelos entrenados
â””â”€â”€ pyproject.toml          # ConfiguraciÃ³n de paquete
</code></pre>
<p><strong>ConfiguraciÃ³n en pyproject.toml:</strong></p>
<pre><code class="language-toml">[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;bankchurn&quot;
version = &quot;0.1.0&quot;

[tool.setuptools.packages.find]
where = [&quot;src&quot;]
</code></pre>
<p><strong>Relacionados:</strong> pyproject.toml, Package, Import, Project Structure</p>
<h3>Staging</h3>
<p><strong>DefiniciÃ³n:</strong> Ambiente que replica producciÃ³n para testing final.</p>
<p><strong>AnalogÃ­a:</strong> Ensayo general antes del estreno.</p>
<h3>Stratified Split</h3>
<p><strong>DefiniciÃ³n:</strong> DivisiÃ³n que mantiene proporciÃ³n de clases en train y test.</p>
<pre><code class="language-python">train_test_split(X, y, stratify=y)
</code></pre>
<h3>Streamlit</h3>
<p><strong>DefiniciÃ³n tÃ©cnica:</strong> Framework Python para crear aplicaciones web interactivas con cÃ³digo puro Python. Convierte scripts de anÃ¡lisis de datos en dashboards web sin necesidad de conocimientos de HTML, CSS o JavaScript.</p>
<p><strong>ExplicaciÃ³n conceptual:</strong> Data Scientists crean anÃ¡lisis increÃ­bles en notebooks, pero compartirlos requiere que el receptor tenga Python instalado y sepa ejecutar notebooks. Streamlit permite convertir ese anÃ¡lisis en una aplicaciÃ³n web que cualquiera puede usar: aÃ±ades decoradores como <code>st.title()</code>, <code>st.button()</code>, <code>st.dataframe()</code> y Streamlit genera una UI web automÃ¡ticamente. Es la forma mÃ¡s rÃ¡pida de pasar de "script de anÃ¡lisis" a "aplicaciÃ³n interactiva".</p>
<p><strong>AnalogÃ­a desarrollada:</strong> Imagina que eres un chef que crea recetas increÃ­bles. Jupyter notebooks es como escribir la receta en un cuaderno tÃ©cnicoâ€”otros chefs pueden seguirla, pero no el pÃºblico general. Streamlit es como montar un food truck donde la gente puede probar tus platos sin saber cocinar. Tu cÃ³digo Python sigue siendo la "cocina", pero ahora tiene una ventana de servicio bonita.</p>
<p><strong>Ejemplo del portafolio (CarVision Dashboard):</strong></p>
<pre><code class="language-python">import streamlit as st
import pandas as pd
import joblib

st.set_page_config(page_title=&quot;CarVision Predictor&quot;, page_icon=&quot;ğŸš—&quot;)
st.title(&quot;ğŸš— CarVision Price Predictor&quot;)

# Sidebar para inputs
with st.sidebar:
    st.header(&quot;Vehicle Features&quot;)
    year = st.slider(&quot;Year&quot;, 2000, 2024, 2018)
    mileage = st.number_input(&quot;Mileage&quot;, 0, 300000, 50000)
    brand = st.selectbox(&quot;Brand&quot;, [&quot;Toyota&quot;, &quot;Honda&quot;, &quot;Ford&quot;])

# Cargar modelo (con cache para no recargar)
@st.cache_resource
def load_model():
    return joblib.load(&quot;artifacts/model.joblib&quot;)

model = load_model()

# BotÃ³n de predicciÃ³n
if st.button(&quot;ğŸ”® Predict Price&quot;):
    input_df = pd.DataFrame([{&quot;year&quot;: year, &quot;mileage&quot;: mileage, &quot;brand&quot;: brand}])
    prediction = model.predict(input_df)[0]

    st.success(f&quot;Estimated Price: ${prediction:,.0f}&quot;)

    # MÃ©tricas visuales
    col1, col2 = st.columns(2)
    col1.metric(&quot;Predicted Price&quot;, f&quot;${prediction:,.0f}&quot;)
    col2.metric(&quot;Confidence&quot;, &quot;High&quot; if prediction &gt; 10000 else &quot;Medium&quot;)
</code></pre>
<p><strong>Componentes clave:</strong><br />
- <code>st.title()</code>, <code>st.header()</code>: TÃ­tulos<br />
- <code>st.slider()</code>, <code>st.number_input()</code>, <code>st.selectbox()</code>: Inputs<br />
- <code>st.button()</code>: Acciones<br />
- <code>st.dataframe()</code>, <code>st.plotly_chart()</code>: VisualizaciÃ³n<br />
- <code>@st.cache_resource</code>: Cache de modelos/datos pesados</p>
<p><strong>Relacionados:</strong> Dashboard, FastAPI, Gradio, Panel</p>
<h2>T</h2>
<h3>Target</h3>
<p><strong>DefiniciÃ³n:</strong> Variable que queremos predecir. TambiÃ©n llamada "label" o "y".</p>
<h3>Terraform</h3>
<p><strong>DefiniciÃ³n:</strong> Infrastructure as Code. Provisiona recursos en cloud con cÃ³digo.</p>
<pre><code class="language-hcl">resource &quot;aws_instance&quot; &quot;ml_server&quot; {
  instance_type = &quot;t3.medium&quot;
}
</code></pre>
<h3>Test Coverage</h3>
<p><strong>DefiniciÃ³n:</strong> Porcentaje de cÃ³digo ejecutado durante tests.</p>
<p><strong>Relacionados:</strong> Coverage, pytest</p>
<h3>Threshold (Umbral)</h3>
<p><strong>DefiniciÃ³n:</strong> Punto de corte para convertir probabilidades en clases.</p>
<p><strong>Default:</strong> 0.5, pero ajustable segÃºn necesidades de negocio.</p>
<h3>Throughput</h3>
<p><strong>DefiniciÃ³n:</strong> Cantidad de predicciones/requests por unidad de tiempo.</p>
<p><strong>AnalogÃ­a:</strong> CuÃ¡ntos platos puede servir el restaurante por hora.</p>
<h3>Traces</h3>
<p><strong>DefiniciÃ³n:</strong> Seguimiento de requests a travÃ©s de sistema distribuido.</p>
<p><strong>Herramientas:</strong> Jaeger, OpenTelemetry</p>
<p><strong>Relacionados:</strong> Observabilidad, Logs, Metrics</p>
<h3>TransformerMixin</h3>
<p><strong>DefiniciÃ³n:</strong> Mixin sklearn que aÃ±ade <code>fit_transform()</code> automÃ¡ticamente.</p>
<p><strong>Relacionados:</strong> BaseEstimator, Custom Transformer</p>
<h3>Trivy</h3>
<p><strong>DefiniciÃ³n:</strong> EscÃ¡ner de vulnerabilidades para contenedores.</p>
<pre><code class="language-bash">trivy image my-app:latest
</code></pre>
<h3>Type Hints</h3>
<p><strong>DefiniciÃ³n:</strong> Anotaciones en Python que indican tipos esperados.</p>
<pre><code class="language-python">def predict(data: pd.DataFrame) -&gt; np.ndarray:
    pass
</code></pre>
<p><strong>Relacionados:</strong> mypy, Pydantic</p>
<h2>U</h2>
<h3>Underfitting (Subajuste)</h3>
<p><strong>DefiniciÃ³n:</strong> Modelo demasiado simple. No captura patrones.</p>
<p><strong>SeÃ±ales:</strong> Train y validation accuracy bajas.</p>
<h3>Unit Test</h3>
<p><strong>DefiniciÃ³n:</strong> Test de funciÃ³n/mÃ©todo individual en aislamiento.</p>
<pre><code class="language-python">def test_feature_ratio():
    result = compute_ratio(100, 2)
    assert result == 50
</code></pre>
<h3>Uvicorn</h3>
<p><strong>DefiniciÃ³n:</strong> Servidor ASGI de alto rendimiento para FastAPI.</p>
<pre><code class="language-bash">uvicorn app:app --host 0.0.0.0 --port 8000
</code></pre>
<h2>V</h2>
<h3>Validation Set</h3>
<p><strong>DefiniciÃ³n:</strong> Datos para ajustar hiperparÃ¡metros, separado de train y test.</p>
<p><strong>Split tÃ­pico:</strong> 60% train, 20% validation, 20% test</p>
<h3>Vendor Lock-in</h3>
<p><strong>DefiniciÃ³n:</strong> Dependencia de proveedor especÃ­fico que dificulta migraciÃ³n.</p>
<p><strong>AnalogÃ­a:</strong> Comprar auto donde repuestos solo existen en una tienda.</p>
<h3>Version Control</h3>
<p><strong>DefiniciÃ³n:</strong> Sistema para rastrear cambios en archivos.</p>
<p><strong>Herramientas:</strong> Git (cÃ³digo), DVC (datos), MLflow (modelos)</p>
<h3>Voting Classifier</h3>
<p><strong>DefiniciÃ³n:</strong> Ensemble que combina predicciones por votaciÃ³n.</p>
<pre><code class="language-python">VotingClassifier([
    ('rf', RandomForestClassifier()),
    ('xgb', XGBClassifier())
], voting='soft')
</code></pre>
<h2>W</h2>
<h3>Weights &amp; Biases (W&amp;B)</h3>
<p><strong>DefiniciÃ³n:</strong> Plataforma SaaS para experiment tracking con visualizaciones avanzadas.</p>
<p><strong>Relacionados:</strong> MLflow, Experiment Tracking</p>
<h3>Workflow (GitHub Actions)</h3>
<p><strong>DefiniciÃ³n:</strong> Proceso automatizado definido en archivo YAML.</p>
<p><strong>Relacionados:</strong> Job, Step, CI/CD</p>
<h2>X</h2>
<h3>XGBoost</h3>
<p><strong>DefiniciÃ³n:</strong> ImplementaciÃ³n optimizada de gradient boosting. Muy popular en competencias.</p>
<pre><code class="language-python">from xgboost import XGBClassifier
model = XGBClassifier(n_estimators=100, learning_rate=0.1)
</code></pre>
<h2>Y</h2>
<h3>YAML</h3>
<p><strong>DefiniciÃ³n:</strong> Formato de serializaciÃ³n legible para configuraciÃ³n.</p>
<pre><code class="language-yaml">model:
  type: ensemble
  n_estimators: 100
</code></pre>
<h2>Z</h2>
<h3>Zero-Downtime Deployment</h3>
<p><strong>DefiniciÃ³n:</strong> Actualizar aplicaciÃ³n sin interrumpir servicio.</p>
<p><strong>TÃ©cnicas:</strong> Rolling update, Blue-green deployment</p>
<h2>SÃ­mbolos y Abreviaciones</h2>
<table>
<thead>
<tr>
<th>SÃ­mbolo</th>
<th>Significado</th>
</tr>
</thead>
<tbody>
<tr>
<td>TP</td>
<td>True Positive</td>
</tr>
<tr>
<td>TN</td>
<td>True Negative</td>
</tr>
<tr>
<td>FP</td>
<td>False Positive</td>
</tr>
<tr>
<td>FN</td>
<td>False Negative</td>
</tr>
<tr>
<td>P95</td>
<td>Percentil 95</td>
</tr>
<tr>
<td>GHCR</td>
<td>GitHub Container Registry</td>
</tr>
<tr>
<td>IaC</td>
<td>Infrastructure as Code</td>
</tr>
<tr>
<td>DAG</td>
<td>Directed Acyclic Graph</td>
</tr>
<tr>
<td>OOM</td>
<td>Out of Memory</td>
</tr>
<tr>
<td>CRUD</td>
<td>Create, Read, Update, Delete</td>
</tr>
<tr>
<td>SLA</td>
<td>Service Level Agreement</td>
</tr>
<tr>
<td>SLO</td>
<td>Service Level Objective</td>
</tr>
<tr>
<td>TTL</td>
<td>Time To Live</td>
</tr>
</tbody>
</table>
<h2>ğŸ“Š Tablas de Referencia RÃ¡pida</h2>
<h3>MÃ©tricas de ClasificaciÃ³n</h3>
<table>
<thead>
<tr>
<th>MÃ©trica</th>
<th>FÃ³rmula</th>
<th>Uso</th>
</tr>
</thead>
<tbody>
<tr>
<td>Accuracy</td>
<td>(TP+TN)/(Total)</td>
<td>Balance general (clases balanceadas)</td>
</tr>
<tr>
<td>Precision</td>
<td>TP/(TP+FP)</td>
<td>Minimizar falsos positivos</td>
</tr>
<tr>
<td>Recall</td>
<td>TP/(TP+FN)</td>
<td>Minimizar falsos negativos</td>
</tr>
<tr>
<td>F1</td>
<td>2Ã—PÃ—R/(P+R)</td>
<td>Balance P y R</td>
</tr>
<tr>
<td>AUC-ROC</td>
<td>Ãrea bajo curva</td>
<td>Capacidad discriminatoria</td>
</tr>
</tbody>
</table>
<h3>Tipos de Testing</h3>
<table>
<thead>
<tr>
<th>Tipo</th>
<th>Alcance</th>
<th>Ejemplo</th>
</tr>
</thead>
<tbody>
<tr>
<td>Unit</td>
<td>FunciÃ³n individual</td>
<td><code>test_compute_ratio()</code></td>
</tr>
<tr>
<td>Integration</td>
<td>MÃºltiples componentes</td>
<td><code>test_pipeline_fit()</code></td>
</tr>
<tr>
<td>E2E</td>
<td>Sistema completo</td>
<td><code>test_api_predict_flow()</code></td>
</tr>
</tbody>
</table>
<h3>Ambientes</h3>
<table>
<thead>
<tr>
<th>Ambiente</th>
<th>PropÃ³sito</th>
<th>Datos</th>
</tr>
</thead>
<tbody>
<tr>
<td>Development</td>
<td>Desarrollo</td>
<td>SintÃ©ticos/muestra</td>
</tr>
<tr>
<td>Staging</td>
<td>Testing final</td>
<td>RÃ©plica producciÃ³n</td>
</tr>
<tr>
<td>Production</td>
<td>Usuarios reales</td>
<td>Reales</td>
</tr>
</tbody>
</table>
<h3>NavegaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">â—€ï¸ Anterior</th>
<th style="text-align: center;">ğŸ“‘ Ãndice</th>
<th style="text-align: left;">â–¶ï¸ Siguiente</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="#mod_20_PROYECTO_INTEGRADOR">20_PROYECTO_INTEGRADOR.md</a></td>
<td style="text-align: center;"><a href="#mod_00_INDICE">Ãndice</a></td>
<td style="text-align: left;"><a href="#mod_22_CHECKLIST">22_CHECKLIST.md</a></td>
</tr>
</tbody>
</table>
<p><em>Â© 2025 DuqueOM - GuÃ­a MLOps v5.0: Senior Edition</em></p>
<p><strong>MÃ³dulo 21 Completado</strong> âœ…</p>
            </div>
        
            <!-- MÃ“DULO: 22_CHECKLIST.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_22_CHECKLIST" class="cover-title">CHECKLIST</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 22: CHECKLIST FINAL</h1>
<h1>VerificaciÃ³n del Portafolio</h1>
<h1>GuÃ­a MLOps v2.0 | DuqueOM | Noviembre 2025</h1>
<h1>âœ… MÃ“DULO 22: Checklist Final</h1>
<p><strong>VerificaciÃ³n del Portafolio</strong></p>
<p><em>"La calidad se verifica, no se asume."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Nivel</th>
<th style="text-align: center;">DuraciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ“š Referencia</td>
<td style="text-align: center;">1 hora</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ Objetivo</h2>
<p>Lista de verificaciÃ³n completa para asegurar que tu portafolio MLOps estÃ¡ listo para presentar.</p>
<h2>âœ… Checklist Pre-Release</h2>
<h3>1. Repositorio y Estructura</h3>
<pre><code class="language-markdown">## Estructura del Repo
- [ ] README.md completo con badges
- [ ] LICENSE presente (MIT recomendado)
- [ ] .gitignore apropiado para Python/ML
- [ ] Estructura de carpetas profesional
- [ ] Cada proyecto tiene su propio README

## Versionado
- [ ] Commits con formato convencional
- [ ] Branches organizados (main, develop)
- [ ] Tags para releases
- [ ] CHANGELOG.md actualizado
</code></pre>
<h3>2. CÃ³digo y Calidad</h3>
<pre><code class="language-markdown">## CÃ³digo
- [ ] CÃ³digo modular (src/proyecto/)
- [ ] ConfiguraciÃ³n con Pydantic (config.py)
- [ ] Logging implementado
- [ ] Type hints en funciones principales
- [ ] Docstrings en clases y funciones pÃºblicas

## Estilo
- [ ] Formateado con Black
- [ ] Imports ordenados con isort
- [ ] Sin errores crÃ­ticos de flake8
- [ ] Sin warnings de mypy (o justificados)
</code></pre>
<h3>3. Datos</h3>
<pre><code class="language-markdown">## Versionado de Datos
- [ ] DVC inicializado
- [ ] Datasets versionados
- [ ] Remote configurado (local o cloud)
- [ ] .dvc files commiteados
- [ ] dvc.yaml con pipeline definido

## DocumentaciÃ³n de Datos
- [ ] Data Card presente
- [ ] DescripciÃ³n de features
- [ ] DistribuciÃ³n de target documentada
</code></pre>
<h3>4. Modelo y Pipeline</h3>
<pre><code class="language-markdown">## Pipeline ML
- [ ] Pipeline sklearn unificado
- [ ] Preprocessor incluido en pipeline
- [ ] Modelo serializable con joblib
- [ ] Reproducibilidad verificada (seeds)

## Tracking
- [ ] MLflow configurado
- [ ] ParÃ¡metros logueados
- [ ] MÃ©tricas logueadas
- [ ] Modelos registrados como artefactos
</code></pre>
<h3>5. Testing</h3>
<pre><code class="language-markdown">## Tests
- [ ] tests/conftest.py con fixtures
- [ ] Tests unitarios (test_*.py)
- [ ] Tests de integraciÃ³n
- [ ] Tests de API
- [ ] Coverage â‰¥ 70%

## EjecuciÃ³n
- [ ] pytest ejecuta sin errores
- [ ] pytest --cov reporta coverage
- [ ] Tests son independientes (no orden)
- [ ] Tests rÃ¡pidos (&lt;30s total)
</code></pre>
<h3>6. CI/CD</h3>
<pre><code class="language-markdown">## GitHub Actions
- [ ] .github/workflows/ci.yml presente
- [ ] Jobs: lint, test, build
- [ ] Matrix testing (Python 3.11, 3.12)
- [ ] Badge de CI en README
- [ ] Pipeline pasa en verde

## Seguridad
- [ ] Bandit scan sin HIGH severity
- [ ] Gitleaks configurado
- [ ] No secrets en cÃ³digo
- [ ] .env.example presente (no .env)
</code></pre>
<h3>7. Docker</h3>
<pre><code class="language-markdown">## Dockerfile
- [ ] Multi-stage build
- [ ] Usuario no-root
- [ ] .dockerignore presente
- [ ] Imagen &lt; 1GB (idealmente &lt; 500MB)
- [ ] HEALTHCHECK configurado

## Compose
- [ ] docker-compose.yml funcional
- [ ] Servicios se levantan correctamente
- [ ] Health checks pasan
- [ ] Puertos documentados
</code></pre>
<h3>8. API</h3>
<pre><code class="language-markdown">## FastAPI
- [ ] /health endpoint
- [ ] /predict endpoint
- [ ] ValidaciÃ³n con Pydantic
- [ ] DocumentaciÃ³n en /docs
- [ ] CORS configurado

## Funcionamiento
- [ ] API responde correctamente
- [ ] Predicciones son vÃ¡lidas
- [ ] Errores tienen mensajes claros
- [ ] Latencia &lt; 100ms
</code></pre>
<h3>9. DocumentaciÃ³n</h3>
<pre><code class="language-markdown">## README Principal
- [ ] DescripciÃ³n clara del proyecto
- [ ] Quick Start funcional
- [ ] Instrucciones de instalaciÃ³n
- [ ] Ejemplos de uso
- [ ] Badges de CI, coverage, etc.

## Model Card
- [ ] Model Details completos
- [ ] Intended Use documentado
- [ ] MÃ©tricas de performance
- [ ] Limitaciones explÃ­citas
- [ ] Consideraciones Ã©ticas
</code></pre>
<h3>10. Demo</h3>
<pre><code class="language-markdown">## Video Demo
- [ ] DuraciÃ³n 3-5 minutos
- [ ] IntroducciÃ³n del problema
- [ ] Muestra estructura del cÃ³digo
- [ ] Demo en vivo funcionando
- [ ] CI/CD pipeline visible
- [ ] Cierre con call-to-action
</code></pre>
<h2>ğŸ” VerificaciÃ³n Final</h2>
<h3>Comandos de ValidaciÃ³n</h3>
<pre><code class="language-bash"># 1. Clone limpio
cd /tmp
git clone https://github.com/USUARIO/REPO.git
cd REPO

# 2. Instalar y testear
pip install -e &quot;.[dev]&quot;
pytest tests/ -v --cov=src

# 3. Lint
black --check src/
flake8 src/ --select=E9,F63,F7,F82

# 4. Docker
docker build -t test-image .
docker run --rm -d -p 8000:8000 test-image
sleep 10
curl http://localhost:8000/health

# 5. DVC
dvc status
dvc repro --dry

# 6. MLflow
mlflow ui --port 5000 &amp;
# Verificar UI en http://localhost:5000
</code></pre>
<h3>Criterios de AprobaciÃ³n</h3>
<table>
<thead>
<tr>
<th>Criterio</th>
<th>MÃ­nimo</th>
<th>Ideal</th>
</tr>
</thead>
<tbody>
<tr>
<td>Coverage</td>
<td>70%</td>
<td>85%+</td>
</tr>
<tr>
<td>Latencia API</td>
<td>&lt;200ms</td>
<td>&lt;50ms</td>
</tr>
<tr>
<td>TamaÃ±o Docker</td>
<td>&lt;1GB</td>
<td>&lt;500MB</td>
</tr>
<tr>
<td>Tests</td>
<td>10+</td>
<td>30+</td>
</tr>
<tr>
<td>CI tiempo</td>
<td>&lt;10min</td>
<td>&lt;5min</td>
</tr>
</tbody>
</table>
<h2>ğŸ“‹ Checklist por Proyecto</h2>
<h3>BankChurn-Predictor</h3>
<pre><code class="language-markdown">- [ ] src/bankchurn/ modular
- [ ] VotingClassifier implementado
- [ ] CalibraciÃ³n de probabilidades
- [ ] Tests de fairness
- [ ] API /predict funcional
- [ ] Model Card con mÃ©tricas
</code></pre>
<h3>CarVision-Market-Intelligence</h3>
<pre><code class="language-markdown">- [ ] FeatureEngineer centralizado
- [ ] Pipeline [features, pre, model]
- [ ] Streamlit dashboard
- [ ] FastAPI backend
- [ ] Data leakage prevenido
- [ ] Bootstrap confidence intervals
</code></pre>
<h3>TelecomAI-Customer-Intelligence</h3>
<pre><code class="language-markdown">- [ ] ClasificaciÃ³n multi-estrategia
- [ ] VotingClassifier configurado
- [ ] Pipeline end-to-end
- [ ] Tests de integraciÃ³n
- [ ] API documentada
</code></pre>
<h2>ğŸš€ Pre-Push Checklist</h2>
<p>Antes de cada push importante:</p>
<pre><code class="language-markdown">## Quick Check
- [ ] `pytest` pasa
- [ ] `black --check .` pasa
- [ ] `flake8 src/` sin errores crÃ­ticos
- [ ] `docker build` funciona
- [ ] Commit message es descriptivo
- [ ] No hay archivos sensibles staged
</code></pre>
<h2>ğŸ“Š Scorecard de Portafolio</h2>
<h3>Auto-evaluaciÃ³n (0-10 por Ã­tem)</h3>
<table>
<thead>
<tr>
<th>CategorÃ­a</th>
<th>PuntuaciÃ³n</th>
<th>Notas</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CÃ³digo</strong></td>
<td>/10</td>
<td>Modularidad, estilo, documentaciÃ³n</td>
</tr>
<tr>
<td><strong>Testing</strong></td>
<td>/10</td>
<td>Coverage, variedad de tests</td>
</tr>
<tr>
<td><strong>CI/CD</strong></td>
<td>/10</td>
<td>AutomatizaciÃ³n, velocidad</td>
</tr>
<tr>
<td><strong>Docker</strong></td>
<td>/10</td>
<td>OptimizaciÃ³n, seguridad</td>
</tr>
<tr>
<td><strong>API</strong></td>
<td>/10</td>
<td>Funcionalidad, documentaciÃ³n</td>
</tr>
<tr>
<td><strong>Datos</strong></td>
<td>/10</td>
<td>Versionado, documentaciÃ³n</td>
</tr>
<tr>
<td><strong>ML</strong></td>
<td>/10</td>
<td>Pipeline, mÃ©tricas, tracking</td>
</tr>
<tr>
<td><strong>Docs</strong></td>
<td>/10</td>
<td>README, Model Cards</td>
</tr>
<tr>
<td><strong>Demo</strong></td>
<td>/10</td>
<td>Video, presentaciÃ³n</td>
</tr>
<tr>
<td><strong>Profesionalismo</strong></td>
<td>/10</td>
<td>Consistencia, atenciÃ³n al detalle</td>
</tr>
</tbody>
</table>
<p><strong>Total: /100</strong></p>
<h3>Niveles</h3>
<table>
<thead>
<tr>
<th>PuntuaciÃ³n</th>
<th>Nivel</th>
</tr>
</thead>
<tbody>
<tr>
<td>90-100</td>
<td>ğŸ† Excepcional - Listo para entrevistas senior</td>
</tr>
<tr>
<td>80-89</td>
<td>â­ Excelente - Muy competitivo</td>
</tr>
<tr>
<td>70-79</td>
<td>âœ… Bueno - SÃ³lido para aplicar</td>
</tr>
<tr>
<td>60-69</td>
<td>ğŸ“ˆ Aceptable - Necesita mejoras menores</td>
</tr>
<tr>
<td>&lt;60</td>
<td>ğŸ”„ En progreso - Continuar trabajando</td>
</tr>
</tbody>
</table>
<h2>ğŸ¯ Acciones Post-Checklist</h2>
<h3>Si pasas todo:</h3>
<ol>
<li>âœ… Publicar en GitHub</li>
<li>âœ… AÃ±adir a LinkedIn</li>
<li>âœ… Incluir en CV</li>
<li>âœ… Compartir en comunidades</li>
</ol>
<h3>Si faltan items:</h3>
<ol>
<li>Priorizar items crÃ­ticos (tests, CI, docs)</li>
<li>Crear issues para items faltantes</li>
<li>Planificar sprints de mejora</li>
<li>Re-evaluar en 1 semana</li>
</ol>
<h3>NavegaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">â—€ï¸ Anterior</th>
<th style="text-align: center;">ğŸ“‘ Ãndice</th>
<th style="text-align: left;">â–¶ï¸ Siguiente</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a></td>
<td style="text-align: center;"><a href="#mod_00_INDICE">Ãndice</a></td>
<td style="text-align: left;"><a href="#mod_23_RECURSOS">23_RECURSOS.md</a></td>
</tr>
</tbody>
</table>
<p><em>Â© 2025 DuqueOM - GuÃ­a MLOps v3.0</em></p>
<p><strong>MÃ³dulo 22 Completado</strong> âœ…</p>
            </div>
        
            <!-- MÃ“DULO: 23_RECURSOS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_23_RECURSOS" class="cover-title">RECURSOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>MÃ“DULO 23: RECURSOS Y REFERENCIAS</h1>
<h1>Links, Cursos y Comunidades</h1>
<h1>GuÃ­a MLOps v2.0 | DuqueOM | Noviembre 2025</h1>
<h1>ğŸ”— MÃ“DULO 23: Recursos y Referencias</h1>
<p><strong>Links, Cursos y Comunidades</strong></p>
<p><em>"El aprendizaje nunca termina."</em></p>
<table>
<thead>
<tr>
<th style="text-align: center;">Nivel</th>
<th style="text-align: center;">DuraciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ“š Referencia</td>
<td style="text-align: center;">Consulta</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š Recursos Recomendados</h2>
<p>Esta lista contiene los recursos mÃ¡s valiosos para profundizar en cada Ã¡rea de MLOps.</p>
<blockquote>
<p>ğŸ“º <strong>Â¿Buscas recursos especÃ­ficos por mÃ³dulo?</strong> Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para videos, cursos y documentaciÃ³n curados para cada mÃ³dulo con sistema de clasificaciÃ³n ğŸ”´ğŸŸ¡ğŸŸ¢.</p>
<p>AdemÃ¡s de estos recursos externos, revisa tambiÃ©n los recursos internos de esta guÃ­a:<br />
<a href="#mod_PLANTILLAS">PLANTILLAS.md</a>, <a href="#mod_GUIA_AUDIOVISUAL">GUIA_AUDIOVISUAL.md</a> y los scripts<br />
<code>generate_pdfs.py</code> / <code>generate_audio.py</code> para exportar la guÃ­a a PDF y audio.</p>
</blockquote>
<h2>ğŸ“ Cursos y Programas</h2>
<h3>MLOps Fundamentales</h3>
<table>
<thead>
<tr>
<th>Recurso</th>
<th>Tipo</th>
<th>Nivel</th>
<th>Costo</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://madewithml.com/">Made With ML</a></td>
<td>Curso</td>
<td>Intermedio</td>
<td>Gratis</td>
</tr>
<tr>
<td><a href="https://fullstackdeeplearning.com/">Full Stack Deep Learning</a></td>
<td>Curso</td>
<td>Avanzado</td>
<td>Gratis</td>
</tr>
<tr>
<td><a href="https://github.com/DataTalksClub/mlops-zoomcamp">MLOps Zoomcamp</a></td>
<td>Bootcamp</td>
<td>Intermedio</td>
<td>Gratis</td>
</tr>
<tr>
<td><a href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops">Coursera MLOps Specialization</a></td>
<td>EspecializaciÃ³n</td>
<td>Intermedio</td>
<td>Pagado</td>
</tr>
</tbody>
</table>
<h3>Herramientas EspecÃ­ficas</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Recurso Oficial</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLflow</td>
<td><a href="https://mlflow.org/docs/latest/index.html">Docs</a></td>
</tr>
<tr>
<td>DVC</td>
<td><a href="https://dvc.org/doc">Docs</a></td>
</tr>
<tr>
<td>FastAPI</td>
<td><a href="https://fastapi.tiangolo.com/tutorial/">Tutorial</a></td>
</tr>
<tr>
<td>Docker</td>
<td><a href="https://docs.docker.com/get-started/">Docs</a></td>
</tr>
<tr>
<td>Kubernetes</td>
<td><a href="https://kubernetes.io/docs/tutorials/">Docs</a></td>
</tr>
<tr>
<td>GitHub Actions</td>
<td><a href="https://docs.github.com/en/actions">Docs</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“– Libros</h2>
<h3>Esenciales</h3>
<table>
<thead>
<tr>
<th>TÃ­tulo</th>
<th>Autor</th>
<th>Tema</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Designing Machine Learning Systems</strong></td>
<td>Chip Huyen</td>
<td>MLOps end-to-end</td>
</tr>
<tr>
<td><strong>Building Machine Learning Pipelines</strong></td>
<td>Hapke &amp; Nelson</td>
<td>Pipelines con TFX</td>
</tr>
<tr>
<td><strong>Machine Learning Engineering</strong></td>
<td>Andriy Burkov</td>
<td>PrÃ¡cticas de ML</td>
</tr>
<tr>
<td><strong>Reliable Machine Learning</strong></td>
<td>Cathy Chen et al.</td>
<td>ML en producciÃ³n</td>
</tr>
</tbody>
</table>
<h3>Python y Software Engineering</h3>
<table>
<thead>
<tr>
<th>TÃ­tulo</th>
<th>Autor</th>
<th>Tema</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Fluent Python</strong></td>
<td>Luciano Ramalho</td>
<td>Python avanzado</td>
</tr>
<tr>
<td><strong>Clean Code</strong></td>
<td>Robert C. Martin</td>
<td>CÃ³digo limpio</td>
</tr>
<tr>
<td><strong>The Pragmatic Programmer</strong></td>
<td>Hunt &amp; Thomas</td>
<td>Buenas prÃ¡cticas</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Blogs y ArtÃ­culos</h2>
<h3>Blogs de Empresas</h3>
<table>
<thead>
<tr>
<th>Empresa</th>
<th>Blog</th>
<th>Foco</th>
</tr>
</thead>
<tbody>
<tr>
<td>Netflix</td>
<td><a href="https://netflixtechblog.com/">Tech Blog</a></td>
<td>ML a escala</td>
</tr>
<tr>
<td>Uber</td>
<td><a href="https://eng.uber.com/">Engineering Blog</a></td>
<td>ML en tiempo real</td>
</tr>
<tr>
<td>Airbnb</td>
<td><a href="https://medium.com/airbnb-engineering">Tech Blog</a></td>
<td>Feature stores</td>
</tr>
<tr>
<td>Spotify</td>
<td><a href="https://engineering.atspotify.com/">Engineering Blog</a></td>
<td>Recomendaciones</td>
</tr>
<tr>
<td>Google AI</td>
<td><a href="https://ai.googleblog.com/">Blog</a></td>
<td>InvestigaciÃ³n aplicada</td>
</tr>
</tbody>
</table>
<h3>ArtÃ­culos Fundamentales</h3>
<ol>
<li><strong>Model Cards</strong></li>
<li><a href="https://arxiv.org/abs/1810.03993">Model Cards for Model Reporting</a> - Mitchell et al.</li>
<li>
<p><a href="https://huggingface.co/docs/hub/model-cards">Hugging Face Model Cards Guide</a></p>
</li>
<li>
<p><strong>MLOps</strong></p>
</li>
<li><a href="https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf">Hidden Technical Debt in ML Systems</a> - Google</li>
<li>
<p><a href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning">Continuous Delivery for ML</a></p>
</li>
<li>
<p><strong>Testing ML</strong></p>
</li>
<li><a href="https://www.jeremyjordan.me/testing-ml/">Testing ML Systems</a> - Jeremy Jordan</li>
<li><a href="https://www.thoughtworks.com/insights/articles/testing-strategies-for-machine-learning-systems">Effective Testing for ML</a></li>
</ol>
<h2>ğŸ› ï¸ Herramientas por CategorÃ­a</h2>
<h3>Tracking de Experimentos</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLflow</td>
<td>Open Source</td>
<td><a href="https://mlflow.org/">mlflow.org</a></td>
</tr>
<tr>
<td>Weights &amp; Biases</td>
<td>SaaS</td>
<td><a href="https://wandb.ai/">wandb.ai</a></td>
</tr>
<tr>
<td>Neptune</td>
<td>SaaS</td>
<td><a href="https://neptune.ai/">neptune.ai</a></td>
</tr>
<tr>
<td>Comet</td>
<td>SaaS</td>
<td><a href="https://www.comet.ml/">comet.ml</a></td>
</tr>
<tr>
<td>DVC</td>
<td>Open Source</td>
<td><a href="https://dvc.org/">dvc.org</a></td>
</tr>
</tbody>
</table>
<h3>Feature Stores</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feast</td>
<td>Open Source</td>
<td><a href="https://feast.dev/">feast.dev</a></td>
</tr>
<tr>
<td>Tecton</td>
<td>SaaS</td>
<td><a href="https://www.tecton.ai/">tecton.ai</a></td>
</tr>
<tr>
<td>Hopsworks</td>
<td>HÃ­brido</td>
<td><a href="https://www.hopsworks.ai/">hopsworks.ai</a></td>
</tr>
</tbody>
</table>
<h3>Monitoreo de Modelos</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Evidently</td>
<td>Open Source</td>
<td><a href="https://evidentlyai.com/">evidentlyai.com</a></td>
</tr>
<tr>
<td>WhyLabs</td>
<td>SaaS</td>
<td><a href="https://whylabs.ai/">whylabs.ai</a></td>
</tr>
<tr>
<td>Arize</td>
<td>SaaS</td>
<td><a href="https://arize.com/">arize.com</a></td>
</tr>
<tr>
<td>NannyML</td>
<td>Open Source</td>
<td><a href="https://nannyml.com/">nannyml.com</a></td>
</tr>
</tbody>
</table>
<h3>CI/CD para ML</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>GitHub Actions</td>
<td>SaaS</td>
<td><a href="https://github.com/features/actions">github.com/features/actions</a></td>
</tr>
<tr>
<td>GitLab CI</td>
<td>SaaS/Self</td>
<td><a href="https://docs.gitlab.com/ee/ci/">docs.gitlab.com/ee/ci/</a></td>
</tr>
<tr>
<td>CML</td>
<td>Open Source</td>
<td><a href="https://cml.dev/">cml.dev</a></td>
</tr>
<tr>
<td>Kubeflow Pipelines</td>
<td>Open Source</td>
<td><a href="https://www.kubeflow.org/">kubeflow.org</a></td>
</tr>
</tbody>
</table>
<h3>Serving de Modelos</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>FastAPI</td>
<td>Open Source</td>
<td><a href="https://fastapi.tiangolo.com/">fastapi.tiangolo.com</a></td>
</tr>
<tr>
<td>BentoML</td>
<td>Open Source</td>
<td><a href="https://www.bentoml.com/">bentoml.com</a></td>
</tr>
<tr>
<td>Seldon</td>
<td>Open Source</td>
<td><a href="https://www.seldon.io/">seldon.io</a></td>
</tr>
<tr>
<td>TensorFlow Serving</td>
<td>Open Source</td>
<td><a href="https://www.tensorflow.org/tfx/guide/serving">tensorflow.org/tfx/guide/serving</a></td>
</tr>
<tr>
<td>Triton</td>
<td>Open Source</td>
<td><a href="https://developer.nvidia.com/triton-inference-server">developer.nvidia.com/triton-inference-server</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“º Videos y Charlas</h2>
<h3>Conferencias</h3>
<table>
<thead>
<tr>
<th>Conferencia</th>
<th>Foco</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLOps World</td>
<td>MLOps</td>
<td><a href="https://mlopsworld.com/">mlopsworld.com</a></td>
</tr>
<tr>
<td>ML Conf</td>
<td>ML Engineering</td>
<td><a href="https://mlconf.com/">mlconf.com</a></td>
</tr>
<tr>
<td>PyData</td>
<td>Python + Data</td>
<td><a href="https://pydata.org/">pydata.org</a></td>
</tr>
<tr>
<td>KubeCon</td>
<td>Kubernetes</td>
<td><a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/">kubecon.io</a></td>
</tr>
</tbody>
</table>
<h3>Charlas Recomendadas</h3>
<ol>
<li><strong>MLOps Overview</strong></li>
<li><a href="https://www.youtube.com/watch?v=NGiqH8Qy-aI">Practical MLOps</a> - Stanford</li>
<li>
<p><a href="https://www.youtube.com/watch?v=06-AZXmwHjo">ML Engineering at Google</a></p>
</li>
<li>
<p><strong>Testing ML</strong></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=k9Ed5J_-Fow">Testing ML Systems</a> - PyCon</p>
</li>
<li>
<p><strong>Production ML</strong></p>
</li>
<li><a href="https://www.youtube.com/watch?v=UYjDFpxrPzY">ML at Scale</a> - Netflix</li>
</ol>
<h2>ğŸ™ Repositorios de Referencia</h2>
<h3>Plantillas y Ejemplos</h3>
<table>
<thead>
<tr>
<th>Repositorio</th>
<th>DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/drivendata/cookiecutter-data-science">cookiecutter-data-science</a></td>
<td>Plantilla de proyectos DS</td>
</tr>
<tr>
<td><a href="https://github.com/fmind/mlops-python-package">mlops-python-package</a></td>
<td>Plantilla MLOps</td>
</tr>
<tr>
<td><a href="https://github.com/GokuMohandas/Made-With-ML">made-with-ml</a></td>
<td>Curso completo</td>
</tr>
<tr>
<td><a href="https://github.com/DataTalksClub/mlops-zoomcamp">mlops-zoomcamp</a></td>
<td>Bootcamp MLOps</td>
</tr>
</tbody>
</table>
<h3>Proyectos de Referencia</h3>
<table>
<thead>
<tr>
<th>Repositorio</th>
<th>Destacado</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/DuqueOM/ML-MLOps-Portfolio">DuqueOM/ML-MLOps-Portfolio</a></td>
<td>Este portafolio</td>
</tr>
<tr>
<td><a href="https://github.com/kedro-org/kedro">kedro</a></td>
<td>Framework de pipelines</td>
</tr>
<tr>
<td><a href="https://github.com/feast-dev/feast">feast</a></td>
<td>Feature store</td>
</tr>
<tr>
<td><a href="https://github.com/evidentlyai/evidently">evidently</a></td>
<td>Monitoreo de drift</td>
</tr>
</tbody>
</table>
<h2>ğŸ“‹ Cheat Sheets</h2>
<h3>Git</h3>
<ul>
<li><a href="https://education.github.com/git-cheat-sheet-education.pdf">Git Cheat Sheet (GitHub)</a></li>
<li><a href="https://danielkummer.github.io/git-flow-cheatsheet/">Git Flow</a></li>
</ul>
<h3>Docker</h3>
<ul>
<li><a href="https://dockerlabs.collabnix.com/docker/cheatsheet/">Docker Cheat Sheet</a></li>
<li><a href="https://devhints.io/docker-compose">Docker Compose</a></li>
</ul>
<h3>Kubernetes</h3>
<ul>
<li><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">kubectl Cheat Sheet</a></li>
</ul>
<h3>Python</h3>
<ul>
<li><a href="https://www.pythoncheatsheet.org/">Python Cheat Sheet</a></li>
<li><a href="https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf">Pandas Cheat Sheet</a></li>
</ul>
<h2>ğŸ¯ Rutas de Aprendizaje</h2>
<h3>Ruta Principiante (2-3 meses)</h3>
<pre><code>1. Python bÃ¡sico â†’ intermedio
2. Git y GitHub
3. pandas y sklearn
4. pytest bÃ¡sico
5. Docker fundamentals
</code></pre>
<h3>Ruta Intermedia (3-4 meses)</h3>
<pre><code>1. Pipelines sklearn avanzados
2. MLflow tracking
3. DVC para datos
4. FastAPI
5. GitHub Actions CI/CD
6. Testing completo
</code></pre>
<h3>Ruta Avanzada (4-6 meses)</h3>
<pre><code>1. Kubernetes
2. Terraform / IaC
3. Feature stores
4. Monitoreo de drift
5. A/B testing
6. Auto-retraining
</code></pre>
<h2>ğŸ“¬ Comunidades</h2>
<h3>Discord/Slack</h3>
<table>
<thead>
<tr>
<th>Comunidad</th>
<th>Foco</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLOps Community</td>
<td>MLOps</td>
<td><a href="https://mlops.community/">mlops.community</a></td>
</tr>
<tr>
<td>DataTalks.Club</td>
<td>Data Engineering</td>
<td><a href="https://datatalks.club/">datatalks.club</a></td>
</tr>
<tr>
<td>Locally Optimistic</td>
<td>Data Teams</td>
<td><a href="https://locallyoptimistic.com/">locallyoptimistic.com</a></td>
</tr>
</tbody>
</table>
<h3>Reddit</h3>
<ul>
<li>r/MachineLearning</li>
<li>r/learnmachinelearning</li>
<li>r/datascience</li>
<li>r/MLOps</li>
</ul>
<h3>Twitter/X</h3>
<p>Cuentas recomendadas:<br />
- @ChipHuyen<br />
- @kaboroevich<br />
- @eugeneyan<br />
- @sh_reya</p>
<h2>ğŸ”§ Herramientas de Productividad</h2>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Uso</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Notion</td>
<td>DocumentaciÃ³n</td>
<td><a href="https://notion.so/">notion.so</a></td>
</tr>
<tr>
<td>Obsidian</td>
<td>Notas</td>
<td><a href="https://obsidian.md/">obsidian.md</a></td>
</tr>
<tr>
<td>Excalidraw</td>
<td>Diagramas</td>
<td><a href="https://excalidraw.com/">excalidraw.com</a></td>
</tr>
<tr>
<td>Mermaid</td>
<td>Diagramas en cÃ³digo</td>
<td><a href="https://mermaid.js.org/">mermaid.js.org</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“Š Datasets para Practicar</h2>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Tipo</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kaggle</td>
<td>Variado</td>
<td><a href="https://www.kaggle.com/datasets">kaggle.com/datasets</a></td>
</tr>
<tr>
<td>UCI ML Repository</td>
<td>ClÃ¡sicos</td>
<td><a href="https://archive.ics.uci.edu/ml/index.php">archive.ics.uci.edu/ml</a></td>
</tr>
<tr>
<td>Hugging Face Datasets</td>
<td>NLP/CV</td>
<td><a href="https://huggingface.co/datasets">huggingface.co/datasets</a></td>
</tr>
<tr>
<td>Google Dataset Search</td>
<td>BÃºsqueda</td>
<td><a href="https://datasetsearch.research.google.com/">datasetsearch.research.google.com</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“… Mantente Actualizado</h2>
<h3>Newsletters</h3>
<table>
<thead>
<tr>
<th>Newsletter</th>
<th>Foco</th>
<th>Frecuencia</th>
</tr>
</thead>
<tbody>
<tr>
<td>The Batch</td>
<td>AI General</td>
<td>Semanal</td>
</tr>
<tr>
<td>MLOps Community</td>
<td>MLOps</td>
<td>Semanal</td>
</tr>
<tr>
<td>Data Elixir</td>
<td>Data Science</td>
<td>Semanal</td>
</tr>
<tr>
<td>Python Weekly</td>
<td>Python</td>
<td>Semanal</td>
</tr>
</tbody>
</table>
<h3>Podcasts</h3>
<table>
<thead>
<tr>
<th>Podcast</th>
<th>Foco</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLOps Coffee Sessions</td>
<td>MLOps</td>
</tr>
<tr>
<td>Practical AI</td>
<td>ML aplicado</td>
</tr>
<tr>
<td>Data Engineering Podcast</td>
<td>Data infra</td>
</tr>
<tr>
<td>Talk Python To Me</td>
<td>Python</td>
</tr>
</tbody>
</table>
<h3>Recursos Relacionados</h3>
<table>
<thead>
<tr>
<th>Recurso</th>
<th>DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td>ğŸ“º <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a></td>
<td>Videos y cursos especÃ­ficos para cada mÃ³dulo</td>
</tr>
<tr>
<td>ğŸ“‹ <a href="#mod_PLANTILLAS">PLANTILLAS.md</a></td>
<td>Templates reutilizables</td>
</tr>
</tbody>
</table>
<h3>NavegaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">â—€ï¸ Anterior</th>
<th style="text-align: center;">ğŸ“‘ Ãndice</th>
<th style="text-align: left;">ğŸ¯ Final</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="#mod_22_CHECKLIST">22_CHECKLIST.md</a></td>
<td style="text-align: center;"><a href="#mod_00_INDICE">Ãndice</a></td>
<td style="text-align: left;">ğŸ‰ Â¡GuÃ­a Completada!</td>
</tr>
</tbody>
</table>
<p><em>Â© 2025 DuqueOM - GuÃ­a MLOps v3.0</em></p>
<p><strong>MÃ³dulo 23 Completado</strong> âœ…</p>
<p><strong>ğŸ‰ Â¡FELICITACIONES! Has completado toda la guÃ­a MLOps.</strong></p>
            </div>
        
            <!-- MÃ“DULO: RECURSOS_POR_MODULO.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_RECURSOS_POR_MODULO" class="cover-title">RECURSOS POR MÃ“DULO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“š Recursos Externos por MÃ³dulo â€” GuÃ­a MLOps</h1>
<blockquote>
<p><strong>Videos, cursos y materiales externos curados e integrados con cada mÃ³dulo</strong></p>
</blockquote>
<p><strong>Ãšltima actualizaciÃ³n</strong>: Diciembre 2025<br />
<strong>Sistema de clasificaciÃ³n</strong>: ğŸ”´ Obligatorio | ğŸŸ¡ Recomendado | ğŸŸ¢ Complementario</p>
<h2>ğŸ·ï¸ Sistema de Etiquetas</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Etiqueta</th>
<th style="text-align: left;">Significado</th>
<th style="text-align: left;">CuÃ¡ndo Usarlo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´ <strong>Obligatorio</strong></td>
<td style="text-align: left;">Esencial para entender el mÃ³dulo</td>
<td style="text-align: left;">Si tienes dudas conceptuales despuÃ©s de leer el mÃ³dulo</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡ <strong>Recomendado</strong></td>
<td style="text-align: left;">Profundiza significativamente el tema</td>
<td style="text-align: left;">Si quieres dominar el tema, no solo entenderlo</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢ <strong>Complementario</strong></td>
<td style="text-align: left;">Perspectiva adicional o avanzada</td>
<td style="text-align: left;">Si ya dominas lo bÃ¡sico y quieres mÃ¡s</td>
</tr>
</tbody>
</table>
<h2>ğŸ“‹ Ãndice RÃ¡pido</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Tema</th>
<th style="text-align: center;">Videos</th>
<th style="text-align: center;">Cursos</th>
<th style="text-align: center;">Docs</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">01</td>
<td style="text-align: left;">Python Moderno</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td style="text-align: left;">DiseÃ±o de Sistemas</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td style="text-align: left;">Estructura de Proyecto</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td style="text-align: left;">Entornos Virtuales</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td style="text-align: left;">Git Profesional</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td style="text-align: left;">Versionado de Datos</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td style="text-align: left;">sklearn Pipelines</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td style="text-align: left;">Feature Engineering</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td style="text-align: left;">Training Profesional</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: left;">Experiment Tracking</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: left;">Testing ML</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: left;">CI/CD</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: left;">Docker</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td style="text-align: left;">FastAPI</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">15</td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: left;">Observabilidad</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">17</td>
<td style="text-align: left;">Despliegue</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">18</td>
<td style="text-align: left;">Infraestructura</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 01: Python Moderno</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Type Hints in Python</strong></td>
<td style="text-align: left;">ArjanCodes</td>
<td style="text-align: center;">18 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=QORvB-_mbZ0">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Pydantic V2: The Complete Guide</strong></td>
<td style="text-align: left;">ArjanCodes</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=502XOB0u8OY">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Python OOP - Classes and Objects</strong></td>
<td style="text-align: left;">Corey Schafer</td>
<td style="text-align: center;">15 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=ZDa-Z5JzLYM">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;">Modern Python 3 Bootcamp</td>
<td style="text-align: left;">Udemy</td>
<td style="text-align: center;">30h</td>
<td style="text-align: left;"><a href="https://www.udemy.com/course/the-modern-python3-bootcamp/">Udemy</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.pydantic.dev/">Pydantic Docs</a></td>
<td style="text-align: left;">DocumentaciÃ³n oficial de Pydantic V2</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://docs.python.org/3/library/typing.html">typing Module</a></td>
<td style="text-align: left;">DocumentaciÃ³n de type hints</td>
</tr>
</tbody>
</table>
<h3>ğŸ’¡ CuÃ¡ndo Consultar</h3>
<ul>
<li><strong>Antes de empezar</strong>: Ve el video de Type Hints si no los usas regularmente</li>
<li><strong>Durante el mÃ³dulo</strong>: Consulta Pydantic docs cuando trabajes con <code>config.py</code></li>
<li><strong>DespuÃ©s</strong>: El curso complementario si quieres profundizar en POO</li>
</ul>
<h2>ğŸ“– MÃ³dulo 02: DiseÃ±o de Sistemas ML</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>ML System Design Interview</strong></td>
<td style="text-align: left;">Exponent</td>
<td style="text-align: center;">22 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=C9ABKzpIknM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Designing ML Systems (Chip Huyen)</strong></td>
<td style="text-align: left;">Stanford MLSys</td>
<td style="text-align: center;">55 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=yoT9ZfECbj4">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Machine Learning System Design</td>
<td style="text-align: left;">Educative.io</td>
<td style="text-align: center;">8h</td>
<td style="text-align: left;"><a href="https://www.educative.io/courses/machine-learning-system-design">Educative</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://www.ownml.co/machine-learning-canvas">ML Canvas Template</a></td>
<td style="text-align: left;">Canvas para diseÃ±o ML</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://adr.github.io/">ADR GitHub</a></td>
<td style="text-align: left;">GuÃ­a de Architecture Decision Records</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://c4model.com/">C4 Model</a></td>
<td style="text-align: left;">Modelo de diagramas de arquitectura</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 05: Git Profesional</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Git for Professionals</strong></td>
<td style="text-align: left;">freeCodeCamp</td>
<td style="text-align: center;">41 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=Uszj_k0DGsg">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Git Branching Strategies</strong></td>
<td style="text-align: left;">DevOps Toolkit</td>
<td style="text-align: center;">18 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=U_IFGpJDbeU">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Pre-commit Hooks Tutorial</strong></td>
<td style="text-align: left;">mCoding</td>
<td style="text-align: center;">12 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=psjz6rwzMdk">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;">Version Control with Git</td>
<td style="text-align: left;">Coursera (Atlassian)</td>
<td style="text-align: center;">13h</td>
<td style="text-align: left;"><a href="https://www.coursera.org/learn/version-control-with-git">Coursera</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 06: Versionado de Datos (DVC)</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>DVC Tutorial - Data Version Control</strong></td>
<td style="text-align: left;">DVCorg</td>
<td style="text-align: center;">12 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=kLKBcPonMYw">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>DVC Pipelines Deep Dive</strong></td>
<td style="text-align: left;">DVCorg</td>
<td style="text-align: center;">18 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=71IGzyH95UY">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>MLOps with DVC and CML</strong></td>
<td style="text-align: left;">DataTalksClub</td>
<td style="text-align: center;">45 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=9BgIDqAzfuA">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Iterative Tools for ML</td>
<td style="text-align: left;">DVCorg</td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;"><a href="https://learn.iterative.ai/">Learn.iterative.ai</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://dvc.org/doc/start">DVC Get Started</a></td>
<td style="text-align: left;">Tutorial oficial paso a paso</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://dvc.org/doc/user-guide/data-management/remote-storage">DVC with Remote Storage</a></td>
<td style="text-align: left;">ConfiguraciÃ³n de remotes S3/GCS</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 07: sklearn Pipelines</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Sklearn Pipeline Tutorial</strong></td>
<td style="text-align: left;">Data School</td>
<td style="text-align: center;">28 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=irHhDMbw3xo">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>ColumnTransformer Explained</strong></td>
<td style="text-align: left;">Data School</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=NGq8wnH5VSo">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Custom Transformers in Sklearn</strong></td>
<td style="text-align: left;">PyData</td>
<td style="text-align: center;">32 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=BFaadIqWlAg">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Sklearn Pipeline Best Practices</strong></td>
<td style="text-align: left;">PyData Berlin</td>
<td style="text-align: center;">45 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=0UWXCAYn8rk">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;">ML Pipelines with scikit-learn</td>
<td style="text-align: left;">DataCamp</td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;"><a href="https://www.datacamp.com/courses/machine-learning-with-scikit-learn">DataCamp</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Feature Engineering for ML</td>
<td style="text-align: left;">Coursera (Google)</td>
<td style="text-align: center;">5 weeks</td>
<td style="text-align: left;"><a href="https://www.coursera.org/learn/feature-engineering">Coursera</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://scikit-learn.org/stable/modules/compose.html">sklearn Pipeline User Guide</a></td>
<td style="text-align: left;">GuÃ­a oficial de pipelines</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://scikit-learn.org/stable/developers/develop.html">Custom Transformers</a></td>
<td style="text-align: left;">CÃ³mo crear transformers custom</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 10: Experiment Tracking (MLflow)</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>MLflow Tutorial (2024)</strong></td>
<td style="text-align: left;">DataTalksClub</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=MiA7LQin9c8">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>MLflow Model Registry</strong></td>
<td style="text-align: left;">Databricks</td>
<td style="text-align: center;">22 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=x3cxvsUFVZA">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>MLflow Projects and Models</strong></td>
<td style="text-align: left;">MLflow</td>
<td style="text-align: center;">28 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=859OxXrt_TI">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>MLflow + Docker Integration</strong></td>
<td style="text-align: left;">Databricks</td>
<td style="text-align: center;">18 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=G-6qCpSAzb8">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">End-to-End ML with MLflow</td>
<td style="text-align: left;">Databricks Academy</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;"><a href="https://www.databricks.com/learn/training/catalog">Databricks</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://mlflow.org/docs/latest/quickstart.html">MLflow Quickstart</a></td>
<td style="text-align: left;">Inicio rÃ¡pido oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://mlflow.org/docs/latest/tracking.html">MLflow Tracking Guide</a></td>
<td style="text-align: left;">GuÃ­a completa de tracking</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://mlflow.org/docs/latest/model-registry.html">MLflow Model Registry</a></td>
<td style="text-align: left;">Registro de modelos</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 11: Testing para ML</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>pytest Tutorial - Full Course</strong></td>
<td style="text-align: left;">freeCodeCamp</td>
<td style="text-align: center;">90 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=cHYq1MRoyI0">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Testing ML Models</strong></td>
<td style="text-align: left;">Made With ML</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=UvHnTJwGjuk">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>pytest Fixtures Deep Dive</strong></td>
<td style="text-align: left;">ArjanCodes</td>
<td style="text-align: center;">20 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=ScEQRKwUePI">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Property-Based Testing with Hypothesis</strong></td>
<td style="text-align: left;">PyCon</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=jvwfDdgg93E">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Testing ML Models</td>
<td style="text-align: left;">Made With ML</td>
<td style="text-align: center;">2h</td>
<td style="text-align: left;"><a href="https://madewithml.com/courses/mlops/testing/">MadeWithML</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.pytest.org/">pytest Documentation</a></td>
<td style="text-align: left;">DocumentaciÃ³n oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://pytest-cov.readthedocs.io/">pytest-cov</a></td>
<td style="text-align: left;">Plugin de coverage</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://docs.greatexpectations.io/">Great Expectations</a></td>
<td style="text-align: left;">Testing de datos</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 12: CI/CD con GitHub Actions</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>GitHub Actions Tutorial</strong></td>
<td style="text-align: left;">TechWorld with Nana</td>
<td style="text-align: center;">32 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=R8_veQiYBjI">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>CI/CD for ML Projects</strong></td>
<td style="text-align: left;">DataTalksClub</td>
<td style="text-align: center;">40 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=s8AjEfLTMaM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Matrix Strategy Deep Dive</strong></td>
<td style="text-align: left;">GitHub</td>
<td style="text-align: center;">15 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=4lO3t2Ns0Fc">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Security Scanning in CI</strong></td>
<td style="text-align: left;">GitHub Universe</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=0exXGqPR3dI">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">GitHub Actions</td>
<td style="text-align: left;">GitHub Learning Lab</td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;"><a href="https://github.com/skills/hello-github-actions">GitHub</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.github.com/en/actions">GitHub Actions Docs</a></td>
<td style="text-align: left;">DocumentaciÃ³n oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://docs.github.com/en/actions/using-workflows/reusing-workflows">Reusable Workflows</a></td>
<td style="text-align: left;">Workflows reutilizables</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 13: Docker para ML</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Docker Tutorial for Beginners</strong></td>
<td style="text-align: left;">TechWorld with Nana</td>
<td style="text-align: center;">60 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=3c-iBn73dDE">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Multi-stage Docker Builds</strong></td>
<td style="text-align: left;">Docker</td>
<td style="text-align: center;">15 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=zpkqNPwEzac">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Docker for Data Science</strong></td>
<td style="text-align: left;">DataTalksClub</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=B0s1Sy3k9og">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Docker Compose Tutorial</strong></td>
<td style="text-align: left;">TechWorld with Nana</td>
<td style="text-align: center;">45 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=SXwC9fSwct8">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Docker Security Best Practices</strong></td>
<td style="text-align: left;">Aqua Security</td>
<td style="text-align: center;">28 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=8T9Vj_7VTLg">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Docker Mastery</td>
<td style="text-align: left;">Udemy</td>
<td style="text-align: center;">20h</td>
<td style="text-align: left;"><a href="https://www.udemy.com/course/docker-mastery/">Udemy</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;">Containerization for ML</td>
<td style="text-align: left;">Coursera</td>
<td style="text-align: center;">4 weeks</td>
<td style="text-align: left;"><a href="https://www.coursera.org/learn/containerized-applications-on-aws">Coursera</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.docker.com/get-started/">Docker Get Started</a></td>
<td style="text-align: left;">Tutorial oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/">Dockerfile Best Practices</a></td>
<td style="text-align: left;">Mejores prÃ¡cticas</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://docs.docker.com/engine/security/">Docker Security</a></td>
<td style="text-align: left;">GuÃ­a de seguridad</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 14: FastAPI para ML</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>FastAPI Full Course</strong></td>
<td style="text-align: left;">freeCodeCamp</td>
<td style="text-align: center;">5h 30m</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=0sOvCWFmrtA">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Deploy ML Models with FastAPI</strong></td>
<td style="text-align: left;">Patrick Loeber</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=h5wLuVDr0oc">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>FastAPI Best Practices</strong></td>
<td style="text-align: left;">ArjanCodes</td>
<td style="text-align: center;">22 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=zN4VCb0LbQI">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Async FastAPI with ML</strong></td>
<td style="text-align: left;">Python Engineer</td>
<td style="text-align: center;">18 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=7t2alSnE2-I">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">FastAPI Fundamentals</td>
<td style="text-align: left;">TestDriven.io</td>
<td style="text-align: center;">8h</td>
<td style="text-align: left;"><a href="https://testdriven.io/courses/fastapi/">TestDriven.io</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://fastapi.tiangolo.com/tutorial/">FastAPI Tutorial</a></td>
<td style="text-align: left;">Tutorial oficial completo</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://fastapi.tiangolo.com/tutorial/body/">Pydantic with FastAPI</a></td>
<td style="text-align: left;">Schemas y validaciÃ³n</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 15: Streamlit Dashboards</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Streamlit Crash Course</strong></td>
<td style="text-align: left;">Patrick Loeber</td>
<td style="text-align: center;">45 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=JwSS70SZdyM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Build ML Apps with Streamlit</strong></td>
<td style="text-align: left;">Data Professor</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=JwSS70SZdyM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Streamlit Multi-page Apps</strong></td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: center;">20 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=nSw96qUbK9o">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Advanced Streamlit - Caching</strong></td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: center;">15 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=Q4cB_tGySbE">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">30 Days of Streamlit</td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: center;">30 days</td>
<td style="text-align: left;"><a href="https://30days.streamlit.app/">Streamlit</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.streamlit.io/">Streamlit Docs</a></td>
<td style="text-align: left;">DocumentaciÃ³n oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://streamlit.io/gallery">Streamlit Gallery</a></td>
<td style="text-align: left;">Ejemplos de apps</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 16: Observabilidad</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Prometheus + Grafana Tutorial</strong></td>
<td style="text-align: left;">TechWorld with Nana</td>
<td style="text-align: center;">50 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=7gW5pSM6dlU">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>ML Model Monitoring with Evidently</strong></td>
<td style="text-align: left;">Evidently AI</td>
<td style="text-align: center;">30 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=L4Pv6ExBQPM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Drift Detection Explained</strong></td>
<td style="text-align: left;">NannyML</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=82Sb8n3wN24">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">ML Monitoring</td>
<td style="text-align: left;">Made With ML</td>
<td style="text-align: center;">3h</td>
<td style="text-align: left;"><a href="https://madewithml.com/courses/mlops/monitoring/">MadeWithML</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.evidentlyai.com/">Evidently Docs</a></td>
<td style="text-align: left;">DocumentaciÃ³n oficial</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://prometheus.io/docs/">Prometheus Docs</a></td>
<td style="text-align: left;">DocumentaciÃ³n de Prometheus</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><a href="https://grafana.com/docs/grafana/latest/dashboards/">Grafana Dashboards</a></td>
<td style="text-align: left;">CreaciÃ³n de dashboards</td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 17: Despliegue</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Deploy ML Models to Production</strong></td>
<td style="text-align: left;">Made With ML</td>
<td style="text-align: center;">40 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=mL8t0YEbkqM">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>AWS for ML Deployment</strong></td>
<td style="text-align: left;">AWS</td>
<td style="text-align: center;">35 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=q75wgk9jVjA">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>GCP Cloud Run for ML</strong></td>
<td style="text-align: left;">Google Cloud</td>
<td style="text-align: center;">25 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=nhwYc4StHIc">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">MLOps on AWS</td>
<td style="text-align: left;">Coursera (AWS)</td>
<td style="text-align: center;">4 weeks</td>
<td style="text-align: left;"><a href="https://www.coursera.org/learn/mlops-aws-sagemaker">Coursera</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;">MLOps on GCP</td>
<td style="text-align: left;">Coursera (Google)</td>
<td style="text-align: center;">5 weeks</td>
<td style="text-align: left;"><a href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops">Coursera</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“– MÃ³dulo 18: Infraestructura (Kubernetes/Terraform)</h2>
<h3>ğŸ¬ Videos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Canal</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Kubernetes Tutorial</strong></td>
<td style="text-align: left;">TechWorld with Nana</td>
<td style="text-align: center;">4h</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=X48VuDVv0do">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Terraform Tutorial</strong></td>
<td style="text-align: left;">freeCodeCamp</td>
<td style="text-align: center;">2h 30m</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=7xngnjfIlK4">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>Kubeflow for ML</strong></td>
<td style="text-align: left;">Google Cloud</td>
<td style="text-align: center;">40 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/watch?v=HBxyLnEzyhw">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Cloud Cost Optimization for ML Workloads</strong></td>
<td style="text-align: left;">AWS re:Invent</td>
<td style="text-align: center;">45 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/results?search_query=aws+reinvent+cost+optimization+ml">YouTube</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;"><strong>FinOps Fundamentals on GCP</strong></td>
<td style="text-align: left;">Google Cloud</td>
<td style="text-align: center;">30 min</td>
<td style="text-align: left;"><a href="https://www.youtube.com/results?search_query=google+cloud+finops+cost+management">YouTube</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“š Cursos</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">TÃ­tulo</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: center;">DuraciÃ³n</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;">Kubernetes Fundamentals</td>
<td style="text-align: left;">Linux Foundation</td>
<td style="text-align: center;">35h</td>
<td style="text-align: left;"><a href="https://training.linuxfoundation.org/training/kubernetes-fundamentals/">LF Training</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¢</td>
<td style="text-align: left;">Terraform Associate</td>
<td style="text-align: left;">HashiCorp</td>
<td style="text-align: center;">15h</td>
<td style="text-align: left;"><a href="https://learn.hashicorp.com/terraform">HashiCorp Learn</a></td>
</tr>
</tbody>
</table>
<h3>ğŸ“„ DocumentaciÃ³n</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Recurso</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><a href="https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/welcome.html">AWS Well-Architected â€“ Cost Optimization Pillar</a></td>
<td style="text-align: left;">GuÃ­a oficial para diseÃ±ar sistemas eficientes en costos</td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><a href="https://cloud.google.com/cost-management/docs">Google Cloud â€“ Cost Management</a></td>
<td style="text-align: left;">DocumentaciÃ³n de gestiÃ³n de costos en GCP</td>
</tr>
</tbody>
</table>
<h2>ğŸ“Œ Cursos Integrales Recomendados</h2>
<p>Estos cursos cubren <strong>mÃºltiples mÃ³dulos</strong> y son excelentes para una visiÃ³n completa:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">ğŸ·ï¸</th>
<th style="text-align: left;">Curso</th>
<th style="text-align: left;">Plataforma</th>
<th style="text-align: left;">Cubre MÃ³dulos</th>
<th style="text-align: left;">Link</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>MLOps Zoomcamp</strong></td>
<td style="text-align: left;">DataTalksClub</td>
<td style="text-align: left;">06, 07, 10, 11, 12, 13, 14, 16, 17</td>
<td style="text-align: left;"><a href="https://github.com/DataTalksClub/mlops-zoomcamp">GitHub</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸ”´</td>
<td style="text-align: left;"><strong>Made With ML</strong></td>
<td style="text-align: left;">Made With ML</td>
<td style="text-align: left;">07, 08, 09, 11, 14, 16</td>
<td style="text-align: left;"><a href="https://madewithml.com/">MadeWithML</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>Full Stack Deep Learning</strong></td>
<td style="text-align: left;">FSDL</td>
<td style="text-align: left;">02, 07, 10, 12, 13, 16, 17</td>
<td style="text-align: left;"><a href="https://fullstackdeeplearning.com/">FSDL</a></td>
</tr>
<tr>
<td style="text-align: center;">ğŸŸ¡</td>
<td style="text-align: left;"><strong>MLOps Specialization</strong></td>
<td style="text-align: left;">Coursera (DeepLearning.AI)</td>
<td style="text-align: left;">07, 08, 10, 12, 13, 17</td>
<td style="text-align: left;"><a href="https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops">Coursera</a></td>
</tr>
</tbody>
</table>
<h2>ğŸ“º Canales de YouTube Recomendados</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Canal</th>
<th style="text-align: left;">Foco</th>
<th style="text-align: left;">Por quÃ© seguirlo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@ArjanCodes">ArjanCodes</a></td>
<td style="text-align: left;">Python profesional</td>
<td style="text-align: left;">Mejores prÃ¡cticas, patrones de diseÃ±o</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@TechWorldwithNana">TechWorld with Nana</a></td>
<td style="text-align: left;">DevOps/MLOps</td>
<td style="text-align: left;">Docker, K8s, CI/CD explicados claramente</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@dataschool">Data School</a></td>
<td style="text-align: left;">sklearn, pandas</td>
<td style="text-align: left;">Tutoriales detallados de ML</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@patloeber">Patrick Loeber</a></td>
<td style="text-align: left;">ML deployment</td>
<td style="text-align: left;">FastAPI, PyTorch, deployment</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@daborgan">DVCorg</a></td>
<td style="text-align: left;">DVC, CML</td>
<td style="text-align: left;">Versionado de datos</td>
</tr>
<tr>
<td style="text-align: left;"><a href="https://www.youtube.com/@DataTalksClub">DataTalksClub</a></td>
<td style="text-align: left;">MLOps completo</td>
<td style="text-align: left;">MLOps Zoomcamp, entrevistas</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— CÃ³mo Integrar los Recursos en tu Estudio</h2>
<h3>Flujo Recomendado por MÃ³dulo</h3>
<pre><code>1. ğŸ“– LEE el mÃ³dulo de la guÃ­a (completo)
          â†“
2. ğŸ¬ VE el video ğŸ”´ Obligatorio si hay dudas conceptuales
          â†“
3. ğŸ’» HAZ los ejercicios del mÃ³dulo
          â†“
4. ğŸ” COMPARA con el cÃ³digo real del portafolio
          â†“
5. ğŸ¬ VE videos ğŸŸ¡ Recomendados para profundizar
          â†“
6. ğŸ“š EXPLORA cursos ğŸŸ¢ Complementarios si quieres dominar el tema
</code></pre>
<h3>Tiempo Estimado por MÃ³dulo</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Profundidad</th>
<th style="text-align: center;">Solo GuÃ­a</th>
<th style="text-align: center;">+ Videos ğŸ”´</th>
<th style="text-align: center;">+ Videos ğŸŸ¡</th>
<th style="text-align: center;">+ Cursos</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">BÃ¡sico</td>
<td style="text-align: center;">2-3h</td>
<td style="text-align: center;">+1-2h</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Intermedio</td>
<td style="text-align: center;">2-3h</td>
<td style="text-align: center;">+1-2h</td>
<td style="text-align: center;">+2-3h</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: left;">Avanzado</td>
<td style="text-align: center;">2-3h</td>
<td style="text-align: center;">+1-2h</td>
<td style="text-align: center;">+2-3h</td>
<td style="text-align: center;">+10-20h</td>
</tr>
</tbody>
</table>
            </div>
        
            <!-- MÃ“DULO: EJERCICIOS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_EJERCICIOS" class="cover-title">EJERCICIOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ”§ Ejercicios PrÃ¡cticos â€” GuÃ­a MLOps</h1>
<blockquote>
<p><strong>Ejercicios organizados por mÃ³dulo para practicar cada concepto</strong></p>
</blockquote>
<h2>ğŸ“‹ Ãndice de Ejercicios</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Tema</th>
<th style="text-align: center;">Dificultad</th>
<th style="text-align: center;">Ejercicios</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">01</td>
<td style="text-align: left;">Python Moderno</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td style="text-align: left;">DiseÃ±o de Sistemas</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td style="text-align: left;">Estructura de Proyecto</td>
<td style="text-align: center;">â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td style="text-align: left;">Entornos</td>
<td style="text-align: center;">â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td style="text-align: left;">Git Profesional</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td style="text-align: left;">Versionado de Datos</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td style="text-align: left;">sklearn Pipelines</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td style="text-align: left;">Feature Engineering</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td style="text-align: left;">Training Profesional</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: left;">Experiment Tracking</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: left;">Testing ML</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: left;">CI/CD</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: left;">Docker</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td style="text-align: left;">FastAPI</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">15</td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: left;">Observabilidad</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">17</td>
<td style="text-align: left;">Despliegue</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">18</td>
<td style="text-align: left;">Infraestructura</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">19</td>
<td style="text-align: left;">DocumentaciÃ³n</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: left;">Proyecto Integrador</td>
<td style="text-align: center;">â­â­â­</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">21</td>
<td style="text-align: left;">Glosario</td>
<td style="text-align: center;">â­</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">22</td>
<td style="text-align: left;">Checklist</td>
<td style="text-align: center;">â­â­</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: center;">23</td>
<td style="text-align: left;">Recursos</td>
<td style="text-align: center;">â­</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p><strong>Total: 43 ejercicios</strong></p>
<blockquote>
<p>ğŸ“º <strong>Recursos externos</strong>: Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para videos y cursos complementarios organizados por mÃ³dulo.</p>
</blockquote>
<h2>ğŸ“ MÃ³dulo 01: Python Moderno</h2>
<h3>Ejercicio 1.1: Type Hints</h3>
<p><strong>Objetivo</strong>: AÃ±adir type hints a funciones existentes.</p>
<pre><code class="language-python"># ANTES (sin tipos)
def load_data(path):
    return pd.read_csv(path)

def train_model(X, y, params):
    model = RandomForestClassifier(**params)
    return model.fit(X, y)

# TU TAREA: AÃ±adir type hints completos
# Hint: usa pd.DataFrame, np.ndarray, dict[str, Any]
</code></pre>
<h3>Ejercicio 1.2: Pydantic Config</h3>
<p><strong>Objetivo</strong>: Crear configuraciÃ³n validada con Pydantic.</p>
<pre><code class="language-python"># Crear una clase ModelConfig que valide:
# - n_estimators: int entre 10 y 500
# - max_depth: int opcional, entre 1 y 50
# - random_state: int, default 42

# TU CÃ“DIGO AQUÃ
from pydantic import BaseModel, Field

class ModelConfig(BaseModel):
    # ...
    pass
</code></pre>
<h3>Ejercicio 1.3: src/ Layout</h3>
<p><strong>Objetivo</strong>: Reorganizar cÃ³digo en estructura profesional.</p>
<pre><code># Dado este cÃ³digo en un solo archivo main.py:
# - load_data()
# - preprocess()
# - train()
# - predict()
# - FastAPI app

# TU TAREA: Crear estructura src/ con:
# src/myproject/data.py
# src/myproject/training.py
# src/myproject/prediction.py
# app/fastapi_app.py
</code></pre>
<h2>ğŸ“ MÃ³dulo 02: DiseÃ±o de Sistemas</h2>
<h3>Ejercicio 2.1: ML Canvas</h3>
<p><strong>Objetivo</strong>: Completar un ML Canvas para un proyecto.</p>
<pre><code class="language-markdown"># ML Canvas: [Tu Proyecto]

## 1. Propuesta de Valor
- Â¿QuÃ© problema de negocio resuelve?
- Â¿CuÃ¡l es el impacto medible?

## 2. Datos
- Â¿De dÃ³nde vienen los datos?
- Â¿QuÃ© features son necesarias?

## 3. Modelo
- Â¿QuÃ© tipo de modelo (clasificaciÃ³n/regresiÃ³n)?
- Â¿MÃ©tricas de Ã©xito?

# TU TAREA: Completar para BankChurn-Predictor
</code></pre>
<h3>Ejercicio 2.2: ADR (Architecture Decision Record)</h3>
<p><strong>Objetivo</strong>: Documentar una decisiÃ³n tÃ©cnica.</p>
<pre><code class="language-markdown"># ADR-001: ElecciÃ³n de Framework de API

## Estado
Propuesto | Aceptado | Deprecado

## Contexto
Â¿Por quÃ© necesitamos tomar esta decisiÃ³n?

## Opciones Consideradas
1. FastAPI
2. Flask
3. Django REST

## DecisiÃ³n
Â¿CuÃ¡l elegimos y por quÃ©?

## Consecuencias
- Positivas:
- Negativas:

# TU TAREA: Crear ADR para decisiÃ³n de modelo en TelecomAI
</code></pre>
<h2>ğŸ“ MÃ³dulo 03: Estructura de Proyecto</h2>
<h3>Ejercicio 3.1: Crear src/ Layout</h3>
<p><strong>Objetivo</strong>: Organizar cÃ³digo en estructura profesional.</p>
<pre><code class="language-bash"># TU TAREA: Crear la siguiente estructura para un proyecto &quot;fraud_detector&quot;

fraud-detector/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ frauddetector/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py      # Crear con Pydantic
â”‚       â”œâ”€â”€ data.py        # load_data()
â”‚       â”œâ”€â”€ features.py    # FeatureEngineer
â”‚       â”œâ”€â”€ training.py    # FraudTrainer
â”‚       â””â”€â”€ pipeline.py    # build_pipeline()
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ pyproject.toml
â””â”€â”€ Makefile
</code></pre>
<h3>Ejercicio 3.2: pyproject.toml</h3>
<p><strong>Objetivo</strong>: Configurar proyecto Python moderno.</p>
<pre><code class="language-toml"># TU TAREA: Completar pyproject.toml

[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;fraud-detector&quot;
version = &quot;0.1.0&quot;
# ... completar dependencies, optional-dependencies, scripts
</code></pre>
<h2>ğŸ“ MÃ³dulo 04: Entornos</h2>
<h3>Ejercicio 4.1: Makefile</h3>
<p><strong>Objetivo</strong>: Crear Makefile con comandos esenciales.</p>
<pre><code class="language-makefile"># TU TAREA: Crear Makefile con estos targets

.PHONY: install test lint format train serve clean

install:
    # Instalar dependencias

test:
    # Ejecutar tests con coverage

lint:
    # Ejecutar ruff check

format:
    # Formatear con ruff format

train:
    # Entrenar modelo

serve:
    # Iniciar API

clean:
    # Limpiar artefactos
</code></pre>
<h3>Ejercicio 4.2: Entorno Reproducible</h3>
<p><strong>Objetivo</strong>: Configurar entorno desde cero.</p>
<pre><code class="language-bash"># TU TAREA: Ejecutar estos comandos y documentar cualquier problema

# 1. Crear entorno virtual
python -m venv .venv
source .venv/bin/activate

# 2. Instalar proyecto en modo editable
pip install -e &quot;.[dev]&quot;

# 3. Verificar instalaciÃ³n
python -c &quot;import frauddetector; print(frauddetector.__version__)&quot;

# 4. Ejecutar tests
pytest tests/ -v
</code></pre>
<h2>ğŸ“ MÃ³dulo 05: Git Profesional</h2>
<h3>Ejercicio 5.1: Conventional Commits</h3>
<p><strong>Objetivo</strong>: Escribir commits con formato profesional.</p>
<pre><code class="language-bash"># TU TAREA: Convertir estos mensajes a Conventional Commits

# MAL: &quot;fixed bug&quot;
# BIEN: ???

# MAL: &quot;added tests&quot;
# BIEN: ???

# MAL: &quot;updated readme&quot;
# BIEN: ???

# MAL: &quot;refactored code&quot;
# BIEN: ???

# Formato: &lt;type&gt;(&lt;scope&gt;): &lt;description&gt;
# Types: feat, fix, docs, style, refactor, test, chore
</code></pre>
<h3>Ejercicio 5.2: Pre-commit Hooks</h3>
<p><strong>Objetivo</strong>: Configurar hooks de calidad.</p>
<pre><code class="language-yaml"># .pre-commit-config.yaml
# TU TAREA: Completar configuraciÃ³n

repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.4.4
    hooks:
      # Â¿QuÃ© hooks de ruff necesitas?

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      # Â¿QuÃ© hooks bÃ¡sicos necesitas?

# DespuÃ©s: pre-commit install &amp;&amp; pre-commit run --all-files
</code></pre>
<h2>ğŸ“ MÃ³dulo 06: Versionado de Datos</h2>
<h3>Ejercicio 6.1: Inicializar DVC</h3>
<p><strong>Objetivo</strong>: Configurar DVC en un proyecto.</p>
<pre><code class="language-bash"># TU TAREA: Ejecutar y documentar cada paso

# 1. Inicializar DVC
dvc init

# 2. AÃ±adir remote local (para prÃ¡ctica)
dvc remote add -d localremote /tmp/dvc-storage

# 3. Trackear datos
dvc add data/raw/dataset.csv

# 4. Commitear archivos .dvc
git add data/raw/dataset.csv.dvc data/raw/.gitignore
git commit -m &quot;chore(data): track dataset with DVC&quot;

# PREGUNTA: Â¿QuÃ© archivos se crean? Â¿QuÃ© contiene el .dvc?
</code></pre>
<h3>Ejercicio 6.2: Pipeline DVC</h3>
<p><strong>Objetivo</strong>: Definir pipeline reproducible.</p>
<pre><code class="language-yaml"># dvc.yaml
# TU TAREA: Definir pipeline de 3 stages

stages:
  prepare:
    cmd: python src/data.py
    deps:
      # Â¿QuÃ© dependencias?
    outs:
      # Â¿QuÃ© outputs?

  train:
    cmd: python src/training.py
    deps:
      # ???
    outs:
      # ???
    metrics:
      # ???

  evaluate:
    cmd: python src/evaluate.py
    deps:
      # ???
    metrics:
      # ???
</code></pre>
<h2>ğŸ“ MÃ³dulo 07: sklearn Pipelines</h2>
<h3>Ejercicio 7.1: Pipeline BÃ¡sico</h3>
<p><strong>Objetivo</strong>: Crear un pipeline con preprocesamiento.</p>
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# TU TAREA: Crear pipeline con:
# 1. StandardScaler para features numÃ©ricas
# 2. RandomForestClassifier

pipe = Pipeline([
    # TU CÃ“DIGO
])
</code></pre>
<h3>Ejercicio 7.2: ColumnTransformer</h3>
<p><strong>Objetivo</strong>: Procesar columnas numÃ©ricas y categÃ³ricas por separado.</p>
<pre><code class="language-python"># Dado un DataFrame con:
# - numeric_cols = ['age', 'balance', 'salary']
# - categorical_cols = ['geography', 'gender']

# TU TAREA: Crear ColumnTransformer que:
# - Aplique StandardScaler a numÃ©ricas
# - Aplique OneHotEncoder a categÃ³ricas

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

preprocessor = ColumnTransformer([
    # TU CÃ“DIGO
])
</code></pre>
<h3>Ejercicio 7.3: Custom Transformer</h3>
<p><strong>Objetivo</strong>: Crear un transformer personalizado.</p>
<pre><code class="language-python">from sklearn.base import BaseEstimator, TransformerMixin

# TU TAREA: Crear AgeGroupTransformer que:
# - AÃ±ada columna 'age_group' basada en rangos de edad
# - 0-30: 'young', 31-50: 'middle', 51+: 'senior'

class AgeGroupTransformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # TU CÃ“DIGO
        return self

    def transform(self, X):
        # TU CÃ“DIGO
        pass
</code></pre>
<h2>ğŸ“ MÃ³dulo 08: Feature Engineering</h2>
<h3>Ejercicio 8.1: Detectar Data Leakage</h3>
<p><strong>Objetivo</strong>: Identificar leakage en un pipeline.</p>
<pre><code class="language-python"># CÃ“DIGO CON LEAKAGE - Encuentra los 3 errores:

df = pd.read_csv('data.csv')

# Error 1: Â¿DÃ³nde estÃ¡?
df['price_category'] = pd.cut(df['price'], bins=3, labels=['low', 'mid', 'high'])

# Error 2: Â¿DÃ³nde estÃ¡?
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'])

# Error 3: Â¿DÃ³nde estÃ¡?
model = RandomForestClassifier()
model.fit(X_train, y_train)
</code></pre>
<h3>Ejercicio 8.2: Pipeline Sin Leakage</h3>
<p><strong>Objetivo</strong>: Reescribir el cÃ³digo anterior sin leakage.</p>
<pre><code class="language-python"># TU TAREA: Reescribir el ejercicio 8.1 sin data leakage
# Hint: El scaler debe estar DENTRO del pipeline
# Hint: No crear features basadas en el target antes del split
</code></pre>
<h2>ğŸ“ MÃ³dulo 09: Training Profesional</h2>
<h3>Ejercicio 9.1: Trainer Class</h3>
<p><strong>Objetivo</strong>: Implementar clase de entrenamiento profesional.</p>
<pre><code class="language-python"># TU TAREA: Completar la clase FraudTrainer

from pathlib import Path
import pandas as pd
from sklearn.model_selection import cross_val_score

class FraudTrainer:
    &quot;&quot;&quot;Entrenador profesional siguiendo patrÃ³n del portafolio.&quot;&quot;&quot;

    def __init__(self, config: dict):
        self.config = config
        self.model_ = None
        self.metrics_ = {}

    def run(self, input_path: Path, output_dir: Path) -&gt; dict:
        &quot;&quot;&quot;Flujo completo de entrenamiento.&quot;&quot;&quot;
        # TODO: Implementar:
        # 1. load_data()
        # 2. split_data()
        # 3. cross_validate()
        # 4. fit modelo final
        # 5. evaluate()
        # 6. save_artifacts()
        pass

    def cross_validate(self, X, y) -&gt; dict:
        &quot;&quot;&quot;Cross-validation con mÃ©tricas.&quot;&quot;&quot;
        # TODO: Implementar CV estratificada
        pass
</code></pre>
<h3>Ejercicio 9.2: Reproducibilidad</h3>
<p><strong>Objetivo</strong>: Garantizar resultados reproducibles.</p>
<pre><code class="language-python"># TU TAREA: Hacer este cÃ³digo 100% reproducible

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Â¿QuÃ© seeds faltan?
X_train, X_test, y_train, y_test = train_test_split(X, y)
model = RandomForestClassifier()
model.fit(X_train, y_train)

# PISTA: np.random.seed, random_state en split, random_state en modelo
</code></pre>
<h2>ğŸ“ MÃ³dulo 10: Experiment Tracking</h2>
<h3>Ejercicio 10.1: MLflow BÃ¡sico</h3>
<p><strong>Objetivo</strong>: Loggear experimento con MLflow.</p>
<pre><code class="language-python">import mlflow

# TU TAREA: Completar el tracking

mlflow.set_tracking_uri(&quot;file:./mlruns&quot;)
mlflow.set_experiment(&quot;fraud-detection&quot;)

with mlflow.start_run():
    # TODO: Log parÃ¡metros
    mlflow.log_params({
        # ???
    })

    # TODO: Entrenar modelo
    model.fit(X_train, y_train)

    # TODO: Log mÃ©tricas
    mlflow.log_metrics({
        # ???
    })

    # TODO: Log modelo
    mlflow.sklearn.log_model(???)
</code></pre>
<h3>Ejercicio 10.2: Comparar Experimentos</h3>
<p><strong>Objetivo</strong>: Ejecutar y comparar mÃºltiples runs.</p>
<pre><code class="language-python"># TU TAREA: Crear script que entrene 3 modelos diferentes
# y los compare en MLflow UI

models = [
    (&quot;rf&quot;, RandomForestClassifier(n_estimators=100)),
    (&quot;gb&quot;, GradientBoostingClassifier(n_estimators=100)),
    (&quot;lr&quot;, LogisticRegression()),
]

for name, model in models:
    with mlflow.start_run(run_name=name):
        # TODO: Entrenar, evaluar, loggear
        pass

# DespuÃ©s: mlflow ui -&gt; comparar runs
</code></pre>
<h2>ğŸ“ MÃ³dulo 11: Testing ML</h2>
<h3>Ejercicio 11.1: Test de Datos</h3>
<p><strong>Objetivo</strong>: Escribir tests para validar datos.</p>
<pre><code class="language-python"># TU TAREA: Escribir tests que verifiquen:
# 1. No hay valores nulos en columnas crÃ­ticas
# 2. Valores de 'age' estÃ¡n entre 18 y 100
# 3. 'target' solo contiene 0 y 1

import pytest

def test_no_nulls(sample_data):
    # TU CÃ“DIGO
    pass

def test_age_range(sample_data):
    # TU CÃ“DIGO
    pass

def test_target_binary(sample_data):
    # TU CÃ“DIGO
    pass
</code></pre>
<h3>Ejercicio 11.2: Test de Modelo</h3>
<p><strong>Objetivo</strong>: Testear que el modelo funciona correctamente.</p>
<pre><code class="language-python"># TU TAREA: Escribir tests que verifiquen:
# 1. El modelo puede hacer fit sin errores
# 2. Las predicciones tienen el shape correcto
# 3. El accuracy es mayor que un baseline (ej: 0.5)

def test_model_fit(trained_model, sample_data):
    # TU CÃ“DIGO
    pass

def test_predictions_shape(trained_model, sample_data):
    # TU CÃ“DIGO
    pass

def test_accuracy_above_baseline(trained_model, sample_data):
    # TU CÃ“DIGO
    pass
</code></pre>
<h3>Ejercicio 11.3: Fixture con conftest.py</h3>
<p><strong>Objetivo</strong>: Crear fixtures reutilizables.</p>
<pre><code class="language-python"># tests/conftest.py

import pytest
import pandas as pd

# TU TAREA: Crear fixtures para:
# 1. sample_data: DataFrame con datos de prueba
# 2. trained_model: Modelo ya entrenado
# 3. config: ConfiguraciÃ³n de prueba

@pytest.fixture
def sample_data():
    # TU CÃ“DIGO
    pass

@pytest.fixture
def trained_model(sample_data):
    # TU CÃ“DIGO
    pass
</code></pre>
<h2>ğŸ“ MÃ³dulo 12: CI/CD</h2>
<h3>Ejercicio 12.1: GitHub Actions BÃ¡sico</h3>
<p><strong>Objetivo</strong>: Crear workflow de CI.</p>
<pre><code class="language-yaml"># .github/workflows/ci.yml

# TU TAREA: Crear workflow que:
# 1. Se ejecute en push y PR a main
# 2. Use Python 3.11
# 3. Instale dependencias
# 4. Ejecute tests con coverage
# 5. Falle si coverage &lt; 80%

name: CI

on:
  # TU CÃ“DIGO

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      # TU CÃ“DIGO
</code></pre>
<h2>ğŸ“ MÃ³dulo 13: Docker</h2>
<h3>Ejercicio 13.1: Dockerfile Multi-stage</h3>
<p><strong>Objetivo</strong>: Crear Dockerfile optimizado.</p>
<pre><code class="language-dockerfile"># TU TAREA: Crear Dockerfile que:
# 1. Use multi-stage build
# 2. Stage 1: instalar dependencias
# 3. Stage 2: copiar solo lo necesario
# 4. Use usuario non-root
# 5. Exponga puerto 8000

# Stage 1: Builder
FROM python:3.11-slim AS builder
# TU CÃ“DIGO

# Stage 2: Runtime
FROM python:3.11-slim
# TU CÃ“DIGO
</code></pre>
<h3>Ejercicio 13.2: Docker Compose Avanzado</h3>
<p><strong>Objetivo</strong>: Orquestar stack ML completo.</p>
<pre><code class="language-yaml"># docker-compose.ml.yml
# TU TAREA: Crear compose que levante:
# 1. API de ML (tu Dockerfile)
# 2. MLflow server
# 3. Prometheus para mÃ©tricas
# 4. Red compartida entre servicios
# 5. VolÃºmenes para persistencia

version: '3.8'

services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.0
    # TODO: ports, volumes, environment, healthcheck

  api:
    build: .
    # TODO: ports, depends_on, environment, healthcheck

  prometheus:
    image: prom/prometheus:v2.47.0
    # TODO: ports, volumes, command

networks:
  # TODO: Red compartida

volumes:
  # TODO: VolÃºmenes persistentes
</code></pre>
<blockquote>
<p>ğŸ“º Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> - MÃ³dulo 13 para videos de Docker Compose</p>
</blockquote>
<h2>ğŸ“ MÃ³dulo 14: FastAPI</h2>
<h3>Ejercicio 14.1: Schemas Pydantic</h3>
<p><strong>Objetivo</strong>: Crear schemas de request/response.</p>
<pre><code class="language-python"># TU TAREA: Crear schemas para API de predicciÃ³n

from pydantic import BaseModel, Field

class PredictionRequest(BaseModel):
    # Features del modelo
    # TU CÃ“DIGO
    pass

class PredictionResponse(BaseModel):
    # prediction: int
    # probability: float
    # TU CÃ“DIGO
    pass
</code></pre>
<h3>Ejercicio 14.2: Endpoint de PredicciÃ³n</h3>
<p><strong>Objetivo</strong>: Implementar /predict endpoint.</p>
<pre><code class="language-python">from fastapi import FastAPI, HTTPException

app = FastAPI()

# TU TAREA: Implementar endpoint que:
# 1. Reciba PredictionRequest
# 2. Valide los datos
# 3. Haga predicciÃ³n con modelo cargado
# 4. Retorne PredictionResponse
# 5. Maneje errores con HTTPException

@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    # TU CÃ“DIGO
    pass
</code></pre>
<h2>ğŸ“ MÃ³dulo 15: Streamlit</h2>
<h3>Ejercicio 15.1: Dashboard de PredicciÃ³n</h3>
<p><strong>Objetivo</strong>: Crear dashboard interactivo.</p>
<pre><code class="language-python"># app/streamlit_app.py
# TU TAREA: Crear dashboard con:
# 1. Sidebar con inputs para features
# 2. BotÃ³n de predicciÃ³n
# 3. Mostrar resultado con probabilidad
# 4. VisualizaciÃ³n de importancia de features

import streamlit as st
import pandas as pd
import joblib

st.title(&quot;ğŸ”® Fraud Predictor&quot;)

# TODO: Sidebar con inputs
with st.sidebar:
    # st.number_input, st.selectbox, etc.
    pass

# TODO: Cargar modelo
@st.cache_resource
def load_model():
    # ???
    pass

# TODO: BotÃ³n y predicciÃ³n
if st.button(&quot;Predecir&quot;):
    # ???
    pass

# TODO: Mostrar resultado
# st.success(), st.error(), st.metric()
</code></pre>
<h2>ğŸ“ MÃ³dulo 16: Observabilidad</h2>
<h3>Ejercicio 16.1: Logging Estructurado</h3>
<p><strong>Objetivo</strong>: Implementar logging profesional.</p>
<pre><code class="language-python"># TU TAREA: Configurar logging estructurado

import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    &quot;&quot;&quot;Formatter que produce logs en JSON.&quot;&quot;&quot;

    def format(self, record):
        log_data = {
            &quot;timestamp&quot;: datetime.utcnow().isoformat(),
            &quot;level&quot;: record.levelname,
            &quot;message&quot;: record.getMessage(),
            &quot;module&quot;: record.module,
            # TODO: AÃ±adir mÃ¡s campos Ãºtiles
        }
        return json.dumps(log_data)

# TODO: Configurar logger
logger = logging.getLogger(__name__)
# ???

# Uso:
logger.info(&quot;Prediction made&quot;, extra={&quot;customer_id&quot;: 123, &quot;prediction&quot;: 1})
</code></pre>
<h2>ğŸ“ MÃ³dulo 17: Despliegue</h2>
<h3>Ejercicio 17.1: Dockerfile Multi-stage</h3>
<p><strong>Objetivo</strong>: Crear un Dockerfile optimizado para producciÃ³n.</p>
<pre><code class="language-dockerfile"># TU TAREA: Crear Dockerfile multi-stage para una API de ML
# Requisitos:
# 1. Stage &quot;builder&quot;: Instalar dependencias
# 2. Stage &quot;runtime&quot;: Imagen mÃ­nima para producciÃ³n
# 3. Usuario no-root
# 4. Health check

# STAGE 1: Builder
FROM python:3.11-slim AS builder

# TODO: Instalar dependencias de compilaciÃ³n
# TODO: Copiar requirements e instalar

# STAGE 2: Runtime
FROM python:3.11-slim

# TODO: Crear usuario no-root
# TODO: Copiar solo lo necesario del builder
# TODO: Configurar HEALTHCHECK
# TODO: CMD para ejecutar uvicorn
</code></pre>
<h3>Ejercicio 17.2: Docker Compose para Stack ML</h3>
<p><strong>Objetivo</strong>: Orquestar mÃºltiples servicios ML.</p>
<pre><code class="language-yaml"># docker-compose.yml
# TU TAREA: Crear stack con:
# 1. API de ML (FastAPI)
# 2. MLflow server
# 3. Prometheus
# 4. Red compartida
# 5. VolÃºmenes persistentes

version: '3.8'

services:
  mlflow:
    # TODO: Configurar MLflow server

  api:
    # TODO: Configurar API con dependencia de MLflow

  prometheus:
    # TODO: Configurar Prometheus con config file

networks:
  # TODO: Red compartida

volumes:
  # TODO: VolÃºmenes persistentes
</code></pre>
<h2>ğŸ“ MÃ³dulo 18: Infraestructura</h2>
<h3>Ejercicio 18.1: Kubernetes Deployment</h3>
<p><strong>Objetivo</strong>: Crear manifests K8s para una API ML.</p>
<pre><code class="language-yaml"># k8s/deployment.yaml
# TU TAREA: Crear Deployment con:
# 1. 2 replicas
# 2. Resource limits (CPU, memoria)
# 3. Liveness y readiness probes
# 4. Environment variables desde ConfigMap

apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
  # TODO: labels
spec:
  replicas: # ???
  selector:
    # TODO: matchLabels
  template:
    spec:
      containers:
      - name: api
        image: # ???
        ports:
        - containerPort: 8000
        resources:
          # TODO: limits y requests
        livenessProbe:
          # TODO: Configurar probe
        readinessProbe:
          # TODO: Configurar probe
        envFrom:
          # TODO: ConfigMap reference
</code></pre>
<h3>Ejercicio 18.2: Horizontal Pod Autoscaler</h3>
<p><strong>Objetivo</strong>: Configurar autoscaling basado en CPU.</p>
<pre><code class="language-yaml"># k8s/hpa.yaml
# TU TAREA: Crear HPA que:
# 1. Escale entre 2 y 10 pods
# 2. Target CPU utilization: 70%
# 3. Scale down stabilization: 5 minutos

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api-hpa
spec:
  scaleTargetRef:
    # TODO: Referencia al Deployment
  minReplicas: # ???
  maxReplicas: # ???
  metrics:
  - type: Resource
    resource:
      # TODO: Configurar mÃ©trica de CPU
  behavior:
    scaleDown:
      # TODO: Configurar estabilizaciÃ³n
</code></pre>
<h2>ğŸ“ MÃ³dulo 19: DocumentaciÃ³n</h2>
<h3>Ejercicio 19.1: Model Card</h3>
<p><strong>Objetivo</strong>: Documentar un modelo siguiendo estÃ¡ndares.</p>
<pre><code class="language-markdown">&lt;!-- model_card.md --&gt;
&lt;!-- TU TAREA: Completar Model Card para BankChurn --&gt;

# Model Card: BankChurn Predictor

## Model Details
- **Developed by**: ???
- **Model type**: ???
- **Language**: ???
- **License**: ???

## Intended Use
- **Primary use case**: ???
- **Primary users**: ???
- **Out-of-scope uses**: ???

## Training Data
- **Dataset**: ???
- **Size**: ???
- **Features**: ???

## Evaluation Metrics
| Metric | Value |
|--------|-------|
| ROC-AUC | ??? |
| Recall | ??? |
| Precision | ??? |

## Ethical Considerations
- ???

## Limitations
- ???
</code></pre>
<h3>Ejercicio 19.2: Dataset Card</h3>
<p><strong>Objetivo</strong>: Documentar un dataset siguiendo estÃ¡ndares.</p>
<pre><code class="language-markdown">&lt;!-- dataset_card.md --&gt;
&lt;!-- TU TAREA: Completar Dataset Card --&gt;

# Dataset Card: Bank Customer Churn

## Dataset Description
- **Source**: ???
- **Size**: ??? rows, ??? columns
- **Time period**: ???

## Features
| Feature | Type | Description |
|---------|------|-------------|
| CreditScore | int | ??? |
| Geography | str | ??? |
| ... | ... | ... |

## Data Quality
- **Missing values**: ???
- **Class balance**: ???

## Ethical Considerations
- **Sensitive attributes**: ???
- **Potential biases**: ???
</code></pre>
<h2>ğŸ“ MÃ³dulo 20: Proyecto Integrador</h2>
<h3>Ejercicio 20.1: IntegraciÃ³n End-to-End</h3>
<p><strong>Objetivo</strong>: Crear script que ejecute pipeline completo.</p>
<pre><code class="language-python"># scripts/run_e2e.py
# TU TAREA: Script que:
# 1. Cargue datos
# 2. Entrene modelo
# 3. EvalÃºe mÃ©tricas
# 4. Guarde artefactos
# 5. Registre en MLflow
# 6. Pruebe API localmente

import subprocess
import requests
from pathlib import Path

def run_e2e_pipeline():
    &quot;&quot;&quot;Ejecuta pipeline completo de ML.&quot;&quot;&quot;

    # 1. Verificar datos
    data_path = Path(&quot;data/raw/dataset.csv&quot;)
    assert data_path.exists(), &quot;Dataset no encontrado&quot;

    # 2. Entrenar modelo
    # TODO: Ejecutar training script

    # 3. Verificar artefactos
    # TODO: Verificar que model.joblib existe

    # 4. Levantar API
    # TODO: subprocess.Popen para uvicorn

    # 5. Test de integraciÃ³n
    # TODO: requests.post(&quot;/predict&quot;, ...)

    # 6. Cleanup
    # TODO: Terminar proceso de API

if __name__ == &quot;__main__&quot;:
    run_e2e_pipeline()
</code></pre>
<h3>Ejercicio 20.2: Health Check Script</h3>
<p><strong>Objetivo</strong>: Verificar salud de todos los servicios.</p>
<pre><code class="language-python"># scripts/health_check.py
# TU TAREA: Script que verifique:
# 1. Todos los servicios responden
# 2. Modelos estÃ¡n cargados
# 3. MLflow estÃ¡ accesible
# 4. Genera reporte de estado

import requests
from dataclasses import dataclass
from typing import List

@dataclass
class ServiceHealth:
    name: str
    url: str
    healthy: bool
    details: str

def check_service(name: str, url: str) -&gt; ServiceHealth:
    &quot;&quot;&quot;Verifica salud de un servicio.&quot;&quot;&quot;
    # TODO: Implementar
    pass

def check_all_services() -&gt; List[ServiceHealth]:
    &quot;&quot;&quot;Verifica todos los servicios del stack.&quot;&quot;&quot;
    services = [
        (&quot;MLflow&quot;, &quot;http://localhost:5000/health&quot;),
        (&quot;BankChurn API&quot;, &quot;http://localhost:8001/health&quot;),
        (&quot;CarVision API&quot;, &quot;http://localhost:8002/health&quot;),
        (&quot;TelecomAI API&quot;, &quot;http://localhost:8003/health&quot;),
    ]

    results = []
    for name, url in services:
        # TODO: Verificar cada servicio
        pass

    return results

def generate_report(results: List[ServiceHealth]) -&gt; str:
    &quot;&quot;&quot;Genera reporte de salud.&quot;&quot;&quot;
    # TODO: Implementar
    pass

if __name__ == &quot;__main__&quot;:
    results = check_all_services()
    print(generate_report(results))
</code></pre>
<h2>ğŸ“ MÃ³dulo 21: Glosario (Autoestudio)</h2>
<h3>Ejercicio 21.1: Flashcards de TÃ©rminos</h3>
<p><strong>Objetivo</strong>: Crear set de flashcards para memorizar tÃ©rminos clave.</p>
<pre><code class="language-markdown">&lt;!-- Formato: Pregunta | Respuesta --&gt;

Â¿QuÃ© es Data Drift? | Cambio en la distribuciÃ³n de features entre training y producciÃ³n

Â¿QuÃ© es Concept Drift? | Cambio en la relaciÃ³n P(Y|X) entre features y target

Â¿Diferencia entre Precision y Recall? | Precision=TP/(TP+FP), Recall=TP/(TP+FN)

Â¿QuÃ© resuelve class_weight='balanced'? | Penaliza mÃ¡s los errores en la clase minoritaria

&lt;!-- TU TAREA: AÃ±adir 20 flashcards mÃ¡s con tÃ©rminos del glosario --&gt;
</code></pre>
<h2>ğŸ“ MÃ³dulo 22: Checklist de ProducciÃ³n</h2>
<h3>Ejercicio 22.1: AuditorÃ­a de Proyecto</h3>
<p><strong>Objetivo</strong>: Aplicar checklist a un proyecto existente.</p>
<pre><code class="language-markdown"># AuditorÃ­a: CarVision-Market-Intelligence

## CÃ³digo
- [ ] Type hints en todas las funciones
- [ ] Docstrings en clases y mÃ©todos pÃºblicos
- [ ] Sin secretos hardcodeados
- [ ] Linting pasando (ruff check)

## Testing
- [ ] Coverage &gt;= 80%
- [ ] Tests de datos (schema, rangos)
- [ ] Tests de modelo (predicciones vÃ¡lidas)
- [ ] Tests de integraciÃ³n (API funcional)

## CI/CD
- [ ] Pipeline ejecuta en cada PR
- [ ] Tests ejecutan en mÃºltiples versiones Python
- [ ] Security scanning configurado
- [ ] Docker build automatizado

## DocumentaciÃ³n
- [ ] README actualizado
- [ ] Model Card completado
- [ ] API documentada (Swagger)

## Observabilidad
- [ ] Logging estructurado
- [ ] MÃ©tricas de Prometheus
- [ ] Health endpoint implementado

&lt;!-- TU TAREA: Ejecutar esta auditorÃ­a en el proyecto real --&gt;
&lt;!-- Marcar items completados y crear issues para pendientes --&gt;
</code></pre>
<h2>ğŸ“ MÃ³dulo 23: Recursos (PrÃ¡ctica)</h2>
<h3>Ejercicio 23.1: Plan de Estudio Personalizado</h3>
<p><strong>Objetivo</strong>: Crear plan basado en gaps identificados.</p>
<pre><code class="language-markdown"># Mi Plan de Estudio MLOps

## AutoevaluaciÃ³n (1-5)
| Ãrea | Nivel | Prioridad |
|------|:-----:|:---------:|
| Python moderno | ??? | ??? |
| sklearn Pipelines | ??? | ??? |
| Docker | ??? | ??? |
| CI/CD | ??? | ??? |
| Testing | ??? | ??? |
| Observabilidad | ??? | ??? |

## Gaps Identificados
1. ???
2. ???
3. ???

## Recursos Seleccionados
| Gap | Recurso | Tipo | Tiempo |
|-----|---------|------|:------:|
| ??? | ??? | Video/Curso/Doc | ???h |

## Timeline
| Semana | MÃ³dulos | Recursos Externos | Entregable |
|:------:|---------|-------------------|------------|
| 1 | ??? | ??? | ??? |
| 2 | ??? | ??? | ??? |

&lt;!-- TU TAREA: Completar basÃ¡ndote en tu autoevaluaciÃ³n honesta --&gt;
</code></pre>
<h2>âœ… Soluciones</h2>
<p>Ver <a href="#mod_EJERCICIOS_SOLUCIONES">EJERCICIOS_SOLUCIONES.md</a> para las soluciones detalladas.</p>
<h2>ğŸ“Œ CÃ³mo Usar los Ejercicios</h2>
<ol>
<li><strong>Lee el mÃ³dulo</strong> correspondiente primero</li>
<li><strong>Intenta resolver</strong> sin mirar la soluciÃ³n</li>
<li><strong>Compara</strong> con el cÃ³digo real del portafolio</li>
<li><strong>Valida</strong> ejecutando tests cuando sea posible</li>
</ol>
<h3>Referencia RÃ¡pida al Portafolio</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Archivo de Referencia</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">01</td>
<td style="text-align: left;"><code>BankChurn-Predictor/src/bankchurn/config.py</code></td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td style="text-align: left;">Estructura de cualquier proyecto</td>
</tr>
<tr>
<td style="text-align: center;">07</td>
<td style="text-align: left;"><code>BankChurn-Predictor/src/bankchurn/training.py</code></td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td style="text-align: left;"><code>CarVision-Market-Intelligence/src/carvision/features.py</code></td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td style="text-align: left;"><code>BankChurn-Predictor/src/bankchurn/training.py</code></td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: left;"><code>CarVision-Market-Intelligence/tests/conftest.py</code></td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: left;"><code>.github/workflows/ci-mlops.yml</code></td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: left;"><code>BankChurn-Predictor/Dockerfile</code></td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td style="text-align: left;"><code>BankChurn-Predictor/app/fastapi_app.py</code></td>
</tr>
<tr>
<td style="text-align: center;">15</td>
<td style="text-align: left;"><code>CarVision-Market-Intelligence/app/streamlit_app.py</code></td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: left;"><code>infra/prometheus-rules.yaml</code></td>
</tr>
<tr>
<td style="text-align: center;">17</td>
<td style="text-align: left;"><code>docker-compose.demo.yml</code></td>
</tr>
<tr>
<td style="text-align: center;">18</td>
<td style="text-align: left;"><code>k8s/bankchurn-deployment.yaml</code></td>
</tr>
<tr>
<td style="text-align: center;">19</td>
<td style="text-align: left;"><code>BankChurn-Predictor/docs/model_card.md</code></td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: left;"><code>scripts/run_demo_tests.sh</code></td>
</tr>
<tr>
<td style="text-align: center;">22</td>
<td style="text-align: left;"><code>CHECKLIST_RELEASE.md</code></td>
</tr>
</tbody>
</table>
            </div>
        
            <!-- MÃ“DULO: EJERCICIOS_SOLUCIONES.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_EJERCICIOS_SOLUCIONES" class="cover-title">SOLUCIONES DE EJERCICIOS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>âœ… Soluciones â€” Ejercicios GuÃ­a MLOps</h1>
<blockquote>
<p><strong>Soluciones detalladas con explicaciones</strong></p>
</blockquote>
<h2>MÃ³dulo 01: Python Moderno</h2>
<h3>SoluciÃ³n 1.1: Type Hints</h3>
<pre><code class="language-python">from typing import Any
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

def load_data(path: str) -&gt; pd.DataFrame:
    &quot;&quot;&quot;Load CSV data from path.&quot;&quot;&quot;
    return pd.read_csv(path)

def train_model(
    X: pd.DataFrame, 
    y: np.ndarray, 
    params: dict[str, Any]
) -&gt; RandomForestClassifier:
    &quot;&quot;&quot;Train RandomForest with given parameters.&quot;&quot;&quot;
    model = RandomForestClassifier(**params)
    return model.fit(X, y)
</code></pre>
<p><strong>ExplicaciÃ³n</strong>: Los type hints documentan quÃ© tipos espera y retorna cada funciÃ³n, facilitando el mantenimiento y detectando errores con mypy.</p>
<h3>SoluciÃ³n 1.2: Pydantic Config</h3>
<pre><code class="language-python">from pydantic import BaseModel, Field

class ModelConfig(BaseModel):
    &quot;&quot;&quot;Configuration for RandomForest model.&quot;&quot;&quot;

    n_estimators: int = Field(
        default=100,
        ge=10,
        le=500,
        description=&quot;Number of trees in the forest&quot;
    )
    max_depth: int | None = Field(
        default=None,
        ge=1,
        le=50,
        description=&quot;Maximum depth of trees&quot;
    )
    random_state: int = Field(
        default=42,
        description=&quot;Random seed for reproducibility&quot;
    )

# Uso:
config = ModelConfig(n_estimators=200, max_depth=10)
# ValidaciÃ³n automÃ¡tica - esto fallarÃ­a:
# config = ModelConfig(n_estimators=1000)  # Error: &gt; 500
</code></pre>
<h2>MÃ³dulo 07: sklearn Pipelines</h2>
<h3>SoluciÃ³n 7.1: Pipeline BÃ¡sico</h3>
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

pipe = Pipeline([
    (&quot;scaler&quot;, StandardScaler()),
    (&quot;model&quot;, RandomForestClassifier(n_estimators=100, random_state=42))
])

# Uso:
pipe.fit(X_train, y_train)
predictions = pipe.predict(X_test)
</code></pre>
<h3>SoluciÃ³n 7.2: ColumnTransformer</h3>
<pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

numeric_cols = ['age', 'balance', 'salary']
categorical_cols = ['geography', 'gender']

preprocessor = ColumnTransformer([
    (&quot;num&quot;, StandardScaler(), numeric_cols),
    (&quot;cat&quot;, OneHotEncoder(handle_unknown='ignore'), categorical_cols)
])

# Pipeline completo:
pipe = Pipeline([
    (&quot;preprocess&quot;, preprocessor),
    (&quot;model&quot;, RandomForestClassifier())
])
</code></pre>
<h3>SoluciÃ³n 7.3: Custom Transformer</h3>
<pre><code class="language-python">import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin

class AgeGroupTransformer(BaseEstimator, TransformerMixin):
    &quot;&quot;&quot;Transform age into categorical groups.&quot;&quot;&quot;

    def fit(self, X, y=None):
        return self  # Stateless transformer

    def transform(self, X):
        X = X.copy()
        X['age_group'] = pd.cut(
            X['age'],
            bins=[0, 30, 50, 100],
            labels=['young', 'middle', 'senior']
        )
        return X

# Uso en pipeline:
pipe = Pipeline([
    (&quot;age_groups&quot;, AgeGroupTransformer()),
    (&quot;preprocess&quot;, preprocessor),
    (&quot;model&quot;, RandomForestClassifier())
])
</code></pre>
<h2>MÃ³dulo 08: Feature Engineering</h2>
<h3>SoluciÃ³n 8.1: Detectar Data Leakage</h3>
<pre><code class="language-python"># ERROR 1: price_category usa el target (price) antes del split
# Esto causa TARGET LEAKAGE

# ERROR 2: StandardScaler se ajusta a TODO el dataset
# Esto causa TRAIN-TEST CONTAMINATION

# ERROR 3: No hay error aquÃ­, pero los errores anteriores
# ya contaminaron los datos
</code></pre>
<h3>SoluciÃ³n 8.2: Pipeline Sin Leakage</h3>
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('data.csv')

# CORRECCIÃ“N 1: NO crear price_category (depende del target)
# Si necesitas esta feature, crÃ©ala SOLO con datos de training

# CORRECCIÃ“N 2: Split ANTES de cualquier transformaciÃ³n
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# CORRECCIÃ“N 3: Scaler DENTRO del pipeline
pipe = Pipeline([
    (&quot;scaler&quot;, StandardScaler()),  # Se ajusta solo en fit()
    (&quot;model&quot;, RandomForestClassifier())
])

# El scaler solo ve X_train durante fit
pipe.fit(X_train, y_train)
score = pipe.score(X_test, y_test)
</code></pre>
<h2>MÃ³dulo 11: Testing ML</h2>
<h3>SoluciÃ³n 11.1: Test de Datos</h3>
<pre><code class="language-python">import pytest
import pandas as pd

def test_no_nulls(sample_data):
    &quot;&quot;&quot;Critical columns should have no null values.&quot;&quot;&quot;
    critical_cols = ['age', 'balance', 'target']
    for col in critical_cols:
        assert sample_data[col].isnull().sum() == 0, f&quot;Nulls found in {col}&quot;

def test_age_range(sample_data):
    &quot;&quot;&quot;Age should be between 18 and 100.&quot;&quot;&quot;
    assert sample_data['age'].min() &gt;= 18, &quot;Age below 18 found&quot;
    assert sample_data['age'].max() &lt;= 100, &quot;Age above 100 found&quot;

def test_target_binary(sample_data):
    &quot;&quot;&quot;Target should only contain 0 and 1.&quot;&quot;&quot;
    unique_values = set(sample_data['target'].unique())
    assert unique_values &lt;= {0, 1}, f&quot;Invalid target values: {unique_values}&quot;
</code></pre>
<h3>SoluciÃ³n 11.2: Test de Modelo</h3>
<pre><code class="language-python">import numpy as np
from sklearn.metrics import accuracy_score

def test_model_fit(sample_data):
    &quot;&quot;&quot;Model should fit without errors.&quot;&quot;&quot;
    X = sample_data.drop('target', axis=1)
    y = sample_data['target']

    model = RandomForestClassifier(n_estimators=10, random_state=42)
    model.fit(X, y)  # Should not raise

    assert hasattr(model, 'classes_'), &quot;Model not fitted&quot;

def test_predictions_shape(trained_model, sample_data):
    &quot;&quot;&quot;Predictions should match input shape.&quot;&quot;&quot;
    X = sample_data.drop('target', axis=1)
    predictions = trained_model.predict(X)

    assert predictions.shape[0] == len(X), &quot;Prediction count mismatch&quot;

def test_accuracy_above_baseline(trained_model, sample_data):
    &quot;&quot;&quot;Model should beat random baseline.&quot;&quot;&quot;
    X = sample_data.drop('target', axis=1)
    y = sample_data['target']

    predictions = trained_model.predict(X)
    accuracy = accuracy_score(y, predictions)

    assert accuracy &gt; 0.5, f&quot;Accuracy {accuracy} below baseline 0.5&quot;
</code></pre>
<h3>SoluciÃ³n 11.3: conftest.py</h3>
<pre><code class="language-python"># tests/conftest.py

import pytest
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

@pytest.fixture
def sample_data():
    &quot;&quot;&quot;Generate sample data for testing.&quot;&quot;&quot;
    np.random.seed(42)
    n_samples = 100

    return pd.DataFrame({
        'age': np.random.randint(18, 70, n_samples),
        'balance': np.random.uniform(0, 100000, n_samples),
        'salary': np.random.uniform(30000, 150000, n_samples),
        'target': np.random.randint(0, 2, n_samples)
    })

@pytest.fixture
def trained_model(sample_data):
    &quot;&quot;&quot;Return a trained model.&quot;&quot;&quot;
    X = sample_data.drop('target', axis=1)
    y = sample_data['target']

    model = RandomForestClassifier(n_estimators=10, random_state=42)
    model.fit(X, y)
    return model

@pytest.fixture
def config():
    &quot;&quot;&quot;Return test configuration.&quot;&quot;&quot;
    return {
        'model': {'n_estimators': 10, 'random_state': 42},
        'data': {'test_size': 0.2}
    }
</code></pre>
<h2>MÃ³dulo 12: CI/CD</h2>
<h3>SoluciÃ³n 12.1: GitHub Actions</h3>
<pre><code class="language-yaml">name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -e &quot;.[dev]&quot;

      - name: Run tests with coverage
        run: |
          pytest --cov=src/ --cov-report=xml --cov-fail-under=80

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
</code></pre>
<h2>MÃ³dulo 13: Docker</h2>
<h3>SoluciÃ³n 13.1: Dockerfile Multi-stage</h3>
<pre><code class="language-dockerfile"># Stage 1: Builder
FROM python:3.11-slim AS builder

WORKDIR /app

# Install build dependencies
RUN pip install --no-cache-dir --upgrade pip

# Copy and install requirements
COPY requirements.txt .
RUN pip install --no-cache-dir --target=/app/deps -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim

# Create non-root user
RUN useradd --create-home --shell /bin/bash appuser

WORKDIR /app

# Copy dependencies from builder
COPY --from=builder /app/deps /usr/local/lib/python3.11/site-packages/

# Copy application code
COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser artifacts/ ./artifacts/

# Switch to non-root user
USER appuser

EXPOSE 8000

CMD [&quot;python&quot;, &quot;-m&quot;, &quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<h2>MÃ³dulo 14: FastAPI</h2>
<h3>SoluciÃ³n 14.1 y 14.2: Schemas y Endpoint</h3>
<pre><code class="language-python">from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
import joblib
import pandas as pd

# Schemas
class PredictionRequest(BaseModel):
    age: int = Field(..., ge=18, le=100)
    balance: float = Field(..., ge=0)
    salary: float = Field(..., ge=0)
    geography: str = Field(..., pattern=&quot;^(France|Germany|Spain)$&quot;)
    gender: str = Field(..., pattern=&quot;^(Male|Female)$&quot;)

class PredictionResponse(BaseModel):
    prediction: int = Field(..., ge=0, le=1)
    probability: float = Field(..., ge=0, le=1)
    status: str = &quot;success&quot;

# App
app = FastAPI(title=&quot;ML Prediction API&quot;)

# Load model at startup
model = None

@app.on_event(&quot;startup&quot;)
async def load_model():
    global model
    model = joblib.load(&quot;artifacts/model.joblib&quot;)

@app.get(&quot;/health&quot;)
async def health():
    return {&quot;status&quot;: &quot;healthy&quot;, &quot;model_loaded&quot;: model is not None}

@app.post(&quot;/predict&quot;, response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    if model is None:
        raise HTTPException(status_code=503, detail=&quot;Model not loaded&quot;)

    try:
        # Convert to DataFrame
        df = pd.DataFrame([request.model_dump()])

        # Get prediction and probability
        prediction = int(model.predict(df)[0])
        probability = float(model.predict_proba(df)[0, 1])

        return PredictionResponse(
            prediction=prediction,
            probability=probability
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
</code></pre>
<h2>MÃ³dulo 02: DiseÃ±o de Sistemas</h2>
<h3>SoluciÃ³n 2.1: ML Canvas</h3>
<pre><code class="language-markdown"># ML Canvas: BankChurn-Predictor

## 1. Propuesta de Valor
- Reducir churn de clientes bancarios
- Impacto: Retener 15% mÃ¡s clientes = $2M/aÃ±o ahorro estimado

## 2. Datos
- Fuente: Base de datos CRM bancaria (10K clientes)
- Features: CreditScore, Age, Balance, Geography, NumOfProducts, IsActiveMember

## 3. Modelo
- Tipo: ClasificaciÃ³n binaria (churn: 0/1)
- MÃ©tricas: ROC-AUC &gt; 0.85, Recall &gt; 0.75 (priorizar capturar churners)
- Baseline: 79.6% (predecir siempre &quot;no churn&quot;)
</code></pre>
<h3>SoluciÃ³n 2.2: ADR</h3>
<pre><code class="language-markdown"># ADR-001: ElecciÃ³n de RandomForest sobre XGBoost

## Estado
Aceptado

## Contexto
Necesitamos un modelo para predicciÃ³n de churn que sea interpretable y robusto.

## Opciones Consideradas
1. RandomForest - Interpretable, feature importances nativas
2. XGBoost - Mejor performance en benchmarks
3. LogisticRegression - Muy interpretable pero menos potente

## DecisiÃ³n
RandomForest porque:
- Feature importances integradas (Ãºtil para equipo de negocio)
- No requiere tuning extensivo
- Buen balance accuracy/interpretabilidad

## Consecuencias
- Positivas: FÃ¡cil de explicar a stakeholders, pipeline simple
- Negativas: Puede perder 1-2% accuracy vs XGBoost tuneado
</code></pre>
<h2>MÃ³dulo 03: Estructura de Proyecto</h2>
<h3>SoluciÃ³n 3.1: src/ Layout</h3>
<pre><code class="language-bash">mkdir -p fraud-detector/{src/frauddetector,tests,configs,app,artifacts}

# Crear archivos base
touch fraud-detector/src/frauddetector/{__init__,config,data,features,training,pipeline}.py
touch fraud-detector/tests/conftest.py
touch fraud-detector/configs/config.yaml
touch fraud-detector/{pyproject.toml,Makefile,README.md}
</code></pre>
<h3>SoluciÃ³n 3.2: pyproject.toml</h3>
<pre><code class="language-toml">[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;fraud-detector&quot;
version = &quot;0.1.0&quot;
requires-python = &quot;&gt;=3.10&quot;
dependencies = [
    &quot;pandas&gt;=2.0&quot;,
    &quot;scikit-learn&gt;=1.3&quot;,
    &quot;pydantic&gt;=2.0&quot;,
    &quot;pyyaml&gt;=6.0&quot;,
]

[project.optional-dependencies]
dev = [&quot;pytest&gt;=7.0&quot;, &quot;pytest-cov&gt;=4.0&quot;, &quot;ruff&gt;=0.1&quot;]

[project.scripts]
train = &quot;frauddetector.training:main&quot;
</code></pre>
<h2>MÃ³dulo 04: Entornos</h2>
<h3>SoluciÃ³n 4.1: Makefile</h3>
<pre><code class="language-makefile">.PHONY: install test lint format train serve clean

install:
    pip install -e &quot;.[dev]&quot;

test:
    pytest tests/ --cov=src/frauddetector --cov-report=term-missing --cov-fail-under=80

lint:
    ruff check src/ tests/

format:
    ruff format src/ tests/

train:
    python -m frauddetector.training --config configs/config.yaml

serve:
    uvicorn app.fastapi_app:app --reload --port 8000

clean:
    rm -rf __pycache__ .pytest_cache .ruff_cache htmlcov .coverage
    find . -type d -name &quot;__pycache__&quot; -exec rm -rf {} +
</code></pre>
<h2>MÃ³dulo 05: Git Profesional</h2>
<h3>SoluciÃ³n 5.1: Conventional Commits</h3>
<pre><code class="language-bash"># &quot;fixed bug&quot; â†’ 
fix(pipeline): handle NaN values in categorical columns

# &quot;added tests&quot; â†’
test(training): add integration tests for cross-validation

# &quot;updated readme&quot; â†’
docs(readme): add quick start guide and badges

# &quot;refactored code&quot; â†’
refactor(features): extract FeatureEngineer to separate module
</code></pre>
<h3>SoluciÃ³n 5.2: Pre-commit Hooks</h3>
<pre><code class="language-yaml">repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.4.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
</code></pre>
<h2>MÃ³dulo 06: Versionado de Datos</h2>
<h3>SoluciÃ³n 6.1: Inicializar DVC</h3>
<pre><code class="language-bash"># Los archivos creados:
# - .dvc/ (directorio de configuraciÃ³n)
# - .dvcignore (gitignore para DVC)
# - data/raw/dataset.csv.dvc (archivo de tracking)
# - data/raw/.gitignore (ignora el CSV real)

# Contenido de dataset.csv.dvc:
# outs:
# - md5: abc123def456...
#   size: 1234567
#   path: dataset.csv
</code></pre>
<h3>SoluciÃ³n 6.2: Pipeline DVC</h3>
<pre><code class="language-yaml">stages:
  prepare:
    cmd: python src/data.py
    deps:
      - data/raw/dataset.csv
      - src/data.py
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  train:
    cmd: python src/training.py
    deps:
      - data/processed/train.csv
      - src/training.py
      - configs/config.yaml
    outs:
      - artifacts/model.joblib
    metrics:
      - artifacts/metrics.json:
          cache: false

  evaluate:
    cmd: python src/evaluate.py
    deps:
      - data/processed/test.csv
      - artifacts/model.joblib
    metrics:
      - artifacts/evaluation.json:
          cache: false
</code></pre>
<h2>MÃ³dulo 09: Training Profesional</h2>
<h3>SoluciÃ³n 9.1: Trainer Class</h3>
<pre><code class="language-python">from pathlib import Path
import pandas as pd
import joblib
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import accuracy_score, f1_score

class FraudTrainer:
    def __init__(self, config: dict):
        self.config = config
        self.model_ = None
        self.metrics_ = {}

    def run(self, input_path: Path, output_dir: Path) -&gt; dict:
        df = self.load_data(input_path)
        X, y = df.drop('target', axis=1), df['target']
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        self.metrics_['cv_scores'] = self.cross_validate(X_train, y_train)

        self.model_ = self.build_pipeline()
        self.model_.fit(X_train, y_train)

        self.metrics_.update(self.evaluate(X_test, y_test))
        self.save_artifacts(output_dir)

        return self.metrics_

    def cross_validate(self, X, y) -&gt; dict:
        scores = cross_val_score(self.build_pipeline(), X, y, cv=5, scoring='f1')
        return {'mean': scores.mean(), 'std': scores.std()}
</code></pre>
<h3>SoluciÃ³n 9.2: Reproducibilidad</h3>
<pre><code class="language-python">import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

SEED = 42

# 1. Seed global de numpy
np.random.seed(SEED)

# 2. random_state en train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=SEED
)

# 3. random_state en modelo
model = RandomForestClassifier(n_estimators=100, random_state=SEED)
model.fit(X_train, y_train)
</code></pre>
<h2>MÃ³dulo 10: Experiment Tracking</h2>
<h3>SoluciÃ³n 10.1: MLflow BÃ¡sico</h3>
<pre><code class="language-python">import mlflow
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

mlflow.set_tracking_uri(&quot;file:./mlruns&quot;)
mlflow.set_experiment(&quot;fraud-detection&quot;)

with mlflow.start_run():
    mlflow.log_params({
        &quot;model_type&quot;: &quot;RandomForest&quot;,
        &quot;n_estimators&quot;: 100,
        &quot;max_depth&quot;: 10,
        &quot;random_state&quot;: 42
    })

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    mlflow.log_metrics({
        &quot;accuracy&quot;: accuracy_score(y_test, y_pred),
        &quot;f1_score&quot;: f1_score(y_test, y_pred),
        &quot;roc_auc&quot;: roc_auc_score(y_test, y_proba)
    })

    mlflow.sklearn.log_model(model, &quot;model&quot;)
</code></pre>
<h2>MÃ³dulo 15: Streamlit</h2>
<h3>SoluciÃ³n 15.1: Dashboard de PredicciÃ³n</h3>
<pre><code class="language-python">import streamlit as st
import pandas as pd
import joblib

st.title(&quot;ğŸ”® Fraud Predictor&quot;)

with st.sidebar:
    st.header(&quot;Input Features&quot;)
    age = st.number_input(&quot;Age&quot;, 18, 100, 35)
    balance = st.number_input(&quot;Balance&quot;, 0.0, 250000.0, 50000.0)
    salary = st.number_input(&quot;Salary&quot;, 0.0, 200000.0, 60000.0)
    geography = st.selectbox(&quot;Geography&quot;, [&quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;])

@st.cache_resource
def load_model():
    return joblib.load(&quot;artifacts/model.joblib&quot;)

model = load_model()

if st.button(&quot;ğŸ”® Predecir&quot;):
    input_df = pd.DataFrame([{
        &quot;age&quot;: age, &quot;balance&quot;: balance,
        &quot;salary&quot;: salary, &quot;geography&quot;: geography
    }])

    prediction = model.predict(input_df)[0]
    probability = model.predict_proba(input_df)[0, 1]

    col1, col2 = st.columns(2)
    col1.metric(&quot;PredicciÃ³n&quot;, &quot;Fraude&quot; if prediction else &quot;No Fraude&quot;)
    col2.metric(&quot;Probabilidad&quot;, f&quot;{probability:.1%}&quot;)

    if prediction:
        st.error(&quot;âš ï¸ Alto riesgo de fraude detectado&quot;)
    else:
        st.success(&quot;âœ… TransacciÃ³n normal&quot;)
</code></pre>
<h2>MÃ³dulo 16: Observabilidad</h2>
<h3>SoluciÃ³n 16.1: Logging Estructurado</h3>
<pre><code class="language-python">import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            &quot;timestamp&quot;: datetime.utcnow().isoformat(),
            &quot;level&quot;: record.levelname,
            &quot;message&quot;: record.getMessage(),
            &quot;module&quot;: record.module,
            &quot;function&quot;: record.funcName,
            &quot;line&quot;: record.lineno,
        }
        # Add extra fields if present
        if hasattr(record, 'customer_id'):
            log_data['customer_id'] = record.customer_id
        if hasattr(record, 'prediction'):
            log_data['prediction'] = record.prediction
        return json.dumps(log_data)

# Configurar logger
logger = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Uso:
logger.info(&quot;Prediction made&quot;, extra={&quot;customer_id&quot;: 123, &quot;prediction&quot;: 1})
# Output: {&quot;timestamp&quot;: &quot;2024-12-04T...&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;message&quot;: &quot;Prediction made&quot;, &quot;customer_id&quot;: 123, &quot;prediction&quot;: 1}
</code></pre>
<h2>MÃ³dulo 17: Despliegue</h2>
<h3>SoluciÃ³n 17.1: Dockerfile Multi-stage</h3>
<pre><code class="language-dockerfile"># â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1: Builder - Todas las herramientas de compilaciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS builder

WORKDIR /app

# Dependencias de compilaciÃ³n
RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \
    build-essential \
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# Instalar dependencias Python en directorio aislado
COPY requirements.txt .
RUN pip install --no-cache-dir --target=/app/deps -r requirements.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2: Runtime - Solo lo necesario
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim

# Usuario no-root (seguridad)
RUN useradd --create-home --shell /bin/bash appuser

WORKDIR /app

# Copiar dependencias del builder
COPY --from=builder /app/deps /usr/local/lib/python3.11/site-packages/

# Copiar cÃ³digo y artefactos
COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser artifacts/ ./artifacts/

# Cambiar a usuario no-root
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c &quot;import requests; requests.get('http://localhost:8000/health')&quot; || exit 1

EXPOSE 8000

CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<p><strong>ExplicaciÃ³n</strong>: <br />
- Stage 1 tiene todas las herramientas de build (compiladores, headers)<br />
- Stage 2 solo tiene Python runtime + dependencias instaladas<br />
- Usuario non-root previene escalaciÃ³n de privilegios<br />
- HEALTHCHECK permite orquestadores (K8s, Docker Swarm) verificar salud</p>
<h3>SoluciÃ³n 17.2: Docker Compose para Stack ML</h3>
<pre><code class="language-yaml">version: '3.8'

services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.0
    container_name: mlflow-server
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - mlflow-data:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=sqlite:///mlflow/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    command: &gt;
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    networks:
      - mlops-network
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:5000/health&quot;]
      interval: 30s
      timeout: 10s
      retries: 3

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: bankchurn-api
    ports:
      - &quot;8001:8000&quot;
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MODEL_PATH=/app/artifacts/model.joblib
    volumes:
      - ./artifacts:/app/artifacts:ro
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - mlops-network
    healthcheck:
      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:8000/health&quot;]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    ports:
      - &quot;9090:9090&quot;
    volumes:
      - ./infra/prometheus-config.yaml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - mlops-network

networks:
  mlops-network:
    driver: bridge

volumes:
  mlflow-data:
  prometheus-data:
</code></pre>
<p><strong>ExplicaciÃ³n</strong>:<br />
- <code>depends_on</code> con <code>condition: service_healthy</code> asegura orden de inicio<br />
- VolÃºmenes nombrados persisten datos entre reinicios<br />
- Red compartida permite comunicaciÃ³n por nombre de servicio<br />
- Health checks permiten auto-recuperaciÃ³n</p>
<h2>MÃ³dulo 18: Infraestructura</h2>
<h3>SoluciÃ³n 18.1: Kubernetes Deployment</h3>
<pre><code class="language-yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
  namespace: mlops
  labels:
    app: bankchurn
    tier: api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: bankchurn
  template:
    metadata:
      labels:
        app: bankchurn
        tier: api
    spec:
      containers:
      - name: api
        image: ghcr.io/duqueom/bankchurn-api:latest
        ports:
        - containerPort: 8000
          name: http
        resources:
          requests:
            memory: &quot;256Mi&quot;
            cpu: &quot;100m&quot;
          limits:
            memory: &quot;512Mi&quot;
            cpu: &quot;500m&quot;
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 2
        envFrom:
        - configMapRef:
            name: bankchurn-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: bankchurn-config
  namespace: mlops
data:
  MLFLOW_TRACKING_URI: &quot;http://mlflow-service:5000&quot;
  LOG_LEVEL: &quot;INFO&quot;
  MODEL_PATH: &quot;/app/artifacts/model.joblib&quot;
---
apiVersion: v1
kind: Service
metadata:
  name: bankchurn-service
  namespace: mlops
spec:
  selector:
    app: bankchurn
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP
</code></pre>
<p><strong>ExplicaciÃ³n</strong>:<br />
- <code>livenessProbe</code>: K8s reinicia el pod si falla (container muerto)<br />
- <code>readinessProbe</code>: K8s deja de enviar trÃ¡fico si falla (container sobrecargado)<br />
- <code>resources.requests</code>: MÃ­nimo garantizado<br />
- <code>resources.limits</code>: MÃ¡ximo permitido (OOMKilled si excede)<br />
- ConfigMap externaliza configuraciÃ³n del cÃ³digo</p>
<h3>SoluciÃ³n 18.2: Horizontal Pod Autoscaler</h3>
<pre><code class="language-yaml">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api-hpa
  namespace: mlops
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutos
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
</code></pre>
<p><strong>ExplicaciÃ³n</strong>:<br />
- Escala entre 2 y 10 pods basado en CPU (70%) y memoria (80%)<br />
- <code>scaleDown.stabilizationWindowSeconds: 300</code>: Espera 5 min antes de escalar hacia abajo (evita flapping)<br />
- <code>scaleUp</code>: Agresivo (0s estabilizaciÃ³n, hasta 4 pods o 100% mÃ¡s por cada 15s)<br />
- <code>selectPolicy: Max</code>: Usa la polÃ­tica que escale mÃ¡s rÃ¡pido</p>
<h2>MÃ³dulo 19: DocumentaciÃ³n</h2>
<h3>SoluciÃ³n 19.1: Model Card</h3>
<pre><code class="language-markdown"># Model Card: BankChurn Predictor

## Model Details
- **Developed by**: DuqueOM
- **Model type**: Random Forest Classifier
- **Language**: Python 3.11
- **License**: MIT
- **Version**: 1.0.0
- **Last updated**: 2024-12-04

## Intended Use
- **Primary use case**: Predecir probabilidad de abandono de clientes bancarios
- **Primary users**: Equipos de retenciÃ³n, analistas de negocio
- **Out-of-scope uses**: 
  - Decisiones de crÃ©dito automatizadas sin supervisiÃ³n humana
  - DiscriminaciÃ³n basada en atributos protegidos

## Training Data
- **Dataset**: Bank Customer Churn Dataset
- **Size**: 10,000 registros
- **Features**: 11 (CreditScore, Age, Geography, Gender, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary)
- **Target**: Exited (0/1)
- **Class distribution**: 80% no-churn, 20% churn

## Evaluation Metrics
| Metric | Value | Confidence Interval |
|--------|-------|---------------------|
| ROC-AUC | 0.86 | [0.84, 0.88] |
| Recall | 0.75 | [0.72, 0.78] |
| Precision | 0.62 | [0.58, 0.66] |
| F1 Score | 0.68 | [0.64, 0.72] |

## Ethical Considerations
- **Fairness**: El modelo usa Geography y Gender. Se recomienda auditar disparidad de tasas de predicciÃ³n entre grupos.
- **Bias potencial**: El dataset es de una regiÃ³n especÃ­fica; puede no generalizar a otros mercados.
- **Transparencia**: Feature importances disponibles; se recomienda usar SHAP para explicaciones individuales.

## Limitations
- Entrenado solo con datos histÃ³ricos 2019-2023
- No considera factores macroeconÃ³micos externos
- Performance puede degradar con drift significativo en distribuciÃ³n de clientes
- Umbral de decisiÃ³n (0.5) puede necesitar ajuste segÃºn costo de FP vs FN

## How to Use
```python
import joblib
model = joblib.load(&quot;artifacts/model.joblib&quot;)
prediction = model.predict(customer_df)
probability = model.predict_proba(customer_df)[:, 1]
</code></pre>
<pre><code>

### SoluciÃ³n 19.2: Dataset Card

```markdown
# Dataset Card: Bank Customer Churn

## Dataset Description
- **Source**: Kaggle Bank Customer Churn Dataset
- **Size**: 10,000 rows, 14 columns
- **Time period**: 2019-2023 (simulado)
- **License**: CC0 Public Domain

## Features
| Feature | Type | Description | Range/Values |
|---------|------|-------------|--------------|
| CustomerId | int | Identificador Ãºnico | - |
| Surname | str | Apellido (no usar en modelo) | - |
| CreditScore | int | PuntuaciÃ³n crediticia | 300-850 |
| Geography | str | PaÃ­s del cliente | France, Germany, Spain |
| Gender | str | GÃ©nero | Male, Female |
| Age | int | Edad en aÃ±os | 18-92 |
| Tenure | int | AÃ±os como cliente | 0-10 |
| Balance | float | Saldo en cuenta | 0-250K |
| NumOfProducts | int | Productos contratados | 1-4 |
| HasCrCard | int | Tiene tarjeta de crÃ©dito | 0, 1 |
| IsActiveMember | int | Cliente activo | 0, 1 |
| EstimatedSalary | float | Salario estimado | 10K-200K |
| Exited | int | **TARGET**: AbandonÃ³ el banco | 0, 1 |

## Data Quality
- **Missing values**: 0%
- **Duplicates**: 0 (verificado por CustomerId)
- **Class balance**: 79.6% no-churn, 20.4% churn

## Preprocessing Applied
1. Drop: CustomerId, Surname (no predictivos)
2. One-hot encoding: Geography, Gender
3. StandardScaler: Features numÃ©ricas
4. No se aplica SMOTE (usamos class_weight='balanced')

## Ethical Considerations
- **Sensitive attributes**: Geography, Gender pueden introducir sesgo
- **Potential biases**: Dataset europeo, puede no representar otros mercados
- **Recommendations**: Auditar equidad de predicciones por grupo demogrÃ¡fico

## Citation
```bibtex
@misc{bank_churn_dataset,
  title={Bank Customer Churn Dataset},
  author={Kaggle},
  year={2023},
  url={https://www.kaggle.com/datasets/...}
}
</code></pre>
<pre><code>

## MÃ³dulo 20: Proyecto Integrador

### SoluciÃ³n 20.1: IntegraciÃ³n End-to-End

```python
#!/usr/bin/env python3
&quot;&quot;&quot;
scripts/run_e2e.py
Pipeline end-to-end: train â†’ evaluate â†’ serve â†’ test API
&quot;&quot;&quot;

import subprocess
import requests
import time
import sys
from pathlib import Path

def run_e2e_pipeline():
    &quot;&quot;&quot;Ejecuta pipeline completo de ML.&quot;&quot;&quot;

    print(&quot;=&quot; * 60)
    print(&quot;ğŸš€ PIPELINE E2E - BankChurn Predictor&quot;)
    print(&quot;=&quot; * 60)

    # 1. Verificar datos
    print(&quot;\nğŸ“Š [1/6] Verificando datos...&quot;)
    data_path = Path(&quot;data/raw/churn.csv&quot;)
    if not data_path.exists():
        print(f&quot;âŒ Dataset no encontrado: {data_path}&quot;)
        return False
    print(f&quot;âœ… Dataset encontrado: {data_path}&quot;)

    # 2. Entrenar modelo
    print(&quot;\nğŸ¯ [2/6] Entrenando modelo...&quot;)
    result = subprocess.run(
        [&quot;python&quot;, &quot;-m&quot;, &quot;bankchurn.train&quot;],
        capture_output=True, text=True
    )
    if result.returncode != 0:
        print(f&quot;âŒ Training fallÃ³: {result.stderr}&quot;)
        return False
    print(&quot;âœ… Modelo entrenado&quot;)

    # 3. Verificar artefactos
    print(&quot;\nğŸ“¦ [3/6] Verificando artefactos...&quot;)
    model_path = Path(&quot;artifacts/model.joblib&quot;)
    if not model_path.exists():
        print(f&quot;âŒ Modelo no encontrado: {model_path}&quot;)
        return False
    print(f&quot;âœ… Modelo guardado: {model_path}&quot;)

    # 4. Levantar API
    print(&quot;\nğŸŒ [4/6] Iniciando API...&quot;)
    api_process = subprocess.Popen(
        [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;],
        stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    time.sleep(5)  # Esperar inicio

    # 5. Test de integraciÃ³n
    print(&quot;\nğŸ§ª [5/6] Ejecutando test de integraciÃ³n...&quot;)
    try:
        # Health check
        health = requests.get(&quot;http://localhost:8000/health&quot;, timeout=5)
        assert health.status_code == 200, f&quot;Health check fallÃ³: {health.status_code}&quot;
        print(&quot;âœ… Health check OK&quot;)

        # Prediction test
        test_data = {
            &quot;CreditScore&quot;: 650,
            &quot;Geography&quot;: &quot;France&quot;,
            &quot;Gender&quot;: &quot;Male&quot;,
            &quot;Age&quot;: 35,
            &quot;Tenure&quot;: 5,
            &quot;Balance&quot;: 50000.0,
            &quot;NumOfProducts&quot;: 2,
            &quot;HasCrCard&quot;: 1,
            &quot;IsActiveMember&quot;: 1,
            &quot;EstimatedSalary&quot;: 60000.0
        }
        pred = requests.post(&quot;http://localhost:8000/predict&quot;, json=test_data, timeout=5)
        assert pred.status_code == 200, f&quot;Prediction fallÃ³: {pred.status_code}&quot;
        result = pred.json()
        assert &quot;probability&quot; in result, &quot;Response sin probability&quot;
        print(f&quot;âœ… Prediction OK: {result}&quot;)

    except Exception as e:
        print(f&quot;âŒ Test fallÃ³: {e}&quot;)
        api_process.terminate()
        return False

    # 6. Cleanup
    print(&quot;\nğŸ§¹ [6/6] Limpiando...&quot;)
    api_process.terminate()
    api_process.wait()
    print(&quot;âœ… API terminada&quot;)

    print(&quot;\n&quot; + &quot;=&quot; * 60)
    print(&quot;ğŸ‰ PIPELINE E2E COMPLETADO EXITOSAMENTE&quot;)
    print(&quot;=&quot; * 60)
    return True

if __name__ == &quot;__main__&quot;:
    success = run_e2e_pipeline()
    sys.exit(0 if success else 1)
</code></pre>
<h3>SoluciÃ³n 20.2: Health Check Script</h3>
<pre><code class="language-python">#!/usr/bin/env python3
&quot;&quot;&quot;
scripts/health_check.py
Verifica salud de todos los servicios del stack MLOps
&quot;&quot;&quot;

import requests
from dataclasses import dataclass
from typing import List
from datetime import datetime

@dataclass
class ServiceHealth:
    name: str
    url: str
    healthy: bool
    status_code: int | None
    response_time_ms: float
    details: str

def check_service(name: str, url: str, timeout: int = 5) -&gt; ServiceHealth:
    &quot;&quot;&quot;Verifica salud de un servicio.&quot;&quot;&quot;
    start = datetime.now()
    try:
        response = requests.get(url, timeout=timeout)
        response_time = (datetime.now() - start).total_seconds() * 1000

        return ServiceHealth(
            name=name,
            url=url,
            healthy=response.status_code == 200,
            status_code=response.status_code,
            response_time_ms=response_time,
            details=response.json() if response.headers.get('content-type', '').startswith('application/json') else response.text[:100]
        )
    except requests.exceptions.ConnectionError:
        return ServiceHealth(name, url, False, None, 0, &quot;Connection refused&quot;)
    except requests.exceptions.Timeout:
        return ServiceHealth(name, url, False, None, timeout * 1000, &quot;Timeout&quot;)
    except Exception as e:
        return ServiceHealth(name, url, False, None, 0, str(e))

def check_all_services() -&gt; List[ServiceHealth]:
    &quot;&quot;&quot;Verifica todos los servicios del stack.&quot;&quot;&quot;
    services = [
        (&quot;MLflow&quot;, &quot;http://localhost:5000/health&quot;),
        (&quot;BankChurn API&quot;, &quot;http://localhost:8001/health&quot;),
        (&quot;CarVision API&quot;, &quot;http://localhost:8002/health&quot;),
        (&quot;CarVision Dashboard&quot;, &quot;http://localhost:8501/healthz&quot;),
        (&quot;TelecomAI API&quot;, &quot;http://localhost:8003/health&quot;),
        (&quot;Prometheus&quot;, &quot;http://localhost:9090/-/healthy&quot;),
        (&quot;Grafana&quot;, &quot;http://localhost:3000/api/health&quot;),
    ]

    return [check_service(name, url) for name, url in services]

def generate_report(results: List[ServiceHealth]) -&gt; str:
    &quot;&quot;&quot;Genera reporte de salud.&quot;&quot;&quot;
    healthy_count = sum(1 for r in results if r.healthy)
    total = len(results)

    lines = [
        &quot;=&quot; * 70,
        f&quot;ğŸ¥ HEALTH CHECK REPORT - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}&quot;,
        &quot;=&quot; * 70,
        f&quot;Status: {healthy_count}/{total} services healthy&quot;,
        &quot;&quot;,
        f&quot;{'Service':&lt;20} {'Status':&lt;10} {'Code':&lt;6} {'Time':&lt;10} {'Details'}&quot;,
        &quot;-&quot; * 70,
    ]

    for r in results:
        status = &quot;âœ… UP&quot; if r.healthy else &quot;âŒ DOWN&quot;
        code = str(r.status_code) if r.status_code else &quot;N/A&quot;
        time_str = f&quot;{r.response_time_ms:.0f}ms&quot; if r.response_time_ms &gt; 0 else &quot;N/A&quot;
        details = r.details[:30] + &quot;...&quot; if len(r.details) &gt; 30 else r.details
        lines.append(f&quot;{r.name:&lt;20} {status:&lt;10} {code:&lt;6} {time_str:&lt;10} {details}&quot;)

    lines.extend([
        &quot;-&quot; * 70,
        f&quot;Overall: {'ğŸŸ¢ ALL HEALTHY' if healthy_count == total else 'ğŸ”´ DEGRADED'}&quot;,
        &quot;=&quot; * 70,
    ])

    return &quot;\n&quot;.join(lines)

if __name__ == &quot;__main__&quot;:
    results = check_all_services()
    print(generate_report(results))

    # Exit code para CI/CD
    import sys
    sys.exit(0 if all(r.healthy for r in results) else 1)
</code></pre>
<h2>MÃ³dulo 21: Glosario (Autoestudio)</h2>
<h3>SoluciÃ³n 21.1: Flashcards de TÃ©rminos</h3>
<pre><code class="language-markdown">&lt;!-- Formato: Pregunta | Respuesta --&gt;

# Flashcards MLOps - 25 TÃ©rminos Clave

Â¿QuÃ© es Data Drift? | Cambio en la distribuciÃ³n de features P(X) entre training y producciÃ³n

Â¿QuÃ© es Concept Drift? | Cambio en la relaciÃ³n P(Y|X) entre features y target

Â¿Diferencia entre Precision y Recall? | Precision=TP/(TP+FP) &quot;de los que predije positivos, cuÃ¡ntos eran reales&quot;. Recall=TP/(TP+FN) &quot;de los positivos reales, cuÃ¡ntos detectÃ©&quot;

Â¿QuÃ© resuelve class_weight='balanced'? | Penaliza mÃ¡s los errores en la clase minoritaria, inversamente proporcional a su frecuencia

Â¿Para quÃ© sirve ColumnTransformer? | Aplicar diferentes transformaciones a diferentes columnas en paralelo dentro de un Pipeline sklearn

Â¿QuÃ© es training-serving skew? | Diferencia entre el preprocesamiento en training vs producciÃ³n que causa predicciones incorrectas

Â¿Por quÃ© usar Pipeline en vez de pasos separados? | Evita data leakage, garantiza misma transformaciÃ³n en train/test/prod, serializa todo junto

Â¿QuÃ© hace @st.cache_resource? | Cachea recursos pesados (modelos, conexiones DB) que no deben recargarse en cada interacciÃ³n de Streamlit

Â¿QuÃ© es un ADR? | Architecture Decision Record - documento que registra una decisiÃ³n tÃ©cnica con contexto, alternativas y consecuencias

Â¿Diferencia entre liveness y readiness probe? | Liveness: reinicia pod si falla (muerto). Readiness: deja de enviar trÃ¡fico si falla (sobrecargado)

Â¿QuÃ© es multi-stage build en Docker? | Separar build (con compiladores) de runtime (solo binarios) para imÃ¡genes mÃ¡s pequeÃ±as y seguras

Â¿Por quÃ© usuario non-root en Docker? | Seguridad: si el container es comprometido, el atacante no tiene privilegios root

Â¿QuÃ© es PSI (Population Stability Index)? | MÃ©trica para detectar drift: &lt;0.1 no drift, 0.1-0.2 moderado, &gt;0.2 significativo

Â¿QuÃ© hace DVC? | Versiona datasets y modelos grandes junto con Git, sin guardarlos en el repo

Â¿QuÃ© es un Model Card? | DocumentaciÃ³n estandarizada de un modelo: propÃ³sito, mÃ©tricas, limitaciones, consideraciones Ã©ticas

Â¿Para quÃ© sirve HPA en Kubernetes? | Horizontal Pod Autoscaler: escala rÃ©plicas automÃ¡ticamente basado en mÃ©tricas (CPU, memoria)

Â¿QuÃ© es Feature Store? | Repositorio centralizado de features procesadas, reutilizables entre modelos y equipos

Â¿QuÃ© mide ROC-AUC? | Capacidad discriminatoria del modelo: probabilidad de rankear un positivo por encima de un negativo

Â¿Por quÃ© pytest fixtures? | Reutilizar setup de tests (datos, modelos) sin duplicar cÃ³digo, con scope controlado

Â¿QuÃ© hace mlflow.log_artifact()? | Guarda archivos (grÃ¡ficos, modelos, CSVs) asociados a un experimento para reproducibilidad

Â¿QuÃ© es SMOTE? | Synthetic Minority Over-sampling: genera ejemplos sintÃ©ticos de clase minoritaria interpolando entre vecinos

Â¿Por quÃ© src/ layout? | Evita importar cÃ³digo local en vez del paquete instalado, estructura profesional instalable

Â¿QuÃ© son Conventional Commits? | Formato estandarizado de mensajes: type(scope): description. Permite generar CHANGELOGs automÃ¡ticos

Â¿QuÃ© hace conftest.py? | Define fixtures compartidas para todos los tests del directorio, pytest lo descubre automÃ¡ticamente

Â¿QuÃ© es Pydantic? | LibrerÃ­a de validaciÃ³n de datos usando type hints. Valida, serializa y documenta esquemas automÃ¡ticamente
</code></pre>
<h2>MÃ³dulo 22: Checklist de ProducciÃ³n</h2>
<h3>SoluciÃ³n 22.1: AuditorÃ­a de Proyecto</h3>
<pre><code class="language-markdown"># AuditorÃ­a: CarVision-Market-Intelligence

## CÃ³digo âœ…
- [x] Type hints en todas las funciones (verificado: 100% en src/)
- [x] Docstrings en clases y mÃ©todos pÃºblicos
- [x] Sin secretos hardcodeados (verificado con gitleaks)
- [x] Linting pasando (ruff check src/ â†’ 0 errores)

## Testing âœ…
- [x] Coverage &gt;= 80% (actual: 97%)
- [x] Tests de datos (schema, rangos) â†’ test_data.py
- [x] Tests de modelo (predicciones vÃ¡lidas) â†’ test_pipeline.py
- [x] Tests de integraciÃ³n (API funcional) â†’ test_api.py

## CI/CD âœ…
- [x] Pipeline ejecuta en cada PR (ci-mlops.yml)
- [x] Tests ejecutan en mÃºltiples versiones Python (3.10, 3.11)
- [x] Security scanning configurado (Bandit, pip-audit, Trivy)
- [x] Docker build automatizado (GHCR push en main)

## DocumentaciÃ³n âš ï¸
- [x] README actualizado (badges, quickstart, arquitectura)
- [ ] Model Card completado â†’ PENDIENTE: crear docs/model_card.md
- [x] API documentada (Swagger en /docs)

## Observabilidad âš ï¸
- [x] Logging estructurado (common_utils.logger)
- [ ] MÃ©tricas de Prometheus â†’ PENDIENTE: aÃ±adir prometheus_client
- [x] Health endpoint implementado (/health)

## Issues Creados
1. #42: Crear Model Card para CarVision
2. #43: AÃ±adir mÃ©tricas Prometheus a FastAPI

## PuntuaciÃ³n Estimada
- CÃ³digo: 18/20
- Pipeline: 18/20
- Testing/CI: 19/20
- APIs: 13/15
- Tracking: 8/10
- Docs: 12/15

**TOTAL: 88/100 â†’ Senior Level ğŸ¥ˆ**
</code></pre>
<h2>MÃ³dulo 23: Recursos (PrÃ¡ctica)</h2>
<h3>SoluciÃ³n 23.1: Plan de Estudio Personalizado</h3>
<pre><code class="language-markdown"># Mi Plan de Estudio MLOps

## AutoevaluaciÃ³n (1-5)
| Ãrea | Nivel | Prioridad |
|------|:-----:|:---------:|
| Python moderno | 4 | Baja |
| sklearn Pipelines | 3 | Alta |
| Docker | 2 | Alta |
| CI/CD | 2 | Alta |
| Testing | 4 | Media |
| Observabilidad | 1 | Alta |

## Gaps Identificados
1. **Docker**: Solo uso bÃ¡sico, no multi-stage ni compose
2. **CI/CD**: No he configurado GitHub Actions desde cero
3. **Observabilidad**: No conozco Prometheus/Grafana

## Recursos Seleccionados
| Gap | Recurso | Tipo | Tiempo |
|-----|---------|------|:------:|
| Docker | [Docker Tutorial - Nana](https://youtube.com/...) ğŸ”´ | Video | 1h |
| Docker | Docker Mastery (Udemy) ğŸŸ¡ | Curso | 10h |
| CI/CD | [GitHub Actions Tutorial](https://youtube.com/...) ğŸ”´ | Video | 30m |
| CI/CD | MÃ³dulo 12 + Ejercicio 12.1 | GuÃ­a | 3h |
| Observabilidad | [Prometheus+Grafana - Nana](https://youtube.com/...) ğŸ”´ | Video | 50m |
| Observabilidad | MÃ³dulo 16 + prometheus-rules.yaml | GuÃ­a | 4h |

## Timeline
| Semana | MÃ³dulos | Recursos Externos | Entregable |
|:------:|---------|-------------------|------------|
| 1 | 07, 08 | sklearn Pipeline video | FeatureEngineer class |
| 2 | 11, 12 | CI/CD video + ejercicio | GitHub Actions workflow |
| 3 | 13 | Docker tutorial + compose | Multi-stage Dockerfile |
| 4 | 14, 15 | FastAPI video | API + Streamlit |
| 5 | 16 | Prometheus/Grafana video | MÃ©tricas + alertas |
| 6 | 17, 18 | K8s tutorial | Deployment manifest |
| 7 | 19, 20 | - | Model Card + E2E script |
| 8 | 21-23 + Simulacros | - | Speech preparado |

## Checkpoints
- [ ] Semana 2: Primer proyecto con CI verde
- [ ] Semana 4: API funcionando con Docker
- [ ] Semana 6: Stack completo en Kubernetes local
- [ ] Semana 8: Portafolio completo, simulacros hechos
</code></pre>
            </div>
        
            <!-- MÃ“DULO: PLANTILLAS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_PLANTILLAS" class="cover-title">PLANTILLAS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“‹ Plantillas Reutilizables â€” GuÃ­a MLOps</h1>
<blockquote>
<p><strong>Templates listos para usar en tus proyectos ML</strong></p>
<p>ğŸ“ <strong>Ver tambiÃ©n</strong>: <a href="#mod_index">templates/</a> contiene las plantillas como archivos individuales descargables.</p>
</blockquote>
<h2>ğŸ“„ 1. Template README.md</h2>
<pre><code class="language-markdown"># ğŸš€ [Nombre del Proyecto]

[![CI](https://github.com/USER/REPO/actions/workflows/ci.yml/badge.svg)](https://github.com/USER/REPO/actions)
[![Coverage](https://img.shields.io/badge/Coverage-XX%25-brightgreen)](reports/)
[![Python](https://img.shields.io/badge/Python-3.11-blue)](https://python.org)

&gt; Breve descripciÃ³n del proyecto en una lÃ­nea.

## ğŸ¯ MÃ©tricas del Modelo

| MÃ©trica | Valor |
|---------|-------|
| Accuracy | XX% |
| F1-Score | X.XX |
| Coverage | XX% |

## âš¡ Quick Start

```bash

# Clonar
git clone https://github.com/USER/REPO.git
cd REPO

# Instalar
pip install -e &quot;.[dev]&quot;

# Entrenar
make train

# Tests
make test

# Servir API
make serve
\`\`\`

## ğŸ“ Estructura

\`\`\`
proyecto/
â”œâ”€â”€ src/proyecto/      # CÃ³digo fuente
â”œâ”€â”€ app/               # APIs
â”œâ”€â”€ tests/             # Tests
â”œâ”€â”€ configs/           # ConfiguraciÃ³n
â””â”€â”€ artifacts/         # Modelos (gitignored)
\`\`\`

## ğŸ“– DocumentaciÃ³n

- [Model Card](#mod_model_card)
- [API Reference](#mod_api)
</code></pre>
<hr />
<h2>ğŸ“„ 2. Template pyproject.toml</h2>
<pre><code class="language-toml">[build-system]
requires = [&quot;setuptools&gt;=61.0&quot;]
build-backend = &quot;setuptools.build_meta&quot;

[project]
name = &quot;mi-proyecto&quot;
version = &quot;1.0.0&quot;
description = &quot;DescripciÃ³n del proyecto&quot;
readme = &quot;README.md&quot;
requires-python = &quot;&gt;=3.10&quot;
license = {text = &quot;MIT&quot;}

dependencies = [
    &quot;pandas&gt;=2.0.0&quot;,
    &quot;numpy&gt;=1.24.0&quot;,
    &quot;scikit-learn&gt;=1.3.0&quot;,
    &quot;pydantic&gt;=2.0.0&quot;,
    &quot;pyyaml&gt;=6.0&quot;,
]

[project.optional-dependencies]
api = [&quot;fastapi&gt;=0.104.0&quot;, &quot;uvicorn&gt;=0.24.0&quot;]
dev = [&quot;pytest&gt;=7.4.0&quot;, &quot;pytest-cov&gt;=4.1.0&quot;, &quot;black&gt;=23.0.0&quot;, &quot;ruff&gt;=0.1.0&quot;]
all = [&quot;mi-proyecto[api,dev]&quot;]

[tool.setuptools.packages.find]
where = [&quot;src&quot;]

[tool.pytest.ini_options]
testpaths = [&quot;tests&quot;]
addopts = &quot;-v --cov=src/&quot;

[tool.coverage.run]
source = [&quot;src&quot;]

[tool.coverage.report]
fail_under = 80
</code></pre>
<hr />
<h2>ğŸ“„ 3. Template Dockerfile</h2>
<pre><code class="language-dockerfile">
# Stage 1: Builder
FROM python:3.11-slim AS builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir --target=/deps -r requirements.txt

# Stage 2: Runtime
FROM python:3.11-slim
RUN useradd --create-home appuser
WORKDIR /app
COPY --from=builder /deps /usr/local/lib/python3.11/site-packages/
COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser artifacts/ ./artifacts/
USER appuser
EXPOSE 8000
HEALTHCHECK --interval=30s --timeout=3s CMD curl -f http://localhost:8000/health || exit 1
CMD [&quot;uvicorn&quot;, &quot;app.fastapi_app:app&quot;, &quot;--host&quot;, &quot;0.0.0.0&quot;, &quot;--port&quot;, &quot;8000&quot;]
</code></pre>
<hr />
<h2>ğŸ“„ 4. Template GitHub Actions</h2>
<pre><code class="language-yaml">name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.11', '3.12']

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: pip install -e &quot;.[dev]&quot;

      - name: Lint
        run: ruff check src/ tests/

      - name: Test
        run: pytest --cov=src/ --cov-fail-under=80
</code></pre>
<hr />
<h2>ğŸ“„ 5. Template conftest.py</h2>
<pre><code class="language-python">import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_data():
    np.random.seed(42)
    return pd.DataFrame({
        'feature1': np.random.randn(100),
        'feature2': np.random.randn(100),
        'target': np.random.randint(0, 2, 100)
    })

@pytest.fixture
def config():
    return {
        'model': {'n_estimators': 10, 'random_state': 42},
        'data': {'test_size': 0.2}
    }
</code></pre>
<hr />
<h2>ğŸ“„ 6. Template Model Card</h2>
<pre><code class="language-markdown">
# Model Card: [Nombre del Modelo]

## InformaciÃ³n General
- **Desarrollador**: [Tu nombre]
- **Fecha**: [Fecha]
- **VersiÃ³n**: 1.0.0
- **Tipo**: ClasificaciÃ³n binaria

## Uso Previsto
- **Usuarios**: [QuiÃ©n usarÃ¡ el modelo]
- **Casos de uso**: [Para quÃ© se usarÃ¡]

## MÃ©tricas

| MÃ©trica | Train | Test |
|---------|-------|------|
| Accuracy | X% | X% |
| Precision | X% | X% |
| Recall | X% | X% |
| F1 | X% | X% |

## Limitaciones
- [LimitaciÃ³n 1]
- [LimitaciÃ³n 2]

## Consideraciones Ã‰ticas
- [ConsideraciÃ³n 1]
</code></pre>
<hr />
<h2>ğŸ“„ 7. Template .gitignore</h2>
<pre><code class="language-gitignore">
# Python
__pycache__/
*.py[cod]
*.egg-info/
dist/
build/

# Environments
.venv/
venv/

# Data &amp; Models
data/
artifacts/
*.joblib
mlruns/

# IDE
.vscode/
.idea/

# Coverage
.coverage
htmlcov/

# Env
.env
</code></pre>
<hr />
<h2>ğŸ“„ 8. Template Makefile</h2>
<pre><code class="language-makefile">.PHONY: install test lint train serve clean

install:
pip install -e &quot;.[dev]&quot;

test:
pytest --cov=src/ --cov-fail-under=80

lint:
ruff check src/ tests/
black --check src/ tests/

format:
black src/ tests/
ruff check --fix src/ tests/

train:
python -m src.proyecto.training

serve:
uvicorn app.fastapi_app:app --reload --port 8000

clean:
rm -rf __pycache__ .pytest_cache .coverage htmlcov
</code></pre>
<hr />
<h2>ğŸ“š MÃ³dulos que Usan Estas Plantillas</h2>
<table>
<thead>
<tr>
<th>Plantilla</th>
<th>MÃ³dulo</th>
</tr>
</thead>
<tbody>
<tr>
<td>README, pyproject, Makefile</td>
<td><a href="#mod_03_ESTRUCTURA_PROYECTO">03_ESTRUCTURA_PROYECTO.md</a></td>
</tr>
<tr>
<td>GitHub Actions</td>
<td><a href="#mod_12_CI_CD">12_CI_CD.md</a></td>
</tr>
<tr>
<td>Dockerfile</td>
<td><a href="#mod_13_DOCKER">13_DOCKER.md</a></td>
</tr>
<tr>
<td>Model Card</td>
<td><a href="#mod_19_DOCUMENTACION">19_DOCUMENTACION.md</a></td>
</tr>
</tbody>
</table>
<hr />
<div align="center">

[â† Volver al Ãndice](#mod_00_INDICE) | [templates/](#mod_index)

</div>
            </div>
        
            <!-- MÃ“DULO: DECISIONES_TECH.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_DECISIONES_TECH" class="cover-title">DECISIONES TÃ‰CNICAS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>âš–ï¸ Decisiones TÃ©cnicas â€” ADRs del Portafolio</h1>
<blockquote>
<p><strong>Por quÃ© elegimos cada herramienta y tecnologÃ­a</strong></p>
</blockquote>
<p><em>Ãšltima actualizaciÃ³n: Diciembre 2025</em></p>
<h2>ğŸ“‹ Ãndice de ADRs</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">#</th>
<th style="text-align: left;">DecisiÃ³n</th>
<th style="text-align: left;">Alternativas</th>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Estado</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">001</td>
<td style="text-align: left;">Python 3.11+</td>
<td style="text-align: left;">R, Julia</td>
<td style="text-align: center;">01</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">002</td>
<td style="text-align: left;">scikit-learn</td>
<td style="text-align: left;">XGBoost, LightGBM</td>
<td style="text-align: center;">07</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">003</td>
<td style="text-align: left;">Pydantic v2</td>
<td style="text-align: left;">dataclasses, attrs</td>
<td style="text-align: center;">01</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">004</td>
<td style="text-align: left;">FastAPI</td>
<td style="text-align: left;">Flask, Django</td>
<td style="text-align: center;">14</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">005</td>
<td style="text-align: left;">pytest</td>
<td style="text-align: left;">unittest</td>
<td style="text-align: center;">11</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">006</td>
<td style="text-align: left;">GitHub Actions</td>
<td style="text-align: left;">Jenkins, GitLab CI</td>
<td style="text-align: center;">12</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">007</td>
<td style="text-align: left;">MLflow</td>
<td style="text-align: left;">W&amp;B, Neptune</td>
<td style="text-align: center;">10</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">008</td>
<td style="text-align: left;">Docker</td>
<td style="text-align: left;">Conda, Poetry</td>
<td style="text-align: center;">13, 17</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">009</td>
<td style="text-align: left;">DVC</td>
<td style="text-align: left;">Git LFS, S3 directo</td>
<td style="text-align: center;">06</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">010</td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: left;">Gradio, Panel</td>
<td style="text-align: center;">15</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">011</td>
<td style="text-align: left;">Prometheus + Grafana</td>
<td style="text-align: left;">Datadog, New Relic</td>
<td style="text-align: center;">16</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">012</td>
<td style="text-align: left;">Kubernetes</td>
<td style="text-align: left;">Docker Swarm, ECS</td>
<td style="text-align: center;">18</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">013</td>
<td style="text-align: left;">Ruff</td>
<td style="text-align: left;">Flake8 + Black + isort</td>
<td style="text-align: center;">01</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
<tr>
<td style="text-align: left;">014</td>
<td style="text-align: left;">src/ Layout</td>
<td style="text-align: left;">Flat layout</td>
<td style="text-align: center;">03</td>
<td style="text-align: left;">âœ… Aceptada</td>
</tr>
</tbody>
</table>
<h2>ADR-001: Python 3.11+</h2>
<h3>Contexto</h3>
<p>Necesitamos un lenguaje para todo el stack ML.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Python 3.11+ como lenguaje principal.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>R</strong>: Mejor para estadÃ­stica, peor para APIs y producciÃ³n</li>
<li><strong>Julia</strong>: MÃ¡s rÃ¡pido, ecosistema menos maduro</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Ecosistema ML mÃ¡s completo</li>
<li>âœ… FastAPI, Pydantic nativos</li>
<li>âœ… Mayor pool de talento</li>
<li>âŒ MÃ¡s lento que lenguajes compilados</li>
</ul>
<h2>ADR-002: scikit-learn para Modelos</h2>
<h3>Contexto</h3>
<p>Necesitamos un framework ML para clasificaciÃ³n/regresiÃ³n tabular.</p>
<h3>DecisiÃ³n</h3>
<p>Usar scikit-learn como framework principal.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>XGBoost/LightGBM</strong>: MÃ¡s performance, menos integraciÃ³n con pipelines</li>
<li><strong>PyTorch</strong>: Overkill para datos tabulares</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Pipelines unificados con <code>Pipeline</code> y <code>ColumnTransformer</code></li>
<li>âœ… FÃ¡cil de testear y serializar</li>
<li>âœ… DocumentaciÃ³n excelente</li>
<li>âŒ Menos performance que gradient boosting dedicado</li>
</ul>
<h2>ADR-003: Pydantic v2 para ConfiguraciÃ³n</h2>
<h3>Contexto</h3>
<p>Necesitamos validar configuraciÃ³n de forma robusta.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Pydantic v2 para todas las configuraciones.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>dataclasses</strong>: Sin validaciÃ³n built-in</li>
<li><strong>attrs</strong>: Menos popular, similar funcionalidad</li>
<li><strong>Dict/YAML directo</strong>: Sin validaciÃ³n</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… ValidaciÃ³n automÃ¡tica de tipos</li>
<li>âœ… Errores claros en config invÃ¡lida</li>
<li>âœ… IntegraciÃ³n perfecta con FastAPI</li>
<li>âŒ Dependencia adicional</li>
</ul>
<p><strong>Ejemplo:</strong></p>
<pre><code class="language-python">class ModelConfig(BaseModel):
    n_estimators: int = Field(ge=10, le=500)
    max_depth: int | None = Field(default=None, ge=1)
</code></pre>
<h2>ADR-004: FastAPI para APIs</h2>
<h3>Contexto</h3>
<p>Necesitamos servir modelos via HTTP.</p>
<h3>DecisiÃ³n</h3>
<p>Usar FastAPI para todas las APIs.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Flask</strong>: MÃ¡s simple, sin async, sin docs automÃ¡ticas</li>
<li><strong>Django</strong>: Overkill para APIs ML</li>
<li><strong>gRPC</strong>: MÃ¡s complejo, mejor para microservicios internos</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Async por defecto</li>
<li>âœ… Docs OpenAPI automÃ¡ticas</li>
<li>âœ… ValidaciÃ³n con Pydantic integrada</li>
<li>âœ… Rendimiento excelente</li>
<li>âŒ Menos tutoriales que Flask</li>
</ul>
<h2>ADR-005: pytest para Testing</h2>
<h3>Contexto</h3>
<p>Necesitamos un framework de testing.</p>
<h3>DecisiÃ³n</h3>
<p>Usar pytest con pytest-cov.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>unittest</strong>: MÃ¡s verboso, menos features</li>
<li><strong>nose2</strong>: Abandonado</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Fixtures potentes</li>
<li>âœ… Plugins (pytest-cov, pytest-mock)</li>
<li>âœ… Sintaxis simple con assert</li>
<li>âœ… ParametrizaciÃ³n fÃ¡cil</li>
</ul>
<h2>ADR-006: GitHub Actions para CI/CD</h2>
<h3>Contexto</h3>
<p>Necesitamos CI/CD automatizado.</p>
<h3>DecisiÃ³n</h3>
<p>Usar GitHub Actions.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Jenkins</strong>: Self-hosted, mÃ¡s mantenimiento</li>
<li><strong>GitLab CI</strong>: Requiere migrar repos</li>
<li><strong>CircleCI</strong>: Costo adicional</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Integrado con GitHub</li>
<li>âœ… Gratis para repos pÃºblicos</li>
<li>âœ… Matrix testing fÃ¡cil</li>
<li>âœ… Marketplace de actions</li>
<li>âŒ Vendor lock-in con GitHub</li>
</ul>
<h2>ADR-007: MLflow para Tracking</h2>
<h3>Contexto</h3>
<p>Necesitamos tracking de experimentos y registry de modelos.</p>
<h3>DecisiÃ³n</h3>
<p>Usar MLflow (local + server).</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>W&amp;B (Weights &amp; Biases)</strong>: Mejor UI, costo para equipos</li>
<li><strong>Neptune</strong>: Similar a W&amp;B</li>
<li><strong>DVC</strong>: MÃ¡s para datos que experimentos</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Open source, sin vendor lock-in</li>
<li>âœ… Model Registry integrado</li>
<li>âœ… Funciona local sin servidor</li>
<li>âŒ UI menos moderna que W&amp;B</li>
</ul>
<h2>ADR-008: Docker para Empaquetado</h2>
<h3>Contexto</h3>
<p>Necesitamos empaquetar aplicaciones para deploy.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Docker con multi-stage builds.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Conda pack</strong>: Solo Python, sin proceso completo</li>
<li><strong>Poetry</strong>: Solo dependencias, no containerizaciÃ³n</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Reproducibilidad total</li>
<li>âœ… Funciona en cualquier cloud</li>
<li>âœ… Compose para desarrollo local</li>
<li>âŒ Overhead de imagen</li>
</ul>
<h2>ADR-009: DVC para Versionado de Datos</h2>
<h3>Contexto</h3>
<p>Necesitamos versionar datasets grandes sin guardarlos en Git.</p>
<h3>DecisiÃ³n</h3>
<p>Usar DVC (Data Version Control).</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Git LFS</strong>: Pago por storage, menos features</li>
<li><strong>S3 directo</strong>: Sin versionado semÃ¡ntico</li>
<li><strong>Delta Lake</strong>: Overkill para nuestro tamaÃ±o</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Versionado semÃ¡ntico de datos</li>
<li>âœ… Pipelines reproducibles</li>
<li>âœ… IntegraciÃ³n con Git</li>
<li>âŒ Curva de aprendizaje adicional</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_06_VERSIONADO_DATOS">MÃ³dulo 06</a></p>
</blockquote>
<h2>ADR-010: Streamlit para Dashboards</h2>
<h3>Contexto</h3>
<p>Necesitamos crear dashboards interactivos para stakeholders.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Streamlit para dashboards ML.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Gradio</strong>: MÃ¡s simple, menos personalizable</li>
<li><strong>Panel</strong>: Menos popular, mÃ¡s verboso</li>
<li><strong>Dash</strong>: MÃ¡s complejo, mejor para apps empresariales</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Python puro, sin HTML/CSS/JS</li>
<li>âœ… Reactivo por defecto</li>
<li>âœ… Caching de modelos integrado</li>
<li>âœ… Deploy fÃ¡cil (Streamlit Cloud)</li>
<li>âŒ Menos control sobre UI que frameworks web</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_15_STREAMLIT">MÃ³dulo 15</a></p>
</blockquote>
<h2>ADR-011: Prometheus + Grafana para Observabilidad</h2>
<h3>Contexto</h3>
<p>Necesitamos monitorear modelos en producciÃ³n y detectar drift.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Prometheus para mÃ©tricas y Grafana para dashboards.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Datadog</strong>: Excelente pero costoso</li>
<li><strong>New Relic</strong>: Similar a Datadog</li>
<li><strong>CloudWatch/Stackdriver</strong>: Vendor lock-in</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Open source, sin costo</li>
<li>âœ… EstÃ¡ndar de la industria</li>
<li>âœ… Alertas configurables</li>
<li>âœ… IntegraciÃ³n con K8s nativa</li>
<li>âŒ MÃ¡s setup que SaaS</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_16_OBSERVABILIDAD">MÃ³dulo 16</a></p>
</blockquote>
<h2>ADR-012: Kubernetes para OrquestaciÃ³n</h2>
<h3>Contexto</h3>
<p>Necesitamos orquestar contenedores en producciÃ³n con auto-scaling.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Kubernetes para deployment.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Docker Swarm</strong>: MÃ¡s simple, menos features</li>
<li><strong>ECS/Fargate</strong>: Vendor lock-in AWS</li>
<li><strong>Nomad</strong>: Menos adopciÃ³n</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… EstÃ¡ndar de la industria</li>
<li>âœ… Auto-scaling (HPA)</li>
<li>âœ… Self-healing (probes)</li>
<li>âœ… Portable entre clouds</li>
<li>âŒ Curva de aprendizaje alta</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_18_INFRAESTRUCTURA">MÃ³dulo 18</a></p>
</blockquote>
<h2>ADR-013: Ruff para Linting</h2>
<h3>Contexto</h3>
<p>Necesitamos herramientas de calidad de cÃ³digo rÃ¡pidas.</p>
<h3>DecisiÃ³n</h3>
<p>Usar Ruff como linter y formateador unificado.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Flake8 + Black + isort</strong>: MÃºltiples herramientas, mÃ¡s lento</li>
<li><strong>Pylint</strong>: Muy lento, muchos false positives</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… 10-100x mÃ¡s rÃ¡pido que alternativas</li>
<li>âœ… Una herramienta = una config</li>
<li>âœ… Compatible con reglas de Flake8</li>
<li>âœ… Formateador incluido</li>
<li>âŒ Herramienta relativamente nueva</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_01_PYTHON_MODERNO">MÃ³dulo 01</a> - Glosario: <a href="21_GLOSARIO.md#ruff">Ruff</a></p>
</blockquote>
<h2>ADR-014: src/ Layout para Proyectos</h2>
<h3>Contexto</h3>
<p>Necesitamos una estructura de proyecto profesional e instalable.</p>
<h3>DecisiÃ³n</h3>
<p>Usar src/ layout en todos los proyectos.</p>
<h3>Alternativas Consideradas</h3>
<ul>
<li><strong>Flat layout</strong>: MÃ¡s simple pero problemÃ¡tico con imports</li>
<li><strong>Monorepo</strong>: MÃ¡s complejo para este tamaÃ±o</li>
</ul>
<h3>Consecuencias</h3>
<ul>
<li>âœ… Evita importar cÃ³digo local en vez del paquete</li>
<li>âœ… Estructura profesional estÃ¡ndar</li>
<li>âœ… Instalable con <code>pip install -e .</code></li>
<li>âŒ Un nivel mÃ¡s de directorios</li>
</ul>
<blockquote>
<p>ğŸ“– Ver <a href="#mod_03_ESTRUCTURA_PROYECTO">MÃ³dulo 03</a></p>
</blockquote>
<h2>ğŸ“Š Matriz de Decisiones Resumen</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Ãrea</th>
<th style="text-align: left;">Herramienta</th>
<th style="text-align: left;">Por quÃ©</th>
<th style="text-align: center;">MÃ³dulo</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Lenguaje</td>
<td style="text-align: left;">Python 3.11+</td>
<td style="text-align: left;">Ecosistema ML</td>
<td style="text-align: center;">01</td>
</tr>
<tr>
<td style="text-align: left;">ML Framework</td>
<td style="text-align: left;">scikit-learn</td>
<td style="text-align: left;">Pipelines unificados</td>
<td style="text-align: center;">07</td>
</tr>
<tr>
<td style="text-align: left;">Config</td>
<td style="text-align: left;">Pydantic v2</td>
<td style="text-align: left;">ValidaciÃ³n + FastAPI</td>
<td style="text-align: center;">01</td>
</tr>
<tr>
<td style="text-align: left;">API</td>
<td style="text-align: left;">FastAPI</td>
<td style="text-align: left;">Async + docs auto</td>
<td style="text-align: center;">14</td>
</tr>
<tr>
<td style="text-align: left;">Dashboard</td>
<td style="text-align: left;">Streamlit</td>
<td style="text-align: left;">Python puro, reactivo</td>
<td style="text-align: center;">15</td>
</tr>
<tr>
<td style="text-align: left;">Testing</td>
<td style="text-align: left;">pytest</td>
<td style="text-align: left;">Fixtures + plugins</td>
<td style="text-align: center;">11</td>
</tr>
<tr>
<td style="text-align: left;">CI/CD</td>
<td style="text-align: left;">GitHub Actions</td>
<td style="text-align: left;">IntegraciÃ³n nativa</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td style="text-align: left;">Tracking</td>
<td style="text-align: left;">MLflow</td>
<td style="text-align: left;">Open source + local</td>
<td style="text-align: center;">10</td>
</tr>
<tr>
<td style="text-align: left;">Versionado datos</td>
<td style="text-align: left;">DVC</td>
<td style="text-align: left;">Git + datos grandes</td>
<td style="text-align: center;">06</td>
</tr>
<tr>
<td style="text-align: left;">Container</td>
<td style="text-align: left;">Docker</td>
<td style="text-align: left;">Reproducibilidad</td>
<td style="text-align: center;">13, 17</td>
</tr>
<tr>
<td style="text-align: left;">OrquestaciÃ³n</td>
<td style="text-align: left;">Kubernetes</td>
<td style="text-align: left;">Auto-scaling, probes</td>
<td style="text-align: center;">18</td>
</tr>
<tr>
<td style="text-align: left;">Monitoreo</td>
<td style="text-align: left;">Prometheus + Grafana</td>
<td style="text-align: left;">Open source, estÃ¡ndar</td>
<td style="text-align: center;">16</td>
</tr>
<tr>
<td style="text-align: left;">Linting</td>
<td style="text-align: left;">Ruff</td>
<td style="text-align: left;">RÃ¡pido, unificado</td>
<td style="text-align: center;">01</td>
</tr>
<tr>
<td style="text-align: left;">Estructura</td>
<td style="text-align: left;">src/ layout</td>
<td style="text-align: left;">Profesional, instalable</td>
<td style="text-align: center;">03</td>
</tr>
</tbody>
</table>
<h2>ğŸ”— Referencias</h2>
<ul>
<li><a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> - Videos y cursos por herramienta</li>
<li><a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a> - Definiciones detalladas de cada herramienta</li>
</ul>
            </div>
        
            <!-- MÃ“DULO: RUBRICA_EVALUACION.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_RUBRICA_EVALUACION" class="cover-title">RÃšBRICA DE EVALUACIÃ“N</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ“Š RÃºbrica de EvaluaciÃ³n â€” Portfolio MLOps</h1>
<blockquote>
<p><strong>Criterios profesionales para evaluar proyectos ML</strong></p>
</blockquote>
<h2>ğŸ¯ PuntuaciÃ³n Total: 100 puntos</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Rango</th>
<th style="text-align: left;">Nivel</th>
<th style="text-align: left;">DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">90-100</td>
<td style="text-align: left;"><strong>Staff/Principal</strong></td>
<td style="text-align: left;">Listo para liderar equipos ML</td>
</tr>
<tr>
<td style="text-align: center;">80-89</td>
<td style="text-align: left;"><strong>Senior</strong></td>
<td style="text-align: left;">Production-ready, contrataciÃ³n inmediata</td>
</tr>
<tr>
<td style="text-align: center;">70-79</td>
<td style="text-align: left;"><strong>Mid-Level</strong></td>
<td style="text-align: left;">SÃ³lido, necesita pulir detalles</td>
</tr>
<tr>
<td style="text-align: center;">60-69</td>
<td style="text-align: left;"><strong>Junior+</strong></td>
<td style="text-align: left;">Funcional, falta madurez</td>
</tr>
<tr>
<td style="text-align: center;">&lt;60</td>
<td style="text-align: left;"><strong>En desarrollo</strong></td>
<td style="text-align: left;">Requiere mÃ¡s trabajo</td>
</tr>
</tbody>
</table>
<h2>ğŸ“‹ Criterios de EvaluaciÃ³n</h2>
<h3>1. Calidad del CÃ³digo (20 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Type hints</td>
<td style="text-align: center;">5</td>
<td style="text-align: left;">100% de funciones pÃºblicas tipadas</td>
</tr>
<tr>
<td style="text-align: left;">Docstrings</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Todas las clases y funciones documentadas</td>
</tr>
<tr>
<td style="text-align: left;">Pydantic configs</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">ConfiguraciÃ³n validada, no dicts crudos</td>
</tr>
<tr>
<td style="text-align: left;">src/ layout</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Estructura profesional instalable</td>
</tr>
<tr>
<td style="text-align: left;">SOLID principles</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">CÃ³digo modular y extensible</td>
</tr>
</tbody>
</table>
<p><strong>Ejemplo 5/5 en type hints:</strong></p>
<pre><code class="language-python">def predict(self, features: pd.DataFrame) -&gt; np.ndarray:
    &quot;&quot;&quot;Generate predictions for input features.&quot;&quot;&quot;
    return self.model.predict(features)
</code></pre>
<h3>2. Pipeline ML (20 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">sklearn Pipeline</td>
<td style="text-align: center;">6</td>
<td style="text-align: left;">Pipeline unificado (no pasos sueltos)</td>
</tr>
<tr>
<td style="text-align: left;">ColumnTransformer</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Preprocessing organizado</td>
</tr>
<tr>
<td style="text-align: left;">Custom Transformer</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Al menos 1 transformer propio</td>
</tr>
<tr>
<td style="text-align: left;">Data leakage prevention</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">drop_columns correcto, sin target leak</td>
</tr>
<tr>
<td style="text-align: left;">Reproducibilidad</td>
<td style="text-align: center;">2</td>
<td style="text-align: left;">random_state fijado</td>
</tr>
</tbody>
</table>
<p><strong>Ejemplo 6/6 en Pipeline:</strong></p>
<pre><code class="language-python">pipe = Pipeline([
    (&quot;features&quot;, FeatureEngineer()),
    (&quot;preprocess&quot;, ColumnTransformer([...])),
    (&quot;model&quot;, RandomForestClassifier())
])
</code></pre>
<h3>3. Testing y CI/CD (20 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Coverage â‰¥80%</td>
<td style="text-align: center;">6</td>
<td style="text-align: left;">Medido con pytest-cov</td>
</tr>
<tr>
<td style="text-align: left;">Unit tests</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Tests de funciones individuales</td>
</tr>
<tr>
<td style="text-align: left;">Integration tests</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Tests de pipeline completo</td>
</tr>
<tr>
<td style="text-align: left;">GitHub Actions</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">CI automÃ¡tico en cada push</td>
</tr>
<tr>
<td style="text-align: left;">Security scanning</td>
<td style="text-align: center;">2</td>
<td style="text-align: left;">Bandit, pip-audit, o similar</td>
</tr>
</tbody>
</table>
<p><strong>Ejemplo 6/6 en Coverage:</strong></p>
<pre><code class="language-yaml"># ci.yml
- name: Test with coverage
  run: pytest --cov=src/ --cov-fail-under=80
</code></pre>
<h3>4. ContainerizaciÃ³n y APIs (15 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Dockerfile multi-stage</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Build y runtime separados</td>
</tr>
<tr>
<td style="text-align: left;">Non-root user</td>
<td style="text-align: center;">2</td>
<td style="text-align: left;">Seguridad bÃ¡sica</td>
</tr>
<tr>
<td style="text-align: left;">FastAPI schemas</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Pydantic request/response</td>
</tr>
<tr>
<td style="text-align: left;">Health endpoint</td>
<td style="text-align: center;">2</td>
<td style="text-align: left;">/health funcional</td>
</tr>
<tr>
<td style="text-align: left;">Error handling</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Respuestas HTTP correctas</td>
</tr>
</tbody>
</table>
<h3>5. Experiment Tracking (10 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">MLflow logging</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Params, metrics, artifacts</td>
</tr>
<tr>
<td style="text-align: left;">Model Registry</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Modelo registrado con versiÃ³n</td>
</tr>
<tr>
<td style="text-align: left;">ComparaciÃ³n experimentos</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">MÃºltiples runs comparables</td>
</tr>
</tbody>
</table>
<h3>6. DocumentaciÃ³n (15 puntos)</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">Aspecto</th>
<th style="text-align: center;">Puntos</th>
<th style="text-align: left;">Criterio</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">README profesional</td>
<td style="text-align: center;">5</td>
<td style="text-align: left;">Badges, quickstart, arquitectura</td>
</tr>
<tr>
<td style="text-align: left;">Model Card</td>
<td style="text-align: center;">4</td>
<td style="text-align: left;">Performance, limitaciones, uso</td>
</tr>
<tr>
<td style="text-align: left;">Docstrings</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">CÃ³digo autodocumentado</td>
</tr>
<tr>
<td style="text-align: left;">ADRs</td>
<td style="text-align: center;">3</td>
<td style="text-align: left;">Decisiones tÃ©cnicas explicadas</td>
</tr>
</tbody>
</table>
<h2>ğŸ“Š Checklist RÃ¡pido por Proyecto</h2>
<h3>BankChurn-Predictor</h3>
<ul>
<li>[ ] Pipeline con ResampleClassifier</li>
<li>[ ] Coverage â‰¥79%</li>
<li>[ ] MLflow tracking</li>
<li>[ ] FastAPI /predict endpoint</li>
<li>[ ] Dockerfile funcional</li>
</ul>
<h3>CarVision-Market-Intelligence</h3>
<ul>
<li>[ ] FeatureEngineer custom transformer</li>
<li>[ ] Coverage â‰¥80%</li>
<li>[ ] Streamlit dashboard</li>
<li>[ ] drop_columns para evitar leakage</li>
</ul>
<h3>TelecomAI-Customer-Intelligence</h3>
<ul>
<li>[ ] Pipeline sklearn completo</li>
<li>[ ] Coverage â‰¥80%</li>
<li>[ ] MÃºltiples modelos comparados</li>
<li>[ ] API funcional</li>
</ul>
<h2>ğŸ† Niveles de CertificaciÃ³n</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Nivel</th>
<th style="text-align: center;">PuntuaciÃ³n</th>
<th style="text-align: center;">Badge</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">MLOps Practitioner</td>
<td style="text-align: center;">70-79</td>
<td style="text-align: center;">ğŸ¥‰</td>
</tr>
<tr>
<td style="text-align: left;">MLOps Engineer</td>
<td style="text-align: center;">80-89</td>
<td style="text-align: center;">ğŸ¥ˆ</td>
</tr>
<tr>
<td style="text-align: left;">Senior MLOps Engineer</td>
<td style="text-align: center;">90-94</td>
<td style="text-align: center;">ğŸ¥‡</td>
</tr>
<tr>
<td style="text-align: left;">Staff MLOps Engineer</td>
<td style="text-align: center;">95-100</td>
<td style="text-align: center;">ğŸ’</td>
</tr>
</tbody>
</table>
<h2>ğŸ“š EvaluaciÃ³n por MÃ³dulo</h2>
<p>Sistema de autoevaluaciÃ³n para cada fase del programa.</p>
<h3>Fase 1: Fundamentos (MÃ³dulos 01-06)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Criterio de AprobaciÃ³n</th>
<th style="text-align: left;">Ejercicio Requerido</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">01</td>
<td style="text-align: left;">Type hints en 100% funciones, config Pydantic</td>
<td style="text-align: left;">1.1, 1.2</td>
</tr>
<tr>
<td style="text-align: center;">02</td>
<td style="text-align: left;">Diagrama C4 de un proyecto, ADR documentado</td>
<td style="text-align: left;">2.1</td>
</tr>
<tr>
<td style="text-align: center;">03</td>
<td style="text-align: left;">Proyecto con src/ layout instalable</td>
<td style="text-align: left;">3.1</td>
</tr>
<tr>
<td style="text-align: center;">04</td>
<td style="text-align: left;">requirements.txt + lockfile, .env funcional</td>
<td style="text-align: left;">4.1</td>
</tr>
<tr>
<td style="text-align: center;">05</td>
<td style="text-align: left;">pre-commit configurado, commits convencionales</td>
<td style="text-align: left;">5.1</td>
</tr>
<tr>
<td style="text-align: center;">06</td>
<td style="text-align: left;">DVC pipeline funcional, remote configurado</td>
<td style="text-align: left;">6.1</td>
</tr>
</tbody>
</table>
<p><strong>Checkpoint Fase 1</strong>: Proyecto con estructura profesional, versionado con DVC</p>
<h3>Fase 2: ML Engineering (MÃ³dulos 07-10)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Criterio de AprobaciÃ³n</th>
<th style="text-align: left;">Ejercicio Requerido</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">07</td>
<td style="text-align: left;">Pipeline sklearn unificado, ColumnTransformer</td>
<td style="text-align: left;">7.1, 7.2</td>
</tr>
<tr>
<td style="text-align: center;">08</td>
<td style="text-align: left;">Custom Transformer (FeatureEngineer o similar)</td>
<td style="text-align: left;">8.1</td>
</tr>
<tr>
<td style="text-align: center;">09</td>
<td style="text-align: left;">Clase Trainer con fit/predict, cross-validation</td>
<td style="text-align: left;">9.1</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: left;">MLflow tracking: params, metrics, artifacts</td>
<td style="text-align: left;">10.1</td>
</tr>
</tbody>
</table>
<p><strong>Checkpoint Fase 2</strong>: Modelo entrenado con pipeline unificado, experimentos en MLflow</p>
<h3>Fase 3: MLOps Core (MÃ³dulos 11-16)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Criterio de AprobaciÃ³n</th>
<th style="text-align: left;">Ejercicio Requerido</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: left;">Tests con â‰¥80% coverage, conftest.py</td>
<td style="text-align: left;">11.1, 11.2</td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: left;">GitHub Actions CI funcionando en cada push</td>
<td style="text-align: left;">12.1</td>
</tr>
<tr>
<td style="text-align: center;">13</td>
<td style="text-align: left;">Dockerfile multi-stage, non-root user</td>
<td style="text-align: left;">13.1 (â†’17.1)</td>
</tr>
<tr>
<td style="text-align: center;">14</td>
<td style="text-align: left;">FastAPI /predict + /health, schemas Pydantic</td>
<td style="text-align: left;">14.1, 14.2</td>
</tr>
<tr>
<td style="text-align: center;">15</td>
<td style="text-align: left;">Dashboard Streamlit funcional</td>
<td style="text-align: left;">15.1</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: left;">Logging JSON estructurado</td>
<td style="text-align: left;">16.1</td>
</tr>
</tbody>
</table>
<p><strong>Checkpoint Fase 3</strong>: API dockerizada con CI/CD verde, â‰¥80% coverage</p>
<h3>Fase 4: ProducciÃ³n (MÃ³dulos 17-18)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Criterio de AprobaciÃ³n</th>
<th style="text-align: left;">Ejercicio Requerido</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">17</td>
<td style="text-align: left;">Docker Compose con API + MLflow + Prometheus</td>
<td style="text-align: left;">17.2</td>
</tr>
<tr>
<td style="text-align: center;">18</td>
<td style="text-align: left;">K8s Deployment con probes, HPA configurado</td>
<td style="text-align: left;">18.1, 18.2</td>
</tr>
</tbody>
</table>
<p><strong>Checkpoint Fase 4</strong>: Stack completo desplegable en K8s local</p>
<h3>Fase 5: EspecializaciÃ³n (MÃ³dulos 19-23)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">MÃ³dulo</th>
<th style="text-align: left;">Criterio de AprobaciÃ³n</th>
<th style="text-align: left;">Ejercicio Requerido</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">19</td>
<td style="text-align: left;">Model Card + Dataset Card completados</td>
<td style="text-align: left;">19.1, 19.2</td>
</tr>
<tr>
<td style="text-align: center;">20</td>
<td style="text-align: left;">Script E2E funcionando</td>
<td style="text-align: left;">20.1</td>
</tr>
<tr>
<td style="text-align: center;">21</td>
<td style="text-align: left;">Flashcards revisadas, tÃ©rminos dominados</td>
<td style="text-align: left;">21.1</td>
</tr>
<tr>
<td style="text-align: center;">22</td>
<td style="text-align: left;">AuditorÃ­a de proyecto completada</td>
<td style="text-align: left;">22.1</td>
</tr>
<tr>
<td style="text-align: center;">23</td>
<td style="text-align: left;">Plan de estudio personalizado</td>
<td style="text-align: left;">23.1</td>
</tr>
</tbody>
</table>
<p><strong>Checkpoint Fase 5</strong>: Portafolio documentado, listo para entrevistas</p>
<h2>ğŸ¯ AutoevaluaciÃ³n RÃ¡pida</h2>
<p>Completa esta tabla honestamente para identificar tus gaps:</p>
<pre><code class="language-markdown">| Competencia | 1-5 | Gap? | Recurso |
|-------------|:---:|:----:|---------|
| Type hints + Pydantic | _ | | MÃ³dulo 01 |
| sklearn Pipeline | _ | | MÃ³dulo 07 |
| Testing (pytest) | _ | | MÃ³dulo 11 |
| GitHub Actions | _ | | MÃ³dulo 12 |
| Docker | _ | | MÃ³dulo 13, 17 |
| FastAPI | _ | | MÃ³dulo 14 |
| MLflow | _ | | MÃ³dulo 10 |
| Observabilidad | _ | | MÃ³dulo 16 |
| Kubernetes | _ | | MÃ³dulo 18 |
</code></pre>
<blockquote>
<p>ğŸ“º Ver <a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a> para videos y cursos segÃºn tus gaps</p>
</blockquote>
            </div>
        
            <!-- MÃ“DULO: APENDICE_A_SPEECH_PORTAFOLIO.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_APENDICE_A_SPEECH_PORTAFOLIO" class="cover-title">APÃ‰NDICE A: SPEECH PORTAFOLIO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>Speech de entrevista â€“ Portafolio ML/MLOps (5â€“7 minutos)</h1>
<h2>0. Objetivo del speech</h2>
<p>Este guion estÃ¡ pensado para una respuesta de <strong>â€œCuÃ©ntame de tu portafolio / experiencia en ML/MLOpsâ€</strong> en <strong>5â€“7 minutos</strong>.<br />
Te posiciona explÃ­citamente como <strong>Senior / Staff ML(MLOps) Engineer</strong> que diseÃ±a y opera <strong>sistemas ML multiâ€‘proyecto</strong>.</p>
<h2>1. Apertura (0:00 â€“ 1:00)</h2>
<p><strong>Mensaje clave:</strong> QuiÃ©n eres, quÃ© rol buscas, y una frase muy clara sobre el portafolio.</p>
<ul>
<li>PresÃ©ntate con rol y foco:</li>
<li>"Soy <em>Daniel Duque</em>, ML/MLOps Engineer, y mi foco es llevar modelos de ML a producciÃ³n con buenas prÃ¡cticas de ingenierÃ­a de software, observabilidad y automatizaciÃ³n."</li>
<li>En una frase, resume el portfolio:</li>
<li>"Para demostrarlo construÃ­ un portafolio compuesto por <strong>3 proyectos ML de negocio reales</strong> (churn bancario, pricing de vehÃ­culos y recomendaciÃ³n de planes de telecom), todos integrados en un <strong>ecosistema MLOps unificado</strong>."</li>
<li>Aclara el nivel que quieres transmitir:</li>
<li>"MÃ¡s que tres demos aisladas, es <strong>un sistema multiâ€‘servicio</strong>, con CI/CD compartido, MLflow centralizado, Docker/Kubernetes, monitoreo con Prometheus/Grafana y workflows de drift + retraining."</li>
</ul>
<h2>2. Vista global del portfolio (1:00 â€“ 2:30)</h2>
<p><strong>Mensaje clave:</strong> No son proyectos sueltos; hay una plataforma y decisiones de arquitectura.</p>
<ul>
<li>Estructura:</li>
<li>"El repo tiene tres servicios: <strong>BankChurnâ€‘Predictor</strong>, <strong>CarVisionâ€‘Marketâ€‘Intelligence</strong> y <strong>TelecomAIâ€‘Customerâ€‘Intelligence</strong>."</li>
<li>"Comparten librerÃ­as comunes, una <strong>pipeline de CI unificada</strong> en GitHub Actions y un <strong>stack de observabilidad e infraestructura</strong> coherente."</li>
<li>CI/CD:</li>
<li>"La CI se define en un Ãºnico workflow con <strong>matrices de Python</strong> y <strong>umbrales de cobertura por proyecto</strong> (â‰ˆ79â€“97%), integraciÃ³n con <strong>GHCR</strong> para las imÃ¡genes Docker y <strong>tests de integraciÃ³n</strong> con Docker Compose."</li>
<li>Plataforma MLOps:</li>
<li>"Uso <strong>MLflow</strong> como capa de experiment tracking y model registry comÃºn."</li>
<li>"Para producciÃ³n describo despliegue con <strong>Docker + Kubernetes</strong>, IaC con <strong>Terraform</strong>, y monitoreo con <strong>Prometheus + Grafana</strong>."</li>
<li>Temas avanzados:</li>
<li>"IncluÃ­ <strong>explainability con SHAP</strong>, <strong>data drift monitoring con Evidently</strong> y un workflow de <strong>retrain orquestado por GitHub Actions</strong> en el caso de churn."</li>
<li>"TambiÃ©n documento <strong>FinOps</strong> y el diseÃ±o de un <strong>Feature Store</strong> compartido como extensiones futuras."</li>
</ul>
<p>Frase puente:</p>
<blockquote>
<p>"Sobre esa plataforma, cada proyecto resuelve un problema de negocio distinto. Te resumo cada uno muy rÃ¡pido."</p>
</blockquote>
<h2>3. Proyecto 1 â€“ BankChurnâ€‘Predictor (2:30 â€“ 3:45)</h2>
<p><strong>Mensaje clave:</strong> Proyecto â€œestrellaâ€ de churn con MLOps profundo.</p>
<ul>
<li>Problema y valor:</li>
<li>"BankChurnâ€‘Predictor es un sistema para <strong>predecir churn de clientes bancarios</strong>, priorizando recall para reducir fuga de clientes."</li>
<li>Modelado:</li>
<li>"Uso un <strong>ensemble</strong> con modelos clÃ¡sicos y tÃ©cnicas de balanceo de clases, con mÃ©tricas sÃ³lidas documentadas en la <em>Model Card</em>."</li>
<li>"Todo estÃ¡ encapsulado en pipelines de sklearn para evitar discrepancias entre entrenamiento y serving."</li>
<li>MLOps:</li>
<li>"Tiene <strong>alta cobertura de tests</strong>, incluyendo rutas complejas como <code>explainability.py</code> con SHAP y fallbacks cuando la librerÃ­a no estÃ¡ disponible."</li>
<li>"EstÃ¡ integrado con <strong>MLflow</strong> para registrar experimentos, mÃ©tricas y versiones de modelo."</li>
<li>Explainability:</li>
<li>"ImplementÃ© una clase <code>ModelExplainer</code> basada en <strong>SHAP</strong> con mecanismos de fallback (coeficientes / feature_importances) y pruebas unitarias que cubren esos caminos."</li>
<li>Drift + Retrain:</li>
<li>"Para este proyecto aÃ±adÃ­ un flujo de <strong>data drift monitoring</strong> con <strong>Evidently</strong> que genera reportes y, de forma manual controlada, puede disparar el workflow de <strong>retrain</strong> en GitHub Actions."</li>
<li>DocumentaciÃ³n:</li>
<li>"El proyecto tiene <strong>ARCHITECTURE.md</strong>, README muy detallado y Model Card, lo que permite entender decisiones de diseÃ±o, tradeâ€‘offs y roadmap (Feature Store, explainability avanzada, etc.)."</li>
</ul>
<p>Frase de cierre:</p>
<blockquote>
<p>"BankChurn muestra mi capacidad de diseÃ±ar un sistema ML <strong>endâ€‘toâ€‘end</strong> con explainability, drift y retraining, no sÃ³lo un modelo."</p>
</blockquote>
<h2>4. Proyecto 2 â€“ CarVisionâ€‘Marketâ€‘Intelligence (3:45 â€“ 5:00)</h2>
<p><strong>Mensaje clave:</strong> Pricing de vehÃ­culos con API + dashboard y foco fuerte en experiencia de usuario y calidad de cÃ³digo.</p>
<ul>
<li>Problema:</li>
<li>"CarVision es un proyecto de <strong>pricing de vehÃ­culos</strong>: predice el precio de mercado a partir de caracterÃ­sticas del coche, ayudando a tomar decisiones de compra/venta."</li>
<li>Modelado:</li>
<li>"Uso modelos de regresiÃ³n (por ejemplo, RandomForest Regressor) comparados con alternativas lineales, con mÃ©tricas como <strong>RÂ²</strong> y <strong>RMSE</strong> documentadas."</li>
<li>"La parte interesante es el diseÃ±o de un <strong>FeatureEngineer</strong> como transformer de sklearn para mantener alineados entrenamiento y serving."</li>
<li>Producto / UX:</li>
<li>"AdemÃ¡s de la <strong>API de inferencia</strong>, hay un <strong>dashboard en Streamlit</strong> con 4 secciones (overview, anÃ¡lisis de mercado, mÃ©tricas del modelo y predictor interactivo), pensado para stakeholders no tÃ©cnicos."</li>
<li>MLOps:</li>
<li>"La cobertura de tests es muy alta (alrededor del 97%), y se integra en la misma CI compartida usando MLflow, Docker, GHCR, etc."</li>
<li>Valor:</li>
<li>"Este proyecto demuestra que puedo llevar un caso de uso tabular a un producto usable con API, UI, tracking de experimentos y buenas prÃ¡cticas de ingenierÃ­a."</li>
</ul>
<p>Frase de cierre:</p>
<blockquote>
<p>"CarVision refuerza mi perfil <strong>producto + plataforma</strong>, mostrando cÃ³mo empaqueto modelos en APIs y dashboards operables."</p>
</blockquote>
<h2>5. Proyecto 3 â€“ TelecomAIâ€‘Customerâ€‘Intelligence (5:00 â€“ 6:00)</h2>
<p><strong>Mensaje clave:</strong> Recomendador de planes con mÃ©tricas claras y buen diseÃ±o operando como microservicio robusto.</p>
<ul>
<li>Problema:</li>
<li>"TelecomAI es un sistema de <strong>recomendaciÃ³n de planes de telecom</strong> (Standard vs Ultra) basado en el comportamiento de uso."</li>
<li>MÃ©tricas:</li>
<li>"El modelo consigue aproximadamente <strong>0.84 de AUCâ€‘ROC</strong>, <strong>82% de accuracy</strong> y <strong>0.63 de F1</strong>, con una <strong>cobertura de tests ~97%</strong>."</li>
<li>Servicio:</li>
<li>"EstÃ¡ implementado como una <strong>API FastAPI</strong> con endpoints <code>/predict</code> y <code>/health</code>, y con <strong>mÃ©tricas de Prometheus</strong> expuestas en <code>/metrics</code> para observabilidad."</li>
<li>"El health check maneja estados <em>degraded</em> (por ejemplo cuando el modelo no estÃ¡ disponible en CI), lo que es muy realista a nivel de producciÃ³n."</li>
<li>Plataforma:</li>
<li>"Comparte el mismo pipeline de CI/CD, prÃ¡cticas de Docker y experiment tracking del resto del portfolio."</li>
<li>DocumentaciÃ³n:</li>
<li>"Tiene un <strong>ONEâ€‘PAGER de negocio</strong>, README completo, Model Card y un <strong>ARCHITECTURE.md</strong> alineado con los otros dos proyectos."</li>
</ul>
<p>Frase de cierre:</p>
<blockquote>
<p>"TelecomAI es un microservicio ML muy limpio y con excelente coverage, que demuestra consistencia en mis patrones de diseÃ±o."</p>
</blockquote>
<h2>6. Cierre (6:00 â€“ 7:00)</h2>
<p><strong>Mensaje clave:</strong> Reforzar nivel, madurez y cÃ³mo esto se traduce en valor para el equipo.</p>
<ul>
<li>Nivel:</li>
<li>"En conjunto, el portafolio estÃ¡ diseÃ±ado para demostrar un nivel <strong>Senior / Staff</strong>: no sÃ³lo modelos, sino <strong>sistemas completos</strong>, con CI/CD multiâ€‘proyecto, observabilidad, workflows de retraining y documentaciÃ³n estilo empresa."</li>
<li>Aprendizajes:</li>
<li>"En el proceso he trabajado temas como explainability, drift, diseÃ±o de Feature Store, y <strong>FinOps</strong> para estimar y optimizar costes en cloud."</li>
<li>CÃ³mo encaja en la empresa:</li>
<li>"Mi objetivo es traer este enfoque al equipo: <strong>estandarizar pipelines</strong>, mejorar <strong>confiabilidad y observabilidad</strong> de los modelos en producciÃ³n y reducir el tiempo desde prototipo hasta valor en negocio."</li>
</ul>
<p>Cierre corto:</p>
<blockquote>
<p>"Si querÃ©is, puedo profundizar en cualquiera de los tres proyectos, en la parte de CI/CD, en explainability o en cÃ³mo diseÃ±arÃ­a el Feature Store y el coste en vuestra infraestructura actual."</p>
</blockquote>
<p><strong>ApÃ©ndice A â€” Material de PreparaciÃ³n para Entrevistas</strong></p>
            </div>
        
            <!-- MÃ“DULO: APENDICE_B_TALKING_POINTS.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_APENDICE_B_TALKING_POINTS" class="cover-title">APÃ‰NDICE B: TALKING POINTS</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>Talking Points â€“ Portafolio ML/MLOps</h1>
<p>GuÃ­a rÃ¡pida para responder preguntas de entrevista sobre el portafolio y cada proyecto.</p>
<h2>1. Mensaje global del portafolio</h2>
<ul>
<li><strong>Rol objetivo</strong></li>
<li>Apunta a <strong>Senior / Staff ML(MLOps) Engineer</strong>.</li>
<li>
<p>Demuestra capacidad de diseÃ±ar y operar un <strong>ecosistema multiâ€‘servicio</strong>.</p>
</li>
<li>
<p><strong>Arquitectura global</strong></p>
</li>
<li>3 proyectos: churn bancario, pricing vehÃ­culos, recomendaciÃ³n de planes telecom.</li>
<li>LibrerÃ­as comunes y estructura homogÃ©nea de proyectos.</li>
<li>
<p><strong>MLflow centralizado</strong>, <strong>Docker + Kubernetes</strong>, <strong>Terraform</strong> descrito para IaC.</p>
</li>
<li>
<p><strong>CI/CD y calidad</strong></p>
</li>
<li>Un Ãºnico workflow (<code>ci-mlops.yml</code>) con <strong>matrices de Python</strong> y <strong>umbrales de cobertura por proyecto</strong>.</li>
<li>Coverage â‰ˆ <strong>79%+</strong> en BankChurn y â‰ˆ <strong>97%</strong> en CarVision y TelecomAI.</li>
<li>
<p>Jobs de <strong>integration tests</strong>, build y push de imÃ¡genes a <strong>GHCR</strong>, escaneos de seguridad.</p>
</li>
<li>
<p><strong>Observabilidad y operaciones</strong></p>
</li>
<li>APIs con <strong>/metrics</strong> vÃ­a Prometheus.</li>
<li>IntegraciÃ³n con <strong>Grafana</strong> descrita en docs.</li>
<li>
<p><strong>RUNBOOK</strong> y <code>OPERATIONS_PORTFOLIO.md</code> para procedimientos operativos.</p>
</li>
<li>
<p><strong>Temas avanzados</strong></p>
</li>
<li><strong>Explainability</strong> (SHAP + fallbacks) en BankChurn.</li>
<li><strong>Data drift monitoring</strong> con Evidently + reporte y recomendaciones de <strong>retrain</strong>.</li>
<li>DiseÃ±o de <strong>Feature Store</strong> compartido como futura extensiÃ³n.</li>
<li>SecciÃ³n especÃ­fica de <strong>FinOps</strong> (costes, rightâ€‘sizing, buenas prÃ¡cticas de infra).</li>
</ul>
<h2>2. BankChurnâ€‘Predictor â€“ Talking Points</h2>
<ul>
<li><strong>Problema de negocio</strong></li>
<li>Reducir <strong>churn de clientes bancarios</strong> identificando quiÃ©n probablemente se marcharÃ¡.</li>
<li>
<p>Prioriza recall y estabilidad del modelo; impacto directo en retenciÃ³n.</p>
</li>
<li>
<p><strong>Modeling &amp; ML</strong></p>
</li>
<li>Pipelines de sklearn con <strong>preprocesamiento + modelo</strong>.</li>
<li><strong>Ensemble</strong> y tÃ©cnicas de desbalanceo (SMOTE / resampling).</li>
<li>
<p>MÃ©tricas sÃ³lidas (AUC, F1) documentadas en Model Card.</p>
</li>
<li>
<p><strong>MLOps / Plataforma</strong></p>
</li>
<li><strong>Alta cobertura de tests</strong> (incluyendo rutas complejas como explainability).</li>
<li>Seguimiento de experimentos en <strong>MLflow</strong>.</li>
<li>
<p>Makefile con comandos estÃ¡ndar (<code>train</code>, <code>evaluate</code>, <code>check-drift</code>, <code>serve</code>, etc.).</p>
</li>
<li>
<p><strong>Explainability</strong></p>
</li>
<li>
<p>Clase <code>ModelExplainer</code> con:</p>
<ul>
<li>SHAP (Tree/KernelExplainer).</li>
<li>Fallbacks (coeficientes o <code>feature_importances_</code>).</li>
<li>Pruebas unitarias para cubrir escenarios sin SHAP o sin explainer.</li>
</ul>
</li>
<li>
<p><strong>Drift &amp; Retrain</strong></p>
</li>
<li>Script de drift basado en <strong>Evidently</strong>.</li>
<li>Workflow <code>drift-bankchurn.yml</code>: genera reportes y recomendaciones.</li>
<li>
<p>Workflow <code>retrain-bankchurn.yml</code>: reentrena y registra modelos en MLflow, con opciÃ³n de promociÃ³n.</p>
</li>
<li>
<p><strong>Diferenciadores para entrevista</strong></p>
</li>
<li>Caso donde puedes hablar de:<ul>
<li>tradeâ€‘offs de <strong>automatizar o no</strong> el retraining,</li>
<li>relaciÃ³n entre drift y <strong>mÃ©tricas de negocio</strong>,</li>
<li>cÃ³mo integrar esto con un equipo real (alertas, SLOs).</li>
</ul>
</li>
</ul>
<h2>3. CarVisionâ€‘Marketâ€‘Intelligence â€“ Talking Points</h2>
<ul>
<li><strong>Problema de negocio</strong></li>
<li>
<p>PredicciÃ³n del <strong>precio de vehÃ­culos</strong> para soporte a decisiones de compra/venta.</p>
</li>
<li>
<p><strong>Modeling &amp; ML</strong></p>
</li>
<li>Modelos de regresiÃ³n (ej. RandomForest) comparados con alternativas.</li>
<li>MÃ©tricas como <strong>RÂ²</strong> y <strong>RMSE</strong> (documentadas en la Model Card).</li>
<li>
<p>DiseÃ±o de <strong>FeatureEngineer</strong> reutilizable como transformer sklearn.</p>
</li>
<li>
<p><strong>Producto y UX</strong></p>
</li>
<li><strong>API de inferencia</strong> para integrarse con otros sistemas.</li>
<li>
<p><strong>Dashboard Streamlit</strong> con:</p>
<ul>
<li>overview del dataset,</li>
<li>anÃ¡lisis de mercado,</li>
<li>mÃ©tricas de modelo,</li>
<li>predictor interactivo.</li>
</ul>
</li>
<li>
<p><strong>MLOps / Calidad</strong></p>
</li>
<li>Coverage â‰ˆ <strong>97%</strong>.</li>
<li>IntegraciÃ³n con CI unificada, MLflow, Docker, GHCR.</li>
<li>
<p>Buen manejo de configuraciÃ³n, logging y estructura de paquetes.</p>
</li>
<li>
<p><strong>Diferenciadores para entrevista</strong></p>
</li>
<li>Ejemplo claro de pasar de un <strong>modelo en notebook</strong> a un <strong>producto utilizable</strong>.</li>
<li>Permite hablar de experiencia colaborando con negocio (dashboard, explicaciones visuales).</li>
</ul>
<h2>4. TelecomAIâ€‘Customerâ€‘Intelligence â€“ Talking Points</h2>
<ul>
<li><strong>Problema de negocio</strong></li>
<li><strong>Recomendar el plan de telecom Ã³ptimo</strong> (Standard vs Ultra) segÃºn uso.</li>
<li>
<p>Minimiza tanto la fuga por sobreâ€‘coste como la pÃ©rdida de ingresos por infraâ€‘venta.</p>
</li>
<li>
<p><strong>Modeling &amp; ML</strong></p>
</li>
<li>Modelos tipo GradientBoosting / RandomForest.</li>
<li>
<p>MÃ©tricas (documentadas y fÃ¡ciles de citar):</p>
<ul>
<li><strong>AUCâ€‘ROC â‰ˆ 0.84</strong></li>
<li><strong>Accuracy â‰ˆ 82%</strong></li>
<li><strong>F1 â‰ˆ 0.63</strong></li>
<li><strong>Cobertura de tests â‰ˆ 97%</strong></li>
</ul>
</li>
<li>
<p><strong>Servicio y operaciones</strong></p>
</li>
<li>API <strong>FastAPI</strong> con:<ul>
<li><code>/predict</code> (plan recomendado + probabilidad),</li>
<li><code>/health</code> (incluye estado <strong>degraded</strong> para escenarios sin modelo).</li>
</ul>
</li>
<li>ExposiciÃ³n de mÃ©tricas en <code>/metrics</code> para Prometheus.</li>
<li>
<p>Arquitectura y operaciones documentadas en <code>ARCHITECTURE.md</code> y ONEâ€‘PAGER.</p>
</li>
<li>
<p><strong>MLOps / Plataforma</strong></p>
</li>
<li>Comparte CI, MLflow, Docker, GHCR del resto.</li>
<li>
<p>Casos de test e2e para validar comportamiento endâ€‘toâ€‘end.</p>
</li>
<li>
<p><strong>Diferenciadores para entrevista</strong></p>
</li>
<li>Excelente ejemplo de <strong>microservicio ML</strong> con:<ul>
<li>health checks realistas,</li>
<li>alta cobertura,</li>
<li>integraciÃ³n en un ecosistema mayor.</li>
</ul>
</li>
</ul>
<h2>5. Preguntas frecuentes y Ã¡ngulos de respuesta</h2>
<ul>
<li><strong>â€œÂ¿En quÃ© se diferencia esto de un proyecto tÃ­pico de Kaggle?â€</strong></li>
<li>Enfatizar:<ul>
<li>sistemas multiâ€‘servicio,</li>
<li>CI/CD, cobertura, observabilidad,</li>
<li>documentaciÃ³n de arquitectura y operaciones.</li>
</ul>
</li>
<li><strong>â€œÂ¿QuÃ© harÃ­as si tuvieras mÃ¡s tiempo?â€</strong></li>
<li>Implementar el <strong>Feature Store real</strong>, extender drift monitoring a los 3 proyectos,<br />
    aÃ±adir <strong>auth, RBAC y multiâ€‘tenant</strong> en las APIs, y pipelines de datos en streaming.</li>
<li><strong>â€œÂ¿CÃ³mo aplicarÃ­as esto en nuestra empresa?â€</strong></li>
<li>Responder con:<ul>
<li>estandarizar pipelines y CI/CD,</li>
<li>mejorar visibilidad de modelos en producciÃ³n (logs, mÃ©tricas, alertas),</li>
<li>diseÃ±ar <strong>runbooks</strong> y <strong>playbooks de incidentes</strong>,</li>
<li>definir una estrategia de <strong>FinOps</strong> bÃ¡sica para workloads de ML.</li>
</ul>
</li>
</ul>
<h2>6. Uso recomendado de esta guÃ­a</h2>
<ul>
<li>Imprimir o tener abierta esta hoja durante simulacros de entrevista.</li>
<li>Practicar el <strong>speech de 5â€“7 minutos</strong> del archivo <a href="#mod_APENDICE_A_SPEECH_PORTAFOLIO">APENDICE_A_SPEECH_PORTAFOLIO.md</a>.</li>
<li>Usar estas bullets para responder preguntas de seguimiento sin perder el mensaje principal:</li>
<li>soluciones de negocio,</li>
<li>calidad tÃ©cnica,</li>
<li>visiÃ³n de plataforma.</li>
</ul>
<p><strong>ApÃ©ndice B â€” Material de PreparaciÃ³n para Entrevistas</strong></p>
            </div>
        
            <!-- MÃ“DULO: GUIA_AUDIOVISUAL.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_GUIA_AUDIOVISUAL" class="cover-title">GUÃA AUDIOVISUAL</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ¬ GuÃ­a de Material Audiovisual â€” ML-MLOps Portfolio</h1>
<blockquote>
<p><strong>GuÃ­a completa para crear demos profesionales de tu portafolio</strong></p>
</blockquote>
<p><strong>Ãšltima actualizaciÃ³n</strong>: Diciembre 2025<br />
<strong>VersiÃ³n</strong>: 5.1 â€” Portfolio Edition<br />
<strong>Repositorio</strong>: <a href="https://github.com/DuqueOM/ML-MLOps-Portfolio">github.com/DuqueOM/ML-MLOps-Portfolio</a></p>
<h2>ğŸ“‹ Ãndice</h2>
<ol>
<li><a href="#-estado-actual-del-portafolio">Estado Actual del Portafolio</a></li>
<li><a href="#-servicios-del-stack-demo">Servicios del Stack Demo</a></li>
<li><a href="#-material-audiovisual-requerido">Material Audiovisual Requerido</a></li>
<li><a href="#-herramientas-recomendadas">Herramientas Recomendadas</a></li>
<li><a href="#-guÃ­a-de-gifs-demostrativos">GuÃ­a de GIFs Demostrativos</a></li>
<li><a href="#-guÃ­a-de-screenshots">GuÃ­a de Screenshots</a></li>
<li><a href="#-guÃ­a-de-video-principal">GuÃ­a de Video Principal</a></li>
<li><a href="#-comandos-y-scripts-Ãºtiles">Comandos y Scripts Ãštiles</a></li>
<li><a href="#-checklist-final">Checklist Final</a></li>
</ol>
<h2>ğŸ¯ Estado Actual del Portafolio</h2>
<h3>Proyectos del Portafolio</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th>DescripciÃ³n</th>
<th>TecnologÃ­as Clave</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BankChurn-Predictor</strong></td>
<td>PredicciÃ³n de abandono bancario</td>
<td>sklearn Pipeline, ResampleClassifier, MLflow</td>
</tr>
<tr>
<td><strong>CarVision-Market-Intelligence</strong></td>
<td>PredicciÃ³n de precios de vehÃ­culos</td>
<td>FeatureEngineer transformer, Streamlit dashboard</td>
</tr>
<tr>
<td><strong>TelecomAI-Customer-Intelligence</strong></td>
<td>ClasificaciÃ³n de planes mÃ³viles</td>
<td>Pipeline ML unificado</td>
</tr>
</tbody>
</table>
<h3>MÃ©tricas Actuales</h3>
<table>
<thead>
<tr>
<th>Proyecto</th>
<th style="text-align: center;">Coverage</th>
<th style="text-align: center;">MÃ©trica Principal</th>
<th style="text-align: center;">CI Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>BankChurn</td>
<td style="text-align: center;">79%</td>
<td style="text-align: center;">86% AUC</td>
<td style="text-align: center;">âœ… Passing</td>
</tr>
<tr>
<td>CarVision</td>
<td style="text-align: center;">80%</td>
<td style="text-align: center;">0.87 RÂ²</td>
<td style="text-align: center;">âœ… Passing</td>
</tr>
<tr>
<td>TelecomAI</td>
<td style="text-align: center;">80%</td>
<td style="text-align: center;">82% Accuracy</td>
<td style="text-align: center;">âœ… Passing</td>
</tr>
</tbody>
</table>
<h2>ğŸ–¥ Servicios del Stack Demo</h2>
<h3>Comando para Levantar</h3>
<pre><code class="language-bash">docker-compose -f docker-compose.demo.yml up -d
</code></pre>
<h3>5 Servicios Principales</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVICIOS DEL STACK DEMO                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ”¹ MLFLOW TRACKING SERVER                                              â”‚
â”‚     URL: http://localhost:5000                                          â”‚
â”‚     FunciÃ³n: Tracking de experimentos, Model Registry                   â”‚
â”‚     Mostrar: Lista de experimentos, mÃ©tricas, modelos registrados       â”‚
â”‚                                                                         â”‚
â”‚  ğŸ”¹ BANKCHURN API (FastAPI)                                             â”‚
â”‚     URL: http://localhost:8001/docs                                     â”‚
â”‚     FunciÃ³n: PredicciÃ³n de abandono de clientes                         â”‚
â”‚     Mostrar: Swagger UI, endpoint /predict, respuesta JSON              â”‚
â”‚                                                                         â”‚
â”‚  ğŸ”¹ CARVISION API (FastAPI)                                             â”‚
â”‚     URL: http://localhost:8002/docs                                     â”‚
â”‚     FunciÃ³n: PredicciÃ³n de precios de vehÃ­culos                         â”‚
â”‚     Mostrar: Swagger UI, endpoint /predict                              â”‚
â”‚                                                                         â”‚
â”‚  ğŸ”¹ CARVISION STREAMLIT DASHBOARD                                       â”‚
â”‚     URL: http://localhost:8501                                          â”‚
â”‚     FunciÃ³n: Dashboard interactivo para anÃ¡lisis y predicciÃ³n           â”‚
â”‚     Mostrar: GrÃ¡ficos, formulario de predicciÃ³n, resultados             â”‚
â”‚                                                                         â”‚
â”‚  ğŸ”¹ TELECOMAI API (FastAPI)                                             â”‚
â”‚     URL: http://localhost:8003/docs                                     â”‚
â”‚     FunciÃ³n: ClasificaciÃ³n de planes mÃ³viles                            â”‚
â”‚     Mostrar: Swagger UI, endpoint /predict                              â”‚
â”‚                                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SERVICIOS OPCIONALES (con --profile monitoring)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ”¸ PROMETHEUS: http://localhost:9090                                   â”‚
â”‚  ğŸ”¸ GRAFANA:    http://localhost:3000 (admin/admin)                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Resumen de URLs</h3>
<table>
<thead>
<tr>
<th>Servicio</th>
<th style="text-align: center;">Puerto</th>
<th>URL Completa</th>
<th style="text-align: center;">Tipo</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLflow UI</td>
<td style="text-align: center;">5000</td>
<td>http://localhost:5000</td>
<td style="text-align: center;">Dashboard</td>
</tr>
<tr>
<td>BankChurn API</td>
<td style="text-align: center;">8001</td>
<td>http://localhost:8001/docs</td>
<td style="text-align: center;">Swagger</td>
</tr>
<tr>
<td>CarVision API</td>
<td style="text-align: center;">8002</td>
<td>http://localhost:8002/docs</td>
<td style="text-align: center;">Swagger</td>
</tr>
<tr>
<td><strong>CarVision Dashboard</strong></td>
<td style="text-align: center;"><strong>8501</strong></td>
<td><strong>http://localhost:8501</strong></td>
<td style="text-align: center;"><strong>Streamlit</strong></td>
</tr>
<tr>
<td>TelecomAI API</td>
<td style="text-align: center;">8003</td>
<td>http://localhost:8003/docs</td>
<td style="text-align: center;">Swagger</td>
</tr>
<tr>
<td>Prometheus</td>
<td style="text-align: center;">9090</td>
<td>http://localhost:9090</td>
<td style="text-align: center;">Monitoring</td>
</tr>
<tr>
<td>Grafana</td>
<td style="text-align: center;">3000</td>
<td>http://localhost:3000</td>
<td style="text-align: center;">Dashboards</td>
</tr>
</tbody>
</table>
<h2>ğŸ“Š Material Audiovisual Requerido</h2>
<h3>Resumen de Elementos</h3>
<table>
<thead>
<tr>
<th>CategorÃ­a</th>
<th style="text-align: center;">Cantidad</th>
<th style="text-align: center;">Prioridad</th>
<th>DescripciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td>GIFs Demostrativos</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">ğŸ”´ Alta</td>
<td>Portfolio, 3 APIs, Streamlit</td>
</tr>
<tr>
<td>Screenshots</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">ğŸŸ¡ Media</td>
<td>UIs, dashboards, CI</td>
</tr>
<tr>
<td>Video Demo Principal</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">ğŸ”´ Alta</td>
<td>3-5 min completo</td>
</tr>
<tr>
<td>Thumbnails</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">ğŸŸ¢ Baja</td>
<td>Para YouTube/docs</td>
</tr>
</tbody>
</table>
<h3>Mapa de Archivos â†’ Referencias</h3>
<table>
<thead>
<tr>
<th>Archivo</th>
<th>UbicaciÃ³n</th>
<th>Se usa en</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>portfolio-demo.gif</code></td>
<td><code>media/gifs/</code></td>
<td>README.md principal</td>
</tr>
<tr>
<td><code>bankchurn-preview.gif</code></td>
<td><code>media/gifs/</code></td>
<td>README.md, BankChurn/README.md</td>
</tr>
<tr>
<td><code>carvision-preview.gif</code></td>
<td><code>media/gifs/</code></td>
<td>README.md, CarVision/README.md</td>
</tr>
<tr>
<td><code>streamlit-carvision.gif</code></td>
<td><code>media/gifs/</code></td>
<td>CarVision/README.md</td>
</tr>
<tr>
<td><code>telecom-preview.gif</code></td>
<td><code>media/gifs/</code></td>
<td>README.md, TelecomAI/README.md</td>
</tr>
<tr>
<td><code>mlflow-experiments.png</code></td>
<td><code>media/screenshots/</code></td>
<td>docs/, READMEs</td>
</tr>
<tr>
<td><code>mlflow-model-registry.png</code></td>
<td><code>media/screenshots/</code></td>
<td>docs/</td>
</tr>
<tr>
<td><code>swagger-bankchurn.png</code></td>
<td><code>media/screenshots/</code></td>
<td>BankChurn/README.md</td>
</tr>
<tr>
<td><code>swagger-carvision.png</code></td>
<td><code>media/screenshots/</code></td>
<td>CarVision/README.md</td>
</tr>
<tr>
<td><code>swagger-telecom.png</code></td>
<td><code>media/screenshots/</code></td>
<td>TelecomAI/README.md</td>
</tr>
<tr>
<td><code>streamlit-dashboard.png</code></td>
<td><code>media/screenshots/</code></td>
<td>CarVision/README.md</td>
</tr>
<tr>
<td><code>github-actions-ci.png</code></td>
<td><code>media/screenshots/</code></td>
<td>README.md principal</td>
</tr>
</tbody>
</table>
<h2>ğŸ›  Herramientas Recomendadas</h2>
<h3>Para Windows</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Uso</th>
<th>InstalaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OBS Studio</strong></td>
<td>Grabar pantalla</td>
<td><code>winget install OBSProject.OBSStudio</code></td>
</tr>
<tr>
<td><strong>Greenshot</strong></td>
<td>Screenshots</td>
<td><code>winget install Greenshot.Greenshot</code></td>
</tr>
<tr>
<td><strong>ffmpeg</strong></td>
<td>Convertir videoâ†’GIF</td>
<td><code>winget install ffmpeg</code></td>
</tr>
<tr>
<td><strong>ShareX</strong></td>
<td>GIFs directos</td>
<td><code>winget install ShareX.ShareX</code></td>
</tr>
</tbody>
</table>
<h3>Para Linux</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Uso</th>
<th>InstalaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OBS Studio</strong></td>
<td>Grabar pantalla</td>
<td><code>sudo apt install obs-studio</code></td>
</tr>
<tr>
<td><strong>Flameshot</strong></td>
<td>Screenshots</td>
<td><code>sudo apt install flameshot</code></td>
</tr>
<tr>
<td><strong>ffmpeg</strong></td>
<td>Convertir videoâ†’GIF</td>
<td><code>sudo apt install ffmpeg</code></td>
</tr>
<tr>
<td><strong>Peek</strong></td>
<td>GIFs directos</td>
<td><code>sudo apt install peek</code></td>
</tr>
</tbody>
</table>
<h3>Para macOS</h3>
<table>
<thead>
<tr>
<th>Herramienta</th>
<th>Uso</th>
<th>InstalaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OBS Studio</strong></td>
<td>Grabar pantalla</td>
<td><code>brew install obs</code></td>
</tr>
<tr>
<td><strong>Screenshot nativo</strong></td>
<td>Screenshots</td>
<td>Cmd+Shift+4</td>
</tr>
<tr>
<td><strong>ffmpeg</strong></td>
<td>Convertir videoâ†’GIF</td>
<td><code>brew install ffmpeg</code></td>
</tr>
<tr>
<td><strong>Gifski</strong></td>
<td>GIFs de alta calidad</td>
<td><code>brew install gifski</code></td>
</tr>
</tbody>
</table>
<h2>ğŸ GuÃ­a de GIFs Demostrativos</h2>
<h3>GIF 1: Portfolio Demo Principal (TODOS los servicios)</h3>
<p><strong>Archivo</strong>: <code>media/gifs/portfolio-demo.gif</code><br />
<strong>DuraciÃ³n</strong>: 20-25 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion Detallado</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PORTFOLIO DEMO PRINCIPAL (20-25 segundos)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:03  ESCENA 1: Levantar servicios                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Terminal con comando:                                                â”‚
â”‚    docker-compose -f docker-compose.demo.yml up -d                      â”‚
â”‚  â€¢ Mostrar output: &quot;Creating mlflow-server...&quot;,                         â”‚
â”‚    &quot;Creating bankchurn-api...&quot;, &quot;Creating carvision-api...&quot;,            â”‚
â”‚    &quot;Creating carvision-dashboard...&quot;, &quot;Creating telecom-api...&quot;         â”‚
â”‚                                                                         â”‚
â”‚  0:03-0:08  ESCENA 2: Los 5 servicios funcionando                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Abrir 5 pestaÃ±as del navegador (split screen o en secuencia):       â”‚
â”‚    1. http://localhost:5000 (MLflow)                                    â”‚
â”‚    2. http://localhost:8001/docs (BankChurn Swagger)                    â”‚
â”‚    3. http://localhost:8002/docs (CarVision Swagger)                    â”‚
â”‚    4. http://localhost:8501 (CarVision Streamlit) â† IMPORTANTE         â”‚
â”‚    5. http://localhost:8003/docs (TelecomAI Swagger)                    â”‚
â”‚  â€¢ Pausar 2 segundos en cada una                                        â”‚
â”‚                                                                         â”‚
â”‚  0:08-0:13  ESCENA 3: Demo Streamlit Dashboard                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Enfocar en localhost:8501                                            â”‚
â”‚  â€¢ Mostrar grÃ¡ficos de anÃ¡lisis de datos                                â”‚
â”‚  â€¢ Llenar formulario de predicciÃ³n rÃ¡pido                               â”‚
â”‚  â€¢ Mostrar resultado de precio estimado                                 â”‚
â”‚                                                                         â”‚
â”‚  0:13-0:18  ESCENA 4: PredicciÃ³n en API                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Cambiar a BankChurn Swagger (localhost:8001/docs)                    â”‚
â”‚  â€¢ Click en POST /predict â†’ &quot;Try it out&quot;                                â”‚
â”‚  â€¢ Ejecutar y mostrar respuesta JSON                                    â”‚
â”‚                                                                         â”‚
â”‚  0:18-0:22  ESCENA 5: MLflow Experiments                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Cambiar a MLflow (localhost:5000)                                    â”‚
â”‚  â€¢ Mostrar lista de experimentos                                        â”‚
â”‚  â€¢ Click en un experimento para ver mÃ©tricas                            â”‚
â”‚                                                                         â”‚
â”‚  0:22-0:25  ESCENA 6: Cierre                                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Volver a vista general con las 5 pestaÃ±as                            â”‚
â”‚  â€¢ O mostrar terminal con &quot;docker-compose ps&quot; (5 running)               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4>PreparaciÃ³n Completa</h4>
<pre><code class="language-bash"># 1. Levantar todos los servicios
cd /path/to/ML-MLOps-Portfolio
docker-compose -f docker-compose.demo.yml up -d

# 2. Esperar a que estÃ©n listos (importante!)
echo &quot;Esperando 45 segundos para que todos los servicios inicien...&quot;
sleep 45

# 3. Verificar TODOS los servicios
echo &quot;=== Verificando 5 servicios ===&quot;
echo &quot;MLflow:&quot; &amp;&amp; curl -s http://localhost:5000/health 2&gt;/dev/null || echo &quot;OK&quot;
echo &quot;BankChurn:&quot; &amp;&amp; curl -s http://localhost:8001/health
echo &quot;CarVision API:&quot; &amp;&amp; curl -s http://localhost:8002/health
echo &quot;CarVision Streamlit:&quot; &amp;&amp; curl -s http://localhost:8501 &gt;/dev/null &amp;&amp; echo '{&quot;status&quot;:&quot;healthy&quot;}'
echo &quot;TelecomAI:&quot; &amp;&amp; curl -s http://localhost:8003/health

# 4. Ver estado de contenedores
docker-compose -f docker-compose.demo.yml ps

# 5. Abrir TODAS las pestaÃ±as
# Linux:
xdg-open http://localhost:5000      # MLflow
xdg-open http://localhost:8001/docs # BankChurn
xdg-open http://localhost:8002/docs # CarVision API
xdg-open http://localhost:8501      # CarVision Streamlit â† NO OLVIDAR
xdg-open http://localhost:8003/docs # TelecomAI

# Windows (PowerShell):
# Start-Process http://localhost:5000
# Start-Process http://localhost:8001/docs
# Start-Process http://localhost:8002/docs
# Start-Process http://localhost:8501
# Start-Process http://localhost:8003/docs
</code></pre>
<h3>GIF 2: BankChurn API Demo</h3>
<p><strong>Archivo</strong>: <code>media/gifs/bankchurn-preview.gif</code><br />
<strong>DuraciÃ³n</strong>: 8-10 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BANKCHURN DEMO (8-10 segundos)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:02  Swagger UI de BankChurn                                    â”‚
â”‚  â€¢ Mostrar http://localhost:8001/docs                                   â”‚
â”‚  â€¢ TÃ­tulo visible: &quot;BankChurn Predictor API&quot;                            â”‚
â”‚                                                                         â”‚
â”‚  0:02-0:05  Expandir /predict                                          â”‚
â”‚  â€¢ Click en POST /predict                                               â”‚
â”‚  â€¢ Click &quot;Try it out&quot;                                                   â”‚
â”‚  â€¢ Llenar con datos de ejemplo (ver abajo)                              â”‚
â”‚                                                                         â”‚
â”‚  0:05-0:08  Ejecutar y ver resultado                                   â”‚
â”‚  â€¢ Click &quot;Execute&quot;                                                      â”‚
â”‚  â€¢ Scroll para ver respuesta:                                           â”‚
â”‚    {                                                                    â”‚
â”‚      &quot;prediction&quot;: 0,                                                   â”‚
â”‚      &quot;probability&quot;: 0.23,                                               â”‚
â”‚      &quot;label&quot;: &quot;No Churn&quot;                                                â”‚
â”‚    }                                                                    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4>Datos de Ejemplo para BankChurn</h4>
<pre><code class="language-json">{
  &quot;credit_score&quot;: 650,
  &quot;age&quot;: 45,
  &quot;tenure&quot;: 5,
  &quot;balance&quot;: 50000,
  &quot;num_of_products&quot;: 2,
  &quot;has_cr_card&quot;: 1,
  &quot;is_active_member&quot;: 1,
  &quot;estimated_salary&quot;: 75000,
  &quot;geography&quot;: &quot;France&quot;,
  &quot;gender&quot;: &quot;Male&quot;
}
</code></pre>
<h3>GIF 3: CarVision API Demo</h3>
<p><strong>Archivo</strong>: <code>media/gifs/carvision-preview.gif</code><br />
<strong>DuraciÃ³n</strong>: 8-10 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CARVISION API DEMO (8-10 segundos)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:02  Swagger UI de CarVision                                    â”‚
â”‚  â€¢ Mostrar http://localhost:8002/docs                                   â”‚
â”‚  â€¢ TÃ­tulo: &quot;CarVision Market Intelligence API&quot;                          â”‚
â”‚                                                                         â”‚
â”‚  0:02-0:05  Expandir /predict                                          â”‚
â”‚  â€¢ Click en POST /predict                                               â”‚
â”‚  â€¢ &quot;Try it out&quot;                                                         â”‚
â”‚  â€¢ Llenar datos de vehÃ­culo                                             â”‚
â”‚                                                                         â”‚
â”‚  0:05-0:08  Resultado                                                  â”‚
â”‚  â€¢ Ejecutar predicciÃ³n                                                  â”‚
â”‚  â€¢ Mostrar precio estimado: {&quot;predicted_price&quot;: 25430.50}               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h4>Datos de Ejemplo para CarVision</h4>
<pre><code class="language-json">{
  &quot;model_year&quot;: 2020,
  &quot;model&quot;: &quot;toyota camry&quot;,
  &quot;condition&quot;: &quot;good&quot;,
  &quot;odometer&quot;: 35000,
  &quot;fuel&quot;: &quot;gas&quot;,
  &quot;transmission&quot;: &quot;automatic&quot;,
  &quot;type&quot;: &quot;sedan&quot;,
  &quot;paint_color&quot;: &quot;white&quot;
}
</code></pre>
<h3>GIF 4: CarVision Streamlit Dashboard (NUEVO - IMPORTANTE)</h3>
<p><strong>Archivo</strong>: <code>media/gifs/streamlit-carvision.gif</code><br />
<strong>DuraciÃ³n</strong>: 12-15 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion Detallado</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CARVISION STREAMLIT DEMO (12-15 segundos)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:03  Dashboard Principal                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar http://localhost:8501                                        â”‚
â”‚  â€¢ Vista inicial del dashboard con tÃ­tulo                               â”‚
â”‚  â€¢ Sidebar visible con opciones                                         â”‚
â”‚                                                                         â”‚
â”‚  0:03-0:06  SecciÃ³n de AnÃ¡lisis de Datos                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar grÃ¡ficos de distribuciÃ³n de precios                          â”‚
â”‚  â€¢ GrÃ¡fico de precios por marca/aÃ±o                                     â”‚
â”‚  â€¢ EstadÃ­sticas descriptivas                                            â”‚
â”‚                                                                         â”‚
â”‚  0:06-0:10  Formulario de PredicciÃ³n                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Navegar a secciÃ³n de predicciÃ³n                                      â”‚
â”‚  â€¢ Seleccionar marca: Toyota                                            â”‚
â”‚  â€¢ Seleccionar modelo: Camry                                            â”‚
â”‚  â€¢ AÃ±o: 2020                                                            â”‚
â”‚  â€¢ Kilometraje: 35,000                                                  â”‚
â”‚  â€¢ CondiciÃ³n: Good                                                      â”‚
â”‚                                                                         â”‚
â”‚  0:10-0:13  Resultado de PredicciÃ³n                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Click en botÃ³n &quot;Predecir Precio&quot;                                     â”‚
â”‚  â€¢ Mostrar resultado: &quot;$25,430&quot; (grande, visible)                       â”‚
â”‚  â€¢ Mostrar intervalo de confianza si existe                             â”‚
â”‚                                                                         â”‚
â”‚  0:13-0:15  Vista Final                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Scroll up para mostrar todo el dashboard                             â”‚
â”‚  â€¢ O cambiar a otra secciÃ³n brevemente                                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>GIF 5: TelecomAI API Demo</h3>
<p><strong>Archivo</strong>: <code>media/gifs/telecom-preview.gif</code><br />
<strong>DuraciÃ³n</strong>: 8 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TELECOMAI DEMO (8 segundos)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:02  Swagger UI de TelecomAI                                    â”‚
â”‚  â€¢ Mostrar http://localhost:8003/docs                                   â”‚
â”‚  â€¢ TÃ­tulo: &quot;TelecomAI Customer Intelligence API&quot;                        â”‚
â”‚                                                                         â”‚
â”‚  0:02-0:05  Expandir /predict                                          â”‚
â”‚  â€¢ Llenar datos de uso del cliente                                      â”‚
â”‚                                                                         â”‚
â”‚  0:05-0:08  Resultado                                                  â”‚
â”‚  â€¢ Ejecutar predicciÃ³n                                                  â”‚
â”‚  â€¢ Mostrar plan recomendado                                             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>GIF 6: MLflow Dashboard (NUEVO - Recomendado)</h3>
<p><strong>Archivo</strong>: <code>media/gifs/mlflow-demo.gif</code><br />
<strong>DuraciÃ³n</strong>: 10-12 segundos<br />
<strong>ResoluciÃ³n</strong>: 800x600</p>
<h4>Guion</h4>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MLFLOW DEMO (10-12 segundos)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:03  MLflow UI Principal                                        â”‚
â”‚  â€¢ Mostrar http://localhost:5000                                        â”‚
â”‚  â€¢ Lista de experimentos visible                                        â”‚
â”‚                                                                         â”‚
â”‚  0:03-0:06  Seleccionar Experimento                                    â”‚
â”‚  â€¢ Click en experimento &quot;bankchurn&quot; o &quot;carvision&quot;                       â”‚
â”‚  â€¢ Mostrar lista de runs                                                â”‚
â”‚                                                                         â”‚
â”‚  0:06-0:09  Ver MÃ©tricas                                               â”‚
â”‚  â€¢ Click en un run especÃ­fico                                           â”‚
â”‚  â€¢ Mostrar mÃ©tricas: AUC, F1, Accuracy                                  â”‚
â”‚  â€¢ Mostrar parÃ¡metros logueados                                         â”‚
â”‚                                                                         â”‚
â”‚  0:09-0:12  Model Artifacts                                            â”‚
â”‚  â€¢ Mostrar secciÃ³n de artifacts                                         â”‚
â”‚  â€¢ Modelo guardado visible                                              â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>ğŸ“¸ GuÃ­a de Screenshots</h2>
<h3>Screenshots Requeridos (8 total)</h3>
<table>
<thead>
<tr>
<th style="text-align: center;">#</th>
<th>Nombre</th>
<th>QuÃ© capturar</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td><code>mlflow-experiments.png</code></td>
<td>Lista de experimentos en MLflow</td>
<td>localhost:5000</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td><code>mlflow-metrics.png</code></td>
<td>GrÃ¡ficos de mÃ©tricas de un run</td>
<td>localhost:5000</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td><code>swagger-bankchurn.png</code></td>
<td>Swagger UI de BankChurn</td>
<td>localhost:8001/docs</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td><code>swagger-carvision.png</code></td>
<td>Swagger UI de CarVision</td>
<td>localhost:8002/docs</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td><code>swagger-telecom.png</code></td>
<td>Swagger UI de TelecomAI</td>
<td>localhost:8003/docs</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td><code>streamlit-dashboard.png</code></td>
<td>Dashboard Streamlit completo</td>
<td>localhost:8501</td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td><code>streamlit-prediction.png</code></td>
<td>Resultado de predicciÃ³n en Streamlit</td>
<td>localhost:8501</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td><code>github-actions-ci.png</code></td>
<td>CI pipeline pasando</td>
<td>GitHub</td>
</tr>
</tbody>
</table>
<h3>CÃ³mo Tomar Buenos Screenshots</h3>
<ol>
<li><strong>Usa zoom al 100%</strong> en el navegador</li>
<li><strong>Limpia la URL bar</strong> (quita extensiones visibles)</li>
<li><strong>Usa modo claro</strong> para mejor legibilidad en docs</li>
<li><strong>ResoluciÃ³n mÃ­nima</strong>: 1200x800</li>
<li><strong>Comprime</strong> despuÃ©s con <code>pngquant</code></li>
</ol>
<pre><code class="language-bash"># Comprimir todos los screenshots
for f in media/screenshots/*.png; do
  pngquant --quality=65-80 &quot;$f&quot; --output &quot;${f%.png}-opt.png&quot;
done
</code></pre>
<h2>ğŸ¥ GuÃ­a de Video Principal</h2>
<h3>Especificaciones</h3>
<table>
<thead>
<tr>
<th>Campo</th>
<th>Valor</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DuraciÃ³n</strong></td>
<td>4-6 minutos</td>
</tr>
<tr>
<td><strong>ResoluciÃ³n</strong></td>
<td>1080p (1920x1080)</td>
</tr>
<tr>
<td><strong>Formato</strong></td>
<td>MP4</td>
</tr>
<tr>
<td><strong>Audio</strong></td>
<td>NarraciÃ³n clara</td>
</tr>
<tr>
<td><strong>Plataforma</strong></td>
<td>YouTube (unlisted) o Google Drive</td>
</tr>
</tbody>
</table>
<h3>Estructura del Video (Actualizada)</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  VIDEO DEMO PRINCIPAL (4-6 min)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  0:00-0:30  INTRODUCCIÃ“N                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ &quot;Hola, soy [nombre] y este es mi portafolio MLOps&quot;                   â”‚
â”‚  â€¢ Mostrar GitHub repo                                                  â”‚
â”‚  â€¢ &quot;3 proyectos ML end-to-end con CI/CD y 5 servicios dockerizados&quot;     â”‚
â”‚                                                                         â”‚
â”‚  0:30-1:00  LEVANTAR EL STACK                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar terminal: docker-compose up                                  â”‚
â”‚  â€¢ Explicar: &quot;Con un solo comando levanto 5 servicios&quot;                  â”‚
â”‚  â€¢ Mostrar docker ps con los 5 contenedores                             â”‚
â”‚                                                                         â”‚
â”‚  1:00-2:00  TOUR POR LOS 5 SERVICIOS                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ MLflow (5000): &quot;AquÃ­ trackeo todos los experimentos&quot;                 â”‚
â”‚  â€¢ BankChurn API (8001): &quot;API de predicciÃ³n de churn&quot;                   â”‚
â”‚  â€¢ CarVision API (8002): &quot;API de precios de vehÃ­culos&quot;                  â”‚
â”‚  â€¢ Streamlit (8501): &quot;Dashboard interactivo para CarVision&quot;             â”‚
â”‚  â€¢ TelecomAI API (8003): &quot;ClasificaciÃ³n de planes mÃ³viles&quot;              â”‚
â”‚                                                                         â”‚
â”‚  2:00-3:00  DEMO BANKCHURN                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar cÃ³digo del pipeline sklearn                                  â”‚
â”‚  â€¢ Ejecutar predicciÃ³n en Swagger UI                                    â”‚
â”‚  â€¢ Mostrar mÃ©tricas en MLflow                                           â”‚
â”‚                                                                         â”‚
â”‚  3:00-4:00  DEMO CARVISION + STREAMLIT                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar FeatureEngineer custom transformer                           â”‚
â”‚  â€¢ Demo en Streamlit Dashboard (grÃ¡ficos + predicciÃ³n)                  â”‚
â”‚  â€¢ Mostrar API tambiÃ©n funcionando                                      â”‚
â”‚                                                                         â”‚
â”‚  4:00-4:30  CI/CD Y TESTING                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar GitHub Actions                                               â”‚
â”‚  â€¢ Tests con 80%+ coverage                                              â”‚
â”‚  â€¢ Badge de CI passing                                                  â”‚
â”‚                                                                         â”‚
â”‚  4:30-5:00  ARQUITECTURA                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Mostrar diagrama de arquitectura                                     â”‚
â”‚  â€¢ Stack: sklearn, MLflow, FastAPI, Streamlit, Docker                   â”‚
â”‚  â€¢ ConfiguraciÃ³n con Pydantic                                           â”‚
â”‚                                                                         â”‚
â”‚  5:00-5:30  CIERRE                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  â€¢ Resumen: &quot;3 proyectos, 5 servicios, 80%+ coverage&quot;                   â”‚
â”‚  â€¢ &quot;Todo el cÃ³digo estÃ¡ en GitHub&quot;                                      â”‚
â”‚  â€¢ Mostrar URL del repositorio                                          â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Script de NarraciÃ³n</h3>
<blockquote>
<p><strong>INTRO</strong>: "Hola, soy [nombre]. Este es mi portafolio de Machine Learning y MLOps. Incluye tres proyectos completos que se ejecutan como cinco servicios dockerizados: tres APIs con FastAPI, un dashboard con Streamlit, y tracking centralizado con MLflow."</p>
<p><strong>STACK</strong>: "Con docker-compose levanto todo el stack. Mira, aquÃ­ puedes ver los cinco contenedores corriendo: el servidor de MLflow, las tres APIs de predicciÃ³n, y el dashboard de Streamlit para CarVision."</p>
<p><strong>TOUR</strong>: "DÃ©jame mostrarte cada servicio. En el puerto 5000 tenemos MLflow donde trackeo todos los experimentos. En 8001 estÃ¡ BankChurn para predicciÃ³n de abandono de clientes. En 8002 CarVision para precios de vehÃ­culos. En 8501, que es muy importante, tenemos el dashboard de Streamlit con visualizaciones interactivas. Y en 8003 TelecomAI para clasificaciÃ³n de planes."</p>
<p><strong>BANKCHURN</strong>: "Veamos BankChurn. El modelo usa un pipeline unificado de sklearn con ColumnTransformer para preprocesamiento. AquÃ­ hago una predicciÃ³n en la API... y mira, el cliente tiene 23% de probabilidad de abandonar."</p>
<p><strong>CARVISION</strong>: "CarVision tiene algo especial: un custom transformer llamado FeatureEngineer que calcula features como la edad del vehÃ­culo. Pero lo mejor es el dashboard de Streamlit... aquÃ­ puedo ver anÃ¡lisis de datos y hacer predicciones de forma interactiva. Mira, este Toyota Camry 2020 tiene un precio estimado de $25,000."</p>
<p><strong>CIERRE</strong>: "Todo pasa por CI con GitHub Actions y tiene mÃ¡s de 80% de coverage. El cÃ³digo completo estÃ¡ en GitHub. Gracias por ver."</p>
</blockquote>
<h2>ğŸ’» Comandos y Scripts Ãštiles</h2>
<h3>Levantar el Stack Completo</h3>
<pre><code class="language-bash"># Clonar repositorio
git clone https://github.com/DuqueOM/ML-MLOps-Portfolio.git
cd ML-MLOps-Portfolio

# Levantar los 5 servicios principales
docker-compose -f docker-compose.demo.yml up -d

# Esperar a que estÃ©n listos
sleep 45

# Verificar TODOS los servicios (5)
echo &quot;=== Estado de los 5 servicios ===&quot;
echo &quot;1. MLflow (5000):&quot;
curl -s http://localhost:5000 &gt;/dev/null &amp;&amp; echo &quot;   âœ… Running&quot; || echo &quot;   âŒ Down&quot;

echo &quot;2. BankChurn API (8001):&quot;
curl -s http://localhost:8001/health &amp;&amp; echo &quot;&quot;

echo &quot;3. CarVision API (8002):&quot;
curl -s http://localhost:8002/health &amp;&amp; echo &quot;&quot;

echo &quot;4. CarVision Streamlit (8501):&quot;
curl -s http://localhost:8501 &gt;/dev/null &amp;&amp; echo '   âœ… {&quot;status&quot;:&quot;healthy&quot;}' || echo &quot;   âŒ Down&quot;

echo &quot;5. TelecomAI API (8003):&quot;
curl -s http://localhost:8003/health &amp;&amp; echo &quot;&quot;

# Ver contenedores
docker-compose -f docker-compose.demo.yml ps
</code></pre>
<h3>Abrir Todas las URLs</h3>
<pre><code class="language-bash"># Linux
xdg-open http://localhost:5000 &amp;      # MLflow
xdg-open http://localhost:8001/docs &amp; # BankChurn
xdg-open http://localhost:8002/docs &amp; # CarVision API
xdg-open http://localhost:8501 &amp;      # CarVision Streamlit
xdg-open http://localhost:8003/docs &amp; # TelecomAI

# macOS
open http://localhost:5000
open http://localhost:8001/docs
open http://localhost:8002/docs
open http://localhost:8501
open http://localhost:8003/docs
</code></pre>
<h3>PowerShell (Windows)</h3>
<pre><code class="language-powershell"># Abrir todas las URLs
Start-Process &quot;http://localhost:5000&quot;      # MLflow
Start-Process &quot;http://localhost:8001/docs&quot; # BankChurn
Start-Process &quot;http://localhost:8002/docs&quot; # CarVision API
Start-Process &quot;http://localhost:8501&quot;      # CarVision Streamlit
Start-Process &quot;http://localhost:8003/docs&quot; # TelecomAI
</code></pre>
<h3>Convertir Video a GIF</h3>
<pre><code class="language-bash"># MÃ©todo con paleta (mejor calidad)
ffmpeg -i video.mp4 -vf &quot;fps=12,scale=800:-1:flags=lanczos,palettegen&quot; palette.png
ffmpeg -i video.mp4 -i palette.png -filter_complex &quot;fps=12,scale=800:-1:flags=lanczos[x];[x][1:v]paletteuse&quot; output.gif
rm palette.png

# Optimizar tamaÃ±o
gifsicle -O3 --colors 128 output.gif -o output-optimized.gif
</code></pre>
<h3>Ejemplos de PredicciÃ³n para Demo</h3>
<pre><code class="language-bash"># BankChurn - Cliente que NO abandonarÃ¡
curl -X POST http://localhost:8001/predict \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;credit_score&quot;: 750,
    &quot;age&quot;: 35,
    &quot;tenure&quot;: 8,
    &quot;balance&quot;: 125000,
    &quot;num_of_products&quot;: 2,
    &quot;has_cr_card&quot;: 1,
    &quot;is_active_member&quot;: 1,
    &quot;estimated_salary&quot;: 95000,
    &quot;geography&quot;: &quot;France&quot;,
    &quot;gender&quot;: &quot;Female&quot;
  }' | jq

# CarVision - Predecir precio
curl -X POST http://localhost:8002/predict \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model_year&quot;: 2020,
    &quot;model&quot;: &quot;toyota camry&quot;,
    &quot;condition&quot;: &quot;good&quot;,
    &quot;odometer&quot;: 35000,
    &quot;fuel&quot;: &quot;gas&quot;,
    &quot;transmission&quot;: &quot;automatic&quot;,
    &quot;type&quot;: &quot;sedan&quot;
  }' | jq
</code></pre>
<h2>âœ… Checklist Final</h2>
<h3>Material de Alta Prioridad (5 GIFs)</h3>
<ul>
<li>[ ] <code>media/gifs/portfolio-demo.gif</code> â€” Demo completo (5 servicios)</li>
<li>[ ] <code>media/gifs/bankchurn-preview.gif</code> â€” Demo API BankChurn</li>
<li>[ ] <code>media/gifs/carvision-preview.gif</code> â€” Demo API CarVision</li>
<li>[ ] <code>media/gifs/streamlit-carvision.gif</code> â€” Demo Streamlit Dashboard â† NUEVO</li>
<li>[ ] <code>media/gifs/telecom-preview.gif</code> â€” Demo API TelecomAI</li>
</ul>
<h3>Material de Alta Prioridad (Video)</h3>
<ul>
<li>[ ] Video principal grabado (4-6 min)</li>
<li>[ ] Video subido a YouTube/Drive</li>
<li>[ ] Link actualizado en README.md</li>
</ul>
<h3>Material de Media Prioridad (Screenshots)</h3>
<ul>
<li>[ ] <code>mlflow-experiments.png</code> â€” Lista de experimentos</li>
<li>[ ] <code>mlflow-metrics.png</code> â€” MÃ©tricas de un run</li>
<li>[ ] <code>swagger-bankchurn.png</code> â€” Swagger BankChurn</li>
<li>[ ] <code>swagger-carvision.png</code> â€” Swagger CarVision</li>
<li>[ ] <code>swagger-telecom.png</code> â€” Swagger TelecomAI</li>
<li>[ ] <code>streamlit-dashboard.png</code> â€” Dashboard completo</li>
<li>[ ] <code>streamlit-prediction.png</code> â€” Resultado de predicciÃ³n</li>
<li>[ ] <code>github-actions-ci.png</code> â€” CI pasando</li>
</ul>
<h3>VerificaciÃ³n Final</h3>
<ul>
<li>[ ] Todos los GIFs pesan &lt; 5MB</li>
<li>[ ] Screenshots optimizados</li>
<li>[ ] Video tiene audio claro</li>
<li>[ ] READMEs actualizados con GIFs</li>
<li>[ ] Links funcionan correctamente</li>
<li>[ ] Git push realizado</li>
</ul>
<h2>ğŸ“š Recursos Adicionales</h2>
<h3>Tutoriales Recomendados</h3>
<ul>
<li><a href="https://obsproject.com/wiki/OBS-Studio-Quickstart">OBS Studio Quickstart</a></li>
<li><a href="https://engineering.giphy.com/how-to-make-gifs-with-ffmpeg/">ffmpeg GIF Guide</a></li>
<li><a href="https://docs.streamlit.io/streamlit-community-cloud/deploy-your-app">Streamlit Deployment</a></li>
</ul>
<h3>Ejemplos de Portafolios con Buenos Demos</h3>
<ul>
<li><a href="https://github.com/GokuMohandas/made-with-ml">made-with-ml</a></li>
<li><a href="https://github.com/DataTalksClub/mlops-zoomcamp">mlops-zoomcamp</a></li>
</ul>
<h2>ğŸ”— Links del Portafolio</h2>
<table>
<thead>
<tr>
<th>Recurso</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Repositorio</strong></td>
<td>https://github.com/DuqueOM/ML-MLOps-Portfolio</td>
</tr>
<tr>
<td><strong>BankChurn</strong></td>
<td>/BankChurn-Predictor</td>
</tr>
<tr>
<td><strong>CarVision</strong></td>
<td>/CarVision-Market-Intelligence</td>
</tr>
<tr>
<td><strong>TelecomAI</strong></td>
<td>/TelecomAI-Customer-Intelligence</td>
</tr>
</tbody>
</table>
<h3>URLs Locales (con Docker)</h3>
<table>
<thead>
<tr>
<th>Servicio</th>
<th>URL</th>
</tr>
</thead>
<tbody>
<tr>
<td>MLflow</td>
<td>http://localhost:5000</td>
</tr>
<tr>
<td>BankChurn API</td>
<td>http://localhost:8001/docs</td>
</tr>
<tr>
<td>CarVision API</td>
<td>http://localhost:8002/docs</td>
</tr>
<tr>
<td>CarVision Streamlit</td>
<td>http://localhost:8501</td>
</tr>
<tr>
<td>TelecomAI API</td>
<td>http://localhost:8003/docs</td>
</tr>
</tbody>
</table>
<p><strong>Â¡Tu portafolio tiene 5 servicios listos para demostrar!</strong> ğŸš€</p>
            </div>
        
            <!-- MÃ“DULO: MAINTENANCE_GUIDE.md -->
            <div class="cover-page">
                <div class="cover-content">
                    <div style="font-size:40pt;margin-bottom:20px;">ğŸ’</div>
                    <div id="mod_MAINTENANCE_GUIDE" class="cover-title">GUÃA DE MANTENIMIENTO</div>
                    <div class="cover-subtitle">GuÃ­a MLOps v5.0</div>
                    <div class="cover-badge">PORTFOLIO EDITION</div>
                </div>
                <div style="position:absolute;bottom:30px;font-size:10pt;opacity:0.6;">DUQUEOM | 2025</div>
            </div>
            <div class="content">
                <h1>ğŸ”§ GuÃ­a de Mantenimiento â€” guia_mlops v5</h1>
<blockquote>
<p><strong>Meta-documento</strong>: Esta guÃ­a describe cÃ³mo mantener <strong>la guÃ­a MLOps en sÃ­ misma</strong> actualizada y funcional.</p>
<p>âš ï¸ <strong>Â¿Buscas contenido sobre operaciones de sistemas ML en producciÃ³n?</strong> Ver:<br />
- <a href="17_DESPLIEGUE.md#-operaciones-y-runbooks">17_DESPLIEGUE.md â†’ Operaciones y Runbooks</a><br />
- <a href="#mod_16_OBSERVABILIDAD">16_OBSERVABILIDAD.md</a> â€” Monitoreo y alertas<br />
- <a href="#mod_OPERATIONS_PORTFOLIO">Runbook del Portafolio</a> â€” Operaciones end-to-end del portafolio</p>
</blockquote>
<p><em>Ãšltima actualizaciÃ³n: Diciembre 2025</em></p>
<h2>ğŸ“Š Estado Actual de la GuÃ­a</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Componente</th>
<th style="text-align: center;">Cantidad</th>
<th style="text-align: center;">Estado</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">MÃ³dulos principales</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">âœ… Completos</td>
</tr>
<tr>
<td style="text-align: left;">Ejercicios</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">âœ… Con soluciones</td>
</tr>
<tr>
<td style="text-align: left;">ADRs</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">âœ… Actualizados</td>
</tr>
<tr>
<td style="text-align: left;">Recursos externos</td>
<td style="text-align: center;">50+ videos</td>
<td style="text-align: center;">âœ… Curados</td>
</tr>
<tr>
<td style="text-align: left;">Glosario</td>
<td style="text-align: center;">100+ tÃ©rminos</td>
<td style="text-align: center;">âœ… Expandido</td>
</tr>
</tbody>
</table>
<h2>ğŸ“… Calendario de Mantenimiento</h2>
<h3>Mensual</h3>
<ul>
<li>[ ] Verificar que todos los links funcionan (<code>./scripts/check_links.sh</code>)</li>
<li>[ ] Actualizar versiones de dependencias en <code>requirements.txt</code></li>
<li>[ ] Ejecutar tests de todos los mÃ³dulos</li>
<li>[ ] Verificar que videos de RECURSOS_POR_MODULO.md siguen disponibles</li>
</ul>
<h3>Trimestral</h3>
<ul>
<li>[ ] Revisar y actualizar ejemplos de cÃ³digo con mejores prÃ¡cticas</li>
<li>[ ] Regenerar <code>requirements.txt</code> con versiones actuales</li>
<li>[ ] Verificar compatibilidad con Python mÃ¡s reciente (actualmente 3.11+)</li>
<li>[ ] Actualizar templates con mejores prÃ¡cticas</li>
<li>[ ] Revisar y actualizar RECURSOS_POR_MODULO.md con nuevos videos/cursos</li>
</ul>
<h3>Semestral</h3>
<ul>
<li>[ ] Revisar estructura completa de la guÃ­a (23 mÃ³dulos)</li>
<li>[ ] Actualizar referencias y recursos externos</li>
<li>[ ] Incorporar feedback de usuarios</li>
<li>[ ] Evaluar nuevas herramientas del ecosistema MLOps</li>
<li>[ ] Actualizar DECISIONES_TECH.md con nuevas herramientas</li>
<li>[ ] Revisar que el glosario cubre todos los tÃ©rminos usados en mÃ³dulos</li>
</ul>
<h2>ğŸ” ValidaciÃ³n de la GuÃ­a</h2>
<h3>Script de ValidaciÃ³n</h3>
<p>Ejecutar para verificar la integridad de la guÃ­a:</p>
<pre><code class="language-bash"># Dar permisos de ejecuciÃ³n
chmod +x scripts/validate_guide.sh

# Ejecutar validaciÃ³n
./scripts/validate_guide.sh
</code></pre>
<p>El script verifica:<br />
1. <strong>Estructura de directorios</strong>: Todos los mÃ³dulos existen<br />
2. <strong>Archivos requeridos</strong>: mkdocs.yml, requirements.txt, etc.<br />
3. <strong>Links en Markdown</strong>: No hay links rotos<br />
4. <strong>Sintaxis YAML</strong>: Archivos de configuraciÃ³n vÃ¡lidos<br />
5. <strong>Tests por mÃ³dulo</strong>: Cada mÃ³dulo tiene tests<br />
6. <strong>Notebooks</strong>: Son JSON vÃ¡lidos</p>
<h3>Ejecutar Tests Completos</h3>
<pre><code class="language-bash"># Activar entorno
source .venv/bin/activate

# Ejecutar todos los tests
make check-all

# O mÃ³dulo por mÃ³dulo
make check-01
make check-02
# ...
</code></pre>
<h2>ğŸ“¦ ActualizaciÃ³n de Dependencias</h2>
<h3>Verificar Desactualizadas</h3>
<pre><code class="language-bash">pip list --outdated
</code></pre>
<h3>Proceso de ActualizaciÃ³n</h3>
<ol>
<li>
<p><strong>Crear branch de actualizaciÃ³n</strong><br />
<code>bash
   git checkout -b chore/update-deps-YYYY-MM</code></p>
</li>
<li>
<p><strong>Actualizar dependencias</strong><br />
<code>bash
   pip install --upgrade package-name</code></p>
</li>
<li>
<p><strong>Ejecutar tests</strong><br />
<code>bash
   pytest docs/ -v</code></p>
</li>
<li>
<p><strong>Si pasan, regenerar lockfile</strong><br />
<code>bash
   pip freeze &gt; requirements.lock</code></p>
</li>
<li>
<p><strong>Commit y PR</strong><br />
<code>bash
   git add requirements.txt requirements.lock
   git commit -m "chore: update dependencies YYYY-MM"</code></p>
</li>
</ol>
<h3>AuditorÃ­a de Seguridad</h3>
<pre><code class="language-bash"># Instalar herramientas
pip install pip-audit safety

# Verificar vulnerabilidades
pip-audit
safety check
</code></pre>
<h2>ğŸ› ResoluciÃ³n de Problemas</h2>
<h3>Tests Fallando</h3>
<ol>
<li>Verificar que el entorno estÃ¡ activado</li>
<li>Reinstalar dependencias: <code>pip install -r requirements.txt</code></li>
<li>Verificar versiÃ³n de Python: <code>python --version</code> (3.10+)</li>
<li>Ejecutar test individual para mÃ¡s detalles</li>
</ol>
<h3>Links Rotos</h3>
<ol>
<li>Ejecutar <code>./scripts/validate_guide.sh</code></li>
<li>Revisar output para links especÃ­ficos</li>
<li>Actualizar o eliminar links rotos</li>
</ol>
<h3>MkDocs No Funciona</h3>
<ol>
<li>Verificar instalaciÃ³n: <code>mkdocs --version</code></li>
<li>Reinstalar: <code>pip install mkdocs mkdocs-material</code></li>
<li>Verificar sintaxis de <code>mkdocs.yml</code></li>
</ol>
<h2>ğŸ“ Contribuir a la GuÃ­a</h2>
<h3>Agregar Nuevo Contenido</h3>
<ol>
<li>Crear branch: <code>git checkout -b feat/new-content</code></li>
<li>Agregar contenido en el mÃ³dulo correspondiente</li>
<li>Agregar tests si aplica</li>
<li>Actualizar <code>mkdocs.yml</code> si es necesario</li>
<li>Ejecutar validaciÃ³n: <code>./scripts/validate_guide.sh</code></li>
<li>Crear PR con descripciÃ³n clara</li>
</ol>
<h3>Estructura de un MÃ³dulo</h3>
<pre><code>docs/XX_nombre_modulo/
â”œâ”€â”€ index.md           # Contenido principal
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_*.py      # Tests del mÃ³dulo
â””â”€â”€ solutions/
    â””â”€â”€ *.py           # Soluciones de ejercicios
</code></pre>
<h3>Convenciones</h3>
<ul>
<li>Usar <strong>Markdown</strong> estÃ¡ndar</li>
<li>Incluir <strong>ejemplos de cÃ³digo</strong> ejecutables</li>
<li>Agregar <strong>ejercicios prÃ¡cticos</strong> con tests</li>
<li>Mantener <strong>links relativos</strong> entre mÃ³dulos</li>
</ul>
<h2>ğŸ“Š MÃ©tricas de Calidad</h2>
<h3>Objetivos</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">MÃ©trica</th>
<th style="text-align: left;">Objetivo</th>
<th style="text-align: left;">Actual</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Tests pasando</td>
<td style="text-align: left;">100%</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">Links rotos</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">MÃ³dulos completos</td>
<td style="text-align: left;">23/23</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">Ejercicios con soluciÃ³n</td>
<td style="text-align: left;">42/42</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">ADRs documentados</td>
<td style="text-align: left;">14/14</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">Glosario tÃ©rminos</td>
<td style="text-align: left;">100+</td>
<td style="text-align: left;">âœ…</td>
</tr>
<tr>
<td style="text-align: left;">Recursos externos</td>
<td style="text-align: left;">50+</td>
<td style="text-align: left;">âœ…</td>
</tr>
</tbody>
</table>
<h3>Monitoreo</h3>
<p>Ejecutar semanalmente:</p>
<pre><code class="language-bash">./scripts/validate_guide.sh &gt; reports/validation_$(date +%Y%m%d).log
</code></pre>
<h2>ğŸ“ Estructura de Archivos de la GuÃ­a</h2>
<pre><code>docs/guia_mlops/
â”œâ”€â”€ 00_INDICE.md              # Ãndice principal
â”œâ”€â”€ 01-23_*.md                # 23 mÃ³dulos temÃ¡ticos
â”œâ”€â”€ EJERCICIOS.md             # 42 ejercicios prÃ¡cticos
â”œâ”€â”€ EJERCICIOS_SOLUCIONES.md  # Soluciones detalladas
â”œâ”€â”€ RUBRICA_EVALUACION.md     # Sistema de evaluaciÃ³n (100 puntos)
â”œâ”€â”€ RECURSOS_POR_MODULO.md    # ğŸ“º Videos y cursos externos
â”œâ”€â”€ DECISIONES_TECH.md        # 14 ADRs de herramientas
â”œâ”€â”€ 21_GLOSARIO.md            # 100+ tÃ©rminos con ejemplos
â”œâ”€â”€ SIMULACRO_*.md            # Entrevistas tÃ©cnicas
â”œâ”€â”€ APENDICE_A_SPEECH.md      # Speech de portafolio
â”œâ”€â”€ APENDICE_B_TALKING.md     # Puntos clave
â”œâ”€â”€ SYLLABUS.md               # Programa de 8 semanas
â”œâ”€â”€ PLAN_ESTUDIOS.md          # Cronograma dÃ­a a dÃ­a
â”œâ”€â”€ GUIA_AUDIOVISUAL.md       # Crear demos y videos
â”œâ”€â”€ MAINTENANCE_GUIDE.md      # Esta guÃ­a
â”œâ”€â”€ templates/                # 13 plantillas reutilizables
â””â”€â”€ mkdocs.yml                # ConfiguraciÃ³n MkDocs
</code></pre>
<h2>ğŸ”— Recursos Internos</h2>
<table>
<thead>
<tr>
<th>Archivo</th>
<th>PropÃ³sito</th>
<th style="text-align: center;">ActualizaciÃ³n</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#mod_RECURSOS_POR_MODULO">RECURSOS_POR_MODULO.md</a></td>
<td>Videos y cursos externos</td>
<td style="text-align: center;">Trimestral</td>
</tr>
<tr>
<td><a href="#mod_DECISIONES_TECH">DECISIONES_TECH.md</a></td>
<td>ADRs de herramientas</td>
<td style="text-align: center;">Semestral</td>
</tr>
<tr>
<td><a href="#mod_21_GLOSARIO">21_GLOSARIO.md</a></td>
<td>Definiciones de tÃ©rminos</td>
<td style="text-align: center;">Mensual</td>
</tr>
<tr>
<td><a href="#mod_RUBRICA_EVALUACION">RUBRICA_EVALUACION.md</a></td>
<td>Sistema de puntuaciÃ³n</td>
<td style="text-align: center;">Semestral</td>
</tr>
</tbody>
</table>
<h3>Recursos Externos</h3>
<ul>
<li><a href="https://www.mkdocs.org/">MkDocs Documentation</a></li>
<li><a href="https://squidfunk.github.io/mkdocs-material/">Material for MkDocs</a></li>
<li><a href="https://docs.pytest.org/">pytest Documentation</a></li>
</ul>
<h2>ğŸ‘¥ Contacto</h2>
<ul>
<li><strong>Mantenedor</strong>: DuqueOM</li>
<li><strong>Repositorio</strong>: <a href="https://github.com/DuqueOM/ML-MLOps-Portfolio">ML-MLOps-Portfolio</a></li>
</ul>
            </div>
        
    </body>
    </html>
    