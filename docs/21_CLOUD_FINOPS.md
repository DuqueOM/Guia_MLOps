# 21. Cloud FinOps y Estrategia de Costos ML

## ğŸ¯ Objetivo

Dominar la gestiÃ³n de costos cloud para cargas de trabajo ML, incluyendo estrategias de Spot/On-Demand, auto-scaling inteligente y cÃ¡lculo de TCO.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  "El mejor modelo no es el mÃ¡s preciso, sino el que genera mÃ¡s ROI          â•‘
â•‘   considerando costos de entrenamiento, inferencia e infraestructura."      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“‹ Contenido

1. [Fundamentos de FinOps](#1-fundamentos)
2. [Costos en ML: Training vs Inference](#2-training-inference)
3. [Estrategias Spot vs On-Demand](#3-spot-ondemand)
4. [Auto-scaling Inteligente](#4-autoscaling)
5. [CÃ¡lculo de TCO](#5-tco)
6. [Ejercicio: Reducir 30% el TCO](#6-ejercicio)
7. [Preguntas de Entrevista Senior](#7-entrevista)

---

<a id="1-fundamentos"></a>

## 1. Fundamentos de FinOps

### Â¿QuÃ© es FinOps?

**FinOps** = Financial Operations para Cloud. PrÃ¡ctica de gestionar costos cloud con la misma rigurosidad que el cÃ³digo.

### Principios Clave

| Principio | DescripciÃ³n | AplicaciÃ³n ML |
|-----------|-------------|---------------|
| **Visibility** | Ver todos los costos | Tags por proyecto/modelo |
| **Optimization** | Reducir desperdicio | Right-sizing de instancias |
| **Governance** | PolÃ­ticas y lÃ­mites | Budgets y alertas |

### Estructura de Costos ML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DISTRIBUCIÃ“N TÃPICA DE COSTOS ML                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  TRAINING (30-50% del costo total)                                         â”‚
â”‚  â”œâ”€â”€ Compute (GPU/CPU)................ 70%                                 â”‚
â”‚  â”œâ”€â”€ Storage (datasets)............... 20%                                 â”‚
â”‚  â””â”€â”€ Networking....................... 10%                                 â”‚
â”‚                                                                             â”‚
â”‚  INFERENCE (40-60% del costo total)                                        â”‚
â”‚  â”œâ”€â”€ Compute (API servers)............ 60%                                 â”‚
â”‚  â”œâ”€â”€ Load Balancer.................... 15%                                 â”‚
â”‚  â”œâ”€â”€ Storage (model artifacts)........ 15%                                 â”‚
â”‚  â””â”€â”€ Networking (egress).............. 10%                                 â”‚
â”‚                                                                             â”‚
â”‚  SUPPORTING (10-20% del costo total)                                       â”‚
â”‚  â”œâ”€â”€ MLflow/Experiment Tracking....... 30%                                 â”‚
â”‚  â”œâ”€â”€ Monitoring/Logging............... 40%                                 â”‚
â”‚  â””â”€â”€ CI/CD............................ 30%                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<a id="2-training-inference"></a>

## 2. Costos: Training vs Inference

### 2.1 Calculadora de Costos

```python
# cost_calculator.py
"""Calculadora de costos ML para AWS/GCP/Azure."""

from dataclasses import dataclass                   # Contenedores de datos inmutables.
from typing import Dict                             # Type hints para diccionarios.
from enum import Enum                               # Enumeraciones tipadas.


class InstanceType(Enum):
    """
    Tipos de instancia comunes para ML.
    
    Valores incluyen specs y precio/hora On-Demand.
    """
    # CPU - Para inferencia ligera y preprocesamiento.
    CPU_SMALL = "t3.medium"                         # 2 vCPU, 4GB RAM - $0.0416/hr.
    CPU_LARGE = "c5.2xlarge"                        # 8 vCPU, 16GB RAM - $0.34/hr.
    
    # GPU - Para entrenamiento e inferencia de modelos.
    GPU_T4 = "g4dn.xlarge"                          # 1x NVIDIA T4, 4 vCPU - $0.526/hr.
    GPU_V100 = "p3.2xlarge"                         # 1x NVIDIA V100, 8 vCPU - $3.06/hr.
    GPU_A100 = "p4d.24xlarge"                       # 8x NVIDIA A100, 96 vCPU - $32.77/hr.


# ========== PRECIOS DE REFERENCIA ==========
# Fuente: AWS us-east-1, On-Demand pricing (2024).
# Nota: Precios cambian frecuentemente, verificar en consola AWS.
HOURLY_PRICES: Dict[str, float] = {
    "t3.medium": 0.0416,                            # Uso general, burstable.
    "c5.2xlarge": 0.34,                             # Compute-optimized.
    "g4dn.xlarge": 0.526,                           # GPU T4 (inference/training ligero).
    "p3.2xlarge": 3.06,                             # GPU V100 (training intensivo).
    "p4d.24xlarge": 32.77,                          # GPU A100 (LLMs, modelos grandes).
}

# Descuento tÃ­pico de Spot Instances (60-90% off On-Demand).
SPOT_DISCOUNT = 0.70                                # 70% descuento = pagar 30% del precio.


@dataclass
class TrainingJob:
    """
    Representa un job de entrenamiento.
    
    Attributes:
        name: Nombre identificador del job.
        instance_type: Tipo de instancia EC2.
        hours: DuraciÃ³n promedio por ejecuciÃ³n.
        runs_per_month: Frecuencia de ejecuciÃ³n mensual.
    """
    name: str                                       # Ej: "BankChurn-Train".
    instance_type: str                              # Ej: "g4dn.xlarge".
    hours: float                                    # Horas por ejecuciÃ³n.
    runs_per_month: int = 1                         # Ejecuciones mensuales.


@dataclass
class InferenceEndpoint:
    """
    Representa un endpoint de inferencia (API).
    
    Attributes:
        name: Nombre del endpoint.
        instance_type: Tipo de instancia.
        instances: NÃºmero de rÃ©plicas.
        hours_per_day: Horas de operaciÃ³n diaria.
    """
    name: str                                       # Ej: "BankChurn-API".
    instance_type: str                              # Ej: "t3.medium".
    instances: int                                  # NÃºmero de rÃ©plicas para HA.
    hours_per_day: float = 24.0                     # 24 = 24/7, 12 = solo dÃ­a.


def calculate_training_cost(
    job: TrainingJob,                               # ConfiguraciÃ³n del job.
    use_spot: bool = False,                         # True = usar Spot instances.
) -> Dict[str, float]:
    """
    Calcula costo mensual de entrenamiento.
    
    Returns:
        Dict con desglose: hourly_rate, monthly_cost_usd, etc.
    """
    # Obtener precio base (fallback a $0.5/hr si no existe).
    base_price = HOURLY_PRICES.get(job.instance_type, 0.5)
    
    # Aplicar descuento Spot si corresponde.
    if use_spot:
        effective_price = base_price * (1 - SPOT_DISCOUNT)  # 30% del precio.
    else:
        effective_price = base_price                        # Precio completo.
    
    # Costo mensual = precio/hr Ã— horas/run Ã— runs/mes.
    monthly_cost = effective_price * job.hours * job.runs_per_month
    
    return {
        "job_name": job.name,                       # Identificador.
        "instance": job.instance_type,              # Tipo de instancia.
        "hourly_rate": round(effective_price, 4),   # Precio efectivo/hr.
        "hours_per_run": job.hours,                 # DuraciÃ³n por ejecuciÃ³n.
        "runs_per_month": job.runs_per_month,       # Frecuencia mensual.
        "monthly_cost_usd": round(monthly_cost, 2), # Costo total mensual.
        "using_spot": use_spot,                     # Indicador de Spot.
    }


def calculate_inference_cost(
    endpoint: InferenceEndpoint,                    # ConfiguraciÃ³n del endpoint.
    days_per_month: int = 30,                       # DÃ­as de operaciÃ³n.
) -> Dict[str, float]:
    """
    Calcula costo mensual de inferencia.
    
    FÃ³rmula: precio/hr Ã— instancias Ã— horas/dÃ­a Ã— dÃ­as/mes.
    """
    base_price = HOURLY_PRICES.get(endpoint.instance_type, 0.5)
    
    # Calcular horas totales al mes.
    hours_per_month = endpoint.hours_per_day * days_per_month
    
    # Costo = precio Ã— nÃºmero de instancias Ã— horas totales.
    monthly_cost = base_price * endpoint.instances * hours_per_month
    
    return {
        "endpoint_name": endpoint.name,             # Identificador.
        "instance": endpoint.instance_type,         # Tipo de instancia.
        "instances": endpoint.instances,            # NÃºmero de rÃ©plicas.
        "hours_per_day": endpoint.hours_per_day,    # Horas de operaciÃ³n.
        "monthly_cost_usd": round(monthly_cost, 2), # Costo mensual.
    }


# ========== EJEMPLO: CALCULAR COSTOS DEL PORTFOLIO ==========
if __name__ == "__main__":
    # Definir jobs de entrenamiento del Portfolio.
    jobs = [
        TrainingJob("BankChurn-Train", "g4dn.xlarge", hours=2, runs_per_month=4),
        TrainingJob("CarVision-Train", "p3.2xlarge", hours=8, runs_per_month=2),
        TrainingJob("TelecomAI-Train", "c5.2xlarge", hours=1, runs_per_month=8),
    ]
    
    # Definir endpoints de inferencia.
    endpoints = [
        InferenceEndpoint("BankChurn-API", "t3.medium", instances=2),  # 24/7.
        InferenceEndpoint("CarVision-API", "g4dn.xlarge", instances=1, hours_per_day=12),  # Solo dÃ­a.
    ]
    
    # ===== REPORTE DE TRAINING =====
    print("=" * 60)
    print("COSTOS DE TRAINING (mensual)")
    print("=" * 60)
    
    total_training = 0                              # Acumulador.
    for job in jobs:
        # Comparar On-Demand vs Spot para cada job.
        od = calculate_training_cost(job, use_spot=False)   # Precio completo.
        spot = calculate_training_cost(job, use_spot=True)  # Con descuento.
        savings = od["monthly_cost_usd"] - spot["monthly_cost_usd"]  # Ahorro.
        
        print(f"\n{job.name}:")                     # Nombre del job.
        print(f"  On-Demand: ${od['monthly_cost_usd']:.2f}/mes")
        print(f"  Spot:      ${spot['monthly_cost_usd']:.2f}/mes")
        print(f"  Ahorro:    ${savings:.2f}/mes ({SPOT_DISCOUNT*100:.0f}%)")
        
        total_training += spot["monthly_cost_usd"]  # Sumar costo Spot.
    
    # ===== REPORTE DE INFERENCE =====
    print("\n" + "=" * 60)
    print("COSTOS DE INFERENCE (mensual)")
    print("=" * 60)
    
    total_inference = 0                             # Acumulador.
    for ep in endpoints:
        cost = calculate_inference_cost(ep)         # Calcular costo.
        print(f"\n{ep.name}:")
        print(f"  Instancias: {cost['instances']}x {cost['instance']}")
        print(f"  Horas/dÃ­a:  {cost['hours_per_day']}")
        print(f"  Costo:      ${cost['monthly_cost_usd']:.2f}/mes")
        
        total_inference += cost["monthly_cost_usd"]  # Sumar.
    
    # ===== RESUMEN TOTAL =====
    print("\n" + "=" * 60)
    print(f"TOTAL TRAINING:  ${total_training:.2f}/mes")
    print(f"TOTAL INFERENCE: ${total_inference:.2f}/mes")
    print(f"TOTAL MENSUAL:   ${total_training + total_inference:.2f}/mes")
```

---

<a id="3-spot-ondemand"></a>

## 3. Estrategias Spot vs On-Demand

### Matriz de DecisiÃ³n

| Caso de Uso | RecomendaciÃ³n | RazÃ³n |
|-------------|---------------|-------|
| **Training batch** | âœ… Spot | Tolerante a interrupciones, checkpoints |
| **Hyperparameter tuning** | âœ… Spot | Muchos jobs pequeÃ±os, algunos pueden fallar |
| **API de inferencia crÃ­tica** | âŒ On-Demand | Disponibilidad 99.9% requerida |
| **API de inferencia no-crÃ­tica** | âš ï¸ Mixed | Base On-Demand + Spot para picos |
| **Notebooks/Dev** | âœ… Spot | Bajo costo, interrupciones aceptables |

### ImplementaciÃ³n con Checkpoints

```python
# spot_training.py
"""Training tolerante a interrupciones con checkpoints."""

import os                                           # Variables de entorno.
import json                                         # SerializaciÃ³n de checkpoints.
import signal                                       # Manejo de seÃ±ales del SO.
from pathlib import Path                            # Manejo de paths.
from datetime import datetime                       # Timestamps.
from typing import Optional, Dict, Any              # Type hints.
import logging                                      # Sistema de logging.

# Configurar logging bÃ¡sico.
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SpotInterruptionHandler:
    """
    Maneja interrupciones de instancias Spot de forma graceful.
    
    Funcionamiento:
    1. AWS envÃ­a SIGTERM 2 minutos antes de terminar Spot.
    2. Este handler captura la seÃ±al.
    3. Guarda checkpoint del estado actual.
    4. Permite que el proceso termine limpiamente.
    
    Uso: Permite resumir entrenamiento desde el Ãºltimo checkpoint.
    """
    
    def __init__(self, checkpoint_dir: str = "checkpoints"):
        """Inicializa el handler de interrupciones."""
        self.checkpoint_dir = Path(checkpoint_dir)  # Directorio de checkpoints.
        self.checkpoint_dir.mkdir(exist_ok=True)    # Crear si no existe.
        self.interrupted = False                    # Flag de interrupciÃ³n.
        
        # Registrar handlers para seÃ±ales del sistema operativo.
        signal.signal(signal.SIGTERM, self._handle_sigterm)  # SeÃ±al de terminaciÃ³n.
        signal.signal(signal.SIGINT, self._handle_sigterm)   # Ctrl+C.
    
    def _handle_sigterm(self, signum, frame):
        """
        Handler para SIGTERM (seÃ±al de interrupciÃ³n Spot).
        
        Args:
            signum: NÃºmero de seÃ±al recibida.
            frame: Stack frame actual (no usado).
        """
        logger.warning("âš ï¸ Spot interruption detected! Saving checkpoint...")
        self.interrupted = True                     # Marcar como interrumpido.
    
    def save_checkpoint(
        self,
        epoch: int,                                 # Ã‰poca actual del entrenamiento.
        model_state: Dict[str, Any],                # state_dict del modelo.
        optimizer_state: Dict[str, Any],            # state_dict del optimizador.
        metrics: Dict[str, float],                  # MÃ©tricas actuales (loss, acc).
    ) -> str:
        """
        Guarda checkpoint del entrenamiento.
        
        Returns:
            Path al archivo de checkpoint guardado.
        """
        # Construir diccionario de checkpoint.
        checkpoint = {
            "epoch": epoch,                         # Para resumir desde aquÃ­.
            "model_state": model_state,             # Pesos del modelo.
            "optimizer_state": optimizer_state,     # Estado del optimizador (momentum, etc).
            "metrics": metrics,                     # Para comparar al resumir.
            "timestamp": datetime.now().isoformat(),  # CuÃ¡ndo se guardÃ³.
        }
        
        # Nombre de archivo con nÃºmero de Ã©poca.
        path = self.checkpoint_dir / f"checkpoint_epoch_{epoch}.json"
        
        # Guardar (en producciÃ³n usarÃ­as torch.save() o joblib).
        with open(path, "w") as f:
            json.dump(checkpoint, f, indent=2, default=str)
        
        logger.info(f"âœ… Checkpoint saved: {path}")
        return str(path)
    
    def load_latest_checkpoint(self) -> Optional[Dict[str, Any]]:
        """
        Carga el checkpoint mÃ¡s reciente.
        
        Returns:
            Dict con el checkpoint o None si no existe.
        """
        # Buscar todos los checkpoints ordenados.
        checkpoints = sorted(self.checkpoint_dir.glob("checkpoint_*.json"))
        
        if not checkpoints:                         # No hay checkpoints previos.
            logger.info("No checkpoints found, starting fresh")
            return None
        
        latest = checkpoints[-1]                    # Ãšltimo (mÃ¡s reciente).
        logger.info(f"ğŸ“‚ Loading checkpoint: {latest}")
        
        with open(latest) as f:
            return json.load(f)                     # Deserializar y retornar.
    
    def should_stop(self) -> bool:
        """Retorna True si se detectÃ³ interrupciÃ³n Spot."""
        return self.interrupted                     # Verificar flag.


def train_with_spot_support(
    model,                                          # Modelo a entrenar.
    train_data,                                     # Datos de entrenamiento.
    epochs: int = 100,                              # NÃºmero total de Ã©pocas.
    checkpoint_every: int = 5,                      # Guardar cada N Ã©pocas.
):
    """
    Entrenamiento con soporte para Spot instances.
    
    Features:
    - Resume automÃ¡tico desde checkpoint.
    - Guardado periÃ³dico.
    - Graceful shutdown en interrupciÃ³n.
    """
    handler = SpotInterruptionHandler()             # Crear handler de interrupciones.
    
    # ===== INTENTAR RESUMIR DESDE CHECKPOINT =====
    checkpoint = handler.load_latest_checkpoint()   # Buscar checkpoint previo.
    start_epoch = checkpoint["epoch"] + 1 if checkpoint else 0  # Ã‰poca inicial.
    
    if checkpoint:
        # Restaurar estado del modelo (pseudo-cÃ³digo).
        # model.load_state_dict(checkpoint["model_state"])
        # optimizer.load_state_dict(checkpoint["optimizer_state"])
        logger.info(f"Resuming from epoch {start_epoch}")
    
    # ===== LOOP DE ENTRENAMIENTO =====
    for epoch in range(start_epoch, epochs):
        # Verificar interrupciÃ³n ANTES de cada Ã©poca.
        if handler.should_stop():                   # Se detectÃ³ SIGTERM.
            logger.warning("Stopping due to Spot interruption")
            handler.save_checkpoint(                # Guardar estado actual.
                epoch=epoch,
                model_state={"weights": "..."},
                optimizer_state={"lr": 0.001},
                metrics={"loss": 0.5},
            )
            break                                   # Salir del loop limpiamente.
        
        # Training de una Ã©poca (pseudo-cÃ³digo).
        logger.info(f"Training epoch {epoch}/{epochs}")
        # loss = train_one_epoch(model, train_data)
        
        # Checkpoint periÃ³dico cada N Ã©pocas.
        if epoch % checkpoint_every == 0:           # Guardar cada 5 Ã©pocas por defecto.
            handler.save_checkpoint(
                epoch=epoch,
                model_state={"weights": "..."},
                optimizer_state={"lr": 0.001},
                metrics={"loss": 0.5},
            )
    
    logger.info("Training completed!")              # Fin del entrenamiento.
```

---

<a id="4-autoscaling"></a>

## 4. Auto-scaling Inteligente

### 4.1 Kubernetes HPA para ML

```yaml
# k8s/hpa-ml-api.yaml
# HPA optimizado para APIs de ML
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api-hpa
  namespace: ml-production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  
  # Rango de rÃ©plicas.
  minReplicas: 2          # MÃ­nimo para HA.
  maxReplicas: 10         # MÃ¡ximo para controlar costos.
  
  # MÃ©tricas para escalar.
  metrics:
    # CPU: escalar si > 70%.
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    
    # Memoria: escalar si > 80%.
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    
    # Custom: requests por segundo (requiere Prometheus).
    - type: Pods
      pods:
        metric:
          name: http_requests_per_second
        target:
          type: AverageValue
          averageValue: "100"
  
  # Comportamiento de escalado.
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300   # 5 min antes de bajar.
      policies:
        - type: Percent
          value: 10                     # Bajar mÃ¡x 10% por vez.
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0     # Escalar inmediato.
      policies:
        - type: Percent
          value: 100                    # Duplicar si necesario.
          periodSeconds: 15
        - type: Pods
          value: 4                      # O +4 pods mÃ¡ximo.
          periodSeconds: 15
      selectPolicy: Max                 # Usar polÃ­tica mÃ¡s agresiva.
```

### 4.2 Scaling Basado en Costo/Latencia

```python
# cost_aware_scaler.py
"""Scaler que balancea costo vs latencia."""

from dataclasses import dataclass                   # Contenedores de datos.
from typing import Tuple                            # Type hints para tuplas.
import logging                                      # Sistema de logging.

logger = logging.getLogger(__name__)                # Logger del mÃ³dulo.


@dataclass
class ScalingConfig:
    """
    ConfiguraciÃ³n de scaling.
    
    Define lÃ­mites y umbrales para el auto-scaler.
    """
    min_replicas: int = 2                           # MÃ­nimo para HA (High Availability).
    max_replicas: int = 10                          # MÃ¡ximo para controlar costos.
    target_latency_p95_ms: float = 200.0            # SLA: P95 < 200ms.
    max_cost_per_hour: float = 10.0                 # Budget mÃ¡ximo por hora.
    cost_per_replica_hour: float = 0.50             # Costo de cada rÃ©plica/hora.


class CostAwareScaler:
    """
    Auto-scaler que optimiza costo vs latencia.
    
    Algoritmo de decisiÃ³n (en orden de prioridad):
    1. Si latency > target â†’ SCALE UP (prioridad mÃ¡xima).
    2. Si cost > budget Y latency OK â†’ SCALE DOWN.
    3. Si ambos OK â†’ HOLD (mantener).
    
    Esto prioriza la experiencia del usuario sobre el costo.
    """
    
    def __init__(self, config: ScalingConfig):      # Constructor.
        self.config = config                        # Guardar configuraciÃ³n.
        self.current_replicas = config.min_replicas # Iniciar con mÃ­nimo.
    
    def calculate_decision(
        self,
        current_latency_p95: float,                 # Latencia P95 actual (ms).
        current_replicas: int,                      # NÃºmero de rÃ©plicas actuales.
    ) -> Tuple[str, int]:
        """
        Decide acciÃ³n de scaling basada en mÃ©tricas.
        
        Returns:
            Tuple de (nombre_acciÃ³n, nuevas_rÃ©plicas).
        """
        # Calcular costo actual por hora.
        current_cost = current_replicas * self.config.cost_per_replica_hour
        
        # ===== CASO 1: LATENCIA MUY ALTA (>150% del target) =====
        # Prioridad mÃ¡xima: escalar agresivamente.
        if current_latency_p95 > self.config.target_latency_p95_ms * 1.5:
            new_replicas = min(                     # Agregar 2 rÃ©plicas.
                current_replicas + 2,               # +2 rÃ©plicas.
                self.config.max_replicas,           # Sin exceder mÃ¡ximo.
            )
            return ("SCALE_UP_URGENT", new_replicas)
        
        # ===== CASO 2: LATENCIA ALTA (>100% del target) =====
        # Escalar gradualmente (+1 rÃ©plica).
        if current_latency_p95 > self.config.target_latency_p95_ms:
            new_replicas = min(                     # Agregar 1 rÃ©plica.
                current_replicas + 1,               # +1 rÃ©plica.
                self.config.max_replicas,           # Sin exceder mÃ¡ximo.
            )
            return ("SCALE_UP", new_replicas)
        
        # ===== CASO 3: COSTO ALTO PERO LATENCIA OK =====
        # Solo bajar si latencia estÃ¡ muy por debajo del target (<70%).
        if (current_cost > self.config.max_cost_per_hour and 
            current_latency_p95 < self.config.target_latency_p95_ms * 0.7):
            new_replicas = max(                     # Quitar 1 rÃ©plica.
                current_replicas - 1,               # -1 rÃ©plica.
                self.config.min_replicas,           # Sin bajar del mÃ­nimo.
            )
            return ("SCALE_DOWN_COST", new_replicas)
        
        # ===== CASO 4: TODO OK =====
        # Mantener configuraciÃ³n actual.
        return ("HOLD", current_replicas)
    
    def log_decision(
        self,
        action: str,                                # Nombre de la acciÃ³n tomada.
        old_replicas: int,                          # RÃ©plicas antes de la decisiÃ³n.
        new_replicas: int,                          # RÃ©plicas despuÃ©s.
        latency: float,                             # Latencia que disparÃ³ la decisiÃ³n.
        cost: float,                                # Costo actual por hora.
    ):
        """Log la decisiÃ³n de scaling para auditorÃ­a."""
        logger.info(
            f"Scaling: {action} | "                 # AcciÃ³n tomada.
            f"Replicas: {old_replicas}â†’{new_replicas} | "  # Cambio.
            f"Latency P95: {latency:.0f}ms | "      # MÃ©trica de latencia.
            f"Cost: ${cost:.2f}/hr"                 # Costo horario.
        )


# ========== EJEMPLO DE USO ==========
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)         # Configurar logging.
    
    # Crear configuraciÃ³n de scaling.
    config = ScalingConfig(
        min_replicas=2,                             # MÃ­nimo 2 para HA.
        max_replicas=10,                            # MÃ¡ximo 10 por costos.
        target_latency_p95_ms=200,                  # SLA: P95 < 200ms.
        max_cost_per_hour=5.0,                      # Budget: $5/hr.
        cost_per_replica_hour=0.50,                 # $0.50 por rÃ©plica/hr.
    )
    
    scaler = CostAwareScaler(config)                # Crear scaler.
    
    # Simular diferentes escenarios de carga.
    scenarios = [
        (150, 2),                                   # Latencia OK, pocas rÃ©plicas â†’ HOLD.
        (250, 2),                                   # Latencia alta, pocas rÃ©plicas â†’ SCALE_UP.
        (350, 3),                                   # Latencia muy alta â†’ SCALE_UP_URGENT.
        (120, 8),                                   # Latencia baja, muchas rÃ©plicas â†’ SCALE_DOWN.
    ]
    
    # Evaluar cada escenario.
    for latency, replicas in scenarios:
        action, new_replicas = scaler.calculate_decision(latency, replicas)
        cost = replicas * config.cost_per_replica_hour  # Costo actual.
        scaler.log_decision(action, replicas, new_replicas, latency, cost)
```

---

<a id="5-tco"></a>

## 5. CÃ¡lculo de TCO (Total Cost of Ownership)

### 5.1 Framework de TCO

```python
# tco_calculator.py
"""Calculadora de TCO (Total Cost of Ownership) para arquitecturas MLOps."""

from dataclasses import dataclass, field            # Contenedores de datos.
from typing import List, Dict                       # Type hints.
from enum import Enum                               # Enumeraciones.


class CostCategory(Enum):
    """
    CategorÃ­as de costos cloud.
    
    Permite agrupar y analizar costos por tipo.
    """
    COMPUTE = "compute"                             # EC2, Lambda, EKS, etc.
    STORAGE = "storage"                             # S3, EBS, EFS.
    NETWORK = "network"                             # Data transfer, ALB, NAT.
    SERVICES = "managed_services"                   # CloudWatch, Secrets Manager.
    LABOR = "labor"                                 # Costo de personal (opcional).


@dataclass
class CostItem:
    """
    Item de costo individual.
    
    Representa un recurso o servicio con su costo mensual.
    """
    name: str                                       # Nombre descriptivo.
    category: CostCategory                          # CategorÃ­a para agrupaciÃ³n.
    monthly_cost: float                             # Costo mensual en USD.
    notes: str = ""                                 # Notas adicionales (specs, etc).


@dataclass
class TCOAnalysis:
    """
    AnÃ¡lisis completo de TCO.
    
    Agrega mÃºltiples CostItems y genera reportes.
    """
    project_name: str                               # Nombre del proyecto.
    items: List[CostItem] = field(default_factory=list)  # Lista de items.
    
    def add_item(self, item: CostItem):             # AÃ±adir item a la lista.
        """AÃ±ade un item de costo al anÃ¡lisis."""
        self.items.append(item)
    
    def total_monthly(self) -> float:               # Sumar todos los costos mensuales.
        """Retorna costo mensual total."""
        return sum(i.monthly_cost for i in self.items)
    
    def total_annual(self) -> float:                # Costo anual = mensual * 12.
        """Retorna costo anual total."""
        return self.total_monthly() * 12
    
    def by_category(self) -> Dict[str, float]:      # Agrupar por categorÃ­a.
        """Retorna costos agrupados por categorÃ­a."""
        result = {}                                 # Diccionario de resultados.
        for item in self.items:                     # Iterar items.
            cat = item.category.value               # Obtener nombre de categorÃ­a.
            result[cat] = result.get(cat, 0) + item.monthly_cost  # Sumar.
        return result
    
    def generate_report(self) -> str:
        """
        Genera reporte de TCO formateado.
        
        Returns:
            String con el reporte completo.
        """
        # Encabezado del reporte.
        lines = [
            "=" * 60,
            f"TCO ANALYSIS: {self.project_name}",
            "=" * 60,
            "",
            "DESGLOSE POR CATEGORÃA:",
            "-" * 40,
        ]
        
        # Desglose por categorÃ­a (ordenado por costo descendente).
        by_cat = self.by_category()
        for cat, cost in sorted(by_cat.items(), key=lambda x: -x[1]):
            pct = (cost / self.total_monthly()) * 100  # Porcentaje del total.
            lines.append(f"  {cat:20} ${cost:>10,.2f} ({pct:>5.1f}%)")
        
        # Totales.
        lines.extend([
            "",
            "-" * 40,
            f"  TOTAL MENSUAL:      ${self.total_monthly():>10,.2f}",
            f"  TOTAL ANUAL:        ${self.total_annual():>10,.2f}",
            "=" * 60,
        ])
        
        return "\n".join(lines)                     # Unir lÃ­neas con saltos.


def calculate_portfolio_tco() -> TCOAnalysis:
    """
    Calcula TCO del Portfolio MLOps.
    
    Returns:
        TCOAnalysis con todos los costos del portfolio.
    """
    tco = TCOAnalysis("ML-MLOps-Portfolio")         # Crear anÃ¡lisis.
    
    # ========== COMPUTE ==========
    # Training jobs (usando Spot para ahorro).
    tco.add_item(CostItem(
        name="BankChurn Training (Spot)",           # Modelo de churn.
        category=CostCategory.COMPUTE,
        monthly_cost=15.80,                         # $15.80/mes.
        notes="g4dn.xlarge, 2hr/run, 4 runs/month, 70% Spot discount"
    ))
    tco.add_item(CostItem(
        name="CarVision Training (Spot)",           # Modelo de visiÃ³n.
        category=CostCategory.COMPUTE,
        monthly_cost=14.69,                         # $14.69/mes.
        notes="p3.2xlarge, 8hr/run, 2 runs/month, 70% Spot discount"
    ))
    
    # APIs de inferencia (On-Demand para disponibilidad).
    tco.add_item(CostItem(
        name="BankChurn API (On-Demand)",           # API de predicciÃ³n.
        category=CostCategory.COMPUTE,
        monthly_cost=59.90,                         # $59.90/mes.
        notes="2x t3.medium, 24/7"                  # 2 rÃ©plicas 24/7.
    ))
    tco.add_item(CostItem(
        name="CarVision API (On-Demand)",           # API de imÃ¡genes.
        category=CostCategory.COMPUTE,
        monthly_cost=189.36,                        # $189.36/mes.
        notes="1x g4dn.xlarge, 12hr/day"            # Solo horario laboral.
    ))
    
    # ========== STORAGE ==========
    tco.add_item(CostItem(
        name="S3 - Datasets",                       # Datos de entrenamiento.
        category=CostCategory.STORAGE,
        monthly_cost=23.00,                         # $23/mes.
        notes="~1TB, S3 Standard"                   # Tier Standard para acceso frecuente.
    ))
    tco.add_item(CostItem(
        name="S3 - Model Artifacts",                # Modelos guardados.
        category=CostCategory.STORAGE,
        monthly_cost=5.00,                          # $5/mes.
        notes="~200GB, S3 Standard-IA"              # Infrequent Access para artefactos.
    ))
    tco.add_item(CostItem(
        name="ECR - Docker Images",                 # ImÃ¡genes Docker.
        category=CostCategory.STORAGE,
        monthly_cost=10.00,                         # $10/mes.
        notes="~100GB images"                       # ImÃ¡genes de contenedores.
    ))
    
    # ========== NETWORK ==========
    tco.add_item(CostItem(
        name="Data Transfer (Egress)",              # TrÃ¡fico de salida.
        category=CostCategory.NETWORK,
        monthly_cost=45.00,                         # $45/mes.
        notes="~500GB egress/month"                 # TrÃ¡fico hacia internet.
    ))
    tco.add_item(CostItem(
        name="Load Balancer",                       # Balanceador de carga.
        category=CostCategory.NETWORK,
        monthly_cost=18.00,                         # $18/mes.
        notes="ALB + LCU"                           # Application Load Balancer.
    ))
    
    # ========== MANAGED SERVICES ==========
    tco.add_item(CostItem(
        name="CloudWatch Logs",                     # Logging centralizado.
        category=CostCategory.SERVICES,
        monthly_cost=15.00,                         # $15/mes.
        notes="Ingestion + Storage"                 # Ingesta y almacenamiento.
    ))
    tco.add_item(CostItem(
        name="Secrets Manager",                     # GestiÃ³n de secretos.
        category=CostCategory.SERVICES,
        monthly_cost=2.00,                          # $2/mes.
        notes="~5 secrets"                          # API keys, credenciales.
    ))
    
    return tco                                      # Retornar anÃ¡lisis completo.


# ========== EJEMPLO DE USO ==========
if __name__ == "__main__":
    tco = calculate_portfolio_tco()                 # Calcular TCO.
    print(tco.generate_report())                    # Imprimir reporte.
```

**Output esperado:**
```
============================================================
TCO ANALYSIS: ML-MLOps-Portfolio
============================================================

DESGLOSE POR CATEGORÃA:
----------------------------------------
  compute              $   279.75 (70.5%)
  network              $    63.00 (15.9%)
  storage              $    38.00 ( 9.6%)
  managed_services     $    17.00 ( 4.3%)

----------------------------------------
  TOTAL MENSUAL:      $   397.75
  TOTAL ANUAL:        $ 4,773.00
============================================================
```

---

<a id="6-ejercicio"></a>

## 6. Ejercicio: Reducir TCO en 30%

### Escenario

El Portfolio actual tiene TCO de ~$400/mes. Tu objetivo: **reducir a $280/mes (-30%)**.

### Estrategias a Evaluar

1. **Spot para Training** (ya implementado) - âœ…
2. **Reserved Instances para APIs 24/7**
3. **Right-sizing de instancias**
4. **Apagar APIs en horarios de bajo trÃ¡fico**
5. **Migrar storage a tiers mÃ¡s baratos**

### Template de SoluciÃ³n

```python
# ejercicio_tco_reduction.py
"""Ejercicio: Reducir TCO del Portfolio en 30%."""

from dataclasses import dataclass                   # Contenedores de datos.
from typing import List, Tuple                      # Type hints.


@dataclass
class OptimizationStrategy:
    """
    Estrategia de optimizaciÃ³n de costos.
    
    Representa una oportunidad de reducciÃ³n con su
    impacto esperado y nivel de riesgo.
    """
    name: str                                       # Nombre descriptivo.
    current_cost: float                             # Costo actual mensual.
    optimized_cost: float                           # Costo despuÃ©s de optimizar.
    implementation: str                             # CÃ³mo implementar.
    risk: str                                       # "low", "medium", "high".
    
    @property
    def savings(self) -> float:                     # Propiedad calculada.
        """Ahorro mensual en USD."""
        return self.current_cost - self.optimized_cost
    
    @property
    def savings_pct(self) -> float:                 # Propiedad calculada.
        """Porcentaje de ahorro."""
        return (self.savings / self.current_cost) * 100


def propose_optimizations() -> List[OptimizationStrategy]:
    """
    Propone estrategias de optimizaciÃ³n.
    
    Returns:
        Lista de estrategias ordenadas por impacto.
    """
    return [
        # Estrategia 1: Reserved Instances para APIs 24/7.
        OptimizationStrategy(
            name="Reserved Instances para BankChurn API",
            current_cost=59.90,                     # On-Demand actual.
            optimized_cost=35.94,                   # 40% descuento con RI 1yr.
            implementation="Comprar RI 1-year para 2x t3.medium",
            risk="low"                              # Bajo riesgo: compromiso conocido.
        ),
        # Estrategia 2: Reducir horas de operaciÃ³n.
        OptimizationStrategy(
            name="Apagar CarVision API en noches",
            current_cost=189.36,                    # 12hr/dÃ­a actual.
            optimized_cost=94.68,                   # Reducir a 6hr/dÃ­a.
            implementation="Schedule: 8am-8pm Ãºnicamente",
            risk="medium"                           # Medio: requiere validar uso nocturno.
        ),
        # Estrategia 3: Storage tiering.
        OptimizationStrategy(
            name="Migrar datasets antiguos a S3 Glacier",
            current_cost=23.00,                     # S3 Standard actual.
            optimized_cost=8.00,                    # Glacier para datos antiguos.
            implementation="Lifecycle policy: 30 dÃ­as â†’ Glacier",
            risk="low"                              # Bajo: polÃ­ticas automÃ¡ticas.
        ),
        # Estrategia 4: Right-sizing.
        OptimizationStrategy(
            name="Right-size BankChurn API",
            current_cost=59.90,                     # t3.medium actual.
            optimized_cost=29.95,                   # t3.small (50% ahorro).
            implementation="Reducir a t3.small (validar latencia)",
            risk="medium"                           # Medio: requiere pruebas de carga.
        ),
    ]


def calculate_optimized_tco(
    strategies: List[OptimizationStrategy],         # Lista de estrategias.
) -> Tuple[float, float]:
    """
    Calcula TCO optimizado aplicando todas las estrategias.
    
    Returns:
        Tuple de (ahorro_total, nuevo_tco).
    """
    current_tco = 397.75                            # TCO actual del portfolio.
    total_savings = sum(s.savings for s in strategies)  # Sumar ahorros.
    new_tco = current_tco - total_savings           # Nuevo TCO.
    
    return total_savings, new_tco


# ========== EJEMPLO DE USO ==========
if __name__ == "__main__":
    strategies = propose_optimizations()            # Obtener estrategias.
    
    # Imprimir encabezado.
    print("=" * 60)
    print("PLAN DE OPTIMIZACIÃ“N DE TCO")
    print("=" * 60)
    
    # Mostrar cada estrategia.
    for s in strategies:
        print(f"\nğŸ“Œ {s.name}")                      # Nombre.
        print(f"   Actual:     ${s.current_cost:.2f}/mes")  # Costo actual.
        print(f"   Optimizado: ${s.optimized_cost:.2f}/mes")  # Costo optimizado.
        print(f"   Ahorro:     ${s.savings:.2f}/mes ({s.savings_pct:.0f}%)")  # Ahorro.
        print(f"   Riesgo:     {s.risk}")           # Nivel de riesgo.
        print(f"   CÃ³mo:       {s.implementation}")  # ImplementaciÃ³n.
    
    # Calcular totales.
    savings, new_tco = calculate_optimized_tco(strategies)
    reduction_pct = (savings / 397.75) * 100        # Porcentaje de reducciÃ³n.
    
    # Imprimir resumen.
    print("\n" + "=" * 60)
    print("RESUMEN")
    print("=" * 60)
    print(f"TCO Actual:     ${397.75:.2f}/mes")
    print(f"TCO Optimizado: ${new_tco:.2f}/mes")
    print(f"Ahorro Total:   ${savings:.2f}/mes ({reduction_pct:.0f}%)")
    print(f"Meta (30%):     {'âœ… CUMPLIDA' if reduction_pct >= 30 else 'âŒ NO CUMPLIDA'}")
```

### Entregables

- [ ] Script con estrategias de optimizaciÃ³n.
- [ ] CÃ¡lculo de nuevo TCO.
- [ ] Plan de implementaciÃ³n con timeline.
- [ ] AnÃ¡lisis de riesgos por estrategia.

---

<a id="7-entrevista"></a>

## 7. Preguntas de Entrevista Senior

### Conceptuales

1. **Â¿QuÃ© es FinOps y cÃ³mo se aplica a ML?**
2. **Â¿CuÃ¡ndo usar Spot vs On-Demand vs Reserved?**
3. **Â¿CÃ³mo calculas el ROI de un modelo ML?**

### DiseÃ±o

4. **DiseÃ±a un sistema de auto-scaling que balancee costo y latencia.**
5. **Â¿CÃ³mo implementarÃ­as checkpointing para training en Spot?**
6. **Â¿CÃ³mo reducirÃ­as costos de inference sin afectar latencia?**

### Caso PrÃ¡ctico

7. **Tu modelo de churn cuesta $10K/mes en inference. El CFO pide reducir 40%. Â¿QuÃ© opciones propones?**

### Respuestas Clave

**P1**: FinOps es la prÃ¡ctica de gestionar costos cloud como cÃ³digo: visibilidad, optimizaciÃ³n y governance. En ML: tagging por experimento, right-sizing GPU, Spot para training.

**P2**: 
- **Spot**: Training batch, hyperparameter tuning, dev/test.
- **On-Demand**: APIs crÃ­ticas, cargas impredecibles.
- **Reserved**: APIs 24/7 con carga estable (40-70% descuento).

**P7**: Opciones:
1. Reserved Instances (-40%).
2. Auto-scaling agresivo en horarios de bajo trÃ¡fico.
3. Model distillation (modelo mÃ¡s pequeÃ±o).
4. Batch predictions en lugar de real-time donde sea posible.
5. Edge inference para reducir llamadas al cloud.

---

## ğŸ“º Recursos Externos del MÃ³dulo

> ğŸ·ï¸ Sistema: ğŸ”´ Obligatorio | ğŸŸ¡ Recomendado | ğŸŸ¢ Complementario

### ğŸ“„ DocumentaciÃ³n

| ğŸ·ï¸ | Recurso | DescripciÃ³n |
|:--:|:--------|:------------|
| ğŸ”´ | [AWS Cost Optimization](https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/) | Well-Architected |
| ğŸŸ¡ | [FinOps Foundation](https://www.finops.org/) | Comunidad y certificaciones |
| ğŸŸ¢ | [Spot Instance Advisor](https://aws.amazon.com/ec2/spot/instance-advisor/) | Herramienta AWS |

---

## ğŸ”— Glosario del MÃ³dulo

| TÃ©rmino | DefiniciÃ³n |
|---------|------------|
| **FinOps** | PrÃ¡ctica de gestionar costos cloud como cÃ³digo |
| **TCO** | Total Cost of Ownership - costo total de propiedad |
| **Spot Instance** | Capacidad excedente de cloud a ~70% descuento |
| **Reserved Instance** | Compromiso 1-3 aÃ±os con 40-70% descuento |

---

<div align="center">

**Siguiente mÃ³dulo** â†’ [22. IaC Empresarial](22_IAC_EMPRESARIAL.md)

---

[â† Volver al Ãndice](00_INDICE.md)

</div>
