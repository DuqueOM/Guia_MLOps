# 01. Python Moderno para MLOps

## ğŸ¯ Objetivo del MÃ³dulo

Transformar tu cÃ³digo de "funciona en un notebook" a "pasa code review en una empresa FAANG".

En este portafolio aplicarÃ¡s estos patrones sobre `common_utils/` y el cÃ³digo de los tres proyectos
(BankChurn-Predictor, CarVision-Market-Intelligence, TelecomAI-Customer-Intelligence), para que
tu Python sea consistente en todo el stack.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   ANTES (Data Scientist tÃ­pico)          DESPUÃ‰S (MLOps Engineer)            â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â•‘
â•‘   â€¢ Un archivo gigante                   â€¢ Paquete instalable                â•‘
â•‘   â€¢ Sin tipos                            â€¢ Type hints en todo                â•‘
â•‘   â€¢ Config hardcodeada                   â€¢ Pydantic validation               â•‘
â•‘   â€¢ "Funciona en mi mÃ¡quina"             â€¢ Funciona en cualquier mÃ¡quina     â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

<a id="00-prerrequisitos"></a>

## 0.0 Prerrequisitos

- Python bÃ¡sico: funciones, clases, mÃ³dulos.
- Terminal: ejecutar comandos y navegar carpetas.
- Entorno listo para ejecutar el portafolio (si todavÃ­a no lo tienes, usa el mÃ³dulo **[04_ENTORNOS](04_ENTORNOS.md)**).
- Opcional (pero recomendado): entender quÃ© significa instalar un paquete en modo editable (`pip install -e .`).

---

<a id="01-protocolo-e-como-estudiar-este-modulo"></a>

## 0.1 ğŸ§  Protocolo E: CÃ³mo estudiar este mÃ³dulo

- **Antes de leer**: abre **[Protocolo E](study_tools/PROTOCOLO_E.md)** y define tu *output mÃ­nimo* de la sesiÃ³n.
- **Mientras implementas**: si te atoras >15 min, registra el bloqueo en **[Diario de Errores](study_tools/DIARIO_ERRORES.md)**.
- **Al cerrar la semana**: usa **[Cierre Semanal](study_tools/CIERRE_SEMANAL.md)** para decidir en quÃ© mejorar (calidad, reproducibilidad, etc.).

---

<a id="02-entregables-verificables-minimo-viable"></a>

## 0.2 âœ… Entregables verificables (mÃ­nimo viable)

Al terminar este mÃ³dulo, deberÃ­as poder mostrar (en al menos 1 proyecto del portafolio):

- [ ] **Type hints** en funciones pÃºblicas (carga de datos, features, train, predict)
- [ ] **`mypy` corriendo** sobre `src/` sin errores crÃ­ticos
- [ ] **Config con Pydantic** (cargando YAML y validando rangos)
- [ ] **`src/` layout real** (paquete instalable)
- [ ] **InstalaciÃ³n editable**: `pip install -e ".[dev]"` y `pytest` corriendo desde raÃ­z

---

<a id="03-puente-teoria-codigo-portafolio"></a>

## 0.3 ğŸ§© Puente teorÃ­a â†” cÃ³digo (Portafolio)

Para que esto cuente como progreso real, fuerza este mapeo:

- **Concepto**: typing / Pydantic / packaging
- **Archivo**: `src/<paquete>/config.py`, `src/<paquete>/training.py`, `pyproject.toml`
- **Prueba**: `mypy src/` + `pytest`
- **Evidencia**: checklist del mÃ³dulo + 1 entrada en Diario si hubo bloqueo
## ğŸ“‹ Contenido

- **0.0** [Prerrequisitos](#00-prerrequisitos)
- **0.1** [Protocolo E: CÃ³mo estudiar este mÃ³dulo](#01-protocolo-e-como-estudiar-este-modulo)
- **0.2** [Entregables verificables (mÃ­nimo viable)](#02-entregables-verificables-minimo-viable)
- **0.3** [Puente teorÃ­a â†” cÃ³digo (Portafolio)](#03-puente-teoria-codigo-portafolio)
- **0.4** [Repaso: Fundamentos de Python para MLOps](#04-repaso-fundamentos-python) â­ NUEVO
1. [Type Hints: Tu Contrato con el Futuro](#11-type-hints-tu-contrato-con-el-futuro)
2. [Pydantic: ValidaciÃ³n AutomÃ¡tica](#12-pydantic-validation-automatica)
3. [src/ Layout: Estructura Profesional](#13-src-layout-estructura-profesional)
4. [Principios SOLID para ML](#14-principios-solid-para-ml)
5. [OOP para ML: Protocolos y ABC](#15-oop-para-ml) â­ NUEVO
6. [Pandera: ValidaciÃ³n de DataFrames](#16-pandera-validacion-dataframes) â­ NUEVO
7. [Ejercicios PrÃ¡cticos](#17-ejercicios-practicos)

---

<a id="04-repaso-fundamentos-python"></a>

## 0.4 Repaso: Fundamentos de Python para MLOps

> **Si vienes de Python bÃ¡sico**, esta secciÃ³n te prepara para el salto a cÃ³digo profesional.
> Si ya dominas funciones, clases y mÃ³dulos, puedes saltar a la secciÃ³n 1.1.

### ğŸ¯ De Notebook a CÃ³digo Profesional: El Mindset

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  EL PROBLEMA DEL DATA SCIENTIST TÃPICO:                                       â•‘
â•‘                                                                               â•‘
â•‘  En un notebook:                                                              â•‘
â•‘  â€¢ Escribes cÃ³digo en celdas desordenadas                                     â•‘
â•‘  â€¢ Variables globales por todos lados                                         â•‘
â•‘  â€¢ "Funciona" = Ã©xito                                                         â•‘
â•‘  â€¢ Cuando algo falla, reinicias el kernel y vuelves a correr todo            â•‘
â•‘                                                                               â•‘
â•‘  En producciÃ³n:                                                               â•‘
â•‘  â€¢ El cÃ³digo debe ser MODULAR (dividido en piezas reutilizables)             â•‘
â•‘  â€¢ Las dependencias deben ser EXPLÃCITAS (no variables mÃ¡gicas)              â•‘
â•‘  â€¢ "Funciona" = pasa tests + se entiende + se mantiene                       â•‘
â•‘  â€¢ Cuando algo falla, necesitas DIAGNOSTICAR sin reiniciar                   â•‘
â•‘                                                                               â•‘
â•‘  Esta guÃ­a te lleva del primer mindset al segundo.                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Funciones: La Unidad BÃ¡sica de CÃ³digo Reutilizable

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NIVEL BÃSICO: Funciones simples
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âŒ CÃ³digo de notebook (todo en celdas sueltas) - NO HAGAS ESTO
import pandas as pd                              # pandas: librerÃ­a para manipular tablas (DataFrames). "pd" es la convenciÃ³n universal.
df = pd.read_csv("data.csv")                     # read_csv() lee un archivo CSV y lo convierte en DataFrame (tabla en memoria).
df = df.dropna()                                 # dropna() elimina TODAS las filas con algÃºn valor faltante (NaN). Peligroso: puedes perder datos.
df["Age"] = df["Age"].fillna(df["Age"].mean())   # fillna() rellena NaN con un valor; mean() calcula el promedio. Problema: esto ya modificÃ³ df arriba.
# ... y asÃ­ 200 lÃ­neas mÃ¡s                       # En notebooks, el cÃ³digo crece sin estructura â†’ imposible de mantener/testear.

# âœ… CÃ³digo profesional (encapsulado en funciones)
def load_and_clean_data(path: str) -> pd.DataFrame:  # def: define una funciÃ³n. "path: str" indica que espera un string. "-> pd.DataFrame" indica quÃ© retorna.
    """Carga datos y aplica limpieza bÃ¡sica.         # Docstring: documentaciÃ³n de la funciÃ³n. SIEMPRE documenta funciones pÃºblicas.
    
    Args:                                            # Args: lista de parÃ¡metros que recibe la funciÃ³n.
        path: Ruta al archivo CSV.                   # Describe cada parÃ¡metro con tipo y propÃ³sito.
        
    Returns:                                         # Returns: describe quÃ© devuelve la funciÃ³n.
        DataFrame limpio listo para feature engineering.
        
    Example:                                         # Example: muestra cÃ³mo usar la funciÃ³n (doctests ejecutables con pytest).
        >>> df = load_and_clean_data("data/raw/churn.csv")
        >>> df.shape
        (10000, 14)
    """
    df = pd.read_csv(path)                           # Lee el CSV. La ruta viene como parÃ¡metro â†’ la funciÃ³n es REUTILIZABLE.
    df = df.dropna(subset=["target"])                # subset=["target"]: solo elimina filas donde "target" es NaN, no todas las filas.
    df["Age"] = df["Age"].fillna(df["Age"].median()) # median() es mÃ¡s robusto que mean() frente a outliers.
    return df                                        # return: devuelve el resultado. Sin return, la funciÃ³n devuelve None.

# Ahora puedo REUTILIZAR esta funciÃ³n en cualquier parte
df_train = load_and_clean_data("data/train.csv")     # Llamo la funciÃ³n con datos de entrenamiento â†’ obtienen misma limpieza.
df_test = load_and_clean_data("data/test.csv")       # Llamo con datos de test â†’ GARANTIZA consistencia entre train y test.
```

### Clases: Agrupando Datos y Comportamiento

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â¿POR QUÃ‰ CLASES? La AnalogÃ­a del Formulario
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Imagina que tienes que procesar solicitudes de crÃ©dito:
#
# SIN CLASES (diccionarios sueltos):
# solicitud1 = {"nombre": "Juan", "edad": 30, "salario": 50000}
# solicitud2 = {"nombre": "Ana", "edad": None, "salario": -1000}  # Â¿VÃ¡lido?
#
# Â¿CÃ³mo validas que la edad no sea None?
# Â¿CÃ³mo evitas salarios negativos?
# Â¿DÃ³nde pones la lÃ³gica de calcular el score crediticio?
#
# CON CLASES (estructura + validaciÃ³n + comportamiento):

from dataclasses import dataclass      # dataclass: decorador que genera automÃ¡ticamente __init__, __repr__, __eq__ para tu clase.
from typing import Optional            # Optional[X] significa "puede ser X o None". Equivale a Union[X, None].

@dataclass                             # @dataclass: convierte la clase en una "data class" â†’ menos cÃ³digo boilerplate.
class SolicitudCredito:                # class: define un nuevo tipo de objeto. PascalCase por convenciÃ³n (primera letra mayÃºscula).
    """Una solicitud de crÃ©dito con validaciÃ³n bÃ¡sica."""  # Docstring de la clase: explica su propÃ³sito.
    nombre: str                        # Atributo: nombre de tipo str (texto). dataclass lo convierte en parÃ¡metro del __init__.
    edad: int                          # Atributo: edad de tipo int (entero). SerÃ¡ obligatorio al crear la instancia.
    salario: float                     # Atributo: salario de tipo float (decimal). TambiÃ©n obligatorio.
    historial_crediticio: Optional[float] = None  # Atributo OPCIONAL: tiene valor por defecto None. Puede o no proporcionarse.
    
    def __post_init__(self):           # __post_init__: mÃ©todo especial que se ejecuta DESPUÃ‰S de que dataclass crea el objeto.
        """ValidaciÃ³n al crear la instancia."""  # AquÃ­ ponemos validaciones que deben ocurrir al instanciar.
        if self.edad < 18:             # self: referencia al objeto actual. self.edad accede al atributo edad de ESTA instancia.
            raise ValueError("Debe ser mayor de edad")  # raise: lanza una excepciÃ³n. ValueError: error por valor invÃ¡lido.
        if self.salario <= 0:          # ValidaciÃ³n de negocio: salario debe ser positivo.
            raise ValueError("Salario debe ser positivo")
    
    def calcular_score(self) -> float: # MÃ©todo: funciÃ³n que pertenece a la clase. self siempre es el primer parÃ¡metro.
        """Calcula score crediticio bÃ¡sico."""
        base = min(self.salario / 1000, 100)      # min(a, b): retorna el menor. Limita el score base a 100 mÃ¡ximo.
        edad_bonus = min(self.edad - 18, 30) * 0.5  # Bonus por edad, mÃ¡ximo 15 puntos (30 * 0.5).
        return base + edad_bonus       # return: devuelve el resultado del cÃ¡lculo.

# Ahora es IMPOSIBLE crear una solicitud invÃ¡lida
solicitud = SolicitudCredito(nombre="Juan", edad=30, salario=50000)  # Crea instancia: dataclass genera __init__ con estos parÃ¡metros.
print(f"Score: {solicitud.calcular_score()}")  # f-string: f"..." permite insertar {expresiones} dentro del string. Score: 56.0

# Esto FALLA inmediatamente con un error claro
# solicitud_mala = SolicitudCredito(nombre="Ana", edad=15, salario=-1000)
# ValueError: Debe ser mayor de edad  # El error es CLARO y ocurre EN LA CREACIÃ“N, no despuÃ©s cuando ya es tarde.
```

### MÃ³dulos: Organizando CÃ³digo en Archivos

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Â¿POR QUÃ‰ MÃ“DULOS? La AnalogÃ­a de la Biblioteca
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Una biblioteca tiene SECCIONES (mÃ³dulos):
# - SecciÃ³n de novelas (data.py)
# - SecciÃ³n de ciencia (features.py)
# - SecciÃ³n de historia (training.py)
#
# Cada secciÃ³n tiene su PROPÃ“SITO y no mezclas libros de cocina con novelas.

# Estructura tÃ­pica de un proyecto ML:
#
# src/bankchurn/
# â”œâ”€â”€ __init__.py      # "Esta carpeta es un paquete Python"
# â”œâ”€â”€ config.py        # ConfiguraciÃ³n (Pydantic)
# â”œâ”€â”€ data.py          # Carga y limpieza de datos
# â”œâ”€â”€ features.py      # Feature engineering
# â”œâ”€â”€ training.py      # Entrenamiento del modelo
# â”œâ”€â”€ evaluation.py    # MÃ©tricas y evaluaciÃ³n
# â””â”€â”€ prediction.py    # Inferencia en producciÃ³n

# Importar desde mÃ³dulos:
from bankchurn.config import BankChurnConfig
from bankchurn.data import load_and_clean_data
from bankchurn.training import ChurnTrainer

# Esto es MUCHO mÃ¡s claro que tener todo en un archivo de 2000 lÃ­neas
```

### Decoradores: Funciones que Modifican Funciones

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DECORADORES: Muy usados en MLOps (logging, timing, caching, validaciÃ³n)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import time                            # time: mÃ³dulo estÃ¡ndar de Python para medir tiempo. time.time() da segundos desde 1970.
from functools import wraps            # wraps: preserva metadatos de la funciÃ³n original (nombre, docstring) al decorarla.

def medir_tiempo(func):                # Un decorador es una funciÃ³n que RECIBE otra funciÃ³n como parÃ¡metro.
    """Decorador que mide el tiempo de ejecuciÃ³n de una funciÃ³n."""
    @wraps(func)                       # @wraps(func): copia __name__, __doc__ de func a wrapper. Sin esto, se pierde el nombre original.
    def wrapper(*args, **kwargs):      # wrapper: funciÃ³n interna que "envuelve" a la original. *args/**kwargs capturan cualquier argumento.
        inicio = time.time()           # Guarda el tiempo ANTES de ejecutar la funciÃ³n.
        resultado = func(*args, **kwargs)  # Ejecuta la funciÃ³n original con sus argumentos. func es la funciÃ³n decorada.
        fin = time.time()              # Guarda el tiempo DESPUÃ‰S de ejecutar.
        print(f"â±ï¸ {func.__name__} tardÃ³ {fin - inicio:.2f}s")  # __name__: nombre de la funciÃ³n. :.2f formatea a 2 decimales.
        return resultado               # Retorna lo que retornÃ³ la funciÃ³n original (no "comerse" el resultado).
    return wrapper                     # El decorador retorna la funciÃ³n wrapper, que reemplaza a la original.

# Uso:
@medir_tiempo                          # @decorador es equivalente a: entrenar_modelo = medir_tiempo(entrenar_modelo)
def entrenar_modelo(X, y):             # Esta funciÃ³n ahora estÃ¡ "envuelta" por wrapper. Al llamarla, ejecuta wrapper.
    """Entrena un modelo (simulado)."""
    time.sleep(2)                      # sleep(2): pausa 2 segundos. Simula un proceso que tarda (como entrenar un modelo).
    return "modelo_entrenado"          # Retorna un string (en la realidad serÃ­a el modelo entrenado).

modelo = entrenar_modelo(None, None)   # Llamar entrenar_modelo() realmente llama a wrapper(), que mide tiempo y llama a la original.
# Output: â±ï¸ entrenar_modelo tardÃ³ 2.00s  # El decorador aÃ±adiÃ³ comportamiento (medir tiempo) SIN modificar la funciÃ³n original.

# En el portafolio verÃ¡s decoradores para:
# - Logging automÃ¡tico de funciones    # Registrar cada llamada a funciÃ³n con sus parÃ¡metros.
# - Caching de resultados costosos     # @lru_cache: guarda resultados para no recalcular.
# - ValidaciÃ³n de inputs/outputs       # Verificar tipos o rangos antes/despuÃ©s de ejecutar.
# - Retry de operaciones que pueden fallar  # Reintentar N veces si hay error (Ãºtil para APIs, BD).
```

### Context Managers: Recursos que se Limpian Solos

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTEXT MANAGERS: Cruciales para archivos, conexiones, MLflow runs
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# âŒ PROBLEMA: Si hay un error, el archivo queda abierto
f = open("data.csv", "r")              # open(): abre un archivo. "r" = modo lectura. Retorna un objeto file.
data = f.read()                        # read(): lee TODO el contenido del archivo a memoria (cuidado con archivos grandes).
# ... si algo falla aquÃ­, f nunca se cierra  # Si ocurre una excepciÃ³n, el cÃ³digo salta y f.close() nunca se ejecuta.
f.close()                              # close(): libera el recurso. Sin cerrar, puedes agotar file descriptors del sistema.

# âœ… SOLUCIÃ“N: with garantiza que el archivo se cierre
with open("data.csv", "r") as f:       # with: inicia un "context manager". "as f" asigna el archivo a la variable f.
    data = f.read()                    # El cÃ³digo dentro del with tiene acceso a f.
# f se cierra automÃ¡ticamente, incluso si hay error  # Al salir del with (normal o por excepciÃ³n), Python llama f.__exit__() que cierra el archivo.

# En MLflow (que usarÃ¡s en el mÃ³dulo 10):
import mlflow                          # mlflow: librerÃ­a para tracking de experimentos ML. VerÃ¡s mÃ¡s en mÃ³dulo 10.

with mlflow.start_run(run_name="experimento_1"):  # start_run(): inicia un "run" de MLflow. Es un context manager.
    mlflow.log_param("n_estimators", 100)         # log_param(): registra un hiperparÃ¡metro. Se guarda asociado al run.
    mlflow.log_metric("f1_score", 0.85)           # log_metric(): registra una mÃ©trica. Puedes ver esto en la UI de MLflow.
    # El run se cierra automÃ¡ticamente al salir del with  # MLflow guarda todo y marca el run como finalizado.
```

### Comprehensions: CÃ³digo Conciso y PythÃ³nico

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPREHENSIONS: Transformaciones elegantes de datos
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# List comprehension (muy comÃºn en ML)
columnas = ["CreditScore", "Age", "Balance", "Exited"]  # Lista de strings con nombres de columnas.
columnas_numericas = [col for col in columnas if col != "Exited"]  # [expresiÃ³n for variable in iterable if condiciÃ³n]
# ['CreditScore', 'Age', 'Balance']  # Resultado: lista con todos los elementos EXCEPTO "Exited".
# Equivale a:                        # Es equivalente a un for loop, pero en UNA lÃ­nea:
# columnas_numericas = []            # result = []
# for col in columnas:               # for col in columnas:
#     if col != "Exited":            #     if col != "Exited":
#         columnas_numericas.append(col)  #         result.append(col)

# Dict comprehension (Ãºtil para mÃ©tricas)
metricas = {"accuracy": 0.85, "precision": 0.78, "recall": 0.72}  # Diccionario: {clave: valor}.
metricas_redondeadas = {k: round(v, 2) for k, v in metricas.items()}  # {clave: valor for clave, valor in dict.items()}
# items(): retorna pares (clave, valor). round(v, 2): redondea v a 2 decimales.

# Filtrar columnas por tipo (patrÃ³n comÃºn en feature engineering)
import pandas as pd                  # pandas ya se explicÃ³ arriba; aquÃ­ se re-importa por claridad del ejemplo.
df = pd.DataFrame({"A": [1, 2], "B": ["x", "y"], "C": [1.5, 2.5]})  # DataFrame: tabla con 3 columnas.
columnas_numericas = [col for col in df.columns if df[col].dtype in ["int64", "float64"]]
# df.columns: lista de nombres de columnas. df[col].dtype: tipo de datos de esa columna.
# "int64", "float64": tipos numÃ©ricos de pandas/numpy. Este patrÃ³n filtra SOLO columnas numÃ©ricas.

# Crear diccionario de features categÃ³ricas a codificar
cat_cols = ["Geography", "Gender"]   # Lista de columnas categÃ³ricas que queremos codificar.
encoding_map = {col: df[col].unique().tolist() for col in cat_cols}
# unique(): valores Ãºnicos de la columna. tolist(): convierte array a lista Python.
# Resultado: {"Geography": ["France", "Spain", ...], "Gender": ["Male", "Female"]}
```

### Manejo de Excepciones: CÃ³digo que No se Rompe

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXCEPCIONES: Anticipar y manejar errores profesionalmente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from pathlib import Path                # Path: clase para manejar rutas de archivos de forma segura y multiplataforma.
import logging                          # logging: mÃ³dulo estÃ¡ndar para registrar mensajes (mejor que print en producciÃ³n).

logger = logging.getLogger(__name__)    # getLogger(__name__): crea un logger con el nombre del mÃ³dulo actual.
                                        # __name__ es una variable especial que contiene el nombre del mÃ³dulo.

def cargar_modelo(path: Path):          # FunciÃ³n que recibe un Path (no string) â†’ mÃ¡s seguro y con autocompletado.
    """Carga un modelo serializado con manejo de errores.
    
    Args:
        path: Ruta al archivo .joblib del modelo.
        
    Returns:
        Modelo cargado.
        
    Raises:                              # Raises: documenta quÃ© excepciones puede lanzar esta funciÃ³n.
        FileNotFoundError: Si el archivo no existe.
        ValueError: Si el archivo no contiene un modelo vÃ¡lido.
    """
    if not path.exists():                # exists(): mÃ©todo de Path que verifica si el archivo/carpeta existe.
        raise FileNotFoundError(f"Modelo no encontrado: {path}")  # raise: lanza una excepciÃ³n. El programa se detiene aquÃ­.
    
    try:                                 # try: intenta ejecutar el cÃ³digo. Si falla, salta al except.
        import joblib                    # joblib: librerÃ­a para serializar objetos Python (modelos sklearn).
        modelo = joblib.load(path)       # load(): deserializa el archivo y retorna el objeto Python guardado.
    except Exception as e:               # except: captura la excepciÃ³n si algo fallÃ³ en el try. "as e" guarda el error.
        logger.error(f"Error cargando modelo: {e}")  # error(): registra un mensaje de nivel ERROR en el log.
        raise ValueError(f"Archivo invÃ¡lido: {path}") from e  # from e: encadena excepciones (muestra la causa original).
    
    # Validar que sea un modelo sklearn
    if not hasattr(modelo, "predict"):   # hasattr(): verifica si el objeto tiene un atributo/mÃ©todo. Todos los modelos sklearn tienen predict().
        raise ValueError(f"El archivo no contiene un modelo vÃ¡lido: {path}")
    
    logger.info(f"Modelo cargado exitosamente: {path}")  # info(): mensaje informativo (menos grave que error).
    return modelo                        # Si llegamos aquÃ­, todo saliÃ³ bien. Retornamos el modelo cargado.

# Uso con manejo de error
try:                                     # try/except: patrÃ³n para manejar errores sin que el programa crashee.
    modelo = cargar_modelo(Path("models/pipeline.joblib"))  # Path(): convierte string a objeto Path.
except FileNotFoundError:                # Captura SOLO FileNotFoundError. Otros errores no se capturan aquÃ­.
    print("âš ï¸ Modelo no encontrado. Ejecuta 'make train' primero.")  # Mensaje amigable al usuario.
except ValueError as e:                  # Captura ValueError. "as e" permite acceder al mensaje de error.
    print(f"âŒ Error de validaciÃ³n: {e}")  # f-string con el error especÃ­fico.
```

### ğŸ¯ Ejercicio de Auto-evaluaciÃ³n: Â¿EstÃ¡s Listo?

Antes de continuar, verifica que puedes responder estas preguntas:

```python
# 1. Â¿QuÃ© hace este cÃ³digo?
def process(items: list[str]) -> dict[str, int]:
    return {item: len(item) for item in items if item}

# 2. Â¿Por quÃ© esto es mejor que usar un diccionario?
@dataclass
class Config:
    batch_size: int = 32
    learning_rate: float = 0.001

# 3. Â¿QuÃ© problema evita el "with"?
with open("file.txt") as f:
    data = f.read()

# 4. Â¿QuÃ© imprime este cÃ³digo?
def decorator(func):
    def wrapper():
        print("antes")
        func()
        print("despuÃ©s")
    return wrapper

@decorator
def hello():
    print("hola")

hello()
```

<details>
<summary>ğŸ” Ver respuestas</summary>

1. **Crea un diccionario** donde las keys son strings no vacÃ­os y los values son sus longitudes.

2. **ValidaciÃ³n y documentaciÃ³n automÃ¡tica**: `@dataclass` genera `__init__`, `__repr__`, y permite type hints. Un diccionario no valida tipos ni tiene autocompletado en el IDE.

3. **Evita dejar archivos abiertos**: Si hay un error dentro del `with`, el archivo se cierra automÃ¡ticamente.

4. **Imprime**:
   ```
   antes
   hola
   despuÃ©s
   ```
   El decorador "envuelve" la funciÃ³n original.

</details>

---

<a id="11-type-hints-tu-contrato-con-el-futuro"></a>

## 1.1 Type Hints: Tu Contrato con el Futuro

### La AnalogÃ­a del Restaurante

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ½ï¸ IMAGINA UN RESTAURANTE:                                               â•‘
â•‘                                                                           â•‘
â•‘  SIN MENÃš (cÃ³digo sin tipos):                                             â•‘
â•‘  - "TrÃ¡eme algo de comer"                                                 â•‘
â•‘  - El chef improvisa                                                      â•‘
â•‘  - El cliente no sabe quÃ© esperar                                         â•‘
â•‘  - Resultado: sorpresas (bugs)                                            â•‘
â•‘                                                                           â•‘
â•‘  CON MENÃš (cÃ³digo con tipos):                                             â•‘
â•‘  - "Quiero el plato #5: Pasta Carbonara"                                  â•‘
â•‘  - El chef sabe exactamente quÃ© preparar                                  â•‘
â•‘  - El cliente sabe quÃ© recibirÃ¡                                           â•‘
â•‘  - Resultado: consistencia                                                â•‘
â•‘                                                                           â•‘
â•‘  TYPE HINTS = El menÃº de tu cÃ³digo                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### CÃ³digo Real del Portafolio: Sin Tipos vs Con Tipos

```python
# âŒ ANTES: Â¿QuÃ© recibe? Â¿QuÃ© retorna? 
# (Esto es lo que encontrarÃ­as en un notebook)

def prepare_features(df, num_cols, cat_cols, target):  # Define una funciÃ³n sin type hints: no sabemos tipos esperados ni retornos.
    X = df.drop(columns=[target])  # Separa features (X) eliminando la columna objetivo del DataFrame.
    y = df[target]  # Extrae el target (y) como una Serie; asume que `target` existe y estÃ¡ bien escrito.
    
    preprocessor = ColumnTransformer([  # Crea un transformador por columnas: aplica pipelines distintos a columnas numÃ©ricas vs categÃ³ricas.
        ('num', StandardScaler(), num_cols),  # (nombre, transformer, columnas): escala numÃ©ricas a media=0, var=1 (ayuda a muchos modelos).
        ('cat', OneHotEncoder(), cat_cols)  # One-hot a categÃ³ricas; por defecto puede fallar si aparece una categorÃ­a nueva en inferencia.
    ])  # Termina la definiciÃ³n del ColumnTransformer (aÃºn no se ha entrenado/ajustado).
    
    X_transformed = preprocessor.fit_transform(X)  # Ajusta (fit) el preprocesador usando X y luego transforma X; devuelve una matriz (a menudo sparse).
    return X_transformed, y, preprocessor  # Retorna features transformadas, el target y el preprocesador ya ajustado (para usar igual en valid/test/inferencia).
```

```python
# âœ… DESPUÃ‰S: CÃ³digo real de BankChurn-Predictor/src/bankchurn/training.py

from __future__ import annotations  # Posponer evaluaciÃ³n de anotaciones: permite forward refs y reduce problemas de import/ciclos.

from pathlib import Path  # Paths tipados/seguros (mejor que strings) para rutas de archivos/directorios.
from typing import List, Tuple  # Tipos genÃ©ricos para anotar colecciones y retornos compuestos.

import numpy as np  # NumPy: arrays y tipos numÃ©ricos; Ãºtil para tipar dtypes concretos.
import pandas as pd  # Pandas: DataFrame/Series, estructuras tÃ­picas para datos tabulares.
from numpy.typing import NDArray  # Tipo estÃ¡tico para arrays NumPy: ayuda a mypy a entender shapes/dtypes (hasta cierto punto).
from sklearn.compose import ColumnTransformer  # Enrutador de transformaciones por grupo de columnas (numÃ©ricas/categÃ³ricas/etc.).
from sklearn.preprocessing import OneHotEncoder, StandardScaler  # Transformadores estÃ¡ndar de scikit-learn.

def prepare_features(
    df: pd.DataFrame,  # Input tabular: se asume que contiene features + columna objetivo.
    num_cols: List[str],  # Lista de nombres de columnas numÃ©ricas: se usarÃ¡ para escalar.
    cat_cols: List[str],  # Lista de nombres de columnas categÃ³ricas: se usarÃ¡ para one-hot.
    target: str  # Nombre de la columna objetivo (label) que se va a separar en y.
) -> Tuple[NDArray[np.float64], pd.Series, ColumnTransformer]:
    """Prepara features para entrenamiento.
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    num_cols : List[str]
        Nombres de columnas numÃ©ricas.
    cat_cols : List[str]
        Nombres de columnas categÃ³ricas.
    target : str
        Nombre de la columna objetivo.
    
    Returns
    -------
    Tuple[NDArray, pd.Series, ColumnTransformer]
        Features transformadas, target, y preprocessor fitted.
    """
    X = df.drop(columns=[target])  # Construye X eliminando la columna objetivo: evita leakage obvio (target dentro de features).
    y = df[target]  # Construye y como Serie: etiqueta que el modelo intentarÃ¡ predecir.
    
    preprocessor = ColumnTransformer([  # Define el pipeline de preprocesamiento: se â€œfijaâ€ aquÃ­ para ser reproducible.
        ('num', StandardScaler(), num_cols),  # Escalado numÃ©rico: Ãºtil para modelos lineales/NN; inofensivo para muchos casos.
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)  # ignore evita crash en inferencia si llega una categorÃ­a nueva.
    ])  # Nota MLOps: guardar este objeto es clave para que producciÃ³n use la misma transformaciÃ³n que entrenamiento.
    
    X_transformed = preprocessor.fit_transform(X)  # Ajusta el preprocesador (learn stats/categorÃ­as) y transforma X al espacio numÃ©rico.
    return X_transformed, y, preprocessor  # Retorna tuple explÃ­cita y tipada: mypy/IDE verifican contratos y ayudan en refactors.
```

### Los Tipos Esenciales para ML

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS BÃSICOS - Los usarÃ¡s constantemente
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import (                   # typing: mÃ³dulo estÃ¡ndar de Python para anotaciones de tipos.
    List,       # Lista de elementos: List[str] = ["a", "b"]  # Lista donde TODOS los elementos son strings.
    Dict,       # Diccionario: Dict[str, float] = {"acc": 0.95}  # Dict con claves str y valores float.
    Tuple,      # Tupla fija: Tuple[int, int] = (100, 10)  # Tupla de exactamente 2 enteros.
    Optional,   # Puede ser None: Optional[Path] = None  # Equivale a Union[Path, None].
    Union,      # MÃºltiples tipos: Union[str, List[str]]  # Puede ser string O lista de strings.
    Any,        # Cualquier tipo (evitar si posible)  # Desactiva type checking - Ãºsalo solo si es inevitable.
    Literal,    # Valores especÃ­ficos: Literal["train", "eval"]  # SOLO puede ser "train" o "eval", nada mÃ¡s.
)
from pathlib import Path               # Path: ya explicado en excepciones. Mejor que strings para rutas.

# Ejemplos del portafolio real:

# BankChurn: features son listas de strings
features: List[str] = ["CreditScore", "Age", "Balance"]  # ": List[str]" indica el tipo. mypy verifica que sea correcto.

# CarVision: mÃ©tricas son diccionario string->float
metrics: Dict[str, float] = {"rmse": 4794.27, "r2": 0.77}  # Claves son strings (nombres), valores son floats (nÃºmeros).

# TelecomAI: puede recibir path o None
model_path: Optional[Path] = None      # Optional[X] = puede ser X o None. Ãštil para parÃ¡metros opcionales.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS PARA ML - EspecÃ­ficos de Machine Learning
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import pandas as pd                    # pandas: la librerÃ­a estÃ¡ndar para datos tabulares. Ya la vimos antes.
import numpy as np                     # numpy: librerÃ­a para arrays numÃ©ricos de alto rendimiento. Base de sklearn/pandas.
from numpy.typing import NDArray       # NDArray: tipo para arrays numpy. NDArray[np.float64] = array de floats de 64 bits.
from sklearn.base import BaseEstimator # BaseEstimator: clase base de TODOS los modelos sklearn. Garantiza fit/predict.
from sklearn.pipeline import Pipeline  # Pipeline: encadena transformadores + modelo. Lo verÃ¡s en mÃ³dulo 07.

# DataFrame de pandas
def load_data(path: Path) -> pd.DataFrame:  # Retorna pd.DataFrame: indica que devuelve una tabla de pandas.
    return pd.read_csv(path)           # read_csv lee el archivo y retorna un DataFrame.

# Array NumPy tipado
def predict_proba(X: NDArray[np.float64]) -> NDArray[np.float64]:  # NDArray[np.float64]: array de floats 64-bit.
    return model.predict_proba(X)[:, 1]  # predict_proba retorna probabilidades. [:, 1] selecciona columna 1 (clase positiva).

# Modelo sklearn
def train_model(X: NDArray, y: NDArray) -> BaseEstimator:  # Retorna BaseEstimator: cualquier modelo sklearn.
    model = RandomForestClassifier()   # Crea instancia del modelo. RandomForest: ensemble de Ã¡rboles de decisiÃ³n.
    model.fit(X, y)                    # fit(): entrena el modelo con datos X (features) e y (target).
    return model                       # Retorna el modelo entrenado (listo para predict).

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS AVANZADOS - Para cÃ³digo mÃ¡s robusto
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from typing import TypedDict, Literal  # TypedDict: dict con estructura fija. Literal: valores especÃ­ficos.

# TypedDict: diccionarios con estructura conocida
class MetricsDict(TypedDict):          # TypedDict: define un diccionario donde cada clave tiene tipo especÃ­fico.
    accuracy: float                    # La clave "accuracy" DEBE ser float. mypy lo verifica.
    precision: float                   # Todas las mÃ©tricas de clasificaciÃ³n son floats.
    recall: float                      # recall: proporciÃ³n de positivos reales detectados.
    f1: float                          # f1: media armÃ³nica de precision y recall.
    roc_auc: float                     # roc_auc: Ã¡rea bajo la curva ROC. 1.0 = perfecto.

# Literal: solo valores especÃ­ficos permitidos
ModelType = Literal["random_forest", "logistic", "gradient_boosting"]  # Crea un "tipo alias" que solo acepta estos 3 strings.

def build_model(model_type: ModelType, seed: int) -> BaseEstimator:  # model_type SOLO puede ser uno de los 3 valores.
    """
    mypy SABE que model_type solo puede ser estos 3 valores.
    Si escribes build_model("xgboost", 42), mypy darÃ¡ error.
    """
    if model_type == "random_forest":  # Compara string. Python permite esto aunque model_type sea Literal.
        return RandomForestClassifier(random_state=seed)  # random_state: semilla para reproducibilidad.
    elif model_type == "logistic":     # elif: "else if" - solo se evalÃºa si el if anterior fue False.
        return LogisticRegression(random_state=seed)      # LogisticRegression: modelo lineal para clasificaciÃ³n.
    else:  # gradient_boosting         # else: se ejecuta si ningÃºn if/elif fue True.
        return GradientBoostingClassifier(random_state=seed)  # GradientBoosting: ensemble de Ã¡rboles secuenciales.
```

### Configurar mypy

AÃ±ade esto a tu `pyproject.toml`:

```toml
# pyproject.toml - ConfiguraciÃ³n de mypy
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true      # â† Fuerza tipos en todas las funciones
ignore_missing_imports = true     # â† Para librerÃ­as sin stubs

# Ignorar librerÃ­as de ML que no tienen stubs completos
[[tool.mypy.overrides]]
module = [
    "sklearn.*",
    "pandas.*", 
    "numpy.*",
    "mlflow.*",
    "joblib.*",
]
ignore_missing_imports = true
```

Ejecutar:
```bash
mypy src/  # Verifica tipos en todo el cÃ³digo
```

---

<a id="12-pydantic-validation-automatica"></a>

## 1.2 Pydantic: ValidaciÃ³n AutomÃ¡tica

### La AnalogÃ­a del Guardia de Seguridad

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ›¡ï¸ IMAGINA UN EDIFICIO DE OFICINAS:                                      â•‘
â•‘                                                                           â•‘
â•‘  SIN GUARDIA (cÃ³digo sin Pydantic):                                       â•‘
â•‘  - Cualquiera entra con cualquier cosa                                    â•‘
â•‘  - Descubres problemas CUANDO YA PASARON                                  â•‘
â•‘  - "Â¿Por quÃ© hay un test_size de 1.5?" â†’ Error en producciÃ³n              â•‘
â•‘                                                                           â•‘
â•‘  CON GUARDIA (cÃ³digo con Pydantic):                                       â•‘
â•‘  - Verifica credenciales EN LA ENTRADA                                    â•‘
â•‘  - Problemas detectados ANTES de causar daÃ±o                              â•‘
â•‘  - "test_size debe ser entre 0 y 1" â†’ Error inmediato y claro             â•‘
â•‘                                                                           â•‘
â•‘  PYDANTIC = El guardia de tu configuraciÃ³n                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### CÃ³digo Real: BankChurn Config (Nivel Staff)

Este es el archivo `src/bankchurn/config.py` del portafolio:

```python
"""Configuration management for BankChurn predictor.

Este mÃ³dulo demuestra Pydantic a nivel profesional:
- ValidaciÃ³n de rangos con Field
- Configuraciones anidadas
- Valores por defecto sensatos
- Carga desde YAML
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, List

import yaml
from pydantic import BaseModel, Field


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIONES ANIDADAS - Cada componente tiene su propia config
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LogisticRegressionConfig(BaseModel):
    """HiperparÃ¡metros de Logistic Regression."""
    C: float = 0.1
    class_weight: str = "balanced"
    solver: str = "liblinear"
    max_iter: int = 1000


class RandomForestConfig(BaseModel):
    """HiperparÃ¡metros de Random Forest."""
    n_estimators: int = 100
    max_depth: int = 10
    min_samples_split: int = 10
    min_samples_leaf: int = 5
    class_weight: str = "balanced_subsample"
    n_jobs: int = -1


class EnsembleConfig(BaseModel):
    """ConfiguraciÃ³n del ensemble."""
    voting: str = Field("soft", pattern="^(hard|soft)$")  # â† Solo permite "hard" o "soft"
    weights: List[float] = [0.4, 0.6]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N PRINCIPAL - Agrupa todo con validaciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ModelConfig(BaseModel):
    """ConfiguraciÃ³n de entrenamiento del modelo."""
    type: str = "ensemble"
    test_size: float = Field(0.2, ge=0.0, le=1.0)   # â† VALIDACIÃ“N: entre 0 y 1
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)                   # â† VALIDACIÃ“N: mÃ­nimo 2
    resampling_strategy: str = "none"
    
    # Configuraciones de modelos especÃ­ficos (anidadas)
    ensemble: EnsembleConfig = EnsembleConfig()
    logistic_regression: LogisticRegressionConfig = LogisticRegressionConfig()
    random_forest: RandomForestConfig = RandomForestConfig()


class DataConfig(BaseModel):
    """ConfiguraciÃ³n de datos."""
    target_column: str = "Exited"
    categorical_features: List[str] = []
    numerical_features: List[str] = []
    drop_columns: List[str] = []


class MLflowConfig(BaseModel):
    """ConfiguraciÃ³n de MLflow tracking."""
    tracking_uri: str = "file:./mlruns"
    experiment_name: str = "bankchurn"
    enabled: bool = True


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N RAÃZ - El punto de entrada
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BankChurnConfig(BaseModel):
    """ConfiguraciÃ³n completa de BankChurn.
    
    Uso:
        config = BankChurnConfig.from_yaml("configs/config.yaml")
        print(config.model.test_size)  # 0.2
    """
    model: ModelConfig
    data: DataConfig
    mlflow: MLflowConfig

    @classmethod
    def from_yaml(cls, config_path: str | Path) -> BankChurnConfig:
        """Carga configuraciÃ³n desde archivo YAML.
        
        Parameters
        ----------
        config_path : str or Path
            Ruta al archivo YAML.
            
        Returns
        -------
        BankChurnConfig
            ConfiguraciÃ³n validada.
            
        Raises
        ------
        FileNotFoundError
            Si el archivo no existe.
        ValidationError
            Si la configuraciÃ³n es invÃ¡lida.
        """
        config_path = Path(config_path)
        
        if not config_path.exists():
            raise FileNotFoundError(f"Config file not found: {config_path}")
        
        with open(config_path, "r") as f:
            config_dict = yaml.safe_load(f) or {}
        
        # Valores por defecto para secciones faltantes
        if "model" not in config_dict:
            config_dict["model"] = ModelConfig().dict()
        if "data" not in config_dict:
            config_dict["data"] = DataConfig().dict()
        if "mlflow" not in config_dict:
            config_dict["mlflow"] = MLflowConfig().dict()
        
        return cls(**config_dict)  # â† Pydantic valida automÃ¡ticamente
```

### El YAML Correspondiente

```yaml
# configs/config.yaml
model:
  type: ensemble
  test_size: 0.2         # Si pones 1.5, Pydantic darÃ¡ error
  random_state: 42
  cv_folds: 5            # Si pones 1, Pydantic darÃ¡ error
  resampling_strategy: none
  
  ensemble:
    voting: soft         # Si pones "maybe", Pydantic darÃ¡ error
    weights: [0.4, 0.6]
    
  random_forest:
    n_estimators: 200
    max_depth: 10

data:
  target_column: Exited
  categorical_features:
    - Geography
    - Gender
  numerical_features:
    - CreditScore
    - Age
    - Balance
  drop_columns:
    - RowNumber
    - CustomerId
    - Surname

mlflow:
  tracking_uri: "file:./mlruns"
  experiment_name: bankchurn
  enabled: true
```

### Ejemplo de Error de ValidaciÃ³n

```python
# âŒ Esto FALLA inmediatamente con un error claro

config_dict = {
    "model": {
        "test_size": 1.5,  # â† Error: debe ser <= 1.0
        "cv_folds": 1,     # â† Error: debe ser >= 2
    },
    "data": {},
    "mlflow": {}
}

try:
    config = BankChurnConfig(**config_dict)
except ValidationError as e:
    print(e)
    # Output:
    # 2 validation errors for BankChurnConfig
    # model -> test_size
    #   ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
    # model -> cv_folds
    #   ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)
```

---

<a id="13-src-layout-estructura-profesional"></a>

## 1.3 src/ Layout: Estructura Profesional

### La AnalogÃ­a de la Casa

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ  IMAGINA ORGANIZAR UNA CASA:                                           â•‘
â•‘                                                                           â•‘
â•‘  CASA DESORDENADA (cÃ³digo en raÃ­z):                                       â•‘
â•‘  - Todo en el living: ropa, comida, herramientas                          â•‘
â•‘  - Imposible encontrar algo                                               â•‘
â•‘  - Invitas a alguien: "perdÃ³n por el desorden"                            â•‘
â•‘                                                                           â•‘
â•‘  CASA ORGANIZADA (src/ layout):                                           â•‘
â•‘  - Cocina para cocinar, baÃ±o para baÃ±o, closet para ropa                  â•‘
â•‘  - Cada cosa en su lugar                                                  â•‘
â•‘  - Invitas a alguien: "bienvenido, siÃ©ntate"                              â•‘
â•‘                                                                           â•‘
â•‘  src/ layout = OrganizaciÃ³n profesional de cÃ³digo                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Estructura del Portafolio

```
BankChurn-Predictor/
â”œâ”€â”€ src/                          # â† TODO el cÃ³digo fuente aquÃ­
â”‚   â”œâ”€â”€ __init__.py               # Hace src/ un paquete
â”‚   â””â”€â”€ bankchurn/                # â† El paquete principal
â”‚       â”œâ”€â”€ __init__.py           # Exporta la API pÃºblica
â”‚       â”œâ”€â”€ config.py             # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ training.py           # Pipeline de entrenamiento
â”‚       â”œâ”€â”€ evaluation.py         # MÃ©tricas y evaluaciÃ³n
â”‚       â”œâ”€â”€ prediction.py         # Inferencia
â”‚       â”œâ”€â”€ models.py             # Custom classifiers
â”‚       â””â”€â”€ cli.py                # Interfaz de lÃ­nea de comandos
â”‚
â”œâ”€â”€ app/                          # â† Aplicaciones (no es un paquete)
â”‚   â””â”€â”€ fastapi_app.py            # API REST
â”‚
â”œâ”€â”€ tests/                        # â† Tests (espejo de src/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidas
â”‚   â”œâ”€â”€ test_config.py            # Tests para config.py
â”‚   â”œâ”€â”€ test_training.py          # Tests para training.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ configs/                      # â† ConfiguraciÃ³n externa
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/                         # â† Datos (gitignored)
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ Churn_Modelling.csv
â”‚
â”œâ”€â”€ artifacts/                    # â† Artefactos generados (gitignored)
â”‚   â”œâ”€â”€ model.joblib
â”‚   â””â”€â”€ training_results.json
â”‚
â”œâ”€â”€ pyproject.toml                # â† Metadata del proyecto
â”œâ”€â”€ Makefile                      # â† Comandos comunes
â”œâ”€â”€ Dockerfile                    # â† ContainerizaciÃ³n
â””â”€â”€ README.md                     # â† DocumentaciÃ³n
```

### Â¿Por quÃ© src/ y no cÃ³digo en la raÃ­z?

```python
# âŒ PROBLEMA: Sin src/, Python puede importar cÃ³digo no instalado
# Esto causa el famoso "funciona en mi mÃ¡quina pero no en CI"

# Estructura plana (problemÃ¡tica):
# myproject/
# â”œâ”€â”€ mymodule.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
import mymodule  # â† Â¿De dÃ³nde viene? Â¿Del directorio actual? Â¿De pip?

# âœ… SOLUCIÃ“N: Con src/, el cÃ³digo DEBE estar instalado para importar
# myproject/
# â”œâ”€â”€ src/
# â”‚   â””â”€â”€ mymodule/
# â”‚       â””â”€â”€ __init__.py
# â””â”€â”€ tests/
#     â””â”€â”€ test_mymodule.py

# En test_mymodule.py:
from mymodule import something  # â† Solo funciona si `pip install -e .`
```

### pyproject.toml: El CorazÃ³n del Proyecto

```toml
# pyproject.toml - ConfiguraciÃ³n completa del proyecto
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "bankchurn"
version = "1.0.0"
description = "Bank Customer Churn Prediction System"
authors = [
    {name = "Daniel Duque", email = "duque@example.com"}
]
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}

dependencies = [
    "pandas>=2.0.0",
    "scikit-learn>=1.3.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "mlflow>=2.9.0",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "black>=23.0.0",
    "mypy>=1.7.0",
    "ruff>=0.1.0",
]

[project.scripts]
bankchurn = "bankchurn.cli:main"  # â† Comando CLI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HERRAMIENTAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[tool.setuptools.packages.find]
where = ["src"]  # â† Busca paquetes en src/

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=src/bankchurn --cov-report=term-missing"

[tool.coverage.run]
source = ["src"]
omit = ["tests/*"]

[tool.coverage.report]
fail_under = 79  # â† Coverage mÃ­nimo para pasar CI

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
disallow_untyped_defs = true
ignore_missing_imports = true
```

### InstalaciÃ³n en Modo Editable

```bash
# Instalar el paquete en modo editable (para desarrollo)
pip install -e .

# Ahora puedes importar desde cualquier lugar
python -c "from bankchurn.config import BankChurnConfig; print('âœ… Funciona!')"

# Y los tests tambiÃ©n funcionan
pytest tests/
```

---

<a id="14-principios-solid-para-ml"></a>

## 1.4 Principios SOLID para ML

### Single Responsibility: Un MÃ³dulo, Una Tarea

```python
# âŒ ANTES: Un archivo hace TODO
# training.py (500 lÃ­neas)
def train_model(data_path, config_path, output_path):
    # Carga datos (lÃ­neas 1-50)
    # Limpia datos (lÃ­neas 51-100)
    # Feature engineering (lÃ­neas 101-200)
    # Entrena modelo (lÃ­neas 201-300)
    # EvalÃºa modelo (lÃ­neas 301-400)
    # Guarda artefactos (lÃ­neas 401-450)
    # Loguea a MLflow (lÃ­neas 451-500)
    pass

# âœ… DESPUÃ‰S: Cada archivo tiene UNA responsabilidad
# src/bankchurn/
# â”œâ”€â”€ data.py         â†’ Solo carga y valida datos
# â”œâ”€â”€ features.py     â†’ Solo feature engineering
# â”œâ”€â”€ training.py     â†’ Solo entrenamiento
# â”œâ”€â”€ evaluation.py   â†’ Solo mÃ©tricas
# â””â”€â”€ prediction.py   â†’ Solo inferencia
```

### CÃ³digo Real del Portafolio

```python
# src/bankchurn/training.py - SOLO se encarga de entrenar
class ChurnTrainer:
    """Training pipeline - Single Responsibility."""
    
    def __init__(self, config: BankChurnConfig):
        self.config = config
    
    def load_data(self, path: Path) -> pd.DataFrame:
        """Delega a mÃ³dulo de datos."""
        pass
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """Prepara X e y."""
        pass
    
    def build_pipeline(self) -> Pipeline:
        """Construye el pipeline sklearn."""
        pass
    
    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:
        """Entrena el modelo."""
        pass
    
    def cross_validate(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """Valida con CV."""
        pass

# src/bankchurn/evaluation.py - SOLO se encarga de evaluar
def evaluate_model(
    model: Pipeline,
    X_test: pd.DataFrame,
    y_test: pd.Series
) -> Dict[str, float]:
    """Calcula mÃ©tricas - Single Responsibility."""
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]
    
    return {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred),
        "recall": recall_score(y_test, y_pred),
        "f1": f1_score(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, y_proba),
    }
```

---

<a id="15-oop-para-ml"></a>

## 1.5 OOP para ML: Protocolos y Clases Abstractas

> **CRÃTICO**: Sin entender OOP profesional, NO podrÃ¡s leer el cÃ³digo del Portafolio.

### El Problema: CÃ³digo No Intercambiable

```python
# âŒ CÃ“DIGO JUNIOR: Cada trainer tiene API diferente
class TrainerA:
    def entrenar(self, X, y): ...  # espaÃ±ol
    def predecir(self, X): ...

class TrainerB:
    def fit_model(self, features, labels): ...  # nombres diferentes
    def get_predictions(self, features): ...

# Â¿CÃ³mo escribo cÃ³digo genÃ©rico que funcione con ambos?
# Imposible sin reescribir todo.
```

### La SoluciÃ³n: Protocol y ABC

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROTOCOL: Duck Typing verificable por mypy (para sklearn y librerÃ­as externas)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from typing import Protocol, runtime_checkable
from numpy.typing import ArrayLike

@runtime_checkable
class Predictor(Protocol):
    """Si tiene fit() y predict() con estas firmas, ES un Predictor."""
    
    def fit(self, X: ArrayLike, y: ArrayLike) -> "Predictor": ...
    def predict(self, X: ArrayLike) -> ArrayLike: ...

# sklearn cumple automÃ¡ticamente sin modificar nada:
from sklearn.ensemble import RandomForestClassifier
assert isinstance(RandomForestClassifier(), Predictor)  # True!


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ABC: Contrato que OBLIGA implementaciÃ³n (para TUS clases)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from abc import ABC, abstractmethod
import pandas as pd

class BaseTrainer(ABC):
    """Clase base para todos los trainers del portafolio.
    
    BankChurn, CarVision y TelecomAI DEBEN implementar estos mÃ©todos.
    Si no lo hacen, Python da error al instanciar.
    """
    
    @abstractmethod
    def fit(self, X: pd.DataFrame, y: pd.Series) -> "BaseTrainer":
        """Entrena el modelo."""
        pass
    
    @abstractmethod
    def predict(self, X: pd.DataFrame) -> pd.Series:
        """Genera predicciones."""
        pass
    
    @abstractmethod
    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> dict[str, float]:
        """EvalÃºa el modelo."""
        pass
    
    # MÃ©todo concreto que usa los abstractos
    def fit_and_evaluate(
        self, 
        X_train: pd.DataFrame, y_train: pd.Series,
        X_test: pd.DataFrame, y_test: pd.Series
    ) -> dict[str, float]:
        """Entrena y evalÃºa en un paso."""
        self.fit(X_train, y_train)
        return self.evaluate(X_test, y_test)


# ImplementaciÃ³n concreta:
class ChurnTrainer(BaseTrainer):
    """Trainer de BankChurn - DEBE implementar fit, predict, evaluate."""
    
    def fit(self, X: pd.DataFrame, y: pd.Series) -> "ChurnTrainer":
        self._pipeline = self._build_pipeline()
        self._pipeline.fit(X, y)
        return self
    
    def predict(self, X: pd.DataFrame) -> pd.Series:
        return pd.Series(self._pipeline.predict(X))
    
    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> dict[str, float]:
        y_pred = self.predict(X)
        return {"accuracy": accuracy_score(y, y_pred)}
```

### Puente al Portafolio

Crear `common_utils/base.py` con `BaseTrainer` para que los 3 proyectos compartan la misma interfaz.

---

<a id="16-pandera-validacion-dataframes"></a>

## 1.6 Pandera: ValidaciÃ³n de DataFrames

> **CRÃTICO**: Sin Pandera, los errores de datos aparecen en sklearn, no donde ocurrieron.

### El Problema: DataFrames que Mienten

```python
# âŒ CÃ“DIGO JUNIOR: Asume que el DataFrame es correcto
def train_model(df: pd.DataFrame) -> Pipeline:
    X = df.drop("Exited", axis=1)  # Â¿Y si "Exited" no existe?
    y = df["Exited"]               # Â¿Y si tiene valores como 2, -1, None?
    
    pipeline.fit(X, y)
    return pipeline

# Todo parece funcionar... hasta que llegan datos corruptos:
bad_data = pd.DataFrame({
    "Age": [-5, 25, 200],        # Edad negativa y 200 aÃ±os
    "Balance": [1000, -500, 0],  # Balance negativo
    "Exited": [0, 2, None],      # Valor 2 y None (no binario)
})
model = train_model(bad_data)  # NO DA ERROR, pero modelo es basura
```

### La SoluciÃ³n: Pandera Schema

```python
import pandera as pa
from pandera.typing import DataFrame, Series

class BankChurnSchema(pa.DataFrameModel):
    """Schema para datos de Bank Churn - producciÃ³n."""
    
    CreditScore: Series[int] = pa.Field(ge=300, le=850, description="FICO score")
    Age: Series[int] = pa.Field(ge=18, le=100, description="Edad del cliente")
    Balance: Series[float] = pa.Field(ge=0, description="Balance en cuenta")
    NumOfProducts: Series[int] = pa.Field(ge=1, le=4)
    Exited: Series[int] = pa.Field(isin=[0, 1], description="Target binario")
    
    class Config:
        strict = True   # Rechaza columnas extra
        coerce = True   # Convierte tipos automÃ¡ticamente


@pa.check_types  # Decorador que valida entrada automÃ¡ticamente
def train_model(df: DataFrame[BankChurnSchema]) -> Pipeline:
    """DataFrame GARANTIZADO vÃ¡lido por Pandera."""
    X = df.drop("Exited", axis=1)
    y = df["Exited"]
    # Ahora podemos confiar en que los datos son correctos
    ...


# Error CLARO si datos son invÃ¡lidos:
# SchemaError: Column 'Age' failed check: greater_than_or_equal_to(18)
```

### Schemas del Portafolio

```python
# src/bankchurn/schemas.py

class RawDataSchema(pa.DataFrameModel):
    """Schema permisivo para datos crudos (permite nulos)."""
    CreditScore: Series[float] = pa.Field(nullable=True)
    Age: Series[float] = pa.Field(nullable=True, ge=0)
    class Config:
        strict = False  # Permite columnas extra (RowNumber, etc.)


class ProcessedDataSchema(pa.DataFrameModel):
    """Schema estricto para datos listos para entrenar."""
    CreditScore: Series[int] = pa.Field(ge=300, le=850)
    Age: Series[int] = pa.Field(ge=18, le=100)
    Exited: Series[int] = pa.Field(isin=[0, 1])
    class Config:
        strict = True  # No permite columnas extra


@pa.check_types
def preprocess(raw: DataFrame[RawDataSchema]) -> DataFrame[ProcessedDataSchema]:
    """Pipeline validado: entrada permisiva, salida estricta."""
    df = raw.dropna()
    df = df.drop(columns=["RowNumber", "CustomerId", "Surname"])
    return df
```

---

<a id="17-ejercicios-practicos"></a>

## 1.7 Ejercicios PrÃ¡cticos

### Ejercicio 1: AÃ±adir Type Hints

```python
# âŒ CÃ³digo sin tipos (tÃ­pico de notebook)
# Tu tarea: AÃ±ade type hints completos

def process_training_data(df, config):
    target = config["target"]
    features = config["features"]
    
    X = df[features]
    y = df[target]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.get("test_size", 0.2)
    )
    
    return X_train, X_test, y_train, y_test


def calculate_metrics(y_true, y_pred):
    return {
        "accuracy": accuracy_score(y_true, y_pred),
        "f1": f1_score(y_true, y_pred)
    }
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```python
from typing import Dict, List, Tuple, Any
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score


def process_training_data(
    df: pd.DataFrame,
    config: Dict[str, Any]
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """Procesa datos para entrenamiento.
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame con datos crudos.
    config : Dict[str, Any]
        ConfiguraciÃ³n con keys: "target", "features", "test_size" (opcional).
    
    Returns
    -------
    Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]
        X_train, X_test, y_train, y_test
    """
    target: str = config["target"]
    features: List[str] = config["features"]
    
    X: pd.DataFrame = df[features]
    y: pd.Series = df[target]
    
    test_size: float = config.get("test_size", 0.2)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    return X_train, X_test, y_train, y_test


def calculate_metrics(
    y_true: pd.Series,
    y_pred: pd.Series
) -> Dict[str, float]:
    """Calcula mÃ©tricas de clasificaciÃ³n.
    
    Parameters
    ----------
    y_true : pd.Series
        Labels verdaderos.
    y_pred : pd.Series
        Predicciones del modelo.
    
    Returns
    -------
    Dict[str, float]
        Diccionario con accuracy y f1.
    """
    return {
        "accuracy": float(accuracy_score(y_true, y_pred)),
        "f1": float(f1_score(y_true, y_pred))
    }
```

</details>

---

### Ejercicio 2: Crear Config con Pydantic

```python
# Tu tarea: Crea una configuraciÃ³n Pydantic para TelecomAI
# Requisitos:
# - project_name: str
# - random_seed: int (entre 0 y 1000)
# - test_size: float (entre 0.1 y 0.5)
# - model_type: solo puede ser "logreg", "random_forest", o "gradient_boosting"
# - features: lista de strings
# - target: str

# Escribe tu cÃ³digo aquÃ­:
from pydantic import BaseModel, Field
from typing import List, Literal

class TelecomConfig(BaseModel):
    # ... tu cÃ³digo
    pass
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```python
from pydantic import BaseModel, Field
from typing import List, Literal, Optional, Dict, Any
from pathlib import Path
import yaml


class TelecomConfig(BaseModel):
    """ConfiguraciÃ³n para TelecomAI Customer Intelligence."""
    
    project_name: str = Field(..., min_length=1)
    random_seed: int = Field(42, ge=0, le=1000)
    test_size: float = Field(0.2, ge=0.1, le=0.5)
    model_type: Literal["logreg", "random_forest", "gradient_boosting"] = "logreg"
    features: List[str] = Field(..., min_items=1)
    target: str
    
    # Opcionales
    threshold: float = Field(0.5, ge=0.0, le=1.0)
    mlflow_enabled: bool = True
    
    @classmethod
    def from_yaml(cls, path: str | Path) -> "TelecomConfig":
        with open(path) as f:
            data = yaml.safe_load(f)
        return cls(**data)
    
    class Config:
        extra = "forbid"  # No permite campos extra en el YAML


# Uso:
config = TelecomConfig(
    project_name="TelecomAI",
    features=["calls", "minutes", "messages", "mb_used"],
    target="is_ultra"
)

# Esto FALLA:
# config = TelecomConfig(
#     project_name="",  # Error: min_length=1
#     test_size=0.8,    # Error: le=0.5
#     model_type="xgboost",  # Error: not in Literal
#     features=[],      # Error: min_items=1
# )
```

</details>

---

### Ejercicio 3: Convertir a src/ Layout

```
Tu tarea: Reorganiza esta estructura plana a src/ layout

ANTES:
myproject/
â”œâ”€â”€ train.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ data.csv
â””â”€â”€ test_train.py

DESPUÃ‰S:
myproject/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ ???
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ???
â””â”€â”€ pyproject.toml
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```
myproject/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ myproject/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ training.py      # Antes: train.py
â”‚       â”œâ”€â”€ prediction.py    # Antes: predict.py
â”‚       â””â”€â”€ utils.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Fixtures compartidas
â”‚   â””â”€â”€ test_training.py     # Antes: test_train.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ data.csv
â”œâ”€â”€ artifacts/               # Para modelos generados
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

 </details>

---

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos

En este mÃ³dulo suelen aparecer siempre los mismos problemas. La idea no es solo evitarlos, sino **saber reconocerlos rÃ¡pido** en tus propios proyectos.

Si alguno de estos errores te tomÃ³ **>15 minutos**, regÃ­stralo en el **[Diario de Errores](study_tools/DIARIO_ERRORES.md)** y aplica el flujo de **rescate cognitivo** de **[Protocolo E](study_tools/PROTOCOLO_E.md)**.

### 1) Type hints + mypy: errores ruidosos en pandas/sklearn

**SÃ­ntomas tÃ­picos**

- `Function is missing a type annotation for parameter 'df'`
- `Incompatible return value type (got "DataFrame", expected "Series")`
- Cientos de warnings en librerÃ­as externas (`pandas.*`, `sklearn.*`).
**Proceso para identificarlos**

- Ejecuta siempre:
  ```bash
  mypy src/  # o mypy src/bankchurn src/carvision src/telecomai
  ```
- Localiza primero los errores **en tu cÃ³digo** (archivos dentro de `src/`), ignora de momento los de librerÃ­as.
- Si ves muchos errores en `site-packages` o mÃ³dulos externos, revisa tu secciÃ³n `[tool.mypy]` del `pyproject.toml` (ver ejemplo en este mismo mÃ³dulo).

**CÃ³mo solucionarlos (patrÃ³n general)**

- AÃ±ade tipos a **todas las firmas pÃºblicas** (funciones/clases usadas fuera de su archivo).
- Usa tipos especÃ­ficos para ML:
  - `pd.DataFrame`, `pd.Series`
  - `NDArray[np.float64]`
  - `BaseEstimator`, `Pipeline`
- AÃ­sla tipos muy complejos usando `TypedDict` o `Alias`:
  ```python
  class MetricsDict(TypedDict):
      accuracy: float
      f1: float
      roc_auc: float
  ```
- Para **reducir ruido de mypy** con librerÃ­as ML:
  - Configura `ignore_missing_imports = true` y los overrides mostrados en este mÃ³dulo.
  - Re-lanza `mypy` y verifica que solo quedan errores en tu cÃ³digo.

> ğŸ’¡ **Regla prÃ¡ctica**: si mypy empieza a gritar en medio de un refactor, reduce el problema a una funciÃ³n pequeÃ±a, tipa bien esa funciÃ³n, y despuÃ©s propaga los tipos al resto.

---

### 2) Pydantic: `ValidationError` por config mal definida

**SÃ­ntomas tÃ­picos**

- Al cargar la configuraciÃ³n:
  ```text
  pydantic.error_wrappers.ValidationError: 2 validation errors for ModelConfig
  model -> test_size
    ensure this value is less than or equal to 1.0 (type=value_error.number.not_le)
  model -> cv_folds
    ensure this value is greater than or equal to 2 (type=value_error.number.not_ge)
  ```
- Tu servicio/API no arranca porque falla la lectura de `config.yaml`.

**Proceso para identificarlos**

- Localiza **quÃ© modelo Pydantic** estÃ¡ fallando (`ModelConfig`, `BankChurnConfig`, `TelecomConfig`, etc.).
- Revisa el `traceback`: casi siempre indica **la ruta completa del campo** (`model -> test_size`, `data -> categorical_features`, etc.).
- Abre el YAML correspondiente (`configs/config.yaml`) y compara **valor real** vs **restricciÃ³n en `Field(...)`**.

**CÃ³mo solucionarlos (patrÃ³n general)**

- Ajusta el YAML para respetar los rangos:
  - `test_size` entre `0.0` y `1.0`.
  - `cv_folds` â‰¥ 2.
  - Literales vÃ¡lidos (`voting: "hard" | "soft"`, `model_type: "logreg" | "random_forest" | ...`).
- Si el error te parece injustificado, revisa la declaraciÃ³n del modelo:
  ```python
  test_size: float = Field(0.2, ge=0.0, le=1.0)
  ```
  QuizÃ¡ necesitas permitir un rango distinto en tu contexto.
- En desarrollo, **falla rÃ¡pido**: no atrapes el `ValidationError` salvo para mostrar un mensaje mÃ¡s amigable; deja que la app se caiga antes que usar una config corrupta.

> ğŸ”§ **Ejercicio mental**: rompe a propÃ³sito tu `configs/config.yaml` (pon `test_size: 1.5`) y observa el error. Luego arrÃ©glalo. Hazlo una vez y nunca mÃ¡s te asustarÃ¡ un `ValidationError` en producciÃ³n.

---

### 3) src/ layout e imports: `ModuleNotFoundError` en CI pero no en tu mÃ¡quina

**SÃ­ntomas tÃ­picos**

- En local â€œtodo funcionaâ€, pero en GitHub Actions o en otra mÃ¡quina obtienes:
  ```text
  ModuleNotFoundError: No module named 'bankchurn'
  ```
- Los tests solo pasan si ejecutas `pytest` desde la raÃ­z exacta del proyecto.

**Proceso para identificarlos**

- Revisa la **estructura** de tu proyecto (deberÃ­a parecerse al diagrama de este mÃ³dulo):
  - CÃ³digo dentro de `src/<paquete>/`.
  - Tests bajo `tests/` usando imports del paquete, no rutas relativas raras.
- Verifica tu `pyproject.toml`:
  - `[project.name]` coincide con el paquete (`bankchurn`, `carvision`, `telecomai`).
  - `[tool.setuptools.packages.find] where = ["src"]`.
- Comprueba si instalaste en modo editable:
  ```bash
  pip install -e .
  python -c "import bankchurn; print(bankchurn.__file__)"
  ```

**CÃ³mo solucionarlos (patrÃ³n general)**

- Mueve el cÃ³digo de raÃ­z a `src/` siguiendo el ejemplo de este mÃ³dulo.
- Cambia imports tipo:
  ```python
  # âŒ from .training import train_model  (desde scripts sueltos)
  # âœ… from bankchurn.training import train_model
  ```
- AsegÃºrate de que los comandos de CI usan instalaciÃ³n editable:
  ```yaml
  - name: Install
    run: pip install -e ".[dev]"
  ```

> âš ï¸ **Bandera roja**: si tus tests solo funcionan cuando haces `cd src` o ajustas manualmente `PYTHONPATH`, tu layout todavÃ­a no estÃ¡ bien resuelto.

---

### 4) PatrÃ³n general de debugging para este mÃ³dulo

1. **Reproduce el error** con un comando simple y determinista:
   - `mypy src/`
   - `python -m src.proyecto.training`
   - `pytest -k nombre_test`.
2. **Lee literalmente** el mensaje de error (campo, valor, restricciÃ³n).
3. **Conecta el error con el concepto del mÃ³dulo**:
   - Type hints â†’ firma de funciÃ³n o tipo de retorno.
   - Pydantic â†’ `Field(...)` y YAML.
   - src/ layout â†’ estructura de carpetas + `pyproject.toml` + instalaciÃ³n editable.
4. **Aplica el patrÃ³n de soluciÃ³n** que viste arriba.

Si automatizas este ciclo en tus tres proyectos del portafolio, tu tiempo de debugging se reduce drÃ¡sticamente y es justo lo que se espera de un perfil Senior/Staff.

---

## âœ… Checkpoint: Â¿Completaste el MÃ³dulo?

Antes de continuar, verifica:

- [ ] Tu cÃ³digo tiene type hints en todas las funciones
- [ ] Puedes ejecutar `mypy src/` sin errores crÃ­ticos
- [ ] Tienes al menos una clase Pydantic para configuraciÃ³n
- [ ] Tu proyecto tiene estructura src/ layout
- [ ] Puedes instalar tu paquete con `pip install -e .`

---

## ğŸ”— ADR: Â¿Por QuÃ© Estas Decisiones?

### ADR-001: Type Hints Obligatorios

**Contexto**: El cÃ³digo de ML suele ser difÃ­cil de mantener porque las funciones aceptan "cualquier cosa".

**DecisiÃ³n**: Requerimos type hints en todas las funciones pÃºblicas.

**Consecuencias**:
- âœ… El IDE autocompleta correctamente
- âœ… Errores detectados antes de ejecutar
- âœ… DocumentaciÃ³n implÃ­cita
- âŒ MÃ¡s cÃ³digo que escribir inicialmente
- âŒ Curva de aprendizaje para tipos complejos

### ADR-002: Pydantic para ConfiguraciÃ³n

**Contexto**: Configuraciones en diccionarios son propensas a errores.

**DecisiÃ³n**: Toda configuraciÃ³n pasa por Pydantic.

**Consecuencias**:
- âœ… ValidaciÃ³n automÃ¡tica
- âœ… Errores claros
- âœ… DocumentaciÃ³n de la config
- âŒ Dependencia adicional
- âŒ MÃ¡s verboso que un dict simple

### ADR-003: src/ Layout

**Contexto**: CÃ³digo en raÃ­z causa problemas de importaciÃ³n.

**DecisiÃ³n**: Todo cÃ³digo en `src/<paquete>/`.

**Consecuencias**:
- âœ… Importaciones consistentes
- âœ… Funciona igual en desarrollo y CI
- âœ… EstÃ¡ndar de la industria
- âŒ Requiere `pip install -e .`
- âŒ Path mÃ¡s largo para imports

---

## ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio

Este mÃ³dulo se aplica **directamente** en los 3 proyectos del portafolio. AquÃ­ estÃ¡n los archivos reales que implementan cada concepto:

### Type Hints en el Portafolio

```python
# BankChurn-Predictor/src/bankchurn/config.py (lÃ­neas 89-109)
@classmethod
def from_yaml(cls, config_path: str | Path) -> BankChurnConfig:
    """Load configuration from YAML file.
    
    Parameters
    ----------
    config_path : str or Path
        Path to YAML configuration file.
    
    Returns
    -------
    config : BankChurnConfig
        Validated configuration object.
    """
```

### Pydantic en el Portafolio

Cada proyecto tiene su configuraciÃ³n Pydantic:

| Proyecto | Archivo | Clases principales |
|----------|---------|-------------------|
| BankChurn | `src/bankchurn/config.py` | `BankChurnConfig`, `ModelConfig`, `DataConfig` |
| CarVision | `src/carvision/config.py` | `CarVisionConfig`, `FiltersConfig` |
| TelecomAI | `src/telecomai/config.py` | `TelecomConfig` |

```python
# Ejemplo real: BankChurn-Predictor/src/bankchurn/config.py
class ModelConfig(BaseModel):
    """Model training configuration."""
    type: str = "ensemble"
    test_size: float = Field(0.2, ge=0.0, le=1.0)  # â† ValidaciÃ³n automÃ¡tica
    random_state: int = 42
    cv_folds: int = Field(5, ge=2)  # â† MÃ­nimo 2 folds
```

### src/ Layout en el Portafolio

Los 3 proyectos siguen exactamente la estructura descrita:

```
BankChurn-Predictor/
â”œâ”€â”€ src/bankchurn/       â† Paquete instalable
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py        â† Pydantic configs
â”‚   â”œâ”€â”€ pipeline.py      â† sklearn Pipeline
â”‚   â””â”€â”€ trainer.py       â† Clase de entrenamiento
â”œâ”€â”€ pyproject.toml       â† Metadata y dependencias
â””â”€â”€ setup.py             â† Fallback para pip install -e .
```

### ğŸ”§ Ejercicio: Verifica en el Repo Real

```bash
# 1. Ve al proyecto BankChurn
cd BankChurn-Predictor

# 2. Instala en modo editable
pip install -e ".[dev]"

# 3. Verifica tipos con mypy
mypy src/bankchurn/config.py

# 4. Prueba que Pydantic valida correctamente
python -c "from bankchurn.config import BankChurnConfig; print(BankChurnConfig.from_yaml('configs/config.yaml'))"
```

---

## ğŸ’¼ Consejos Profesionales

> **Recomendaciones para destacar en entrevistas y proyectos reales**

### Para Entrevistas

1. **Domina Type Hints**: Los entrevistadores valoran cÃ³digo tipado. Practica explicar por quÃ© `def process(data: pd.DataFrame) -> Dict[str, float]` es mejor que `def process(data)`.

2. **Conoce Pydantic vs Dataclasses**: Pregunta comÃºn: "Â¿CuÃ¡ndo usarÃ­as uno u otro?" Respuesta: Pydantic para validaciÃ³n de datos externos (APIs, configs), dataclasses para estructuras internas simples.

3. **Demuestra comprensiÃ³n de `__init__.py`**: Explica cÃ³mo controla la API pÃºblica de un paquete y por quÃ© `from package import *` es peligroso.

### Para Proyectos Reales

| SituaciÃ³n | Consejo |
|-----------|---------|
| CÃ³digo legacy sin tipos | AÃ±ade tipos gradualmente, empezando por funciones pÃºblicas |
| ValidaciÃ³n de configs | Usa Pydantic con `model_validator` para validaciones cruzadas |
| Logs en producciÃ³n | Usa `structlog` o `loguru` en lugar de `print()` |
| Errores en producciÃ³n | Implementa excepciones personalizadas con contexto Ãºtil |

### Anti-patrones a Evitar

- âŒ `from typing import *` â€” importa solo lo que necesitas
- âŒ `except Exception:` sin logging â€” siempre registra el error
- âŒ Funciones de mÃ¡s de 50 lÃ­neas â€” refactoriza en funciones mÃ¡s pequeÃ±as
- âŒ Nombres como `data`, `info`, `result` â€” usa nombres descriptivos


---

## ğŸ“º Recursos Externos Recomendados

> Ver [RECURSOS_POR_MODULO.md](RECURSOS_POR_MODULO.md) para la lista completa.

| ğŸ·ï¸ | Recurso | Tipo |
|:--:|:--------|:-----|
| ğŸ”´ | [Type Hints - ArjanCodes](https://www.youtube.com/watch?v=dgBCEB2jVU0) | Video |
| ğŸ”´ | [Pydantic V2 Tutorial](https://www.youtube.com/watch?v=502XOB0u8OY) | Video |
| ğŸŸ¡ | [Python Type Checking - Real Python](https://realpython.com/python-type-checking/) | Tutorial |

**DocumentaciÃ³n oficial:**
- [PEP 484 â€“ Type Hints](https://peps.python.org/pep-0484/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Python Packaging Guide](https://packaging.python.org/)

---

## ğŸ”— Referencias del Glosario

Ver [21_GLOSARIO.md](21_GLOSARIO.md) para definiciones de:
- **Type Hints**: Anotaciones de tipos en Python
- **Pydantic**: ValidaciÃ³n de datos con type hints
- **src/ Layout**: Estructura de proyecto profesional

---

## âœ… Ejercicios

Ver [EJERCICIOS.md](EJERCICIOS.md) - MÃ³dulo 01:
- **1.1**: AÃ±adir type hints a funciones
- **1.2**: Crear config con Pydantic
- **1.3**: Estructurar proyecto con src/ layout

---

<div align="center">

[â† Volver al Ãndice](00_INDICE.md) | [Siguiente: DiseÃ±o de Sistemas ML â†’](02_DISENO_SISTEMAS.md)

</div>
