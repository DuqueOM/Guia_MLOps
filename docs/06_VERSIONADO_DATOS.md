# MÃ“DULO 06: INGENIERÃA DE DATOS Y DVC

<div align="center">

# ğŸ“Š MÃ“DULO 06: IngenierÃ­a de Datos y DVC

### El Arte de Versionar lo que Git No Puede

*"Si no puedo recrear tus datos, no puedo reproducir tu modelo."*

| DuraciÃ³n             | TeorÃ­a               | PrÃ¡ctica             |
| :------------------: | :------------------: | :------------------: |
| **5-6 horas**        | 30%                  | 70%                  |

</div>

---

<a id="00-prerrequisitos"></a>

## 0.0 Prerrequisitos

- Haber completado **[05_GIT_PROFESIONAL](05_GIT_PROFESIONAL.md)** (ramas limpias, PRs, `.gitignore`).
- Entender que **Git NO estÃ¡ hecho para datasets grandes**.
- Tener acceso (o plan) para un remote de DVC (local, GDrive, S3/GCS/Azure).

---

<a id="01-protocolo-e-como-estudiar-este-modulo"></a>

## 0.1 ğŸ§  Protocolo E: CÃ³mo estudiar este mÃ³dulo

- **Antes de correr comandos**: abre **[Protocolo E](study_tools/PROTOCOLO_E.md)** y define tu *output mÃ­nimo* (ej: â€œ`dvc.yaml` + `params.yaml` + repro reproducibleâ€).
- **Mientras integras DVC**: si te atoras >15 min (remotes, credenciales, `dvc repro`, `dvc checkout`), registra el bloqueo en **[Diario de Errores](study_tools/DIARIO_ERRORES.md)**.
- **Al cerrar la semana**: usa **[Cierre Semanal](study_tools/CIERRE_SEMANAL.md)** para decidir quÃ© mejorar (reproducibilidad, estructura del pipeline, naming de stages).

---

<a id="02-entregables-verificables-minimo-viable"></a>

## 0.2 âœ… Entregables verificables (mÃ­nimo viable)

Al terminar este mÃ³dulo, deberÃ­as poder mostrar (en al menos 1 proyecto del portafolio):

- [ ] **Datos trackeados por DVC** (no en Git), con `.dvc/` y/o archivos `.dvc` en el repo.
- [ ] **Remote configurado** y flujo bÃ¡sico funcionando: `dvc push` / `dvc pull`.
- [ ] **Pipeline reproducible** con `dvc.yaml` + `params.yaml` y `dvc repro`.
- [ ] **Evidencia**: poder recrear resultados al hacer `git checkout <tag>` + `dvc checkout` + `dvc pull`.

---

<a id="03-puente-teoria-codigo-portafolio"></a>

## 0.3 ğŸ§© Puente teorÃ­a â†” cÃ³digo (Portafolio)

Para que esto cuente como progreso real, fuerza este mapeo:

- **Concepto**: versionado de datos / DAG / reproducibilidad
- **Archivo**: `dvc.yaml`, `params.yaml`, `.dvc/config`, `data/**.dvc`, `metrics/*.json`
- **Comandos**: `dvc status`, `dvc dag`, `dvc repro`, `dvc push`, `dvc pull`, `dvc checkout`
- **Evidencia**: resultados reproducibles cuando cambias de commit/tag.

---

## ğŸ“‹ Contenido

- **0.0** [Prerrequisitos](#00-prerrequisitos)
- **0.1** [Protocolo E: CÃ³mo estudiar este mÃ³dulo](#01-protocolo-e-como-estudiar-este-modulo)
- **0.2** [Entregables verificables (mÃ­nimo viable)](#02-entregables-verificables-minimo-viable)
- **0.3** [Puente teorÃ­a â†” cÃ³digo (Portafolio)](#03-puente-teoria-codigo-portafolio)
- [ADR de Inicio](#adr-inicio)
- [6.1 El Problema](#61-problema)
- [6.2 ConfiguraciÃ³n Inicial](#62-configuracion)
- [6.3 Versionado BÃ¡sico](#63-versionado-basico)
- [6.4 Pipelines con dvc.yaml](#64-pipelines)
- [6.5 MÃ©tricas y Experimentos](#65-metricas)
- [6.6 ğŸ”¬ IngenierÃ­a Inversa: DVC Pipeline Real](#66-ingenieria-inversa-dvc) â­ NUEVO
- [Errores habituales](#errores-habituales)
- [6.7 Ejercicio Integrador](#67-ejercicio)
- [6.8 AutoevaluaciÃ³n](#68-autoevaluacion)

---

<a id="adr-inicio"></a>

## ğŸ¯ ADR de Inicio: Â¿CuÃ¡ndo (NO) Usar DVC?

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-006: Criterios para Usar DVC                                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  âœ… USA DVC SI:                                                               â•‘
â•‘  â€¢ Datos > 100MB que no caben cÃ³modamente en Git                              â•‘
â•‘  â€¢ Necesitas reproducibilidad exacta de datasets                              â•‘
â•‘  â€¢ Equipo colabora en el mismo pipeline de datos                              â•‘
â•‘  â€¢ Quieres DAGs declarativos para pipelines                                   â•‘
â•‘  â€¢ Datos son batch (no streaming)                                             â•‘
â•‘                                                                               â•‘
â•‘  âŒ NO USES DVC SI:                                                           â•‘
â•‘  â€¢ Datos < 50MB y no cambian frecuentemente â†’ Git LFS o Git directo           â•‘
â•‘  â€¢ Datos son streaming (Kafka, Kinesis) â†’ No aplica versionado batch          â•‘
â•‘  â€¢ Ya tienes Data Lake con Delta Lake/Iceberg â†’ Usar versionado nativo        â•‘
â•‘  â€¢ Solo 1 persona trabaja en el proyecto â†’ Puede ser overkill                 â•‘
â•‘  â€¢ Pipeline ya estÃ¡ en Airflow/Prefect â†’ Evitar duplicaciÃ³n                   â•‘
â•‘                                                                               â•‘
â•‘  DECISIÃ“N PARA BANKCHURN:                                                     â•‘
â•‘  Usar DVC porque: datos ~50MB con potencial de crecer, equipo colabora,       â•‘
â•‘  queremos reproducibilidad completa, y el pipeline es batch.                  â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Lo Que LograrÃ¡s en Este MÃ³dulo

1. **Entender** el problema del versionado de datos en ML
2. **Configurar** DVC con remote storage
3. **Crear** pipelines reproducibles con `dvc.yaml`
4. **DiseÃ±ar** DAGs para proyectos complejos

### ğŸ§© CÃ³mo se aplica en este portafolio

- En `BankChurn-Predictor/` ya tienes configurado DVC con:
  - `dvc.yaml` y `params.yaml` en la raÃ­z del proyecto.
  - Carpeta `data/` con datasets y `.dvc/` con metadatos de versionado.
- Desde esa carpeta puedes practicar el flujo completo de este mÃ³dulo ejecutando:
  ```bash
  cd BankChurn-Predictor
  dvc status
  dvc repro
  dvc pull
  ```
- Aplica los mismos principios a futuros proyectos del portafolio para mantener datos y
  pipelines de forma reproducible, especialmente cuando crees el proyecto integrador.

---

<a id="61-problema"></a>

## 6.1 El Problema: Git No Escala para Datos

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ˜± EL INFIERNO DEL VERSIONADO DE DATOS                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN VERSIONADO:                                                             â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â”œâ”€â”€ churn.csv                   # Â¿Original o procesado?                    â•‘
â•‘   â”œâ”€â”€ churn_v2.csv                # Â¿QuÃ© cambiÃ³?                              â•‘
â•‘   â”œâ”€â”€ churn_final.csv             # Â¿Es realmente el final?                   â•‘
â•‘   â”œâ”€â”€ churn_final_v2.csv          # ğŸ˜±                                        â•‘
â•‘   â”œâ”€â”€ churn_final_FINAL.csv       # ğŸ’€                                        â•‘
â•‘   â””â”€â”€ churn_20231115_backup.csv   # ???                                       â•‘
â•‘                                                                               â•‘
â•‘   PROBLEMAS:                                                                  â•‘
â•‘   â€¢ No sÃ© quÃ© datos usÃ³ el modelo v1.2.3                                      â•‘
â•‘   â€¢ No puedo reproducir resultados de hace 2 meses                            â•‘
â•‘   â€¢ Git se rompe con archivos grandes                                         â•‘
â•‘   â€¢ ColaboraciÃ³n es imposible ("Â¿tienes el CSV actualizado?")                 â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   CON DVC:                                                                    â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â””â”€â”€ raw/                                                                    â•‘
â•‘       â””â”€â”€ churn.csv.dvc     # Metadatos en Git, datos en storage              â•‘
â•‘                                                                               â•‘
â•‘   git checkout v1.2.3 && dvc checkout                                         â•‘
â•‘   â†’ Tengo EXACTAMENTE los datos de esa versiÃ³n                                â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Comparativa de Soluciones

| SoluciÃ³n | TamaÃ±o MÃ¡x | Versionado | Pipelines | Costo | Complejidad |
| :------- | :--------: | :--------: | :-------: | :---: | :---------: |
| Git directo | ~10MB | âœ… | âŒ | Gratis | Baja |
| Git LFS | ~2GB | âœ… | âŒ | $$$ | Baja |
| **DVC** | Ilimitado | âœ… | âœ… | Storage | Media |
| Delta Lake | Ilimitado | âœ… | âŒ | Spark | Alta |
| LakeFS | Ilimitado | âœ… | âŒ | Server | Alta |

### ğŸ§  Mapa Mental de Conceptos: DVC y Versionado de Datos

```
                          â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                          â•‘   DVC: DATA VERSION CONTROL          â•‘
                          â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                                            â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                                  â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VERSIONADO      â”‚              â”‚  PIPELINES       â”‚              â”‚  REMOTES         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                 â”‚                                 â”‚
â”œâ”€ data/*.dvc                     â”œâ”€ dvc.yaml                      â”œâ”€ S3
â”œâ”€ .dvc/ (metadatos)              â”œâ”€ params.yaml                   â”œâ”€ GCS
â”œâ”€ dvc add                        â”œâ”€ dvc repro                     â”œâ”€ Azure
â”œâ”€ dvc checkout                   â”œâ”€ dvc dag                       â”œâ”€ GDrive
â””â”€ dvc push/pull                  â””â”€ stages                        â””â”€ Local
```

**TÃ©rminos clave que debes dominar:**

| TÃ©rmino | Significado | Comando |
|---------|-------------|---------|
| **dvc add** | Trackear archivo/carpeta con DVC | `dvc add data/raw/churn.csv` |
| **dvc.yaml** | Pipeline declarativo (DAG) | Define stages y dependencias |
| **params.yaml** | ParÃ¡metros del pipeline | HiperparÃ¡metros, configs |
| **dvc repro** | Ejecutar pipeline reproducible | Solo re-ejecuta lo que cambiÃ³ |
| **Remote** | Storage externo para datos | S3, GCS, GDrive, local |
| **.dvc file** | Metadatos del archivo trackeado | Hash MD5, tamaÃ±o |

---

### ğŸ’» Ejercicio Puente: DVC BÃ¡sico

> **Meta**: Antes de crear pipelines complejos, domina el versionado bÃ¡sico.

**Ejercicio 1: Inicializar DVC**
```bash
# TU TAREA: En un proyecto nuevo
mkdir my-dvc-project && cd my-dvc-project
git init
dvc init

# Â¿QuÃ© archivos creÃ³ dvc init?
ls -la .dvc/
```

**Ejercicio 2: Trackear un archivo**
```bash
# Crea un CSV de prueba
echo "id,value" > data.csv
echo "1,100" >> data.csv

# TU TAREA: Trackea con DVC
dvc add data.csv

# Â¿QuÃ© archivos se crearon?
ls -la data.csv*
cat data.csv.dvc
```

**Ejercicio 3: Simular cambio de versiÃ³n**
```bash
# Commit versiÃ³n 1
git add data.csv.dvc .gitignore
git commit -m "data: add initial dataset v1"

# Modifica el archivo
echo "2,200" >> data.csv
dvc add data.csv
git add data.csv.dvc
git commit -m "data: add new row to dataset v2"

# TU TAREA: Vuelve a la versiÃ³n 1
git checkout HEAD~1 -- data.csv.dvc
dvc checkout
cat data.csv  # Â¿QuÃ© versiÃ³n tienes?
```

<details>
<summary>ğŸ” Ver SoluciÃ³n</summary>

```bash
# Ejercicio 1: dvc init crea:
# .dvc/
# â”œâ”€â”€ .gitignore
# â””â”€â”€ config

# Ejercicio 2: dvc add crea:
# data.csv.dvc  (metadatos con hash MD5)
# AdemÃ¡s aÃ±ade "data.csv" a .gitignore

# data.csv.dvc contiene algo como:
# outs:
# - md5: abc123...
#   size: 20
#   hash: md5
#   path: data.csv

# Ejercicio 3: DespuÃ©s de checkout
# Tienes la versiÃ³n 1 (solo 1 fila de datos)
# Porque Git restaurÃ³ el .dvc con el hash antiguo
# Y dvc checkout descargÃ³ esa versiÃ³n del cache
```
</details>

---

### ğŸ› ï¸ PrÃ¡ctica del Portafolio: DVC en BankChurn

> **Tarea**: Explorar y entender la configuraciÃ³n DVC de BankChurn-Predictor.

**Paso 1: Examina la estructura**
```bash
cd BankChurn-Predictor
ls -la .dvc/
cat .dvc/config
ls -la data/
```

**Paso 2: Entiende el pipeline**
```bash
# Ver el DAG visual
dvc dag

# Ver el pipeline completo
cat dvc.yaml

# Ver los parÃ¡metros
cat params.yaml
```

**Paso 3: Reproduce el pipeline**
```bash
# Ver quÃ© estÃ¡ desactualizado
dvc status

# Ejecutar pipeline completo
dvc repro

# Â¿QuÃ© stages se ejecutaron?
```

**Paso 4: Simula un experimento**
```bash
# Cambia un parÃ¡metro en params.yaml
# ej: test_size: 0.3 â†’ test_size: 0.2

# Â¿QuÃ© stages necesitan re-ejecutarse?
dvc status

# Ejecuta
dvc repro
```

---

### âœ… Checkpoint de Conocimiento: DVC

**Pregunta 1**: Â¿QuÃ© guarda Git cuando usas DVC para datos?

A) El archivo de datos completo  
B) Solo el archivo .dvc con metadatos (hash MD5)  
C) Una copia comprimida  
D) Nada, DVC reemplaza a Git  

**Pregunta 2**: Â¿CuÃ¡l es la ventaja de `dvc repro` sobre correr scripts manualmente?

A) Es mÃ¡s rÃ¡pido  
B) Solo re-ejecuta stages cuyas dependencias cambiaron  
C) Usa menos memoria  
D) Es mÃ¡s fÃ¡cil de escribir  

**Pregunta 3**: Si haces `git checkout v1.0.0` pero NO haces `dvc checkout`, Â¿quÃ© pasa?

A) Tienes cÃ³digo v1.0.0 pero datos de la versiÃ³n actual (inconsistente)  
B) Todo funciona automÃ¡ticamente  
C) Git falla  
D) DVC borra los datos  

**ğŸ”§ Escenario de Debugging:**

```
SituaciÃ³n: Ejecutas dvc repro y obtienes:
  ERROR: failed to reproduce 'train': 
  Could not find data/raw/churn.csv

Pero el archivo .dvc existe: data/raw/churn.csv.dvc
```

**Â¿CuÃ¡l es el problema y cÃ³mo lo solucionarÃ­as?**

<details>
<summary>ğŸ” Ver Respuestas</summary>

**Pregunta 1**: B) Solo el archivo .dvc con metadatos. Los datos reales van al remote storage.

**Pregunta 2**: B) Solo re-ejecuta stages cuyas dependencias cambiaron. Ahorra tiempo y recursos.

**Pregunta 3**: A) Tienes cÃ³digo v1.0.0 pero datos de la versiÃ³n actual. SIEMPRE haz `dvc checkout` despuÃ©s de `git checkout`.

**Escenario de Debugging**: 
- **Problema**: El archivo `.dvc` existe, pero los datos reales no estÃ¡n descargados.
- **SoluciÃ³n**: 
```bash
dvc pull  # Descarga los datos del remote
# O si no hay remote configurado:
dvc checkout  # Restaura desde cache local
```
- **PrevenciÃ³n**: DespuÃ©s de `git clone` siempre ejecuta `dvc pull`.
</details>

---

<a id="62-configuracion"></a>

## 6.2 ConfiguraciÃ³n Inicial de DVC

### InstalaciÃ³n

```bash
# Con pip
pip install dvc

# Con extras para storage
pip install "dvc[s3]"      # Amazon S3
pip install "dvc[gs]"      # Google Cloud Storage
pip install "dvc[azure]"   # Azure Blob Storage
pip install "dvc[gdrive]"  # Google Drive (para proyectos personales)
```

### InicializaciÃ³n

```bash
# En un repo Git existente
cd bankchurn-predictor           # Navega al proyecto (debe ser repo Git).
dvc init                         # Inicializa DVC en el repositorio.

# Esto crea:
# .dvc/           - Directorio de configuraciÃ³n de DVC (como .git para Git).
# .dvc/.gitignore - Ignora cache local de DVC.
# .dvc/config     - ConfiguraciÃ³n de remotes y opciones.
# .dvcignore      - Archivos/carpetas que DVC debe ignorar.
```

### Configurar Remote Storage

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 1: Local (para desarrollo)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d localremote /path/to/dvc-storage  # Crea remote llamado "localremote".
# -d = default remote: este remote se usa por defecto en push/pull.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 2: Amazon S3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d s3remote s3://my-bucket/dvc-storage  # s3://bucket/path formato S3.
dvc remote modify s3remote region us-east-1            # Configura regiÃ³n del bucket.
# Credenciales: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY en variables de entorno.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 3: Google Cloud Storage
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gcsremote gs://my-bucket/dvc-storage  # gs://bucket/path formato GCS.
# Credenciales: GOOGLE_APPLICATION_CREDENTIALS apunta a JSON de service account.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 4: Google Drive (Gratis, bueno para proyectos personales)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gdriveremote gdrive://folder-id      # folder-id: ID de carpeta en Drive.
# La primera vez pedirÃ¡ autenticaciÃ³n OAuth en el browser.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ver configuraciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cat .dvc/config                                        # Muestra configuraciÃ³n actual.
```

### Estructura de Directorios Recomendada

```
bankchurn-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (DVC tracked)
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ churn.csv          # â†’ churn.csv.dvc en Git
â”‚   â”œâ”€â”€ processed/             # Datos procesados (output de pipeline)
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ external/              # Datos de terceros
â”‚       â””â”€â”€ .gitkeep
â”œâ”€â”€ models/                    # Modelos entrenados (DVC tracked)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ .dvc/
â”‚   â””â”€â”€ config
â”œâ”€â”€ .dvcignore
â””â”€â”€ dvc.yaml                   # Pipeline definition
```

---

<a id="63-versionado-basico"></a>

## 6.3 Versionado BÃ¡sico de Archivos

### AÃ±adir Datos a DVC

```bash
# AÃ±adir archivo
dvc add data/raw/churn.csv

# Esto crea:
# data/raw/churn.csv.dvc   - Metadatos (hash, size)
# data/raw/.gitignore      - Ignora el CSV en Git

# Ver contenido del .dvc
cat data/raw/churn.csv.dvc
```

```yaml
# data/raw/churn.csv.dvc
outs:
- md5: abc123def456...
  size: 52428800
  hash: md5
  path: churn.csv
```

### Flujo de Trabajo

```bash
# 1. Modificar datos
# ... (actualizar churn.csv con nuevos registros)

# 2. Actualizar tracking
dvc add data/raw/churn.csv

# 3. Commit ambos cambios
git add data/raw/churn.csv.dvc data/raw/.gitignore
git commit -m "data(raw): update churn dataset with Q4 2024 data"

# 4. Push datos a remote
dvc push

# 5. Push cÃ³digo a Git
git push
```

### Recuperar Datos de VersiÃ³n Anterior

```bash
# Ver versiones del archivo
git log data/raw/churn.csv.dvc

# Checkout versiÃ³n especÃ­fica
git checkout v1.0.0 -- data/raw/churn.csv.dvc
dvc checkout data/raw/churn.csv

# O mÃ¡s simple: checkout todo
git checkout v1.0.0
dvc checkout
# â†’ Ahora tienes cÃ³digo Y datos de v1.0.0
```

---

<a id="64-pipelines"></a>

## 6.4 Pipelines con dvc.yaml (El Poder Real)

### Â¿Por QuÃ© Pipelines?

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         PIPELINES DVC: REPRODUCIBILIDAD                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN PIPELINE:                                                               â•‘
â•‘   "Para reproducir, ejecuta preprocess.py, luego train.py, luego..."          â•‘
â•‘   "Ah, pero primero asegÃºrate de tener los datos correctos..."                â•‘
â•‘   "Y usa los mismos hiperparÃ¡metros que estÃ¡n en... algÃºn lugar..."           â•‘
â•‘                                                                               â•‘
â•‘   CON PIPELINE DVC:                                                           â•‘
â•‘   $ dvc repro                                                                 â•‘
â•‘   â†’ Ejecuta TODO automÃ¡ticamente, en orden correcto,                          â•‘
â•‘     saltando stages que no cambiaron.                                         â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### dvc.yaml Completo para BankChurn

```yaml
# dvc.yaml
stages:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 1: PreparaciÃ³n de Datos
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  prepare:
    cmd: python src/bankchurn/data/prepare.py
    deps:
      - src/bankchurn/data/prepare.py
      - data/raw/churn.csv
      - configs/config.yaml
    params:
      - prepare.test_size
      - prepare.random_state
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 2: Feature Engineering
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  featurize:
    cmd: python src/bankchurn/features/build.py
    deps:
      - src/bankchurn/features/build.py
      - data/processed/train.csv
      - data/processed/test.csv
      - configs/config.yaml
    params:
      - features.numerical
      - features.categorical
    outs:
      - data/processed/train_features.pkl
      - data/processed/test_features.pkl

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 3: Entrenamiento
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  train:
    cmd: python src/bankchurn/training.py
    deps:
      - src/bankchurn/training.py
      - data/processed/train_features.pkl
      - configs/config.yaml
    params:
      - train.n_estimators
      - train.max_depth
      - train.random_state
    outs:
      - models/pipeline.pkl
    metrics:
      - metrics/train_metrics.json:
          cache: false

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 4: EvaluaciÃ³n
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  evaluate:
    cmd: python src/bankchurn/evaluate.py
    deps:
      - src/bankchurn/evaluate.py
      - models/pipeline.pkl
      - data/processed/test_features.pkl
    metrics:
      - metrics/eval_metrics.json:
          cache: false
    plots:
      - metrics/roc_curve.json:
          x: fpr
          y: tpr
      - metrics/confusion_matrix.json:
          template: confusion
          x: predicted
          y: actual
```

### params.yaml (ConfiguraciÃ³n del Pipeline)

```yaml
# params.yaml
prepare:
  test_size: 0.2
  random_state: 42

features:
  numerical:
    - CreditScore
    - Age
    - Tenure
    - Balance
    - NumOfProducts
    - EstimatedSalary
  categorical:
    - Geography
    - Gender

train:
  n_estimators: 100
  max_depth: 10
  random_state: 42
```

### Comandos de Pipeline

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REPRODUCIR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ejecutar todo el pipeline
dvc repro

# Ejecutar stage especÃ­fico (y sus dependencias)
dvc repro train

# Forzar re-ejecuciÃ³n (aunque no haya cambios)
dvc repro --force

# Ver quÃ© se ejecutarÃ­a sin ejecutar
dvc repro --dry

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZAR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver DAG en terminal
dvc dag

# Generar imagen del DAG
dvc dag --dot | dot -Tpng -o pipeline.png

# Ver dependencias de un stage
dvc dag --outs train
```

### VisualizaciÃ³n del DAG

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         DVC DAG: BANKCHURN                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                         â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘
â•‘                        â”‚  data/raw/*.csv â”‚                              â•‘
â•‘                        â”‚  configs/*.yaml â”‚                              â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â•‘
â•‘                                 â”‚                                       â•‘
â•‘                                 â–¼                                       â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘
â•‘                        â”‚    prepare      â”‚                              â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â•‘
â•‘                                 â”‚                                       â•‘
â•‘                                 â–¼                                       â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘
â•‘                        â”‚   featurize     â”‚                              â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â•‘
â•‘                                 â”‚                                       â•‘
â•‘                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â•‘
â•‘                     â–¼                       â–¼                           â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â•‘
â•‘            â”‚     train       â”‚    â”‚    (test data)  â”‚                   â•‘
â•‘            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â•‘
â•‘                     â”‚                      â”‚                            â•‘
â•‘                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â•‘
â•‘                                â–¼                                        â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â•‘
â•‘                       â”‚    evaluate     â”‚                               â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â•‘
â•‘                                â”‚                                        â•‘
â•‘                                â–¼                                        â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â•‘
â•‘                       â”‚    metrics/     â”‚                               â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â•‘
â•‘                                                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

<a id="65-metricas"></a>

## 6.5 MÃ©tricas y Experimentos

### Tracking de MÃ©tricas

```bash
# Ver mÃ©tricas actuales
dvc metrics show

# Comparar con otra rama/commit
dvc metrics diff HEAD~1

# Output ejemplo:
# Path                     Metric    HEAD     HEAD~1   Change
# metrics/eval_metrics.json  auc_roc   0.8721   0.8534   0.0187
# metrics/eval_metrics.json  f1        0.7234   0.7012   0.0222
```

### Experimentos con DVC

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EJECUTAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Experimento con cambio de parÃ¡metro
dvc exp run --set-param train.n_estimators=200

# MÃºltiples experimentos en paralelo
dvc exp run --queue --set-param train.n_estimators=100
dvc exp run --queue --set-param train.n_estimators=200
dvc exp run --queue --set-param train.n_estimators=300
dvc exp run --run-all --parallel 3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPARAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver todos los experimentos
dvc exp show

# Output:
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
# â”ƒ Experiment    â”ƒ auc_roc     â”ƒ f1          â”ƒ n_estimators   â”ƒ
# â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
# â”‚ main          â”‚ 0.8721      â”‚ 0.7234      â”‚ 100            â”‚
# â”‚ exp-abc123    â”‚ 0.8856      â”‚ 0.7421      â”‚ 200            â”‚
# â”‚ exp-def456    â”‚ 0.8812      â”‚ 0.7356      â”‚ 300            â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APLICAR MEJOR EXPERIMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Aplicar a workspace
dvc exp apply exp-abc123

# O crear branch
dvc exp branch exp-abc123 feature/best-model
```

---

<a id="66-patrones-avanzados"></a>

## 6.6 Patrones Avanzados

### Multi-Output Stages

```yaml
# dvc.yaml
stages:
  split:
    cmd: python src/split.py
    deps:
      - data/raw/full_dataset.csv
    outs:
      - data/processed/train.csv
      - data/processed/val.csv
      - data/processed/test.csv
```

### Stages Condicionales (foreach)

```yaml
# dvc.yaml - Entrenar mÃºltiples modelos
stages:
  train:
    foreach:
      - random_forest
      - xgboost
      - lightgbm
    do:
      cmd: python src/train.py --model ${item}
      deps:
        - src/train.py
        - data/processed/train.csv
      params:
        - train.${item}
      outs:
        - models/${item}.pkl
      metrics:
        - metrics/${item}_metrics.json:
            cache: false
```

### IntegraciÃ³n con MLflow

```python
# src/bankchurn/training.py
import mlflow
import dvc.api
import yaml

def train():
    # Obtener parÃ¡metros de DVC
    params = dvc.api.params_show()
    
    with mlflow.start_run():
        # Log parÃ¡metros
        mlflow.log_params(params["train"])
        
        # Entrenar...
        model = train_model(params["train"])
        
        # Log mÃ©tricas
        metrics = evaluate(model)
        mlflow.log_metrics(metrics)
        
        # Guardar mÃ©tricas para DVC tambiÃ©n
        with open("metrics/train_metrics.json", "w") as f:
            json.dump(metrics, f)
        
        # Log modelo
        mlflow.sklearn.log_model(model, "model")
```

---

<a id="66-ingenieria-inversa-dvc"></a>

## 6.6 ğŸ”¬ IngenierÃ­a Inversa PedagÃ³gica: DVC Pipeline Real

> **Objetivo**: Entender CADA decisiÃ³n detrÃ¡s del `dvc.yaml` del portafolio.

### 6.6.1 ğŸ¯ El "Por QuÃ©" ArquitectÃ³nico

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECISIONES ARQUITECTÃ“NICAS DEL PORTAFOLIO                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PROBLEMA 1: Â¿CÃ³mo garantizo que preprocesamiento se re-ejecuta si cambia algo? â”‚
â”‚  DECISIÃ“N: deps: [data/raw/Churn.csv, configs/config.yaml, script.py]           â”‚
â”‚  RESULTADO: DVC detecta cambios y re-ejecuta solo lo necesario                  â”‚
â”‚                                                                                 â”‚
â”‚  PROBLEMA 2: Â¿CÃ³mo evito re-entrenar si nada cambiÃ³?                            â”‚
â”‚  DECISIÃ“N: outs: [models/best_model.pkl] + DAG de dependencias                  â”‚
â”‚  RESULTADO: `dvc repro` es idempotente - solo ejecuta stages afectados          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.6.2 ğŸ” AnatomÃ­a de `dvc.yaml`

**Archivo**: `ML-MLOps-Portfolio/BankChurn-Predictor/dvc.yaml`

```yaml
stages:
  preprocess:
    cmd: python data/preprocess.py --input data/raw/Churn.csv --output data/processed/churn_processed.csv
    deps:                           # Si CUALQUIERA cambia â†’ re-ejecutar.
      - data/raw/Churn.csv          # Datos crudos.
      - configs/config.yaml         # ParÃ¡metros.
      - data/preprocess.py          # El script mismo.
    outs:
      - data/processed/churn_processed.csv

  train:
    cmd: python main.py --mode train --seed 42
    deps:
      - data/processed/churn_processed.csv  # Output del stage anterior (DAG).
      - main.py
    outs:
      - models/best_model.pkl
      - artifacts/training_results.json

  evaluate:
    cmd: python main.py --mode evaluate --model models/best_model.pkl
    deps:
      - models/best_model.pkl       # Depende del modelo entrenado.
    outs:
      - artifacts/metrics
```

### 6.6.3 ğŸš¨ Troubleshooting Preventivo

| SÃ­ntoma | Causa | SoluciÃ³n |
|---------|-------|----------|
| **Stage no se re-ejecuta** | Script no en `deps` | AÃ±ade el .py a deps. |
| **`dvc repro` ejecuta TODO** | Cache corrupto | `dvc gc -w` y re-ejecutar. |

---
 
<a id="errores-habituales"></a>

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en DVC

Aunque DVC parece â€œcaja negra que fallaâ€, en la prÃ¡ctica los errores suelen venir de **desalineaciÃ³n entre Git, datos y configuraciÃ³n**.

Si alguno de estos errores te tomÃ³ **>15 minutos**, regÃ­stralo en el **[Diario de Errores](study_tools/DIARIO_ERRORES.md)** y aplica el flujo de **rescate cognitivo** de **[Protocolo E](study_tools/PROTOCOLO_E.md)**.

### 1) Datos no aparecen al clonar el repo (`dvc pull`/`dvc checkout` olvidados)

**SÃ­ntomas tÃ­picos**

- Clonas el repositorio, ejecutas el cÃ³digo y obtienes errores como:
  ```text
  FileNotFoundError: data/raw/churn.csv not found
  ```
- La carpeta `data/` estÃ¡ vacÃ­a o solo tiene `.gitkeep`.

**CÃ³mo identificarlo**

- Ejecuta:
  ```bash
  dvc list .
  dvc status
  ```
  para ver quÃ© outs estÃ¡n trackeados.
- Mira si existen archivos `.dvc` (`data/raw/churn.csv.dvc`) pero no los datos reales.

**CÃ³mo corregirlo**

- DespuÃ©s de clonar o cambiar de rama/tag, **siempre** ejecuta:
  ```bash
  dvc pull      # trae los datos desde el remote
  dvc checkout  # sincroniza versiones de datos con los .dvc actuales
  ```
- Documenta esto en el README del proyecto y en este mÃ³dulo como parte del flujo estÃ¡ndar.

---

### 2) `.dvc` committeados pero remote sin configurar (`dvc push` fallando)

**SÃ­ntomas tÃ­picos**

- Haces `dvc push` y ves errores tipo:
  ```text
  ERROR: failed to push data to the cloud - config file error
  ```
  o credenciales faltantes.
- CompaÃ±eros de equipo tienen los `.dvc`, pero `dvc pull` no trae nada.

**CÃ³mo identificarlo**

- Revisa `.dvc/config` para ver quÃ© remote estÃ¡ configurado (`localremote`, `s3remote`, etc.).
- Ejecuta `dvc remote list` y valida que el remote por defecto (`-d`) exista y sea accesible.

**CÃ³mo corregirlo**

- AsegÃºrate de que todos usen **el mismo nombre de remote** y que estÃ© configurado en el repo (no solo en local).
- Para remotes cloud (S3, GCS): documenta las variables de entorno necesarias (`AWS_ACCESS_KEY_ID`, etc.).
- Haz un `dvc push` de prueba y luego un `dvc pull` desde otra mÃ¡quina para validar.

---

### 3) `dvc repro` no ejecuta stages que esperas (cambios no detectados)

**SÃ­ntomas tÃ­picos**

- Modificas cÃ³digo o parÃ¡metros, ejecutas `dvc repro` y ves:
  ```text
  Stage 'train' didn't change, skipping
  ```
  aunque esperabas que volviera a entrenar.

**CÃ³mo identificarlo**

- Mira el `dvc.yaml` y verifica que:
  - El script que cambiaste estÃ© en `deps:` del stage.
  - Los parÃ¡metros que tocaste estÃ©n en `params:`.

**CÃ³mo corregirlo**

- AsegÃºrate de listar **todas las dependencias reales** en `deps:` (scripts, configs, datos intermedios).
- Si cambiaste parÃ¡metros en `params.yaml`, agrÃ©galos a la lista `params:` del stage correspondiente.
- Si quieres forzar una re-ejecuciÃ³n puntual, usa `dvc repro --force train`.

---

### 4) Conflictos entre `.gitignore` y `.dvc` (datos en Git por accidente)

**SÃ­ntomas tÃ­picos**

- Ves archivos grandes (`data/raw/*.csv`, `models/*.pkl`) en `git status`.
- Existen `.dvc` pero los datos tambiÃ©n se han aÃ±adido a Git.

**CÃ³mo identificarlo**

- Revisa `data/raw/.gitignore` generado por `dvc add` y el `.gitignore` del proyecto principal; puede que se estÃ©n pisando.

**CÃ³mo corregirlo**

- Respeta el patrÃ³n DVC:
  - Los datos **no** se aÃ±aden a Git, solo los `.dvc`.
  - AsegÃºrate de que `.gitignore` incluya las carpetas de datos/artefactos y que no contradiga los `.gitignore` generados por DVC.
- Si ya has commiteado datos grandes, elimÃ­nalos del historial (o al menos del Ãºltimo commit) y deja solo los `.dvc`.

---

### 5) DVC + CI/CD: pipelines que fallan en GitHub Actions

**SÃ­ntomas tÃ­picos**

- En CI, `dvc repro` falla porque no encuentra datos o no tiene acceso al remote.

**CÃ³mo identificarlo**

- Revisa el workflow de CI y verifica si:
  - Has instalado DVC con los extras correctos (`dvc[s3]`, etc.).
  - Has configurado variables de entorno con credenciales.
  - EstÃ¡s ejecutando `dvc pull` **antes** de correr el pipeline.

**CÃ³mo corregirlo**

- AÃ±ade pasos en tu workflow:
  ```yaml
  - name: Install DVC
    run: pip install "dvc[s3]"

  - name: Pull data with DVC
    run: dvc pull

  - name: Run pipeline
    run: dvc repro
  ```
- Usa `dvc repro --dry` localmente para ver quÃ© deberÃ­a ejecutarse antes de llevarlo a CI.

---

### PatrÃ³n general de debugging en DVC

1. **Inspecciona el estado** con `dvc status` y `dvc dag`.
2. **Verifica remotes y credenciales** (`dvc remote list`, `.dvc/config`).
3. **Comprueba deps/outs/params** en `dvc.yaml` para el stage problemÃ¡tico.
4. **Sincroniza Git + DVC**: `git checkout <tag/branch>` seguido de `dvc checkout` y `dvc pull` si hace falta.

Con este checklist, DVC pasa de ser â€œcaja negra que fallaâ€ a una herramienta controlable para reproducir datos y pipelines.

---

<a id="67-ejercicio"></a>

## 6.7 Ejercicio Integrador

### Setup Completo de DVC

```bash
# 1. Inicializar DVC
cd bankchurn-predictor
dvc init

# 2. Configurar remote (local para empezar)
mkdir -p ~/dvc-storage
dvc remote add -d localremote ~/dvc-storage

# 3. Crear estructura de datos
mkdir -p data/{raw,processed} models metrics

# 4. AÃ±adir datos raw
# (asumiendo que tienes churn.csv)
cp /path/to/churn.csv data/raw/
dvc add data/raw/churn.csv

# 5. Crear dvc.yaml (copiar del ejemplo anterior)

# 6. Crear params.yaml

# 7. Commit todo
git add .
git commit -m "data(dvc): setup DVC pipeline"

# 8. Ejecutar pipeline
dvc repro

# 9. Push a remote
dvc push
git push
```

### Checklist de VerificaciÃ³n

```
CONFIGURACIÃ“N:
[ ] DVC inicializado
[ ] Remote configurado y funcionando
[ ] Datos raw tracked con DVC

PIPELINE:
[ ] dvc.yaml con stages definidos
[ ] params.yaml con parÃ¡metros
[ ] dvc repro ejecuta sin errores

VERSIONADO:
[ ] Puedo hacer git checkout + dvc checkout a versiones anteriores
[ ] dvc push/pull funcionan correctamente
[ ] MÃ©tricas se trackean con dvc metrics show
```

---

<a id="68-autoevaluacion"></a>

## 6.8 AutoevaluaciÃ³n

### Preguntas de ReflexiÃ³n

1. Â¿Por quÃ© DVC usa hashes MD5 en lugar de guardar los archivos?
2. Â¿QuÃ© pasa si cambio `params.yaml` pero no el cÃ³digo?
3. Â¿CuÃ¡ndo DVC salta un stage sin ejecutarlo?
4. Â¿CÃ³mo integrarÃ­as DVC con GitHub Actions para CI?

---

## ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio

El portafolio tiene DVC configurado a nivel global:

### Estructura DVC del Portafolio

```
ML-MLOps-Portfolio/
â”œâ”€â”€ .dvc/                  # ConfiguraciÃ³n DVC
â”‚   â””â”€â”€ config             # Remote storage config
â”œâ”€â”€ .dvc-storage/          # Remote local (para demo)
â”œâ”€â”€ .dvcignore            # Archivos a ignorar
â””â”€â”€ */data/raw/*.dvc       # Archivos .dvc en cada proyecto
```

### Archivos .dvc Reales

```bash
# BankChurn-Predictor/data/raw/bank_churn.csv.dvc
md5: abc123def456...
size: 1234567
path: bank_churn.csv

# CarVision-Market-Intelligence/data/raw/car_prices.csv.dvc
md5: xyz789ghi012...
size: 2345678
path: car_prices.csv
```

### Flujo de Datos en el Portafolio

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE DATOS DVC                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  data/raw/*.csv    â†’    .dvc files    â†’    .dvc-storage/     â”‚
â”‚  (gitignored)           (tracked)          (remote local)    â”‚
â”‚                                                              â”‚
â”‚  Para CI/CD:                                                 â”‚
â”‚  git clone â†’ dvc pull â†’ datos disponibles                    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comandos DVC del Portafolio

```bash
# Ver quÃ© datos estÃ¡n trackeados
dvc status

# Obtener datos despuÃ©s de clonar
dvc pull

# Agregar nuevos datos
dvc add data/raw/nuevos_datos.csv
git add data/raw/nuevos_datos.csv.dvc data/raw/.gitignore
git commit -m "data(dvc): add nuevos_datos"
dvc push
```

### ğŸ”§ Ejercicio: Trabaja con DVC Real

```bash
# 1. Ve a la raÃ­z del portafolio
cd ML-MLOps-Portfolio

# 2. Verifica estado de DVC
dvc status

# 3. ObtÃ©n los datos (si no los tienes)
dvc pull

# 4. Verifica que los datos existen
ls -la BankChurn-Predictor/data/raw/
ls -la CarVision-Market-Intelligence/data/raw/

# 5. Experimenta: modifica params y reproduce
cd BankChurn-Predictor
dvc repro  # Si tienes dvc.yaml configurado
```

---

## ğŸ’¼ Consejos Profesionales

> **Recomendaciones para destacar en entrevistas y proyectos reales**

### Para Entrevistas

1. **DVC vs Git LFS**: Explica que DVC es especÃ­fico para ML (pipelines, mÃ©tricas), LFS es genÃ©rico para archivos grandes.

2. **Reproducibilidad**: Menciona que puedes recrear cualquier experimento con `dvc checkout` + `git checkout`.

3. **Data Lineage**: Explica cÃ³mo DVC trackea la procedencia de datos transformados.

### Para Proyectos Reales

| SituaciÃ³n | Consejo |
|-----------|---------|
| Datos sensibles | Usa DVC con storage encriptado (S3 + KMS) |
| Datasets grandes | Usa `dvc push/pull` selectivo por carpeta |
| CI/CD | Cachea datos en CI para evitar descargas repetidas |
| ColaboraciÃ³n | Documenta dÃ³nde estÃ¡ el remote storage |

### Flujo Profesional de Datos

1. Raw data â†’ nunca modificar, solo agregar
2. Processed data â†’ versionado con DVC
3. Features â†’ cacheados para reutilizaciÃ³n
4. Modelos â†’ versionados con mÃ©tricas


---

## ğŸ“º Recursos Externos del MÃ³dulo

> ğŸ·ï¸ Sistema: ğŸ”´ Obligatorio | ğŸŸ¡ Recomendado | ğŸŸ¢ Complementario

### ğŸ¬ Videos

| ğŸ·ï¸ | TÃ­tulo | Canal | DuraciÃ³n | Link |
|:--:|:-------|:------|:--------:|:-----|
| ğŸ”´ | **DVC Tutorial - Data Version Control** | DVCorg | 12 min | [YouTube](https://www.youtube.com/watch?v=kLKBcPonMYw) |
| ğŸ”´ | **DVC Pipelines Deep Dive** | DVCorg | 18 min | [YouTube](https://www.youtube.com/watch?v=71IGzyH95UY) |
| ğŸŸ¡ | **MLOps with DVC and CML** | DataTalksClub | 45 min | [YouTube](https://www.youtube.com/watch?v=9BgIDqAzfuA) |

### ğŸ“š Cursos

| ğŸ·ï¸ | TÃ­tulo | Plataforma | DuraciÃ³n | Link |
|:--:|:-------|:-----------|:--------:|:-----|
| ğŸŸ¡ | Iterative Tools for ML | DVCorg | 4h | [Learn.iterative.ai](https://learn.iterative.ai/) |

### ğŸ“„ DocumentaciÃ³n

| ğŸ·ï¸ | Recurso | DescripciÃ³n |
|:--:|:--------|:------------|
| ğŸ”´ | [DVC Get Started](https://dvc.org/doc/start) | Tutorial oficial paso a paso |
| ğŸŸ¡ | [DVC Remote Storage](https://dvc.org/doc/user-guide/data-management/remote-storage) | ConfiguraciÃ³n de remotes S3/GCS |

---

## âš–ï¸ DecisiÃ³n TÃ©cnica: ADR-009 DVC

**Contexto**: Necesitamos versionar datasets grandes sin guardarlos en Git.

**DecisiÃ³n**: Usar DVC (Data Version Control).

**Alternativas Consideradas**:
- **Git LFS**: Pago por storage, menos features
- **S3 directo**: Sin versionado semÃ¡ntico
- **Delta Lake**: Overkill para nuestro tamaÃ±o

**Consecuencias**:
- âœ… Versionado semÃ¡ntico de datos
- âœ… Pipelines reproducibles con `dvc.yaml`
- âœ… IntegraciÃ³n con Git (`.dvc` files)
- âŒ Curva de aprendizaje adicional

---

## ğŸ”§ Ejercicios del MÃ³dulo

### Ejercicio 6.1: Inicializar DVC
**Objetivo**: Configurar DVC en un proyecto.
**Dificultad**: â­â­

```bash
# TU TAREA: Ejecutar y documentar cada paso

# 1. Inicializar DVC
dvc init

# 2. AÃ±adir remote local (para prÃ¡ctica)
dvc remote add -d localremote /tmp/dvc-storage

# 3. Trackear datos
dvc add data/raw/dataset.csv

# 4. Commitear archivos .dvc
git add data/raw/dataset.csv.dvc data/raw/.gitignore
git commit -m "chore(data): track dataset with DVC"

# PREGUNTA: Â¿QuÃ© archivos se crean? Â¿QuÃ© contiene el .dvc?
```

<details>
<summary>ğŸ’¡ Ver soluciÃ³n</summary>

**Archivos creados:**
- `data/raw/dataset.csv.dvc` â€” Metadatos del archivo (hash MD5)
- `data/raw/.gitignore` â€” Ignora el archivo real, trackea solo el `.dvc`

**Contenido del .dvc:**
```yaml
outs:
- md5: abc123def456...
  size: 1234567
  path: dataset.csv
```

**Flujo completo:**
```bash
# Inicializar
dvc init
git add .dvc .dvcignore
git commit -m "chore: initialize DVC"

# Configurar remote
dvc remote add -d myremote s3://my-bucket/dvc-storage
git add .dvc/config
git commit -m "chore(dvc): configure S3 remote"

# Trackear datos
dvc add data/raw/dataset.csv
git add data/raw/dataset.csv.dvc data/raw/.gitignore
git commit -m "chore(data): track dataset with DVC"

# Push datos al remote
dvc push
```
</details>

---

### Ejercicio 6.2: Pipeline DVC
**Objetivo**: Definir pipeline reproducible.
**Dificultad**: â­â­

```yaml
# dvc.yaml
# TU TAREA: Definir pipeline de 3 stages

stages:
  prepare:
    cmd: python src/data.py
    deps:
      # Â¿QuÃ© dependencias?
    outs:
      # Â¿QuÃ© outputs?

  train:
    cmd: python src/training.py
    deps:
      # ???
    outs:
      # ???
    metrics:
      # ???

  evaluate:
    cmd: python src/evaluate.py
    deps:
      # ???
    metrics:
      # ???
```

<details>
<summary>ğŸ’¡ Ver soluciÃ³n</summary>

```yaml
stages:
  prepare:
    cmd: python src/data.py
    deps:
      - src/data.py
      - data/raw/dataset.csv
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  train:
    cmd: python src/training.py
    deps:
      - src/training.py
      - data/processed/train.csv
    params:
      - train.n_estimators
      - train.max_depth
    outs:
      - models/model.joblib
    metrics:
      - metrics/train_metrics.json:
          cache: false

  evaluate:
    cmd: python src/evaluate.py
    deps:
      - src/evaluate.py
      - models/model.joblib
      - data/processed/test.csv
    metrics:
      - metrics/eval_metrics.json:
          cache: false
    plots:
      - plots/confusion_matrix.png
```

**Ejecutar pipeline:**
```bash
dvc repro          # Ejecuta stages necesarios
dvc metrics show   # Muestra mÃ©tricas
dvc plots show     # Genera visualizaciones
```
</details>

---

## ğŸ”— Glosario del MÃ³dulo

| TÃ©rmino | DefiniciÃ³n |
|---------|------------|
| **DVC** | Data Version Control - herramienta para versionar datos y pipelines ML |
| **Remote Storage** | Almacenamiento externo (S3, GCS, Azure) para datos versionados |
| **dvc.yaml** | Archivo que define stages de un pipeline reproducible |
| **dvc.lock** | Archivo generado con hashes exactos de cada stage ejecutado |

---

## ğŸ CHECKPOINT FASE 1: Fundamentos Completados

> ğŸ¯ **Â¡Has completado los mÃ³dulos 01-06!**
>
> Ahora tienes las bases de un MLOps Engineer profesional:
> - âœ… Python moderno con type hints y Pydantic
> - âœ… DiseÃ±o de sistemas ML
> - âœ… Estructura de proyectos profesional
> - âœ… Entornos reproducibles
> - âœ… Git profesional con pre-commit
> - âœ… Versionado de datos con DVC

---

### ğŸ“‹ Examen de Hito 1: Setup Profesional

> **Formato**: Self-Correction Code Review  
> **DuraciÃ³n**: 45-60 minutos  
> **Puntaje mÃ­nimo**: 70/100

#### Ejercicio de Examen: Type Hints y Estructura

**CÃ³digo a Revisar:**
```python
# archivo: src/bankchurn/training.py

def load_data(path):
    """Carga datos desde CSV."""
    import pandas as pd
    return pd.read_csv(path)

def prepare_features(df, target_col, features):
    X = df[features]
    y = df[target_col]
    return X, y

def train_model(X, y, n_estimators=100, max_depth=None):
    from sklearn.ensemble import RandomForestClassifier
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
    model.fit(X, y)
    return model
```

**Tu tarea**: Identifica TODOS los errores y propÃ³n correcciones.

<details>
<summary>ğŸ“ Ver SoluciÃ³n del Examen</summary>

**Errores Encontrados:**

| # | Problema | Severidad | CorrecciÃ³n |
|---|----------|-----------|------------|
| 1 | `load_data(path)` sin type hints | ğŸŸ¡ | `path: str \| Path` â†’ `pd.DataFrame` |
| 2 | Import dentro de funciÃ³n | ğŸŸ¢ | Mover imports al inicio |
| 3 | `prepare_features` sin tipos | ğŸŸ¡ | AÃ±adir tipos a parÃ¡metros y retorno |
| 4 | `train_model` sin tipo retorno | ğŸŸ¡ | `-> RandomForestClassifier` |
| 5 | Sin `random_state` | ğŸŸ¡ | AÃ±adir para reproducibilidad |

**CÃ³digo Corregido:**
```python
from pathlib import Path
from typing import Tuple, Sequence, Optional
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

def load_data(path: str | Path) -> pd.DataFrame:
    """Carga datos desde CSV."""
    return pd.read_csv(path)

def prepare_features(
    df: pd.DataFrame,
    target_col: str,
    features: Sequence[str]
) -> Tuple[pd.DataFrame, pd.Series]:
    """Separa features y target."""
    return df[list(features)], df[target_col]

def train_model(
    X: pd.DataFrame,
    y: pd.Series,
    n_estimators: int = 100,
    max_depth: Optional[int] = None
) -> RandomForestClassifier:
    """Entrena modelo Random Forest."""
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42
    )
    return model.fit(X, y)
```
</details>

---

### ğŸ¤ Simulacro de Entrevista: Nivel Junior

> **50 preguntas** para validar fundamentos (MÃ³dulos 01-06)
> **Tiempo**: 60 minutos
> **Objetivo**: PreparaciÃ³n para posiciones Junior ML Engineer

#### Preguntas de Muestra

**Python Moderno (10 preguntas)**
1. Â¿QuÃ© son los type hints y por quÃ© usarlos en ML?
2. Â¿Diferencia entre `dataclass` y Pydantic `BaseModel`?
3. Â¿QuÃ© hace `Field(ge=0, le=100)` en Pydantic?

**Estructura de Proyecto (8 preguntas)**
4. Â¿Por quÃ© usar `src/` layout en vez de flat layout?
5. Â¿QuÃ© es `pip install -e .` y cuÃ¡ndo usarlo?
6. Â¿QuÃ© debe contener un `pyproject.toml` mÃ­nimo?

**Git Profesional (8 preguntas)**
7. Â¿QuÃ© es un Conventional Commit? Da un ejemplo.
8. Â¿Para quÃ© sirve pre-commit y quÃ© hooks usarÃ­as?
9. Â¿Diferencia entre `git merge` y `git rebase`?

**DVC y Datos (8 preguntas)**
10. Â¿Por quÃ© no versionar datos directamente en Git?
11. Â¿QuÃ© contiene un archivo `.dvc`?
12. Â¿CÃ³mo reproducir un experimento con DVC?

<details>
<summary>ğŸ’¡ Ver Respuestas de Muestra</summary>

**1. Type hints en ML:**
> Documentan tipos esperados, ayudan al IDE con autocompletado, y permiten validaciÃ³n estÃ¡tica con mypy. En ML, evitan errores como pasar un `np.array` donde se esperaba `pd.DataFrame`.

**4. src/ layout:**
> Evita que Python importe el cÃ³digo local en vez del paquete instalado. Es el estÃ¡ndar profesional que permite `pip install -e .` y tests aislados.

**7. Conventional Commit:**
> `feat(training): add cross-validation support`
> - `feat`: nueva funcionalidad
> - `(training)`: scope/mÃ³dulo afectado
> - descripciÃ³n en imperativo

**11. Archivo .dvc:**
> Contiene el hash MD5 del archivo real, su tamaÃ±o y path. El archivo real se ignora en Git y se almacena en el remote de DVC.
</details>

---

[Ver simulacro completo â†’](SIMULACRO_ENTREVISTA_JUNIOR.md)

---

## ğŸª¤ La Trampa â€” Errores Comunes de Este MÃ³dulo

### Trampa 1: dvc add en archivo ya trackeado por Git

**SÃ­ntoma**:
```bash
dvc add data/customers.csv
# ERROR: data/customers.csv is already tracked by Git
```

**SoluciÃ³n**:
```bash
# 1. Remover de Git (mantener archivo local)
git rm --cached data/customers.csv

# 2. Ahora sÃ­, aÃ±adir a DVC
dvc add data/customers.csv

# 3. Commitear el .dvc y .gitignore
git add data/customers.csv.dvc data/.gitignore
git commit -m "data: track customers.csv with DVC"
```

---

### Trampa 2: dvc repro no detecta cambios en cÃ³digo

**SÃ­ntoma**:
```bash
# Modifico train.py
vim src/bankchurn/train.py

dvc repro
# "Stage 'train' didn't change, skipping"  â† Â¡DeberÃ­a re-ejecutar!
```

**Causa raÃ­z**: El archivo modificado no estÃ¡ en `deps:` del stage.

**SoluciÃ³n**:
```yaml
# dvc.yaml
stages:
  train:
    cmd: python src/bankchurn/train.py
    deps:
      - src/bankchurn/train.py      # â† El script
      - src/bankchurn/pipeline.py   # â† Dependencias del script
      - data/processed/train.csv    # â† Datos
    outs:
      - models/model.pkl
```

---

### Trampa 3: dvc pull falla silenciosamente

**SÃ­ntoma**:
```bash
dvc pull
# (sin output)
ls data/
# (vacÃ­o o archivos antiguos)
```

**SoluciÃ³n**:
```bash
# Verificar configuraciÃ³n
dvc remote list
dvc remote default

# Pull con verbose
dvc pull -v
```

---

## ğŸ“ Quiz del MÃ³dulo â€” Semanas 5-6

### Quiz Semana 5: DVC Fundamentos

#### Pregunta 1 (25 pts)
Â¿CuÃ¡l es la diferencia fundamental entre Git LFS y DVC?

<details>
<summary>âœ… Respuesta</summary>

| Aspecto | Git LFS | DVC |
|---------|---------|-----|
| **Storage** | GitHub (pago por ancho de banda) | Tu propio storage (S3, GCS, local) |
| **Pipelines** | âŒ No | âœ… `dvc.yaml` con DAGs |
| **Experimentos** | âŒ No | âœ… `dvc exp run` |
| **Cache** | âŒ No | âœ… Reutiliza artefactos |
</details>

#### Pregunta 2 (25 pts)
Â¿QuÃ© hace `dvc add data/raw.csv` internamente?

<details>
<summary>âœ… Respuesta</summary>

1. **Calcula hash MD5** del archivo
2. **Crea `data/raw.csv.dvc`** (puntero con el hash)
3. **AÃ±ade `data/raw.csv` a `.gitignore`**
4. **Mueve el archivo al cache** (`.dvc/cache/`)
</details>

#### Pregunta 3 (25 pts)
Â¿Por quÃ© `dvc repro` no re-ejecuta si no hay cambios?

<details>
<summary>âœ… Respuesta</summary>

DVC trackea **hashes de deps y outs** en `dvc.lock`. En `dvc repro`:
1. Calcula hashes actuales de deps
2. Compara con `dvc.lock`
3. Si coinciden â†’ skip
4. Si difieren â†’ re-ejecuta y actualiza lock
</details>

#### ğŸ”§ Ejercicio PrÃ¡ctico (25 pts)

Escribe un `dvc.yaml` con dos stages:
1. `prepare`: lee `data/raw.csv`, genera `data/processed.csv`
2. `train`: lee `data/processed.csv` + `src/train.py`, genera `models/model.pkl`

<details>
<summary>âœ… SoluciÃ³n</summary>

```yaml
stages:
  prepare:
    cmd: python src/prepare.py
    deps:
      - src/prepare.py
      - data/raw.csv
    outs:
      - data/processed.csv

  train:
    cmd: python src/train.py
    deps:
      - src/train.py
      - data/processed.csv
    outs:
      - models/model.pkl
    metrics:
      - metrics.json:
          cache: false
```
</details>

---

## ğŸ”œ Siguiente Fase: ML Engineering

Con los fundamentos completados, es hora de construir **pipelines de sklearn avanzados**.

**[Comenzar Fase 2 â†’ MÃ³dulo 07: sklearn Pipelines](07_SKLEARN_PIPELINES.md)**

---

<div align="center">

[â† Git Profesional](05_GIT_PROFESIONAL.md) | [Siguiente: sklearn Pipelines â†’](07_SKLEARN_PIPELINES.md)

</div>
